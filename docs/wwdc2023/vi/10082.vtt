WEBVTT

00:00:00.000 --> 00:00:02.000
♪ Hip-hop nhạc cụ êm dịu ♪

00:00:02.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:12.000
Ryan Taylor: Xin chào! Tên tôi là Ryan.

00:00:12.000 --> 00:00:13.000
Conner Brooks: Và Tôi Là Conner.

00:00:13.000 --> 00:00:18.000
Ryan: Trong phiên này, chúng tôi sẽ giới thiệu cho bạn ARKit về điện toán không gian.

00:00:18.000 --> 00:00:25.000
Chúng ta sẽ thảo luận về vai trò quan trọng của nó trên nền tảng mới này và cách bạn có thể tận dụng nó để xây dựng thế hệ ứng dụng tiếp theo.

00:00:25.000 --> 00:00:32.000
ARKit sử dụng các thuật toán thị giác máy tính tinh vi để xây dựng sự hiểu biết về thế giới xung quanh bạn, cũng như các chuyển động của bạn.

00:00:32.000 --> 00:00:42.000
Lần đầu tiên chúng tôi giới thiệu công nghệ này trong iOS 11 như một cách để các nhà phát triển tạo ra những trải nghiệm thực tế tăng cường tuyệt vời mà bạn có thể sử dụng trong lòng bàn tay của mình.

00:00:42.000 --> 00:00:50.000
Trên nền tảng này, ARKit đã trưởng thành thành một dịch vụ hệ thống toàn diện, được xây dựng lại từ đầu với nền tảng thời gian thực mới.

00:00:50.000 --> 00:01:00.000
ARKit được đan xen sâu vào kết cấu của toàn bộ hệ điều hành, cung cấp năng lượng cho mọi thứ từ tương tác với cửa sổ, đến chơi một trò chơi nhập vai.

00:01:00.000 --> 00:01:04.000
Là một phần của hành trình này, chúng tôi cũng đã đại tu hoàn toàn API của mình.

00:01:04.000 --> 00:01:12.000
Thiết kế mới là kết quả của mọi thứ mà chúng tôi đã học trên iOS, cộng với nhu cầu độc đáo của điện toán không gian và chúng tôi nghĩ rằng bạn sẽ thích nó.

00:01:12.000 --> 00:01:21.000
ARKit cung cấp nhiều tính năng mạnh mẽ mà bạn có thể kết hợp để làm những điều đáng kinh ngạc, chẳng hạn như đặt nội dung ảo trên bàn.

00:01:21.000 --> 00:01:27.000
Bạn có thể tiếp cận và chạm vào nội dung, như thể nó thực sự ở đó, và sau đó xem nội dung tương tác với thế giới thực.

00:01:27.000 --> 00:01:30.000
Đó thực sự là một trải nghiệm kỳ diệu.

00:01:30.000 --> 00:01:38.000
Bây giờ bạn đã thấy một cái nhìn thoáng qua về những gì có thể được thực hiện bằng cách sử dụng ARKit trên nền tảng mới này, hãy để tôi hướng dẫn bạn qua chương trình nghị sự của chúng tôi.

00:01:38.000 --> 00:01:43.000
Chúng ta sẽ bắt đầu với một cái nhìn tổng quan về các khái niệm cơ bản và các khối xây dựng tạo nên API của chúng ta.

00:01:43.000 --> 00:01:50.000
Tiếp theo, chúng ta sẽ đi sâu vào theo dõi thế giới, điều cần thiết để đặt nội dung ảo so với thế giới thực.

00:01:50.000 --> 00:01:57.000
Sau đó, chúng tôi sẽ khám phá các tính năng hiểu cảnh của chúng tôi, cung cấp thông tin hữu ích về môi trường xung quanh bạn.

00:01:57.000 --> 00:02:10.000
Sau đó, chúng tôi sẽ giới thiệu cho bạn tính năng mới nhất của chúng tôi, theo dõi bằng tay, một bổ sung mới thú vị mà bạn có thể tận dụng để đặt nội dung ảo so với bàn tay của mình hoặc xây dựng các loại tương tác riêng biệt khác.

00:02:10.000 --> 00:02:20.000
Và cuối cùng, chúng tôi sẽ đi vòng tròn đầy đủ và xem xét ứng dụng thực tế của một số tính năng này bằng cách kiểm tra mã từ video mà chúng tôi đã cho bạn xem cách đây một lúc.

00:02:20.000 --> 00:02:22.000
Được rồi, hãy bắt đầu nào!

00:02:22.000 --> 00:02:31.000
API mới của chúng tôi đã được chế tạo tỉ mỉ với hai hương vị tiếp thêm sinh lực, Swift hiện đại và C cổ điển.

00:02:31.000 --> 00:02:35.000
Tất cả các tính năng của ARKit hiện được cung cấp gọi món.

00:02:35.000 --> 00:02:43.000
Chúng tôi muốn các nhà phát triển có càng linh hoạt càng tốt, để bạn có thể chỉ cần chọn và chọn những gì bạn cần để xây dựng trải nghiệm của mình.

00:02:43.000 --> 00:02:47.000
Quyền truy cập vào dữ liệu ARKit đã được thiết kế với cách tiếp cận ưu tiên quyền riêng tư.

00:02:47.000 --> 00:02:54.000
Chúng tôi đã đưa ra các biện pháp bảo vệ để bảo vệ quyền riêng tư của mọi người, đồng thời duy trì sự đơn giản cho các nhà phát triển.

00:02:54.000 --> 00:03:03.000
API bao gồm ba khối xây dựng cơ bản: phiên, nhà cung cấp dữ liệu và neo.

00:03:03.000 --> 00:03:08.000
Hãy bắt đầu với neo và sau đó làm việc theo cách của chúng tôi trở lại các phiên.

00:03:08.000 --> 00:03:12.000
Một mỏ neo đại diện cho một vị trí và định hướng trong thế giới thực.

00:03:12.000 --> 00:03:17.000
Tất cả các neo bao gồm một mã định danh duy nhất, cũng như một biến đổi.

00:03:17.000 --> 00:03:20.000
Một số loại neo cũng có thể theo dõi được.

00:03:20.000 --> 00:03:28.000
Khi một neo có thể theo dõi không được theo dõi, bạn nên ẩn bất kỳ nội dung ảo nào mà bạn đã neo với nó.

00:03:28.000 --> 00:03:32.000
Nhà cung cấp dữ liệu đại diện cho một tính năng ARKit riêng lẻ.

00:03:32.000 --> 00:03:37.000
Các nhà cung cấp dữ liệu cho phép bạn thăm dò ý kiến hoặc quan sát các cập nhật dữ liệu, chẳng hạn như thay đổi neo.

00:03:37.000 --> 00:03:42.000
Các loại nhà cung cấp dữ liệu khác nhau cung cấp các loại dữ liệu khác nhau.

00:03:42.000 --> 00:03:48.000
Một phiên đại diện cho một tập hợp các tính năng ARKit kết hợp mà bạn muốn sử dụng cùng nhau cho một trải nghiệm cụ thể.

00:03:48.000 --> 00:03:53.000
Bạn điều hành một phiên bằng cách cung cấp cho nó một tập hợp các nhà cung cấp dữ liệu.

00:03:53.000 --> 00:03:58.000
Khi phiên đang chạy, các nhà cung cấp dữ liệu sẽ bắt đầu nhận dữ liệu.

00:03:58.000 --> 00:04:03.000
Các bản cập nhật đến không đồng bộ và ở các tần số khác nhau, tùy thuộc vào loại dữ liệu.

00:04:03.000 --> 00:04:08.000
Hãy tiếp tục ngay bây giờ và nói về quyền riêng tư và cách ứng dụng của bạn có quyền truy cập vào dữ liệu ARKit.

00:04:08.000 --> 00:04:11.000
Quyền riêng tư là một quyền cơ bản của con người.

00:04:11.000 --> 00:04:14.000
Nó cũng là một trong những giá trị cốt lõi của chúng tôi.

00:04:14.000 --> 00:04:18.000
Kiến trúc và API của ARKit đã được thiết kế chu đáo để bảo vệ quyền riêng tư của mọi người.

00:04:18.000 --> 00:04:25.000
Để ARKit xây dựng sự hiểu biết về thế giới xung quanh bạn, thiết bị có nhiều máy ảnh và các loại cảm biến khác.

00:04:25.000 --> 00:04:30.000
Dữ liệu từ các cảm biến này, chẳng hạn như khung máy ảnh, không bao giờ được gửi đến không gian khách hàng.

00:04:30.000 --> 00:04:36.000
Thay vào đó, dữ liệu cảm biến được gửi đến trình nền của ARKit để xử lý an toàn bởi các thuật toán của chúng tôi.

00:04:36.000 --> 00:04:45.000
Dữ liệu kết quả được tạo ra bởi các thuật toán này sau đó được sắp xếp cẩn thận trước khi được chuyển tiếp đến bất kỳ khách hàng nào đang yêu cầu dữ liệu, chẳng hạn như ứng dụng của bạn.

00:04:45.000 --> 00:04:49.000
Có một vài điều kiện tiên quyết để truy cập dữ liệu ARKit.

00:04:49.000 --> 00:04:52.000
Đầu tiên, ứng dụng của bạn phải vào Full Space.

00:04:52.000 --> 00:04:57.000
ARKit không gửi dữ liệu đến các ứng dụng nằm trong Không gian chia sẻ.

00:04:57.000 --> 00:05:01.000
Thứ hai, một số loại dữ liệu ARKit yêu cầu quyền truy cập.

00:05:01.000 --> 00:05:07.000
Nếu người đó không cấp quyền, thì chúng tôi sẽ không gửi loại dữ liệu đó đến ứng dụng của bạn.

00:05:07.000 --> 00:05:15.000
Để tạo điều kiện thuận lợi cho việc này, ARKit cung cấp một API ủy quyền thuận tiện để xử lý quyền.

00:05:15.000 --> 00:05:21.000
Sử dụng phiên của bạn, bạn có thể yêu cầu ủy quyền cho các loại dữ liệu mà bạn muốn truy cập.

00:05:21.000 --> 00:05:29.000
Nếu bạn không làm điều này, ARKit sẽ tự động nhắc người đó cho phép khi bạn chạy phiên, nếu cần.

00:05:29.000 --> 00:05:32.000
Ở đây, chúng tôi đang yêu cầu quyền truy cập vào dữ liệu theo dõi bằng tay.

00:05:32.000 --> 00:05:39.000
Bạn có thể gộp tất cả các loại ủy quyền mà bạn cần lại với nhau trong một yêu cầu duy nhất.

00:05:39.000 --> 00:05:46.000
Khi chúng tôi có kết quả ủy quyền, chúng tôi lặp lại chúng và kiểm tra trạng thái cho từng loại ủy quyền.

00:05:46.000 --> 00:05:51.000
Nếu người đó đã cho phép, trạng thái sẽ được cho phép.

00:05:51.000 --> 00:05:59.000
Cố gắng chạy một phiên với nhà cung cấp dữ liệu cung cấp dữ liệu mà người đó đã từ chối quyền truy cập sẽ dẫn đến phiên không thành công.

00:05:59.000 --> 00:06:06.000
Bây giờ, chúng ta hãy xem xét kỹ hơn từng tính năng mà ARKit hỗ trợ trên nền tảng này, bắt đầu với theo dõi thế giới.

00:06:06.000 --> 00:06:10.000
Theo dõi thế giới cho phép bạn neo nội dung ảo trong thế giới thực.

00:06:10.000 --> 00:06:19.000
ARKit theo dõi chuyển động của thiết bị theo sáu bậc tự do và cập nhật từng neo, để chúng ở cùng một vị trí so với môi trường xung quanh bạn.

00:06:19.000 --> 00:06:26.000
Loại DataProvider mà theo dõi thế giới sử dụng được gọi là WorldTrackingProvider, và nó cung cấp cho bạn một số khả năng quan trọng.

00:06:26.000 --> 00:06:34.000
Nó cho phép bạn thêm WorldAnchors, mà ARKit sau đó sẽ cập nhật để vẫn cố định so với môi trường xung quanh mọi người khi thiết bị di chuyển xung quanh.

00:06:34.000 --> 00:06:38.000
WorldAnchors là một công cụ thiết yếu để sắp xếp nội dung ảo.

00:06:38.000 --> 00:06:43.000
Bất kỳ WorldAnchors nào mà bạn thêm sẽ tự động tồn tại khi khởi chạy và khởi động lại ứng dụng.

00:06:43.000 --> 00:06:52.000
Nếu hành vi này là không mong muốn đối với trải nghiệm mà bạn đang xây dựng, bạn có thể chỉ cần loại bỏ các neo khi bạn hoàn thành chúng và chúng sẽ không còn tồn tại nữa.

00:06:52.000 --> 00:06:57.000
Điều quan trọng cần lưu ý là có một số trường hợp không có sự kiên trì.

00:06:57.000 --> 00:07:06.000
Bạn cũng có thể sử dụng WorldTrackingProvider để có được tư thế của thiết bị liên quan đến nguồn gốc ứng dụng, điều này là cần thiết nếu bạn đang tự kết xuất bằng Metal.

00:07:06.000 --> 00:07:11.000
Hãy bắt đầu bằng cách xem xét kỹ hơn WorldAnchor là gì và tại sao bạn lại muốn sử dụng nó.

00:07:11.000 --> 00:07:22.000
WorldAnchor là một TrackableAnchor với trình khởi tạo nhận chuyển đổi, đó là vị trí và hướng mà bạn muốn đặt neo, liên quan đến nguồn gốc của ứng dụng.

00:07:22.000 --> 00:07:29.000
Chúng tôi đã chuẩn bị một ví dụ để giúp hình dung sự khác biệt giữa nội dung ảo không được neo và nội dung được neo.

00:07:29.000 --> 00:07:32.000
Ở đây chúng ta có hai hình khối.

00:07:32.000 --> 00:07:40.000
Khối lập phương màu xanh ở bên trái không được cập nhật bởi WorldAnchor, trong khi khối lập phương màu đỏ ở bên phải đang được cập nhật bởi WorldAnchor.

00:07:40.000 --> 00:07:45.000
Cả hai hình khối được đặt liên quan đến nguồn gốc của ứng dụng khi ứng dụng được khởi chạy.

00:07:45.000 --> 00:07:50.000
Khi thiết bị di chuyển xung quanh, cả hai hình khối vẫn ở nơi chúng được đặt.

00:07:50.000 --> 00:07:54.000
Bạn có thể nhấn và giữ vương miện để cập ứng dụng gần đây hơn.

00:07:54.000 --> 00:07:59.000
Khi recentering xảy ra, nguồn gốc của ứng dụng sẽ được chuyển đến vị trí hiện tại của bạn.

00:07:59.000 --> 00:08:11.000
Lưu ý rằng khối lập phương màu xanh lam, không được neo, di chuyển để duy trì vị trí tương đối của nó với nguồn gốc của ứng dụng; trong khi khối lập phương màu đỏ, được neo, vẫn cố định so với thế giới thực.

00:08:11.000 --> 00:08:14.000
Hãy cùng xem sự kiên trì của WorldAnchor hoạt động như thế nào.

00:08:14.000 --> 00:08:19.000
Khi thiết bị di chuyển xung quanh, ARKit sẽ xây dựng một bản đồ xung quanh bạn.

00:08:19.000 --> 00:08:25.000
Khi bạn thêm WorldAnchors, chúng tôi sẽ chèn chúng vào bản đồ và tự động duy trì chúng cho bạn.

00:08:25.000 --> 00:08:29.000
Chỉ những định danh và biến đổi của WorldAnchor mới được duy trì.

00:08:29.000 --> 00:08:33.000
Không có dữ liệu nào khác, chẳng hạn như nội dung ảo của bạn, được bao gồm.

00:08:33.000 --> 00:08:41.000
Tùy thuộc vào bạn để duy trì ánh xạ các số nhận dạng WorldAnchor cho bất kỳ nội dung ảo nào mà bạn liên kết với chúng.

00:08:41.000 --> 00:08:53.000
Bản đồ dựa trên vị trí, vì vậy khi bạn đưa thiết bị của mình đến một vị trí mới - ví dụ: từ nhà đến văn phòng - bản đồ nhà của bạn sẽ được dỡ xuống và sau đó một bản đồ khác sẽ được bản địa hóa cho văn phòng.

00:08:53.000 --> 00:08:59.000
Bất kỳ neo nào mà bạn thêm vào tại vị trí mới này sẽ đi vào bản đồ đó.

00:08:59.000 --> 00:09:09.000
Khi bạn rời văn phòng vào cuối ngày và về nhà, bản đồ mà ARKit đang xây dựng tại văn phòng, cùng với bất kỳ mỏ neo nào bạn đặt ở đó, sẽ được dỡ xuống.

00:09:09.000 --> 00:09:14.000
Tuy nhiên, một lần nữa, chúng tôi đã tự động duy trì bản đồ cùng với các neo của bạn.

00:09:14.000 --> 00:09:26.000
Khi trở về nhà, ARKit sẽ nhận ra rằng vị trí đã thay đổi và chúng tôi sẽ bắt đầu quá trình định vị lại bằng cách kiểm tra bản đồ hiện có cho vị trí này.

00:09:26.000 --> 00:09:35.000
Nếu chúng tôi tìm thấy một cái, chúng tôi sẽ bản địa hóa với nó và tất cả các neo mà bạn đã thêm trước đó ở nhà sẽ bị theo dõi một lần nữa.

00:09:35.000 --> 00:09:38.000
Hãy chuyển sang tư thế thiết bị.

00:09:38.000 --> 00:09:45.000
Cùng với việc thêm và xóa WorldAnchors, bạn cũng có thể sử dụng WorldTrackingProvider để có được tư thế của thiết bị.

00:09:45.000 --> 00:09:50.000
Tư thế là vị trí và hướng của thiết bị liên quan đến nguồn gốc của ứng dụng.

00:09:50.000 --> 00:09:58.000
Truy vấn tư thế là bắt buộc nếu bạn đang thực hiện kết xuất của riêng mình với Metal và CompositorServices trong một trải nghiệm hoàn toàn nhập vai.

00:09:58.000 --> 00:10:00.000
Truy vấn này tương đối tốn kém.

00:10:00.000 --> 00:10:07.000
Hãy thận trọng khi truy vấn tư thế thiết bị cho các loại logic ứng dụng khác, chẳng hạn như vị trí nội dung.

00:10:07.000 --> 00:10:16.000
Hãy nhanh chóng xem qua một ví dụ kết xuất đơn giản để chứng minh cách bạn có thể cung cấp các tư thế thiết bị từ ARKit đến CompositorServices.

00:10:16.000 --> 00:10:23.000
Chúng tôi có một cấu trúc Trình kết xuất sẽ tổ chức phiên của chúng tôi, nhà cung cấp theo dõi thế giới và tư thế mới nhất.

00:10:23.000 --> 00:10:28.000
Khi khởi tạo Renderer, chúng tôi bắt đầu bằng cách tạo một phiên.

00:10:28.000 --> 00:10:36.000
Tiếp theo, chúng tôi tạo ra một nhà cung cấp theo dõi thế giới, mà chúng tôi sẽ sử dụng để truy vấn cho tư thế thiết bị khi chúng tôi hiển thị từng khung hình.

00:10:36.000 --> 00:10:41.000
Bây giờ, chúng ta có thể tiếp tục và chạy phiên của mình với bất kỳ nhà cung cấp dữ liệu nào mà chúng ta cần.

00:10:41.000 --> 00:10:45.000
Trong trường hợp này, chúng tôi chỉ sử dụng nhà cung cấp dịch vụ theo dõi thế giới.

00:10:45.000 --> 00:10:49.000
Chúng tôi cũng tạo ra một tư thế để tránh phân bổ trong hàm kết xuất.

00:10:49.000 --> 00:10:55.000
Hãy chuyển sang chức năng kết xuất của chúng tôi ngay bây giờ, chúng tôi sẽ gọi ở tốc độ khung hình.

00:10:55.000 --> 00:11:00.000
Sử dụng bản vẽ từ CompositorServices, chúng tôi tìm nạp thời gian kết xuất mục tiêu.

00:11:00.000 --> 00:11:06.000
Tiếp theo, chúng tôi sử dụng thời gian kết xuất mục tiêu để truy vấn tư thế của thiết bị.

00:11:06.000 --> 00:11:11.000
Nếu thành công, chúng ta có thể trích xuất một biến đổi của tư thế liên quan đến nguồn gốc của ứng dụng.

00:11:11.000 --> 00:11:15.000
Đây là sự chuyển đổi để sử dụng để hiển thị nội dung của bạn.

00:11:15.000 --> 00:11:25.000
Cuối cùng, trước khi chúng tôi gửi khung để tổng hợp, chúng tôi đã đặt tư thế trên có thể vẽ được, để bộ tổng hợp biết chúng tôi đã sử dụng tư thế nào để hiển thị nội dung cho khung.

00:11:25.000 --> 00:11:32.000
Để biết thêm thông tin về việc thực hiện kết xuất của riêng bạn, hãy xem phiên dành riêng cho việc sử dụng Metal để tạo các ứng dụng nhập vai.

00:11:32.000 --> 00:11:39.000
Ngoài ra, có một phiên tuyệt vời về các cân nhắc hiệu suất điện toán không gian mà chúng tôi cũng khuyến khích bạn kiểm tra.

00:11:39.000 --> 00:11:43.000
Tiếp theo, chúng ta hãy xem xét sự hiểu biết về cảnh.

00:11:43.000 --> 00:11:48.000
Hiểu cảnh là một loại các tính năng thông báo cho bạn về môi trường xung quanh theo những cách khác nhau.

00:11:48.000 --> 00:11:51.000
Hãy bắt đầu với việc phát hiện máy bay.

00:11:51.000 --> 00:11:58.000
Phát hiện mặt phẳng cung cấp neo cho các bề mặt ngang và dọc mà ARKit phát hiện trong thế giới thực.

00:11:58.000 --> 00:12:03.000
Loại DataProvider mà tính năng phát hiện mặt phẳng sử dụng được gọi là PlaneDetectionProvider.

00:12:03.000 --> 00:12:09.000
Khi các máy bay được phát hiện xung quanh bạn, chúng được cung cấp cho bạn dưới dạng PlaneAnchors.

00:12:09.000 --> 00:12:16.000
PlaneAnchors có thể được sử dụng để tạo điều kiện thuận lợi cho việc đặt nội dung, chẳng hạn như đặt một đối tượng ảo trên bàn.

00:12:16.000 --> 00:12:24.000
Ngoài ra, bạn có thể sử dụng các mặt phẳng để mô phỏng vật lý trong đó hình học phẳng, cơ bản, chẳng hạn như sàn hoặc tường, là đủ.

00:12:24.000 --> 00:12:35.000
Mỗi PlaneAnchor bao gồm một căn chỉnh, nằm ngang hoặc dọc; hình học của mặt phẳng; và một phân loại ngữ nghĩa.

00:12:35.000 --> 00:12:40.000
Máy bay có thể được phân loại là nhiều loại bề mặt khác nhau, chẳng hạn như sàn hoặc bàn.

00:12:40.000 --> 00:12:51.000
Nếu chúng tôi không thể xác định một bề mặt cụ thể, phân loại được cung cấp sẽ được đánh dấu là không xác định, không xác định hoặc không có sẵn, tùy thuộc vào hoàn cảnh.

00:12:51.000 --> 00:12:55.000
Bây giờ, hãy chuyển sang hình học cảnh.

00:12:55.000 --> 00:13:02.000
Hình học cảnh cung cấp các neo chứa một lưới đa giác ước tính hình dạng của thế giới thực.

00:13:02.000 --> 00:13:08.000
Loại DataProvider mà hình học cảnh sử dụng được gọi là SceneReconstructionProvider.

00:13:08.000 --> 00:13:18.000
Khi ARKit quét thế giới xung quanh bạn, chúng tôi tái tạo lại môi trường xung quanh bạn dưới dạng lưới được chia nhỏ, sau đó được cung cấp cho bạn dưới dạng MeshAnchors.

00:13:18.000 --> 00:13:23.000
Giống như PlaneAnchors, MeshAnchors có thể được sử dụng để tạo điều kiện thuận lợi cho việc đặt nội dung.

00:13:23.000 --> 00:13:33.000
Bạn cũng có thể đạt được các mô phỏng vật lý có độ trung thực cao hơn trong trường hợp bạn cần nội dung ảo để tương tác với các đối tượng không chỉ đơn giản, bề mặt phẳng.

00:13:33.000 --> 00:13:37.000
Mỗi MeshAnchor bao gồm hình dạng của lưới.

00:13:37.000 --> 00:13:47.000
Hình học này chứa các đỉnh, chuẩn mực, mặt và phân loại ngữ nghĩa, trên mỗi mặt.

00:13:47.000 --> 00:13:51.000
Các mặt lưới có thể được phân loại là nhiều loại vật thể khác nhau.

00:13:51.000 --> 00:13:58.000
Nếu chúng tôi không thể xác định một đối tượng cụ thể, phân loại được cung cấp sẽ không có.

00:13:58.000 --> 00:14:02.000
Cuối cùng, chúng ta hãy xem xét việc theo dõi hình ảnh.

00:14:02.000 --> 00:14:07.000
Theo dõi hình ảnh cho phép bạn phát hiện hình ảnh 2D trong thế giới thực.

00:14:07.000 --> 00:14:13.000
Loại DataProvider mà theo dõi hình ảnh sử dụng được gọi là ImageTrackingProvider.

00:14:13.000 --> 00:14:18.000
Bạn định cấu hình ImageTrackingProvider với một bộ ReferenceImages mà bạn muốn phát hiện.

00:14:18.000 --> 00:14:22.000
Những hình ảnh tham khảo này có thể được tạo ra theo một vài cách khác nhau.

00:14:22.000 --> 00:14:28.000
Một lựa chọn là tải chúng từ nhóm tài nguyên AR trong danh mục tài sản dự án của bạn.

00:14:28.000 --> 00:14:36.000
Ngoài ra, bạn cũng có thể tự khởi tạo ReferenceImage bằng cách cung cấp CVPixelBuffer hoặc CGImage.

00:14:36.000 --> 00:14:41.000
Khi một hình ảnh được phát hiện, ARKit cung cấp cho bạn một ImageAnchor.

00:14:41.000 --> 00:14:46.000
ImageAnchors có thể được sử dụng để đặt nội dung vào các hình ảnh đã biết, được đặt tĩnh.

00:14:46.000 --> 00:14:52.000
Ví dụ, bạn có thể hiển thị một số thông tin về một bộ phim bên cạnh áp phích phim.

00:14:52.000 --> 00:15:05.000
ImageAnchors là TrackableAnchors bao gồm hệ số tỷ lệ ước tính, cho biết kích thước của hình ảnh được phát hiện so với kích thước vật lý mà bạn đã chỉ định và ReferenceImage mà neo tương ứng như thế nào.

00:15:05.000 --> 00:15:12.000
Bây giờ, để cho bạn biết về tính năng mới của chúng tôi, theo dõi tay và sau đó hướng dẫn bạn qua ví dụ, đây là Conner.

00:15:12.000 --> 00:15:16.000
Conner: Xin chào. Chúng ta hãy xem xét tính năng theo dõi bằng tay, một bổ sung hoàn toàn mới cho ARKit.

00:15:16.000 --> 00:15:21.000
Theo dõi bàn tay cung cấp cho bạn các neo chứa dữ liệu xương cho mỗi bàn tay của bạn.

00:15:21.000 --> 00:15:26.000
Loại DataProvider mà theo dõi tay sử dụng được gọi là HandTrackingProvider.

00:15:26.000 --> 00:15:30.000
Khi bàn tay của bạn được phát hiện, chúng sẽ được cung cấp cho bạn dưới dạng HandAnchors.

00:15:30.000 --> 00:15:33.000
HandAnchor là TrackableAnchor.

00:15:33.000 --> 00:15:37.000
HandAnchors bao gồm một bộ xương và một chirality.

00:15:37.000 --> 00:15:41.000
Chirality cho chúng ta biết đây là tay trái hay tay phải.

00:15:41.000 --> 00:15:47.000
Biến đổi của HandAnchor là biến đổi của cổ tay liên quan đến nguồn gốc của ứng dụng.

00:15:47.000 --> 00:15:51.000
Bộ xương bao gồm các khớp, có thể được truy vấn theo tên.

00:15:51.000 --> 00:16:07.000
Một khớp chứa khớp mẹ của nó; tên của nó; một localTransform, có liên quan đến khớp mẹ của nó; một rootTransform, có liên quan đến khớp gốc; và cuối cùng, mỗi khớp chứa một bool, cho biết khớp này có được theo dõi hay không.

00:16:07.000 --> 00:16:11.000
Ở đây chúng tôi liệt kê tất cả các khớp có sẵn trong bộ xương tay.

00:16:11.000 --> 00:16:14.000
Hãy xem qua một tập hợp con của hệ thống phân cấp của khớp.

00:16:14.000 --> 00:16:17.000
Cổ tay là khớp gốc của bàn tay.

00:16:17.000 --> 00:16:25.000
Đối với mỗi ngón tay, khớp đầu tiên được đặt vào cổ tay; ví dụ, 1 được đặt ở 0.

00:16:25.000 --> 00:16:33.000
Các khớp ngón tay tiếp theo được đặt ở khớp trước đó; ví dụ, 2 khớp được đặt ở 1, v.v.

00:16:33.000 --> 00:16:38.000
HandAnchors có thể được sử dụng để đặt nội dung liên quan đến bàn tay của bạn hoặc phát hiện các cử chỉ tùy chỉnh.

00:16:38.000 --> 00:16:46.000
Có hai tùy chọn để nhận HandAnchors - bạn có thể thăm dò ý kiến để cập nhật hoặc nhận neo không đồng bộ khi chúng có sẵn.

00:16:46.000 --> 00:16:54.000
Chúng ta sẽ xem xét các bản cập nhật không đồng bộ trong ví dụ Swift của chúng ta sau này, vì vậy hãy thêm bỏ phiếu neo tay vào trình kết xuất của chúng ta từ trước đó.

00:16:54.000 --> 00:16:56.000
Đây là định nghĩa cấu trúc được cập nhật của chúng tôi.

00:16:56.000 --> 00:17:01.000
Chúng tôi đã thêm một nhà cung cấp dịch vụ theo dõi tay, cùng với một neo tay trái và phải.

00:17:01.000 --> 00:17:12.000
Trong chức năng init được cập nhật của chúng tôi, chúng tôi tạo nhà cung cấp theo dõi tay mới của mình và thêm nó vào danh sách các nhà cung cấp mà chúng tôi chạy; sau đó chúng tôi tạo các neo tay trái và phải mà chúng tôi sẽ cần khi thăm dò ý kiến.

00:17:12.000 --> 00:17:17.000
Lưu ý, chúng tôi tạo những thứ này trước thời hạn để tránh phân bổ trong vòng lặp kết xuất.

00:17:17.000 --> 00:17:23.000
Với cấu trúc của chúng tôi được cập nhật và khởi tạo, chúng tôi có thể gọi get_latest_anchors trong hàm kết xuất của mình.

00:17:23.000 --> 00:17:27.000
Chúng tôi vượt qua nhà cung cấp và các neo tay được phân bổ trước của chúng tôi.

00:17:27.000 --> 00:17:32.000
Các neo của chúng tôi sẽ được điền với dữ liệu có sẵn mới nhất.

00:17:32.000 --> 00:17:36.000
Với các neo mới nhất của chúng tôi được điền, giờ đây chúng tôi có thể sử dụng dữ liệu của họ trong trải nghiệm của mình.

00:17:36.000 --> 00:17:38.000
Rất tuyệt.

00:17:38.000 --> 00:17:41.000
Bây giờ là lúc để xem lại ví dụ mà chúng tôi đã chỉ cho bạn trước đó.

00:17:41.000 --> 00:17:45.000
Chúng tôi đã sử dụng kết hợp các tính năng ARKit và RealityKit để xây dựng trải nghiệm này.

00:17:45.000 --> 00:17:52.000
Hình học cảnh được sử dụng làm máy va chạm cho vật lý và cử chỉ, trong khi theo dõi tay được sử dụng để tương tác trực tiếp với các thực thể khối lập phương.

00:17:52.000 --> 00:17:55.000
Hãy cùng xem cách chúng tôi xây dựng ví dụ này.

00:17:55.000 --> 00:17:59.000
Đầu tiên, chúng ta sẽ kiểm tra cấu trúc ứng dụng và xem mô hình.

00:17:59.000 --> 00:18:02.000
Tiếp theo, chúng ta sẽ khởi tạo phiên ARKit.

00:18:02.000 --> 00:18:07.000
Sau đó, chúng tôi sẽ thêm máy va chạm cho đầu ngón tay và máy va chạm từ việc tái tạo cảnh.

00:18:07.000 --> 00:18:10.000
Cuối cùng, chúng ta sẽ xem xét cách thêm các hình khối bằng cử chỉ.

00:18:10.000 --> 00:18:13.000
Hãy nhảy ngay vào nó.

00:18:13.000 --> 00:18:17.000
Đây là ứng dụng của chúng tôi, TimeForCube.

00:18:17.000 --> 00:18:21.000
Chúng tôi có một ứng dụng SwiftUI tương đối chuẩn và thiết lập cảnh.

00:18:21.000 --> 00:18:24.000
Trong bối cảnh của chúng tôi, chúng tôi tuyên bố một ImmersiveSpace.

00:18:24.000 --> 00:18:29.000
IimmersiveSpace là bắt buộc vì chúng ta sẽ cần chuyển sang Full Space để có quyền truy cập vào dữ liệu ARKit.

00:18:29.000 --> 00:18:35.000
Trong ImmersiveSpace, chúng tôi xác định một RealityView sẽ trình bày nội dung từ mô hình xem của chúng tôi.

00:18:35.000 --> 00:18:38.000
Mô hình chế độ xem là nơi mà hầu hết logic của ứng dụng của chúng tôi sẽ tồn tại.

00:18:38.000 --> 00:18:41.000
Hãy xem nhanh.

00:18:41.000 --> 00:18:55.000
Mô hình xem giữ phiên ARKit; các nhà cung cấp dữ liệu chúng tôi sẽ sử dụng; thực thể nội dung của chúng tôi, sẽ chứa tất cả các thực thể khác mà chúng tôi tạo; và cả bản đồ cảnh và máy va chạm tay của chúng tôi.

00:18:55.000 --> 00:18:59.000
Mô hình xem của chúng tôi cũng cung cấp nhiều chức năng khác nhau mà chúng tôi sẽ gọi từ ứng dụng.

00:18:59.000 --> 00:19:02.000
Chúng ta sẽ xem qua từng điều này trong ngữ cảnh từ ứng dụng.

00:19:02.000 --> 00:19:09.000
Chức năng đầu tiên chúng tôi sẽ gọi nằm trong đóng cửa thực tế của RealityView để thiết lập contentEntity.

00:19:09.000 --> 00:19:17.000
Chúng tôi sẽ thêm thực thể này vào nội dung của Chế độ xem thực tế của chúng tôi, để mô hình chế độ xem có thể thêm các thực thể vào nội dung của chế độ xem.

00:19:17.000 --> 00:19:24.000
setupContentEntity chỉ cần thêm tất cả các thực thể ngón tay trong bản đồ của chúng tôi dưới dạng con của contentEntity và sau đó trả về nó.

00:19:24.000 --> 00:19:25.000
Tuyệt vời!

00:19:25.000 --> 00:19:28.000
Hãy chuyển sang khởi tạo phiên.

00:19:28.000 --> 00:19:31.000
Khởi tạo phiên của chúng tôi chạy theo một trong ba nhiệm vụ.

00:19:31.000 --> 00:19:34.000
Nhiệm vụ đầu tiên của chúng tôi gọi hàm runSession.

00:19:34.000 --> 00:19:39.000
Chức năng này chỉ đơn giản là chạy phiên với hai nhà cung cấp của chúng tôi.

00:19:39.000 --> 00:19:42.000
Với phiên đang chạy, chúng ta có thể bắt đầu nhận các bản cập nhật neo.

00:19:42.000 --> 00:19:47.000
Hãy tạo và cập nhật các máy va chạm đầu ngón tay mà chúng ta sẽ sử dụng để tương tác với các hình khối.

00:19:47.000 --> 00:19:51.000
Đây là nhiệm vụ của chúng tôi để xử lý các bản cập nhật bằng tay.

00:19:51.000 --> 00:19:56.000
Chức năng của nó lặp lại qua chuỗi cập nhật neo không đồng bộ trên nhà cung cấp.

00:19:56.000 --> 00:20:06.000
Chúng tôi đảm bảo rằng neo tay được theo dõi, lấy khớp ngón trỏ và kiểm tra xem bản thân khớp có được theo dõi hay không.

00:20:06.000 --> 00:20:12.000
Sau đó chúng tôi tính toán sự biến đổi của đầu ngón trỏ so với nguồn gốc ứng dụng.

00:20:12.000 --> 00:20:19.000
Cuối cùng, chúng tôi tra cứu thực thể ngón tay nào chúng tôi nên cập nhật và thiết lập biến đổi của nó.

00:20:19.000 --> 00:20:21.000
Hãy xem lại bản đồ thực thể ngón tay của chúng ta.

00:20:21.000 --> 00:20:31.000
Chúng tôi tạo ra một thực thể trên mỗi tay thông qua một phần mở rộng cho ModelEntity, Phần mở rộng này tạo ra một hình cầu 5mm với hình dạng va chạm.

00:20:31.000 --> 00:20:37.000
Chúng tôi thêm một thành phần cơ thể vật lý động học và ẩn thực thể này bằng cách thêm một thành phần độ mờ.

00:20:37.000 --> 00:20:43.000
Mặc dù chúng tôi sẽ ẩn những thứ này cho trường hợp sử dụng của mình, nhưng thật tuyệt khi hình dung các thực thể đầu ngón tay của chúng tôi để xác minh rằng mọi thứ đang hoạt động như mong đợi.

00:20:43.000 --> 00:20:48.000
Hãy tạm thời đặt độ mờ của chúng ta thành một và đảm bảo rằng các thực thể của chúng ta ở đúng nơi.

00:20:48.000 --> 00:20:49.000
Tuyệt vời!

00:20:49.000 --> 00:20:51.000
Chúng ta có thể nhìn thấy những quả cầu ngay trong tầm tay của chúng ta!

00:20:51.000 --> 00:20:54.000
Lưu ý, bàn tay của chúng ta đang che đi một phần các quả cầu.

00:20:54.000 --> 00:21:01.000
Đây được gọi là tắc tay, một tính năng hệ thống cho phép một người nhìn thấy bàn tay của họ trên nội dung ảo.

00:21:01.000 --> 00:21:11.000
Điều này được bật theo mặc định, nhưng nếu chúng ta muốn nhìn thấy quả cầu của mình rõ ràng hơn một chút, chúng ta có thể định cấu hình khả năng hiển thị tắc tay bằng cách sử dụng trình thiết lập UpperLimbVisibility trên cảnh của chúng ta.

00:21:11.000 --> 00:21:18.000
Nếu chúng ta đặt khả năng hiển thị chi thành ẩn, chúng ta sẽ thấy toàn bộ quả cầu bất kể bàn tay của chúng ta ở đâu.

00:21:18.000 --> 00:21:23.000
Đối với ví dụ của chúng tôi, chúng tôi sẽ để khả năng hiển thị chi trên làm giá trị mặc định và đặt độ mờ trở lại 0.

00:21:23.000 --> 00:21:29.000
Gọn gàng! Bây giờ hãy thêm máy va chạm cảnh - chúng ta sẽ sử dụng chúng cho vật lý và làm mục tiêu cử chỉ.

00:21:29.000 --> 00:21:32.000
Đây là nhiệm vụ gọi hàm trên mô hình của chúng tôi.

00:21:32.000 --> 00:21:44.000
Chúng tôi lặp lại chuỗi cập nhật neo không đồng bộ trên nhà cung cấp, cố gắng tạo ShapeResource từ MeshAnchor, sau đó bật sự kiện cập nhật neo.

00:21:44.000 --> 00:21:56.000
Nếu chúng ta đang thêm một neo, chúng ta tạo một thực thể mới, đặt biến đổi của nó, thêm một thành phần cơ thể vật lý và va chạm, sau đó thêm một thành phần mục tiêu đầu vào để máy va chạm này có thể là mục tiêu cho các cử chỉ.

00:21:56.000 --> 00:22:02.000
Cuối cùng, chúng tôi thêm một thực thể mới vào bản đồ của mình và là con của thực thể nội dung của chúng tôi.

00:22:02.000 --> 00:22:09.000
Để cập nhật một thực thể, chúng tôi lấy nó từ bản đồ, sau đó cập nhật hình dạng thành phần biến đổi và va chạm của nó.

00:22:09.000 --> 00:22:15.000
Để loại bỏ, chúng tôi xóa thực thể tương ứng khỏi cha mẹ của nó và bản đồ.

00:22:15.000 --> 00:22:19.000
Bây giờ chúng ta đã có máy va chạm tay và cảnh, chúng ta có thể sử dụng cử chỉ để thêm hình khối.

00:22:19.000 --> 00:22:27.000
Chúng tôi thêm SpatialTapGesture nhắm mục tiêu đến bất kỳ thực thể nào, điều này sẽ cho chúng tôi biết nếu ai đó đã khai thác bất kỳ thực thể nào trong nội dung RealityView của chúng tôi.

00:22:27.000 --> 00:22:33.000
Khi vòi đó kết thúc, chúng tôi nhận được một vị trí 3D mà chúng tôi chuyển đổi từ tọa độ toàn cầu sang tọa độ cảnh.

00:22:33.000 --> 00:22:35.000
Hãy hình dung vị trí này.

00:22:35.000 --> 00:22:40.000
Đây là những gì chúng ta sẽ thấy nếu chúng ta thêm một hình cầu vào vị trí của vòi.

00:22:40.000 --> 00:22:44.000
Bây giờ, chúng tôi yêu cầu mô hình chế độ xem của mình thêm một khối lập phương so với vị trí này.

00:22:44.000 --> 00:22:51.000
Để thêm một khối lập phương, trước tiên chúng tôi tính toán vị trí vị trí cao hơn 20 cm so với vị trí vòi.

00:22:51.000 --> 00:22:55.000
Sau đó chúng tôi tạo khối lập phương và đặt vị trí của nó thành vị trí được tính toán của chúng tôi.

00:22:55.000 --> 00:23:01.000
Chúng tôi thêm một InputTargetComponent, cho phép chúng tôi đặt loại cử chỉ mà thực thể của chúng tôi sẽ phản hồi.

00:23:01.000 --> 00:23:09.000
Đối với trường hợp sử dụng của chúng tôi, chúng tôi sẽ chỉ cho phép các loại đầu vào gián tiếp cho các hình khối này, vì các máy va chạm đầu ngón tay của chúng tôi sẽ cung cấp tương tác trực tiếp.

00:23:09.000 --> 00:23:14.000
Chúng tôi thêm một PhysicsBodyComponent với các tham số tùy chỉnh để làm cho các tương tác vật lý đẹp hơn một chút.

00:23:14.000 --> 00:23:20.000
Cuối cùng, chúng tôi thêm khối lập phương của mình vào thực thể nội dung, có nghĩa là cuối cùng đã đến lúc cho khối lập phương.

00:23:20.000 --> 00:23:24.000
Hãy xem xét lần cuối ví dụ của chúng ta, từ đầu đến cuối.

00:23:24.000 --> 00:23:29.000
Mỗi khi chúng tôi chạm vào các máy va chạm cảnh hoặc một khối lập phương, một khối lập phương mới sẽ được thêm vào phía trên vị trí chạm.

00:23:29.000 --> 00:23:36.000
Hệ thống vật lý làm cho khối lập phương rơi xuống các máy va chạm hiện trường và máy va chạm tay của chúng ta cho phép chúng ta tương tác với các khối lập phương.

00:23:36.000 --> 00:23:42.000
Để biết thêm thông tin về RealityKit, hãy xem phiên giới thiệu về cách sử dụng RealityKit cho điện toán không gian.

00:23:42.000 --> 00:23:51.000
Và, nếu bạn đã có trải nghiệm ARKit hiện có trên iOS mà bạn muốn đưa lên nền tảng này, hãy nhớ xem phiên chuyên dụng về chủ đề này để được hướng dẫn thêm.

00:23:51.000 --> 00:23:56.000
Toàn bộ nhóm của chúng tôi vô cùng vui mừng khi bạn có được phiên bản ARKit mới.

00:23:56.000 --> 00:24:01.000
Chúng tôi nóng lòng muốn xem tất cả các ứng dụng đột phá mà bạn sẽ tạo cho nền tảng mới thú vị này.

00:24:01.000 --> 00:24:03.000
Ryan: Cảm ơn vì đã xem!

00:24:03.000 --> 23:59:59.000
♪

