WEBVTT

00:00:00.000 --> 00:00:03.000
♪ Hip-hop nhạc cụ êm dịu ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:12.000
Xin chào, tôi là Chris.

00:00:12.000 --> 00:00:16.000
Tôi là một kỹ sư trong nhóm AVFoundation, và tôi muốn chào đón bạn đến với phiên họp của chúng tôi.

00:00:16.000 --> 00:00:23.000
Trong buổi nói chuyện này, chúng ta sẽ xem xét cách chuẩn bị và phân phối nội dung phát trực tuyến cho trải nghiệm không gian.

00:00:23.000 --> 00:00:30.000
Chúng ta sẽ bắt đầu với một đánh giá ngắn gọn về các bước hiện tại trong việc sản xuất, chuẩn bị và phân phối phương tiện 2D bằng cách sử dụng HTTP Live Streaming.

00:00:30.000 --> 00:00:32.000
Còn được gọi là HLS.

00:00:32.000 --> 00:00:41.000
Với việc chuẩn bị và phân phối nội dung 2D được bảo hiểm, chúng tôi sẽ chuyển sang nội dung video 3D - những gì được hỗ trợ và cập nhật các bước vừa được mô tả.

00:00:41.000 --> 00:00:46.000
Xem xét quy trình nội dung, chúng ta sẽ bắt đầu với mã hóa phương tiện của video, âm thanh và chú thích.

00:00:46.000 --> 00:00:51.000
Sau đó, những tài nguyên truyền thông đó cần được đóng gói, sẵn sàng để giao HLS.

00:00:51.000 --> 00:00:54.000
Đây là cách nội dung 2D được phân phối ngày hôm nay.

00:00:54.000 --> 00:00:58.000
Mục tiêu của việc cung cấp nội dung 3D là xây dựng dựa trên các quy trình 2D hiện tại.

00:00:58.000 --> 00:01:05.000
HLS bổ sung hỗ trợ mới cho siêu dữ liệu hẹn giờ MP4 bị phân mảnh cho phép thích ứng quan trọng.

00:01:05.000 --> 00:01:14.000
Vui lòng lưu ý trang Phát trực tiếp HTTP trên trang web Nhà phát triển Apple, cung cấp các liên kết đến tài liệu, công cụ, luồng ví dụ, diễn đàn nhà phát triển và các tài nguyên khác.

00:01:14.000 --> 00:01:19.000
Đây là nơi mà các chi tiết được đề cập trong bài nói chuyện này sẽ được cung cấp theo thời gian.

00:01:19.000 --> 00:01:25.000
Mục tiêu của chúng tôi là cung cấp nội dung nghe nhìn 2D cho nền tảng này phải giống như tất cả các nền tảng khác của chúng tôi.

00:01:25.000 --> 00:01:39.000
Điều này đạt được bằng cách xây dựng dựa trên công nghệ Apple Media như HTTP Live Streaming, AVFoundation, Core Media và các định dạng dựa trên tiêu chuẩn như định dạng tệp phương tiện dựa trên ISO, thường được coi là MPEG-4.

00:01:39.000 --> 00:01:43.000
Điều này được thực hiện tất cả trong khi hỗ trợ một mô hình trải nghiệm không gian mới.

00:01:43.000 --> 00:01:53.000
Để tìm hiểu sâu hơn về cách hỗ trợ phát lại phương tiện nghe nhìn tốt nhất, hãy xem phiên "Tạo trải nghiệm không gian tuyệt vời để phát lại video".

00:01:53.000 --> 00:01:55.000
Đối với video, hãy mã hóa video nguồn.

00:01:55.000 --> 00:02:00.000
Chỉnh sửa nó theo độ dài phù hợp và chỉnh màu sắc cho các tầng tốc độ bit quan trọng với bạn.

00:02:00.000 --> 00:02:07.000
Tại đây bạn sẽ đưa ra lựa chọn về cách bạn định cấu hình và sử dụng các bộ mã hóa video như HEVC, viết tắt của Mã hóa video hiệu quả cao.

00:02:07.000 --> 00:02:15.000
Mặc dù hỗ trợ cho phương tiện nghe nhìn 2D hiện có mà bạn cung cấp cho các nền tảng khác của Apple được hỗ trợ đầy đủ, hãy lưu ý các khả năng phát lại này.

00:02:15.000 --> 00:02:21.000
Nền tảng này hỗ trợ phát lại độ phân giải lên đến 4K, cho phép trải nghiệm video chất lượng cao nhất của bạn.

00:02:21.000 --> 00:02:29.000
Tốc độ làm mới của màn hình là 90 Hertz và đối với video 24 khung hình mỗi giây, chế độ 96 hertz đặc biệt có thể được sử dụng tự động.

00:02:29.000 --> 00:02:33.000
Có hỗ trợ cho dải động tiêu chuẩn và cao.

00:02:33.000 --> 00:02:39.000
Đối với âm thanh tương ứng của video của bạn, hãy xác định và tạo ra số lượng luồng âm thanh nguồn bạn cần.

00:02:39.000 --> 00:02:45.000
Con số phụ thuộc vào tập hợp các ngôn ngữ nói mà bạn đang nhắm mục tiêu và vai trò của âm thanh đó.

00:02:45.000 --> 00:02:49.000
Một vai trò có thể là đối thoại chính, một vai trò khác, mô tả âm thanh.

00:02:49.000 --> 00:02:53.000
Mã hóa các nguồn này để phân phối với HLS trong tâm trí.

00:02:53.000 --> 00:02:58.000
Bạn có thể muốn cung cấp Âm thanh Không gian, cùng với một đoạn âm thanh nổi dự phòng.

00:02:58.000 --> 00:03:04.000
Điều này đảm bảo trải nghiệm tuyệt vời cho những thiết bị hỗ trợ Âm thanh Không gian và phát lại đáng tin cậy ở mọi nơi.

00:03:04.000 --> 00:03:08.000
Trang Nhà phát triển HLS có các liên kết đến tài liệu về việc chuẩn bị âm thanh.

00:03:08.000 --> 00:03:10.000
Và sau đó là chú thích.

00:03:10.000 --> 00:03:16.000
Ở đây, phụ đề bao gồm cả phụ đề và phụ đề chi tiết để bao gồm các ngôn ngữ và vai trò khác nhau.

00:03:16.000 --> 00:03:27.000
Thuật ngữ "phụ đề" được sử dụng để phiên âm văn bản nói cung cấp bản dịch bằng các ngôn ngữ khác nhau cho người xem có thể không nói ngôn ngữ hoặc để thiết lập thời gian và địa điểm cài đặt.

00:03:27.000 --> 00:03:32.000
Phụ đề chi tiết giống như phụ đề nhưng được dự định khi người xem không thể nghe thấy âm thanh.

00:03:32.000 --> 00:03:38.000
Chú thích chi tiết cung cấp phiên âm không chỉ đoạn hội thoại mà còn của các hiệu ứng âm thanh và các tín hiệu âm thanh có liên quan khác.

00:03:38.000 --> 00:03:44.000
Cũng có thể có phụ đề cho người khiếm thính và khiếm thính, SDH, phục vụ cùng một mục đích.

00:03:44.000 --> 00:03:52.000
Giống như mã hóa video và âm thanh, bạn nên tạo các tệp chú thích và định dạng được HLS hỗ trợ, phổ biến nhất là WebVTT.

00:03:52.000 --> 00:03:57.000
Với video nguồn, âm thanh và chú thích trong tay, tiếp theo là bao bì.

00:03:57.000 --> 00:04:04.000
Bao bì là một quá trình biến phương tiện nguồn thành nhiều loại phân đoạn khác nhau để giao hàng đáng tin cậy.

00:04:04.000 --> 00:04:09.000
Điều này có thể được thực hiện với các công cụ HLS của Apple có sẵn tại trang phát trực tuyến HLS trước đó.

00:04:09.000 --> 00:04:14.000
Một số nhà cung cấp nội dung có thể sử dụng các công cụ sản xuất, phần cứng hoặc quy trình làm việc của riêng họ.

00:04:14.000 --> 00:04:18.000
Những người khác có thể là nhà cung cấp cung cấp các dịch vụ và công cụ đó cho nhóm đầu tiên.

00:04:18.000 --> 00:04:27.000
Mục tiêu của việc đóng gói là tạo ra một tập hợp các phân đoạn phương tiện, danh sách phát phương tiện thúc đẩy việc sử dụng chúng và danh sách phát đa biến liên kết tất cả chúng lại với nhau.

00:04:27.000 --> 00:04:32.000
Hai loại phân đoạn phương tiện HLS được sử dụng phổ biến nhất hiện nay.

00:04:32.000 --> 00:04:39.000
Các phân đoạn phương tiện MP4 bị phân mảnh được tạo ra bằng cách bắt đầu với một tệp phim video hoặc âm thanh đã được mã hóa và tạo ra một số tài nguyên.

00:04:39.000 --> 00:04:42.000
Những tài nguyên này được gọi là phân đoạn truyền thông.

00:04:42.000 --> 00:04:47.000
Chính những phân đoạn này được các thiết bị khách hàng truy xuất trong quá trình phát lại.

00:04:47.000 --> 00:04:50.000
Các tệp phụ đề cũng yêu cầu phân đoạn.

00:04:50.000 --> 00:04:54.000
Điều này được thực hiện với một công cụ phân đoạn phụ đề để tạo các phân đoạn phương tiện.

00:04:54.000 --> 00:05:01.000
Tệp WebVTT nguồn có thể được chia thành bất kỳ số lượng tệp WebVTT nào trong khoảng thời gian phân đoạn mục tiêu.

00:05:01.000 --> 00:05:07.000
Cuối cùng, bộ sưu tập tài nguyên HLS được lưu trữ trên máy chủ web để phân phối HTTP.

00:05:07.000 --> 00:05:15.000
Điều này có thể là đến một máy chủ phục vụ khách hàng trực tiếp hoặc đến một máy chủ gốc được sử dụng với mạng phân phối nội dung hoặc CDN.

00:05:15.000 --> 00:05:20.000
Dù bằng cách nào, chính những tài nguyên này được gửi đến các thiết bị khách hàng để phát lại.

00:05:20.000 --> 00:05:29.000
Bây giờ chúng tôi đã xem xét quy trình sản xuất và phân phối 2D, hãy chuyển sang nội dung 3D và sự khác biệt tận dụng các khả năng đặc biệt mới.

00:05:29.000 --> 00:05:37.000
Chúng tôi sẽ xem xét lại mã hóa nguồn, đóng gói và phân phối, tập trung vào sự khác biệt giữa nội dung 2D và nội dung lập thể 3D.

00:05:37.000 --> 00:05:40.000
Vì vậy, chúng ta đang nói về video 3D.

00:05:40.000 --> 00:05:42.000
Hãy giải cấu trúc thuật ngữ này.

00:05:42.000 --> 00:05:48.000
Đầu tiên, đó là video, vì vậy một chuỗi các khung hình trong bản nhạc phim hoặc luồng mạng.

00:05:48.000 --> 00:06:01.000
"3D" trong "video 3D" được sử dụng thay thế cho nhau với lập thể, cung cấp hình ảnh cho mắt trái và một hình ảnh rất giống nhau từ một góc nhìn hơi khác cho mắt phải.

00:06:01.000 --> 00:06:09.000
Những khác biệt giữa hình ảnh trái và phải, được gọi là thị sai, khiến bạn cảm nhận được độ sâu ba chiều trong video khi được trình bày.

00:06:09.000 --> 00:06:14.000
Mặc dù có những lựa chọn về cách các khung hình video 3D có thể được thực hiện nhưng có một số nguyên tắc hướng dẫn có vẻ hữu ích.

00:06:14.000 --> 00:06:21.000
Bằng cách sử dụng một bản nhạc video duy nhất cho tất cả các khung hình âm thanh nổi, sản xuất truyền thống với các bản video 2D được bảo tồn.

00:06:21.000 --> 00:06:26.000
Cả hình ảnh hoặc chế độ xem bên trái và bên phải, cho bất kỳ thời gian hiển thị nào đều nằm trong một khung nén duy nhất.

00:06:26.000 --> 00:06:31.000
Nếu bạn có một khung trong tay, bạn có cả chế độ xem hoặc cặp âm thanh nổi.

00:06:31.000 --> 00:06:45.000
Nó phải hiệu quả, lý tưởng nhất, nó được hỗ trợ bởi silicon của Apple và ở mức độ lớn nhất có thể, nó nên được giải mã bằng cách phát lại không nhận biết 3D, cho phép video được thử giọng trong quy trình làm việc 2D.

00:06:45.000 --> 00:06:52.000
Để cung cấp khung âm thanh nổi, chúng tôi giới thiệu việc sử dụng MULTIview HEVC, còn được gọi là "MV-HEVC."

00:06:52.000 --> 00:06:54.000
Đó là một phần mở rộng của HEVC.

00:06:54.000 --> 00:06:56.000
"MV" là đa chế độ xem.

00:06:56.000 --> 00:07:03.000
Mang nhiều hơn một chế độ xem trong mỗi khung hình, mỗi khung hình có một cặp hình ảnh nén trái và phải.

00:07:03.000 --> 00:07:08.000
Bởi vì MV-HEVC là HEVC ở trung tâm của nó, Apple silicon hỗ trợ nó.

00:07:08.000 --> 00:07:14.000
Trong MV-HEVC lưu trữ chế độ xem HEVC 2D cơ bản trong mỗi khung nén.

00:07:14.000 --> 00:07:18.000
Mã hóa xác định sự khác biệt, hoặc delta, giữa hình ảnh trái và phải.

00:07:18.000 --> 00:07:26.000
Kỹ thuật này, được gọi là 2D Plus Delta, có nghĩa là bộ giải mã 2D có thể tìm và sử dụng chế độ xem 2D cơ bản, ví dụ như mắt trái.

00:07:26.000 --> 00:07:31.000
Nhưng bộ giải mã 3D có thể tính toán chế độ xem khác để trình bày cả hai chế độ xem cho mắt tương ứng.

00:07:31.000 --> 00:07:45.000
Hiệu quả đạt được vì sự khác biệt giữa hình ảnh 2D cơ bản sử dụng các kỹ thuật HEVC tiêu chuẩn và chỉ có sự khác biệt giữa chế độ xem mắt trái và mắt phải được mô tả trong khung âm thanh nổi.

00:07:45.000 --> 00:08:00.000
Mô tả định dạng video hoặc mục nhập mẫu trực quan ở định dạng MPEG-4, cho biết loại mã hóa, codec, kích thước của mỗi chế độ xem và các chi tiết khác cần thiết để giải mã các khung hình video.

00:08:00.000 --> 00:08:03.000
Một phần mở rộng mới cho mô tả định dạng video được giới thiệu.

00:08:03.000 --> 00:08:12.000
Được gọi là hộp Sử dụng Mở rộng Video, nó đóng vai trò như một tín hiệu nhẹ, dễ phát hiện rằng video là lập thể và có chế độ xem mắt âm thanh nổi nào.

00:08:12.000 --> 00:08:15.000
Đối với giao hàng HLS, điều này sẽ là cả trái và phải.

00:08:15.000 --> 00:08:21.000
Một đặc điểm kỹ thuật mô tả hộp VEXU mới này có sẵn với SDK.

00:08:21.000 --> 00:08:25.000
Cấu trúc của nó sẽ phát triển, và điều đó sẽ được mô tả trong thông số kỹ thuật.

00:08:25.000 --> 00:08:33.000
Giống như nội dung 2D, video 3D sử dụng HEVC, ngoại trừ lần này, biến thể được gọi là MV-HEVC.

00:08:33.000 --> 00:08:36.000
Điều này được yêu cầu để mang các chế độ xem lập thể.

00:08:36.000 --> 00:08:43.000
Giống như với sản xuất 2D, các bộ phim địa phương với MV-HEVC có thể được sử dụng và nên hoạt động giống như các video 2D khác.

00:08:43.000 --> 00:08:53.000
Có cả hình ảnh trái và phải được trình bày cho mắt tương ứng tạo ra nhận thức về độ sâu lập thể, cung cấp cảm giác về độ sâu tương đối.

00:08:53.000 --> 00:09:00.000
Một đối tượng trong cảnh video có thể được cảm nhận gần hơn hoặc xa hơn một đối tượng khác do số lượng thị sai khác nhau.

00:09:00.000 --> 00:09:03.000
Ba vùng chính của độ sâu lập thể có thể được xác định.

00:09:03.000 --> 00:09:17.000
Chúng là mặt phẳng màn hình không có tín hiệu thị sai; thị sai âm, sẽ khiến các vật thể được cảm nhận trước mặt phẳng màn hình; và thị sai dương, sẽ khiến các vật thể được cảm nhận phía sau mặt phẳng màn hình.

00:09:17.000 --> 00:09:27.000
Nếu một phần tử như chú thích được hiển thị không có thị sai trong cùng một khu vực của khung với các tín hiệu thị sai âm, thì xung đột chiều sâu sẽ được tạo ra và gây khó chịu khi xem.

00:09:27.000 --> 00:09:29.000
Câu hỏi.

00:09:29.000 --> 00:09:35.000
Với thị sai lập thể và khả năng xung đột chiều sâu, việc tạo chú thích cho video 3D có liên quan như thế nào?

00:09:35.000 --> 00:09:37.000
Chúng tôi có thể hỗ trợ những điều sau đây không?

00:09:37.000 --> 00:09:52.000
Phát lại hoạt động cho phụ đề theo chiều ngang, phát lại hoạt động trên các ngôn ngữ, bao gồm cả phụ đề dọc và phát lại hoạt động khi cài đặt trợ năng được sử dụng để điều chỉnh kích thước chú thích ưa thích của người dùng.

00:09:52.000 --> 00:09:54.000
Chà, câu trả lời là có.

00:09:54.000 --> 00:10:05.000
Với video lập thể sử dụng cách tiếp cận mà tôi sẽ mô tả tiếp theo, chú thích sẽ hoạt động như hiện tại, đồng thời cho phép chia sẻ cùng một nội dung chú thích 2D giữa trải nghiệm 2D và 3D.

00:10:05.000 --> 00:10:11.000
Điều này có thể thực hiện được bằng cách bao gồm siêu dữ liệu hẹn giờ mới mà tôi đã đề cập trước đó.

00:10:11.000 --> 00:10:17.000
Với video lập thể, việc tránh xung đột chiều sâu và các yếu tố hình ảnh phủ lên video là rất quan trọng.

00:10:17.000 --> 00:10:25.000
Thay vì yêu cầu các định dạng chú thích mới hoặc thay đổi các định dạng hiện có, chúng tôi cung cấp một cách để mô tả thị sai của mỗi khung hình video.

00:10:25.000 --> 00:10:30.000
Điều này có thể thay đổi trên khung hình với một số khu vực rõ ràng gần hơn và một số xa người xem hơn.

00:10:30.000 --> 00:10:38.000
Chúng tôi gọi đây là đường viền thị sai và nó được ghi lại dưới dạng siêu dữ liệu trong bản nhạc siêu dữ liệu được đồng bộ hóa với các khung hình của bản nhạc video.

00:10:38.000 --> 00:10:48.000
Nếu chúng ta gạch video 3D và chỉ thị sai độ sâu cho mỗi ô, chúng ta có thể sử dụng nó để đảm bảo rằng chú thích không bao giờ can thiệp vào các yếu tố trong video âm thanh nổi.

00:10:48.000 --> 00:10:55.000
Trong quá trình phát lại, thị sai của chú thích sẽ được tự động điều chỉnh để tránh xung đột độ sâu.

00:10:55.000 --> 00:11:04.000
Mỗi mục siêu dữ liệu có đường viền video thị sai như vậy mô tả ốp lát 2D của video được liên kết với giá trị thị sai tối thiểu được liên kết với mỗi ô.

00:11:04.000 --> 00:11:10.000
Bản trình bày của mỗi khung hình video nên được liên kết với một mục siêu dữ liệu mô tả đường viền của khung video.

00:11:10.000 --> 00:11:20.000
Chúng tôi đề xuất ốp lát 10 x 10 như một sự cân bằng tốt giữa lưu trữ và độ phân giải để mô tả các khu vực thị sai khác nhau trong video.

00:11:20.000 --> 00:11:25.000
Xem xét cách siêu dữ liệu thị sai này được tạo ra, hãy bắt đầu với chế độ xem trái và phải cho mỗi khung.

00:11:25.000 --> 00:11:30.000
Điều này có thể được thực hiện trong quá trình sản xuất với hai bản nhạc video được đồng bộ hóa và không yêu cầu MV-HEVC.

00:11:30.000 --> 00:11:37.000
Sau đó, thực hiện phân tích thị sai hoặc chênh lệch để tạo thông tin thị sai phù hợp để mô tả ốp lát.

00:11:37.000 --> 00:11:42.000
Đối với mỗi khung âm thanh nổi, điều này sau đó được đóng gói trong một tải trọng siêu dữ liệu cho bước tiếp theo.

00:11:42.000 --> 00:11:48.000
Một đặc điểm kỹ thuật mô tả định dạng của siêu dữ liệu này có sẵn với SDK.

00:11:48.000 --> 00:11:53.000
Thông tin thị sai này được đóng gói trong các mẫu siêu dữ liệu và được ghi vào một theo dõi siêu dữ liệu theo thời gian.

00:11:53.000 --> 00:12:00.000
Theo dõi siêu dữ liệu sẽ được liên kết với video tương ứng mà nó mô tả.

00:12:00.000 --> 00:12:10.000
Siêu dữ liệu và bản nhạc video nên được ghép kênh với video để bao bì HLS sẽ tạo ra các phân đoạn video với cả siêu dữ liệu video và thị sai.

00:12:10.000 --> 00:12:14.000
Chú thích bạn có thể đã sản xuất cho 2D có thể được sử dụng lại với 3D.

00:12:14.000 --> 00:12:21.000
Điều này có nghĩa là các quy trình được sử dụng ngày nay hoặc nhà cung cấp mà bạn có thể làm việc cùng có thể tiếp tục hoạt động trong 2D với sản xuất 3D của bạn.

00:12:21.000 --> 00:12:32.000
Ngoài ra, điều này có nghĩa là nội dung 3D của bạn bất khả tri đối với việc lựa chọn ngôn ngữ, bố cục ngang và dọc hoặc người dùng sử dụng tiềm năng các tùy chọn phụ đề về khả năng truy cập.

00:12:32.000 --> 00:12:40.000
Bằng cách thêm siêu dữ liệu thị sai được mô tả, nền tảng thích ứng linh hoạt với siêu dữ liệu thị sai mà bạn xây dựng.

00:12:40.000 --> 00:12:45.000
Đối với việc sử dụng âm thanh với video 3D, bạn có thể sử dụng cùng một cách sử dụng âm thanh để phân phối 2D.

00:12:45.000 --> 00:12:50.000
Vì nền tảng hỗ trợ theo dõi đầu, hãy cân nhắc sử dụng định dạng Âm thanh Không gian.

00:12:50.000 --> 00:12:57.000
Để chia sẻ cùng một âm thanh giữa trải nghiệm 2D và 3D, video phải khớp với thời gian, có cùng các chỉnh sửa.

00:12:57.000 --> 00:13:03.000
Nếu chúng khác nhau, bạn sẽ cần tách các bản âm thanh giữa nội dung 2D và 3D.

00:13:03.000 --> 00:13:12.000
Chuyển sang đóng gói 3D, các công cụ HLS cập nhật chăm sóc các chi tiết, với tài sản 3D làm cho quy trình gần giống với quy trình với 2D.

00:13:12.000 --> 00:13:21.000
Hầu hết các hệ thống sản xuất, không sử dụng các công cụ của Apple, sẽ có thể sử dụng các thông số kỹ thuật mới đang được phát hành để xây dựng chức năng tương đương.

00:13:21.000 --> 00:13:27.000
Nếu bạn đang xây dựng danh sách phát của riêng mình hoặc kiểm tra chúng, hãy lưu ý một vài thay đổi.

00:13:27.000 --> 00:13:33.000
REQ-VIDEO-LAYOUT là một thẻ mới cho các luồng video để chỉ ra video là lập thể.

00:13:33.000 --> 00:13:37.000
Giá trị thuộc tính cho biết video có âm thanh nổi hay không.

00:13:37.000 --> 00:13:42.000
Lưu ý rằng nếu tài sản của bạn được tải dưới dạng 3D, nó sẽ không chuyển sang 2D hoặc ngược lại.

00:13:42.000 --> 00:13:48.000
Video 2D không thay đổi và có thể được trộn lẫn với video 3D trong cùng một danh sách phát.

00:13:48.000 --> 00:13:53.000
REQ-VIDEO-LAYOUT yêu cầu phiên bản mới của thông số kỹ thuật HLS, vì vậy phiên bản được cập nhật lên 12.

00:13:53.000 --> 00:13:57.000
Điều này được ghi lại với SDK.

00:13:57.000 --> 00:14:06.000
Đây là một danh sách phát đa biến ví dụ với sự thay đổi số phiên bản thành 12 và sử dụng REQ-VIDEO-LAYOUT cho luồng video 3D.

00:14:06.000 --> 00:14:15.000
Để có trải nghiệm điều hướng tốt nhất, bạn nên bao gồm luồng iFrame 2D vào danh sách phát đa biến để hỗ trợ xóa hình thu nhỏ.

00:14:15.000 --> 00:14:21.000
Cuối cùng, phân phối HLS hoạt động tương tự với tài sản 3D.

00:14:21.000 --> 00:14:27.000
Cung cấp tài sản 3D phần lớn giống như cung cấp tài sản 2D, nhưng có một số điều bạn có thể làm để tối ưu hóa trải nghiệm.

00:14:27.000 --> 00:14:34.000
Chuẩn bị tài sản nguồn của bạn, lưu ý sử dụng MV-HEVC cho video 3D và bao gồm siêu dữ liệu đường viền thị sai mới.

00:14:34.000 --> 00:14:37.000
Sản xuất âm thanh và chú thích có thể giống nhau.

00:14:37.000 --> 00:14:41.000
Sử dụng bao bì cập nhật để tạo ra các phân đoạn và danh sách phát có liên quan.

00:14:41.000 --> 00:14:44.000
Lưu trữ vẫn giữ nguyên.

00:14:44.000 --> 00:14:50.000
Trước khi kết thúc, tôi muốn nhấn mạnh rằng sự thoải mái về hình ảnh là mục tiêu thiết kế nội dung chính cho trải nghiệm 3D.

00:14:50.000 --> 00:14:55.000
Nội dung 3D nên thoải mái để xem trong thời gian đủ dài.

00:14:55.000 --> 00:15:09.000
Một số đặc điểm nội dung 3D có khả năng gây ra các vấn đề về sự thoải mái bao gồm thị sai cực cao, cả tiêu cực và tích cực, chuyển động cao trong nội dung gây khó khăn trong việc tập trung; cũng như xung đột chiều sâu do một cái gì đó được gọi là "vi phạm cửa sổ".

00:15:09.000 --> 00:15:16.000
Kích thước màn hình có thể ảnh hưởng đến sự thoải mái khi xem, tùy thuộc vào mức độ hiển thị trong trường nhìn ngang của người xem.

00:15:16.000 --> 00:15:21.000
Lưu ý rằng người dùng có thể ảnh hưởng đến kích thước màn hình bằng cách định vị nó gần hơn hoặc xa hơn.

00:15:21.000 --> 00:15:27.000
Vì vậy, trong hành trình của mình, chúng tôi đã xem xét việc phân phối 2D và 3D với HTTP Live Streaming.

00:15:27.000 --> 00:15:30.000
Đối với video, tôi đã giới thiệu MV-HEVC.

00:15:30.000 --> 00:15:35.000
Đối với âm thanh, chúng tôi lưu ý rằng các luồng âm thanh giống nhau có thể được sử dụng trên 2D và 3D.

00:15:35.000 --> 00:15:40.000
Đối với phụ đề, các luồng giống nhau cũng có thể được sử dụng trên 2D và 3D.

00:15:40.000 --> 00:15:49.000
Cuối cùng, một định dạng siêu dữ liệu theo thời gian mới được giới thiệu để mô tả thị sai của video 3D, cho phép sử dụng cùng một chú thích.

00:15:49.000 --> 00:15:55.000
Để kết thúc, chúng tôi đã làm cho nó dễ dàng nhất có thể để đưa nội dung 2D hiện tại của bạn vào trải nghiệm không gian.

00:15:55.000 --> 00:16:02.000
Với một số sửa đổi nhỏ đối với đường ống 2D hiện tại của bạn, bạn có thể hỗ trợ nội dung 3D bằng MV-HEVC.

00:16:02.000 --> 00:16:06.000
Bạn thậm chí có thể tiếp tục sử dụng tất cả các chú thích hiện có của mình từ nội dung 2D.

00:16:06.000 --> 00:16:12.000
Nhưng nếu bạn cung cấp siêu dữ liệu theo thời gian, những chú thích đó có thể không bị che khuất và mang lại trải nghiệm xem thoải mái.

00:16:12.000 --> 00:16:18.000
Xem phiên đồng hành của chúng tôi để cân nhắc trong việc thực hiện phát lại video.

00:16:18.000 --> 00:16:21.000
Chúng tôi mong chờ nội dung mới tuyệt vời mà bạn sẽ cung cấp.

00:16:21.000 --> 00:16:23.000
Cảm ơn vì đã tham gia cùng chúng tôi hôm nay.

00:16:23.000 --> 23:59:59.000
♪

