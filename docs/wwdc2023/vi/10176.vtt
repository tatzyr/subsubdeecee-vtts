WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:15.000
Lizzy: Xin chào! Tôi là Lizzy, và tôi là một kỹ sư làm việc trên VisionKit tại Apple.

00:00:15.000 --> 00:00:20.000
Tôi rất vui được nói chuyện với bạn hôm nay về cách đưa việc nâng chủ đề vào ứng dụng của bạn.

00:00:20.000 --> 00:00:28.000
Nâng đối tượng được giới thiệu trong iOS 16, cho phép người dùng chọn, nâng và chia sẻ đối tượng hình ảnh.

00:00:28.000 --> 00:00:32.000
Đầu tiên, tôi sẽ xem xét những điều cơ bản về nâng đối tượng là gì.

00:00:32.000 --> 00:00:39.000
Sau đó, tôi sẽ hướng dẫn bạn cách thêm nâng chủ đề bằng VisionKit API mới.

00:00:39.000 --> 00:00:46.000
Cuối cùng, đồng nghiệp Saumitro của tôi sẽ đi sâu hơn và giới thiệu Vision API cơ bản mới.

00:00:46.000 --> 00:00:49.000
Vậy chính xác thì một chủ đề là gì?

00:00:49.000 --> 00:00:54.000
Một đối tượng là đối tượng tiền cảnh, hoặc các đối tượng, của một bức ảnh.

00:00:54.000 --> 00:00:57.000
Đây không phải lúc nào cũng là một người hay một con vật cưng.

00:00:57.000 --> 00:01:03.000
Nó có thể là bất cứ thứ gì từ một tòa nhà, một đĩa thức ăn hoặc một vài đôi giày.

00:01:03.000 --> 00:01:08.000
Hình ảnh có thể có nhiều chủ đề, như ba tách cà phê này ở đây.

00:01:08.000 --> 00:01:13.000
Điều quan trọng cần lưu ý là các đối tượng không phải lúc nào cũng là một đối tượng riêng lẻ.

00:01:13.000 --> 00:01:20.000
Trong ví dụ này, người đàn ông và con chó của anh ta cùng nhau là tâm điểm của hình ảnh, khiến chúng trở thành một chủ đề kết hợp.

00:01:20.000 --> 00:01:23.000
Vậy làm thế nào bạn có thể đưa cái này vào một ứng dụng?

00:01:23.000 --> 00:01:28.000
Có hai API riêng biệt có sẵn để giúp bạn thêm chủ đề nâng lên ứng dụng của mình.

00:01:28.000 --> 00:01:30.000
VisionKit.

00:01:30.000 --> 00:01:31.000
Và Tầm Nhìn.

00:01:31.000 --> 00:01:38.000
VisionKit cho phép bạn rất dễ dàng áp dụng hành vi nâng đối tượng giống như hệ thống, ngay lập tức.

00:01:38.000 --> 00:01:45.000
Bạn có thể dễ dàng tạo lại giao diện người dùng nâng chủ đề mà tất cả chúng ta đều biết và yêu thích, chỉ với một vài dòng mã.

00:01:45.000 --> 00:01:54.000
VisionKit cũng hiển thị một số thông tin cơ bản về các chủ đề này, vì vậy bạn có thể cung cấp cho mọi người những cách mới để tương tác với các đối tượng hình ảnh.

00:01:54.000 --> 00:02:00.000
Tất cả điều này xảy ra ngoài quy trình, có lợi ích về hiệu suất nhưng có nghĩa là kích thước hình ảnh bị giới hạn.

00:02:00.000 --> 00:02:05.000
Tầm nhìn là một khuôn khổ cấp thấp hơn và không có giao diện người dùng sẵn có.

00:02:05.000 --> 00:02:10.000
Điều này có nghĩa là nó không bị ràng buộc với một khung cảnh, giúp bạn linh hoạt hơn.

00:02:10.000 --> 00:02:17.000
Phân tích hình ảnh diễn ra trong quá trình và không bị giới hạn về độ phân giải hình ảnh như VisionKit.

00:02:17.000 --> 00:02:24.000
Cuối cùng, API này có thể là một phần của các đường ống chỉnh sửa hình ảnh nâng cao hơn, chẳng hạn như những đường ống sử dụng CoreImage.

00:02:24.000 --> 00:02:28.000
Đầu tiên, hãy đi sâu vào chủ đề nâng API trong VisionKit.

00:02:28.000 --> 00:02:36.000
Để thêm nâng đối tượng với VisionKit, chỉ cần khởi tạo ImageAnalysisInteraction và thêm nó vào chế độ xem chứa hình ảnh.

00:02:36.000 --> 00:02:40.000
Đây có thể là một UIImageView, nhưng không cần phải như vậy.

00:02:40.000 --> 00:02:41.000
Thật đơn giản.

00:02:41.000 --> 00:02:45.000
Bây giờ, hình ảnh của bạn sẽ có các tương tác nâng chủ đề hệ thống.

00:02:45.000 --> 00:02:52.000
Tương tự, trên macOS, tạo ImageAnalysisOverlayView và thêm nó làm chế độ xem phụ của NSView có chứa hình ảnh của bạn.

00:02:52.000 --> 00:03:03.000
Bạn có thể đặt các loại tương tác ưa thích của ImageAnalysisInteraction hoặc ImageAnalysisOverlayView để chọn loại tương tác VisionKit nào sẽ hỗ trợ.

00:03:03.000 --> 00:03:07.000
Loại tương tác mặc định là .automatic, phản ánh hành vi của hệ thống.

00:03:07.000 --> 00:03:12.000
Sử dụng loại này nếu bạn muốn nâng chủ đề, văn bản trực tiếp và máy dò dữ liệu.

00:03:12.000 --> 00:03:19.000
Loại imageSubject mới chỉ bao gồm nâng chủ đề, cho các trường hợp bạn không muốn văn bản tương tác.

00:03:19.000 --> 00:03:27.000
Ngoài các tương tác giao diện người dùng này, VisionKit cũng cho phép bạn truy cập theo chương trình các đối tượng của hình ảnh bằng cách sử dụng ImageAnalysis.

00:03:27.000 --> 00:03:34.000
Để tạo ra một phân tích hình ảnh, chỉ cần tạo một ImageAnalyzer, sau đó gọi hàm phân tích.

00:03:34.000 --> 00:03:39.000
Chuyển cấu hình hình ảnh và máy phân tích mong muốn.

00:03:39.000 --> 00:03:46.000
Bạn có thể truy cập không đồng bộ danh sách tất cả các đối tượng của hình ảnh bằng cách sử dụng thuộc tính đối tượng của ImageAnalysis.

00:03:46.000 --> 00:03:51.000
Điều này sử dụng cấu trúc Chủ đề mới, chứa một hình ảnh và giới hạn của nó.

00:03:51.000 --> 00:03:57.000
Thuộc tính chủ đề được đánh dấu trả về một tập hợp các chủ đề được đánh dấu.

00:03:57.000 --> 00:04:01.000
Trong ví dụ này, hai chủ đề dưới cùng đã được tô sáng.

00:04:01.000 --> 00:04:09.000
Người dùng có thể làm nổi bật một chủ đề bằng cách nhấn và giữ nó, nhưng bạn cũng có thể thay đổi trạng thái lựa chọn bằng cách cập nhật các Chủ đề được đánh dấu được đặt trong mã.

00:04:09.000 --> 00:04:14.000
Bạn có thể tra cứu một chủ đề theo điểm, sử dụng phương thức async subject(at:).

00:04:14.000 --> 00:04:19.000
Trong ví dụ này, nhấn vào đây sẽ trả về chủ đề ở giữa.

00:04:19.000 --> 00:04:23.000
Nếu không có chủ ngữ tại thời điểm đó, phương thức này sẽ trả về nil.

00:04:23.000 --> 00:04:27.000
Cuối cùng, bạn có thể tạo hình ảnh chủ đề theo hai cách.

00:04:27.000 --> 00:04:31.000
Đối với một chủ đề duy nhất, chỉ cần truy cập thuộc tính hình ảnh của đối tượng.

00:04:31.000 --> 00:04:40.000
Nếu bạn cần một hình ảnh bao gồm nhiều đối tượng, hãy sử dụng phương pháp async image(for:) và chuyển các đối tượng mà bạn muốn đưa vào.

00:04:40.000 --> 00:04:48.000
Trong ví dụ này, nếu tôi muốn một hình ảnh chỉ của hai đối tượng dưới cùng, tôi có thể sử dụng phương pháp này để tạo ra hình ảnh này.

00:04:48.000 --> 00:04:50.000
Hãy xem tất cả điều này kết hợp với nhau trong một bản demo.

00:04:50.000 --> 00:04:53.000
Tôi đang làm việc trên một ứng dụng giải đố.

00:04:53.000 --> 00:04:57.000
Tôi muốn kéo các mảnh ghép vào câu đố, nhưng tôi chưa thể nhấc bất kỳ mảnh nào trong số chúng lên.

00:04:57.000 --> 00:04:58.000
Hãy sửa nó đi.

00:04:58.000 --> 00:05:05.000
Đầu tiên, tôi sẽ cần bật các tương tác nâng đối tượng trong hình ảnh này, để các mảnh có thể được tương tác.

00:05:05.000 --> 00:05:10.000
Tôi có thể làm điều này bằng cách tạo một ImageAnalysisInteraction...

00:05:10.000 --> 00:05:14.000
...Và chỉ cần thêm nó vào chế độ xem của tôi.

00:05:14.000 --> 00:05:26.000
Tôi đã sử dụng loại tương tác imageSubject ở đây, vì tôi không cần bao gồm văn bản trực tiếp.

00:05:26.000 --> 00:05:27.000
Tuyệt vời!

00:05:27.000 --> 00:05:30.000
Bây giờ tôi có thể chọn các mảnh ghép và tương tác với chúng như thế này.

00:05:30.000 --> 00:05:33.000
Hình ảnh này không được xử lý trước theo bất kỳ cách nào.

00:05:33.000 --> 00:05:36.000
Điều này được thực hiện chỉ với việc nâng đối tượng.

00:05:36.000 --> 00:05:48.000
Tôi đã thêm một số mã để xử lý việc thả các mảnh ghép vào câu đố và thậm chí điều chỉnh chúng vào vị trí.

00:05:48.000 --> 00:05:52.000
Nó trông khá ngầu, nhưng tôi muốn làm cho ứng dụng của mình cảm thấy hấp dẫn hơn nữa.

00:05:52.000 --> 00:05:59.000
Tôi đang nghĩ đến việc thêm một bóng đổ bên dưới mỗi mảnh ghép khi tôi di chuột qua nó, để tạo hiệu ứng 3D nhẹ.

00:05:59.000 --> 00:06:05.000
Tôi đã có một trình xử lý cử chỉ di chuột ở đây, tôi chỉ cần thêm bóng.

00:06:05.000 --> 00:06:10.000
Tôi không thể dễ dàng chỉnh sửa hình ảnh, vì vậy thay vào đó, tôi sẽ làm điều đó với một thủ thuật xếp lớp hình ảnh.

00:06:10.000 --> 00:06:18.000
Đầu tiên, tôi kiểm tra xem tôi có đang di chuột qua một chủ đề hay không bằng cách gọi imageAnalysis.subject(tại điểm:).

00:06:18.000 --> 00:06:29.000
Tôi có một phương pháp addShadow (cho chủ đề:), chèn một bản sao của hình ảnh chủ thể, chuyển nó thành màu xám và bù đắp nó một chút so với vị trí chủ đề ban đầu.

00:06:29.000 --> 00:06:36.000
Sau đó, tôi thêm một bản sao của hình ảnh đối tượng lên trên bóng để nó trông ba chiều.

00:06:36.000 --> 00:06:44.000
Cuối cùng, nếu điểm di chuột không giao với một đối tượng, tôi sẽ xóa bóng.

00:06:44.000 --> 00:06:49.000
Hãy thử nó đi.

00:06:49.000 --> 00:07:00.000
Tuyệt vời. Các mảnh bây giờ có hiệu ứng bóng khi tôi di chuột qua chúng.

00:07:00.000 --> 00:07:10.000
Sử dụng VisionKit, tôi đã có thể thiết lập nâng chủ đề trong ứng dụng của mình và thậm chí thêm hiệu ứng chủ đề thú vị chỉ với một vài dòng mã.

00:07:10.000 --> 00:07:17.000
Tiếp theo, tôi sẽ chuyển mọi thứ cho đồng nghiệp Saumitro của tôi, người sẽ nói về một số Vision API mới và cách tích hợp nó vào ứng dụng của bạn.

00:07:17.000 --> 00:07:19.000
Saumitro: Cảm ơn, Lizzy!

00:07:19.000 --> 00:07:23.000
Xin chào, tôi là Saumitro, và tôi là một kỹ sư trong Nhóm Tầm nhìn.

00:07:23.000 --> 00:07:28.000
API của VisionKit là cách dễ nhất để bắt đầu nâng chủ đề.

00:07:28.000 --> 00:07:32.000
Đối với các ứng dụng cần các tính năng nâng cao hơn, Vision sẽ giúp bạn.

00:07:32.000 --> 00:07:40.000
Nâng chủ đề tham gia vào bộ sưu tập API phân đoạn hiện có của Vision như sự nổi sáng và phân đoạn người.

00:07:40.000 --> 00:07:45.000
Hãy nhanh chóng xem lại từng điểm mạnh của họ và xem việc nâng đối tượng phù hợp như thế nào.

00:07:45.000 --> 00:07:52.000
Các yêu cầu về độ nổi bật, giống như các yêu cầu về sự chú ý và tính đối tượng, được sử dụng tốt nhất để phân tích thô, dựa trên khu vực.

00:07:52.000 --> 00:07:59.000
Lưu ý rằng các bản đồ nổi bật được tạo ra ở độ phân giải khá thấp và do đó, không phù hợp để phân đoạn.

00:07:59.000 --> 00:08:04.000
Thay vào đó, bạn có thể sử dụng các vùng nổi bật cho các tác vụ như tự động cắt ảnh.

00:08:04.000 --> 00:08:11.000
API phân đoạn người tỏa sáng trong việc sản xuất mặt nạ phân đoạn chi tiết cho những người trong cảnh.

00:08:11.000 --> 00:08:16.000
Sử dụng cái này nếu bạn đặc biệt muốn tập trung vào việc phân khúc mọi người.

00:08:16.000 --> 00:08:24.000
API phân đoạn phiên bản người mới đưa mọi thứ đi xa hơn bằng cách cung cấp một mặt nạ riêng cho mỗi người trong cảnh.

00:08:24.000 --> 00:08:28.000
Để tìm hiểu thêm, hãy xem phiên này về phân đoạn người.

00:08:28.000 --> 00:08:35.000
Trái ngược với phân đoạn người, API nâng chủ đề mới được giới thiệu là "lớp bất khả tri".

00:08:35.000 --> 00:08:40.000
Bất kỳ đối tượng tiền cảnh nào, bất kể lớp ngữ nghĩa của nó, đều có khả năng được phân đoạn.

00:08:40.000 --> 00:08:46.000
Ví dụ, hãy chú ý cách nó đón xe ngoài những người trong hình ảnh này.

00:08:46.000 --> 00:08:49.000
Bây giờ chúng ta hãy xem xét một số khái niệm chính liên quan.

00:08:49.000 --> 00:08:51.000
Bạn bắt đầu với một hình ảnh đầu vào.

00:08:51.000 --> 00:08:59.000
Yêu cầu nâng đối tượng xử lý hình ảnh này và tạo ra một mặt nạ phân đoạn mềm ở cùng độ phân giải.

00:08:59.000 --> 00:09:04.000
Lấy mặt nạ này và áp dụng nó vào hình ảnh nguồn dẫn đến hình ảnh được che giấu.

00:09:04.000 --> 00:09:09.000
Mỗi đối tượng được phân đoạn riêng biệt được gọi là một ví dụ.

00:09:09.000 --> 00:09:14.000
Vision cũng cung cấp cho bạn thông tin pixelwise về những trường hợp này.

00:09:14.000 --> 00:09:19.000
Mặt nạ phiên bản này ánh xạ các điểm ảnh trong hình ảnh nguồn đến chỉ mục phiên bản của chúng.

00:09:19.000 --> 00:09:27.000
Chỉ số 0 được dành riêng cho nền, và sau đó mỗi phiên bản tiền cảnh được gắn nhãn tuần tự, bắt đầu từ 1.

00:09:27.000 --> 00:09:33.000
Ngoài việc được dán nhãn liền kề, việc đặt hàng các ID này không được đảm bảo.

00:09:33.000 --> 00:09:39.000
Bạn có thể sử dụng các chỉ mục này để phân đoạn một tập hợp con của các đối tượng tiền cảnh trong hình ảnh nguồn.

00:09:39.000 --> 00:09:44.000
Nếu bạn đang thiết kế một ứng dụng tương tác, mặt nạ phiên bản này cũng hữu ích cho việc kiểm tra lượt truy cập.

00:09:44.000 --> 00:09:47.000
Tôi sẽ trình bày cách thực hiện cả hai nhiệm vụ này một chút.

00:09:47.000 --> 00:09:50.000
Hãy đi sâu vào API.

00:09:50.000 --> 00:09:54.000
Nâng đối tượng tuân theo mô hình quen thuộc của các yêu cầu dựa trên hình ảnh trong Tầm nhìn.

00:09:54.000 --> 00:10:03.000
Bạn bắt đầu bằng cách khởi tạo yêu cầu mặt nạ phiên bản tiền cảnh, tiếp theo là trình xử lý yêu cầu hình ảnh với hình ảnh đầu vào của bạn.

00:10:03.000 --> 00:10:05.000
Sau đó bạn thực hiện yêu cầu.

00:10:05.000 --> 00:10:11.000
Dưới mui xe, đây là khi Vision phân tích hình ảnh để tìm ra đối tượng.

00:10:11.000 --> 00:10:21.000
Mặc dù nó được tối ưu hóa để tận dụng phần cứng của Apple để đạt hiệu quả, nhưng nó vẫn là một nhiệm vụ tốn nhiều tài nguyên và tốt nhất nên chuyển sang luồng nền để không chặn giao diện người dùng.

00:10:21.000 --> 00:10:27.000
Một cách phổ biến để làm điều này là thực hiện bước này không đồng bộ trên một DispatchQueue riêng biệt.

00:10:27.000 --> 00:10:35.000
Nếu một hoặc nhiều đối tượng được phát hiện trong hình ảnh đầu vào, mảng kết quả sẽ được điền với một quan sát duy nhất.

00:10:35.000 --> 00:10:40.000
Từ đây trở đi, bạn có thể truy vấn quan sát về mặt nạ và hình ảnh được phân đoạn.

00:10:40.000 --> 00:10:47.000
Chúng ta hãy xem xét kỹ hơn hai trong số các tham số kiểm soát trường hợp nào được phân đoạn và cách cắt kết quả.

00:10:47.000 --> 00:10:55.000
Tham số trường hợp là một IndexSet kiểm soát đối tượng nào được trích xuất trong hình ảnh hoặc mặt nạ được phân đoạn cuối cùng.

00:10:55.000 --> 00:11:01.000
Ví dụ, hình ảnh này chứa hai trường hợp tiền cảnh, không bao gồm trường hợp nền.

00:11:01.000 --> 00:11:15.000
Vì phân đoạn tất cả các phiên bản tiền cảnh được phát hiện là một hoạt động rất phổ biến, Vision cung cấp thuộc tính allInstances tiện dụng trả về IndexSet chứa tất cả các chỉ mục phiên bản tiền cảnh.

00:11:15.000 --> 00:11:19.000
Đối với hình ảnh ở đây, điều này bao gồm các chỉ số 1 và 2.

00:11:19.000 --> 00:11:23.000
Lưu ý rằng phiên bản nền 0 không được bao gồm.

00:11:23.000 --> 00:11:26.000
Bạn cũng có thể chỉ cung cấp một tập hợp con của các chỉ số đó.

00:11:26.000 --> 00:11:29.000
Đây chỉ là ví dụ 1.

00:11:29.000 --> 00:11:31.000
Và chỉ là ví dụ 2.

00:11:31.000 --> 00:11:34.000
Bạn cũng có thể kiểm soát cách cắt hình ảnh được che cuối cùng.

00:11:34.000 --> 00:11:40.000
Nếu tham số này được đặt thành sai, độ phân giải hình ảnh đầu ra khớp với hình ảnh đầu vào.

00:11:40.000 --> 00:11:48.000
Điều này thật tuyệt khi bạn muốn duy trì vị trí tương đối của các đối tượng được phân đoạn, ví dụ, cho các hoạt động tổng hợp hạ lưu.

00:11:48.000 --> 00:11:53.000
Nếu bạn đặt nó thành true, bạn sẽ nhận được một vụ cắt chặt chẽ cho các trường hợp đã chọn.

00:11:53.000 --> 00:11:58.000
Trong các ví dụ cho đến nay, tôi đã làm việc với các đầu ra hình ảnh được che giấu hoàn toàn.

00:11:58.000 --> 00:12:07.000
Tuy nhiên, đối với một số thao tác, như áp dụng các hiệu ứng mặt nạ, thay vào đó có thể thuận tiện hơn khi làm việc chỉ với các mặt nạ phân đoạn.

00:12:07.000 --> 00:12:13.000
Bạn có thể tạo các mặt nạ này bằng cách gọi phương pháp createScaledMask trên quan sát.

00:12:13.000 --> 00:12:16.000
Các tham số hoạt động giống như trước đây.

00:12:16.000 --> 00:12:23.000
Đầu ra là một bộ đệm điểm ảnh dấu phẩy động một kênh chứa mặt nạ phân đoạn mềm.

00:12:23.000 --> 00:12:27.000
Mặt nạ tôi vừa tạo ra hoàn toàn phù hợp để sử dụng với CoreImage.

00:12:27.000 --> 00:12:32.000
Vision, giống như VisionKit, tạo ra đầu ra SDR.

00:12:32.000 --> 00:12:38.000
Tuy nhiên, việc thực hiện mặt nạ trong CoreImage vẫn duy trì dải động cao của đầu vào.

00:12:38.000 --> 00:12:43.000
Để tìm hiểu thêm về điều này, hãy cân nhắc kiểm tra phiên thêm HDR vào ứng dụng của bạn.

00:12:43.000 --> 00:12:47.000
Một cách để thực hiện mặt nạ này là sử dụng bộ lọc CIBlendWithMask.

00:12:47.000 --> 00:12:50.000
Tôi sẽ bắt đầu với hình ảnh nguồn cần được che giấu.

00:12:50.000 --> 00:12:54.000
Đây thường sẽ là cùng một hình ảnh mà bạn đã chuyển cho Vision.

00:12:54.000 --> 00:12:58.000
Mặt nạ thu được từ cuộc gọi createScaledMask của Vision.

00:12:58.000 --> 00:13:03.000
Và cuối cùng, hình nền mới mà đối tượng sẽ được tổng hợp lên trên.

00:13:03.000 --> 00:13:07.000
Sử dụng một hình ảnh trống cho việc này sẽ dẫn đến một nền trong suốt.

00:13:07.000 --> 00:13:14.000
Ngoài ra, nếu bạn dự định tổng hợp kết quả trên một nền mới, bạn có thể trực tiếp chuyển nó vào đây.

00:13:14.000 --> 00:13:15.000
Và đó là khá nhiều nó.

00:13:15.000 --> 00:13:21.000
Đầu ra sẽ là một hình ảnh được bảo quản HDR và tổng hợp.

00:13:21.000 --> 00:13:26.000
Bây giờ hãy kết hợp mọi thứ lại với nhau để xây dựng một ứng dụng hiệu ứng hình ảnh nâng cao chủ đề thú vị.

00:13:26.000 --> 00:13:32.000
Bạn có thể xóa nền và hiển thị các chế độ xem bên dưới nó, hoặc thay thế nó bằng một cái gì đó khác.

00:13:32.000 --> 00:13:36.000
Trên hết, bạn có thể áp dụng một trong những hiệu ứng đặt trước.

00:13:36.000 --> 00:13:40.000
Và các hiệu ứng sáng tác với nền đã chọn.

00:13:40.000 --> 00:13:45.000
Bạn thậm chí có thể nhấn vào một ví dụ tiền cảnh để nâng nó lên một cách có chọn lọc.

00:13:45.000 --> 00:13:48.000
Hãy xem một phác thảo về cách tôi sẽ tiếp cận việc tạo ra ứng dụng này.

00:13:48.000 --> 00:13:58.000
Cốt lõi của ứng dụng của chúng tôi dựa trên một đường ống hiệu ứng chấp nhận đầu vào từ giao diện người dùng và thực hiện tất cả các công việc cần thiết để tạo ra đầu ra cuối cùng.

00:13:58.000 --> 00:14:02.000
Tôi sẽ bắt đầu bằng cách thực hiện nâng đối tượng trên hình ảnh nguồn.

00:14:02.000 --> 00:14:06.000
Một cú chạm tùy chọn sẽ cho phép lựa chọn các phiên bản riêng lẻ.

00:14:06.000 --> 00:14:10.000
Mặt nạ kết quả sẽ được áp dụng cho hình ảnh nguồn.

00:14:10.000 --> 00:14:18.000
Và cuối cùng, nền và hiệu ứng hình ảnh đã chọn sẽ được áp dụng và tổng hợp để tạo ra hình ảnh đầu ra cuối cùng.

00:14:18.000 --> 00:14:21.000
Hai bước cuối cùng này sẽ được thực hiện bằng CoreImage.

00:14:21.000 --> 00:14:31.000
Chức năng cấp cao nhất của chúng tôi nhận hình ảnh đầu vào, hình ảnh và hiệu ứng nền đã chọn và có khả năng là vị trí nhấn từ người dùng để chọn một trong các trường hợp.

00:14:31.000 --> 00:14:35.000
Loại Hiệu ứng ở đây chỉ là một enum đơn giản cho các cài đặt trước của chúng tôi.

00:14:35.000 --> 00:14:39.000
Đầu ra của nó là hình ảnh tổng hợp cuối cùng, sẵn sàng để hiển thị trong giao diện người dùng.

00:14:39.000 --> 00:14:43.000
Nhiệm vụ này có thể được giải cấu trúc thành hai giai đoạn.

00:14:43.000 --> 00:14:48.000
Đầu tiên, tạo mặt nạ chủ đề cho các trường hợp đã chọn.

00:14:48.000 --> 00:14:52.000
Và thứ hai, sử dụng mặt nạ đó để áp dụng hiệu ứng đã chọn.

00:14:52.000 --> 00:14:54.000
Hãy bắt đầu với giai đoạn đầu tiên.

00:14:54.000 --> 00:14:59.000
Đầu vào cho giai đoạn này là hình ảnh nguồn và vị trí nhấn tùy chọn.

00:14:59.000 --> 00:15:06.000
Chúng tôi đã gặp hầu hết các mã ở đây, chỉ đơn giản là thực hiện yêu cầu Vision và trả lại mặt nạ.

00:15:06.000 --> 00:15:12.000
Điều thú vị là dòng này ánh xạ vị trí chạm đến một tập hợp các chỉ mục bằng cách sử dụng mặt nạ nhãn.

00:15:12.000 --> 00:15:15.000
Chúng ta hãy xem xét kỹ hơn.

00:15:15.000 --> 00:15:19.000
Nếu nhấn bị thiếu, tôi sẽ mặc định sử dụng tất cả các trường hợp.

00:15:19.000 --> 00:15:24.000
Tôi muốn ánh xạ vị trí chạm đến một điểm ảnh trong mặt nạ phiên bản.

00:15:24.000 --> 00:15:27.000
Có hai mẩu thông tin có liên quan ở đây.

00:15:27.000 --> 00:15:33.000
Đầu tiên, giao diện người dùng bình thường hóa vị trí nhấn ở 0, 1 trước khi chuyển nó vào.

00:15:33.000 --> 00:15:38.000
Điều này thật tuyệt vì tôi không phải lo lắng về các chi tiết như độ phân giải màn hình và các yếu tố chia tỷ lệ.

00:15:38.000 --> 00:15:44.000
Thứ hai, nó sử dụng hệ tọa độ UIKit mặc định có nguồn gốc ở trên cùng bên trái.

00:15:44.000 --> 00:15:48.000
Điều này được căn chỉnh với tọa độ không gian hình ảnh của chúng tôi về bộ đệm điểm ảnh.

00:15:48.000 --> 00:15:53.000
Vì vậy, tôi có thể thực hiện chuyển đổi này bằng cách sử dụng chức năng trợ giúp Tầm nhìn hiện có này.

00:15:53.000 --> 00:15:58.000
Bây giờ tôi có tất cả thông tin cần thiết để tra cứu nhãn phiên bản đã nhấn.

00:15:58.000 --> 00:16:04.000
Điều này liên quan đến việc truy cập trực tiếp dữ liệu của bộ đệm pixel và tôi sẽ chỉ cho bạn cách thực hiện điều đó tiếp theo.

00:16:04.000 --> 00:16:08.000
Khi tôi có nhãn, tôi kiểm tra xem nó có bằng không.

00:16:08.000 --> 00:16:12.000
Nhớ lại rằng nhãn 0 ngụ ý rằng người dùng đã chạm vào một điểm ảnh nền.

00:16:12.000 --> 00:16:15.000
Trong trường hợp này, tôi sẽ quay lại chọn tất cả các trường hợp.

00:16:15.000 --> 00:16:20.000
Nếu không, tôi sẽ trả lại một bộ singleton chỉ với nhãn đã chọn.

00:16:20.000 --> 00:16:24.000
Một chút mã này điền vào cách tra cứu nhãn phiên bản được thực hiện.

00:16:24.000 --> 00:16:29.000
Như với bất kỳ bộ đệm pixel nào, trước tiên tôi cần khóa nó trước khi truy cập dữ liệu của nó.

00:16:29.000 --> 00:16:33.000
Quyền truy cập chỉ đọc là đủ cho mục đích của chúng tôi.

00:16:33.000 --> 00:16:42.000
Các hàng của bộ đệm pixel có thể được đệm để căn chỉnh, vì vậy cách mạnh mẽ nhất để tính toán độ lệch byte cho pixel là sử dụng giá trị bytePerRow của nó.

00:16:42.000 --> 00:16:50.000
Vì instanceMask là một bộ đệm UInt8 một kênh, tôi không phải lo lắng về bất kỳ sự mở rộng nào nữa.

00:16:50.000 --> 00:16:53.000
Tôi đã đọc xong từ mặt nạ phiên bản, vì vậy tôi có thể mở khóa bộ đệm.

00:16:53.000 --> 00:16:58.000
Và với cái đó được gói lại, tôi có mặt nạ với ví dụ đã chọn được cách ly.

00:16:58.000 --> 00:17:01.000
Bây giờ tôi có thể chuyển sang áp dụng các hiệu ứng.

00:17:01.000 --> 00:17:04.000
Bước đầu tiên ở đây là áp dụng hiệu ứng đã chọn cho nền.

00:17:04.000 --> 00:17:11.000
Sau khi hoàn tất, tôi sẽ sử dụng CoreImage để tổng hợp đối tượng được che giấu trên nền đã biến đổi.

00:17:11.000 --> 00:17:17.000
Một vài hiệu ứng đầu tiên là các ứng dụng khá đơn giản và trực tiếp của các bộ lọc CoreImage hiện có.

00:17:17.000 --> 00:17:23.000
Ví dụ, để làm nổi bật đối tượng, tôi đã sử dụng bộ lọc điều chỉnh độ phơi sáng để làm mờ nền.

00:17:23.000 --> 00:17:26.000
Hiệu ứng bokeh có liên quan nhiều hơn một chút.

00:17:26.000 --> 00:17:31.000
Ngoài việc làm mờ hậu cảnh, tôi muốn một vầng hào quang làm nổi bật chủ đề đã chọn của chúng tôi.

00:17:31.000 --> 00:17:35.000
Một đường cắt màu trắng cho đối tượng trước khi làm mờ sẽ làm được điều đó.

00:17:35.000 --> 00:17:43.000
Một cách nhanh chóng để thực hiện điều này là sử dụng lại chức năng hiện tại của chúng tôi và chuyển một hình ảnh trắng đặc cho đối tượng.

00:17:43.000 --> 00:17:46.000
Và với điều đó, tôi có lớp cơ sở để tổng hợp.

00:17:46.000 --> 00:17:51.000
Cuối cùng, tôi sẽ thả vào đoạn mã pha trộn CoreImage từ trước đó.

00:17:51.000 --> 00:17:57.000
Điều này tổng hợp đối tượng được nâng lên trên nền mới được chuyển đổi.

00:17:57.000 --> 00:18:02.000
Và với phần cuối cùng của đường ống hiệu ứng tại chỗ, ứng dụng hiện đã hoàn thành.

00:18:02.000 --> 00:18:07.000
Tôi hy vọng nó đã cho bạn cảm nhận những gì có thể với API nâng chủ đề mới.

00:18:07.000 --> 00:18:13.000
Tóm lại, VisionKit là cách nhanh nhất để kết hợp nâng chủ đề vào ứng dụng của bạn.

00:18:13.000 --> 00:18:18.000
Đối với các ứng dụng nâng cao hơn, bạn có thể thả xuống API của Vision.

00:18:18.000 --> 00:18:25.000
Và cuối cùng, CoreImage là người bạn đồng hành hoàn hảo để thực hiện xử lý hình ảnh hỗ trợ HDR với việc nâng đối tượng.

00:18:25.000 --> 00:18:30.000
Lizzy và tôi hy vọng bạn thích video này, và chúng tôi rất vui mừng khi thấy những gì bạn xây dựng.

00:18:30.000 --> 23:59:59.000
♪ ♪

