WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:15.000
Grant: Xin chào, tên tôi là Grant. Tôi là một Kỹ sư trong Nhóm Tiếp cận.

00:00:15.000 --> 00:00:23.000
Nhiều người sử dụng tổng hợp giọng nói trên các nền tảng của Apple và một số người dựa vào giọng nói tổng hợp.

00:00:23.000 --> 00:00:26.000
Những giọng nói này là một cửa sổ vào thiết bị của họ.

00:00:26.000 --> 00:00:31.000
Do đó, tiếng nói họ chọn thường là một lựa chọn rất cá nhân.

00:00:31.000 --> 00:00:37.000
Những người sử dụng tổng hợp giọng nói trên iOS đã có thể chọn từ nhiều giọng nói khác nhau.

00:00:37.000 --> 00:00:41.000
Hãy xem cách bạn có thể cung cấp nhiều hơn nữa.

00:00:41.000 --> 00:00:55.000
Đầu tiên, chúng ta sẽ nói về Ngôn ngữ đánh dấu tổng hợp giọng nói là gì, cách nó có thể mang lại đầu ra giọng nói nhập vai cho giọng nói tùy chỉnh của bạn và lý do tại sao nhà cung cấp giọng nói của bạn nên áp dụng nó.

00:00:55.000 --> 00:01:05.000
Tiếp theo, chúng tôi sẽ hướng dẫn cách bạn có thể triển khai nhà cung cấp tổng hợp giọng nói để mang lại trải nghiệm tổng hợp và giọng nói của bạn trên thiết bị.

00:01:05.000 --> 00:01:09.000
Và cuối cùng, chúng ta sẽ đi sâu vào Giọng nói Cá nhân.

00:01:09.000 --> 00:01:11.000
Đây là một tính năng mới.

00:01:11.000 --> 00:01:18.000
Giờ đây, mọi người có thể ghi lại giọng nói của họ và sau đó tạo ra một giọng nói tổng hợp từ những bản ghi âm đó.

00:01:18.000 --> 00:01:24.000
Vì vậy, bây giờ, bạn có thể tổng hợp lời nói bằng giọng nói cá nhân của chính người dùng.

00:01:24.000 --> 00:01:29.000
Hãy bắt đầu bằng cách xem SSML.

00:01:29.000 --> 00:01:35.000
SSML là một tiêu chuẩn W3C để đại diện cho văn bản nói.

00:01:35.000 --> 00:01:43.000
SSML Speech được thể hiện một cách khai báo bằng cách sử dụng định dạng XML với nhiều thẻ và thuộc tính khác nhau.

00:01:43.000 --> 00:01:49.000
Bạn có thể sử dụng các thẻ này để kiểm soát các thuộc tính giọng nói như tốc độ và cao độ.

00:01:49.000 --> 00:01:53.000
SSML được sử dụng trong các bộ tổng hợp của bên thứ nhất.

00:01:53.000 --> 00:02:00.000
Điều này bao gồm WebSpeech trong WebKit và là đầu vào tiêu chuẩn cho bộ tổng hợp giọng nói.

00:02:00.000 --> 00:02:04.000
Hãy xem cách bạn có thể sử dụng SSML.

00:02:04.000 --> 00:02:07.000
Lấy cụm từ ví dụ này có tạm dừng trong đó.

00:02:07.000 --> 00:02:11.000
Chúng tôi có thể đại diện cho khoảng dừng này trong SSML.

00:02:11.000 --> 00:02:21.000
Chúng ta sẽ bắt đầu với chuỗi "xin chào" của mình, thêm một giây tạm dừng của chúng ta bằng cách sử dụng thẻ ngắt SSML và kết thúc bằng cách tăng tốc "rất vui được gặp bạn!"

00:02:21.000 --> 00:02:29.000
Chúng tôi làm điều này bằng cách thêm thẻ prosody SSML và đặt thuộc tính tỷ lệ thành 200%.

00:02:29.000 --> 00:02:36.000
Bây giờ chúng ta có thể lấy SSML này và tạo một AVSpeechUtterance để nói chuyện.

00:02:36.000 --> 00:02:43.000
Tiếp theo, chúng ta hãy xem cách bạn có thể triển khai giọng nói tổng hợp giọng nói của riêng mình.

00:02:43.000 --> 00:02:45.000
Vậy bộ tổng hợp giọng nói là gì?

00:02:45.000 --> 00:02:58.000
Bộ tổng hợp giọng nói nhận được một số văn bản và thông tin về các thuộc tính giọng nói mong muốn dưới dạng SSML và cung cấp biểu diễn âm thanh của văn bản đó.

00:02:58.000 --> 00:03:06.000
Giả sử bạn có một bộ tổng hợp với những giọng nói mới tuyệt vời và bạn muốn đưa nó lên iOS, macOS và iPadOS.

00:03:06.000 --> 00:03:19.000
Các nhà cung cấp tổng hợp giọng nói cho phép bạn triển khai bộ tổng hợp giọng nói và giọng nói của riêng mình vào nền tảng của chúng tôi để mang lại nhiều cá nhân hóa hơn cho người dùng ngoài giọng nói của hệ thống.

00:03:19.000 --> 00:03:21.000
Hãy xem cái này hoạt động như thế nào.

00:03:21.000 --> 00:03:30.000
Các tiện ích mở rộng đơn vị âm thanh của nhà cung cấp tổng hợp giọng nói sẽ được nhúng vào ứng dụng máy chủ và sẽ nhận được các yêu cầu giọng nói dưới dạng SSML.

00:03:30.000 --> 00:03:42.000
Tiện ích mở rộng sẽ chịu trách nhiệm hiển thị âm thanh cho đầu vào SSML và tùy chọn trả về các điểm đánh dấu cho biết nơi các từ xuất hiện trong các bộ đệm âm thanh đó.

00:03:42.000 --> 00:03:46.000
Hệ thống sau đó sẽ quản lý tất cả phát lại cho yêu cầu giọng nói đó.

00:03:46.000 --> 00:03:55.000
Bạn không cần phải xử lý bất kỳ quản lý phiên âm thanh nào; nó được quản lý nội bộ bởi khuôn khổ Nhà cung cấp tổng hợp giọng nói.

00:03:55.000 --> 00:04:02.000
Bây giờ chúng ta đã hiểu bộ tổng hợp là gì, chúng ta có thể bắt đầu xây dựng một phần mở rộng bộ tổng hợp giọng nói.

00:04:02.000 --> 00:04:20.000
Hãy bắt đầu bằng cách tạo một dự án ứng dụng Mở rộng Đơn vị Âm thanh mới trong Xcode, sau đó chọn Loại Đơn vị Âm thanh "Speech Synthesizer" và cung cấp mã định danh loại phụ bốn ký tự cho bộ tổng hợp của bạn, cũng như mã định danh bốn ký tự cho bạn với tư cách là nhà sản xuất.

00:04:20.000 --> 00:04:27.000
Phần mở rộng đơn vị âm thanh là kiến trúc cốt lõi mà trên đó các phần mở rộng bộ tổng hợp giọng nói đã được xây dựng.

00:04:27.000 --> 00:04:33.000
Chúng cho phép bộ tổng hợp của bạn chạy trong quy trình mở rộng thay vì trong quy trình ứng dụng máy chủ của bạn.

00:04:33.000 --> 00:04:42.000
Ứng dụng của chúng tôi sẽ cung cấp một giao diện đơn giản để mua và chọn một giọng nói mà tiện ích mở rộng của chúng tôi sẽ tổng hợp giọng nói.

00:04:42.000 --> 00:04:48.000
Chúng tôi sẽ bắt đầu bằng cách tạo một chế độ xem danh sách hiển thị các giọng nói có sẵn của chúng tôi để mua.

00:04:48.000 --> 00:04:52.000
Mỗi ô thoại sẽ hiển thị tên giọng nói và nút mua.

00:04:52.000 --> 00:04:56.000
Tiếp theo, tôi sẽ điền vào danh sách của mình với một số giọng nói.

00:04:56.000 --> 00:05:04.000
Ở đây, WWDCVoice là một cấu trúc đơn giản giữ tên giọng nói và số nhận dạng.

00:05:04.000 --> 00:05:13.000
Chúng tôi cũng cần một biến trạng thái để theo dõi các giọng nói đã mua và một phần mới để hiển thị chúng.

00:05:13.000 --> 00:05:17.000
Tiếp theo, hãy tạo một chức năng để mua một giọng nói.

00:05:17.000 --> 00:05:23.000
Tại đây chúng tôi có thể thêm giọng nói mới mua vào danh sách của mình và cập nhật giao diện người dùng của chúng tôi cho phù hợp.

00:05:23.000 --> 00:05:29.000
Lưu ý về phương pháp AVSpeechSynthesisProviderVoice updateSpeechVoices.

00:05:29.000 --> 00:05:39.000
Đó là cách ứng dụng của bạn có thể báo hiệu rằng tập hợp các giọng nói có sẵn cho bộ tổng hợp của bạn đã thay đổi và danh sách giọng nói hệ thống nên được xây dựng lại.

00:05:39.000 --> 00:05:46.000
Trong ví dụ của chúng tôi, chúng tôi có thể thực hiện cuộc gọi này sau khi hoàn tất giao dịch mua trong ứng dụng cho một giọng nói.

00:05:46.000 --> 00:05:53.000
Chúng tôi cũng cần một cách để theo dõi giọng nói nào có sẵn trong tiện ích mở rộng tổng hợp giọng nói của chúng tôi.

00:05:53.000 --> 00:05:59.000
Điều này có thể được thực hiện bằng cách tạo một phiên bản UserDefaults sẽ được chia sẻ thông qua một nhóm ứng dụng.

00:05:59.000 --> 00:06:05.000
Một nhóm ứng dụng sẽ cho phép chúng tôi chia sẻ danh sách thoại này giữa ứng dụng chủ và tiện ích mở rộng của chúng tôi.

00:06:05.000 --> 00:06:11.000
Chúng tôi đang chỉ định rõ ràng một tên bộ mà chúng tôi đã cung cấp khi tạo nhóm ứng dụng.

00:06:11.000 --> 00:06:16.000
Điều này đảm bảo ứng dụng máy chủ và tiện ích mở rộng được đọc từ cùng một miền.

00:06:16.000 --> 00:06:25.000
Nhìn lại chức năng mua hàng, tôi đã triển khai một phương pháp để cập nhật mặc định của người dùng khi mua một giọng nói mới.

00:06:25.000 --> 00:06:31.000
AVSpeechSynthesizer cũng có API mới để lắng nghe sự thay đổi trong giọng nói hệ thống có sẵn.

00:06:31.000 --> 00:06:38.000
Bộ giọng nói hệ thống có thể thay đổi khi người dùng xóa giọng nói hoặc tải xuống giọng nói mới.

00:06:38.000 --> 00:06:47.000
Bạn có thể đăng ký availableVoicesDidChangeNotification để cập nhật danh sách giọng nói của mình dựa trên những thay đổi này.

00:06:47.000 --> 00:06:54.000
Bây giờ ứng dụng máy chủ của chúng tôi đã hoàn tất, hãy điền vào đơn vị âm thanh, bao gồm bốn thành phần chính.

00:06:54.000 --> 00:07:01.000
Điều đầu tiên chúng tôi cần bổ sung là một số cách để thông báo cho hệ thống về những giọng nói mà bộ tổng hợp của chúng tôi sẽ cung cấp.

00:07:01.000 --> 00:07:13.000
Điều này được thực hiện bằng cách ghi đè trình nhận speechVoices để cung cấp danh sách giọng nói và đọc từ nhóm ứng dụng UserDefaults miền mà chúng tôi đã chỉ định trước đó.

00:07:13.000 --> 00:07:21.000
Đối với mỗi mục trong danh sách giọng nói của chúng tôi, chúng tôi sẽ xây dựng một AVSpeechSynthesisProviderVoice tiếng Anh Hoa Kỳ.

00:07:21.000 --> 00:07:27.000
Tiếp theo, chúng ta cần một số cách để hệ thống cho bộ tổng hợp biết văn bản nào cần tổng hợp.

00:07:27.000 --> 00:07:36.000
Phương thức synthesizeSpeechRequest sẽ được gọi khi hệ thống muốn báo hiệu cho một tiện ích mở rộng rằng nó sẽ bắt đầu tổng hợp một số văn bản.

00:07:36.000 --> 00:07:46.000
Đối số của phương pháp này sẽ là một ví dụ của AVSpeechSynthesisProviderRequest chứa SSML và giọng nói nào để nói chuyện.

00:07:46.000 --> 00:07:51.000
Tiếp theo, tôi sẽ gọi một phương thức trợ giúp mà tôi đã tạo trong việc triển khai công cụ giọng nói của mình.

00:07:51.000 --> 00:08:01.000
Trong ví dụ này, phương thức getAudioBuffer của tôi sẽ tạo dữ liệu âm thanh dựa trên giọng nói được chỉ định trong yêu cầu và đầu vào SSML.

00:08:01.000 --> 00:08:13.000
Chúng tôi cũng sẽ đặt một biến thể hiện, được gọi là framePosition, thành 0 để theo dõi số lượng khung hình chúng tôi đã hiển thị khi khối kết xuất được gọi và chúng tôi sao chép các khung ra khỏi bộ đệm.

00:08:13.000 --> 00:08:21.000
Hệ thống cũng cần một cách để báo hiệu cho bộ tổng hợp để ngừng tổng hợp âm thanh và loại bỏ yêu cầu giọng nói hiện tại.

00:08:21.000 --> 00:08:27.000
Điều này được thực hiện với cancelSpeechRequest, nơi chúng tôi sẽ đơn giản loại bỏ bộ đệm hiện tại.

00:08:27.000 --> 00:08:31.000
Cuối cùng, chúng ta cần triển khai khối kết xuất.

00:08:31.000 --> 00:08:35.000
Khối kết xuất được gọi bởi hệ thống với frameCount mong muốn.

00:08:35.000 --> 00:08:42.000
Đơn vị âm thanh sau đó chịu trách nhiệm điền số lượng khung hình được yêu cầu vào đầu ra AudioBuffer.

00:08:42.000 --> 00:08:53.000
Tiếp theo, chúng tôi sẽ tự thiết lập một tham chiếu đến bộ đệm đích và bộ đệm mà chúng tôi đã tạo và lưu trữ trước đó trong cuộc gọi synthesizeSpeechRequest.

00:08:53.000 --> 00:08:57.000
Sau đó, chúng tôi sẽ sao chép các khung vào bộ đệm mục tiêu.

00:08:57.000 --> 00:09:14.000
Và cuối cùng, một khi đơn vị âm thanh đã cạn kiệt tất cả các bộ đệm cho yêu cầu giọng nói hiện tại, đối số actionFlags nên được đặt thành offlineUnitRenderAction_Complete để báo hiệu cho hệ thống rằng kết xuất đã hoàn tất và không còn bộ đệm âm thanh nào được hiển thị nữa.

00:09:14.000 --> 00:09:16.000
Hãy xem nó hoạt động!

00:09:16.000 --> 00:09:19.000
Đây là ứng dụng tổng hợp giọng nói của tôi.

00:09:19.000 --> 00:09:27.000
Tôi sẽ mua một giọng nói và điều hướng đến chế độ xem nơi tôi có thể tổng hợp giọng nói bằng cách sử dụng công cụ giọng nói và giọng nói mới của mình.

00:09:27.000 --> 00:09:34.000
Đầu tiên, tôi sẽ cung cấp cho bộ tổng hợp một đầu vào là "xin chào".

00:09:34.000 --> 00:09:36.000
Giọng nói tổng hợp: Xin chào.

00:09:36.000 --> 00:09:41.000
Grant: Sau đó tôi sẽ đưa ra đầu vào "tạm biệt".

00:09:41.000 --> 00:09:43.000
Giọng tổng hợp: Tạm biệt.

00:09:43.000 --> 00:09:54.000
Grant: Chúng tôi hiện đã triển khai một nhà cung cấp tổng hợp và tạo ra một ứng dụng lưu trữ cung cấp giọng nói mà bạn có thể sử dụng trên toàn hệ thống, từ VoiceOver đến các ứng dụng của riêng bạn!

00:09:54.000 --> 00:10:01.000
Chúng tôi nóng lòng muốn xem những giọng nói và trải nghiệm chuyển văn bản thành giọng nói mới mà bạn tạo ra bằng cách sử dụng các API này.

00:10:01.000 --> 00:10:06.000
Hãy tiếp tục và nói về một tính năng mới có tên là Personal Voice.

00:10:06.000 --> 00:10:14.000
Giờ đây mọi người có thể ghi âm và tạo lại giọng nói của họ trên iOS và macOS bằng sức mạnh của thiết bị.

00:10:14.000 --> 00:10:19.000
Giọng nói cá nhân của bạn được tạo trên thiết bị chứ không phải trên máy chủ.

00:10:19.000 --> 00:10:26.000
Giọng nói này sẽ xuất hiện giữa các giọng nói còn lại của Hệ thống và có thể được sử dụng với một tính năng mới gọi là Live Speech.

00:10:26.000 --> 00:10:38.000
Live Speech là một tính năng gõ để nói trên iOS, iPadOS, macOS và watchOS cho phép một người tổng hợp lời nói bằng giọng nói của chính họ một cách nhanh chóng.

00:10:38.000 --> 00:10:46.000
Bạn có thể yêu cầu quyền truy cập để tổng hợp lời nói với những giọng nói này bằng cách sử dụng API ủy quyền yêu cầu mới cho Giọng nói cá nhân.

00:10:46.000 --> 00:10:55.000
Hãy nhớ rằng việc sử dụng Giọng nói Cá nhân rất nhạy cảm và nên được sử dụng chủ yếu cho các ứng dụng giao tiếp tăng cường hoặc thay thế.

00:10:55.000 --> 00:11:00.000
Hãy kiểm tra một ứng dụng AAC mà tôi đã tạo để sử dụng Personal Voice.

00:11:00.000 --> 00:11:11.000
Ứng dụng của tôi có hai nút sẽ nói các cụm từ phổ biến mà tôi thấy mình đang nói tại WWDC và một nút để yêu cầu quyền truy cập để sử dụng Giọng nói Cá nhân.

00:11:11.000 --> 00:11:20.000
Ủy quyền có thể được yêu cầu với một API mới được gọi là requestPersonalVoiceAuthorization trên AVSpeechSynthesizer.

00:11:20.000 --> 00:11:34.000
Sau khi được ủy quyền, Personal Voices sẽ xuất hiện cùng với System voices trong AVSpeechSynthesisVoice API speechVoices và sẽ được biểu thị bằng một voiceTrait mới được gọi làPersonalVoice.

00:11:34.000 --> 00:11:40.000
Bây giờ tôi đã có quyền truy cập vào Personal Voice, tôi có thể sử dụng nó để nói chuyện.

00:11:40.000 --> 00:11:43.000
Hãy cùng xem bản demo của Personal Voice đang hoạt động.

00:11:43.000 --> 00:11:54.000
Đầu tiên, tôi sẽ nhấn vào nút "Sử dụng giọng nói cá nhân" để yêu cầu ủy quyền và sau khi được ủy quyền, tôi có thể nhấn vào biểu tượng để nghe giọng nói của mình.

00:11:54.000 --> 00:11:58.000
Giọng nói cá nhân: Xin chào, tên tôi là Grant. Chào mừng đến với WWDC23.

00:11:58.000 --> 00:12:00.000
Grant: Điều đó thật tuyệt vời phải không?

00:12:00.000 --> 00:12:04.000
Và bây giờ bạn cũng có thể sử dụng những giọng nói này trong ứng dụng của mình.

00:12:04.000 --> 00:12:13.000
Bây giờ chúng ta đã thảo luận về SSML, bạn nên sử dụng nó để chuẩn hóa đầu vào giọng nói và xây dựng trải nghiệm giọng nói phong phú trong các ứng dụng của mình.

00:12:13.000 --> 00:12:24.000
Chúng tôi cũng đã hướng dẫn cách triển khai Speech Synthesizer của bạn vào các nền tảng của Apple, vì vậy bây giờ bạn có thể cung cấp giọng nói giọng nói mới tuyệt vời mà mọi người có thể sử dụng trên toàn hệ thống.

00:12:24.000 --> 00:12:35.000
Và cuối cùng, với Personal Voice, bạn có thể mang lại nhiều nét cá nhân hơn để tổng hợp trong các ứng dụng của mình, đặc biệt là đối với những người có thể có nguy cơ mất giọng nói của chính họ.

00:12:35.000 --> 00:12:40.000
Chúng tôi rất vui mừng khi thấy những trải nghiệm bạn tạo ra khi sử dụng các API này.

00:12:40.000 --> 23:59:59.000
Cảm ơn vì đã xem.

