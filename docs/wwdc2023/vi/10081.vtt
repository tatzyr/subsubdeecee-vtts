WEBVTT

00:00:00.000 --> 00:00:03.000
♪ Hip-hop nhạc cụ êm dịu ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:15.000
Xin chào, tên tôi là Yujin, và tôi là một kỹ sư trong nhóm RealityKit.

00:00:15.000 --> 00:00:24.000
Hôm nay, tôi sẽ chỉ cho bạn các tính năng mới trong RealityKit mà bạn có thể sử dụng để nâng cao các ứng dụng tính toán không gian của mình.

00:00:24.000 --> 00:00:32.000
Kể từ khi chúng tôi phát hành RealityKit vào năm 2019, Chúng tôi đã thấy các ứng dụng sử dụng bộ tính năng phong phú của nó để tạo ra một số trải nghiệm tuyệt vời.

00:00:32.000 --> 00:00:42.000
Giờ đây, điện toán không gian bổ sung nhiều tính năng hơn cho RealityKit, như cổng thông tin, bộ phát hạt, tệp đính kèm RealityView và nhiều tính năng khác.

00:00:42.000 --> 00:01:03.000
Trong phiên có tiêu đề "Xây dựng trải nghiệm không gian với RealityKit", chúng tôi đã tìm hiểu về các khối xây dựng cơ bản của RealityKit: các thực thể, là các đối tượng chứa; các thành phần, xác định hành vi cụ thể trên các thực thể; và các hệ thống, hoạt động trên cả thực thể và thành phần để thêm chức năng.

00:01:03.000 --> 00:01:09.000
Chúng tôi đã đề cập đến RealityView API, hoạt động như một cầu nối giữa SwiftUI và RealityKit.

00:01:09.000 --> 00:01:15.000
Chúng tôi cũng đã chỉ cho bạn cách thêm tương tác, hoạt ảnh và Âm thanh không gian vào cảnh RealityKit của bạn.

00:01:15.000 --> 00:01:21.000
Nếu bạn chưa xem nó, tôi thực sự khuyên bạn nên xem phiên đó.

00:01:21.000 --> 00:01:29.000
Trong phiên này, chúng tôi sẽ đề cập đến các tính năng mới trong RealityKit sẽ giúp làm cho ứng dụng của bạn trở nên hấp dẫn và nhập vai hơn.

00:01:29.000 --> 00:01:38.000
Đầu tiên, chúng ta sẽ học cách nhúng chế độ xem SwiftUI vào nội dung RealityKit của chúng ta bằng cách sử dụng các tệp đính kèm trong RealityView.

00:01:38.000 --> 00:01:43.000
Tiếp theo, chúng ta sẽ xem xét cách thêm phát lại video trong cảnh RealityKit của chúng ta.

00:01:43.000 --> 00:01:49.000
Sau đó, chúng ta sẽ học cách sử dụng cổng thông tin để mở một cửa sổ đến một thế giới thay thế.

00:01:49.000 --> 00:01:56.000
Chúng ta sẽ xem xét cách sử dụng Particle Emitters API để nâng cao cảnh của bạn với các hiệu ứng hình ảnh.

00:01:56.000 --> 00:02:05.000
Cuối cùng, chúng ta sẽ học cách sử dụng neo trong RealityKit để đính kèm nội dung 3D vào các vị trí trong thế giới thực, chẳng hạn như một bức tường.

00:02:05.000 --> 00:02:08.000
Hãy bắt đầu với các tệp đính kèm RealityView.

00:02:08.000 --> 00:02:14.000
Tệp đính kèm là một cách hữu ích để nhúng nội dung SwiftUI vào cảnh RealityKit của bạn.

00:02:14.000 --> 00:02:21.000
Trong ứng dụng ví dụ này, tôi đã sử dụng tệp đính kèm để đặt nhãn văn bản bên dưới các mô hình của trái đất và mặt trăng.

00:02:21.000 --> 00:02:27.000
Tôi cũng đã đính kèm một quan điểm giải thích cách mặt trăng ảnh hưởng đến thủy triều trên đại dương của chúng ta.

00:02:27.000 --> 00:02:30.000
Hãy xem cách tạo điều này bằng mã.

00:02:30.000 --> 00:02:35.000
Bên trong ứng dụng của mình, tôi đang sử dụng RealityView để hiển thị mô hình trái đất của mình.

00:02:35.000 --> 00:02:40.000
RealityView là một chế độ xem cho phép chúng tôi thêm các thực thể RealityKit.

00:02:40.000 --> 00:02:46.000
Các thực thể cần được thêm vào Chế độ xem thực tế để được hiển thị, hoạt hình và mô phỏng.

00:02:46.000 --> 00:02:52.000
Ở đây chúng tôi chỉ cần tải một thực thể cho trái đất và thêm nó vào nội dung của RealityView.

00:02:52.000 --> 00:02:56.000
Bây giờ hãy thay đổi RealityView của chúng ta để sử dụng tệp đính kèm.

00:02:56.000 --> 00:03:02.000
Tệp đính kèm là các chế độ xem có thể được đặt tại các vị trí cụ thể liên quan đến nội dung RealityKit của bạn.

00:03:02.000 --> 00:03:05.000
Có hai phần để thiết lập tệp đính kèm.

00:03:05.000 --> 00:03:11.000
Đầu tiên, có tham số được thêm vào trong việc đóng thực hiện Chế độ xem thực tế của chúng tôi.

00:03:11.000 --> 00:03:16.000
Thứ hai, có một trình tạo chế độ xem tệp đính kèm được thêm vào Chế độ xem thực tế của chúng tôi.

00:03:16.000 --> 00:03:19.000
Trước tiên hãy bao gồm trình tạo chế độ xem tệp đính kèm.

00:03:19.000 --> 00:03:25.000
Tại đây bạn có thể cung cấp chế độ xem SwiftUI mà bạn muốn thêm vào nội dung RealityKit của mình.

00:03:25.000 --> 00:03:30.000
Trong ví dụ này, tôi đã thêm chế độ xem văn bản để gắn nhãn Trái đất.

00:03:30.000 --> 00:03:39.000
Chúng tôi cũng sẽ thêm một công cụ sửa đổi thẻ vào chế độ xem để sau này chúng tôi có thể xác định nó khi chế độ xem của chúng tôi được chuyển đến make closure với tư cách là một thực thể.

00:03:39.000 --> 00:03:42.000
Thẻ này có thể là bất kỳ giá trị có thể băm nào.

00:03:42.000 --> 00:03:46.000
Ở đây tôi đã sử dụng chuỗi earth_label.

00:03:46.000 --> 00:03:54.000
Trong phần đóng của RealityView của chúng tôi, tham số tệp đính kèm chứa các chế độ xem của chúng tôi hiện được biểu diễn dưới dạng các thực thể.

00:03:54.000 --> 00:04:05.000
Để có được chế độ xem của chúng tôi ở dạng thực thể, chúng tôi gọi thực thể (cho:) trên tệp đính kèm của mình và chuyển cùng một thẻ mà chúng tôi đã cung cấp trong trình tạo chế độ xem, earth_label.

00:04:05.000 --> 00:04:13.000
Kết quả mà chúng tôi nhận được là một thực thể đính kèm xem, mà chúng tôi có thể thêm vào nội dung RealityKit của mình, giống như bất kỳ thực thể nào khác.

00:04:13.000 --> 00:04:23.000
Để làm cho nhãn xuất hiện bên dưới trái đất, chúng tôi sẽ thêm tệp đính kèm như một con của thực thể trái đất của chúng tôi và đặt nó bên dưới một chút.

00:04:23.000 --> 00:04:29.000
Bây giờ chúng ta có thể lặp lại quy trình này cho tất cả các tệp đính kèm khác mà chúng ta muốn thêm bằng cách sử dụng một thẻ khác nhau cho mỗi tệp.

00:04:29.000 --> 00:04:32.000
Hãy cùng xem qua Xcode.

00:04:32.000 --> 00:04:37.000
Trong ứng dụng mẫu của tôi, tôi sẽ thêm ba tệp đính kèm vào RealityView của mình.

00:04:37.000 --> 00:04:40.000
Đầu tiên, tôi sẽ thêm một nhãn bên dưới lòng đất.

00:04:40.000 --> 00:04:44.000
Tôi cũng sẽ làm điều tương tự cho mặt trăng.

00:04:44.000 --> 00:04:50.000
Cuối cùng, tôi sẽ thêm một đoạn văn ngắn giải thích vai trò của quỹ đạo mặt trăng đối với thủy triều.

00:04:50.000 --> 00:04:55.000
Tôi đã tạo kiểu này bằng cách sử dụng glassBackgroundEffect trong SwiftUI.

00:04:55.000 --> 00:05:01.000
Trong phần đóng của RealityView, tôi sẽ thêm các thực thể tương ứng vào nội dung của mình.

00:05:01.000 --> 00:05:06.000
Đầu tiên, tôi sẽ thêm phần đính kèm trái đất bên dưới trái đất.

00:05:06.000 --> 00:05:08.000
Tôi sẽ làm điều tương tự cho mặt trăng.

00:05:08.000 --> 00:05:14.000
Cuối cùng, tôi sẽ đặt người giải thích thủy triều ở bên trái của thực thể container của tôi.

00:05:14.000 --> 00:05:23.000
Tôi sẽ xây dựng và chạy ứng dụng của mình, và chúng ta sẽ thấy các tệp đính kèm mà tôi đã tạo được hiển thị bên cạnh các mô hình của mình.

00:05:23.000 --> 00:05:27.000
Hãy tóm tắt lại luồng dữ liệu cho các tệp đính kèm.

00:05:27.000 --> 00:05:32.000
Tệp đính kèm bắt đầu trong trình tạo chế độ xem tệp đính kèm trong RealityView của chúng tôi.

00:05:32.000 --> 00:05:37.000
Tại đây, chúng tôi có thể cung cấp các chế độ xem SwiftUI mà chúng tôi muốn thêm vào cảnh RealityKit của mình.

00:05:37.000 --> 00:05:46.000
Trong quá trình đóng RealityView của chúng tôi, chúng tôi lấy lại các tệp đính kèm dưới dạng thực thể, sau đó chúng tôi có thể thêm vào cảnh của mình.

00:05:46.000 --> 00:05:50.000
Chúng tôi cũng có thể cập nhật các thực thể bên trong việc đóng bản cập nhật.

00:05:50.000 --> 00:05:56.000
Việc đóng cửa này được gọi khi có những thay đổi đối với trạng thái xem SwiftUI của chúng tôi.

00:05:56.000 --> 00:06:02.000
Bạn có thể sử dụng cái này để phản hồi nội dung thay đổi động trong RealityView của mình.

00:06:02.000 --> 00:06:10.000
Để sử dụng tệp đính kèm chi tiết hơn, hãy xem phiên "Làm việc với nội dung Reality Composer Pro trong Xcode."

00:06:10.000 --> 00:06:17.000
Tệp đính kèm RealityView là một cách hữu ích để thêm nội dung văn bản trong các yếu tố giao diện người dùng khác vào một cảnh.

00:06:17.000 --> 00:06:22.000
Ngoài ra, chúng tôi cũng có thể thêm một video vào ứng dụng của mình để làm cho nó hấp dẫn hơn.

00:06:22.000 --> 00:06:27.000
Để làm điều này, hãy sử dụng VideoPlayerComponent.

00:06:27.000 --> 00:06:36.000
Thành phần trình phát video là một loại thành phần mới trong RealityKit được sử dụng để nhúng nội dung video vào bên trong cảnh 3D.

00:06:36.000 --> 00:06:43.000
Xin nhắc lại, các thành phần xác định hành vi cụ thể mà bạn có thể gắn vào các thực thể.

00:06:43.000 --> 00:06:50.000
Để phát video bằng VideoPlayerComponent, trước tiên chúng tôi sẽ tải tệp video từ gói tài nguyên của mình.

00:06:50.000 --> 00:06:54.000
Sau đó, chúng tôi sẽ sử dụng nó để tạo một phiên bản AVPlayer.

00:06:54.000 --> 00:06:59.000
Với nó, bây giờ chúng ta có thể tạo một VideoPlayerComponent.

00:06:59.000 --> 00:07:09.000
Khi bạn đính kèm một VideoPlayerComponent vào một thực thể, một lưới hình chữ nhật phù hợp với tỷ lệ khung hình của video sẽ tự động được tạo cho bạn.

00:07:09.000 --> 00:07:19.000
Hành vi này tương tự như các API trình phát video hiện có, chẳng hạn như VideoPlayer trong SwiftUI và AVPlayerLayer trong Core Animation.

00:07:19.000 --> 00:07:31.000
Tuy nhiên, vì RealityKit là một khung 3D, video của bạn sẽ được thể hiện như một thực thể có lưới để bạn có thể di chuyển và định vị nó trong không gian 3D.

00:07:31.000 --> 00:07:43.000
Tất cả các định dạng video được AV Foundation hỗ trợ sẽ hoạt động với VideoPlayerComponent, bao gồm các định dạng video 2D và video 3D sử dụng MV-HEVC.

00:07:43.000 --> 00:07:51.000
Cuối cùng, VideoPlayerComponent sẽ tự động hiển thị chú thích được cung cấp thông qua AVPlayer.

00:07:51.000 --> 00:08:03.000
Để tìm hiểu thêm về cách tạo nội dung video của riêng bạn, bao gồm video 3D, hãy xem phiên có tiêu đề "Cung cấp nội dung video cho trải nghiệm không gian".

00:08:03.000 --> 00:08:12.000
Để thêm video vào cảnh RealityKit của tôi, trước tiên chúng tôi sẽ tạo AVPlayerItem bằng cách sử dụng URL đến nội dung video của tôi.

00:08:12.000 --> 00:08:15.000
Sau đó chúng tôi sẽ tạo một AVPlayer.

00:08:15.000 --> 00:08:23.000
Trên thực thể, chúng tôi sẽ thêm một VideoPlayerComponent được khởi tạo với AVPlayer mà chúng tôi vừa tạo.

00:08:23.000 --> 00:08:30.000
VideoPlayerComponent sẽ tự động tạo ra một lưới có kích thước dựa trên tỷ lệ khung hình của video của tôi.

00:08:30.000 --> 00:08:37.000
Bởi vì RealityKit hoạt động trong các đơn vị trong thế giới thực, theo mặc định, video sẽ có chiều cao một mét.

00:08:37.000 --> 00:08:41.000
Để làm cho video có kích thước khác, chúng ta có thể mở rộng quy mô thực thể.

00:08:41.000 --> 00:08:50.000
Trong trường hợp của tôi, tôi muốn video cao 40 cm, vì vậy chúng tôi sẽ nhân thang đo thực thể với 0,4.

00:08:50.000 --> 00:08:52.000
Cuối cùng, chúng tôi đã sẵn sàng để phát video.

00:08:52.000 --> 00:08:59.000
Chúng tôi sẽ đặt mục hiện tại thành AVPlayerItem của chúng tôi, và sau đó gọi play trên AVPlayer.

00:08:59.000 --> 00:09:03.000
Hãy xây dựng lại và chạy ứng dụng của chúng ta với mã này.

00:09:03.000 --> 00:09:08.000
Tôi đã thêm nút Tìm hiểu thêm vào ứng dụng của chúng tôi, nút này sẽ thêm thực thể video vào cảnh của chúng tôi.

00:09:08.000 --> 00:09:15.000
Khi nhấp vào nút, tôi sẽ mờ dần trong video bằng cách sử dụng thành phần độ mờ và fromToByAnimation.

00:09:15.000 --> 00:09:24.000
Đối với nội dung video của chúng tôi, tôi đã chuẩn bị một đoạn clip ngắn giải thích vai trò của lực hấp dẫn của Mặt trăng đối với thủy triều dâng cao của Trái đất.

00:09:24.000 --> 00:09:25.000
Hãy cùng xem nào.

00:09:25.000 --> 00:09:28.000
Mặt trăng quay quanh hành tinh của chúng ta.

00:09:28.000 --> 00:09:43.000
Lực hấp dẫn của nó tác dụng một lực mạnh lên các đại dương của chúng ta, khiến nó hơi phình ra về phía quả cầu mặt trăng. &lt; VideoPlayerComponent tôn trọng các tùy chọn trên toàn hệ thống cho phụ đề.

00:09:43.000 --> 00:09:49.000
Hãy bật chúng lên trong ứng dụng Cài đặt trong phần Trợ năng.

00:09:49.000 --> 00:10:08.000
Và vì vậy, hai lần một ngày, trong một chu kỳ không bao giờ kết thúc, thủy triều lên xuống, được thúc đẩy bởi sự tương tác không ngừng của trái đất và mặt trăng. &lt; VideoPlayerComponent cũng hỗ trợ nhuộm màu truyền qua.

00:10:08.000 --> 00:10:14.000
Khi tính năng này được bật, nội dung chuyển tiếp của bạn sẽ được điều chỉnh để phù hợp với màu sắc trong video.

00:10:14.000 --> 00:10:21.000
Đây là cách xử lý tương tự được sử dụng khi xem phim và chương trình truyền hình bên trong ứng dụng TV trên nền tảng này.

00:10:21.000 --> 00:10:28.000
Để sử dụng tông màu passthrough, bạn có thể đặt thuộc tính isPassthroughTintingEnabled thành true.

00:10:28.000 --> 00:10:39.000
Bạn cũng có thể đăng ký VideoPlayerEvents để được thông báo khi các thuộc tính trên VideoPlayerComponent thay đổi, chẳng hạn như loại nội dung, chế độ xem và kích thước video.

00:10:39.000 --> 00:10:48.000
Để đăng ký các sự kiện, bạn có thể gọi hàm đăng ký trên nội dung RealityViews của mình và chỉ định loại sự kiện và thực thể.

00:10:48.000 --> 00:10:53.000
Bạn có thể phản hồi các sự kiện bên trong việc đóng trình xử lý sự kiện.

00:10:53.000 --> 00:10:58.000
VideoPlayerComponent là một bổ sung tuyệt vời cho cảnh 3D của chúng tôi.

00:10:58.000 --> 00:11:06.000
Cho đến nay, ứng dụng của chúng tôi có mô hình trái đất và mặt trăng, nhưng tôi muốn trình bày nó trong bối cảnh không gian bên ngoài.

00:11:06.000 --> 00:11:15.000
Tôi nghĩ sẽ khá tuyệt nếu chúng ta có thể biến mình thành một cửa sổ ma thuật trong căn phòng để lộ quỹ đạo của mặt trăng ở ngoài không gian.

00:11:15.000 --> 00:11:19.000
Chúng ta có thể làm điều này bằng cách sử dụng một cổng thông tin để hiển thị cảnh của chúng ta.

00:11:19.000 --> 00:11:26.000
Một cổng thông tin tạo ra một lối mở ra một thế giới khác có thể nhìn thấy thông qua bề mặt lưới.

00:11:26.000 --> 00:11:32.000
Các thực thể bên trong thế giới này sử dụng ánh sáng riêng biệt và bị che khuất bởi hình học của cổng thông tin.

00:11:32.000 --> 00:11:36.000
Ví dụ này thể hiện ba tính năng riêng biệt trong RealityKit.

00:11:36.000 --> 00:11:41.000
Đầu tiên, một cổng thông tin được sử dụng để hiển thị cảnh trong không gian bên ngoài.

00:11:41.000 --> 00:11:45.000
Sau đó, một hiệu ứng hạt được sử dụng để trang trí vành của cổng thông tin.

00:11:45.000 --> 00:11:50.000
Cuối cùng, neo được sử dụng để đặt cổng thông tin trên tường phòng của chúng tôi.

00:11:50.000 --> 00:11:53.000
Hãy bắt đầu với cổng thông tin.

00:11:53.000 --> 00:11:56.000
Để tạo ra một cổng thông tin, trước tiên chúng ta phải tạo ra một thế giới.

00:11:56.000 --> 00:12:02.000
Để làm điều này, chúng tôi thêm một thực thể trong cảnh của chúng tôi có thành phần Thế giới.

00:12:02.000 --> 00:12:06.000
Thành phần này đánh dấu cây thực thể của nó thuộc về một thế giới khác.

00:12:06.000 --> 00:12:11.000
Các thực thể trong một thế giới chỉ có thể nhìn thấy thông qua bề mặt cổng thông tin.

00:12:11.000 --> 00:12:17.000
Để thêm nội dung vào thế giới của chúng ta, chúng ta có thể đính kèm các thực thể như con của thực thể thế giới.

00:12:17.000 --> 00:12:27.000
Ở đây, chúng tôi sẽ thêm các mô hình cho bầu trời, trái đất và mặt trăng, cũng như Ánh sáng dựa trên hình ảnh để xác định ánh sáng bên trong thế giới.

00:12:27.000 --> 00:12:33.000
Tất cả hậu duệ của thực thể thế giới sẽ chỉ xuất hiện bên trong thế giới này.

00:12:33.000 --> 00:12:35.000
Tiếp theo, chúng ta sẽ tạo một cổng thông tin.

00:12:35.000 --> 00:12:38.000
Để làm điều này, chúng tôi thêm một thực thể với một thành phần mô hình.

00:12:38.000 --> 00:12:43.000
Thành phần mô hình chứa hai thuộc tính, một lưới và một vật liệu.

00:12:43.000 --> 00:12:49.000
Đối với lưới, chúng tôi sẽ tạo ra một mặt phẳng tròn để hoạt động như bề mặt của cổng thông tin.

00:12:49.000 --> 00:12:55.000
Đối với tài liệu, chúng tôi sẽ chỉ định một tài liệu cổng thông tin mới để làm cho lưới xuất hiện dưới dạng cổng thông tin.

00:12:55.000 --> 00:13:03.000
Để kết nối cổng thông tin với thế giới của chúng ta, chúng ta sẽ thêm một thành phần cổng thông tin vào thực thể và đặt thuộc tính mục tiêu của nó cho thực thể thế giới.

00:13:03.000 --> 00:13:11.000
Điều này cho phép cổng thông tin hoạt động như một mặt nạ để tiết lộ nội dung bên trong thế giới của chúng ta.

00:13:11.000 --> 00:13:14.000
Hãy xem cái này trông như thế nào trong mã.

00:13:14.000 --> 00:13:21.000
Trong RealityView của chúng tôi, tôi đã thêm các cuộc gọi vào hai chức năng sẽ triển khai makeWorld và makePortal.

00:13:21.000 --> 00:13:28.000
Trong chức năng makeWorld của chúng tôi, chúng tôi sẽ tạo một thực thể thế giới và điền vào đó nội dung của cổng thông tin.

00:13:28.000 --> 00:13:35.000
Trong chức năng makePortal, chúng tôi sẽ tạo một cổng thông tin và liên kết nó với thế giới mà chúng tôi vừa tạo.

00:13:35.000 --> 00:13:39.000
Cuối cùng, chúng tôi sẽ thêm cả hai thực thể này vào nội dung của RealityView.

00:13:39.000 --> 00:13:43.000
Hãy đi sâu vào từng chức năng này.

00:13:43.000 --> 00:13:50.000
Bên trong hàm makeWorld, chúng tôi tạo ra một thực thể và đính kèm một WorldComponent.

00:13:50.000 --> 00:13:55.000
Tiếp theo, chúng tôi tải một EnvironmentResource để sử dụng làm ImageBasedLight của chúng tôi.

00:13:55.000 --> 00:14:02.000
Chúng tôi sẽ áp dụng điều này cho thế giới bằng cách sử dụng thành phần ImageBasedLight và ImageBasedLight ReceiverComponent.

00:14:02.000 --> 00:14:11.000
Để tìm hiểu thêm về ánh sáng dựa trên hình ảnh trong RealityKit, hãy xem phiên "Khám phá kết xuất cho điện toán không gian".

00:14:11.000 --> 00:14:14.000
Tiếp theo, chúng ta sẽ lấp đầy thế giới với nội dung của chúng ta.

00:14:14.000 --> 00:14:20.000
Tôi sẽ tải các mô hình cho trái đất, mặt trăng và bầu trời, và thêm chúng vào thế giới khi còn nhỏ.

00:14:20.000 --> 00:14:26.000
Bởi vì những thực thể này là con của thế giới, chúng sẽ chỉ hiển thị thông qua cổng thông tin.

00:14:26.000 --> 00:14:29.000
Hãy chuyển sang chức năng makePortal.

00:14:29.000 --> 00:14:32.000
Để tạo một cổng thông tin, trước tiên chúng ta cần một lưới.

00:14:32.000 --> 00:14:36.000
Chúng tôi sẽ tạo ra một cái bằng cách tạo ra một thành phần mô hình cho thực thể.

00:14:36.000 --> 00:14:44.000
Để làm cho cổng thông tin của chúng tôi tròn, chúng tôi sẽ tạo ra một mặt phẳng có kích thước bằng nhau và bán kính góc bằng một nửa kích thước.

00:14:44.000 --> 00:14:49.000
Tôi cũng sẽ tạo một PortalMaterial để sử dụng làm tài liệu cho ModelComponent.

00:14:49.000 --> 00:14:57.000
Cuối cùng, chúng tôi cũng sẽ đính kèm một thành phần cổng thông tin được khởi tạo với thực thể thế giới mà chúng tôi đã tạo trước đó.

00:14:57.000 --> 00:15:04.000
Điều này liên kết cổng thông tin với thế giới để chúng ta có thể nhìn thấy nội dung của thế giới thông qua lưới.

00:15:04.000 --> 00:15:09.000
Tiếp theo, hãy trang trí vành cổng thông tin bằng hiệu ứng hạt.

00:15:09.000 --> 00:15:14.000
Để làm điều này, chúng ta có thể sử dụng ParticleEmitterComponent được cung cấp trong RealityKit.

00:15:14.000 --> 00:15:24.000
Bộ phát hạt có thể được sử dụng để thể hiện nhiều hiệu ứng hình ảnh khác nhau trong RealityKit, chẳng hạn như tia lửa, tuyết và hiệu ứng va chạm.

00:15:24.000 --> 00:15:38.000
Bộ phát hạt có thể được tạo thông qua Reality Composer Pro hoặc trong thời gian chạy bằng RealityKit thông qua ParticleEmitterComponent Ở đây, tôi đã chuẩn bị một tài sản hạt bằng Reality Composer Pro.

00:15:38.000 --> 00:15:42.000
Chúng ta có thể sử dụng cái này để trang trí cổng thông tin mà chúng ta đã tạo trước đó.

00:15:42.000 --> 00:15:49.000
Hãy tải cái này vào cảnh của chúng ta và sửa đổi các thuộc tính hạt trong thời gian chạy bằng RealityKit.

00:15:49.000 --> 00:15:56.000
Để cập nhật các hạt theo thời gian, tôi đã tạo một hệ thống tùy chỉnh có tên là ParticleTransitionSystem.

00:15:56.000 --> 00:16:03.000
Ở đây, chúng tôi sẽ sử dụng EntityQuery để tìm các thực thể có ParticleEmitterComponent.

00:16:03.000 --> 00:16:10.000
Bên trong bản cập nhật hệ thống, chúng tôi sẽ thực hiện truy vấn của mình và lặp lại các thực thể kết quả.

00:16:10.000 --> 00:16:16.000
Trên mỗi thực thể, chúng tôi sẽ gọi hàm updateParticles, mà chúng tôi sẽ triển khai tiếp theo.

00:16:16.000 --> 00:16:25.000
Để tìm hiểu thêm về các hệ thống tùy chỉnh trong RealityKit, hãy xem phiên "Xây dựng trải nghiệm không gian với RealityKit".

00:16:25.000 --> 00:16:32.000
Bên trong chức năng updateParticles của chúng tôi, trước tiên chúng tôi sẽ nhận được ParticleEmitterComponent từ thực thể.

00:16:32.000 --> 00:16:39.000
ParticleEmitterComponent chứa nhiều thuộc tính kiểm soát các khía cạnh khác nhau của giao diện và hành vi của hạt.

00:16:39.000 --> 00:16:51.000
Ở đây, chúng tôi sẽ thiết lập các thuộc tính lifeSpan và vortexStrength dựa trên quy mô của thực thể, để khi thực thể tăng kích thước, các hạt bắt đầu quay nhanh hơn xung quanh cổng thông tin.

00:16:51.000 --> 00:16:56.000
Cuối cùng, hãy áp dụng các thay đổi của chúng tôi bằng cách gán lại thành phần cho thực thể.

00:16:56.000 --> 00:16:58.000
Và chúng ta đã sẵn sàng.

00:16:58.000 --> 00:17:06.000
Để tìm hiểu về tất cả các thuộc tính khác nhau trên bộ phát hạt, hãy xem phiên "Gặp gỡ Reality Composer Pro".

00:17:06.000 --> 00:17:10.000
Chúng tôi gần như đã hoàn thành việc thêm liên lạc cuối cùng vào ứng dụng của mình.

00:17:10.000 --> 00:17:14.000
Để hoàn thành, hãy gắn cổng thông tin của chúng ta vào bức tường trong phòng của chúng ta.

00:17:14.000 --> 00:17:19.000
Để làm điều này, chúng ta có thể sử dụng neo trong RealityKit.

00:17:19.000 --> 00:17:27.000
Neo có thể được sử dụng để đặt nội dung trên tường, sàn nhà hoặc vị trí liên quan đến đầu hoặc tay của bạn.

00:17:27.000 --> 00:17:32.000
Neo trong RealityKit hỗ trợ hai chế độ theo dõi, .liên tục và .một lần.

00:17:32.000 --> 00:17:40.000
Khi sử dụng chế độ theo dõi liên tục, thực thể neo di chuyển cùng với neo theo thời gian, chẳng hạn như khi đầu bạn di chuyển.

00:17:40.000 --> 00:17:47.000
Khi sử dụng chế độ theo dõi một lần, thực thể neo sẽ không di chuyển sau khi được định vị một lần.

00:17:47.000 --> 00:17:54.000
Để lắng nghe khi một thực thể được neo, bạn có thể đăng ký sự kiện AnchoredStateChanged trong RealityKit.

00:17:54.000 --> 00:18:06.000
Lưu ý rằng trong khi bạn có thể sử dụng neo cho các thực thể mẹ để đặt nội dung 3D, các biến đổi rõ ràng của chính các neo không hiển thị cho ứng dụng để bảo vệ quyền riêng tư của người dùng.

00:18:06.000 --> 00:18:11.000
Để có quyền truy cập vào các biến đổi neo, bạn sẽ cần sử dụng ARKit.

00:18:11.000 --> 00:18:18.000
Để biết thêm thông tin về điều này, hãy xem phiên, "Gặp gỡ ARKit để tính toán không gian."

00:18:18.000 --> 00:18:23.000
Để sử dụng neo trong ứng dụng của chúng tôi, trước tiên chúng tôi cần sửa đổi ứng dụng của mình để sử dụng một không gian nhập vai.

00:18:23.000 --> 00:18:30.000
Không gian nhập vai là một loại vùng chứa đặc biệt cho phép ứng dụng của bạn hiển thị nội dung bên ngoài cửa sổ.

00:18:30.000 --> 00:18:35.000
Để làm điều này, chúng ta có thể thêm một ImmersiveSpace vào cảnh SwiftUI của chúng ta.

00:18:35.000 --> 00:18:40.000
Chúng tôi cũng sẽ thêm một công cụ sửa đổi .immersionStyle và đặt nó thành hỗn hợp.

00:18:40.000 --> 00:18:46.000
Bên trong ImmersiveSpace, chúng ta có thể sử dụng RealityView để đặt nội dung sẽ được neo.

00:18:46.000 --> 00:18:53.000
Để tìm hiểu thêm về Immersive Spaces, hãy xem phiên "Vượt ra ngoài cửa sổ với SwiftUI."

00:18:53.000 --> 00:18:59.000
Bên trong RealityView của chúng tôi, chúng tôi có thể sử dụng một thực thể neo làm vùng chứa cho cổng thông tin của mình.

00:18:59.000 --> 00:19:06.000
Chúng tôi khởi tạo một thực thể neo với đặc điểm kỹ thuật của loại bề mặt mà chúng tôi muốn neo nội dung của mình.

00:19:06.000 --> 00:19:13.000
Trong trường hợp của chúng tôi, chúng tôi đang tìm kiếm một bức tường thẳng đứng với kích thước tối thiểu là một mét x một mét.

00:19:13.000 --> 00:19:20.000
Khi tìm thấy một neo phù hợp với thông số kỹ thuật, RealityKit sẽ tự động đính kèm nội dung của chúng tôi vào tường.

00:19:20.000 --> 00:19:22.000
Và cuối cùng chúng ta đã hoàn thành.

00:19:22.000 --> 00:19:28.000
Khi chúng tôi chạy ứng dụng của mình, chúng tôi nhận được một cổng thông tin được gắn vào tường.

00:19:28.000 --> 00:19:37.000
Từ cổng thông tin và hạt đến neo và tệp đính kèm, RealityKit cung cấp nhiều tính năng cho phép bạn xây dựng trải nghiệm nhập vai.

00:19:37.000 --> 00:19:41.000
Hãy tóm tắt mọi thứ mà chúng ta đã xem qua trong phiên này.

00:19:41.000 --> 00:19:51.000
Tệp đính kèm trong RealityView cho phép bạn nhúng nội dung SwiftUI vào bên trong hệ thống phân cấp thực thể của mình để bạn có thể đặt các phần tử giao diện người dùng cùng với các phần tử 3D.

00:19:51.000 --> 00:20:00.000
VideoPlayerComponent, cổng thông tin và hiệu ứng hạt cho phép bạn thêm các yếu tố động để nâng cao cảnh của mình trong RealityKit.

00:20:00.000 --> 00:20:08.000
Cuối cùng, neo cho phép bạn gắn nội dung 3D vào các bề mặt trong thế giới thực như sàn hoặc tường của bạn.

00:20:08.000 --> 00:20:17.000
Phiên "Xây dựng trải nghiệm không gian với RealityKit" đi qua các khái niệm chính như thực thể, thành phần và RealityView.

00:20:17.000 --> 00:20:28.000
Phiên "Làm việc với nội dung Reality Composer Pro trong Xcode" sẽ đưa bạn qua quá trình xây dựng một ứng dụng nhập vai bằng Reality Composer Pro cùng với RealityKit.

00:20:28.000 --> 00:20:32.000
Tôi nóng lòng muốn xem tất cả những thứ bạn sẽ tạo ra bằng cách sử dụng các tính năng mới này trong RealityKit.

00:20:32.000 --> 00:20:34.000
Cảm ơn bạn đã xem.

00:20:34.000 --> 23:59:59.000
♪

