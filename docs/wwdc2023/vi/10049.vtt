WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:14.000
Ben: Xin chào, tôi là Ben Levine, một kỹ sư trong đội Core ML.

00:00:14.000 --> 00:00:19.000
Hôm nay, tôi sẽ nói về những gì mới khi tích hợp Core ML vào ứng dụng của bạn.

00:00:19.000 --> 00:00:23.000
Xây dựng trải nghiệm thông minh trong ứng dụng của bạn chưa bao giờ dễ dàng hơn thế.

00:00:23.000 --> 00:00:30.000
Xcode SDK cung cấp một nền tảng vững chắc để tận dụng và triển khai các tính năng hỗ trợ học máy.

00:00:30.000 --> 00:00:36.000
Một tập hợp các khung tên miền cụ thể cung cấp cho bạn quyền truy cập vào trí thông minh tích hợp thông qua các API đơn giản.

00:00:36.000 --> 00:00:42.000
Các khả năng mà họ cung cấp được cung cấp bởi các mô hình được đào tạo và tối ưu hóa bởi Apple.

00:00:42.000 --> 00:00:45.000
Những mô hình này được thực thi thông qua Core ML.

00:00:45.000 --> 00:00:50.000
Khung Core ML cung cấp công cụ để chạy các mô hình học máy trên thiết bị.

00:00:50.000 --> 00:00:55.000
Nó cho phép bạn dễ dàng triển khai các mô hình tùy chỉnh cho ứng dụng của mình.

00:00:55.000 --> 00:01:05.000
Nó tóm tắt các chi tiết phần cứng trong khi tận dụng khả năng tính toán hiệu suất cao của Apple silicon với sự trợ giúp từ dòng khung Accelerate và Metal.

00:01:05.000 --> 00:01:10.000
Nhiệm vụ của Core ML là giúp bạn tích hợp các mô hình học máy vào ứng dụng của mình.

00:01:10.000 --> 00:01:15.000
Năm nay, trọng tâm của chúng tôi đối với Core ML là hiệu suất và tính linh hoạt.

00:01:15.000 --> 00:01:21.000
Chúng tôi đã cải thiện quy trình làm việc, bề mặt API và cả công cụ suy luận cơ bản của chúng tôi.

00:01:21.000 --> 00:01:36.000
Trước khi nhảy vào quy trình làm việc và làm nổi bật các cơ hội mới để bạn tối ưu hóa tích hợp Core ML của mình, đây là ý tưởng về các lợi ích hiệu suất tiềm năng mà bạn có thể nhận được tự động chỉ bằng cách cập nhật lên hệ điều hành mới nhất.

00:01:36.000 --> 00:01:46.000
Khi so sánh thời gian dự đoán tương đối giữa iOS 16 và 17, bạn sẽ thấy rằng iOS 17 đơn giản là nhanh hơn đối với nhiều kiểu máy của bạn.

00:01:46.000 --> 00:01:54.000
Sự tăng tốc này trong công cụ suy luận đi kèm với hệ điều hành và không yêu cầu biên dịch lại các mô hình của bạn hoặc thực hiện bất kỳ thay đổi nào đối với mã của bạn.

00:01:54.000 --> 00:01:58.000
Điều tương tự cũng đúng với các nền tảng khác.

00:01:58.000 --> 00:02:02.000
Đương nhiên, số lượng tăng tốc phụ thuộc vào mô hình và phần cứng.

00:02:02.000 --> 00:02:08.000
Chuyển sang chương trình nghị sự, tôi sẽ bắt đầu với tổng quan về quy trình làm việc khi tích hợp Core ML vào ứng dụng của bạn.

00:02:08.000 --> 00:02:14.000
Trên đường đi, tôi sẽ làm nổi bật các cơ hội tối ưu hóa cho các phần khác nhau của quy trình làm việc.

00:02:14.000 --> 00:02:28.000
Sau đó, tôi sẽ tập trung vào tích hợp mô hình và thảo luận về các API và hành vi mới để tính khả dụng của tính toán, vòng đời mô hình và dự đoán không đồng bộ. Tôi sẽ bắt đầu với tổng quan về quy trình làm việc Core ML.

00:02:28.000 --> 00:02:32.000
Có hai giai đoạn để tích hợp Core ML vào ứng dụng của bạn.

00:02:32.000 --> 00:02:37.000
Đầu tiên là phát triển mô hình của bạn, và thứ hai là sử dụng mô hình đó trong ứng dụng của bạn.

00:02:37.000 --> 00:02:41.000
Để phát triển mô hình, bạn có một số lựa chọn.

00:02:41.000 --> 00:02:46.000
Một trong những cách thuận tiện nhất để phát triển mô hình của riêng bạn là sử dụng Create ML.

00:02:46.000 --> 00:02:55.000
Tạo ML cung cấp các mẫu khác nhau cho các tác vụ học máy phổ biến và có thể tận dụng các mô hình được tối ưu hóa cao được tích hợp trong hệ điều hành.

00:02:55.000 --> 00:03:00.000
Nó hướng dẫn bạn qua quy trình phát triển mô hình và cho phép bạn đánh giá kết quả một cách tương tác.

00:03:00.000 --> 00:03:05.000
Nếu bạn muốn tìm hiểu thêm, hãy xem video Tạo ML năm nay.

00:03:05.000 --> 00:03:12.000
Một cách khác để phát triển một mô hình là đào tạo một mô hình bằng cách sử dụng một trong một số khung học máy python.

00:03:12.000 --> 00:03:18.000
Sau đó, sử dụng gói python CoreMLTools để chuyển đổi sang định dạng mô hình Core ML.

00:03:18.000 --> 00:03:25.000
Cuối cùng, điều quan trọng là bạn đánh giá mô hình của mình cả về độ chính xác và hiệu suất trên phần cứng Apple.

00:03:25.000 --> 00:03:32.000
Sử dụng phản hồi từ đánh giá thường dẫn đến việc xem xét lại một số bước này để tối ưu hóa hơn nữa mô hình của bạn.

00:03:32.000 --> 00:03:36.000
Có rất nhiều cơ hội để tối ưu hóa trong các bước này.

00:03:36.000 --> 00:03:41.000
Đối với đào tạo, cách bạn thu thập và chọn dữ liệu đào tạo của mình rất quan trọng.

00:03:41.000 --> 00:03:47.000
Nó phải phù hợp với dữ liệu được chuyển đến mô hình khi nó được triển khai và trong tay người dùng của bạn.

00:03:47.000 --> 00:03:51.000
Kiến trúc mô hình bạn chọn cũng rất quan trọng.

00:03:51.000 --> 00:04:00.000
Bạn có thể đang khám phá nhiều lựa chọn, mỗi lựa chọn có sự cân bằng riêng giữa các yêu cầu dữ liệu đào tạo, độ chính xác, kích thước và hiệu suất.

00:04:00.000 --> 00:04:07.000
Nhiều sự đánh đổi trong số này có thể không được nhìn thấy đầy đủ tại thời điểm đào tạo và yêu cầu một vài lần lặp lại thông qua toàn bộ quá trình phát triển.

00:04:07.000 --> 00:04:10.000
Tiếp theo là chuyển đổi mô hình.

00:04:10.000 --> 00:04:18.000
Các công cụ Core ML cung cấp các tùy chọn khác nhau để giúp tối ưu hóa độ chính xác, dấu chân và chi phí tính toán của mô hình được chuyển đổi.

00:04:18.000 --> 00:04:25.000
Bạn có thể chọn các định dạng đầu vào và đầu ra phù hợp nhất với luồng dữ liệu của ứng dụng để tránh các bản sao không cần thiết.

00:04:25.000 --> 00:04:36.000
Nếu hình dạng đầu vào của bạn có thể thay đổi, bạn có thể chỉ định biến thể đó, thay vì chỉ chọn một hình dạng hoặc chuyển đổi giữa nhiều mô hình hình dạng cụ thể.

00:04:36.000 --> 00:04:41.000
Độ chính xác tính toán cũng có thể được thiết lập rõ ràng cho toàn bộ mô hình hoặc các hoạt động riêng lẻ.

00:04:41.000 --> 00:04:46.000
Cả float32 và float16 đều có sẵn.

00:04:46.000 --> 00:04:53.000
Ngoài độ chính xác của tính toán, bạn cũng có một số quyền kiểm soát cách các tham số mô hình của bạn được biểu diễn.

00:04:53.000 --> 00:05:00.000
CoreMLTools đi kèm với một bộ tiện ích để định lượng và nén trọng lượng sau tập luyện.

00:05:00.000 --> 00:05:06.000
Những tiện ích này có thể giúp bạn giảm đáng kể dấu chân của mô hình và cải thiện hiệu suất trên thiết bị.

00:05:06.000 --> 00:05:12.000
Tuy nhiên, để đạt được những lợi ích này, có một số đánh đổi về độ chính xác.

00:05:12.000 --> 00:05:20.000
Có một số công cụ mới để giúp bạn trong không gian này Có một mô-đun con tối ưu hóa mới trong gói CoreMLTools.

00:05:20.000 --> 00:05:28.000
Nó thống nhất và cập nhật các tiện ích nén sau đào tạo và thêm các tiện ích mở rộng đào tạo nhận biết lượng tử hóa mới cho PyTorch.

00:05:28.000 --> 00:05:35.000
Điều này cho phép bạn truy cập vào tối ưu hóa dựa trên dữ liệu để giúp duy trì độ chính xác cho các mô hình lượng tử hóa trong quá trình đào tạo.

00:05:35.000 --> 00:05:43.000
Điều này được kết hợp với các hoạt động mới hỗ trợ lượng tử hóa kích hoạt trong loại mô hình Chương trình ML của Core ML.

00:05:43.000 --> 00:05:50.000
Kiểm tra phiên năm nay về nén các mô hình học máy với Core ML để tìm hiểu thêm.

00:05:50.000 --> 00:05:52.000
Tiếp theo là đánh giá.

00:05:52.000 --> 00:06:00.000
Một lựa chọn để đánh giá mô hình của bạn là chạy dự đoán trên mô hình đã chuyển đổi trực tiếp từ mã python của bạn với CoreMLTools.

00:06:00.000 --> 00:06:11.000
Nó sẽ sử dụng cùng một ngăn xếp suy luận Core ML mà mã ứng dụng của bạn sẽ sử dụng và cho phép bạn nhanh chóng kiểm tra xem các lựa chọn của mình trong quá trình chuyển đổi mô hình ảnh hưởng như thế nào đến độ chính xác và hiệu suất của mô hình.

00:06:11.000 --> 00:06:18.000
Xcode cũng cung cấp một số công cụ hữu ích khi đánh giá và khám phá các mô hình của bạn.

00:06:18.000 --> 00:06:22.000
Xem trước mô hình có sẵn cho nhiều loại mô hình phổ biến.

00:06:22.000 --> 00:06:30.000
Điều này cho phép bạn cung cấp một số đầu vào mẫu cho mô hình và xem trước đầu ra dự đoán mà không cần phải viết bất kỳ mã nào.

00:06:30.000 --> 00:06:40.000
Báo cáo hiệu suất ML cốt lõi cung cấp cho bạn bảng phân tích hiệu suất tính toán mô hình cho thời gian tải, dự đoán và biên dịch trên bất kỳ thiết bị đính kèm nào.

00:06:40.000 --> 00:06:46.000
Lưu ý rằng điều này có thể hữu ích để đánh giá kiến trúc mô hình ngay cả trước khi bạn đã đào tạo chúng.

00:06:46.000 --> 00:06:52.000
Bây giờ, quay trở lại quy trình làm việc tổng thể, chủ đề tiếp theo là tích hợp mô hình.

00:06:52.000 --> 00:06:55.000
Tích hợp mô hình là một phần trong việc phát triển ứng dụng của bạn.

00:06:55.000 --> 00:07:04.000
Cũng giống như bất kỳ tài nguyên nào khác mà bạn sử dụng trong ứng dụng của mình, bạn muốn quản lý cẩn thận và tối ưu hóa cách bạn sử dụng mô hình Core ML của mình.

00:07:04.000 --> 00:07:06.000
Có ba bước trong tích hợp mô hình.

00:07:06.000 --> 00:07:09.000
Đầu tiên bạn viết mã ứng dụng để sử dụng mô hình.

00:07:09.000 --> 00:07:18.000
Bạn có mã cho nơi và thời điểm tải mô hình, cách chuẩn bị dữ liệu đầu vào của mô hình, đưa ra dự đoán và sử dụng kết quả.

00:07:18.000 --> 00:07:21.000
Sau đó bạn biên dịch mã này cùng với mô hình.

00:07:21.000 --> 00:07:27.000
Và thứ ba, bạn kiểm tra, chạy và lập hồ sơ mô hình đang chạy trong ứng dụng của mình.

00:07:27.000 --> 00:07:33.000
Khi nói đến hồ sơ, bạn có thể thấy các công cụ Core ML và Neural Engine hữu ích.

00:07:33.000 --> 00:07:39.000
Đây cũng là một quá trình thiết kế và tối ưu hóa lặp đi lặp lại cho đến khi bạn sẵn sàng giao hàng.

00:07:39.000 --> 00:07:44.000
Có một số bổ sung mới trong năm nay để tối ưu hóa việc tích hợp mô hình của bạn.

00:07:44.000 --> 00:07:46.000
Đầu tiên là tính toán tính khả dụng.

00:07:46.000 --> 00:07:54.000
Core ML được hỗ trợ trên tất cả các nền tảng của Apple và theo mặc định xem xét tất cả các tính toán có sẵn để tối ưu hóa việc thực thi của nó.

00:07:54.000 --> 00:07:59.000
Điều này bao gồm CPU, GPU và Neural Engine khi có sẵn.

00:07:59.000 --> 00:08:08.000
Tuy nhiên, các đặc tính hiệu suất và tính khả dụng của các thiết bị tính toán này khác nhau giữa phần cứng được hỗ trợ mà ứng dụng của bạn có thể chạy.

00:08:08.000 --> 00:08:15.000
Điều này có thể ảnh hưởng đến trải nghiệm của người dùng với các tính năng được hỗ trợ ML của bạn hoặc ảnh hưởng đến sự lựa chọn của bạn trong các mô hình và cấu hình.

00:08:15.000 --> 00:08:24.000
Ví dụ, một số kinh nghiệm có thể yêu cầu các mô hình chạy trên Động cơ thần kinh để đáp ứng các yêu cầu về hiệu suất hoặc công suất.

00:08:24.000 --> 00:08:29.000
Hiện tại có một API mới để kiểm tra thời gian chạy về tính khả dụng của thiết bị tính toán.

00:08:29.000 --> 00:08:39.000
MLComputeDevice enum nắm bắt loại thiết bị tính toán và các thuộc tính của thiết bị tính toán cụ thể trong giá trị liên quan của nó.

00:08:39.000 --> 00:08:47.000
Với thuộc tính availableComputeDevices trên MLModel, bạn có thể kiểm tra những thiết bị nào có sẵn cho Core ML.

00:08:47.000 --> 00:08:52.000
Ví dụ, mã này kiểm tra xem có sẵn Neural Engine hay không.

00:08:52.000 --> 00:09:00.000
Cụ thể hơn, nó kiểm tra xem bộ sưu tập của tất cả các thiết bị tính toán có sẵn có chứa một thiết bị có loại là Neural Engine hay không.

00:09:00.000 --> 00:09:04.000
Chủ đề tiếp theo để tích hợp mô hình là hiểu vòng đời mô hình.

00:09:04.000 --> 00:09:08.000
Tôi sẽ bắt đầu bằng cách xem xét các loại tài sản mô hình khác nhau.

00:09:08.000 --> 00:09:12.000
Có hai loại: mô hình nguồn và mô hình biên dịch.

00:09:12.000 --> 00:09:17.000
Mô hình nguồn có phần mở rộng tệp của MLModel hoặc MLPackage.

00:09:17.000 --> 00:09:21.000
Đó là một định dạng mở được thiết kế để xây dựng và chỉnh sửa.

00:09:21.000 --> 00:09:25.000
Mô hình được biên dịch có phần mở rộng tệp của MLModelC.

00:09:25.000 --> 00:09:28.000
Nó được thiết kế để truy cập thời gian chạy.

00:09:28.000 --> 00:09:37.000
Trong hầu hết các trường hợp, bạn thêm một mô hình nguồn vào mục tiêu ứng dụng của mình, sau đó Xcode biên dịch mô hình và đưa nó vào tài nguyên của ứng dụng.

00:09:37.000 --> 00:09:43.000
Trong thời gian chạy, để sử dụng mô hình của bạn, bạn khởi tạo một MLModel.

00:09:43.000 --> 00:09:49.000
Instantiation lấy một URL đến dạng biên dịch của nó và một cấu hình tùy chọn.

00:09:49.000 --> 00:10:00.000
MLModel kết quả đã tải tất cả các tài nguyên cần thiết để suy luận tối ưu dựa trên cấu hình được chỉ định và khả năng phần cứng dành riêng cho thiết bị.

00:10:00.000 --> 00:10:04.000
Đây là cái nhìn sâu hơn về những gì xảy ra trong quá trình tải này.

00:10:04.000 --> 00:10:12.000
Đầu tiên, Core ML kiểm tra bộ nhớ cache để xem liệu nó đã chuyên biệt hóa mô hình dựa trên cấu hình và thiết bị chưa.

00:10:12.000 --> 00:10:17.000
Nếu có, nó sẽ tải các tài nguyên cần thiết từ bộ nhớ cache và trả về.

00:10:17.000 --> 00:10:20.000
Đây được gọi là tải được lưu trong bộ nhớ cache.

00:10:20.000 --> 00:10:27.000
Nếu cấu hình không được tìm thấy trong bộ nhớ cache, nó sẽ kích hoạt một bản biên dịch chuyên dụng cho thiết bị cho nó.

00:10:27.000 --> 00:10:34.000
Khi quá trình này hoàn tất, nó sẽ thêm đầu ra vào bộ nhớ cache và kết thúc quá trình tải từ đó.

00:10:34.000 --> 00:10:37.000
Đây được gọi là tải không có bộ nhớ cache.

00:10:37.000 --> 00:10:42.000
Đối với một số mô hình nhất định, tải trọng không được lưu trong bộ nhớ cache có thể mất một khoảng thời gian đáng kể.

00:10:42.000 --> 00:10:50.000
Tuy nhiên, nó tập trung vào việc tối ưu hóa mô hình cho thiết bị và thực hiện các lần tải tiếp theo nhanh nhất có thể.

00:10:50.000 --> 00:10:58.000
Trong quá trình chuyên môn hóa thiết bị, Core ML trước tiên phân tích cú pháp mô hình và áp dụng các đường chuyền tối ưu hóa chung cho nó.

00:10:58.000 --> 00:11:06.000
Sau đó, nó phân đoạn chuỗi hoạt động cho các thiết bị tính toán cụ thể dựa trên hiệu suất ước tính và tính khả dụng của phần cứng.

00:11:06.000 --> 00:11:09.000
Phân đoạn này sau đó được lưu vào bộ nhớ cache.

00:11:09.000 --> 00:11:17.000
Bước cuối cùng là để mỗi phân đoạn trải qua quá trình biên dịch cụ thể của thiết bị tính toán cho thiết bị tính toán mà chúng được chỉ định.

00:11:17.000 --> 00:11:26.000
Bản tổng hợp này bao gồm các tối ưu hóa hơn nữa cho thiết bị tính toán cụ thể và xuất ra một tạo tác mà thiết bị tính toán có thể chạy.

00:11:26.000 --> 00:11:33.000
Sau khi hoàn thành, Core ML lưu trữ các tạo tác này để sử dụng cho các lần tải mô hình tiếp theo.

00:11:33.000 --> 00:11:38.000
Core ML lưu trữ các tài sản chuyên biệt trên đĩa.

00:11:38.000 --> 00:11:42.000
Chúng được gắn với đường dẫn và cấu hình của mô hình.

00:11:42.000 --> 00:11:48.000
Những tài sản này có nghĩa là tồn tại trong quá trình khởi chạy ứng dụng và khởi động lại thiết bị của bạn.

00:11:48.000 --> 00:11:59.000
Khi dung lượng đĩa trống của thiết bị bị cạn kiệt, đã có bản cập nhật hệ thống hoặc mô hình được biên dịch đã bị xóa hoặc sửa đổi, hệ điều hành sẽ xóa bộ nhớ cache.

00:11:59.000 --> 00:12:05.000
Nếu điều này xảy ra, lần tải mô hình tiếp theo sẽ thực hiện chuyên môn hóa thiết bị một lần nữa.

00:12:05.000 --> 00:12:13.000
Để tìm hiểu xem tải mô hình của bạn có va vào bộ nhớ cache hay không, bạn có thể theo dõi ứng dụng của mình bằng Core ML Instrument và xem sự kiện tải.

00:12:13.000 --> 00:12:23.000
Nếu nó có nhãn "chuẩn bị và lưu trữ", thì đó là một tải không được lưu trong bộ nhớ cache, vì vậy Core ML đã thực hiện chuyên môn hóa thiết bị và lưu trữ kết quả.

00:12:23.000 --> 00:12:30.000
Nếu sự kiện tải có nhãn "được lưu trong bộ nhớ cache", thì đó là một tải được lưu trong bộ nhớ cache và không phát sinh chuyên môn hóa thiết bị.

00:12:30.000 --> 00:12:34.000
Đây là sản phẩm mới đặc biệt dành cho các mô hình MLProgram.

00:12:34.000 --> 00:12:40.000
Các báo cáo hiệu suất ML cốt lõi cũng có thể cung cấp cho bạn khả năng hiển thị chi phí tải.

00:12:40.000 --> 00:12:45.000
Theo mặc định, nó hiển thị tải trung bình được lưu trong bộ nhớ cache.

00:12:45.000 --> 00:12:50.000
Bây giờ nó cũng có tùy chọn hiển thị thời gian tải không được lưu trong bộ nhớ cache.

00:12:50.000 --> 00:12:57.000
Vì việc tải một mô hình có thể tốn kém về độ trễ và bộ nhớ, đây là một số phương pháp hay nhất chung.

00:12:57.000 --> 00:13:01.000
Đầu tiên, không tải các mô hình trong quá trình khởi chạy ứng dụng của bạn trên chuỗi giao diện người dùng.

00:13:01.000 --> 00:13:08.000
Thay vào đó, hãy cân nhắc sử dụng API tải không đồng bộ hoặc lười biếng tải mô hình.

00:13:08.000 --> 00:13:18.000
Tiếp theo, giữ cho mô hình được tải nếu ứng dụng có thể sẽ chạy nhiều dự đoán liên tiếp, thay vì tải lại mô hình cho mỗi dự đoán trong chuỗi.

00:13:18.000 --> 00:13:23.000
Cuối cùng, bạn có thể dỡ mô hình nếu ứng dụng của bạn không sử dụng nó trong một thời gian.

00:13:23.000 --> 00:13:29.000
Điều này có thể giúp giảm bớt áp lực bộ nhớ và nhờ bộ nhớ đệm, các lần tải tiếp theo sẽ nhanh hơn.

00:13:29.000 --> 00:13:33.000
Khi mô hình của bạn được tải, đã đến lúc suy nghĩ về việc chạy các dự đoán với mô hình.

00:13:33.000 --> 00:13:38.000
Tôi sẽ nhảy vào bản demo để hiển thị các tùy chọn không đồng bộ mới.

00:13:38.000 --> 00:13:46.000
Để hiển thị API dự đoán không đồng bộ mới, tôi sẽ sử dụng một ứng dụng hiển thị thư viện hình ảnh và cho phép áp dụng các bộ lọc cho hình ảnh.

00:13:46.000 --> 00:13:55.000
Tôi sẽ tập trung vào bộ lọc tô màu sử dụng mô hình Core ML lấy hình ảnh thang độ xám làm đầu vào và xuất ra phiên bản màu của hình ảnh.

00:13:55.000 --> 00:13:58.000
Đây là một ví dụ về ứng dụng đang hoạt động.

00:13:58.000 --> 00:14:08.000
Nó bắt đầu bằng cách tải các hình ảnh gốc, ở thang độ xám, và sau đó khi tôi chọn chế độ Hình ảnh được tô màu, nó sẽ tô màu các hình ảnh bằng Core ML.

00:14:08.000 --> 00:14:15.000
Khi tôi cuộn xuống, mô hình chắc chắn đang hoạt động, nhưng nó chậm hơn một chút so với tôi mong đợi.

00:14:15.000 --> 00:14:24.000
Ngoài ra, nếu tôi cuộn xuống xa, tôi nhận thấy rằng phải mất khá nhiều thời gian để các hình ảnh được tô màu.

00:14:24.000 --> 00:14:30.000
Khi tôi cuộn lại, có vẻ như nó đang dành thời gian tô màu tất cả các hình ảnh trên đường đi.

00:14:30.000 --> 00:14:38.000
Nhưng trong mã SwiftUI của tôi, tôi đang sử dụng LazyVGrid để giữ hình ảnh, vì vậy nó sẽ hủy các tác vụ khi chế độ xem tắt màn hình.

00:14:38.000 --> 00:14:47.000
Hãy để tôi xem xét việc triển khai hiện tại của mình để cố gắng hiểu tại sao hiệu suất lại thiếu và cũng như tại sao nó không tôn trọng các nhiệm vụ bị hủy bỏ.

00:14:47.000 --> 00:14:50.000
Đây là việc thực hiện.

00:14:50.000 --> 00:14:58.000
Vì API dự đoán đồng bộ không an toàn cho luồng, ứng dụng phải đảm bảo rằng các dự đoán được chạy nối tiếp trên mô hình.

00:14:58.000 --> 00:15:06.000
Điều này đạt được bằng cách biến ColorizingService thành một diễn viên, điều này sẽ chỉ cho phép một cuộc gọi đến phương thức colorize tại một thời điểm.

00:15:06.000 --> 00:15:14.000
Diễn viên này sở hữu colorizerModel, là giao diện được tạo tự động được tạo ra cho mô hình đi kèm với ứng dụng.

00:15:14.000 --> 00:15:18.000
Phương pháp tô màu hiện đang thực hiện hai thao tác.

00:15:18.000 --> 00:15:24.000
Đầu tiên, nó chuẩn bị đầu vào cho mô hình, bao gồm thay đổi kích thước hình ảnh để phù hợp với kích thước đầu vào của mô hình.

00:15:24.000 --> 00:15:29.000
Sau đó, nó chạy đầu vào thông qua mô hình và nhận được đầu ra được tô màu.

00:15:29.000 --> 00:15:36.000
Tôi đã tiếp tục và ghi lại dấu vết Instruments của ứng dụng đang chạy với mẫu Core ML Instruments.

00:15:36.000 --> 00:15:44.000
Khi nhìn vào dấu vết của Dụng cụ, nó cho thấy rằng các dự đoán được chạy nối tiếp, điều này được đảm bảo bởi sự cô lập của diễn viên.

00:15:44.000 --> 00:15:52.000
Tuy nhiên, có những khoảng trống xung quanh mỗi dự đoán trước khi dự đoán tiếp theo được chạy, điều này góp phần vào việc thiếu hiệu suất.

00:15:52.000 --> 00:15:59.000
Đây là kết quả của việc cô lập diễn viên được bao bọc xung quanh không chỉ dự đoán mô hình mà còn cả việc chuẩn bị đầu vào.

00:15:59.000 --> 00:16:08.000
Một cải tiến sẽ là đánh dấu việc chuẩn bị đầu vào là một phương pháp không cô lập, vì vậy nó sẽ không chặn yêu cầu tô màu tiếp theo nhập vào diễn viên.

00:16:08.000 --> 00:16:15.000
Mặc dù điều này sẽ hữu ích, nhưng bản thân các dự đoán Core ML vẫn sẽ được tuần tự hóa, đó là nút cổ chai trong quá trình xử lý của tôi.

00:16:15.000 --> 00:16:23.000
Để tận dụng lợi thế của tính đồng thời cho bản thân các dự đoán Core ML, một tùy chọn tôi có thể xem xét là API dự đoán hàng loạt.

00:16:23.000 --> 00:16:27.000
Nó cần một loạt các đầu vào và chạy chúng qua mô hình.

00:16:27.000 --> 00:16:32.000
Dưới mui xe, Core ML sẽ tận dụng lợi thế của sự đồng thời khi có thể.

00:16:32.000 --> 00:16:35.000
Tạo một phiên bản hàng loạt của phương pháp tô màu khá đơn giản.

00:16:35.000 --> 00:16:43.000
Tuy nhiên, phần thách thức là tìm ra cách tôi sẽ thu thập các đầu vào thành một lô và chuyển chúng sang phương pháp này.

00:16:43.000 --> 00:16:49.000
Thực tế có nhiều khía cạnh của trường hợp sử dụng này khiến việc sử dụng API dự đoán hàng loạt trở nên khó khăn.

00:16:49.000 --> 00:16:54.000
API hàng loạt được sử dụng tốt nhất khi có một số lượng công việc đã biết phải được thực hiện.

00:16:54.000 --> 00:17:02.000
Trong trường hợp này, số lượng hình ảnh được xử lý không cố định mà là một chức năng của kích thước màn hình và số lượng cuộn được thực hiện.

00:17:02.000 --> 00:17:11.000
Tôi có thể tự chọn kích thước lô, nhưng tôi sẽ phải xử lý các trường hợp kích thước lô không được đáp ứng nhưng vẫn cần được xử lý.

00:17:11.000 --> 00:17:17.000
Ngoài ra, tôi sẽ có một trải nghiệm giao diện người dùng khác, nơi hình ảnh được tô màu theo lô.

00:17:17.000 --> 00:17:23.000
Cuối cùng, tôi sẽ không thể hủy một lô ngay cả khi người dùng cuộn ra khỏi nó.

00:17:23.000 --> 00:17:29.000
Vì những thách thức này, tôi muốn gắn bó với một API xử lý từng dự đoán một.

00:17:29.000 --> 00:17:33.000
Đây là nơi mà API dự đoán không đồng bộ mới có thể rất hữu ích.

00:17:33.000 --> 00:17:38.000
Nó an toàn với luồng và hoạt động tốt khi sử dụng Core ML cùng với Swift concurrency.

00:17:38.000 --> 00:17:45.000
Để chuyển sang thiết kế không đồng bộ cho mã, trước tiên tôi đã thay đổi phương pháp tô màu thành không đồng bộ.

00:17:45.000 --> 00:17:53.000
Sau đó tôi đã thêm từ khóa await trước cuộc gọi dự đoán, được yêu cầu để sử dụng phiên bản API không đồng bộ mới.

00:17:53.000 --> 00:17:57.000
Sau đó, tôi đã thay đổi ColorizingService thành một lớp học hơn là một diễn viên.

00:17:57.000 --> 00:18:00.000
Bằng cách đó, nhiều hình ảnh có thể được tô màu đồng thời.

00:18:00.000 --> 00:18:05.000
Cuối cùng, tôi đã thêm kiểm tra hủy vào phần đầu của phương pháp.

00:18:05.000 --> 00:18:16.000
API dự đoán không đồng bộ sẽ cố gắng hết sức để phản hồi việc hủy bỏ, đặc biệt là khi nhiều dự đoán được yêu cầu đồng thời, nhưng tốt nhất là bao gồm một kiểm tra bổ sung khi bắt đầu trong trường hợp này.

00:18:16.000 --> 00:18:23.000
Bằng cách đó, nó cũng tránh chuẩn bị đầu vào nếu nhiệm vụ bị hủy trước khi phương thức tô màu thậm chí được nhập.

00:18:23.000 --> 00:18:27.000
Bây giờ tôi sẽ thực hiện những thay đổi này và chạy lại ứng dụng.

00:18:27.000 --> 00:18:31.000
Cũng như trước đây, tôi sẽ đặt nó ở chế độ Tô màu.

00:18:31.000 --> 00:18:35.000
Tôi đã có thể thấy những hình ảnh đang được tô màu nhanh hơn nhiều.

00:18:35.000 --> 00:18:41.000
Và nếu tôi cuộn nhanh xuống dưới cùng, hình ảnh sẽ tải gần như ngay lập tức.

00:18:41.000 --> 00:18:55.000
Cuộn lên một chút, tôi có thể xác minh các hình ảnh đang được tô màu khi tôi cuộn lại, điều đó có nghĩa là các cuộc gọi tô màu đã bị hủy thành công lần đầu tiên khi tôi vuốt nhanh xuống dưới cùng.

00:18:55.000 --> 00:19:04.000
Khi nhìn vào một dấu vết sử dụng thiết kế không đồng bộ mới này, nó cho thấy các dự đoán đang được chạy đồng thời trên nhiều hình ảnh.

00:19:04.000 --> 00:19:08.000
Điều này được biểu thị bằng nhiều khoảng dự đoán xếp chồng lên nhau theo chiều dọc.

00:19:08.000 --> 00:19:16.000
Vì mô hình này chạy một phần trên Động cơ thần kinh, nó cũng có thể được quan sát thấy trong Dụng cụ Động cơ Thần kinh.

00:19:16.000 --> 00:19:26.000
Với việc triển khai ban đầu, tô màu các hình ảnh nối tiếp, việc tô màu chế độ xem ban đầu của hình ảnh mà không cần cuộn mất khoảng hai giây.

00:19:26.000 --> 00:19:35.000
Sau khi chuyển sang triển khai không đồng bộ, điều này tô màu đồng thời cho hình ảnh, thời gian đó đã bị cắt giảm một nửa xuống còn khoảng một giây.

00:19:35.000 --> 00:19:46.000
Vì vậy, nhìn chung, tôi đã có thể đạt được sự cải thiện gấp 2 lần trong tổng thông lượng bằng cách tận dụng API dự đoán không đồng bộ và tính đồng thời với mô hình Colorizer của mình.

00:19:46.000 --> 00:20:05.000
Tuy nhiên, điều quan trọng cần lưu ý là số tiền mà một mô hình và trường hợp sử dụng nhất định có thể được hưởng lợi từ thiết kế đồng thời phụ thuộc rất nhiều vào một số yếu tố, bao gồm hoạt động của mô hình, đơn vị tính toán và kết hợp phần cứng và các công việc khác mà các thiết bị tính toán có thể đang bận rộn.

00:20:05.000 --> 00:20:14.000
Ngoài ra, chương trình ML và các loại mô hình Đường ống sẽ cung cấp những cải tiến hiệu suất tốt nhất từ việc chạy dự đoán đồng thời.

00:20:14.000 --> 00:20:23.000
Nhìn chung, khi thêm đồng thời vào ứng dụng của bạn, bạn nên cẩn thận lập hồ sơ khối lượng công việc để đảm bảo rằng nó thực sự mang lại lợi ích cho trường hợp sử dụng của bạn.

00:20:23.000 --> 00:20:29.000
Một điều quan trọng khác cần lưu ý khi thêm đồng thời vào ứng dụng của bạn là việc sử dụng bộ nhớ.

00:20:29.000 --> 00:20:37.000
Có nhiều bộ đầu vào và đầu ra mô hình được tải đồng thời trong bộ nhớ có thể làm tăng đáng kể mức sử dụng bộ nhớ cao nhất của ứng dụng của bạn.

00:20:37.000 --> 00:20:44.000
Bạn có thể lập hồ sơ này bằng cách kết hợp Công cụ Core ML với Công cụ Phân bổ.

00:20:44.000 --> 00:20:53.000
Dấu vết cho thấy việc sử dụng bộ nhớ của ứng dụng của tôi đang tăng lên nhanh chóng khi tôi tải nhiều đầu vào vào bộ nhớ để chạy qua mô hình tạo màu.

00:20:53.000 --> 00:21:03.000
Một vấn đề tiềm ẩn là phương thức tô màu từ mã của tôi không có kiểm soát luồng, vì vậy số lượng hình ảnh được tô màu đồng thời không có giới hạn cố định.

00:21:03.000 --> 00:21:07.000
Đây có thể không phải là vấn đề nếu đầu vào và đầu ra của mô hình nhỏ.

00:21:07.000 --> 00:21:17.000
Tuy nhiên, nếu chúng lớn, thì việc có nhiều bộ đầu vào và đầu ra này trong bộ nhớ cùng một lúc có thể làm tăng đáng kể mức sử dụng bộ nhớ cao nhất của ứng dụng.

00:21:17.000 --> 00:21:24.000
Một cách để cải thiện điều này là thêm logic giới hạn số lượng dự đoán tối đa trên chuyến bay.

00:21:24.000 --> 00:21:32.000
Điều này sẽ dẫn đến ít đầu vào và đầu ra được tải đồng thời trong bộ nhớ hơn, điều này sẽ làm giảm mức sử dụng bộ nhớ cao nhất trong khi chạy dự đoán.

00:21:32.000 --> 00:21:41.000
Trong ví dụ này, nếu đã có hai mục đang được xử lý, nó sẽ trì hoãn các mục công việc mới cho đến khi mục trước đó hoàn thành.

00:21:41.000 --> 00:21:45.000
Chiến lược tốt nhất sẽ phụ thuộc vào trường hợp sử dụng của bạn.

00:21:45.000 --> 00:21:51.000
Ví dụ, khi truyền dữ liệu từ máy ảnh, bạn có thể chỉ muốn bỏ công việc thay vì trì hoãn nó.

00:21:51.000 --> 00:21:58.000
Bằng cách này, bạn tránh tích lũy khung hình và thực hiện công việc không còn phù hợp về mặt thời gian.

00:21:58.000 --> 00:22:04.000
Lùi lại một chút, đây là một số hướng dẫn chung về thời điểm sử dụng các API dự đoán khác nhau.

00:22:04.000 --> 00:22:15.000
Nếu bạn đang ở trong một ngữ cảnh đồng bộ và thời gian giữa mỗi đầu vào có sẵn là lớn so với độ trễ của mô hình, thì API dự đoán đồng bộ hóa hoạt động tốt.

00:22:15.000 --> 00:22:22.000
Nếu đầu vào của bạn có sẵn theo lô, thì API dự đoán hàng loạt là một sự phù hợp tự nhiên.

00:22:22.000 --> 00:22:32.000
Nếu bạn đang ở trong một ngữ cảnh không đồng bộ và có một lượng lớn đầu vào trở nên có sẵn riêng lẻ theo thời gian, đó là khi API không đồng bộ có thể hữu ích nhất.

00:22:32.000 --> 00:22:42.000
Để kết thúc, khi bạn chuyển qua quy trình làm việc Core ML, có rất nhiều cơ hội để tối ưu hóa trong cả quá trình phát triển mô hình và tích hợp mô hình.

00:22:42.000 --> 00:22:51.000
Các API tính khả dụng tính toán mới có thể giúp bạn đưa ra quyết định trong thời gian chạy dựa trên phần cứng nào có sẵn trên thiết bị.

00:22:51.000 --> 00:22:59.000
Hiểu được vòng đời của mô hình và hành vi bộ nhớ đệm có thể giúp bạn quyết định tốt nhất khi nào và ở đâu để tải và dỡ mô hình của mình.

00:22:59.000 --> 00:23:09.000
Và cuối cùng, API dự đoán không đồng bộ có thể giúp bạn tích hợp Core ML với mã Swift không đồng bộ khác và cũng cải thiện thông lượng bằng cách hỗ trợ các dự đoán đồng thời.

00:23:09.000 --> 23:59:59.000
Đây là Ben từ đội Core ML, và tôi không phải là AI.

