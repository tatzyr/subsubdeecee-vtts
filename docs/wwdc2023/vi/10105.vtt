WEBVTT

00:00:00.000 --> 00:00:11.000
Rob: Xin chào.

00:00:11.000 --> 00:00:20.000
Tôi là Rob Simutis từ nhóm phần mềm Máy ảnh, với Sebastian Medina từ nhóm Ảnh, và chào mừng đến với phiên của chúng tôi, "Tạo ra trải nghiệm máy ảnh nhạy hơn."

00:00:20.000 --> 00:00:28.000
Chúng tôi sẽ giới thiệu một loạt các API mạnh mẽ mới trong các lớp chụp AVFoundation và trong khung PhotoKit.

00:00:28.000 --> 00:00:31.000
Đầu tiên, chúng ta sẽ nói về việc xử lý ảnh hoãn lại.

00:00:31.000 --> 00:00:37.000
Sau đó, tôi sẽ chỉ ra cách bạn thực sự có thể "nắm bắt khoảnh khắc" với độ trễ màn trập bằng không.

00:00:37.000 --> 00:00:41.000
Thứ ba, tôi sẽ đề cập đến các API Responsive Capture mới của chúng tôi.

00:00:41.000 --> 00:00:47.000
Và cuối cùng, tôi sẽ đi qua một cách khác để phản hồi với các hiệu ứng video được cập nhật.

00:00:47.000 --> 00:01:02.000
Bắt đầu với iOS 13, bạn có thể sử dụng giá trị liệt kê Ưu tiên Chất lượng ảnh của AVCapturePhotoSetting để thay đổi khả năng phản hồi hoặc bạn có thể chụp và lấy lại ảnh đã xử lý nhanh như thế nào, sau đó có thể chụp ảnh tiếp theo.

00:01:02.000 --> 00:01:09.000
Ứng dụng của bạn có thể chọn trong số các giá trị liệt kê khác nhau để đạt được khả năng phản hồi phù hợp, nhưng nó ảnh hưởng đến chất lượng hình ảnh.

00:01:09.000 --> 00:01:13.000
Hoặc nếu bạn luôn muốn sử dụng giá trị chất lượng, bạn có thể ảnh hưởng đến thời gian chụp để chụp.

00:01:13.000 --> 00:01:26.000
Trong iOS 17, bạn vẫn có thể sử dụng API này, nhưng chúng tôi sẽ mang đến cho bạn các API mới, bổ sung để bạn có thể cải thiện cơ hội chụp được bức ảnh bạn muốn đồng thời có được những bức ảnh chất lượng cao hơn.

00:01:26.000 --> 00:01:29.000
Tôi sẽ hướng dẫn bạn qua ứng dụng này mà nhóm của tôi đã xây dựng cho phiên của chúng tôi.

00:01:29.000 --> 00:01:39.000
Bằng cách bật từng công tắc bật tắt thành "bật", chúng tôi có thể kích hoạt các tính năng mới trong năm nay và chúng tôi sẽ xây dựng từng khái niệm một để tạo ra trải nghiệm chụp ảnh nhạy bén hơn.

00:01:39.000 --> 00:01:43.000
Vì vậy, hãy bắt đầu di chuyển, bắt đầu với việc xử lý ảnh hoãn lại.

00:01:43.000 --> 00:01:54.000
Ngày nay, để có được những bức ảnh chất lượng cao nhất từ AVCapturePhotoOutput, bạn sử dụng giá trị liệt kê ưu tiên chất lượng ảnh là "chất lượng" trên cài đặt khi bạn chụp ảnh.

00:01:54.000 --> 00:02:00.000
Đối với các giá trị "cân bằng" và "chất lượng" của chúng tôi, điều này thường liên quan đến một số loại phản ứng tổng hợp nhiều khung hình và giảm tiếng ồn.

00:02:00.000 --> 00:02:05.000
Trên iPhone 11 Pro và các mẫu mới hơn, một trong những kỹ thuật tiên tiến nhất của chúng tôi được gọi là "Deep Fusion".

00:02:05.000 --> 00:02:09.000
Điều này mang lại chi tiết tuyệt vời, sắc nét trong các bức ảnh có độ phân giải cao.

00:02:09.000 --> 00:02:14.000
Trong cảnh quay Deep Fusion này, lông của con vẹt siêu sắc nét và thực sự nổi bật.

00:02:14.000 --> 00:02:16.000
Nhưng nó phải trả giá.

00:02:16.000 --> 00:02:22.000
Quá trình xử lý này phải hoàn tất trước khi yêu cầu chụp tiếp theo bắt đầu và có thể mất một thời gian để hoàn thành.

00:02:22.000 --> 00:02:23.000
Hãy nhìn vào một ví dụ thực tế.

00:02:23.000 --> 00:02:29.000
Tôi đang tập hợp một bài thuyết trình về cách nhóm phần mềm máy ảnh đến văn phòng để hoàn thành công việc của mình.

00:02:29.000 --> 00:02:34.000
Đây là đồng nghiệp Devin của tôi đang sử dụng công nghệ xe đạp mới nhất để đi vòng quanh Apple Park.

00:02:34.000 --> 00:02:41.000
Khi tôi nhấn, tôi đang đợi nút chụp hoàn thành việc quay từ một lần chụp trước khi tôi có thể chụp lần tiếp theo.

00:02:41.000 --> 00:02:44.000
Kết quả cuối cùng là những bức ảnh Deep Fusion tuyệt vời.

00:02:44.000 --> 00:02:46.000
Chỉ cần kiểm tra chi tiết bộ râu đó!

00:02:46.000 --> 00:02:52.000
Nhưng trong khi tôi đang gõ, quá trình xử lý chạy đồng bộ và thời gian chụp để bắn cảm thấy hơi chậm chạp.

00:02:52.000 --> 00:02:59.000
Vì vậy, tôi có thể đã có được một bức ảnh đẹp với chi tiết sắc nét, nhưng có lẽ không chính xác là bức ảnh tôi đang tìm kiếm.

00:02:59.000 --> 00:03:02.000
Hãy xem sơ đồ các sự kiện.

00:03:02.000 --> 00:03:10.000
Bạn gọi phương thức capturePhoto của AVCapturePhotoOutput với cài đặt của bạn và đại diện của bạn nhận được cuộc gọi lại tại các điểm khác nhau trong quy trình...

00:03:10.000 --> 00:03:13.000
Chẳng hạn như willBeginCapture cho các cài đặt đã được giải quyết.

00:03:13.000 --> 00:03:21.000
Ngăn xếp phần mềm máy ảnh lấy các khung hình từ cảm biến và sử dụng các kỹ thuật xử lý của chúng tôi để hợp nhất chúng thành hình ảnh Deep Fusion...

00:03:21.000 --> 00:03:26.000
Sau đó, nó gửi lại ảnh cho bạn thông qua cuộc gọi lại đại diện didFinishProcessingPhoto.

00:03:26.000 --> 00:03:32.000
Quá trình xử lý này phải hoàn tất trước khi lần chụp tiếp theo xảy ra và điều đó có thể mất một thời gian.

00:03:32.000 --> 00:03:41.000
Bạn thậm chí có thể gọi capturePhoto trước khi lệnh gọi lại didFinishProcessingPhoto kích hoạt, nhưng nó sẽ không bắt đầu cho đến khi quá trình xử lý ảnh trước đó hoàn tất.

00:03:41.000 --> 00:03:44.000
Với việc xử lý ảnh bị trì hoãn, dòng thời gian này bị thu hẹp.

00:03:44.000 --> 00:03:55.000
Bạn yêu cầu một bức ảnh, và, khi phù hợp, đường ống máy ảnh sẽ cung cấp một bức ảnh "proxy" được xử lý nhẹ thông qua một cuộc gọi lại đại diện didFinishCapturingDeferredPhotoProxy mới.

00:03:55.000 --> 00:03:59.000
Bạn lưu trữ ảnh proxy này vào thư viện dưới dạng trình giữ chỗ.

00:03:59.000 --> 00:04:02.000
Và bức ảnh tiếp theo có thể được chụp ngay lập tức.

00:04:02.000 --> 00:04:09.000
Hệ thống sẽ chạy quá trình xử lý sau để có được bức ảnh cuối cùng sau khi phiên máy ảnh bị loại bỏ.

00:04:09.000 --> 00:04:20.000
Vì vậy, bây giờ nếu tôi bật xử lý ảnh hoãn lại trong cài đặt ứng dụng của mình, phiên chụp sẽ tự cấu hình lại để cung cấp cho tôi ảnh proxy tại thời điểm chụp khi thích hợp.

00:04:20.000 --> 00:04:29.000
Và tôi có thể có được những bức ảnh sắc nét, chi tiết cao như trước đây, nhưng tôi có thể chụp nhiều hơn trong số chúng khi tôi đang ở trong thời điểm này bằng cách trì hoãn quá trình xử lý cuối cùng sang một thời gian sau.

00:04:29.000 --> 00:04:34.000
Bánh xe đẹp. Những chiếc xe đạp đó chắc chắn.

00:04:34.000 --> 00:04:39.000
Vậy là xong. Đó là một bức ảnh tuyệt vời cho bài thuyết trình của tôi, bộ râu và tất cả.

00:04:39.000 --> 00:04:44.000
Vì vậy, hãy xem xét tất cả các phần tương tác để cung cấp cho bạn một bức ảnh được xử lý hoãn lại.

00:04:44.000 --> 00:04:58.000
Là một khóa học bồi dưỡng ngắn gọn từ các bài thuyết trình WW trước đó, khi định cấu hình AVCaptureSession để chụp ảnh, bạn thêm AVCaptureDeviceInput với AVCaptureDevice, tức là máy ảnh, vào phiên.

00:04:58.000 --> 00:05:10.000
Sau đó, bạn thêm AVCapturePhotoOutput vào phiên của mình và bạn chọn một định dạng hoặc cài đặt trước phiên cụ thể, thường là cài đặt trước phiên "Ảnh" khi ứng dụng của bạn gọi capturePhoto trên photoOutput.

00:05:10.000 --> 00:05:18.000
Nếu đó là một loại ảnh phù hợp hơn với việc xử lý ảnh hoãn lại, chúng tôi sẽ gọi lại cho bạn với didFinishCapturing Deferred Photo Proxy.

00:05:18.000 --> 00:05:22.000
Từ đó, bạn gửi dữ liệu proxy đến thư viện ảnh.

00:05:22.000 --> 00:05:30.000
Vì vậy, những gì bạn có bây giờ trong thư viện của mình là một bức ảnh proxy, nhưng cuối cùng bạn sẽ muốn sử dụng hoặc chia sẻ hình ảnh cuối cùng.

00:05:30.000 --> 00:05:42.000
Quá trình xử lý ảnh cuối cùng xảy ra theo yêu cầu khi bạn yêu cầu dữ liệu hình ảnh trở lại từ thư viện hoặc trong nền khi hệ thống xác định rằng các điều kiện là tốt để làm như vậy, chẳng hạn như thiết bị không hoạt động.

00:05:42.000 --> 00:05:46.000
Và bây giờ tôi sẽ để đồng nghiệp Sebastian của tôi chỉ cho bạn cách mã hóa điều này.

00:05:46.000 --> 00:05:48.000
Đến với bạn, Sebastian.

00:05:48.000 --> 00:05:49.000
Sebastian: Cảm ơn, Rob.

00:05:49.000 --> 00:05:52.000
Xin chào, tên tôi là Sebastian Medina và tôi là một kỹ sư trong nhóm Ảnh.

00:05:52.000 --> 00:05:58.000
Hôm nay tôi sẽ xem xét việc chụp một hình ảnh được chụp gần đây thông qua PhotoKit để kích hoạt quá trình xử lý hoãn lại.

00:05:58.000 --> 00:06:05.000
Sau đó, tôi sẽ yêu cầu cùng một hình ảnh đó để hiển thị những gì mới trong việc nhận hình ảnh từ yêu cầu PHImageManager.

00:06:05.000 --> 00:06:13.000
Mặc dù, trước khi tôi bắt đầu xử lý tài sản thông qua PhotoKit, tôi cần đảm bảo rằng API Máy ảnh mới để xử lý hoãn lại được thiết lập.

00:06:13.000 --> 00:06:18.000
Điều này sẽ cho phép ứng dụng của tôi chấp nhận hình ảnh proxy ảnh bị trì hoãn, mà chúng tôi có thể gửi qua PhotoKit.

00:06:18.000 --> 00:06:22.000
Bây giờ, tôi sẽ tiếp tục và viết mã để tận dụng điều này.

00:06:22.000 --> 00:06:27.000
Ở đây, tôi đã thiết lập các đối tượng AVCapturePhotoOutput và AVCaptureSession.

00:06:27.000 --> 00:06:31.000
Bây giờ, tôi có thể bắt đầu cấu hình phiên của chúng ta.

00:06:31.000 --> 00:06:38.000
Trong trường hợp này, tôi muốn phiên có một cài đặt trước loại ảnh để chúng ta có thể tận dụng lợi thế của việc xử lý hoãn lại.

00:06:38.000 --> 00:06:44.000
Bây giờ tôi sẽ lấy thiết bị chụp để sau đó thiết lập đầu vào thiết bị.

00:06:44.000 --> 00:06:50.000
Sau đó, nếu có thể, tôi sẽ thêm đầu vào thiết bị.

00:06:50.000 --> 00:06:55.000
Tiếp theo, tôi sẽ muốn kiểm tra xem photoOutput có thể được thêm vào hay không.

00:06:55.000 --> 00:06:59.000
Và nếu vậy, hãy thêm nó.

00:06:59.000 --> 00:07:00.000
Bây giờ cho những thứ mới.

00:07:00.000 --> 00:07:10.000
Tôi sẽ kiểm tra xem giá trị autoDeferredPhotoDeliverySupported mới có đúng không để đảm bảo rằng tôi có thể gửi ảnh đã chụp thông qua quá trình xử lý hoãn lại.

00:07:10.000 --> 00:07:22.000
Nếu điều này được thông qua, thì tôi có thể tiếp tục và chọn tham gia giao ảnh hoãn lại mới với tài sản autoDeferredPhotoDeliveryEnabled.

00:07:22.000 --> 00:07:29.000
Kiểm tra và kích hoạt giao ảnh hoãn lại này là tất cả những gì bạn cần thêm vào mã Máy ảnh của mình để kích hoạt ảnh bị trì hoãn.

00:07:29.000 --> 00:07:34.000
Cuối cùng, tôi sẽ cam kết cấu hình phiên của chúng tôi.

00:07:34.000 --> 00:07:42.000
Vì vậy, bây giờ khi một cuộc gọi được thực hiện cho phương thức capturePhoto, cuộc gọi lại đại diện mà chúng tôi nhận được sẽ giữ một đối tượng proxy bị trì hoãn.

00:07:42.000 --> 00:07:50.000
Hãy xem một ví dụ về một trong những cuộc gọi lại này.

00:07:50.000 --> 00:08:01.000
Trong cuộc gọi lại chụp ảnh này, tôi đang nhận được các đối tượng AVCapturePhotoOutput và AVCaptureDeferredPhotoProxy từ Camera, có liên quan đến hình ảnh tôi đã chụp gần đây.

00:08:01.000 --> 00:08:11.000
Đầu tiên, thực hành tốt là đảm bảo rằng chúng ta đang nhận được các giá trị đầu ra ảnh phù hợp, vì vậy tôi sẽ kiểm tra giá trị của tham số lỗi.

00:08:11.000 --> 00:08:16.000
Bây giờ, chúng ta sẽ bắt đầu lưu hình ảnh của mình vào thư viện ảnh bằng PhotoKit.

00:08:16.000 --> 00:08:20.000
Tôi sẽ thực hiện các thay đổi trên PHPhotoLibrary được chia sẻ.

00:08:20.000 --> 00:08:26.000
Mặc dù, chỉ cần lưu ý, chỉ cần có quyền truy cập ghi vào thư viện ảnh.

00:08:26.000 --> 00:08:36.000
Sau đó tôi sẽ chụp dữ liệu ảnh từ đối tượng AVCaptureDeferredPhotoProxy.

00:08:36.000 --> 00:08:44.000
Vì tôi sẽ thực hiện các thay đổi đối với thư viện ảnh, tôi sẽ cần thiết lập phương thức phiên bản performChanges có liên quan.

00:08:44.000 --> 00:08:50.000
Giống như với việc tiết kiệm bất kỳ tài sản nào, tôi sẽ sử dụng PHAssetCreationRequest.

00:08:50.000 --> 00:08:56.000
Sau đó tôi sẽ gọi phương thức 'addResource' theo yêu cầu.

00:08:56.000 --> 00:09:01.000
Đối với các thông số, tôi sẽ sử dụng PHAssetResourceType '.photoProxy' mới.

00:09:01.000 --> 00:09:05.000
Đây là những gì yêu cầu PhotoKit kích hoạt quá trình xử lý hoãn lại trên hình ảnh.

00:09:05.000 --> 00:09:10.000
Sau đó, tôi có thể thêm dữ liệu hình ảnh proxy đã chụp trước đó.

00:09:10.000 --> 00:09:15.000
Và trong trường hợp này tôi sẽ không sử dụng bất kỳ lựa chọn nào.

00:09:15.000 --> 00:09:22.000
Ở đây, điều quan trọng cần biết là việc sử dụng loại tài nguyên mới này trên dữ liệu hình ảnh không yêu cầu xử lý hoãn lại sẽ dẫn đến lỗi.

00:09:22.000 --> 00:09:28.000
Và nói về lỗi, tôi sẽ tiếp tục và kiểm tra chúng trong trình xử lý hoàn thành.

00:09:28.000 --> 00:09:29.000
Và nó dễ dàng như vậy.

00:09:29.000 --> 00:09:35.000
Hãy tiếp tục và xử lý thành công và lỗi trong trình xử lý hoàn thành khi ứng dụng của bạn thấy phù hợp.

00:09:35.000 --> 00:09:38.000
Bây giờ, giả sử tôi muốn lấy lại Tài sản của chúng tôi.

00:09:38.000 --> 00:09:43.000
Tôi có thể đạt được điều đó thông qua yêu cầu PHImageManager, vì vậy tôi sẽ xem qua mã để làm điều đó.

00:09:43.000 --> 00:09:52.000
Đối với các thông số, tôi có một đối tượng PHAsset cho hình ảnh tôi vừa gửi qua PhotoKit, kích thước mục tiêu của hình ảnh sẽ được trả về và chế độ nội dung.

00:09:52.000 --> 00:10:05.000
Tôi sẽ lấy một đối tượng PHImageManager mặc định. sau đó, tôi có thể gọi tài sản hình ảnh yêu cầu cho phương thức requestImageForAsset bằng cách sử dụng đối tượng imageManager của chúng tôi.

00:10:05.000 --> 00:10:16.000
Đối với các thông số, tôi sẽ sử dụng nội dung mà tôi đã tìm nạp trước đó, kích thước mục tiêu, chế độ nội dung và trong trường hợp này, tôi sẽ không sử dụng bất kỳ tùy chọn nào.

00:10:16.000 --> 00:10:25.000
Bây giờ tôi có thể xử lý các cuộc gọi lại thông qua resultHandler trong đó resultImage là UIImage và thông tin là một từ điển liên quan đến hình ảnh.

00:10:25.000 --> 00:10:36.000
Hôm nay, cuộc gọi lại đầu tiên sẽ giữ hình ảnh có độ phân giải thấp hơn với khóa phân cách thông tin PHImageResultIsDegradedKey trong khi cuộc gọi lại hình ảnh cuối cùng sẽ không.

00:10:36.000 --> 00:10:41.000
Vì vậy, tôi có thể kiểm tra những thứ đó ở đây.

00:10:41.000 --> 00:10:53.000
Việc bổ sung việc tạo hình ảnh đã xử lý thông qua PhotoKit mang đến cơ hội tốt để đưa ra API mới của chúng tôi, điều này sẽ cho phép các nhà phát triển nhận được hình ảnh phụ từ phương thức requestImageForAsset.

00:10:53.000 --> 00:11:01.000
Vì có thể mất nhiều thời gian hơn để một hình ảnh trải qua quá trình xử lý hoãn lại để hoàn thiện, hình ảnh phụ mới này có thể được hiển thị trong thời gian chờ đợi.

00:11:01.000 --> 00:11:08.000
Để nhận được hình ảnh mới này, bạn sẽ sử dụng allowSecondaryDegradedImage mới trong PHImageRequestOptions.

00:11:08.000 --> 00:11:14.000
Hình ảnh mới này sẽ được nép mình giữa hai lần gọi lại hiện tại từ phương thức requestImageForAsset.

00:11:14.000 --> 00:11:23.000
Và từ điển thông tin liên quan đến hình ảnh sẽ có một mục nhập cho PHImageResultIsDegradedKey, được sử dụng ngày hôm nay trong lần gọi lại hình ảnh đầu tiên.

00:11:23.000 --> 00:11:29.000
Để minh họa rõ hơn những gì đang diễn ra, hôm nay, phương thức requestImageForAsset cung cấp hai hình ảnh.

00:11:29.000 --> 00:11:36.000
Đầu tiên là một hình ảnh chất lượng thấp phù hợp để hiển thị tạm thời trong khi nó chuẩn bị hình ảnh chất lượng cao cuối cùng.

00:11:36.000 --> 00:11:44.000
Với tùy chọn mới này, giữa hai tùy chọn hiện tại, bạn sẽ được cung cấp một hình ảnh mới, có độ phân giải cao hơn để hiển thị trong khi hình ảnh cuối cùng đang được xử lý.

00:11:44.000 --> 00:11:51.000
Hiển thị hình ảnh mới này sẽ mang lại cho người dùng của bạn trải nghiệm hình ảnh dễ chịu hơn trong khi chờ hình ảnh cuối cùng hoàn tất quá trình xử lý.

00:11:51.000 --> 00:11:55.000
Bây giờ, hãy viết mã để tận dụng điều này.

00:11:55.000 --> 00:12:02.000
Mặc dù, lần này, tôi sẽ tạo một đối tượng PHImageRequestOptions.

00:12:02.000 --> 00:12:06.000
Sau đó tôi sẽ đặt tùy chọn allowSecondaryDegradedImage mới là đúng.

00:12:06.000 --> 00:12:11.000
Bằng cách này, yêu cầu biết để gửi lại cuộc gọi lại hình ảnh phụ mới.

00:12:11.000 --> 00:12:22.000
Ở đây, tôi có thể tiếp tục và sử dụng lại phương thức requestImageForAsset mà tôi đã viết trước đây, mặc dù bây giờ tôi sẽ thêm đối tượng tùy chọn yêu cầu hình ảnh mà tôi vừa tạo.

00:12:22.000 --> 00:12:33.000
Vì từ điển thông tin hình ảnh phụ mới sẽ giữ giá trị thực cho PHImageResultIsDegradedKey, giống như lần gọi lại đầu tiên, tôi sẽ kiểm tra điều đó ở đây.

00:12:33.000 --> 00:12:37.000
Và đó là để nhận được hình ảnh đại diện thứ cấp mới.

00:12:37.000 --> 00:12:41.000
Hãy nhớ xử lý các hình ảnh trong trình xử lý kết quả để hỗ trợ tốt nhất cho ứng dụng của bạn.

00:12:41.000 --> 00:12:54.000
Bây giờ bạn đã biết cách thêm hình ảnh vào thư viện ảnh của mình với quá trình xử lý hoãn lại và cách nhận hình ảnh chất lượng cao hơn thứ cấp từ yêu cầu hình ảnh để hiển thị trong ứng dụng của bạn trong khi chờ hình ảnh cuối cùng hoàn tất quá trình xử lý.

00:12:54.000 --> 00:13:04.000
Những thay đổi này sẽ có sẵn bắt đầu với iOS 17, tvOS 17 và macOS Sonoma cùng với các thay đổi PhotoKit xử lý hoãn mới.

00:13:04.000 --> 00:13:10.000
Bây giờ, tôi sẽ giao lại cho Rob để biết thêm về các công cụ mới để tạo ra một Máy ảnh nhạy hơn.

00:13:10.000 --> 00:13:12.000
Rob: Tuyệt vời. Cảm ơn, Sebastian!

00:13:12.000 --> 00:13:17.000
Hãy đi vào chi tiết tốt để đảm bảo bạn có trải nghiệm tuyệt vời với việc xử lý ảnh hoãn lại.

00:13:17.000 --> 00:13:19.000
Chúng ta sẽ bắt đầu với thư viện ảnh.

00:13:19.000 --> 00:13:31.000
Để sử dụng xử lý ảnh bị trì hoãn, bạn sẽ cần có quyền ghi vào thư viện ảnh để lưu trữ ảnh proxy và quyền đọc nếu ứng dụng của bạn cần hiển thị ảnh cuối cùng hoặc muốn sửa đổi nó theo bất kỳ cách nào.

00:13:31.000 --> 00:13:38.000
Nhưng hãy nhớ rằng, bạn chỉ nên yêu cầu quyền truy cập vào thư viện nhỏ nhất khi cần thiết từ khách hàng của mình để duy trì sự riêng tư và tin tưởng nhất thay mặt họ.

00:13:38.000 --> 00:13:46.000
Và, chúng tôi đặc biệt khuyên bạn nên một khi bạn nhận được proxy, bạn sẽ đưa fileDataRepresentation của nó vào thư viện càng nhanh càng tốt.

00:13:46.000 --> 00:13:51.000
Khi ứng dụng của bạn được nền, bạn có một khoảng thời gian giới hạn để chạy trước khi hệ thống tạm dừng nó.

00:13:51.000 --> 00:13:58.000
Nếu áp lực bộ nhớ trở nên quá lớn, ứng dụng của bạn có thể bị hệ thống tự động buộc phải bỏ trong cửa sổ nền đó.

00:13:58.000 --> 00:14:05.000
Đưa proxy vào thư viện càng nhanh càng tốt đảm bảo giảm thiểu khả năng mất dữ liệu cho khách hàng của bạn.

00:14:05.000 --> 00:14:22.000
Tiếp theo, nếu bạn thường thực hiện các thay đổi đối với bộ đệm pixel của ảnh như áp dụng bộ lọc hoặc nếu bạn thực hiện thay đổi đối với siêu dữ liệu hoặc các thuộc tính khác của AVCapturePhoto bằng cách sử dụng AVCapturePhoto File Data Representation Customizer, những điều này sẽ không có hiệu lực đối với ảnh đã hoàn thiện trong thư viện sau khi quá

00:14:22.000 --> 00:14:28.000
Bạn sẽ cần làm điều này sau khi điều chỉnh ảnh bằng cách sử dụng PhotoKit APIs.

00:14:28.000 --> 00:14:34.000
Ngoài ra, mã của bạn cần có khả năng xử lý cả proxy hoãn lại và ảnh không hoãn lại trong cùng một phiên.

00:14:34.000 --> 00:14:39.000
Điều này là do không phải tất cả các bức ảnh đều có ý nghĩa để xử lý với các bước bổ sung cần thiết.

00:14:39.000 --> 00:14:50.000
Ví dụ, chụp flash được chụp theo giá trị liệt kê ưu tiên chất lượng ảnh "chất lượng" không được xử lý theo cách có lợi từ việc tiết kiệm từ ảnh này sang ảnh khác như ảnh Deep Fusion.

00:14:50.000 --> 00:14:55.000
Bạn cũng có thể nhận thấy rằng không có thuộc tính chọn tham gia hoặc chọn không tham gia trên AVCapturePhotoSettings.

00:14:55.000 --> 00:14:58.000
Đó là bởi vì việc xử lý ảnh bị trì hoãn là tự động.

00:14:58.000 --> 00:15:05.000
Nếu bạn chọn tham gia và đường ống máy ảnh sẽ chụp một bức ảnh yêu cầu thời gian xử lý lâu hơn, nó sẽ gửi lại cho bạn một proxy.

00:15:05.000 --> 00:15:11.000
Nếu nó không phù hợp, nó sẽ gửi cho bạn bức ảnh cuối cùng, vì vậy không cần phải chọn tham gia hoặc chọn không tham gia trên cơ sở mỗi lần chụp.

00:15:11.000 --> 00:15:19.000
Bạn chỉ cần nói với AVCapturePhotoOutput rằng bạn muốn isAutoDeferredPhotoProcessingEnabled là true trước khi bạn bắt đầu phiên chụp.

00:15:19.000 --> 00:15:22.000
Cuối cùng, hãy nói về trải nghiệm người dùng.

00:15:22.000 --> 00:15:31.000
Xử lý ảnh bị trì hoãn cung cấp chất lượng hình ảnh tốt nhất của chúng tôi với thời gian chụp nhanh, nhưng điều đó chỉ trì hoãn quá trình xử lý cuối cùng cho đến một thời điểm sau đó.

00:15:31.000 --> 00:15:42.000
Nếu ứng dụng của bạn là ứng dụng mà người dùng có thể muốn hình ảnh ngay lập tức để chia sẻ hoặc chỉnh sửa và họ không quan tâm đến những bức ảnh chất lượng cao nhất mà chúng tôi cung cấp, thì có thể tránh sử dụng xử lý ảnh bị trì hoãn.

00:15:42.000 --> 00:15:49.000
Tính năng này có sẵn bắt đầu từ iPhone 11 Pro và 11 Pro Max và các iPhone mới hơn.

00:15:49.000 --> 00:15:57.000
Và đây là một số video liên quan tuyệt vời về cách làm việc với AVCapturePhotoOutput và xử lý quyền thư viện.

00:15:57.000 --> 00:16:03.000
Và bây giờ, hãy chuyển sang Zero Shutter Lag và nói về trượt ván.

00:16:03.000 --> 00:16:10.000
Đối với bài thuyết trình sắp tới của tôi về phương thức vận chuyển của nhóm phần mềm máy ảnh, chúng tôi đã đến một công viên trượt băng để lấy một số cảnh quay.

00:16:10.000 --> 00:16:20.000
Tôi đang quay phim đồng nghiệp của mình bằng Chế độ hành động trên iPhone 14 Pro và tôi cũng muốn có một số cảnh quay hành động anh hùng chất lượng cao cho các trang trình bày của mình.

00:16:20.000 --> 00:16:25.000
Nhưng, cảnh báo spoiler, tôi sẽ không trượt ván.

00:16:25.000 --> 00:16:29.000
Tôi nhấn vào nút chụp để chụp ảnh đồng nghiệp của tôi, Tomo, bắt không khí.

00:16:29.000 --> 00:16:35.000
Khi tôi đến thư viện ảnh để kiểm tra bức ảnh, đây là những gì tôi nhận được.

00:16:35.000 --> 00:16:40.000
Tôi đã nhấn nút chụp khi anh ấy đang ở độ cao của cú nhảy, nhưng bức ảnh là hạ cánh của anh ấy.

00:16:40.000 --> 00:16:42.000
Nó không chính xác là những gì tôi muốn.

00:16:42.000 --> 00:16:46.000
Vậy chuyện gì đã xảy ra vậy? Độ trễ màn trập.

00:16:46.000 --> 00:16:49.000
Độ trễ màn trập đã xảy ra.

00:16:49.000 --> 00:16:58.000
Bạn có thể nghĩ về "đệp màn trập" là độ trễ từ khi bạn yêu cầu chụp để đọc ra một hoặc nhiều khung hình từ cảm biến để hợp nhất thành ảnh và giao nó cho bạn.

00:16:58.000 --> 00:17:04.000
Ở đây, thời gian đang đi từ trái sang phải, trái là các khung cũ hơn và bên phải là các khung mới hơn.

00:17:04.000 --> 00:17:07.000
Giả sử khung năm là những gì có trong kính ngắm máy ảnh của bạn.

00:17:07.000 --> 00:17:17.000
Hôm nay, khi bạn gọi capturePhoto:with settings on an AVCapturePhotoOutput, đường ống máy ảnh bắt đầu lấy khung hình từ cảm biến và áp dụng các kỹ thuật xử lý của chúng tôi.

00:17:17.000 --> 00:17:22.000
Nhưng khung của các khung hình được chụp bắt đầu sau khi chạm xuống, sau khung năm.

00:17:22.000 --> 00:17:26.000
Những gì bạn nhận được là một bức ảnh dựa trên các khung từ sáu đến chín, hoặc thậm chí muộn hơn.

00:17:26.000 --> 00:17:31.000
Với tốc độ 30 khung hình mỗi giây, mỗi khung hình nằm trong kính ngắm trong 33 mili giây.

00:17:31.000 --> 00:17:35.000
Nghe có vẻ không nhiều, nhưng thực sự không mất nhiều thời gian để hành động kết thúc.

00:17:35.000 --> 00:17:40.000
Điều đó đủ lâu để Tomo hạ cánh, và tôi đã bỏ lỡ cảnh anh hùng đó.

00:17:40.000 --> 00:17:47.000
Với Zero Shutter Lag được bật, đường ống máy ảnh giữ một bộ đệm vòng quay của các khung hình từ quá khứ.

00:17:47.000 --> 00:18:03.000
Bây giờ, khung năm là những gì bạn nhìn thấy trong kính ngắm, bạn nhấn để chụp và đường ống máy ảnh thực hiện một chút du hành thời gian, lấy khung hình từ bộ đệm vòng và hợp nhất chúng lại với nhau và bạn có được bức ảnh bạn muốn.

00:18:03.000 --> 00:18:18.000
Vì vậy, bây giờ nếu tôi sử dụng nút chuyển đổi thứ hai trong ngăn cài đặt ứng dụng của mình để bật Zero Shutter Lag, khi Tomo bắt được không khí, khi tôi nhấn vào nút chụp, tôi sẽ có một trong những bức ảnh "anh hùng" mà tôi muốn cho bài thuyết trình của mình.

00:18:18.000 --> 00:18:24.000
Hãy nói về những gì bạn cần làm để có được Zero Shutter Lag trong ứng dụng của mình.

00:18:24.000 --> 00:18:27.000
Hoàn toàn không có gì!

00:18:27.000 --> 00:18:39.000
Chúng tôi đã bật Zero Shutter Lag trên các ứng dụng liên kết trên hoặc sau iOS 17 cho AVCaptureSessionPresets và AVCaptureDeviceFormats, nơi được hỗ trợ chất lượng ảnh cao nhất là đúng.

00:18:39.000 --> 00:18:49.000
Nhưng, nếu bạn thấy trong quá trình thử nghiệm rằng bạn không nhận được kết quả bạn muốn, bạn có thể đặt AVCapturePhotoOutput.isZeroShutter LagEnabled thành false để chọn không tham gia.

00:18:49.000 --> 00:19:00.000
Và bạn có thể xác minh xem photoOutput có hỗ trợ độ trễ màn trập bằng không cho cài đặt trước hoặc định dạng được định cấu hình hay không bằng cách kiểm tra xem isZeroShutterLagSupported có đúng không khi đầu ra được kết nối với phiên của bạn.

00:19:00.000 --> 00:19:17.000
Một số loại chụp ảnh tĩnh nhất định như chụp đèn flash, định cấu hình AVCaptureDevice để phơi sáng thủ công, chụp trong ngoặc và phân phối ảnh cấu thành, là các khung hình được đồng bộ hóa từ nhiều máy ảnh, không nhận được Zero Shutter Lag.

00:19:17.000 --> 00:19:30.000
Bởi vì đường ống máy ảnh đang di chuyển ngược thời gian để lấy khung hình từ bộ đệm vòng, người dùng có thể khiến máy ảnh rung vào ảnh nếu có độ trễ dài giữa cử chỉ bắt đầu chụp và khi bạn gửi đầu ra ảnh, Cài đặt ảnh.

00:19:30.000 --> 00:19:36.000
Vì vậy, bạn sẽ muốn giảm thiểu bất kỳ công việc nào bạn làm giữa sự kiện nhấn và lệnh gọi capturePhoto API trên đầu ra ảnh.

00:19:36.000 --> 00:19:44.000
Làm tròn các tính năng của chúng tôi để tạo ra trải nghiệm chụp ảnh nhạy hơn, bây giờ tôi sẽ đề cập đến các API Chụp đáp ứng.

00:19:44.000 --> 00:19:56.000
Đây là một nhóm API cho phép khách hàng của bạn chụp ảnh chồng chéo, ưu tiên thời gian chụp để chụp bằng cách điều chỉnh chất lượng ảnh và cũng đưa ra phản hồi giao diện người dùng tuyệt vời khi họ có thể chụp ảnh tiếp theo.

00:19:56.000 --> 00:19:59.000
Đầu tiên, API chính, chụp đáp ứng.

00:19:59.000 --> 00:20:05.000
Trở lại công viên trượt băng, với hai tính năng được bật trước đó, tôi có thể chụp khoảng hai bức ảnh mỗi giây.

00:20:05.000 --> 00:20:09.000
Chúng tôi đã làm chậm cảnh quay để giúp làm cho nó rõ ràng.

00:20:09.000 --> 00:20:18.000
Với hai khung hình mỗi giây, bạn không thể nhìn thấy nhiều hành động của Tomo trong không khí và đây là bức ảnh đẹp nhất mà tôi đã kết thúc.

00:20:18.000 --> 00:20:21.000
Khá tốt, nhưng hãy xem liệu chúng ta có thể làm tốt hơn không.

00:20:21.000 --> 00:20:26.000
Bây giờ tôi sẽ bật công tắc thứ 3 và thứ 4 để bật các tính năng Responsive Capture.

00:20:26.000 --> 00:20:30.000
Tôi sẽ xem xét Ưu tiên Chụp Nhanh một chút.

00:20:30.000 --> 00:20:32.000
Nhưng trước tiên, quay lại công viên!

00:20:32.000 --> 00:20:36.000
Và hãy thử lại lần nữa.

00:20:36.000 --> 00:20:44.000
Với khả năng chụp nhanh, tôi có thể chụp nhiều ảnh hơn trong cùng một khoảng thời gian, tăng cơ hội chụp đúng ảnh.

00:20:44.000 --> 00:20:47.000
Và có cảnh quay "anh hùng" để bắt đầu bài thuyết trình của tôi.

00:20:47.000 --> 00:20:50.000
Đội thực sự sẽ thích nó!

00:20:50.000 --> 00:21:05.000
Bạn có thể nghĩ đến một cuộc gọi đến AVCapturePhotoOutput.capturePhoto với phương pháp cài đặt là trải qua ba giai đoạn riêng biệt: chụp khung hình từ cảm biến, xử lý các khung hình đó đến hình ảnh không nén cuối cùng và sau đó mã hóa ảnh thành HEIC hoặc JPEG.

00:21:05.000 --> 00:21:20.000
Sau khi mã hóa xong, đầu ra ảnh sẽ gọi lại didFinishProcessingPhoto của đại diện của bạn hoặc nếu bạn đã chọn tham gia API xử lý ảnh bị trì hoãn, có lẽ didFinishCapturing Deferred Photo Proxy, nếu đó là một bức ảnh phù hợp.

00:21:20.000 --> 00:21:26.000
Nhưng một khi giai đoạn "chụp" hoàn tất và quá trình "xử lý" bắt đầu, về lý thuyết, đầu ra ảnh có thể bắt đầu một lần chụp khác.

00:21:26.000 --> 00:21:31.000
Và bây giờ, lý thuyết đó là thực tế và có sẵn cho ứng dụng của bạn.

00:21:31.000 --> 00:21:45.000
Bằng cách chọn tham gia API Chụp phản hồi chính, đầu ra ảnh sẽ chồng chéo lên các giai đoạn này để yêu cầu chụp ảnh mới có thể bắt đầu trong khi một yêu cầu khác đang trong giai đoạn xử lý, mang lại cho khách hàng của bạn những bức ảnh liên tiếp nhanh hơn và nhất quán hơn.

00:21:45.000 --> 00:21:57.000
Lưu ý rằng điều này sẽ làm tăng bộ nhớ cao nhất được sử dụng bởi đầu ra ảnh, vì vậy nếu ứng dụng của bạn cũng sử dụng nhiều bộ nhớ, nó sẽ gây áp lực lên hệ thống, trong trường hợp đó bạn có thể thích hoặc cần chọn không tham gia.

00:21:57.000 --> 00:22:02.000
Quay lại sơ đồ dòng thời gian của chúng tôi, tại đây, bạn chụp hai bức ảnh liên tiếp nhanh chóng.

00:22:02.000 --> 00:22:11.000
Đại diện của bạn sẽ được gọi lại cho willBeginCaptureFor resolvedSettings, và didFinishCaptureFor resolvedSettings for photo A.

00:22:11.000 --> 00:22:24.000
Nhưng sau đó thay vì nhận được một cuộc gọi lại Ảnh Xử lý didFinish cho Ảnh A, đó là bức ảnh được mã hóa và gửi cho bạn, bạn có thể nhận được willBeginCapture đầu tiên để giải quyết Cài đặt cho ảnh B.

00:22:24.000 --> 00:22:32.000
Hiện tại có hai yêu cầu ảnh trên chuyến bay, vì vậy bạn sẽ phải đảm bảo mã của mình xử lý đúng các cuộc gọi lại cho các bức ảnh xen kẽ.

00:22:32.000 --> 00:22:38.000
Để có được những ảnh chụp chồng chéo, đáp ứng đó, trước tiên hãy bật Zero Shutter Lag khi nó được hỗ trợ.

00:22:38.000 --> 00:22:42.000
Nó phải được bật để có được hỗ trợ chụp đáp ứng.

00:22:42.000 --> 00:22:53.000
Sau đó sử dụng AVCapturePhotoOutput isResponsiveCaptureSupported API để đảm bảo đầu ra ảnh hỗ trợ nó cho cài đặt trước hoặc định dạng, sau đó bật nó lên bằng cách cài đặt AVCapturePhotoOutput.

00:22:53.000 --> 00:22:56.000
.isResponsiveCaptureEnabled thành true.

00:22:56.000 --> 00:23:02.000
Trước đó, chúng tôi đã bật "ưu tiên chụp nhanh", vì vậy tôi sẽ xem xét ngắn gọn điều đó ngay bây giờ.

00:23:02.000 --> 00:23:17.000
Khi nó được bật cho đầu ra ảnh, nó sẽ phát hiện khi nhiều lần chụp được chụp trong một khoảng thời gian ngắn và để đáp lại, sẽ điều chỉnh chất lượng ảnh từ cài đặt chất lượng cao nhất sang cài đặt chất lượng "cân bằng" hơn để duy trì thời gian chụp để chụp.

00:23:17.000 --> 00:23:22.000
Nhưng, vì điều này có thể ảnh hưởng đến chất lượng ảnh, nó bị tắt theo mặc định.

00:23:22.000 --> 00:23:26.000
Trong ngăn Cài đặt của Camera.app, điều này được gọi là "Ưu tiên chụp nhanh hơn".

00:23:26.000 --> 00:23:38.000
Chúng tôi đã chọn bật nó theo mặc định cho Camera.app vì chúng tôi nghĩ rằng thời gian chụp liên tục quan trọng hơn theo mặc định, nhưng bạn có thể chọn khác cho ứng dụng của mình và khách hàng của mình.

00:23:38.000 --> 00:23:53.000
Như bạn có thể mong đợi bây giờ, bạn có thể kiểm tra thuộc tính "có hỗ trợ ưu tiên chụp nhanh" trên đầu ra ảnh khi nó được hỗ trợ và khi có, bạn có thể đặt "đang bật ưu tiên chụp nhanh" thành đúng nếu bạn hoặc khách hàng của bạn muốn sử dụng tính năng này.

00:23:53.000 --> 00:23:57.000
Bây giờ, hãy trò chuyện về việc quản lý trạng thái nút và giao diện.

00:23:57.000 --> 00:24:06.000
Đầu ra ảnh có thể đưa ra các chỉ báo về thời điểm nó sẵn sàng để bắt đầu lần chụp tiếp theo hoặc khi nó đang xử lý và bạn có thể cập nhật nút chụp ảnh của mình một cách thích hợp.

00:24:06.000 --> 00:24:11.000
Điều này được thực hiện thông qua một danh sách các giá trị được gọi là AVCapturePhotoOutput CaptureReadiness.

00:24:11.000 --> 00:24:21.000
Đầu ra ảnh có thể ở trạng thái "không chạy", "sẵn sàng" và ba trạng thái "chưa sẵn sàng": "Ngay lập tức", "đang chờ chụp" hoặc "đang chờ xử lý".

00:24:21.000 --> 00:24:33.000
Các liệt kê "chưa sẵn sàng" chỉ ra rằng nếu bạn gọi capturePhoto với cài đặt, bạn sẽ phải chịu thời gian chờ đợi lâu hơn giữa việc chụp và phân phối ảnh, làm tăng độ trễ màn trập mà tôi đã nói trước đây.

00:24:33.000 --> 00:24:40.000
Ứng dụng của bạn có thể lắng nghe sự thay đổi trạng thái này bằng cách sử dụng một lớp mới, AVCapturePhotoOutputReadinessCoordinator.

00:24:40.000 --> 00:24:45.000
Điều này thực hiện các cuộc gọi lại đến một đối tượng đại diện mà bạn cung cấp khi mức độ sẵn sàng của Đầu ra Ảnh thay đổi.

00:24:45.000 --> 00:24:52.000
Bạn có thể sử dụng lớp này ngay cả khi bạn không sử dụng Responsive Capture hoặc Fast Capture Prioritization APIs.

00:24:52.000 --> 00:25:01.000
Đây là cách bạn có thể truyền đạt tính khả dụng của màn trập và sửa đổi giao diện nút bằng cách sử dụng Điều phối viên Sẵn sàng và liệt kê Sẵn sàng.

00:25:01.000 --> 00:25:14.000
Ứng dụng cho phiên của chúng tôi tắt các sự kiện tương tác của người dùng trên nút chụp khi xử lý giá trị liệt kê "chưa sẵn sàng" để ngăn các yêu cầu bổ sung vô tình được xếp hàng bằng nhiều lần nhấn, dẫn đến độ trễ màn trập dài.

00:25:14.000 --> 00:25:24.000
Sau một lần nhấn và một capturePhoto với yêu cầu cài đặt đã được xếp hàng, trạng thái captureReadiness nằm giữa giá trị .ready và .notReadyMomentarily enum.

00:25:24.000 --> 00:25:28.000
Chụp đèn flash đạt trạng thái .notReadyWaitingForCapture.

00:25:28.000 --> 00:25:34.000
Cho đến khi đèn flash phát ra, đầu ra ảnh thậm chí còn không nhận được khung hình từ cảm biến, vì vậy nút bị mờ đi.

00:25:34.000 --> 00:25:49.000
Cuối cùng, nếu bạn chỉ sử dụng độ trễ màn trập bằng không và không có tính năng nào khác trong năm nay, Bạn có thể hiển thị một con quay trong khi giá trị enum .notReadyWaitingForProcessing là sự sẵn sàng hiện tại, vì việc chụp và xử lý của mỗi bức ảnh đang hoàn tất.

00:25:49.000 --> 00:25:53.000
Vì vậy, đây là cách bạn sử dụng điều phối viên sẵn sàng trong mã.

00:25:53.000 --> 00:26:02.000
Đầu tiên, tạo một điều phối viên sẵn sàng cho đầu ra ảnh và đặt một đối tượng đại diện thích hợp để nhận các cuộc gọi lại về trạng thái sẵn sàng.

00:26:02.000 --> 00:26:07.000
Sau đó, tại thời điểm mỗi lần chụp, hãy thiết lập cài đặt ảnh của bạn như bình thường.

00:26:07.000 --> 00:26:14.000
Sau đó, yêu cầu điều phối viên sẵn sàng bắt đầu theo dõi trạng thái sẵn sàng của yêu cầu chụp cho các cài đặt đó.

00:26:14.000 --> 00:26:18.000
Và sau đó gọi capturePhoto trên đầu ra ảnh.

00:26:18.000 --> 00:26:23.000
Điều phối viên sẵn sàng sau đó sẽ gọi lại đại diện captureReadinessDidChange.

00:26:23.000 --> 00:26:34.000
Bạn cập nhật trạng thái và giao diện của nút chụp dựa trên giá trị liệt kê sẵn sàng nhận được để cung cấp cho khách hàng của bạn phản hồi tốt nhất về thời điểm họ có thể chụp tiếp theo.

00:26:34.000 --> 00:26:47.000
Các API Responsive Capture và Fast Capture Prioritization có sẵn trên iPhone với chip A12 Bionic trở lên, và Điều phối viên Sẵn sàng có sẵn ở bất cứ nơi nào AVCapturePhotoOutput được hỗ trợ.

00:26:47.000 --> 00:26:56.000
Và bây giờ tôi đã bật tất cả các tính năng mới trong ứng dụng của chúng tôi, với trải nghiệm máy ảnh nhạy nhất có thể cũng mang lại những bức ảnh siêu sắc nét, chất lượng cao.

00:26:56.000 --> 00:27:00.000
Nhưng, bạn không cần phải sử dụng tất cả chúng để có được trải nghiệm được cải thiện.

00:27:00.000 --> 00:27:04.000
Bạn chỉ có thể sử dụng những cái phù hợp với ứng dụng của mình.

00:27:04.000 --> 00:27:07.000
Chúng tôi sẽ kết thúc phiên của mình hôm nay với các hiệu ứng video được cập nhật.

00:27:07.000 --> 00:27:19.000
Trước đây, Trung tâm điều khiển trên macOS đã cung cấp các tùy chọn cho các tính năng phát trực tuyến của máy ảnh như Sân khấu trung tâm, Chân dung và Ánh sáng phòng thu.

00:27:19.000 --> 00:27:25.000
Với macOS Sonoma, chúng tôi đã chuyển các hiệu ứng video ra khỏi Trung tâm điều khiển và vào menu riêng của nó.

00:27:25.000 --> 00:27:32.000
Bạn sẽ thấy bản xem trước của máy ảnh hoặc chia sẻ màn hình của mình và có thể bật Hiệu ứng Video như chế độ Chân dung và Studio Light.

00:27:32.000 --> 00:27:39.000
Các hiệu ứng Portrait và Studio Light hiện có thể điều chỉnh cường độ của chúng và Studio Light có sẵn trên nhiều thiết bị hơn.

00:27:39.000 --> 00:27:43.000
Và chúng ta có một loại hiệu ứng mới được gọi là "Phản ứng".

00:27:43.000 --> 00:27:52.000
Khi bạn đang thực hiện một cuộc gọi video, bạn có thể muốn bày tỏ rằng bạn yêu thích một ý tưởng hoặc giơ ngón tay cái lên về tin tốt, tất cả trong khi để loa tiếp tục mà không bị gián đoạn.

00:27:52.000 --> 00:27:58.000
Phản ứng kết hợp liền mạch video của bạn với bóng bay, hoa giấy và hơn thế nữa.

00:27:58.000 --> 00:28:09.000
Các phản ứng tuân theo mẫu hiệu ứng ánh sáng chân dung và phòng thu, trong đó chúng là tính năng máy ảnh cấp hệ thống, có sẵn ngay lập tức, mà không cần bất kỳ thay đổi mã nào trong ứng dụng của bạn.

00:28:09.000 --> 00:28:17.000
Để biết thêm chi tiết về hiệu ứng Portrait và Studio Light, hãy xem phiên năm 2021, "Có gì mới trong chụp ảnh."

00:28:17.000 --> 00:28:27.000
Chúng tôi có ba cách để hiển thị phản ứng trong luồng video Đầu tiên, bạn có thể nhấp vào hiệu ứng phản ứng ở ngăn dưới cùng trong menu Hiệu ứng Video mới trên macOS.

00:28:27.000 --> 00:28:39.000
Thứ hai, ứng dụng của bạn có thể gọi AVCaptureDevice.performEffect cho: một loại phản ứng. Ví dụ, có thể bạn có một bộ nút phản ứng trong một trong các chế độ xem ứng dụng của mình mà người tham gia có thể nhấp vào để thực hiện phản ứng.

00:28:39.000 --> 00:28:44.000
Và thứ ba, khi các phản ứng được kích hoạt, chúng có thể được gửi bằng cách thực hiện một cử chỉ.

00:28:44.000 --> 00:28:47.000
Hãy kiểm tra cái này.

00:28:47.000 --> 00:29:14.000
Bạn có thể giơ ngón tay cái lên, giơ ngón tay cái xuống, pháo hoa với hai ngón tay cái hướng lên, trái tim, bóng bay với một dấu hiệu chiến thắng, mưa với hai ngón tay cái hướng xuống, hoa giấy với hai dấu hiệu chiến thắng và yêu thích cá nhân của tôi, laser, sử dụng hai dấu hiệu của sừng.

00:29:14.000 --> 00:29:18.000
Này, đó là một loạt các hiệu ứng tuyệt vời.

00:29:18.000 --> 00:29:27.000
Bạn có thể kiểm tra hỗ trợ hiệu ứng phản ứng bằng cách xem thuộc tính reactionEffectsSupported trên AVCaptureDeviceFormat mà bạn muốn sử dụng trong phiên chụp của mình.

00:29:27.000 --> 00:29:36.000
Có những thuộc tính trên AVCaptureDevice mà bạn có thể đọc hoặc quan sát khóa-giá trị để biết khi nào nhận dạng cử chỉ được bật và khi nào hiệu ứng phản ứng đã được bật.

00:29:36.000 --> 00:29:42.000
Hãy nhớ rằng, vì những thứ này nằm dưới sự kiểm soát của người dùng, ứng dụng của bạn không thể bật hoặc tắt chúng.

00:29:42.000 --> 00:29:44.000
Trên iOS, đó là cùng một ý tưởng.

00:29:44.000 --> 00:29:51.000
Người tham gia vào Trung tâm điều khiển để bật hoặc tắt nhận dạng cử chỉ và bạn có thể quan sát giá trị chính khi điều này xảy ra.

00:29:51.000 --> 00:29:55.000
Tuy nhiên, để kích hoạt các hiệu ứng trong ứng dụng của bạn trên iOS, bạn sẽ cần thực hiện theo chương trình.

00:29:55.000 --> 00:29:59.000
Vì vậy, hãy xem qua cách bạn có thể làm điều đó, ngay bây giờ.

00:29:59.000 --> 00:30:07.000
Khi thuộc tính "canPerformReactionEffects" là đúng, việc gọi phương thức performEffect for reactionType sẽ hiển thị các phản ứng vào nguồn cấp dữ liệu video.

00:30:07.000 --> 00:30:10.000
Ứng dụng của bạn nên cung cấp các nút để kích hoạt các hiệu ứng.

00:30:10.000 --> 00:30:19.000
Các phản ứng đến thông qua cử chỉ có thể được hiển thị ở một vị trí khác trong video so với khi bạn gọi performEffect\ tùy thuộc vào tín hiệu nào được sử dụng để phát hiện.

00:30:19.000 --> 00:30:32.000
Chúng tôi có một enum mới được gọi là AVCaptureReactionType cho tất cả các hiệu ứng phản ứng khác nhau, chẳng hạn như ngón tay cái lên hoặc bóng bay mà AVCaptureDevice sẽ nhận ra trong phiên chụp và có thể hiển thị vào nội dung video.

00:30:32.000 --> 00:30:41.000
Và thuộc tính "AVCaptureDevice.availableReactionTypes" trả về một tập hợp AVCaptureReactionTypes dựa trên định dạng được định cấu hình hoặc cài đặt trước phiên.

00:30:41.000 --> 00:30:47.000
Những hiệu ứng này cũng có sẵn UIImages hệ thống tích hợp mà bạn có thể đặt trong chế độ xem của riêng mình.

00:30:47.000 --> 00:31:02.000
Bạn có thể lấy systemName cho một phản ứng từ một hàm mới AVCaptureReactionType.systemImageName nhận AVCaptureReactionType và trả về chuỗi thích hợp để sử dụng với hàm tạo UIImage systemName.

00:31:02.000 --> 00:31:10.000
Và chúng tôi có API để cho bạn biết khi nào các hiệu ứng phản ứng đang diễn ra, AVCaptureDevice.reactionEffectsInProgress có tên khéo léo.

00:31:10.000 --> 00:31:18.000
Khi người dùng thực hiện nhiều hiệu ứng phản ứng theo trình tự, chúng có thể chồng chéo lên nhau một thời gian ngắn, vì vậy điều này trả về một mảng các đối tượng trạng thái.

00:31:18.000 --> 00:31:22.000
Bạn có thể sử dụng quan sát Key-value để biết khi nào những điều này bắt đầu và kết thúc.

00:31:22.000 --> 00:31:33.000
Nếu bạn là một ứng dụng hội nghị thoại qua IP, bạn cũng có thể sử dụng thông tin này để gửi siêu dữ liệu về các hiệu ứng đến chế độ xem từ xa, đặc biệt khi những người gọi đó đã tắt video vì lý do băng thông.

00:31:33.000 --> 00:31:38.000
Ví dụ, bạn có thể hiển thị biểu tượng hiệu ứng trong giao diện người dùng của họ thay mặt cho người gọi khác.

00:31:38.000 --> 00:31:43.000
Kết xuất hoạt ảnh hiệu ứng cho luồng video có thể là một thách thức đối với bộ mã hóa video.

00:31:43.000 --> 00:31:49.000
Chúng làm tăng độ phức tạp của nội dung và nó có thể yêu cầu ngân sách tốc độ bit lớn hơn để mã hóa nó.

00:31:49.000 --> 00:31:57.000
Bằng cách quan sát Key-Value reactionEffectsInProgress, bạn có thể thực hiện các điều chỉnh bộ mã hóa trong khi kết xuất đang diễn ra.

00:31:57.000 --> 00:32:02.000
Nếu nó khả thi cho ứng dụng của bạn, bạn có thể tăng tốc độ bit của bộ mã hóa trong khi các hiệu ứng đang hiển thị.

00:32:02.000 --> 00:32:27.000
Hoặc nếu bạn đang sử dụng bộ mã hóa video có độ trễ thấp thông qua VideoToolbox và cài đặt MaxAllowedFrameQP VTCompressionPropertyKey, thì chúng tôi khuyến khích bạn chạy thử nghiệm trong ứng dụng của mình bằng cách sử dụng các cấu hình video khác nhau bao gồm độ phân giải, tốc độ khung hình và cấp tốc độ bit được

00:32:27.000 --> 00:32:35.000
Lưu ý rằng với giá trị MaxAllowedFrameQP thấp, tốc độ khung hình của các hiệu ứng có thể bị xâm phạm và bạn sẽ kết thúc với tốc độ khung hình video thấp.

00:32:35.000 --> 00:32:44.000
Phiên năm 2021 "Khám phá mã hóa video có độ trễ thấp với VideoToolbox" có nhiều thông tin tuyệt vời hơn khi làm việc với tính năng này.

00:32:44.000 --> 00:32:49.000
Bạn cũng nên biết rằng tốc độ khung hình video có thể thay đổi khi các hiệu ứng đang diễn ra.

00:32:49.000 --> 00:32:58.000
Ví dụ: nếu bạn đã định cấu hình AVCaptureSession của mình để chạy ở tốc độ 60 khung hình mỗi giây, bạn sẽ nhận được 60 khung hình mỗi giây trong khi các hiệu ứng không chạy.

00:32:58.000 --> 00:33:04.000
Nhưng trong khi các hiệu ứng đang được tiến hành, bạn có thể nhận được tốc độ khung hình khác nhau, chẳng hạn như 30 khung hình mỗi giây.

00:33:04.000 --> 00:33:11.000
Điều này tuân theo mô hình hiệu ứng Portrait và Studio Light trong đó tốc độ khung hình cuối có thể thấp hơn bạn đã chỉ định.

00:33:11.000 --> 00:33:22.000
Để xem tốc độ khung hình đó sẽ là bao nhiêu, hãy xem AVCaptureDeviceFormat.videoFrameRateRange ForReactionEffectsInProgress để biết định dạng bạn đang định cấu hình trên thiết bị.

00:33:22.000 --> 00:33:29.000
Như với các thuộc tính AVCaptureDeviceFormat khác, đây là thông tin cho ứng dụng của bạn, chứ không phải là thứ bạn có thể kiểm soát.

00:33:29.000 --> 00:33:35.000
Trên macOS và với các ứng dụng tvOS sử dụng Continuity Camera, hiệu ứng phản ứng luôn được bật.

00:33:35.000 --> 00:33:41.000
Trên hệ điều hành iOS và iPad, các ứng dụng có thể chọn tham gia thông qua các thay đổi đối với Info.plist của chúng.

00:33:41.000 --> 00:33:54.000
Bạn chọn tham gia bằng cách quảng cáo rằng bạn là danh mục ứng dụng VoIP trong mảng UIBackgroundModes của mình hoặc bằng cách thêm NSCameraReactionEffectsEnabled với giá trị CÓ.

00:33:54.000 --> 00:34:18.000
Hiệu ứng phản ứng và nhận dạng cử chỉ có sẵn trên iPhone và iPad với chip A14 trở lên, chẳng hạn như iPhone 12, Apple Silicon Macs và Intel Macs và Apple TV sử dụng các thiết bị Continuity Camera, màn hình Apple Studio được gắn vào USB-C iPad hoặc Apple Silicon Mac, và camera của bên thứ ba được gắn vào USB-C iPad hoặc

00:34:18.000 --> 00:34:23.000
Và điều đó kết thúc phiên của chúng tôi về trải nghiệm máy ảnh đáp ứng với các API mới trong năm nay.

00:34:23.000 --> 00:34:44.000
Chúng tôi đã nói về xử lý ảnh bị trì hoãn, độ trễ màn trập không và API chụp đáp ứng để cung cấp cho bạn những khả năng mới để tạo ra ứng dụng chụp ảnh phản hồi nhanh nhất với chất lượng hình ảnh được cải thiện và chúng tôi cũng đề cập đến cách người dùng của bạn thực sự có thể thể hiện bản thân với các hiệu ứng video được cập nhật, bao

00:34:44.000 --> 00:34:48.000
Tôi nóng lòng muốn xem bạn phản hồi như thế nào với tất cả các tính năng mới tuyệt vời.

00:34:48.000 --> 00:34:49.000
Cảm ơn vì đã xem.

00:34:49.000 --> 23:59:59.000
.

