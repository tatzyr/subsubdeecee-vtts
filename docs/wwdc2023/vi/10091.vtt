WEBVTT

00:00:00.000 --> 00:00:03.000
♪ Hip-hop nhạc cụ êm dịu ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:12.000
Omid Khalili: Xin chào! Tên tôi là Omid.

00:00:12.000 --> 00:00:25.000
Oliver và tôi là kỹ sư trong nhóm ARKit và chúng tôi rất vui mừng được xem xét các khái niệm - một số quen thuộc và một số mới - mà bạn sẽ cần biết khi đưa ứng dụng iOS AR của mình lên nền tảng mới của chúng tôi.

00:00:25.000 --> 00:00:35.000
ARKit đã được giới thiệu trên iOS vào năm 2017 và cùng với nó, chúng tôi đã giới thiệu ba khái niệm chính để xây dựng các ứng dụng thực tế tăng cường.

00:00:35.000 --> 00:00:42.000
Với tính năng theo dõi thế giới, ARKit có thể theo dõi vị trí thiết bị của bạn trên thế giới với sáu bậc tự do.

00:00:42.000 --> 00:00:48.000
Điều này cho phép neo nội dung ảo với vị trí và định hướng đến thế giới thực.

00:00:48.000 --> 00:00:52.000
Hiểu cảnh cung cấp cái nhìn sâu sắc về thế giới thực xung quanh bạn.

00:00:52.000 --> 00:01:02.000
Sử dụng kiến thức hình học và ngữ nghĩa được cung cấp, nội dung của bạn có thể được đặt một cách thông minh và tương tác thực tế với môi trường xung quanh.

00:01:02.000 --> 00:01:14.000
Cuối cùng, các công cụ kết xuất có thể đăng ký và tổng hợp chính xác nội dung ảo của bạn qua các hình ảnh đã chụp bằng cách sử dụng các biến đổi máy ảnh và nội tại do ARKit cung cấp.

00:01:14.000 --> 00:01:22.000
Ban đầu, chúng tôi bắt đầu với chế độ xem SceneKit để sử dụng các biến đổi máy ảnh của ARKit và hiển thị nội dung 3D trên iOS.

00:01:22.000 --> 00:01:34.000
Sau đó, chúng tôi đã giới thiệu RealityKit, đặt nền móng cho một công cụ có khả năng kết xuất dựa trên vật lý chân thực cao và mô phỏng đối tượng chính xác với môi trường xung quanh bạn.

00:01:34.000 --> 00:01:42.000
Để cho phép tính toán không gian, ARKit và RealityKit đã trưởng thành và được tích hợp sâu vào hệ điều hành.

00:01:42.000 --> 00:01:53.000
Ví dụ, theo dõi và Hiểu cảnh của ARKit hiện đang chạy dưới dạng dịch vụ hệ thống, sao lưu mọi thứ từ vị trí cửa sổ đến âm thanh không gian.

00:01:53.000 --> 00:01:59.000
Hệ thống đảm nhận các trách nhiệm từng thuộc về các ứng dụng.

00:01:59.000 --> 00:02:09.000
Camera truyền qua và thảm của bàn tay người dùng hiện đã được tích hợp sẵn, vì vậy ứng dụng của bạn nhận được những khả năng này miễn phí.

00:02:09.000 --> 00:02:20.000
Một khả năng tích hợp khác là bản đồ thế giới ARKit liên tục được duy trì bởi một dịch vụ hệ thống, vì vậy ứng dụng của bạn không cần phải làm điều đó nữa.

00:02:20.000 --> 00:02:29.000
Chúng tôi tin rằng điều này sẽ giải phóng bạn để tập trung vào việc xây dựng ứng dụng và nội dung tốt nhất có thể cho nền tảng này.

00:02:29.000 --> 00:02:35.000
Đây là một ví dụ thể hiện những khả năng này, cùng với những khả năng mới được giới thiệu với nền tảng này.

00:02:35.000 --> 00:02:47.000
Ví dụ, ARKit hiện cung cấp tính năng theo dõi bằng tay cho ứng dụng của bạn, cho phép mọi người tiếp cận và tương tác trực tiếp với nội dung ảo mà sau đó có thể tương tác với môi trường xung quanh.

00:02:47.000 --> 00:02:56.000
Để tận dụng tất cả các khả năng mới và trải nghiệm nhập vai mà nền tảng mới này cung cấp, bạn sẽ cần cập nhật trải nghiệm dựa trên iOS ARKit của mình.

00:02:56.000 --> 00:03:03.000
Đây là một cơ hội tuyệt vời để hình dung lại ứng dụng và trải nghiệm AR của bạn cho điện toán không gian.

00:03:03.000 --> 00:03:11.000
Là một phần của quá trình chuyển đổi này, bạn sẽ sử dụng các khái niệm quen thuộc mà chúng tôi đã giới thiệu với ARKit và RealityKit.

00:03:11.000 --> 00:03:18.000
Chúng tôi sẽ đề cập đến cách các khái niệm này được thực hiện, cách chúng phát triển và cách bạn có thể tận dụng chúng.

00:03:18.000 --> 00:03:20.000
Hãy bắt đầu nào!

00:03:20.000 --> 00:03:30.000
Đầu tiên, chúng tôi sẽ khám phá một số cách mới mà bạn có thể trình bày ứng dụng của mình cho điện toán không gian và giới thiệu các công cụ nội dung mới có sẵn cho bạn.

00:03:30.000 --> 00:03:38.000
Tiếp theo, chúng ta sẽ nói về Reality Kit, là công cụ để sử dụng để hiển thị và tương tác với nội dung của bạn.

00:03:38.000 --> 00:03:46.000
Chúng ta sẽ xem RealityView cho phép ứng dụng của bạn tận dụng tính toán không gian tương tự như ARView trên iOS như thế nào.

00:03:46.000 --> 00:03:53.000
Sau đó, chúng ta sẽ nói về những cách khác nhau mà ứng dụng của bạn có thể đưa nội dung vào môi trường xung quanh mọi người.

00:03:53.000 --> 00:04:00.000
Raycasting là thứ mà nhiều ứng dụng iOS sử dụng để đặt nội dung.

00:04:00.000 --> 00:04:09.000
Chúng tôi sẽ chỉ ra một ví dụ về cách kết hợp dữ liệu ARKit và RealityKit để kích hoạt raycasting cho điện toán không gian.

00:04:09.000 --> 00:04:19.000
Và cuối cùng, chúng ta sẽ xem xét các bản cập nhật cho ARKit và xem những cách mới để sử dụng các khái niệm quen thuộc từ iOS.

00:04:19.000 --> 00:04:25.000
Hãy chuẩn bị để di chuyển trải nghiệm của bạn cho máy tính không gian.

00:04:25.000 --> 00:04:32.000
Điện toán không gian cho phép bạn lấy trải nghiệm iOS AR của mình và mở rộng nó ra ngoài cửa sổ.

00:04:32.000 --> 00:04:41.000
Nền tảng này cung cấp những cách mới để trình bày ứng dụng của bạn mà bạn sẽ muốn xem xét khi bạn mang lại trải nghiệm iOS của mình.

00:04:41.000 --> 00:04:44.000
Đây là một ví dụ từ ứng dụng mẫu Hello World của chúng tôi.

00:04:44.000 --> 00:04:51.000
Bây giờ bạn có thể hiển thị giao diện người dùng, bao gồm cửa sổ và nội dung ba chiều, ở bất kỳ đâu xung quanh bạn.

00:04:51.000 --> 00:04:56.000
Theo mặc định, các ứng dụng trên nền tảng này khởi chạy vào Không gian chia sẻ.

00:04:56.000 --> 00:05:02.000
Không gian chia sẻ là nơi các ứng dụng tồn tại cạnh nhau, giống như nhiều ứng dụng trên máy tính để bàn Mac.

00:05:02.000 --> 00:05:08.000
Bên trong Không gian Chia sẻ, ứng dụng của bạn có thể mở một hoặc nhiều cửa sổ để hiển thị nội dung.

00:05:08.000 --> 00:05:13.000
Ngoài ra, ứng dụng của bạn có thể tạo ra một khối lượng ba chiều.

00:05:13.000 --> 00:05:24.000
Ví dụ: bây giờ bạn có thể hiển thị danh sách các trò chơi hội đồng có sẵn trong một cửa sổ, các quy tắc trong một cửa sổ khác và mở trò chơi đã chọn theo khối lượng riêng của nó.

00:05:24.000 --> 00:05:30.000
Trò chơi có thể được chơi trong khi vẫn mở cửa sổ Safari để đọc các chiến lược chiến thắng.

00:05:30.000 --> 00:05:39.000
Nội dung bạn thêm vào cửa sổ và âm lượng vẫn nằm trong giới hạn của nó để cho phép chia sẻ không gian với các ứng dụng khác.

00:05:39.000 --> 00:05:49.000
Trong một số trường hợp, bạn có thể muốn ứng dụng của mình kiểm soát nhiều hơn mức độ đắm chìm trong trải nghiệm của bạn - có thể để chơi một trò chơi tương tác với phòng của bạn.

00:05:49.000 --> 00:05:59.000
Đối với điều này, ứng dụng của bạn có thể mở một Không gian đầy đủ chuyên dụng, trong đó chỉ các cửa sổ, khối lượng và đối tượng 3D của ứng dụng của bạn xuất hiện.

00:05:59.000 --> 00:06:05.000
Khi ở trong không gian đầy đủ, ứng dụng của bạn có quyền truy cập vào nhiều tính năng hơn.

00:06:05.000 --> 00:06:17.000
Sử dụng các thực thể neo của RealityKit, bạn có thể nhắm mục tiêu và gắn các vật thể vào môi trường xung quanh như bàn, sàn nhà và thậm chí các bộ phận của bàn tay như lòng bàn tay hoặc cổ tay.

00:06:17.000 --> 00:06:22.000
Các thực thể neo hoạt động mà không cần sự cho phép của người dùng.

00:06:22.000 --> 00:06:26.000
Dữ liệu ARKit là thứ khác mà ứng dụng của bạn chỉ có thể truy cập trong Không gian đầy đủ.

00:06:26.000 --> 00:06:42.000
Với sự cho phép, ARKit sẽ cung cấp dữ liệu về các bề mặt trong thế giới thực, hình học cảnh và theo dõi bàn tay xương, mở rộng khả năng vật lý thực tế và tương tác tự nhiên của ứng dụng của bạn.

00:06:42.000 --> 00:06:47.000
Cửa sổ, âm lượng và khoảng trắng đều là các loại cảnh SwiftUI.

00:06:47.000 --> 00:06:50.000
Còn rất nhiều điều để bạn tìm hiểu về những điều này.

00:06:50.000 --> 00:06:55.000
Để bắt đầu, bạn có thể đến phiên được đề cập ở đây.

00:06:55.000 --> 00:07:03.000
Tiếp theo, hãy xem lại các bước chính cần thiết để chuẩn bị nội dung của bạn để đưa nó vào điện toán không gian.

00:07:03.000 --> 00:07:12.000
Trải nghiệm AR đáng nhớ trên iOS bắt đầu với nội dung 3D tuyệt vời; điều tương tự cũng đúng với trải nghiệm không gian trên nền tảng này.

00:07:12.000 --> 00:07:21.000
Và khi nói đến nội dung 3D, thật tuyệt khi dựa vào một tiêu chuẩn mở như Mô tả cảnh phổ quát, hoặc viết tắt là USD.

00:07:21.000 --> 00:07:31.000
USD đã được chứng minh sản xuất và quy mô từ những người sáng tạo ra tài sản đơn lẻ đến các hãng phim lớn làm việc trên các trò chơi và phim AAA.

00:07:31.000 --> 00:07:39.000
Apple đã sớm áp dụng USD, thêm nó vào nền tảng của chúng tôi vào năm 2017 và tăng cường hỗ trợ kể từ đó.

00:07:39.000 --> 00:07:44.000
Ngày nay, USD là trung tâm của nội dung 3D cho điện toán không gian.

00:07:44.000 --> 00:07:56.000
Với tài sản USD đã sẵn sàng, bạn có thể đưa chúng vào công cụ dành cho nhà phát triển mới của chúng tôi, Reality Composer Pro, để soạn, chỉnh sửa và xem trước nội dung 3D của bạn.

00:07:56.000 --> 00:08:03.000
Nếu bạn đang sử dụng CustomMaterials cho nội dung 3D của mình trên iOS, thì bạn sẽ cần xây dựng lại chúng bằng biểu đồ đổ bóng của nó.

00:08:03.000 --> 00:08:08.000
Bạn cũng có khả năng chỉnh sửa các thành phần RealityKit của mình trực tiếp thông qua giao diện người dùng.

00:08:08.000 --> 00:08:24.000
Và cuối cùng, bạn có thể nhập dự án Reality Composer Pro trực tiếp vào Xcode, cho phép bạn dễ dàng gói tất cả tài sản, tài liệu và thành phần tùy chỉnh USD vào dự án Xcode của mình.

00:08:24.000 --> 00:08:34.000
Chúng tôi có một số phiên tuyệt vời để giúp bạn tìm hiểu thêm về Reality Composer Pro và cách xây dựng các tài liệu tùy chỉnh của riêng bạn cho điện toán không gian.

00:08:34.000 --> 00:08:44.000
Bây giờ chúng ta đã thấy những cách khác nhau để trình bày ứng dụng của bạn, hãy cùng tìm hiểu thêm về các tính năng mà RealityView cung cấp khi bạn mang lại trải nghiệm của mình.

00:08:44.000 --> 00:08:48.000
Chúng tôi vừa thấy cách điện toán không gian cho phép các ứng dụng hiển thị nội dung trong không gian của bạn.

00:08:48.000 --> 00:08:55.000
Một trong những điểm khác biệt chính đến từ iOS là cách các yếu tố khác nhau có thể được trình bày cạnh nhau.

00:08:55.000 --> 00:09:03.000
Chú ý cách nội dung 3D và các yếu tố 2D của bạn có thể xuất hiện và hoạt động cùng nhau.

00:09:03.000 --> 00:09:08.000
Đến từ iOS, bạn sẽ sử dụng các khuôn khổ quen thuộc để tạo ra từng khuôn khổ này.

00:09:08.000 --> 00:09:15.000
Bạn sẽ sử dụng SwiftUI để xây dựng giao diện người dùng 2D tốt nhất và nhận các sự kiện cử chỉ hệ thống giống như trên iOS.

00:09:15.000 --> 00:09:21.000
Và bạn sẽ sử dụng RealityKit để hiển thị nội dung 3D của mình cho trải nghiệm không gian.

00:09:21.000 --> 00:09:34.000
Cách để giao tiếp với cả hai thứ này cùng một lúc là thông qua RealityView - một chế độ xem SwiftUI mới mà chúng tôi đang giới thiệu để đáp ứng nhu cầu độc đáo của điện toán không gian.

00:09:34.000 --> 00:09:45.000
RealityView thực sự kết nối SwiftUI và RealityKit, cho phép bạn kết hợp các yếu tố 2D và 3D và tạo ra trải nghiệm không gian đáng nhớ.

00:09:45.000 --> 00:09:52.000
Bạn sẽ sử dụng RealityView để giữ tất cả các thực thể mà bạn muốn hiển thị và tương tác.

00:09:52.000 --> 00:09:57.000
Bạn có thể nhận các sự kiện cử chỉ và kết nối chúng với các thực thể trong tầm nhìn của bạn để kiểm soát chúng.

00:09:57.000 --> 00:10:09.000
Và với quyền truy cập vào sự hiểu biết về cảnh của ARKit, bạn có thể cho phép mô phỏng thực tế với môi trường xung quanh mọi người và thậm chí cả bàn tay của họ bằng cách sử dụng các thành phần va chạm của RealityKit.

00:10:09.000 --> 00:10:20.000
Trước khi chúng ta xem xét cách sử dụng RealityKit chuyển từ iOS, hãy làm bồi dưỡng nhanh về cách làm việc với Hệ thống Thành phần Thực thể của RealityKit.

00:10:20.000 --> 00:10:27.000
Trong Hệ thống Thành phần Thực thể Bộ Thực tế, mỗi thực thể là một vùng chứa nội dung 3D.

00:10:27.000 --> 00:10:31.000
Các thành phần khác nhau được thêm vào một thực thể để xác định giao diện và hành vi của nó.

00:10:31.000 --> 00:10:41.000
Điều này có thể bao gồm một thành phần mô hình về cách nó sẽ hiển thị; một thành phần va chạm, về cách nó có thể va chạm với các thực thể khác; và nhiều hơn nữa.

00:10:41.000 --> 00:10:50.000
Bạn có thể sử dụng RealityComposer Pro để chuẩn bị các thành phần RealityKit như các thành phần va chạm và thêm chúng vào các thực thể của bạn.

00:10:50.000 --> 00:10:55.000
Các hệ thống chứa mã để hành động trên các thực thể có các thành phần cần thiết.

00:10:55.000 --> 00:11:05.000
Ví dụ, hệ thống cần thiết để hỗ trợ cử chỉ hoạt động trên các thực thể có CollisionComponent và InputTargetComponent.

00:11:05.000 --> 00:11:14.000
Rất nhiều khái niệm được RealityView sử dụng cho điện toán không gian chuyển từ ARView trên iOS.

00:11:14.000 --> 00:11:17.000
Hãy xem hai thứ này xếp chồng lên nhau như thế nào.

00:11:17.000 --> 00:11:24.000
Cả hai chế độ xem đều là vùng chứa nhận biết sự kiện để chứa các thực thể bạn muốn hiển thị trong ứng dụng của mình.

00:11:24.000 --> 00:11:30.000
Bạn có thể thêm Hỗ trợ Cử chỉ vào chế độ xem của mình để cho phép lựa chọn và tương tác với các thực thể.

00:11:30.000 --> 00:11:37.000
Với SwiftUI cho tính toán không gian, bạn có thể tiếp cận để chọn hoặc kéo các thực thể của mình.

00:11:37.000 --> 00:11:43.000
Cả ARView và RealityView đều cung cấp một bộ sưu tập các thực thể của bạn.

00:11:43.000 --> 00:11:46.000
ARView sử dụng một Cảnh cho việc này.

00:11:46.000 --> 00:11:50.000
RealityView có một Nội dung để thêm các thực thể của bạn vào.

00:11:50.000 --> 00:11:56.000
Bạn có thể thêm AnchorEntities vào chúng, cho phép bạn neo nội dung của mình vào thế giới thực.

00:11:56.000 --> 00:12:03.000
Trên cả hai nền tảng, bạn tạo một thực thể để tải mô hình nội dung của mình và một AnchorEntity để đặt nó.

00:12:03.000 --> 00:12:09.000
Một điểm khác biệt chính giữa các nền tảng là trong hành vi của các thực thể neo.

00:12:09.000 --> 00:12:21.000
ARView trên iOS sử dụng ARSession và ứng dụng của bạn phải nhận được quyền chạy các thuật toán hiểu cảnh cần thiết để các thực thể neo hoạt động.

00:12:21.000 --> 00:12:26.000
RealityView đang sử dụng Dịch vụ Hệ thống để kích hoạt anchorEntities.

00:12:26.000 --> 00:12:34.000
Điều này có nghĩa là trải nghiệm không gian có thể neo nội dung vào môi trường xung quanh bạn mà không cần sự cho phép.

00:12:34.000 --> 00:12:41.000
Các ứng dụng sử dụng phương pháp này không nhận được dữ liệu hiểu hoặc biến đổi cảnh cơ bản.

00:12:41.000 --> 00:12:50.000
Không có dữ liệu chuyển đổi cho ứng dụng của bạn để đặt nội dung có một số hàm ý mà Oliver sẽ nói về sau trong phần của anh ấy.

00:12:50.000 --> 00:13:01.000
Như chúng ta đã thấy, có rất nhiều khái niệm quen thuộc đến từ iOS, nhưng cũng có những khả năng mới mà RealityKit cung cấp cho điện toán không gian.

00:13:01.000 --> 00:13:12.000
Chúng tôi chỉ làm xước bề mặt của những gì có thể với RealityKit trên nền tảng mới này và bạn có thể muốn xem phiên bên dưới để theo dõi thêm.

00:13:12.000 --> 00:13:19.000
Bây giờ hãy đến Oliver, người sẽ nói nhiều hơn về RealityView và cách đưa nội dung của bạn vào từ iOS.

00:13:19.000 --> 00:13:20.000
Oliver Dunkley: Cảm ơn, Omid!

00:13:20.000 --> 00:13:26.000
Hãy tiếp tục bằng cách khám phá những cách khác nhau mà bạn có thể đưa nội dung hiện có của mình vào điện toán không gian.

00:13:26.000 --> 00:13:28.000
Hãy bắt đầu trong Không gian Chung.

00:13:28.000 --> 00:13:34.000
Chúng ta có thể thêm nội dung 3D vào cửa sổ hoặc âm lượng và sử dụng các cử chỉ hệ thống để tương tác với nó.

00:13:34.000 --> 00:13:39.000
Để hiển thị tài sản của bạn, bạn chỉ cần thêm chúng trực tiếp vào Nội dung của RealityView.

00:13:39.000 --> 00:13:46.000
Bạn làm điều này bằng cách tạo một thực thể để giữ thành phần mô hình của bạn và định vị nó bằng cách thiết lập thành phần biến đổi.

00:13:46.000 --> 00:13:51.000
Bạn cũng có thể thiết lập hỗ trợ cử chỉ để sửa đổi thành phần chuyển đổi.

00:13:51.000 --> 00:14:01.000
Lưu ý rằng tất cả các thực thể được thêm vào nội dung của chế độ xem tồn tại trong cùng một không gian so với nguồn gốc của không gian và do đó có thể tương tác với nhau.

00:14:01.000 --> 00:14:05.000
Trong Không gian Chung, nội dung không thể được neo vào môi trường xung quanh bạn.

00:14:05.000 --> 00:14:09.000
Hãy xem xét các lựa chọn của chúng tôi nếu chúng tôi chuyển ứng dụng của mình sang Không gian đầy đủ.

00:14:09.000 --> 00:14:16.000
Một trong những điểm khác biệt chính đến từ Không gian chia sẻ là các ứng dụng hiện có thể neo thêm nội dung vào môi trường xung quanh mọi người.

00:14:16.000 --> 00:14:19.000
Neo nội dung của bạn ở đây có thể xảy ra theo hai cách.

00:14:19.000 --> 00:14:28.000
Trước tiên hãy xem xét việc sử dụng AnchorEntity của RealityKit để đặt nội dung mà không yêu cầu quyền sử dụng dữ liệu ARKit trong ứng dụng của bạn.

00:14:28.000 --> 00:14:36.000
AnchorEntities của RealityKit cho phép bạn chỉ định một mục tiêu để hệ thống tìm và tự động neo nội dung của bạn vào.

00:14:36.000 --> 00:14:46.000
Vì vậy, ví dụ, để đặt mô hình 3D trên bề mặt bàn trước mặt bạn, bạn có thể sử dụng RealityKit AnchorEntity với mục tiêu được đặt thành bảng.

00:14:46.000 --> 00:14:52.000
Khác với iOS, AnchorEntities có thể được sử dụng mà không cần phải nhắc nhở về quyền của người dùng.

00:14:52.000 --> 00:15:00.000
Quyền riêng tư của mọi người được bảo tồn bằng cách không chia sẻ các biến đổi cơ bản của AnchorEntity với ứng dụng của bạn.

00:15:00.000 --> 00:15:05.000
Lưu ý: điều này ngụ ý rằng con cái của các thực thể neo khác nhau không nhận thức được nhau.

00:15:05.000 --> 00:15:12.000
Mới đối với anchorEntities, bạn có thể nhắm mục tiêu bàn tay, điều này mở ra một lĩnh vực hoàn toàn mới của các cơ hội tương tác thú vị.

00:15:12.000 --> 00:15:19.000
Ví dụ, bạn có thể neo nội dung vào lòng bàn tay của một người và để nó theo tay họ khi họ di chuyển chúng.

00:15:19.000 --> 00:15:25.000
Tất cả điều này được thực hiện bởi hệ thống, mà không cho ứng dụng của bạn biết vị trí thực sự của mọi người.

00:15:25.000 --> 00:15:32.000
AnchorEntitys cung cấp một cách nhanh chóng, thân thiện với quyền riêng tư để ứng dụng của bạn neo nội dung vào môi trường xung quanh mọi người.

00:15:32.000 --> 00:15:39.000
Quay trở lại Không gian đầy đủ, chúng ta cũng có thể tận dụng ARKit để kết hợp kiến thức cấp hệ thống về môi trường xung quanh mọi người.

00:15:39.000 --> 00:15:43.000
Điều này cho phép bạn xây dựng logic vị trí tùy chỉnh của riêng mình.

00:15:43.000 --> 00:15:46.000
Hãy cùng xem cái này hoạt động như thế nào.

00:15:46.000 --> 00:15:51.000
Tương tự như iOS, ứng dụng của bạn nhận được các bản cập nhật neo cho dữ liệu hiểu cảnh.

00:15:51.000 --> 00:15:58.000
Bạn có thể tích hợp dữ liệu neo này vào logic ứng dụng của mình để đạt được tất cả các loại trải nghiệm tuyệt vời.

00:15:58.000 --> 00:16:03.000
Ví dụ, bạn có thể sử dụng giới hạn của một mặt phẳng để căn giữa và phân phối nội dung của bạn lên.

00:16:03.000 --> 00:16:11.000
Hoặc, bạn có thể sử dụng máy bay và phân loại của chúng để tìm góc phòng bằng cách tìm giao điểm của hai bức tường và sàn nhà.

00:16:11.000 --> 00:16:20.000
Khi bạn đã quyết định nơi đặt nội dung của mình, bạn thêm một neo thế giới để ARKit theo dõi và sử dụng nó để cập nhật thành phần chuyển đổi của thực thể của bạn.

00:16:20.000 --> 00:16:31.000
Điều này không chỉ cho phép nội dung của bạn vẫn được neo vào thế giới thực, vì bản đồ thế giới cơ bản được cập nhật, mà nó còn mở ra cánh cửa cho sự kiên trì của neo đậu, mà chúng ta sẽ khám phá trong thời gian ngắn.

00:16:31.000 --> 00:16:37.000
Tất cả các thực thể được thêm vào không gian của bạn có thể tương tác với nhau cũng như với môi trường xung quanh.

00:16:37.000 --> 00:16:43.000
Tất cả điều này hoạt động bởi vì các neo hiểu cảnh được phân phối với các biến đổi liên quan đến nguồn gốc của không gian.

00:16:43.000 --> 00:16:48.000
Cần có sự cho phép của người dùng để sử dụng các khả năng của ARKit.

00:16:48.000 --> 00:16:54.000
Bạn vừa thấy cách tích hợp dữ liệu ARKit vào logic ứng dụng của bạn có thể kích hoạt các tính năng nâng cao hơn.

00:16:54.000 --> 00:16:57.000
Cho đến nay chúng tôi đã nói về việc để ứng dụng của bạn đặt nội dung.

00:16:57.000 --> 00:17:01.000
Hãy cùng khám phá cách chúng ta có thể để mọi người hướng dẫn vị trí.

00:17:01.000 --> 00:17:07.000
Trên iOS, bạn có thể sử dụng raycasting để dịch đầu vào 2D sang vị trí 3D.

00:17:07.000 --> 00:17:16.000
Nhưng với nền tảng mới này, chúng tôi không cần cây cầu 2D-3D này nữa, vì chúng tôi có thể sử dụng tay để tương tác trực tiếp với trải nghiệm một cách tự nhiên.

00:17:16.000 --> 00:17:22.000
Raycasting vẫn mạnh mẽ; nó cho phép mọi người vươn xa tầm tay.

00:17:22.000 --> 00:17:25.000
Có nhiều cách khác nhau để thiết lập raycasting.

00:17:25.000 --> 00:17:30.000
Về cơ bản, bạn cần thiết lập các thành phần va chạm của RealityKit để chống lại raycast.

00:17:30.000 --> 00:17:37.000
Các thành phần va chạm cũng có thể được tạo ra từ các neo lưới của ARKit đến tia chống lại môi trường xung quanh mọi người.

00:17:37.000 --> 00:17:47.000
Hãy cùng khám phá hai ví dụ về cách raycast cho điện toán không gian: đầu tiên, sử dụng cử chỉ hệ thống và ví dụ thứ hai sử dụng dữ liệu tay.

00:17:47.000 --> 00:17:54.000
Sau khi có được một vị trí, chúng tôi có thể đặt một ARKit worldAnchor để giữ cho nội dung của chúng tôi được neo đậu.

00:17:54.000 --> 00:17:56.000
Hãy xem xét ví dụ sau.

00:17:56.000 --> 00:18:01.000
Hãy tưởng tượng ứng dụng của chúng tôi xoay quanh việc đặt các tài sản 3D đầy cảm hứng cho các nhà lập mô hình.

00:18:01.000 --> 00:18:10.000
Có thể trong kịch bản cụ thể này, một người muốn sử dụng ứng dụng của chúng tôi để đặt một con tàu ảo trên bàn làm việc của họ cho một số dự án người mẫu.

00:18:10.000 --> 00:18:13.000
Đây là bàn làm việc mà chúng tôi muốn đặt tàu của mình lên.

00:18:13.000 --> 00:18:17.000
Chúng ta sẽ bắt đầu với một RealityView trống.

00:18:17.000 --> 00:18:22.000
Sự hiểu biết về cảnh của ARKit cung cấp các neo lưới mà chúng tôi sẽ sử dụng để đại diện cho môi trường xung quanh.

00:18:22.000 --> 00:18:26.000
Họ cung cấp thông tin hình học và ngữ nghĩa mà chúng ta có thể sử dụng.

00:18:26.000 --> 00:18:32.000
Hãy nhớ rằng các mắt lưới cho dữ liệu tái tạo cảnh được phân phối dưới dạng một loạt các khối.

00:18:32.000 --> 00:18:42.000
Chúng tôi sẽ tạo một thực thể để đại diện cho đoạn lưới này và chúng tôi sẽ đặt chính xác thực thể này trong một không gian đầy đủ bằng cách sử dụng biến đổi của neo lưới.

00:18:42.000 --> 00:18:46.000
Thực thể của chúng tôi sau đó cần một thành phần va chạm để kiểm tra.

00:18:46.000 --> 00:18:54.000
Chúng tôi sẽ sử dụng phương pháp ShapeResources của RealityKit để tạo ra một hình dạng va chạm từ meshAnchor cho thực thể của chúng tôi.

00:18:54.000 --> 00:18:59.000
Sau đó, chúng tôi sẽ thêm thực thể được đặt chính xác của mình để hỗ trợ kiểm tra lượt truy cập.

00:18:59.000 --> 00:19:06.000
Chúng tôi sẽ xây dựng một thực thể và thành phần va chạm cho mỗi đoạn lưới mà chúng tôi nhận được để đại diện cho tất cả môi trường xung quanh.

00:19:06.000 --> 00:19:11.000
Khi việc tái tạo cảnh được tinh chỉnh, chúng tôi có thể nhận được các bản cập nhật cho mắt lưới hoặc loại bỏ các khối.

00:19:11.000 --> 00:19:16.000
Chúng ta cũng nên sẵn sàng cập nhật các thực thể của mình về những thay đổi này.

00:19:16.000 --> 00:19:20.000
Bây giờ chúng tôi có một bộ sưu tập các thực thể đại diện cho môi trường xung quanh.

00:19:20.000 --> 00:19:25.000
Tất cả các thực thể này đều có các thành phần va chạm và có thể hỗ trợ kiểm tra raycast.

00:19:25.000 --> 00:19:32.000
Đầu tiên chúng ta hãy khám phá raycasting bằng cách sử dụng các cử chỉ hệ thống, và sau đó tiếp tục ví dụ bằng cách sử dụng dữ liệu tay.

00:19:32.000 --> 00:19:37.000
Chúng ta có thể raycast và có được một vị trí để đặt con tàu của chúng ta bằng cách sử dụng các cử chỉ hệ thống.

00:19:37.000 --> 00:19:46.000
Cử chỉ chỉ có thể tương tác với các thực thể có cả thành phần Collision và InputTarget, vì vậy chúng tôi thêm một thực thể vào mỗi thực thể lưới của mình.

00:19:46.000 --> 00:19:53.000
Bằng cách thêm SpatialTapGesture vào RealityView, mọi người có thể raycast bằng cách nhìn vào các thực thể và nhấn.

00:19:53.000 --> 00:20:00.000
Sự kiện kết quả này giữ một vị trí trong không gian thế giới đại diện cho nơi mọi người nhìn vào khi gõ.

00:20:00.000 --> 00:20:05.000
Thay vì sử dụng các cử chỉ hệ thống, chúng ta cũng có thể sử dụng neo tay của ARKit để xây dựng một tia sáng.

00:20:05.000 --> 00:20:08.000
Hãy lùi lại một bước và khám phá tùy chọn này.

00:20:08.000 --> 00:20:12.000
Để biết mọi người chỉ vào đâu, trước tiên chúng ta cần một đại diện cho bàn tay của người đó.

00:20:12.000 --> 00:20:16.000
Các mỏ neo tay mới của ARkit cung cấp cho chúng ta mọi thứ chúng ta cần.

00:20:16.000 --> 00:20:23.000
Chúng ta có thể sử dụng thông tin khớp ngón tay để xây dựng nguồn gốc và hướng của tia cho truy vấn của mình.

00:20:23.000 --> 00:20:30.000
Bây giờ chúng ta đã có nguồn gốc và hướng của tia của mình, chúng ta có thể thực hiện một tia chống lại các thực thể trong cảnh của chúng ta.

00:20:30.000 --> 00:20:37.000
CollisionCastHit kết quả cung cấp thực thể đã bị va chạm, cùng với vị trí của nó và bề mặt bình thường.

00:20:37.000 --> 00:20:46.000
Khi chúng tôi xác định một vị trí trên thế giới để đặt nội dung của mình, chúng tôi sẽ thêm một neo thế giới cho ARKit để liên tục theo dõi vị trí này cho chúng tôi.

00:20:46.000 --> 00:20:51.000
ARKit sẽ cập nhật sự biến đổi của mỏ neo thế giới này khi bản đồ thế giới được tinh chỉnh.

00:20:51.000 --> 00:21:00.000
Chúng tôi có thể tạo một thực thể mới để tải mô hình tàu của mình và thiết lập biến đổi của nó bằng cách sử dụng bản cập nhật neo thế giới, định vị nó ở nơi người dùng muốn.

00:21:00.000 --> 00:21:05.000
Cuối cùng, chúng ta có thể thêm thực thể vào nội dung của mình để hiển thị nó trên bàn làm việc.

00:21:05.000 --> 00:21:15.000
Bất cứ khi nào ARKit cập nhật neo thế giới mà chúng tôi đã thêm vào, chúng tôi cập nhật thành phần biến đổi của thực thể tàu của chúng tôi, đảm bảo nó vẫn neo vào thế giới thực.

00:21:15.000 --> 00:21:16.000
Và thế là xong!

00:21:16.000 --> 00:21:21.000
Chúng tôi đã sử dụng bàn tay của mình để chỉ vào một vị trí xung quanh và đặt nội dung ở đó.

00:21:21.000 --> 00:21:26.000
Raycasting không chỉ hữu ích cho việc đặt nội dung mà còn để tương tác với nó.

00:21:26.000 --> 00:21:30.000
Hãy xem những gì nó cần để raycast chống lại con tàu ảo của chúng ta.

00:21:30.000 --> 00:21:33.000
Các thành phần va chạm RealityKit rất mạnh mẽ.

00:21:33.000 --> 00:21:42.000
Chúng tôi có thể để thực thể tàu tham gia vào các vụ va chạm bằng cách chỉ cần thêm một thành phần va chạm thích hợp vào đó, mà Reality Composer Pro có thể giúp chúng tôi.

00:21:42.000 --> 00:21:53.000
Sau khi kích hoạt thành phần va chạm của con tàu và xây dựng một tia mới từ các vị trí khớp tay mới nhất, chúng ta có thể thực hiện một raycast khác và cho biết người dùng đang chỉ vào con tàu hay cái bàn.

00:21:53.000 --> 00:22:03.000
Các ví dụ trước đây đã chứng minh sức mạnh và tính linh hoạt của việc kết hợp các tính năng của RealityKit với sự hiểu biết về cảnh của ARKit để xây dựng những trải nghiệm thực sự hấp dẫn.

00:22:03.000 --> 00:22:08.000
Hãy xem việc sử dụng ARkit đã thay đổi như thế nào đối với điện toán không gian.

00:22:08.000 --> 00:22:15.000
Về cơ bản, giống như trên iOS, ARKit vẫn hoạt động bằng cách chạy một phiên để nhận các bản cập nhật neo.

00:22:15.000 --> 00:22:21.000
Cách bạn định cấu hình và chạy phiên của mình, nhận cập nhật neo và duy trì neo thế giới đã thay đổi trên nền tảng mới này.

00:22:21.000 --> 00:22:23.000
Hãy cùng xem nào!

00:22:23.000 --> 00:22:28.000
Trên iOS, ARKit cung cấp các cấu hình khác nhau để lựa chọn.

00:22:28.000 --> 00:22:33.000
Mỗi cấu hình kết hợp các khả năng cần thiết cho trải nghiệm của bạn.

00:22:33.000 --> 00:22:43.000
Ví dụ, ở đây, chúng tôi đã chọn ARWorldTrackingConfiguration và sẽ cho phép sceneReconstruction cho mắt lưới và planeDetection cho các mặt phẳng.

00:22:43.000 --> 00:22:49.000
Sau đó chúng ta có thể tạo ARSession của mình và chạy nó với cấu hình đã chọn.

00:22:49.000 --> 00:22:56.000
Trên nền tảng mới này, ARKit hiện hiển thị một nhà cung cấp dữ liệu cho khả năng hiểu từng cảnh.

00:22:56.000 --> 00:23:02.000
Theo dõi tay là một khả năng mới được cung cấp bởi ARKit và cũng có nhà cung cấp riêng.

00:23:02.000 --> 00:23:08.000
Trình khởi tạo của mỗi nhà cung cấp dữ liệu nhận các tham số cần thiết để định cấu hình phiên bản nhà cung cấp đó.

00:23:08.000 --> 00:23:18.000
Bây giờ thay vì chọn từ danh mục các cấu hình đặt trước, bạn nhận được lựa chọn gọi món về các nhà cung cấp bạn cần cho ứng dụng của mình.

00:23:18.000 --> 00:23:26.000
Ví dụ ở đây, chúng tôi chọn một SceneReconstructionProvider để nhận neo lưới và một PlaneDetectionProvider để nhận neo mặt phẳng.

00:23:26.000 --> 00:23:32.000
Chúng tôi tạo ra các nhà cung cấp và khởi tạo phân loại lưới và các loại mặt phẳng mà chúng tôi muốn nhận.

00:23:32.000 --> 00:23:40.000
Sau đó, chúng tôi tạo một ARKitSession và chạy nó với các nhà cung cấp khởi tạo.

00:23:40.000 --> 00:23:50.000
Bây giờ chúng ta đã thấy cách cấu hình phiên của bạn đã được đơn giản hóa, hãy đi và hiểu cách các nhà cung cấp dữ liệu mới này thay đổi cách ứng dụng của bạn thực sự nhận dữ liệu ARKit.

00:23:50.000 --> 00:23:54.000
Trên iOS, một đại biểu duy nhất nhận được các bản cập nhật neo và khung.

00:23:54.000 --> 00:24:00.000
Neo được tổng hợp và phân phối với ARFrames để giữ cho khung máy ảnh và neo đồng bộ.

00:24:00.000 --> 00:24:09.000
Các ứng dụng chịu trách nhiệm hiển thị bộ đệm pixel máy ảnh và sử dụng các biến đổi máy ảnh để đăng ký và hiển thị nội dung ảo được theo dõi.

00:24:09.000 --> 00:24:17.000
Neo lưới và neo phẳng được phân phối dưới dạng neo cơ sở, và tùy thuộc vào bạn để định rõ chúng để tìm ra cái nào là cái nào.

00:24:17.000 --> 00:24:22.000
Trên nền tảng mới của chúng tôi, chính các nhà cung cấp dữ liệu cung cấp các bản cập nhật neo.

00:24:22.000 --> 00:24:25.000
Đây là những nhà cung cấp mà chúng tôi đã định cấu hình trước đó.

00:24:25.000 --> 00:24:33.000
Khi bạn chạy ARKitSession, mỗi nhà cung cấp sẽ ngay lập tức bắt đầu xuất bản không đồng bộ các bản cập nhật neo.

00:24:33.000 --> 00:24:39.000
SceneReconstructionProvider cung cấp lưới và planeDetectionProvider cung cấp cho chúng ta PlaneAnchors.

00:24:39.000 --> 00:24:42.000
Không cần định hướng!

00:24:42.000 --> 00:24:48.000
Các bản cập nhật neo đến ngay khi chúng có sẵn và được tách rời khỏi các bản cập nhật của các nhà cung cấp dữ liệu khác.

00:24:48.000 --> 00:24:52.000
Điều quan trọng cần lưu ý là ARFrames không còn được cung cấp nữa.

00:24:52.000 --> 00:25:00.000
Các ứng dụng điện toán không gian không cần khung hoặc dữ liệu máy ảnh để hiển thị nội dung, vì điều này hiện được hệ thống thực hiện tự động.

00:25:00.000 --> 00:25:12.000
Không cần phải đóng gói các bản cập nhật neo bằng ARFrame, ARKit hiện có thể phân phối chúng ngay lập tức, giảm độ trễ, cho phép ứng dụng của bạn phản ứng nhanh với các bản cập nhật trong môi trường xung quanh.

00:25:12.000 --> 00:25:16.000
Tiếp theo, hãy nói về sự kiên trì của worldAnchor.

00:25:16.000 --> 00:25:18.000
Bạn sẽ thích những thay đổi này!

00:25:18.000 --> 00:25:24.000
Trong các ví dụ về raycasting của chúng tôi, chúng tôi đã sử dụng neo thế giới để đặt và neo nội dung ảo vào các vị trí trong thế giới thực.

00:25:24.000 --> 00:25:32.000
Ứng dụng của bạn có thể duy trì các neo này, cho phép nó tự động nhận lại chúng, khi thiết bị quay trở lại cùng một môi trường xung quanh.

00:25:32.000 --> 00:25:37.000
Trước tiên chúng ta hãy nhanh chóng tóm tắt lại sự kiên trì hoạt động như thế nào trên iOS.

00:25:37.000 --> 00:25:43.000
Trên iOS, trách nhiệm của ứng dụng là xử lý bản đồ thế giới và sự kiên trì của neo đậu.

00:25:43.000 --> 00:26:00.000
Điều này bao gồm yêu cầu và lưu bản đồ thế giới của ARKit với neo đã thêm của bạn, thêm logic để tải lại bản đồ thế giới chính xác vào đúng thời điểm, sau đó đợi quá trình định vị lại kết thúc trước khi nhận các neo đã tồn tại trước đó và tiếp tục trải nghiệm ứng dụng.

00:26:00.000 --> 00:26:13.000
Trên nền tảng mới này, hệ thống liên tục duy trì bản đồ thế giới trong nền, tải, tải, tạo và định vị lại bản đồ hiện có một cách liền mạch khi mọi người di chuyển xung quanh.

00:26:13.000 --> 00:26:18.000
Ứng dụng của bạn không phải xử lý bản đồ nữa, hệ thống hiện đang làm điều đó cho bạn!

00:26:18.000 --> 00:26:24.000
Bạn chỉ cần tập trung vào việc sử dụng các neo thế giới để duy trì các vị trí của nội dung ảo.

00:26:24.000 --> 00:26:31.000
Khi đặt nội dung, bạn sẽ sử dụng WorldTrackingProvider mới để thêm WorldAnchors vào bản đồ thế giới.

00:26:31.000 --> 00:26:34.000
Hệ thống sẽ tự động lưu những thứ này cho bạn.

00:26:34.000 --> 00:26:40.000
WorldTrackingProvider sẽ cập nhật trạng thái theo dõi và biến đổi của các neo thế giới này.

00:26:40.000 --> 00:26:47.000
Bạn có thể sử dụng mã định danh WorldAnchor để tải hoặc dỡ nội dung ảo tương ứng.

00:26:47.000 --> 00:26:54.000
Chúng tôi vừa nêu bật một vài cập nhật cho các nguyên tắc ARKit mà bạn biết từ iOS, nhưng còn rất nhiều điều để khám phá!

00:26:54.000 --> 00:27:01.000
Để tìm hiểu sâu hơn, với các ví dụ về mã, chúng tôi khuyên bạn nên xem "Gặp gỡ ARKit để tính toán không gian".

00:27:01.000 --> 00:27:02.000
Hãy kết thúc phiên này!

00:27:02.000 --> 00:27:14.000
Trong phiên này, chúng tôi đã cung cấp sự hiểu biết cấp cao về cách các khái niệm ARKit và RealityKit đã phát triển từ iOS, những thay đổi bạn cần xem xét và phiên nào cần xem để biết thêm chi tiết.

00:27:14.000 --> 00:27:26.000
Nền tảng này đảm nhận nhiều tác vụ mà ứng dụng iOS của bạn phải xử lý, cho phép bạn thực sự tập trung vào việc xây dựng nội dung và trải nghiệm đẹp mắt bằng cách sử dụng các khuôn khổ và khái niệm mà bạn đã quen thuộc.

00:27:26.000 --> 00:27:32.000
Chúng tôi rất vui khi thấy cách bạn tận dụng điện toán không gian và tất cả các khả năng tuyệt vời của nó để phát triển ứng dụng của bạn!

00:27:32.000 --> 00:27:33.000
Cảm ơn bạn đã xem!

00:27:33.000 --> 23:59:59.000
♪

