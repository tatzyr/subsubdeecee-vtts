WEBVTT

00:00:00.000 --> 00:00:03.000
♪ 부드러운 기악 힙합 ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:12.000
안녕, 난 크리스야.

00:00:12.000 --> 00:00:16.000
저는 AVFoundation 팀의 엔지니어이며, 저희 세션에 오신 것을 환영합니다.

00:00:16.000 --> 00:00:23.000
이 강연에서, 우리는 공간 경험을 위한 스트리밍 콘텐츠를 준비하고 전달하는 방법을 살펴볼 것이다.

00:00:23.000 --> 00:00:30.000
HTTP 라이브 스트리밍을 사용하여 2D 미디어를 생산, 준비 및 제공하는 현재 단계에 대한 간략한 검토부터 시작하겠습니다.

00:00:30.000 --> 00:00:32.000
HLS로도 알려져 있다.

00:00:32.000 --> 00:00:41.000
2D 콘텐츠 준비 및 전달을 다루면, 우리는 3D 비디오 콘텐츠로 전환할 것입니다 - 지원되는 내용과 방금 설명한 단계에 대한 업데이트.

00:00:41.000 --> 00:00:46.000
콘텐츠 파이프라인을 고려할 때, 우리는 비디오, 오디오 및 캡션의 미디어 인코딩으로 시작할 것입니다.

00:00:46.000 --> 00:00:51.000
그런 다음, 그 미디어 자원은 포장되어 HLS 배송을 준비해야 합니다.

00:00:51.000 --> 00:00:54.000
이것이 오늘 2D 콘텐츠가 전달되는 방식이다.

00:00:54.000 --> 00:00:58.000
3D 콘텐츠를 제공하는 목표는 현재 2D 프로세스를 기반으로 하는 것이다.

00:00:58.000 --> 00:01:05.000
HLS는 중요한 적응을 가능하게 하는 단편화된 MP4 시간 메타데이터에 대한 새로운 지원을 추가합니다.

00:01:05.000 --> 00:01:14.000
문서, 도구, 예제 스트림, 개발자 포럼 및 기타 리소스에 대한 링크를 제공하는 Apple Developer 웹사이트의 HTTP 라이브 스트리밍 페이지에 유의하십시오.

00:01:14.000 --> 00:01:19.000
이것은 이 강연에서 다룬 더 많은 세부 사항이 시간이 지남에 따라 제공될 것이다.

00:01:19.000 --> 00:01:25.000
우리의 목표는 이 플랫폼에 2D 시청각 콘텐츠를 제공하는 것이 다른 모든 플랫폼과 동일해야 한다는 것입니다.

00:01:25.000 --> 00:01:39.000
이것은 HTTP 라이브 스트리밍, AVFoundation, Core Media와 같은 Apple Media 기술 및 종종 MPEG-4로 생각되는 ISO 기반 미디어 파일 형식과 같은 표준 기반 형식을 기반으로 합니다.

00:01:39.000 --> 00:01:43.000
이것은 새로운 공간 경험 패러다임을 지원하면서 모두 이루어진다.

00:01:43.000 --> 00:01:53.000
시청각 미디어의 재생을 가장 잘 지원하는 방법에 대해 자세히 알아보려면, "비디오 재생을 위한 훌륭한 공간 경험 만들기" 세션을 참조하십시오.

00:01:53.000 --> 00:01:55.000
비디오의 경우, 소스 비디오를 인코딩하세요.

00:01:55.000 --> 00:02:00.000
올바른 길이로 편집하고 당신에게 중요한 비트레이트 계층에 맞게 수정하세요.

00:02:00.000 --> 00:02:07.000
여기서 당신은 고효율 비디오 코딩의 줄임말인 HEVC와 같은 비디오 인코더를 구성하고 사용하는 방법을 선택할 수 있습니다.

00:02:07.000 --> 00:02:15.000
다른 Apple 플랫폼에 제공하는 기존 2D 시청각 미디어에 대한 지원이 완전히 지원되지만, 이러한 재생 기능에 유의하십시오.

00:02:15.000 --> 00:02:21.000
이 플랫폼은 최대 4K 해상도의 재생을 지원하여 최고 품질의 비디오를 경험할 수 있습니다.

00:02:21.000 --> 00:02:29.000
디스플레이의 재생률은 90 헤르츠이며, 초당 24프레임 비디오의 경우 특별한 96 헤르츠 모드를 자동으로 사용할 수 있습니다.

00:02:29.000 --> 00:02:33.000
표준 및 높은 다이내믹 레인지에 대한 지원이 있습니다.

00:02:33.000 --> 00:02:39.000
비디오의 해당 오디오의 경우, 필요한 소스 오디오 스트림의 수를 식별하고 생성하십시오.

00:02:39.000 --> 00:02:45.000
그 숫자는 당신이 목표로 하는 구어 세트와 그 오디오의 역할에 따라 다릅니다.

00:02:45.000 --> 00:02:49.000
한 역할은 주요 대화일 수도 있고, 다른 역할은 오디오 설명일 수도 있다.

00:02:49.000 --> 00:02:53.000
HLS를 염두에 두고 배달을 위해 이 소스를 인코딩하세요.

00:02:53.000 --> 00:02:58.000
대체 스테레오 오디오 트랙과 함께 공간 오디오를 제공하고 싶을 수도 있습니다.

00:02:58.000 --> 00:03:04.000
이것은 모든 곳에서 공간 오디오와 신뢰할 수 있는 재생을 지원하는 장치에 훌륭한 경험을 보장합니다.

00:03:04.000 --> 00:03:08.000
HLS 개발자 페이지에는 오디오 준비에 관한 문서에 대한 링크가 있습니다.

00:03:08.000 --> 00:03:10.000
그리고 캡션이 있어.

00:03:10.000 --> 00:03:16.000
여기서 캡션에는 다양한 언어와 역할을 다루는 자막과 자막이 모두 포함되어 있습니다.

00:03:16.000 --> 00:03:27.000
"자막"이라는 용어는 언어를 구사하지 못하거나 설정 시간과 장소를 설정할 수 있는 시청자를 위해 다른 언어로 번역을 제공하는 음성 텍스트의 전사에 사용됩니다.

00:03:27.000 --> 00:03:32.000
자막은 자막과 비슷하지만 시청자가 오디오를 들을 수 없을 때 의도되었다.

00:03:32.000 --> 00:03:38.000
자막은 대화뿐만 아니라 음향 효과 및 기타 관련 오디오 신호의 전사를 제공합니다.

00:03:38.000 --> 00:03:44.000
청각 장애인과 난청인 SDH를 위한 자막도 있을 수 있으며, 같은 목적을 제공한다.

00:03:44.000 --> 00:03:52.000
비디오 및 오디오 인코딩과 유사하게, HLS, 가장 일반적으로 WebVTT에서 지원하는 캡션 파일과 형식을 생성해야 합니다.

00:03:52.000 --> 00:03:57.000
소스 비디오, 오디오 및 캡션을 손에 들고, 다음은 포장입니다.

00:03:57.000 --> 00:04:04.000
포장은 신뢰할 수 있는 배송을 위해 소스 미디어를 다양한 유형의 세그먼트로 변환하는 과정이다.

00:04:04.000 --> 00:04:09.000
이것은 이전 HLS 스트리밍 페이지에서 사용할 수 있는 Apple의 HLS 도구로 수행할 수 있습니다.

00:04:09.000 --> 00:04:14.000
일부 콘텐츠 제공자는 자체 제작 도구, 하드웨어 또는 워크플로우를 사용할 수 있습니다.

00:04:14.000 --> 00:04:18.000
다른 사람들은 첫 번째 그룹에 그러한 서비스와 도구를 제공하는 공급 업체일 수 있다.

00:04:18.000 --> 00:04:27.000
패키징의 목표는 일련의 미디어 세그먼트, 사용을 유도하는 미디어 재생 목록, 그리고 그것들을 모두 하나로 묶는 다양한 재생 목록을 생산하는 것이다.

00:04:27.000 --> 00:04:32.000
오늘날 두 종류의 HLS 미디어 세그먼트가 가장 일반적으로 사용된다.

00:04:32.000 --> 00:04:39.000
조각 난 MP4 미디어 세그먼트는 이미 인코딩된 비디오 또는 오디오 영화 파일로 시작하여 많은 리소스를 생성하여 생성됩니다.

00:04:39.000 --> 00:04:42.000
이 자원들은 미디어 세그먼트로 알려져 있다.

00:04:42.000 --> 00:04:47.000
재생 중에 클라이언트 장치에서 검색되는 것은 이러한 세그먼트입니다.

00:04:47.000 --> 00:04:50.000
자막 파일 또한 세분화가 필요하다.

00:04:50.000 --> 00:04:54.000
이것은 미디어 세그먼트를 생성하기 위한 자막 세분화 도구로 이루어집니다.

00:04:54.000 --> 00:05:01.000
소스 WebVTT 파일은 대상 세그먼트 기간 동안 원하는 수의 WebVTT 파일로 분할될 수 있습니다.

00:05:01.000 --> 00:05:07.000
마지막으로, HLS 리소스 컬렉션은 HTTP 전송을 위해 웹 서버에서 호스팅됩니다.

00:05:07.000 --> 00:05:15.000
이것은 클라이언트에게 직접 서비스를 제공하는 하나의 서버 또는 콘텐츠 전송 네트워크 또는 CDN과 함께 사용되는 원본 서버일 수 있습니다.

00:05:15.000 --> 00:05:20.000
어느 쪽이든, 재생을 위해 클라이언트 장치로 전달되는 것은 이러한 자원이다.

00:05:20.000 --> 00:05:29.000
이제 2D 생산 및 배송 파이프라인을 검토했으므로, 3D 콘텐츠와 새로운 특수 기능을 활용하는 차이점으로 전환해 봅시다.

00:05:29.000 --> 00:05:37.000
우리는 2D 콘텐츠와 3D 입체 콘텐츠의 차이점에 초점을 맞춰 소스 인코딩, 포장 및 배송을 다시 살펴볼 것입니다.

00:05:37.000 --> 00:05:40.000
그래서, 우리는 3D 비디오에 대해 이야기하고 있습니다.

00:05:40.000 --> 00:05:42.000
이 용어를 해체합시다.

00:05:42.000 --> 00:05:48.000
첫째, 그것은 비디오이므로, 영화 트랙이나 네트워크 스트림의 일련의 프레임이다.

00:05:48.000 --> 00:06:01.000
"3D 비디오"의 "3D"는 왼쪽 눈의 이미지를 제공하는 입체와 오른쪽 눈의 약간 다른 관점에서 매우 유사한 이미지와 상호 교환적으로 사용됩니다.

00:06:01.000 --> 00:06:09.000
시차라고 불리는 왼쪽과 오른쪽 이미지의 이러한 차이점은 제시될 때 비디오의 3차원 깊이를 인식하게 합니다.

00:06:09.000 --> 00:06:14.000
3D 비디오 프레임을 운반하는 방법에는 선택 사항이 있지만 유용해 보이는 몇 가지 지침 원칙이 있습니다.

00:06:14.000 --> 00:06:21.000
모든 스테레오 프레임에 단일 비디오 트랙을 사용하면 2D 비디오 트랙이 있는 전통적인 제작이 보존됩니다.

00:06:21.000 --> 00:06:26.000
모든 디스플레이 시간에 대한 왼쪽과 오른쪽 이미지 또는 뷰는 모두 하나의 압축된 프레임에 있습니다.

00:06:26.000 --> 00:06:31.000
손에 프레임이 있다면, 두 뷰 또는 스테레오 쌍을 모두 사용할 수 있습니다.

00:06:31.000 --> 00:06:45.000
그것은 효율적이어야 하며, 이상적으로는 애플 실리콘에 의해 지원되어야 하며, 가능한 한 3D 인식이 아닌 재생으로 디코딩할 수 있어야 하며, 2D 워크플로우에서 비디오를 오디션할 수 있어야 합니다.

00:06:45.000 --> 00:06:52.000
스테레오 프레임을 제공하기 위해, 우리는 "MV-HEVC"라고도 불리는 멀티뷰 HEVC의 사용을 소개합니다.

00:06:52.000 --> 00:06:54.000
그것은 HEVC의 확장이다.

00:06:54.000 --> 00:06:56.000
"MV"는 멀티뷰이다.

00:06:56.000 --> 00:07:03.000
각 프레임에 하나 이상의 뷰를 가지고 있는 각 프레임에는 한 쌍의 압축된 왼쪽과 오른쪽 이미지가 있습니다.

00:07:03.000 --> 00:07:08.000
MV-HEVC는 그 중심에 HEVC이기 때문에, 애플 실리콘은 그것을 지원한다.

00:07:08.000 --> 00:07:14.000
MV-HEVC는 각 압축 프레임에 기본 HEVC 2D 뷰를 저장합니다.

00:07:14.000 --> 00:07:18.000
인코딩은 왼쪽과 오른쪽 이미지 사이의 차이 또는 델타를 결정한다.

00:07:18.000 --> 00:07:26.000
2D 플러스 델타로 알려진 이 기술은 2D 디코더가 왼쪽 눈과 같은 기본 2D 뷰를 찾고 사용할 수 있다는 것을 의미합니다.

00:07:26.000 --> 00:07:31.000
하지만 3D 디코더는 다른 뷰를 계산하여 해당 눈에 두 뷰를 모두 제시할 수 있다.

00:07:31.000 --> 00:07:45.000
기본 2D 이미지의 차이점은 표준 HEVC 기술을 사용하고 왼쪽과 오른쪽 눈의 차이만 스테레오 프레임에 설명되어 있기 때문에 효율성이 달성됩니다.

00:07:45.000 --> 00:08:00.000
비디오 형식 설명 또는 MPEG-4의 시각적 샘플 항목은 코딩 유형, 코덱, 각 보기의 크기 및 비디오 프레임을 디코딩하는 데 필요한 기타 세부 사항을 나타냅니다.

00:08:00.000 --> 00:08:03.000
비디오 형식 설명의 새로운 확장이 도입되었다.

00:08:03.000 --> 00:08:12.000
비디오 확장 사용 상자라고 불리며, 비디오가 입체적이며 스테레오 아이 뷰가 존재한다는 가볍고 쉽게 발견할 수 있는 신호 역할을 합니다.

00:08:12.000 --> 00:08:15.000
HLS 배송을 위해, 이것은 왼쪽과 오른쪽이 될 것이다.

00:08:15.000 --> 00:08:21.000
이 새로운 VEXU 상자를 설명하는 사양은 SDK와 함께 사용할 수 있습니다.

00:08:21.000 --> 00:08:25.000
그것의 구조는 진화할 것이며, 그것은 사양에 설명될 것이다.

00:08:25.000 --> 00:08:33.000
2D 콘텐츠와 마찬가지로, 3D 비디오는 이번에는 MV-HEVC라고 불리는 변형을 제외하고 HEVC를 사용한다.

00:08:33.000 --> 00:08:36.000
이것은 입체적인 시야를 전달하기 위해 필요하다.

00:08:36.000 --> 00:08:43.000
2D 제작과 마찬가지로, MV-HEVC가 있는 로컬 영화를 사용할 수 있으며 다른 2D 비디오처럼 작동해야 합니다.

00:08:43.000 --> 00:08:53.000
해당 눈에 왼쪽과 오른쪽 이미지를 모두 제시하면 입체 깊이에 대한 인식을 생성하여 상대적인 깊이의 감각을 제공한다.

00:08:53.000 --> 00:09:00.000
비디오 장면의 물체는 시차의 양이 다르기 때문에 다른 물체보다 더 가깝거나 더 멀리 인식될 수 있다.

00:09:00.000 --> 00:09:03.000
입체 깊이의 세 가지 주요 영역을 정의할 수 있다.

00:09:03.000 --> 00:09:17.000
그것들은 시차 단서가 없는 스크린 평면이다; 스크린 평면 앞에서 물체가 인식되도록 하는 부정적인 시차; 그리고 스크린 평면 뒤에서 물체가 인식되도록 하는 긍정적인 시차이다.

00:09:17.000 --> 00:09:27.000
캡션과 같은 요소가 부정적인 시차 단서와 같은 프레임 영역에서 시차 없이 렌더링되면, 깊이 충돌이 발생하고 볼 때 불편함을 유발할 것이다.

00:09:27.000 --> 00:09:29.000
질문.

00:09:29.000 --> 00:09:35.000
입체 시차와 깊이 충돌의 가능성을 감안할 때, 3D 비디오의 캡션을 만드는 것은 얼마나 관련되어 있습니까?

00:09:35.000 --> 00:09:37.000
다음을 지원할 수 있을까요?

00:09:37.000 --> 00:09:52.000
재생은 수평 캡션에서 작동하고, 재생은 수직 캡션을 포함한 여러 언어로 작동하며, 재생은 접근성 설정을 사용하여 사용자가 선호하는 캡션 크기를 조정할 때 작동합니다.

00:09:52.000 --> 00:09:54.000
음, 대답은 '예'야.

00:09:54.000 --> 00:10:05.000
내가 다음에 설명할 접근 방식을 사용하는 입체 비디오로, 캡션은 그대로 작동해야 하며, 2D와 3D 경험 간에 동일한 2D 캡션 자산을 공유할 수 있어야 한다.

00:10:05.000 --> 00:10:11.000
이것은 내가 앞서 언급한 새로운 시간 메타데이터를 포함함으로써 가능하다.

00:10:11.000 --> 00:10:17.000
입체 비디오의 경우, 깊이 충돌과 비디오를 오버레이하는 시각적 요소를 피하는 것이 중요합니다.

00:10:17.000 --> 00:10:25.000
새로운 캡션 형식이나 기존 형식의 변경을 요구하는 대신, 우리는 각 비디오 프레임의 시차를 특성화하는 방법을 제공합니다.

00:10:25.000 --> 00:10:30.000
이것은 프레임에 따라 다를 수 있으며 일부 영역은 분명히 더 가깝고 시청자로부터 더 멀리 떨어져 있습니다.

00:10:30.000 --> 00:10:38.000
우리는 이것을 시차 윤곽이라고 부르며, 비디오 트랙의 프레임과 동기화된 메타데이터 트랙에 메타데이터로 기록됩니다.

00:10:38.000 --> 00:10:48.000
3D 비디오를 타일링하고 각 타일의 깊이 시차를 나타내면, 캡션이 스테레오 비디오의 요소를 방해하지 않도록 하기 위해 그것을 사용할 수 있습니다.

00:10:48.000 --> 00:10:55.000
재생 중에, 캡션의 시차는 깊이 충돌을 피하기 위해 자동으로 조정됩니다.

00:10:55.000 --> 00:11:04.000
이러한 시차 비디오 윤곽이 있는 각 메타데이터 항목은 각 타일과 관련된 최소 시차 값으로 관련 비디오의 2D 타일링을 설명합니다.

00:11:04.000 --> 00:11:10.000
각 비디오 프레임의 프레젠테이션은 비디오 프레임의 윤곽을 설명하는 메타데이터 항목과 연결되어야 합니다.

00:11:10.000 --> 00:11:20.000
우리는 비디오에서 시차의 다른 영역을 특성화하기 위해 저장과 해상도 사이의 좋은 균형으로 10 x 10 타일링을 권장합니다.

00:11:20.000 --> 00:11:25.000
이 시차 메타데이터가 어떻게 생성되는지 고려하여, 각 프레임의 왼쪽과 오른쪽 보기로 시작하세요.

00:11:25.000 --> 00:11:30.000
이것은 두 개의 동기화된 비디오 트랙으로 프로덕션에서 수행할 수 있으며 MV-HEVC가 필요하지 않습니다.

00:11:30.000 --> 00:11:37.000
그런 다음, 타일링 설명에 적합한 시차 정보를 만들기 위해 시차 또는 격차 분석을 수행하십시오.

00:11:37.000 --> 00:11:42.000
각 스테레오 프레임에 대해, 이것은 다음 단계를 위해 메타데이터 페이로드에 패키지화됩니다.

00:11:42.000 --> 00:11:48.000
이 메타데이터의 형식을 설명하는 사양은 SDK에서 사용할 수 있습니다.

00:11:48.000 --> 00:11:53.000
이 시차 정보는 메타데이터 샘플로 포장되어 시간제 메타데이터 트랙에 기록됩니다.

00:11:53.000 --> 00:12:00.000
메타데이터 트랙은 그것이 설명하는 해당 비디오와 연관될 것이다.

00:12:00.000 --> 00:12:10.000
메타데이터와 비디오 트랙은 HLS 패키징이 비디오와 시차 메타데이터가 모두 포함된 비디오 세그먼트를 생성할 수 있도록 비디오와 함께 다중화되어야 합니다.

00:12:10.000 --> 00:12:14.000
이미 2D용으로 제작할 수 있는 캡션은 3D로 재사용할 수 있습니다.

00:12:14.000 --> 00:12:21.000
이것은 오늘날 사용되는 프로세스 또는 함께 작업할 수 있는 공급 업체가 3D 생산과 함께 2D로 계속 작업할 수 있음을 의미합니다.

00:12:21.000 --> 00:12:32.000
또한, 이것은 3D 콘텐츠가 언어 선택, 수평 및 수직 레이아웃 또는 사용자의 접근성 자막 환경 설정의 잠재적 사용에 구애받지 않는다는 것을 의미합니다.

00:12:32.000 --> 00:12:40.000
설명된 시차 메타데이터를 추가함으로써, 플랫폼은 당신이 구축한 시차 메타데이터에 동적으로 적응합니다.

00:12:40.000 --> 00:12:45.000
3D 비디오와 함께 오디오를 사용하는 경우, 2D 전송에 동일한 오디오를 사용할 수 있습니다.

00:12:45.000 --> 00:12:50.000
플랫폼이 헤드 트래킹을 지원하므로, 공간 오디오 형식을 사용하는 것을 고려해 보세요.

00:12:50.000 --> 00:12:57.000
2D와 3D 경험 간에 동일한 오디오를 공유하려면, 비디오는 타이밍에 따라 일치해야 하며, 동일한 편집을 해야 합니다.

00:12:57.000 --> 00:13:03.000
만약 그들이 다르다면, 2D와 3D 자산 간에 오디오 트랙을 분리해야 합니다.

00:13:03.000 --> 00:13:12.000
3D의 패키징으로 돌아가서, 업데이트된 HLS 도구는 세부 사항을 처리하며, 3D 자산은 2D와 거의 동일한 프로세스를 만듭니다.

00:13:12.000 --> 00:13:21.000
애플의 도구를 사용하지 않는 대부분의 생산 시스템은 동등한 기능을 구축하기 위해 출시되는 새로운 사양을 사용할 수 있을 것이다.

00:13:21.000 --> 00:13:27.000
자신만의 재생 목록을 만들거나 검사하는 경우, 몇 가지 변경 사항을 기록하세요.

00:13:27.000 --> 00:13:33.000
REQ-VIDEO-LAYOUT은 비디오가 입체적임을 나타내는 비디오 스트림의 새로운 태그입니다.

00:13:33.000 --> 00:13:37.000
속성 값은 비디오가 스테레오인지 아닌지를 나타냅니다.

00:13:37.000 --> 00:13:42.000
자산이 3D로 로드되면, 2D로 전환되지 않거나 그 반대의 경우도 마찬가지입니다.

00:13:42.000 --> 00:13:48.000
2D 비디오는 변경되지 않으며 동일한 재생 목록에서 3D 비디오와 혼합할 수 있습니다.

00:13:48.000 --> 00:13:53.000
REQ-VIDEO-LAYOUT은 새로운 버전의 HLS 사양이 필요하므로 버전이 12로 업데이트됩니다.

00:13:53.000 --> 00:13:57.000
이것은 SDK와 함께 문서화되어 있다.

00:13:57.000 --> 00:14:06.000
다음은 버전 번호를 12로 변경하고 3D 비디오 스트림에 REQ-VIDEO-LAYOUT을 사용하는 다변형 재생 목록의 예입니다.

00:14:06.000 --> 00:14:15.000
최고의 탐색 경험을 위해, 썸네일 스크러빙을 지원하기 위해 다변형 재생 목록에 2D iFrame 스트림을 포함해야 합니다.

00:14:15.000 --> 00:14:21.000
마지막으로, HLS 배송은 3D 자산과 동일하게 작동합니다.

00:14:21.000 --> 00:14:27.000
3D 자산을 제공하는 것은 2D 자산을 제공하는 것과 거의 동일하지만, 경험을 최적화하기 위해 할 수 있는 몇 가지 일이 있습니다.

00:14:27.000 --> 00:14:34.000
3D 비디오에 MV-HEVC를 사용하고 새로운 시차 윤곽 메타데이터를 포함하여 소스 자산을 준비하십시오.

00:14:34.000 --> 00:14:37.000
오디오와 캡션 제작은 동일할 수 있다.

00:14:37.000 --> 00:14:41.000
업데이트된 포장을 사용하여 관련 세그먼트와 재생 목록을 생성하세요.

00:14:41.000 --> 00:14:44.000
호스팅은 동일하게 유지됩니다.

00:14:44.000 --> 00:14:50.000
닫기 전에, 저는 시각적 편안함이 3D 경험의 핵심 콘텐츠 디자인 목표라는 것을 강조하고 싶습니다.

00:14:50.000 --> 00:14:55.000
3D 콘텐츠는 충분히 오랜 시간 동안 편안하게 볼 수 있어야 한다.

00:14:55.000 --> 00:15:09.000
잠재적으로 편안함 문제를 일으킬 수 있는 일부 3D 콘텐츠 특성에는 초점 장애를 유발하는 콘텐츠의 극도의 시차, 부정적이고 긍정적인 높은 움직임뿐만 아니라 "창 위반"이라고 불리는 것으로 인한 깊이 충돌이 포함됩니다.

00:15:09.000 --> 00:15:16.000
화면 크기는 시청자의 수평 시야에 있는 화면의 양에 따라 시청의 편안함에 영향을 미칠 수 있습니다.

00:15:16.000 --> 00:15:21.000
사용자는 화면 크기를 더 가까이 또는 더 멀리 배치하여 화면 크기에 영향을 미칠 수 있습니다.

00:15:21.000 --> 00:15:27.000
그래서 우리의 여정에서, 우리는 HTTP 라이브 스트리밍으로 2D 및 3D 전달을 살펴보았습니다.

00:15:27.000 --> 00:15:30.000
비디오를 위해, 나는 MV-HEVC를 소개했다.

00:15:30.000 --> 00:15:35.000
오디오의 경우, 우리는 2D와 3D에서 동일한 오디오 스트림을 사용할 수 있다는 점에 주목했다.

00:15:35.000 --> 00:15:40.000
캡션의 경우, 2D와 3D에서 동일한 스트림을 사용할 수 있습니다.

00:15:40.000 --> 00:15:49.000
마지막으로, 3D 비디오의 시차를 특성화하기 위해 새로운 타임 메타데이터 형식이 도입되어 동일한 캡션을 사용할 수 있습니다.

00:15:49.000 --> 00:15:55.000
마무리하기 위해, 우리는 당신의 기존 2D 콘텐츠를 공간적 경험으로 가능한 한 쉽게 가져올 수 있도록 만들었습니다.

00:15:55.000 --> 00:16:02.000
현재 2D 파이프라인을 약간 수정하면 MV-HEVC를 사용하여 3D 콘텐츠를 지원할 수 있습니다.

00:16:02.000 --> 00:16:06.000
2D 자산의 모든 기존 캡션을 계속 사용할 수도 있습니다.

00:16:06.000 --> 00:16:12.000
하지만 시간제 메타데이터를 제공한다면, 그 캡션은 띄지 않고 편안한 시청 경험을 제공할 수 있습니다.

00:16:12.000 --> 00:16:18.000
비디오 재생을 구현할 때 고려해야 할 사항은 동반 세션을 시청하세요.

00:16:18.000 --> 00:16:21.000
우리는 당신이 전달할 훌륭한 새로운 콘텐츠를 기대합니다.

00:16:21.000 --> 00:16:23.000
오늘 우리와 함께 해줘서 고마워.

00:16:23.000 --> 23:59:59.000
♪

