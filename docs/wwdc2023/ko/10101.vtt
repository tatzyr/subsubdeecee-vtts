WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:12.000
이선: 안녕하세요, 저는 이선입니다.

00:00:12.000 --> 00:00:17.000
저는 Siri Understanding 팀 출신이며 음성 인식의 흥미로운 발전에 대해 이야기하기 위해 여기에 있습니다.

00:00:17.000 --> 00:00:20.000
iOS 10에서, 우리는 음성 프레임워크를 도입했다.

00:00:20.000 --> 00:00:29.000
Siri와 키보드 받아쓰기를 지원하는 동일한 기술을 활용하여 간단하고 직관적인 인터페이스를 사용하여 음성 지원 앱을 만들 수 있었습니다.

00:00:29.000 --> 00:00:34.000
그러나, 음성 인식기 수업은 모든 앱에 적합하지 않다.

00:00:34.000 --> 00:00:37.000
이유를 설명하기 위해, 음성 인식이 어떻게 작동하는지 이야기해 봅시다.

00:00:37.000 --> 00:00:44.000
음성 인식 시스템은 먼저 음성 표현을 생성하는 음향 모델에 오디오 데이터를 공급한다.

00:00:44.000 --> 00:00:50.000
그런 다음 음성 표현은 서면 형식 또는 전사로 변환됩니다.

00:00:50.000 --> 00:00:57.000
때때로, 여러 음성 표현이 오디오 데이터에 적합하거나, 단일 음성 표현이 여러 전사에 해당할 수 있다.

00:00:57.000 --> 00:01:03.000
이러한 경우, 우리는 여러 후보자 전사로 끝나며, 모호하게 할 수 있는 방법이 필요하다.

00:01:03.000 --> 00:01:06.000
이것을 하기 위해, 우리는 언어 모델이라고 불리는 것을 사용한다.

00:01:06.000 --> 00:01:11.000
언어 모델은 주어진 단어가 일련의 단어로 다음에 올 가능성을 예측한다.

00:01:11.000 --> 00:01:17.000
전체 문장에 적용하면, 그 문장이 아마도 넌센스인지에 대한 느낌을 줄 수 있다.

00:01:17.000 --> 00:01:24.000
언어 모델은 훈련 중에 모델이 노출된 사용 패턴에 따라 가능성이 없는 후보자를 거부하는 데 도움을 준다.

00:01:24.000 --> 00:01:30.000
iOS 10 이후, 음성 프레임워크는 사용하기 쉬운 인터페이스를 제공하기 위해 이 전체 프로세스를 캡슐화했다.

00:01:30.000 --> 00:01:34.000
왜 그것이 이상적이지 않은지 이해하기 위해, 예를 들어 봅시다.

00:01:34.000 --> 00:01:42.000
저는 체스를 하는 것을 좋아하며, 사용자가 일반적인 오프닝과 방어뿐만 아니라 개별 동작을 지시할 수 있는 체스 앱을 개발하고 있습니다.

00:01:42.000 --> 00:01:47.000
여기서, 내 상대는 고전적인 퀸즈 갬빗을 했다.

00:01:47.000 --> 00:01:53.000
나는 공부하고 있었고, 알빈 카운터 갬빗인 E5의 반응이 마음에 든다.

00:01:53.000 --> 00:01:56.000
알빈 카운터 도박을 하세요.

00:01:56.000 --> 00:01:58.000
어 오, 문제가 있어.

00:01:58.000 --> 00:02:03.000
인식기가 내 체스 동작을 음악 요청으로 잘못 인식하고 있다.

00:02:03.000 --> 00:02:13.000
인식기가 사용하는 언어 모델은 교육 과정에서 많은 음악 요청에 노출되었으므로, "앨범 재생"과 앨범 이름과 같은 쿼리를 위해 준비되었습니다.

00:02:13.000 --> 00:02:18.000
반대로, 그것은 아마도 내가 선호하는 전사를 만난 적이 없을 것이다.

00:02:18.000 --> 00:02:27.000
언어 모델의 동작을 추상화함으로써, 음성 프레임워크는 다른 도메인이 다른 동작을 요구하더라도 모든 앱이 동일한 모델을 사용하도록 강요한다.

00:02:27.000 --> 00:02:38.000
iOS 17부터 SFSpeechRecognizer의 언어 모델의 동작을 사용자 정의하고, 애플리케이션에 맞게 조정하고, 정확성을 향상시킬 수 있습니다.

00:02:38.000 --> 00:02:43.000
언어 모델 사용자 지정을 시작하려면, 먼저 훈련 데이터 모음을 만드세요.

00:02:43.000 --> 00:02:46.000
당신은 개발 과정에서 이것을 할 수 있습니다.

00:02:46.000 --> 00:02:53.000
그런 다음 앱에서 데이터를 준비하고, 인식 요청을 구성한 다음, 실행할 수 있습니다.

00:02:53.000 --> 00:02:57.000
훈련 데이터 수집을 구축하는 과정에 대해 이야기해 봅시다.

00:02:57.000 --> 00:03:05.000
높은 수준에서, 훈련 데이터는 앱 사용자가 말할 가능성이 있는 문구를 나타내는 텍스트 비트로 구성됩니다.

00:03:05.000 --> 00:03:11.000
이것들은 모델에게 그 문구를 기대하도록 가르치고 그들이 올바르게 인식될 가능성을 높일 것이다.

00:03:11.000 --> 00:03:18.000
인식기가 얼마나 유능한지, 그리고 시간이 지남에 따라 얼마나 개선되는지 보는 것은 놀랍기 때문에 자주 실험하세요.

00:03:18.000 --> 00:03:22.000
음성 프레임워크는 훈련 데이터를 위한 컨테이너 역할을 하는 새로운 클래스를 도입한다.

00:03:22.000 --> 00:03:25.000
그것은 결과 빌더 DSL을 사용하여 만들어졌다.

00:03:25.000 --> 00:03:30.000
PhraseCount 객체를 사용하여 정확한 구문이나 구문의 일부를 제공할 수 있습니다.

00:03:30.000 --> 00:03:36.000
PhraseCount는 또한 최종 데이터 세트에서 샘플이 몇 번이나 표현되어야 하는지 설명할 것이다.

00:03:36.000 --> 00:03:40.000
이것은 특정 문구에 다른 문구보다 더 많은 무게를 가하는 데 사용될 수 있다.

00:03:40.000 --> 00:03:47.000
시스템에서 너무 많은 데이터만 받아들일 수 있으므로, 전체 교육 데이터 예산과 구문을 늘려야 할 필요성의 균형을 맞추세요.

00:03:47.000 --> 00:03:52.000
템플릿을 활용하여 일반 패턴에 맞는 많은 수의 샘플을 생성할 수도 있습니다.

00:03:52.000 --> 00:03:57.000
여기서, 나는 체스 동작을 구성하는 세 가지 종류의 단어를 정의했다.

00:03:57.000 --> 00:04:06.000
내가 목표로 하는 파일로 두 배로 움직이는 조각, 보드의 어느 쪽에서 플레이할지 정의하는 왕실 조각, 그리고 이동할 순위.

00:04:06.000 --> 00:04:13.000
그것들을 패턴으로 조합함으로써, 나는 가능한 모든 움직임을 나타내는 데이터 샘플을 쉽게 생성할 수 있다.

00:04:13.000 --> 00:04:21.000
여기서, 카운트는 전체 템플릿에 적용되므로, 나는 모든 결과 데이터 샘플로 균등하게 나누어진 체스 동작을 나타내는 10,000개의 샘플을 얻을 것이다.

00:04:21.000 --> 00:04:28.000
데이터 객체 구축을 마치면, 파일로 내보내고 다른 자산과 마찬가지로 앱에 배포합니다.

00:04:28.000 --> 00:04:41.000
앱이 전문 용어(예: 의약품의 이름을 포함하는 의료 앱)를 사용하는 경우, 해당 용어의 철자와 발음을 모두 정의하고 사용법을 보여주는 구문 수를 제공할 수 있습니다.

00:04:41.000 --> 00:04:45.000
발음은 X-SAMPA 문자열의 형태로 받아들여진다.

00:04:45.000 --> 00:04:50.000
각 로케일은 발음 기호의 고유한 하위 집합을 지원합니다.

00:04:50.000 --> 00:04:55.000
로케일과 지원되는 기호의 전체 세트에 대한 문서를 참조하십시오.

00:04:55.000 --> 00:05:02.000
내 앱의 경우, 나는 인식자가 프랑스 방어의 일반적인 변형인 Winawer 변형을 이해할 수 있도록 하고 싶다.

00:05:02.000 --> 00:05:09.000
나는 이 로케일에서 지원하는 X-SAMPA 기호의 하위 집합을 사용하여 발음을 설명한다.

00:05:09.000 --> 00:05:13.000
동일한 API를 사용하여 앱이 런타임에 액세스할 수 있는 데이터를 훈련할 수 있습니다.

00:05:13.000 --> 00:05:22.000
사용자가 배우려고 하는 체스 오프닝과 방어에 초점을 맞추는 것과 같이 사용자에게 특정한 사용 패턴을 지원하기 위해 이것을 할 수 있습니다.

00:05:22.000 --> 00:05:24.000
당신은 또한 명명된 단체에 대해 훈련하고 싶을 수도 있습니다.

00:05:24.000 --> 00:05:28.000
아마도 당신의 앱은 사용자의 연락처에 대한 네트워크 플레이를 지원할 수 있습니다.

00:05:28.000 --> 00:05:33.000
그리고 언제나처럼, 사용자의 사생활을 존중하는 것이 가장 중요하다.

00:05:33.000 --> 00:05:41.000
예를 들어, 통신 앱은 해당 연락처가 통화 기록에 나타나는 빈도에 따라 연락처를 호출하는 명령을 높일 수 있습니다.

00:05:41.000 --> 00:05:44.000
이런 종류의 정보는 항상 장치에 있어야 한다.

00:05:44.000 --> 00:05:53.000
앱 내에서 동일한 메소드를 호출하여 데이터 객체를 생성하고, 파일에 쓰고, 앞서 표시된 대로 수집하기만 하면 됩니다.

00:05:53.000 --> 00:05:57.000
훈련 데이터가 생성되면, 단일 로케일에 바인딩됩니다.

00:05:57.000 --> 00:06:05.000
단일 스크립트 내에서 여러 로케일을 지원하려면, NSLocalizedString과 같은 표준 현지화 기능을 사용할 수 있습니다.

00:06:05.000 --> 00:06:08.000
이제, 앱에 모델을 배포하는 것에 대해 이야기해 봅시다.

00:06:08.000 --> 00:06:19.000
먼저, 이전 단계에서 생성한 파일을 수락하고 나중에 사용할 두 개의 새 파일을 생성하는 새로운 메서드인 prepareCustomLanguageModel을 호출해야 합니다.

00:06:19.000 --> 00:06:30.000
이 메소드 호출은 많은 양의 관련 대기 시간을 가질 수 있으므로, 메인 스레드를 호출하고 로딩 화면과 같은 일부 UI 뒤에 대기 시간을 숨기는 것이 가장 좋습니다.

00:06:30.000 --> 00:06:35.000
때때로, 사용자의 개인 정보를 존중하기 위해 생성된 장치에 데이터를 보관해야 합니다.

00:06:35.000 --> 00:06:40.000
LM 사용자 지정은 네트워크를 통해 사용자 지정 데이터를 전송하지 않아 이를 지원합니다.

00:06:40.000 --> 00:06:44.000
모든 맞춤형 요청은 장치에서 엄격하게 서비스됩니다.

00:06:44.000 --> 00:06:50.000
앱이 음성 인식 요청을 구성할 때, 먼저 인식이 장치에서 실행되도록 강제합니다.

00:06:50.000 --> 00:06:55.000
그렇게 하지 않으면 사용자 지정 없이 요청을 서비스하게 됩니다.

00:06:55.000 --> 00:06:59.000
그런 다음 언어 모델을 요청 객체에 첨부합니다.

00:06:59.000 --> 00:07:03.000
이제, 내 앱에서 LM 사용자 지정이 켜진 상태에서...

00:07:03.000 --> 00:07:06.000
알빈 카운터 도박을 하세요.

00:07:06.000 --> 00:07:08.000
내 관습 용어도 작동해.

00:07:08.000 --> 00:07:12.000
위나워 변형을 연주하세요.

00:07:12.000 --> 00:07:19.000
언어 모델을 사용자 정의함으로써, 나는 인식기를 내 애플리케이션의 도메인으로 조정했고, 그것이 어떻게 작동하는지 어느 정도 제어할 수 있었다.

00:07:19.000 --> 00:07:24.000
가장 중요한 것은, 내 앱의 음성 인식 정확도를 향상시켰다는 것이다.

00:07:24.000 --> 00:07:32.000
이제 음성 프레임워크는 더 많은 앱과 더 많은 사용자에게 적용될 수 있으므로, 훨씬 더 강력하고 더 나은 경험을 만드는 데 사용할 수 있습니다.

00:07:32.000 --> 00:07:38.000
언어 모델 사용자 지정은 음성 인식기를 향상시키고 앱에 맞게 사용자 지정할 수 있는 방법을 제공합니다.

00:07:38.000 --> 00:07:42.000
나는 네가 그것으로 성취할 모든 놀라운 것들을 보게 되어 정말 신나.

00:07:42.000 --> 00:07:44.000
감사합니다, 그리고 센터를 위해 뛰는 것을 잊지 마세요.

00:07:44.000 --> 23:59:59.000
♪ ♪

