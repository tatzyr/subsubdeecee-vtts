WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:13.000
아담: 환영합니다, 저는 VisionKit의 엔지니어인 아담입니다.

00:00:13.000 --> 00:00:20.000
팀이 올해 작업해 온 새로운 기능과 API에 대해 이야기하기 위해 오늘 당신과 함께 시간을 보내게 되어 기쁩니다.

00:00:20.000 --> 00:00:31.000
요약하자면, 작년에 VisionKit에 라이브 텍스트 지원이 추가되어 앱의 이미지에 대한 텍스트 선택, 번역, QR 지원 등과 같은 상호 작용을 가능하게 했습니다.

00:00:31.000 --> 00:00:44.000
VisionKit은 또한 DataScannerViewController를 도입했습니다. 데이터 스캐너는 라이브 카메라 피드를 사용하여 특정 텍스트 유형과 기계 판독 가능한 코드의 많은 변형을 캡처하는 간단하고 완전한 기능을 갖춘 방법을 제공합니다.

00:00:44.000 --> 00:00:50.000
이러한 API에 대한 정보는 이 WWDC22 세션에 포함되어 있습니다.

00:00:50.000 --> 00:01:00.000
개발자들의 반응은 놀라웠고, 올해 VisionKit이 Subject Lifting과 Visual Look Up 모두에 대한 지원을 추가하고 있다고 발표하게 되어 기쁩니다.

00:01:00.000 --> 00:01:09.000
텍스트 선택을 위한 새로운 라이브 텍스트 API, Catalyst에 대한 확장된 플랫폼 지원, 네이티브 macOS 앱을 위한 컨텍스트 메뉴 통합도 있습니다.

00:01:09.000 --> 00:01:13.000
그리고 이제 나는 주제 리프팅을 시작할 거야.

00:01:13.000 --> 00:01:26.000
이미지의 주제를 간단히 길게 누르면, 그것은 주변으로부터 그것을 들어 올리고 이 아름다운 애니메이션 빛으로 강조되며, 나는 그것을 공유하거나 비주얼 룩업을 호출할 수 있는 몇 가지 옵션이 제시된다.

00:01:26.000 --> 00:01:35.000
iOS 17의 새로운 기능, 이제 들어올린 대상을 사용하여 반짝이는, 푹신한 등과 같은 재미있는 효과로 스티커를 만들어 친구 및 가족과 공유할 수 있습니다.

00:01:35.000 --> 00:01:40.000
이제 좋은 소식은, 주제 리프팅을 통합하는 것이 매우 간단하다는 것이다.

00:01:40.000 --> 00:01:44.000
사실, 당신이 이미 끝났을 가능성이 높습니다.

00:01:44.000 --> 00:01:50.000
여기 제가 이미지를 분석하고 상호 작용에 설정한 작년 비디오와 동일한 코드 스니펫이 있습니다.

00:01:50.000 --> 00:01:54.000
하지만 지금은 코드 변경 없이 주제 리프팅을 지원합니다.

00:01:54.000 --> 00:01:56.000
더 탐구해 봅시다.

00:01:56.000 --> 00:02:00.000
제가 분석기 구성에 특별한 것을 전달하지 않는다는 것을 주목하세요.

00:02:00.000 --> 00:02:10.000
이것은 힘과 성능을 보존하기 위해, 주제 리프팅 분석은 초기 분석이 완료된 후 상호 작용에 의해 별도로 처리되기 때문이다.

00:02:10.000 --> 00:02:18.000
iOS의 경우 이 프로세스는 몇 초 동안 화면에 표시된 후에 발생하며, macOS의 경우 메뉴가 처음 나타날 때 발생합니다.

00:02:18.000 --> 00:02:22.000
이것은 사용자가 많은 사진을 스와이프하는 경우를 처리할 필요가 없다는 것을 의미합니다.

00:02:22.000 --> 00:02:25.000
상호 작용이 당신을 위해 이것을 처리할 것입니다.

00:02:25.000 --> 00:02:33.000
적절한 상호 작용 유형 세트가 있는지 확인하기만 하면 됩니다. 이 경우 자동이며 나머지는 상호 작용에 의해 처리됩니다.

00:02:33.000 --> 00:02:38.000
주제 리프팅 호환 가능한 상호 작용 유형을 좀 더 자세히 살펴봅시다.

00:02:38.000 --> 00:02:45.000
자동은 텍스트 상호 작용, 주제 리프팅 등을 결합하여 기본 제공 경험을 제공합니다.

00:02:45.000 --> 00:02:56.000
텍스트 선택이나 데이터 검출기가 아닌 주제 리프팅만 원하는 경우, 상호 작용 유형을 .imageSegmentation으로 설정하거나 다른 유형과 결합할 수 있습니다.

00:02:56.000 --> 00:03:07.000
그리고 마지막으로, Subject Lifting이 앱에 의미가 없지만 iOS 16의 이전 자동 동작을 원한다면, 문제 없습니다. 새로운 유형인 .automaticTextOnly를 사용할 수 있습니다.

00:03:07.000 --> 00:03:13.000
이것은 텍스트 선택 및 데이터 탐지기와 같은 기능을 제공하지만, 피사체 리프팅은 제공하지 않습니다.

00:03:13.000 --> 00:03:23.000
VisionKit과 Vision 모두에서 이 놀라운 신기술에 대한 고급 주제를 배우고 싶다면 주제 리프팅에 대한 자세한 세션이 있습니다.

00:03:23.000 --> 00:03:28.000
올해 VisionKit은 또한 Visual Look Up을 지원합니다.

00:03:28.000 --> 00:03:35.000
Visual Look Up은 사용자가 애완동물, 자연, 랜드마크, 예술 및 미디어에 대해 쉽게 식별하고 배울 수 있게 해준다.

00:03:35.000 --> 00:03:42.000
그리고 iOS 17에서 Visual Look Up은 음식, 제품, 표지판 및 기호를 포함한 추가 도메인을 지원합니다.

00:03:42.000 --> 00:03:46.000
이제, 마침내, 세탁 태그에 있는 그 기호들이 무엇을 의미하는지 쉽게 찾을 수 있습니다.

00:03:46.000 --> 00:03:49.000
내 말은, 네가 나한테 물어본다면 꽤 멋져.

00:03:49.000 --> 00:03:55.000
Visual Look Up 가용성은 언어를 기반으로 하며, 이러한 언어에서 사용할 수 있습니다.

00:03:55.000 --> 00:03:59.000
후드 아래를 잠깐 들여다보고, Visual Look Up이 어떻게 작동하는지 살펴봅시다.

00:03:59.000 --> 00:04:02.000
그건 사실 두 부분으로 구성된 과정이야.

00:04:02.000 --> 00:04:07.000
초기 처리는 분석 시간에 장치에서 완전히 수행됩니다.

00:04:07.000 --> 00:04:15.000
분석기 구성에 .visualLookUp 유형이 있는 경우, Visual Look Up은 결과의 경계 상자와 최상위 도메인을 찾습니다.

00:04:15.000 --> 00:04:18.000
예를 들어, 그것이 고양이, 책 또는 식물이라면.

00:04:18.000 --> 00:04:22.000
이 단계는 또한 특징 추출을 포함한다.

00:04:22.000 --> 00:04:32.000
사용자가 객체를 찾도록 요청하면, 기능 추출의 도메인과 이미지 임베딩이 추가 처리를 위해 서버로 전송됩니다.

00:04:32.000 --> 00:04:40.000
이제 Visual Look Up이 어떻게 작동하는지 알았으니, 어떻게 사용하는지, 그리고 앱에 추가하기 위해 어떤 조치를 취해야 하는지 빠르게 살펴봅시다.

00:04:40.000 --> 00:04:43.000
비주얼 룩업은 두 가지 다른 방법으로 호출할 수 있다.

00:04:43.000 --> 00:04:57.000
첫 번째는 피사체 리프팅과 함께, 현재 들어 올려진 피사체에 하나, 단 하나의 상관관계의 시각적 조회 결과가 포함되어 있다면, 조회 옵션이 메뉴에서 제공되며, 이를 선택하면 전체 조회 결과가 표시됩니다.

00:04:57.000 --> 00:05:00.000
VisionKit은 이 상호 작용을 자동으로 처리합니다.

00:05:00.000 --> 00:05:07.000
채택자로서 분석 시간에 .visualLookUp을 분석기 구성에 추가하기만 하면 됩니다.

00:05:07.000 --> 00:05:14.000
둘째, 각 시각적 검색 결과 위에 배지가 배치되는 모달 상호 작용이 있습니다.

00:05:14.000 --> 00:05:22.000
뷰포트를 떠나면 배지가 어떻게 코너로 이동하는지 주목하세요. 사용자는 이 배지를 탭하여 조회 결과를 표시할 수 있습니다.

00:05:22.000 --> 00:05:28.000
이것은 예를 들어 사진 앱의 정보 버튼이나 퀵 룩을 클릭하는 것과 같은 상호 작용입니다.

00:05:28.000 --> 00:05:34.000
이 모드는 .visualLookUp을 상호 작용에서 선호하는InteractionType으로 설정하여 호출됩니다.

00:05:34.000 --> 00:05:38.000
참고: 이 유형은 다른 상호 작용 유형보다 우선합니다.

00:05:38.000 --> 00:05:44.000
예를 들어, 비주얼룩업 모드가 설정된 동시에 텍스트나 데이터 탐지기를 선택할 수 없습니다.

00:05:44.000 --> 00:05:52.000
따라서, 이것은 일반적으로 버튼 또는 이 모드에 들어가고 나가는 다른 맞춤형 방법과 함께 사용됩니다.

00:05:52.000 --> 00:05:57.000
예를 들어, 퀵 룩은 정보 버튼을 사용하여 비주얼 룩업 모드로 들어갑니다.

00:05:57.000 --> 00:06:03.000
이제 기어를 바꾸고 라이브 텍스트뿐만 아니라 데이터 스캐너의 새로운 API와 기능에 대해 논의해 봅시다.

00:06:03.000 --> 00:06:11.000
iOS 16에 도입된 DataScannerViewController는 라이브 카메라 뷰파인더와 함께 OCR을 사용하는 가장 쉬운 방법으로 설계되었습니다.

00:06:11.000 --> 00:06:18.000
iOS 17에서는 광학 흐름 추적과 통화 지원으로 향상되었습니다.

00:06:18.000 --> 00:06:23.000
광학 흐름 추적은 라이브 카메라 경험을 위한 텍스트 추적을 향상시킬 수 있다.

00:06:23.000 --> 00:06:25.000
여기 iOS 16에 있는 것이 있습니다.

00:06:25.000 --> 00:06:30.000
highFrameRateTracking이 활성화된 텍스트를 스캔하고 있습니다.

00:06:30.000 --> 00:06:33.000
그리고 이것은 당신이 광학 흐름 추적으로 얻을 수 있는 것입니다.

00:06:33.000 --> 00:06:37.000
이제 하이라이트는 이전보다 훨씬 더 안정적이고 근거가 있다.

00:06:37.000 --> 00:06:47.000
광학 흐름 추적은 DataScannerViewController를 사용할 때마다 무료로 제공되지만, 기계가 읽을 수 있는 코드가 아닌 텍스트를 인식할 때만 사용할 수 있습니다.

00:06:47.000 --> 00:06:53.000
또한 특정 텍스트 콘텐츠 유형 세트 없이 텍스트를 스캔해야 합니다.

00:06:53.000 --> 00:06:57.000
그리고 마지막으로, 다시 한 번, 높은 프레임 속도 추적이 활성화되었는지 확인하세요.

00:06:57.000 --> 00:07:01.000
그것은, 편리하게, 기본값이다.

00:07:01.000 --> 00:07:12.000
어떻게 구성하든, 데이터 스캐너는 훌륭한 텍스트 추적을 제공합니다; 하지만 사용 사례가 이 구성을 허용한다면, 새로운 광학 흐름 추적은 그것을 더욱 향상시킬 수 있습니다.

00:07:12.000 --> 00:07:18.000
다음으로, 데이터 스캐너에는 사용자가 금전적 가치를 찾고 상호 작용할 수 있는 새로운 옵션이 있습니다.

00:07:18.000 --> 00:07:21.000
활성화하는 것은 믿을 수 없을 정도로 간단하다.

00:07:21.000 --> 00:07:32.000
이메일 주소나 전화번호와 같은 다른 콘텐츠 유형과 마찬가지로 데이터 스캐너의 이니셜라이저에서 텍스트 인식을 지정할 때 텍스트 콘텐츠 유형을 통화로 설정하기만 하면 됩니다.

00:07:32.000 --> 00:07:37.000
이제 나는 빠른 예시와 함께 이 새로운 유형을 더 자세히 살펴볼 것이다.

00:07:37.000 --> 00:07:44.000
데이터 스캐너가 텍스트의 통화를 인식할 때, 그것은 경계와 성적표를 모두 포함한다.

00:07:44.000 --> 00:07:49.000
성적 증명서에는 통화 기호와 금액이 모두 있습니다.

00:07:49.000 --> 00:07:54.000
여기 영수증과 같은 것에서 모든 값의 합계를 찾는 예가 있습니다.

00:07:54.000 --> 00:07:58.000
먼저, 나는 현재 로케일을 사용하여 통화 기호를 얻는다.

00:07:58.000 --> 00:08:07.000
인식된 항목 스트림에서 데이터 스캐너의 결과를 기다리는 동안, 인식된 각 항목을 반복하고 성적표를 가져올 수 있습니다.

00:08:07.000 --> 00:08:13.000
성적 증명서에 제가 관심 있는 통화 기호가 포함되어 있다면, 총 가치를 업데이트하겠습니다.

00:08:13.000 --> 00:08:16.000
그리고 그렇게, 이제 당신은 모든 가치의 합을 갖게 될 것입니다.

00:08:16.000 --> 00:08:23.000
이것은 단순한 예일 뿐이지만, 이것은 매우 강력할 수 있습니다. 저는 당신이 이것으로 무엇을 만들 수 있는지 보게 되어 기쁩니다.

00:08:23.000 --> 00:08:27.000
그리고 이제 나는 라이브 텍스트의 향상에 대해 이야기할 것이다.

00:08:27.000 --> 00:08:36.000
우선, 라이브 텍스트는 태국어와 베트남어를 포함하도록 지원되는 언어를 확장함으로써 더 많은 지역에 오고 있다.

00:08:36.000 --> 00:08:40.000
라이브 텍스트에는 올해 문서 구조 감지를 위한 개선 사항도 포함되어 있습니다.

00:08:40.000 --> 00:08:43.000
문서 구조 탐지? 그게 무슨 뜻이야?

00:08:43.000 --> 00:08:49.000
음, 예를 들어, iOS 16 라이브 텍스트에서 목록 감지를 지원합니다.

00:08:49.000 --> 00:08:57.000
이를 통해 메모와 같은 목록을 이해하는 앱에 목록을 쉽게 복사하여 붙여넣을 수 있으며, 목록 서식이 유지됩니다.

00:08:57.000 --> 00:09:01.000
라이브 텍스트는 숫자나 글머리 기호와 같은 여러 목록 스타일을 처리합니다.

00:09:01.000 --> 00:09:12.000
그리고 이제 라이브 텍스트는 테이블에 대한 동일한 지원을 제공하여 이미지에서 Notes 또는 Numbers와 같은 응용 프로그램으로 구조화된 테이블 데이터를 훨씬 쉽게 얻을 수 있습니다.

00:09:12.000 --> 00:09:18.000
이제 이 표를 숫자에 선택하고, 복사하고, 붙여넣을 수 있으며, 구조가 유지됩니다.

00:09:18.000 --> 00:09:22.000
필요한 경우 세포를 자동으로 병합하는 방법을 주목하세요.

00:09:22.000 --> 00:09:27.000
그리고 그렇게, 나는 이제 몇 번의 클릭만으로 이 정보를 그래프로 시각화할 수 있다.

00:09:27.000 --> 00:09:29.000
좋아.

00:09:29.000 --> 00:09:31.000
그리고 그게 전부가 아니야.

00:09:31.000 --> 00:09:35.000
우리는 또한 라이브 텍스트에 컨텍스트 인식 데이터 탐지기를 추가하고 있습니다.

00:09:35.000 --> 00:09:41.000
이 기능을 위해, 데이터 검출기와 그 시각적 관계는 연락처를 추가할 때 사용됩니다.

00:09:41.000 --> 00:09:53.000
이메일 주소에서 이 연락처를 추가할 때 주변 데이터 탐지기의 추가 정보가 포함되어 이 모든 정보를 한 번에 쉽게 추가할 수 있습니다.

00:09:53.000 --> 00:09:57.000
명함이나 전단지에서 연락처를 추가하는 것이 그 어느 때보다 쉬워졌습니다.

00:09:57.000 --> 00:10:04.000
무료로 받을 수 있는 이러한 훌륭한 기능 외에도, VisionKit에는 텍스트 전용 몇 가지 새로운 API가 있습니다.

00:10:04.000 --> 00:10:12.000
작년에, 당신은 이미지 분석의 성적 증명서 속성에 액세스하여 전체 텍스트 내용을 얻을 수 있었습니다.

00:10:12.000 --> 00:10:20.000
당신의 피드백을 바탕으로, 당신은 이제 일반 및 속성 텍스트, 선택된 범위, 그리고 선택한 텍스트에 쉽게 접근할 수 있습니다.

00:10:20.000 --> 00:10:27.000
또한 새로운 대리자 방법이 있으므로 텍스트 선택이 변경될 때 인식하고 UI를 적절하게 업데이트할 수 있습니다.

00:10:27.000 --> 00:10:31.000
이제 사용자가 선택한 것에 의존하는 기능을 쉽게 추가할 수 있습니다.

00:10:31.000 --> 00:10:38.000
예를 들어, 메뉴 빌더 API를 사용하면 현재 텍스트 선택을 기반으로 알림을 생성하는 메뉴 항목을 삽입할 수 있습니다.

00:10:38.000 --> 00:10:42.000
이미지 분석 상호 작용을 소유한 뷰 컨트롤러에서 시작하세요.

00:10:42.000 --> 00:10:47.000
먼저 선택한 텍스트를 잡고, 비어 있지 않은지 확인하세요.

00:10:47.000 --> 00:10:54.000
그런 다음 선택되었을 때 핸들러를 호출하는 명령을 만들고, 이제 명령을 보유하는 메뉴 객체를 만드세요.

00:10:54.000 --> 00:10:59.000
그리고 마지막으로, 공유 메뉴 옵션 뒤에 그 메뉴를 형제로 삽입하세요.

00:10:59.000 --> 00:11:04.000
이제 복사 및 공유와 같은 시스템 항목과 함께 사용자 지정 메뉴가 있습니다.

00:11:04.000 --> 00:11:08.000
이제 나는 우리의 확장된 플랫폼 지원에 대해 이야기할 것이다.

00:11:08.000 --> 00:11:10.000
그리고 올해, 그것은 모두 맥에 관한 것이다.

00:11:10.000 --> 00:11:16.000
iOS 앱의 라이브 텍스트를 Mac으로 쉽게 가져올 수 있도록 Catalyst 지원을 출시하고 있습니다.

00:11:16.000 --> 00:11:26.000
그리고 네이티브 macOS API와 ImageAnalysisOverlayView를 처음 접한다면, 계속 지켜봐 주세요. 왜냐하면 저는 몇 가지 세부 사항과 채택에 대한 몇 가지 팁을 검토할 것이기 때문입니다.

00:11:26.000 --> 00:11:34.000
마지막으로, 저는 VisionKit을 상황에 맞는 메뉴에 간단하고 원활하게 통합하는 새로운 메뉴 시스템에 대해 이야기할 것입니다.

00:11:34.000 --> 00:11:37.000
촉매 채택은 매우 간단하다.

00:11:37.000 --> 00:11:42.000
Catalyst에서 이미지 분석 상호 작용을 작동시키는 것은 간단한 재컴파일이어야 한다.

00:11:42.000 --> 00:11:53.000
우리는 라이브 텍스트, 주제 리프팅 및 시각적 조회를 지원하지만, 안타깝게도 QR 코드 지원은 Catalyst 환경이나 VisionKit용 기본 macOS API에서 사용할 수 없습니다.

00:11:53.000 --> 00:12:05.000
그러나, 공유 구현이 있다면, Catalyst용 분석기 구성에 .machineReadableCodes를 그대로 두는 것이 완벽하게 안전하며, 작동이 되지 않는다는 것을 알려드리고 싶었습니다.

00:12:05.000 --> 00:12:14.000
또한, Mac에서 이 기능이 필요한 경우 Vision Framework에서 QR 감지 지원을 사용할 수 있습니다.

00:12:14.000 --> 00:12:18.000
이제 저는 네이티브 macOS API로 전환하고 있습니다.

00:12:18.000 --> 00:12:27.000
iOS와 마찬가지로, VisionKit을 채택할 때 알아야 할 두 가지 주요 클래스가 있습니다: ImageAnalyzer와 ImageAnalysisOverlayView.

00:12:27.000 --> 00:12:29.000
먼저, 쉬운 부분.

00:12:29.000 --> 00:12:34.000
Mac의 이미지 분석기 및 분석 프로세스는 iOS와 동일합니다.

00:12:34.000 --> 00:12:41.000
앞서 언급했듯이, 기계 판독 가능한 코드를 제외하고, 모든 것이 동일하며 같은 방식으로 사용됩니다.

00:12:41.000 --> 00:12:51.000
iOS ImageAnalysisInteraction과 macOS의 ImageAnalysisOverlayView의 주요 차이점은 상호 작용이 애플리케이션에 추가되는 방법입니다.

00:12:51.000 --> 00:13:00.000
iOS의 경우, ImageAnalysisInteraction은 앱 뷰 계층에 이미 존재하는 뷰에 추가된 UIInteraction입니다.

00:13:00.000 --> 00:13:03.000
하지만 UIInteraction은 Mac에 존재하지 않습니다.

00:13:03.000 --> 00:13:05.000
그래서 넌 뭐해?

00:13:05.000 --> 00:13:11.000
이 경우, 이름에서 알 수 있듯이, 이미지 분석 오버레이 뷰는 NSView의 하위 클래스입니다.

00:13:11.000 --> 00:13:17.000
이미지 콘텐츠 위의 뷰 계층 구조에 오버레이 뷰를 추가하기만 하면 됩니다.

00:13:17.000 --> 00:13:20.000
예를 들어, 여기에 추가할 수 있습니다.

00:13:20.000 --> 00:13:21.000
아니면 심지어 여기도.

00:13:21.000 --> 00:13:26.000
하지만 가장 간단한 방법은 그것을 내 콘텐츠 보기의 하위 보기로 추가하는 것이다.

00:13:26.000 --> 00:13:38.000
어떤 방법을 선택하든 완벽하게 괜찮지만, 서브뷰로 추가하는 것이 일반적으로 더 간단하고, 콘텐츠 뷰 위치가 변경될 때 오버레이 뷰를 재배치할 필요가 없기 때문에 관리하기가 더 쉽다는 것을 알게 되었습니다.

00:13:38.000 --> 00:13:44.000
그리고 이제 앱에 추가하는 방법과 위치를 알게 되었습니다. 직사각형에 대해 이야기해 봅시다.

00:13:44.000 --> 00:13:51.000
오버레이뷰는 콘텐츠를 호스팅하거나 렌더링하지 않기 때문에, 그 범위와 관련하여 콘텐츠가 어디에 있는지 정확히 알아야 합니다.

00:13:51.000 --> 00:13:58.000
이것은 왼쪽 상단의 원점이 있는 단위 좌표 공간에 있는 contentsRect에 의해 설명된다.

00:13:58.000 --> 00:14:00.000
와, 그건 한 입이었어.

00:14:00.000 --> 00:14:02.000
빠른 예시는 이것을 명확히 하는 데 도움이 될 것이다.

00:14:02.000 --> 00:14:07.000
오버레이 뷰는 imageView 위에 직접 배치되기 때문에, 그들은 같은 경계를 가지고 있다.

00:14:07.000 --> 00:14:10.000
이 직사각형의 경계를 보여줄게.

00:14:10.000 --> 00:14:13.000
그리고 나는 또한 일치하는 내용을 다시 추가할 것이다.

00:14:13.000 --> 00:14:16.000
가장 쉬운 경우는 콘텐츠가 경계와 일치하는 경우이다.

00:14:16.000 --> 00:14:19.000
여기는 단순히 단위 직사각형입니다.

00:14:19.000 --> 00:14:21.000
자, 여기에 맞는 측면이 있습니다.

00:14:21.000 --> 00:14:24.000
이미지뷰의 이 부분에는 이제 그 아래에 콘텐츠가 없습니다.

00:14:24.000 --> 00:14:27.000
그리고 내용 rect에 반영된다.

00:14:27.000 --> 00:14:29.000
그리고 여기 측면 채우기가 있습니다.

00:14:29.000 --> 00:14:36.000
이미지의 이 부분은 더 이상 사용자가 볼 수 없습니다. 여기서 콘텐츠가 어떻게 변경되는지 주목하세요.

00:14:36.000 --> 00:14:38.000
이제, 좋은 소식이 있어.

00:14:38.000 --> 00:14:50.000
iOS의 UIImageView와 마찬가지로, NSImageView를 사용하는 경우 오버레이 보기에서 trackingImageView 속성을 설정하기만 하면 이 모든 것을 자동으로 계산할 수 있습니다.

00:14:50.000 --> 00:14:53.000
NSImageView를 사용하지 않는다면, 걱정하지 마세요.

00:14:53.000 --> 00:15:03.000
대리자 메서드 contentsRect(for overlayView:)를 구현하여 콘텐츠 rect를 제공할 수 있습니다. 오버레이 뷰는 경계가 변경될 때 레이아웃 중에 이를 요청합니다.

00:15:03.000 --> 00:15:10.000
그러나 overlayView에서 setContentsRectNeedsUpdate를 호출하여 수동으로 업데이트를 요청할 수 있습니다.

00:15:10.000 --> 00:15:13.000
좋아, 상황에 맞는 메뉴로 넘어가자.

00:15:13.000 --> 00:15:18.000
여러분 모두가 알고 있듯이, 상황에 맞는 메뉴는 Mac 경험의 큰 부분입니다.

00:15:18.000 --> 00:15:27.000
이제 Live Text, Look Up, Subject Lifting 등과 같은 기능을 위해 VisionKit이 제공하는 기능을 메뉴에 직접 쉽게 추가할 수 있습니다.

00:15:27.000 --> 00:15:30.000
네가 가질 수 있는 한 가지 질문은, 왜?

00:15:30.000 --> 00:15:32.000
macOS 사진 앱을 살펴봅시다.

00:15:32.000 --> 00:15:39.000
이 상징적인 도로 표지판의 텍스트를 마우스 오른쪽 버튼으로 클릭하면, VisionKit 텍스트 메뉴만 표시됩니다.

00:15:39.000 --> 00:15:44.000
만약 그것이 텍스트가 아니라면, 나는 텍스트 항목 없이 대신 앱 메뉴를 제공받을 것이다.

00:15:44.000 --> 00:15:46.000
이건 이상적이지 않아.

00:15:46.000 --> 00:15:51.000
이제 macOS 소노마에서는 항목을 동일한 메뉴로 결합할 수 있습니다.

00:15:51.000 --> 00:15:56.000
메뉴 이벤트가 시작된 위치에 상관없이 텍스트와 이미지 기능을 모두 쉽게 얻을 수 있습니다.

00:15:56.000 --> 00:16:01.000
이것은 사용자에게 훨씬 더 나은 경험이며, 구현하기 쉽다.

00:16:01.000 --> 00:16:04.000
이것이 당신의 앱에서 어떻게 달성될 수 있는지 살펴봅시다.

00:16:04.000 --> 00:16:09.000
이제 새로운 대리자 메소드를 사용할 수 있습니다, overlayview:updatedmenu:forevent:atpoint.

00:16:09.000 --> 00:16:18.000
인수에는 메뉴를 트리거한 이벤트와 오버레이 뷰 경계 좌표 공간의 포인트가 포함되어 있으므로 필요한 모든 메뉴를 만들 수 있습니다.

00:16:18.000 --> 00:16:22.000
거기에서, 당신은 당신이 표시하고 싶은 메뉴를 반환하기만 하면 됩니다.

00:16:22.000 --> 00:16:25.000
기본 구현은 VisionKit 메뉴를 반환합니다.

00:16:25.000 --> 00:16:32.000
그러나, 당신은 그 메뉴에 자신의 항목을 추가하거나, 그 메뉴에서 항목을 가져다가 당신의 메뉴에 추가하고 싶을 수도 있습니다.

00:16:32.000 --> 00:16:38.000
VisionKit 메뉴 항목은 태그로 식별되며, 이러한 태그를 포함하는 구조체가 있습니다.

00:16:38.000 --> 00:16:44.000
우리는 이미지와 주제를 복사하고 공유할 수 있는 몇 가지 항목과 Look Up을 위한 항목이 있습니다.

00:16:44.000 --> 00:16:52.000
우리는 또한 VisionKit이 제공하는 메뉴에 항목을 추가하기 위해 제안된 색인을 찾는 데 사용할 수 있는 특별한 항목이 있지만, 나중에 더 자세히 알아볼 수 있습니다.

00:16:52.000 --> 00:16:55.000
여기 이것이 어떻게 사용되는지에 대한 몇 가지 예가 있습니다.

00:16:55.000 --> 00:17:02.000
기존 메뉴가 있고 내가 관심 있는 모든 것이 copySubject 항목을 추가하는 것이라면, 이렇게 쉽게 추가할 수 있다.

00:17:02.000 --> 00:17:05.000
먼저, 앱 메뉴를 받으세요.

00:17:05.000 --> 00:17:06.000
그럼 당신이 관심 있는 아이템을 받으세요.

00:17:06.000 --> 00:17:09.000
이 경우, copySubject.

00:17:09.000 --> 00:17:11.000
그리고 그것을 메뉴에 넣으세요.

00:17:11.000 --> 00:17:15.000
이제, 아이템은 실제로 유효한 경우에만 사용할 수 있다는 것을 기억하는 것이 중요합니다.

00:17:15.000 --> 00:17:22.000
예를 들어, 주제 상호 작용 가능한 유형이 없다면, copySubject 항목은 메뉴에 없을 것이다.

00:17:22.000 --> 00:17:29.000
또한, 시스템이 제공하는 텍스트 항목의 경우, 해당되는 경우 포함되지만, 모두 태그로 식별할 수 있는 것은 아닙니다.

00:17:29.000 --> 00:17:33.000
원하는 대로 이 아이템들을 사용자 정의할 수도 있습니다.

00:17:33.000 --> 00:17:37.000
예를 들어, 나는 그 항목을 복사 이미지에서 복사 사진으로 바꿨다.

00:17:37.000 --> 00:17:39.000
그리고 이러한 속성을 바꾸는 것에 대해 걱정하지 마세요.

00:17:39.000 --> 00:17:44.000
이 아이템들은 매번 다시 생성되며 원하는 대로 변경할 수 있습니다.

00:17:44.000 --> 00:17:51.000
이제 기존 메뉴에 항목을 추가하는 방법을 다뤘으니, VisionKit 메뉴에 항목을 추가하는 방법의 예를 살펴보려고 합니다.

00:17:51.000 --> 00:17:59.000
앞서 언급했듯이, overlayView는 recommendedAppItems라는 항목을 삽입하기 위해 권장 인덱스에 태그가 있는 항목을 제공합니다.

00:17:59.000 --> 00:18:05.000
이 항목의 색인을 요청하고 그 색인에 항목을 삽입하기만 하면 됩니다.

00:18:05.000 --> 00:18:08.000
이 인덱스를 사용하는 것은 선택 사항이며 필수는 아닙니다.

00:18:08.000 --> 00:18:13.000
그러나, 그것은 당신의 사용자를 위해 일관성을 유지하는 좋은 방법입니다.

00:18:13.000 --> 00:18:16.000
이 메뉴 항목 중 일부는 특별한 특성을 가지고 있다는 것을 알게 될 것입니다.

00:18:16.000 --> 00:18:29.000
예를 들어, 주제 관련 메뉴 항목이 강조 표시되면, 내 고양이 KiKi를 둘러싼 영역이 어두워지고 글로우 애니메이션이 시작되어 복사하거나 공유하기 전에 사용자에게 주제를 나타냅니다.

00:18:29.000 --> 00:18:35.000
VisionKit은 아직 시작되지 않은 경우 주제 분석을 시작하기 위해 트리거로 나타나는 메뉴를 사용합니다.

00:18:35.000 --> 00:18:38.000
이것은 모두 당신을 위해 자동으로 처리됩니다.

00:18:38.000 --> 00:18:46.000
이러한 기능을 제공하기 위해, VisionKit은 업데이트 메뉴 방법에서 반환하는 모든 메뉴의 대리인으로 설정됩니다.

00:18:46.000 --> 00:18:58.000
이전에 이러한 NSMenuDelegate 콜백에 의존했다면, VisionKit은 이제 이전에 사용했던 경우 메뉴 항목의 기능을 유지할 수 있는 자체 위임 콜백을 제공합니다.

00:18:58.000 --> 00:19:00.000
그리고 여기 빠른 팁이 있습니다.

00:19:00.000 --> 00:19:06.000
만약 당신이 이 상황에 있다면, 메뉴가 어디에서 시작되었는지에 따라, 그것은 VisionKit에서 오지 않을 수 있습니다.

00:19:06.000 --> 00:19:10.000
그래서 당신은 기존 구현을 유지하고 싶을 것입니다.

00:19:10.000 --> 00:19:21.000
일반적으로 이 모든 것을 동기화하는 가장 간단한 방법은 OverlayViewDelegate 구현이 필요에 따라 조정하여 일치하는 NSMenuDelegate 구현을 호출하도록 하는 것입니다.

00:19:21.000 --> 00:19:26.000
물론, 이것이 당신의 앱에 의미가 있는지 확인하세요, 하지만 일반적으로, 이것은 보통 트릭을 합니다.

00:19:26.000 --> 00:19:29.000
그리고 그것은 VisionKit의 새로운 기능에 대한 간략한 개요입니다.

00:19:29.000 --> 00:19:38.000
오늘 당신과 함께 Subject Lifting과 Visual Look Up뿐만 아니라 새로운 macOS API 및 관련 정보에 대해 논의하게 되어 기뻤습니다.

00:19:38.000 --> 00:19:44.000
저는 당신이 고객을 기쁘게 하고 놀라게 하기 위해 이 새로운 기능을 어떻게 사용하는지 듣기를 고대하고 있습니다.

00:19:44.000 --> 00:19:48.000
그리고 진지하게, 언제나처럼, 재밌게 놀아!

00:19:48.000 --> 23:59:59.000
고마워!

