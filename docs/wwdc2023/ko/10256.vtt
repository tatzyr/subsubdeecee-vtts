WEBVTT

00:00:00.000 --> 00:00:15.000
안녕하세요, 저는 tvOS 팀의 소프트웨어 엔지니어인 Kevin Tulod입니다.

00:00:15.000 --> 00:00:19.000
그리고 저는 Core Audio 팀의 엔지니어인 Somesh Ganesh입니다.

00:00:19.000 --> 00:00:25.000
이 세션에서, 우리는 당신의 tvOS 앱에 카메라와 마이크 지원을 가져오는 것에 대해 논의할 것입니다.

00:00:25.000 --> 00:00:30.000
tvOS 17은 Apple TV에 연속성 카메라와 마이크를 도입한다.

00:00:30.000 --> 00:00:36.000
이제 iPhone 또는 iPad에서 카메라와 마이크 데이터를 스트리밍하여 tvOS의 입력으로 사용할 수 있습니다.

00:00:36.000 --> 00:00:40.000
이것은 큰 화면을 위한 완전히 새로운 장르의 앱과 경험을 열어줍니다.

00:00:40.000 --> 00:00:50.000
tvOS의 대부분의 앱은 일반적으로 두 가지 범주로 나뉩니다: 영화 및 TV 프로그램 스트리밍과 같은 콘텐츠 재생 앱과 게임.

00:00:50.000 --> 00:01:03.000
연속성 카메라를 사용하면 비디오 및 오디오를 녹화하는 콘텐츠 제작 앱이나 화상 회의 및 라이브 스트리밍과 같은 소셜 앱과 같은 완전히 새로운 tvOS용 앱을 구축할 수 있습니다.

00:01:03.000 --> 00:01:12.000
카메라와 마이크를 기존 스트리밍 앱과 게임에 통합하여 이전 버전의 tvOS에서는 불가능했던 완전히 새로운 기능을 만들 수도 있습니다.

00:01:12.000 --> 00:01:22.000
이 기능은 TV를 위한 다양한 앱 세트를 가능하게 하며, 연속성 카메라와 마이크를 tvOS 앱에 가져오는 방법을 보여드리겠습니다.

00:01:22.000 --> 00:01:27.000
작년에 macOS Ventura는 iPhone을 웹캠으로 사용하기 위해 연속성 카메라를 도입했습니다.

00:01:27.000 --> 00:01:33.000
휴대폰을 Mac에 가까이 가져가기만 하면 카메라와 마이크를 입력 장치로 사용할 수 있습니다.

00:01:33.000 --> 00:01:42.000
macOS의 연속성 카메라에 익숙하지 않다면, WWDC 2022에서 이 주제에 대한 세션을 확인하세요.

00:01:42.000 --> 00:01:50.000
이 세션에서, 저는 먼저 당신의 앱이 카메라와 마이크에 접근하기 위해 tvOS에서 채택할 수 있는 API의 개요로 시작하겠습니다.

00:01:50.000 --> 00:01:58.000
다음으로, 앱이 tvOS에서 연속성 카메라를 채택하여 iPhone 또는 iPad를 카메라와 마이크로 사용하는 방법에 대해 자세히 알아보겠습니다.

00:01:58.000 --> 00:02:07.000
그런 다음 tvOS에서 훌륭한 앱 경험을 구축하는 방법에 대해 간략하게 논의하고, 다른 플랫폼용으로 개발하는 것과 비교할 때 유사점과 차이점을 강조하겠습니다.

00:02:07.000 --> 00:02:15.000
마지막으로, Somesh는 다양한 복잡한 오디오 요구에 대해 앱에서 사용할 수 있는 마이크 API에 대해 논의할 것입니다.

00:02:15.000 --> 00:02:20.000
캡처 장치 API에 대한 개요부터 시작합시다.

00:02:20.000 --> 00:02:27.000
AVFoundation, AVFAudio 및 AudioToolbox를 사용하면 비디오와 오디오를 캡처하기 위해 카메라와 마이크에 액세스할 수 있습니다.

00:02:27.000 --> 00:02:34.000
앱이 특히 AVFoundation의 AVCapture 클래스 제품군과 함께 캡처 장치를 어떻게 사용할 수 있는지 검토해 봅시다.

00:02:34.000 --> 00:02:41.000
먼저, 앱은 카메라와 마이크를 나타내는 AVCaptureDevices와 AVCaptureDeviceInputs를 사용합니다.

00:02:41.000 --> 00:02:47.000
이것들은 캡처와 관련된 모든 것의 주요 객체인 AVCaptureSession에 연결됩니다.

00:02:47.000 --> 00:02:51.000
AVCaptureOutputs는 다양한 방법으로 입력에서 데이터를 렌더링합니다.

00:02:51.000 --> 00:03:00.000
이것들을 사용하여 영화를 녹화하고 사진을 찍거나, 카메라와 마이크 버퍼에 액세스하거나, 입력 장치에서 다른 메타데이터를 얻을 수 있습니다.

00:03:00.000 --> 00:03:05.000
UI에 라이브 카메라 피드를 표시하려면 AVCaptureVideoPreviewLayer를 사용할 수 있습니다.

00:03:05.000 --> 00:03:09.000
이것은 CALayer를 서브클래스하는 특별한 유형의 출력이다.

00:03:09.000 --> 00:03:14.000
그리고 데이터는 AVCaptureConnections를 통해 캡처 입력에서 호환 가능한 출력으로 흐릅니다.

00:03:14.000 --> 00:03:22.000
이러한 캡처 API는 tvOS 17부터 iOS, macOS 및 현재 tvOS에서 사용할 수 있습니다.

00:03:22.000 --> 00:03:30.000
AVFoundation의 캡처 기능을 사용하여 개발하는 것이 처음이라면, developer.apple.com의 캡처 설정 시작 페이지에서 자세히 알아볼 수 있습니다.

00:03:30.000 --> 00:03:36.000
tvOS는 이제 iOS에서 제공되는 것과 동일한 카메라와 마이크 API를 지원합니다.

00:03:36.000 --> 00:03:46.000
이미 iOS용으로 제작된 카메라나 마이크 앱이 있다면, 대부분의 코드는 tvOS에서 작동하지만, 몇 가지 API와 코딩 관행이 다릅니다.

00:03:46.000 --> 00:03:54.000
Apple TV에는 AV 입력이 내장되어 있지 않기 때문에, 카메라와 마이크를 사용하기 전에 앱이 장치 검색을 채택해야 합니다.

00:03:54.000 --> 00:04:01.000
이것은 당신의 앱이 연속성 장치가 나타나고 사라질 때와 같은 엣지 케이스를 처리할 수 있도록 하기 위한 것입니다.

00:04:01.000 --> 00:04:10.000
또한 iOS와 다른 tvOS의 앱 업에 대한 몇 가지 뉘앙스가 있으며, 최고의 tvOS 앱 경험을 위해 이러한 고려 사항을 검토할 것입니다.

00:04:10.000 --> 00:04:20.000
iOS의 동일한 카메라와 마이크 API를 이제 tvOS에서 사용할 수 있기 때문에, 기존 iOS 앱에 tvOS 지원을 제공하는 과정을 안내해드리겠습니다.

00:04:20.000 --> 00:04:24.000
저는 이미 iOS용으로 만들어진 간단한 카메라와 마이크 앱을 가지고 있습니다.

00:04:24.000 --> 00:04:30.000
이 앱에는 사진을 캡처하거나 비디오와 오디오를 녹화하기 위해 카메라와 마이크에 액세스하는 기본 UI가 있습니다.

00:04:30.000 --> 00:04:36.000
이 세션 동안, 저는 새로운 연속성 카메라와 마이크 API를 사용하여 이 앱에 tvOS 지원을 제공할 것입니다.

00:04:36.000 --> 00:04:39.000
그것이 어떻게 만들어졌는지 살펴봅시다.

00:04:39.000 --> 00:04:44.000
Xcode에서, 나는 앱의 UI가 정의된 ContentView를 열 것이다.

00:04:44.000 --> 00:04:49.000
여기서 앱은 화면에서 볼 수 있는 기본 UI 요소의 위치를 지정합니다.

00:04:49.000 --> 00:05:00.000
가장 중요한 것은 AVCaptureVideoPreviewLayer에 연결하여 다른 모든 UI 요소 뒤에 라이브 카메라 미리보기를 표시하는 CameraPreview 보기입니다.

00:05:00.000 --> 00:05:07.000
다음은 AVFoundation의 여러 AVCaptureSession 클래스를 래핑하는 CaptureSession 클래스입니다.

00:05:07.000 --> 00:05:15.000
이 클래스에는 어떤 캡처 입력이 선택되고 데이터가 출력되는 위치를 제어하는 데 사용되는 AVCaptureSession에 대한 속성이 있습니다.

00:05:15.000 --> 00:05:22.000
이 경우, 출력은 ContentView에 표시되는 AVCaptureVideoPreviewLayer입니다.

00:05:22.000 --> 00:05:27.000
CaptureSession 클래스에는 활성 비디오 입력을 설정하는 기능도 있습니다.

00:05:27.000 --> 00:05:37.000
이 기능에서, 앱은 선택한 입력의 유효성을 검사하고, AVCaptureSession을 구성하고, 세션을 시작합니다.

00:05:37.000 --> 00:05:43.000
이것은 AVCaptureDevice에서 ContentView에 표시되는 미리보기 레이어로의 데이터 흐름을 시작합니다.

00:05:43.000 --> 00:05:54.000
이 모든 AVCapture API는 이제 tvOS에서도 사용할 수 있으므로, 앱에서 지원되는 OS로 tvOS를 추가하겠습니다.

00:05:54.000 --> 00:06:06.000
저는 이제 프로젝트 네비게이터에서 프로젝트를 선택하고, 앱의 대상을 강조하고, Apple TV를 지원되는 대상으로 추가하고 있습니다.

00:06:06.000 --> 00:06:09.000
이 시점에서, 그 앱은 tvOS에서 빌드하고 실행할 수 있다.

00:06:09.000 --> 00:06:14.000
그러나, 사용 가능한 입력 장치가 없기 때문에, 그 앱은 별로 하지 않을 것이다.

00:06:14.000 --> 00:06:22.000
이것은 캡처 장치를 찾고 tvOS에서 사용하기 위해 선택하는 과정부터 시작하여 연속성 카메라로 우리를 데려온다.

00:06:22.000 --> 00:06:29.000
AVCapture와 관련된 일을 하기 전에, 앱은 비디오 및 오디오 캡처 장치를 사용할 수 있는 권한이 있는지 확인해야 합니다.

00:06:29.000 --> 00:06:36.000
이것은 앱이 이러한 장치에 액세스해야 하는 이유를 설명할 수 있는 기회를 제공하며, 사용자는 액세스를 수락하거나 거부할 수 있습니다.

00:06:36.000 --> 00:06:40.000
Info.plist에서 카메라와 마이크 사용 키를 설정하는 것을 잊지 마세요.

00:06:40.000 --> 00:06:45.000
이 설명은 승인 메시지가 표시되면 사용자에게 표시됩니다.

00:06:45.000 --> 00:06:51.000
카메라가 내장된 iPhone이나 iPad와 같은 사용자의 개인 장치용 앱을 만드는 데 익숙할 수 있습니다.

00:06:51.000 --> 00:06:57.000
그러나 Apple TV는 여러 사람이 자신의 iCloud 계정을 가지고 공유하는 공동 장치이다.

00:06:57.000 --> 00:07:06.000
공동 장치에서 최고의 경험을 하기 위해, 손님을 포함하여 호환 가능한 장치를 가진 사람은 누구나 장치를 연속성 카메라로 사용할 수 있습니다.

00:07:06.000 --> 00:07:13.000
이것은 사용자가 집, 친구의 집 또는 휴가 임대와 같은 공유 공간에서 앱의 녹화 기능을 사용할 수 있다는 것을 의미합니다.

00:07:13.000 --> 00:07:21.000
그것은 또한 카메라가 언제든지 시스템에서 나타나거나 사라질 수 있다는 것을 의미하며, 당신의 앱은 이러한 경우를 처리할 수 있어야 합니다.

00:07:21.000 --> 00:07:27.000
AVKit은 이제 AVContinuityDevicePickerViewController라는 새로운 뷰 컨트롤러를 제공합니다.

00:07:27.000 --> 00:07:32.000
이 컨트롤러를 사용하여 카메라와 마이크로 사용할 적격 연속성 장치를 선택할 수 있습니다.

00:07:32.000 --> 00:07:40.000
이 뷰 컨트롤러는 Apple TV에 로그인한 모든 사용자를 나열하고 연속성 카메라를 위해 장치를 연결할 수 있습니다.

00:07:40.000 --> 00:07:46.000
손님들이 Apple TV와 페어링하여 연속성 카메라를 위해 iOS 기기를 사용할 수 있는 방법도 있습니다.

00:07:46.000 --> 00:07:51.000
캡처 장치에 액세스할 때, 앱은 먼저 사용할 수 있는 것이 있는지 확인해야 합니다.

00:07:51.000 --> 00:07:58.000
사용 가능한 경우, 캡처 장치를 사용하여 캡처 세션을 시작하고 AVCaptureOutputs로 데이터를 보낼 수 있습니다.

00:07:58.000 --> 00:08:04.000
사용 가능한 것이 없다면, 장치 선택기를 사용하여 사용자에게 관련 UI를 제시하십시오.

00:08:04.000 --> 00:08:08.000
이것은 그들의 장치의 카메라와 마이크를 공유하는 과정을 안내한다.

00:08:08.000 --> 00:08:14.000
장치가 선택되면, 뷰 컨트롤러는 대리인 콜백을 호출하여 장치가 나타났다는 것을 알려드릴 것입니다.

00:08:14.000 --> 00:08:19.000
그런 다음 해당 장치의 가용성을 확인하고 캡처 세션을 계속 시작할 수 있습니다.

00:08:19.000 --> 00:08:24.000
무대 뒤에서, tvOS와 iOS는 이 연결을 구축하기 위해 함께 작동한다.

00:08:24.000 --> 00:08:33.000
선택이 이루어지면, tvOS는 Apple TV와 가까운 곳에서 해당 사용자의 적격 장치를 핑하고 확인을 요청합니다.

00:08:33.000 --> 00:08:37.000
그런 다음 사용자는 모든 알림 장치에서 연결을 수락할 수 있습니다.

00:08:37.000 --> 00:08:45.000
그 시점에서, 카메라와 마이크를 앱에서 사용할 수 있게 되며, 카메라와 마이크 데이터는 스트리밍을 시작할 수 있습니다.

00:08:45.000 --> 00:08:55.000
SwiftUI 앱에서 장치 선택기를 제시하기 위해, AVKit은 tvOS 17의 새로운 연속성DevicePicker 수정자를 제공하여 선택기를 제시합니다.

00:08:55.000 --> 00:09:02.000
프레젠테이션 상태는 다른 콘텐츠 표시 보기 수정자와 마찬가지로 상태 변수에 의해 업데이트됩니다.

00:09:02.000 --> 00:09:08.000
장치가 선택되어 사용할 수 있게 되면, 피커는 AVContinuityDevice로 콜백을 해제하고 호출합니다.

00:09:08.000 --> 00:09:18.000
이 객체에는 iPhone 또는 iPad와 같은 주어진 물리적 장치와 관련된 AVCaptureDevices에 대한 참조가 있습니다.

00:09:18.000 --> 00:09:24.000
장치 선택기는 AVContinuityDevicePickerViewController를 사용하여 UIKit 앱에서도 표시할 수 있습니다.

00:09:24.000 --> 00:09:34.000
이 뷰 컨트롤러는 선택적 수명 주기 이벤트와 AVContinuityDevice가 선택되고 사용 가능할 때 콜백을 제공하는 대리인을 받습니다.

00:09:34.000 --> 00:09:46.000
그러한 장치를 사용할 수 있게 되면, 캡처 장치는 AVCaptureDeviceDiscoverySession 또는 AVCaptureDevice의 KVO 관찰자와 같은 다른 장치 리스너에게도 게시됩니다.

00:09:46.000 --> 00:09:50.000
tvOS에서 유일한 캡처 장치는 연속성 카메라라는 것을 기억하세요.

00:09:50.000 --> 00:09:58.000
이것은 당신의 앱이 카메라와 마이크가 사용할 수 없는 것에서 사용할 수 있는 것으로 전환되는 경우를 처리해야 하며, 그 반대의 경우도 마찬가지입니다.

00:09:58.000 --> 00:10:05.000
모든 플랫폼에서 AVCaptureDevice.systemPreferredCamera를 사용하면 가장 적합한 카메라에 액세스할 수 있습니다.

00:10:05.000 --> 00:10:11.000
이 API는 이제 tvOS에서 사용할 수 있으며 정확히 같은 방식으로 작동합니다.

00:10:11.000 --> 00:10:14.000
이 속성은 카메라 가용성에 따라 업데이트될 것입니다.

00:10:14.000 --> 00:10:25.000
한 번에 하나의 연속성 카메라만 Apple TV에 연결할 수 있기 때문에, nil 값은 사용 가능한 카메라가 없다는 것을 의미하며, nil이 아닌 값은 사용 가능한 연속성 카메라가 있음을 의미합니다.

00:10:25.000 --> 00:10:29.000
키-값 관찰을 사용하여 systemPreferredCamera의 변경 사항을 모니터링할 수 있습니다.

00:10:29.000 --> 00:10:36.000
그리고 tvOS에서, 연결된 캡처 장치는 연속성 카메라 유형이 될 것이다.

00:10:36.000 --> 00:10:44.000
Key-value가 systemPreferredCamera 속성을 관찰할 때, 앱은 카메라 가용성에 따라 있어야 할 상태를 재평가할 수 있습니다.

00:10:44.000 --> 00:10:50.000
카메라를 사용할 수 있게 되면, AVCaptureSession을 시작하여 비디오나 오디오 녹화를 시작할 수 있습니다.

00:10:50.000 --> 00:11:01.000
카메라를 사용할 수 없게 되면, 이전 캡처 세션에서 필요한 분해를 수행하고, 사용자에게 장치를 더 이상 사용할 수 없다는 것을 표시하고, 새 장치를 연결할 수 있는 옵션을 제공해야 합니다.

00:11:01.000 --> 00:11:08.000
연속성 카메라가 Apple TV에 연결되면, 앱은 기존의 많은 카메라 캡처 API에 액세스할 수 있습니다.

00:11:08.000 --> 00:11:17.000
예를 들어, AVCaptureMetadataOutput을 사용하여 감지된 얼굴이나 신체와 같은 프레임별 비디오 메타데이터를 얻을 수 있습니다.

00:11:17.000 --> 00:11:31.000
AVCapturePhotoOutput을 사용하여 고해상도 사진을 캡처하고, AVCaptureMovieFileOutput으로 비디오 및 오디오로 영화를 녹화하고, 비디오 효과를 모니터링하거나 zoomFactor와 같은 카메라 속성을 제어할 수 있습니다.

00:11:31.000 --> 00:11:36.000
이제 연속성 카메라로 tvOS에서 사용할 수 있는 더 많은 카메라 API가 있습니다.

00:11:36.000 --> 00:11:42.000
고급 카메라 캡처 기능과 기술에 대해 깊이 파고드는 이전 비디오를 참조할 수 있습니다.

00:11:42.000 --> 00:11:49.000
그것들은 당신의 앱이 연속성 캡처 장치를 발견하고 선택하기 위해 채택해야 하는 tvOS 전용 API입니다.

00:11:49.000 --> 00:11:54.000
우리가 작업하고 있는 앱에 이 기능을 적용해 봅시다.

00:11:54.000 --> 00:12:02.000
Xcode로 돌아가서, ContentView에서, 우리는 장치 선택기의 프레젠테이션 상태를 제어하기 위해 tvOS의 상태 변수가 필요하다는 것을 알고 있습니다.

00:12:02.000 --> 00:12:12.000
상태 변수를 추가하고, 컴파일러 가드를 사용하여 tvOS에서만 사용되는지 확인하겠습니다.

00:12:12.000 --> 00:12:23.000
ContentView 하단에서, 나는 연속성 카메라 특정 논리를 처리하기 위해 tvOS 전용 확장 프로그램을 만들 것이다.

00:12:23.000 --> 00:12:36.000
그런 다음 계산된 변수를 추가하여 우리가 추가한 상태 변수를 전환하여 장치 선택기를 보여주는 버튼을 만들 것입니다.

00:12:36.000 --> 00:12:41.000
다음으로, 연속성 카메라가 연결될 때 호출될 콜백 핸들러를 추가할 것입니다.

00:12:41.000 --> 00:12:52.000
일단 연결되면, 이것은 카메라를 활성 비디오 입력으로 설정하고, 차례로 캡처 세션을 시작합니다.

00:12:52.000 --> 00:13:03.000
마지막으로, 이미 연결되어 있는 경우를 대비하여 연속성 카메라를 활성화하는 방법을 추가하겠습니다.

00:13:03.000 --> 00:13:10.000
이제 UI에 추가하기 시작합시다.

00:13:10.000 --> 00:13:18.000
뷰 본문에서, 나는 장치 선택기 버튼을 내 뷰에 추가할 것이다.

00:13:18.000 --> 00:13:32.000
그런 다음 continuityDevicePicker 뷰 수정자를 추가하고 이전에 추가된 상태 변수와 콜백 함수에 연결하겠습니다.

00:13:32.000 --> 00:13:46.000
마지막으로, 이미 연결되어 있다면 연결된 연속성 장치를 활성화하려고 시도하는 작업을 추가할 것입니다.

00:13:46.000 --> 00:13:52.000
그리고 그것들은 기존 iOS 카메라 앱에 tvOS 지원을 제공하는 데 필요한 모든 코드 변경 사항입니다.

00:13:52.000 --> 00:13:58.000
이제 Apple TV에서 실행하여 어떻게 생겼는지 봅시다.

00:13:58.000 --> 00:14:03.000
이 앱은 기본 UI로 실행되지만, 아직 카메라를 연결하지 않았기 때문에 카메라 피드가 없습니다.

00:14:03.000 --> 00:14:08.000
장치 선택기를 불러올 수 있도록 추가한 버튼을 선택하겠습니다.

00:14:08.000 --> 00:14:10.000
이것은 나에게 카메라를 연결할 수 있는 옵션을 제공한다.

00:14:10.000 --> 00:14:24.000
저스틴의 사용자를 선택하고 지침에 따라 페어링하겠습니다.

00:14:24.000 --> 00:14:26.000
그리고 연속성 카메라가 연결되어 있습니다!

00:14:26.000 --> 00:14:35.000
이 앱의 tvOS 버전은 iOS와 동일한 공유 코드를 사용하는 모습이며, tvOS에 장치 검색을 추가하기 위한 몇 가지 사소한 변경 사항만 있습니다.

00:14:35.000 --> 00:14:38.000
카메라 API의 기존 사용에는 변화가 없었다.

00:14:38.000 --> 00:14:47.000
나는 심지어 iOS 앱에서처럼 사진을 찍을 수도 있다.

00:14:47.000 --> 00:14:53.000
그리고 그것은 tvOS의 연속성 카메라이다.

00:14:53.000 --> 00:15:02.000
기존 앱을 tvOS에 적용하거나 tvOS 개발을 막 시작하는 경우, 플랫폼의 몇 가지 뉘앙스를 빠르게 요약하고 싶습니다.

00:15:02.000 --> 00:15:05.000
tvOS에서 가장 두드러진 차이점은 사용자 상호 작용이다.

00:15:05.000 --> 00:15:08.000
tvOS에는 직접 터치 이벤트가 없습니다.

00:15:08.000 --> 00:15:15.000
사용자는 리모컨의 스와이프, 방향 화살표 누름 및 기타 버튼을 통해 포커스 엔진을 사용하여 시스템과 상호 작용합니다.

00:15:15.000 --> 00:15:21.000
공동 장치로서, tvOS는 여러 사람이 사용할 수 있으며 여러 사용자와 손님을 지원합니다.

00:15:21.000 --> 00:15:27.000
이것은 당신의 앱이 다른 플랫폼과 다르게 개인 정보를 처리해야 할 수도 있다는 것을 의미합니다.

00:15:27.000 --> 00:15:30.000
마지막으로, tvOS는 고유한 파일 저장 정책을 가지고 있다.

00:15:30.000 --> 00:15:36.000
이것은 비디오나 오디오를 녹음하는 콘텐츠 제작 앱을 작성할 때 특히 중요합니다.

00:15:36.000 --> 00:15:38.000
좀 더 자세히 알아보자.

00:15:38.000 --> 00:15:41.000
디스크 공간은 공유 자원이라는 것을 기억하세요.

00:15:41.000 --> 00:15:55.000
디스크 공간의 주요 소비자는 다음과 같습니다: 제거할 수 없는 운영 체제; 프레임워크와 앱 바이너리, 그 중 일부는 설정이 켜져 있으면 오프로드될 수 있습니다; 그리고 대부분의 공간은 임시 데이터의 캐시로 사용됩니다.

00:15:55.000 --> 00:16:02.000
tvOS 앱은 대부분 매우 큰 캐시가 필요한 스트리밍과 같은 콘텐츠 소비를 위해 만들어졌습니다.

00:16:02.000 --> 00:16:09.000
이 디스크 공간 모델을 유지하면 모든 tvOS 앱에서 최고의 사용자 경험을 보장하는 데 도움이 됩니다.

00:16:09.000 --> 00:16:15.000
iOS에서는 FileManager를 사용하여 데이터를 지속적으로 저장하고 .documentDirectory 경로에 쓸 수 있습니다.

00:16:15.000 --> 00:16:21.000
이 API의 사용은 tvOS에서 권장되지 않습니다.

00:16:21.000 --> 00:16:25.000
OS는 대용량 파일의 지속적인 저장을 허용하지 않습니다.

00:16:25.000 --> 00:16:30.000
헤더에서 사용할 수 있지만, .documentDirectory의 사용은 런타임 오류와 함께 실패할 것이다.

00:16:30.000 --> 00:16:37.000
대신, tvOS용으로 빌드할 때, 앱은 .cachesDirectory만 사용해야 합니다.

00:16:37.000 --> 00:16:40.000
이 디렉토리의 데이터는 앱이 실행되는 동안 사용할 수 있습니다.

00:16:40.000 --> 00:16:45.000
그러나, 이 데이터는 앱 실행 사이에 디스크에서 제거될 수 있다.

00:16:45.000 --> 00:16:54.000
그런 이유로, 클라우드에 업로드하고 디스크에서 더 이상 필요하지 않을 때 삭제하는 것과 같이 가능한 한 빨리 데이터를 다른 곳으로 오프로드하는 것이 좋습니다.

00:16:54.000 --> 00:17:00.000
흥미로운 다중 사용자 사용 사례가 있는 tvOS에서 사용할 수 있는 다른 파일 저장 옵션이 있습니다.

00:17:00.000 --> 00:17:06.000
예를 들어, 사용자별로도 CloudKit을 사용하여 앱 데이터를 iCloud에 저장할 수 있습니다.

00:17:06.000 --> 00:17:14.000
우리는 과거에 tvOS에서 여러 사용자를 위한 저장 옵션을 다루었고 자세한 내용은 해당 비디오를 참조하는 것이 좋습니다.

00:17:14.000 --> 00:17:26.000
tvOS 개발을 처음 접하는 경우, developer.apple.com의 tvOS 앱 계획 페이지를 확인하세요. 이 페이지에서 Apple TV용으로 개발할 때 명심해야 할 다양한 기능과 고려 사항을 살펴볼 수 있습니다.

00:17:26.000 --> 00:17:34.000
그리고 그것이 tvOS 17의 새로운 연속성 카메라 및 장치 검색 API로 훌륭한 tvOS 앱 경험을 구축할 수 있는 방법입니다.

00:17:34.000 --> 00:17:40.000
이제 tvOS 17에서 액세스할 수 있는 다양한 마이크 기능에 대해 이야기해 봅시다.

00:17:40.000 --> 00:17:45.000
앱은 사상 처음으로 tvOS에서 마이크를 사용할 수 있습니다!

00:17:45.000 --> 00:17:51.000
이 기능을 활용하기 위해 앱에서 해야 할 일에 대해 바로 알아봅시다.

00:17:51.000 --> 00:17:55.000
여기 올해 변경 사항에 대한 개요가 있습니다.

00:17:55.000 --> 00:18:00.000
tvOS의 AVFAudio 프레임워크에 오디오 세션이 추가되었습니다.

00:18:00.000 --> 00:18:08.000
iOS와 마찬가지로, 오디오 세션은 앱에서 오디오를 어떻게 사용할 것인지 전달하는 시스템 수준의 인터페이스입니다.

00:18:08.000 --> 00:18:17.000
예를 들어, 중단이나 경로 변경과 같은 알림을 등록하고 처리하고 앱의 카테고리와 모드를 설정합니다.

00:18:17.000 --> 00:18:23.000
녹음 API의 전체 제품군도 iOS에서 tvOS로 옮겨졌다.

00:18:23.000 --> 00:18:28.000
여기에는 AVFAudio와 AudioToolbox 프레임워크의 녹음 API가 포함됩니다.

00:18:28.000 --> 00:18:31.000
오디오 세션부터 시작합시다.

00:18:31.000 --> 00:18:37.000
tvOS 17을 사용하면 앱이 Apple TV에서 몇 가지 다른 마이크 장치를 사용할 수 있습니다.

00:18:37.000 --> 00:18:49.000
이것은 iPhone 또는 iPad와 같은 연속성 마이크 또는 AirPods 또는 tvOS 장치와 직접 페어링할 수 있는 다른 헤드셋과 같은 블루투스 장치일 수 있습니다.

00:18:49.000 --> 00:18:55.000
입력 장치의 유형을 인식하는 방법은 AVAudioSessionPort 유형을 통해서입니다.

00:18:55.000 --> 00:19:03.000
장치 검색 흐름을 거친 후, audioSessionPorts 속성이 있는 AVContinuityDevice에 액세스할 수 있습니다.

00:19:03.000 --> 00:19:11.000
포트 유형을 포함한 오디오 장치에 대한 정보는 이 속성에서 조회할 수 있습니다.

00:19:11.000 --> 00:19:23.000
이제 연속성 마이크를 위한 새로운 포트 유형이 있으며, 입력 장치 유형에 따라 앱에서 특정 작업을 수행하려면 이 포트를 식별자로 사용하는 것이 좋습니다.

00:19:23.000 --> 00:19:31.000
그러나 이 흐름은 AVContinuityDevice에 속하는 iPhone과 iPad에서만 작동합니다.

00:19:31.000 --> 00:19:38.000
또한 기존 오디오 세션 API를 계속 사용하여 시스템에서 사용 가능한 입력을 쿼리할 수 있습니다.

00:19:38.000 --> 00:19:44.000
에어팟이나 블루투스 마이크의 기존 포트 유형은 iOS에서 이월되었습니다.

00:19:44.000 --> 00:19:53.000
캡처 장치 가용성을 바탕으로, 이제 마이크 장치 가용성과 tvOS에서 어떻게 모니터링해야 하는지에 대해 이야기해 봅시다.

00:19:53.000 --> 00:20:00.000
Apple TV에는 마이크가 내장되어 있지 않으며, 앱이 항상 마이크 장치에 액세스할 수 있다는 보장은 없습니다.

00:20:00.000 --> 00:20:13.000
이를 위해, 오디오 세션의 InputAvailable 속성은 이제 사용할 수 있는 마이크 장치가 있을 때와 없을 때 모니터링할 수 있는 키 값 관찰 가능한 지원을 제공합니다.

00:20:13.000 --> 00:20:19.000
마이크 가용성에 대한 역동적인 변화를 위해 이 속성을 듣는 것이 좋습니다.

00:20:19.000 --> 00:20:30.000
이것은 또한 오디오 세션을 활성화하고 I/O를 시작하는 타이밍을 결정하고, 마이크 장치가 시스템에서 나타나거나 사라질 때 앱의 상태를 처리하는 데 도움이 될 수 있습니다.

00:20:30.000 --> 00:20:46.000
다음으로, iOS와 마찬가지로, 녹화 권한 API는 이제 tvOS 17에서 사용자가 이미 앱에 마이크에 대한 액세스 권한을 부여했는지 확인하고, 그렇지 않은 경우 녹화 권한을 요청할 수 있습니다.

00:20:46.000 --> 00:20:54.000
앱이 I/O를 시작하는 동안 실패를 피하기 위해 기록할 수 있는 권한을 확보하는 것이 좋습니다.

00:20:54.000 --> 00:21:06.000
마지막으로 오디오 세션에서 playAndRecord 카테고리와 음성 채팅 및 화상 채팅과 같은 모드를 지원하는 카테고리 및 모드는 이제 tvOS에서도 사용할 수 있습니다.

00:21:06.000 --> 00:21:14.000
헤더인 AVAudioSessionTypes를 참조하여 앱에 가장 적합한 오디오 세션 카테고리와 모드를 결정할 수 있습니다.

00:21:14.000 --> 00:21:19.000
그리고 그것들은 모두 tvOS 17의 새로운 오디오 세션 변경 사항입니다.

00:21:19.000 --> 00:21:25.000
이제, 다양한 레코딩 API 세트와 권장 사용 사례에 대해 이야기해 봅시다.

00:21:25.000 --> 00:21:28.000
먼저, AVAudioRecorder.

00:21:28.000 --> 00:21:40.000
이것은 오디오 파일에 녹음하는 가장 간단한 방법이며, 비실시간 사용 사례를 위해 마이크에 들어오는 모든 것을 녹음하기만 하면 AVAudioRecorder가 선택 사항입니다.

00:21:40.000 --> 00:21:47.000
다양한 인코딩 형식, 특정 파일 형식, 샘플 속도 등으로 구성할 수 있습니다.

00:21:47.000 --> 00:21:50.000
다음으로, 우리는 AVCapture를 가지고 있다.

00:21:50.000 --> 00:22:01.000
케빈이 언급했듯이, 카메라와 마이크가 모두 작동 중인 경우 기존 iOS AVCapture API를 활용하여 기본 녹화 사용 사례에 마이크에 액세스할 수 있습니다.

00:22:01.000 --> 00:22:04.000
AVAudioEngine으로 이동하세요.

00:22:04.000 --> 00:22:12.000
AVAudioEngine은 간단하고 복잡한 오디오 처리 사용 사례를 위해 녹음과 재생을 모두 지원합니다.

00:22:12.000 --> 00:22:22.000
이것의 예로는 마이크에서 사용자의 음성 입력을 분석하고 이 마이크 입력을 재생 트랙과 혼합할 수 있는 가라오케 앱이 될 수 있습니다.

00:22:22.000 --> 00:22:28.000
이제, 앱이 실시간 오디오 I/O 주기와 직접 상호 작용하고 싶은 경우가 있습니다.

00:22:28.000 --> 00:22:33.000
AVAudioEngine은 실시간 인터페이스도 제공합니다.

00:22:33.000 --> 00:22:40.000
앱은 AVAudioSinkNode와 AVAudioSourceNode를 통해 실시간 안전 렌더링 콜백을 제공할 수 있습니다.

00:22:40.000 --> 00:22:45.000
AVAudioEngine으로 음성 처리 기능에 액세스할 수도 있습니다.

00:22:45.000 --> 00:22:53.000
저수준 인터페이스를 다루는 앱의 경우, 해당 iOS 메커니즘도 tvOS로 옮겨졌다.

00:22:53.000 --> 00:22:57.000
비실시간 녹음 사용 사례의 경우, AudioQueue에 연락할 수 있습니다.

00:22:57.000 --> 00:23:08.000
실시간 오디오 I/O 주기와 직접 상호 작용하려면, 기존 AudioUnit API를 통해 오디오 장치 AU RemoteIO 및 AU VoiceIO를 사용할 수 있습니다.

00:23:08.000 --> 00:23:18.000
이 API에 대한 더 자세한 정보를 원하시면, AVFAudio 및 Audio Toolbox 프레임워크에 대한 개발자 웹사이트를 확인하는 것이 좋습니다.

00:23:18.000 --> 00:23:30.000
이제, Apple TV의 재생을 에코 취소해야 하는 마이크 스트림이 필요한 경우, 예를 들어 회의 사용 사례에서 음성 처리 API를 선택하는 것이 좋습니다.

00:23:30.000 --> 00:23:32.000
왜 그런지 얘기해 보자.

00:23:32.000 --> 00:23:44.000
표준 에코 취소 문제와 비교할 때, 녹음과 재생이 동일한 장치에서 발생하는 iPhone에서 tvOS 설정의 새로운 모든 것이 여기에 있습니다.

00:23:44.000 --> 00:23:50.000
연속성 마이크가 활성화된 경로로, 녹음은 iPhone 또는 iPad에서 이루어집니다.

00:23:50.000 --> 00:24:14.000
그러나 재생은 tvOS 장치에서 스트리밍되며 임의의 TV 스피커 세트, 홈 시어터 설정, 사운드바 또는 한 쌍의 스테레오 홈팟에서 재생할 수 있으며, 대부분은 5.1 및 7.1 LPCM과 같은 풍부한 형식을 재생하고 사용자 경험을 향상시키기 위해 자체 오디오 처리를 실행할 수 있습니다.

00:24:14.000 --> 00:24:26.000
이와 함께, 일반적인 Apple TV 설정에서, 사용자는 마이크 장치에서 몇 피트 떨어져 있을 수 있으며, 이 마이크 장치는 이러한 시끄러운 재생 장치에 훨씬 더 가까울 수 있습니다.

00:24:26.000 --> 00:24:38.000
이러한 모든 시나리오는 로컬 환경에서 고품질로 오디오를 캡처하는 동안 Apple TV의 모든 재생을 취소하고 싶은 매우 어려운 에코 제어 문제를 설정합니다.

00:24:38.000 --> 00:24:46.000
이러한 모든 문제를 극복할 수 있도록, tvOS 17은 이제 새로운 음성 처리 및 에코 취소 기술을 갖추고 있습니다.

00:24:46.000 --> 00:25:00.000
입력 노드에서 setVoiceProcessingEnabled를 호출하기만 하면 되는 AVAudioEngine에서 tvOS에서도 사용할 수 있는 기존 iOS API를 채택함으로써 이를 활용할 수 있습니다.

00:25:00.000 --> 00:25:07.000
또한 VoiceProcessingIO 하위 유형을 사용하여 AU VoiceIO 오디오 장치를 통해 이에 액세스할 수 있습니다.

00:25:07.000 --> 00:25:15.000
음성 처리 API와 그들이 제공하는 기능에 대한 자세한 내용은 세션을 참조하십시오. 음성 처리의 새로운 기능은 무엇입니까?

00:25:15.000 --> 00:25:20.000
그리고 그것은 올해 tvOS 17에 새로운 모든 오디오 API입니다.

00:25:20.000 --> 00:25:27.000
이제, 앱으로 돌아가서 이 마이크 기능 중 일부를 활용하는 방법을 살펴봅시다.

00:25:27.000 --> 00:25:34.000
Xcode로 돌아가서, 나는 AudioCapturer 수업을 열 것이다.

00:25:34.000 --> 00:25:41.000
이 클래스는 나머지 앱 코드에서 기본 오디오 API의 모든 뉘앙스를 추상화합니다.

00:25:41.000 --> 00:25:51.000
그것은 내가 이 경우에 사용할 녹음 API인 AVAudioEngine의 자체 인스턴스를 가지고 있다.

00:25:51.000 --> 00:25:57.000
그것은 또한 오디오 세션의 공유 인스턴스를 가지고 있다.

00:25:57.000 --> 00:26:00.000
그리고 이것은 이 수업이 무엇을 하는지에 대한 빠른 통찰력이다.

00:26:00.000 --> 00:26:14.000
높은 수준에서, 활성화 전에 오디오 세션 카테고리와 모드를 설정하고, 기본 AVAudioEngine을 올바른 형식으로 설정합니다...

00:26:14.000 --> 00:26:22.000
그리고 사용자가 제어할 수 있는 토글을 통해 입력 노드에서 음성 처리를 설정합니다.

00:26:22.000 --> 00:26:26.000
나는 이 예에서 비실시간 맥락에서 엔진을 실행하고 있다.

00:26:26.000 --> 00:26:31.000
이제, tvOS를 위해 이것을 수정하기 위해 내가 무엇을 해야 하는지 살펴봅시다.

00:26:31.000 --> 00:26:38.000
이 iOS 앱은 마이크 장치를 항상 사용할 수 있다고 가정하면 tvOS와 같이 빌드됩니다.

00:26:38.000 --> 00:26:51.000
제가 해야 할 일은 오디오 세션을 시작하고 I/O를 시작하기 전에 입력 마이크 장치를 사용할 수 있는지 확인하기 위해 inputAvailable KVO 알림을 듣기 위해 관찰자를 추가하는 것입니다.

00:26:51.000 --> 00:26:59.000
내가 가서 그걸 여기에 추가할게.

00:26:59.000 --> 00:27:15.000
또한 마이크 장치가 시스템에서 나타나거나 사라질 때 앱의 상태를 처리해야 하며, 이는 사용자가 세션 중에 Apple TV에서 휴대폰을 분리하는 것일 수 있습니다.

00:27:15.000 --> 00:27:22.000
이건 이제 내 Apple TV에서 잘 작동할 거야. 실제로 그것을 보자!

00:27:22.000 --> 00:27:25.000
여기, 저는 지금 제 앱의 오디오 모드에 있습니다.

00:27:25.000 --> 00:27:31.000
재생을 눌러 노래를 재생한 다음 내가 말하는 것을 녹음할 수 있다.

00:27:31.000 --> 00:27:37.000
와, 이 노래 정말 멋지다!

00:27:37.000 --> 00:27:39.000
나는 그걸 들을 때 항상 춤추고 싶어.

00:27:39.000 --> 00:27:50.000
그거 재밌었어!

00:27:50.000 --> 00:28:03.000
이제, 우리가 있었던 음성 처리 모드에서, Apple TV에서 재생된 이 노래는 취소되어 앱으로 전송되는 로컬 환경의 오디오만 남게 됩니다.

00:28:03.000 --> 00:28:06.000
와, 이 노래는 정말 멋지다.

00:28:06.000 --> 00:28:13.000
나는 그걸 들을 때 항상 춤추고 싶어.

00:28:13.000 --> 00:28:17.000
그리고 그것은 tvOS의 에코 취소이다.

00:28:17.000 --> 00:28:21.000
그리고 그건 포장이야! 우리가 겪은 일을 요약해 봅시다.

00:28:21.000 --> 00:28:27.000
우리는 이 기능을 높은 수준으로 소개하고 tvOS에서 잠금 해제되는 새로운 장르의 앱에 대해 이야기했습니다.

00:28:27.000 --> 00:28:34.000
그런 다음 우리는 장치 선택기를 제시하고 연속성 장치를 선택하기 위한 새로운 장치 검색 API에 대해 논의했습니다.

00:28:34.000 --> 00:28:39.000
우리는 현재 tvOS에서 사용할 수 있는 카메라와 마이크 API를 검토했습니다.

00:28:39.000 --> 00:28:49.000
그리고 마지막으로, 우리는 tvOS용으로 빌드하기 위해 기존 카메라와 마이크 앱을 적용하여 가능한 한 많은 코드를 공유하고 장치 검색만 추가했습니다.

00:28:49.000 --> 00:28:53.000
우리는 또한 tvOS와 관련된 몇 가지 고려 사항을 요약했다.

00:28:53.000 --> 00:28:58.000
tvOS 앱에 카메라와 마이크 지원을 제공하게 되어 매우 기쁩니다.

00:28:58.000 --> 00:29:03.000
우리는 당신이 이 기능으로 이 플랫폼에서 개발할 앱을 빨리 보고 싶습니다!

00:29:03.000 --> 00:29:04.000
고마워.

00:29:04.000 --> 23:59:59.000
.

