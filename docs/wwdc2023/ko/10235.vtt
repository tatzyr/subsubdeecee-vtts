WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:16.000
줄리안: 안녕하세요, "음성 처리의 새로운 기능"에 오신 것을 환영합니다. 저는 코어 오디오 팀의 줄리안입니다.

00:00:16.000 --> 00:00:25.000
Voice over IP 애플리케이션은 사람들이 동료, 친구 및 가족과 계속 연결될 수 있도록 그 어느 때보다도 중요해졌다.

00:00:25.000 --> 00:00:31.000
음성 채팅의 오디오 품질은 훌륭한 사용자 경험을 제공하는 데 중요한 역할을 한다.

00:00:31.000 --> 00:00:39.000
모든 상황에서 훌륭하게 들리는 오디오 처리를 구현하는 것은 중요하지만 도전적이다.

00:00:39.000 --> 00:00:56.000
그렇기 때문에 Apple은 음성 처리 API를 제공하여 모든 사람이 어떤 종류의 음향 환경에 있는지, 어떤 Apple 제품을 사용하고 있는지, 어떤 오디오 액세서리에 연결되어 있는지에 관계없이 앱에서 채팅할 때 항상 최상의 오디오 경험을 즐길 수 있습니다.

00:00:56.000 --> 00:01:03.000
Apple의 음성 처리 API는 자체 FaceTime 및 Phone 앱을 포함한 많은 앱에서 널리 사용됩니다.

00:01:03.000 --> 00:01:14.000
음성 채팅 오디오를 향상시키기 위해 에코 취소, 소음 억제, 자동 게인 제어를 포함한 동급 최고의 오디오 신호 처리를 제공합니다.

00:01:14.000 --> 00:01:25.000
그 성능은 고유한 음향 특성을 설명하기 위해 각 유형의 오디오 장치와 함께 각 Apple 제품 모델에 대한 음향 엔지니어에 의해 조정됩니다.

00:01:25.000 --> 00:01:37.000
Apple의 음성 처리 API를 선택하면 사용자는 표준, 음성 격리 및 와이드 스펙트럼을 포함한 앱의 마이크 모드 설정을 완벽하게 제어할 수 있습니다.

00:01:37.000 --> 00:01:43.000
Voice over IP 애플리케이션에 Apple의 음성 처리 API를 사용하는 것이 좋습니다.

00:01:43.000 --> 00:01:47.000
애플의 음성 처리 API는 두 가지 옵션으로 제공됩니다.

00:01:47.000 --> 00:01:56.000
첫 번째 옵션은 AUVoiceProcessingIO라고도 알려진 AUVoiceIO라는 I/O 오디오 장치입니다.

00:01:56.000 --> 00:02:02.000
이 옵션은 I/O 오디오 장치와 직접 상호 작용해야 하는 앱을 위한 것입니다.

00:02:02.000 --> 00:02:13.000
두 번째 옵션은 AVAudioEngine이며, 더 구체적으로 AVAudioEngine의 "음성 처리" 모드를 활성화합니다.

00:02:13.000 --> 00:02:17.000
AVAudioEngine은 더 높은 수준의 API이다.

00:02:17.000 --> 00:02:23.000
일반적으로 사용하기 쉽고 오디오로 작업할 때 작성해야 하는 코드의 양을 줄입니다.

00:02:23.000 --> 00:02:28.000
두 옵션 모두 동일한 음성 처리 기능을 제공합니다.

00:02:28.000 --> 00:02:30.000
자, 새로운 게 뭐야?

00:02:30.000 --> 00:02:35.000
우리는 처음으로 tvOS에서 음성 처리 API를 사용할 수 있도록 하고 있습니다.

00:02:35.000 --> 00:02:42.000
그것에 대한 자세한 내용은 "tvOS용 연속성 카메라 발견" 세션을 확인하세요.

00:02:42.000 --> 00:02:55.000
우리는 또한 음성 처리에 대한 더 많은 제어를 제공하고 새로운 기능을 구현할 수 있도록 AUVoiceIO와 AVAudioEngine에 몇 가지 새로운 API를 추가하고 있습니다.

00:02:55.000 --> 00:03:04.000
첫 번째 API는 다른 오디오의 더킹 동작을 제어하는 데 도움이 됩니다. 그리고 그것이 무엇을 의미하는지 잠시 후에 설명하겠습니다.

00:03:04.000 --> 00:03:10.000
두 번째 API는 앱에 음소거된 토커 감지 기능을 구현하는 데 도움을 주는 것입니다.

00:03:10.000 --> 00:03:16.000
이 세션에서, 나는 이 두 개의 새로운 API의 세부 사항에 초점을 맞출 것이다.

00:03:16.000 --> 00:03:27.000
제가 이야기하고 싶은 첫 번째 API는 "다른 오디오 더킹"입니다. 이 API에 뛰어들기 전에, 먼저 다른 오디오가 무엇이고 왜 더킹이 중요한지 설명하겠습니다.

00:03:27.000 --> 00:03:33.000
Apple의 음성 처리 API를 사용할 때, 재생 오디오에 무슨 일이 일어나고 있는지 살펴봅시다.

00:03:33.000 --> 00:03:41.000
당신의 앱은 Apple의 음성 처리로 처리되고 출력 장치로 재생되는 음성 채팅 오디오 스트림을 제공하고 있습니다.

00:03:41.000 --> 00:03:46.000
그러나, 동시에 재생되는 다른 오디오 스트림이 있을 수 있다.

00:03:46.000 --> 00:03:55.000
예를 들어, 앱은 음성 처리 API를 통해 렌더링되지 않은 다른 오디오 스트림을 재생할 수 있습니다.

00:03:55.000 --> 00:04:00.000
앱과 동시에 오디오를 재생하는 다른 앱도 있을 수 있습니다.

00:04:00.000 --> 00:04:13.000
앱의 음성 오디오 스트림 이외의 모든 오디오 스트림은 Apple의 음성 처리에 의해 "기타 오디오"로 간주되며, 음성 오디오는 출력 장치로 재생되기 전에 다른 오디오와 혼합됩니다.

00:04:13.000 --> 00:04:19.000
음성 채팅 앱의 경우, 일반적으로 재생 오디오의 주요 초점은 음성 채팅 오디오입니다.

00:04:19.000 --> 00:04:26.000
그것이 우리가 음성 오디오의 명료성을 향상시키기 위해 다른 오디오의 볼륨 레벨을 피하는 이유입니다.

00:04:26.000 --> 00:04:31.000
과거에, 우리는 다른 오디오에 고정된 양의 더킹을 적용했다.

00:04:31.000 --> 00:04:39.000
이것은 대부분의 앱에서 잘 작동했으며, 앱이 현재 더킹 동작에 만족한다면, 아무것도 할 필요가 없습니다.

00:04:39.000 --> 00:04:48.000
그러나, 우리는 일부 앱이 더킹 동작을 더 많이 제어하고 싶어 한다는 것을 알고 있으며, 이 API는 당신이 그것을 달성하는 데 도움이 될 것입니다.

00:04:48.000 --> 00:04:55.000
먼저 AUVoiceIO에 대한 이 API를 살펴보고, 나중에 AVAudioEngine에 접속하겠습니다.

00:04:55.000 --> 00:05:00.000
AUVoiceIO의 경우, 이것은 다른 오디오 더킹 구성의 구조체이다.

00:05:00.000 --> 00:05:15.000
그것은 더킹의 두 가지 독립적인 측면에 대한 제어를 제공합니다 - 더킹 스타일; 즉, mEnableAdvancedDucking, 그리고 더킹의 양, 즉 mDuckingLevel입니다.

00:05:15.000 --> 00:05:19.000
mEnableAdvancedDucking의 경우, 기본적으로 이것은 비활성화되어 있습니다.

00:05:19.000 --> 00:05:29.000
일단 활성화되면, 채팅 참가자 양쪽의 음성 활동 존재에 따라 더킹 레벨을 동적으로 조정합니다.

00:05:29.000 --> 00:05:37.000
즉, 양쪽에서 사용자가 말할 때 더 많은 더킹을 적용하고, 어느 쪽도 말할 때 더킹을 줄인다.

00:05:37.000 --> 00:05:51.000
이것은 FaceTime SharePlay의 더킹과 매우 유사하며, FaceTime의 어느 쪽도 이야기하지 않을 때 미디어 재생 볼륨이 높지만, 누군가가 말하기 시작하자마자 미디어 재생 볼륨이 줄어듭니다.

00:05:51.000 --> 00:05:54.000
다음으로, mDuckingLevel.

00:05:54.000 --> 00:06:01.000
네 가지 수준의 컨트롤이 있습니다: 기본값(기본값), 최소(최소), 중간(중간), 최대(최대).

00:06:01.000 --> 00:06:09.000
기본(기본) 덕팅 레벨은 우리가 적용했던 것과 같은 양의 덕킹을 적용하며, 이것은 계속해서 우리의 기본 설정이 될 것입니다.

00:06:09.000 --> 00:06:13.000
최소 (최소) 덕팅 수준은 우리가 적용하는 덕팅의 양을 최소화합니다.

00:06:13.000 --> 00:06:21.000
즉, 이것은 다른 오디오 볼륨이 가능한 한 크게 되기를 원할 때 사용할 설정입니다.

00:06:21.000 --> 00:06:27.000
반대로, 최대 (최대) 더킹 레벨은 우리가 적용하는 더킹의 양을 극대화한다.

00:06:27.000 --> 00:06:35.000
일반적으로 말하자면, 더 높은 더킹 레벨을 선택하는 것은 음성 채팅의 명료성을 향상시키는 데 도움이 된다.

00:06:35.000 --> 00:06:38.000
두 컨트롤은 독립적으로 사용할 수 있다.

00:06:38.000 --> 00:06:45.000
함께 사용하면, 오리 행동을 제어할 수 있는 완전한 유연성을 제공합니다.

00:06:45.000 --> 00:06:52.000
이제 더킹 구성이 무엇을 하는지 다뤘으니, 앱에 적합한 것을 만들 수 있습니다.

00:06:52.000 --> 00:07:01.000
예를 들어, 여기서 나는 고급 더킹을 활성화하고, 최소 더킹 레벨을 선택할 것이다.

00:07:01.000 --> 00:07:13.000
그런 다음 kAUVoiceIOProperty_ OtherAudioDuckingConfiguration을 통해 이 더킹 구성을 AUVoiceIO로 설정하겠습니다.

00:07:13.000 --> 00:07:19.000
AVAudioEngine 클라이언트의 경우, API는 매우 비슷해 보인다.

00:07:19.000 --> 00:07:31.000
다음은 다른 오디오 더킹 구성의 구조체 정의이며, 이것은 더킹 레벨의 열거형 정의입니다.

00:07:31.000 --> 00:07:47.000
AVAudioEngine과 함께 이 API를 사용하려면, 먼저 엔진의 입력 노드에서 음성 처리를 활성화한 다음 더킹 구성을 설정해야 합니다.

00:07:47.000 --> 00:07:52.000
그리고 마지막으로, 입력 노드에 구성을 설정하세요.

00:07:52.000 --> 00:07:58.000
다음으로, 앱에서 매우 유용한 기능을 구현하는 데 도움이 되는 또 다른 API에 대해 이야기해 봅시다.

00:07:58.000 --> 00:08:12.000
온라인 회의에서 당신이 동료나 친구들과 채팅하고 있다고 생각했지만, 잠시 후, 당신은 당신이 음소거되었고 아무도 실제로 당신의 훌륭한 요점이나 재미있는 이야기를 듣지 못했다는 것을 깨달은 적이 있습니까?

00:08:12.000 --> 00:08:14.000
응, 어색해.

00:08:14.000 --> 00:08:23.000
FaceTime이 여기서 하는 것과 같이 앱에서 음소거된 토커 감지 기능을 제공하는 것은 매우 유용합니다.

00:08:23.000 --> 00:08:29.000
그것이 우리가 당신이 음소거된 말하는 사람의 존재를 감지할 수 있도록 API를 제공하는 이유입니다.

00:08:29.000 --> 00:08:38.000
그것은 iOS 15에서 처음 도입되었으며, 이제 macOS 14와 tvOS 17에서 사용할 수 있도록 하고 있습니다.

00:08:38.000 --> 00:08:43.000
다음은 이 API를 사용하는 방법에 대한 높은 수준의 개요입니다.

00:08:43.000 --> 00:08:53.000
먼저, 음소거된 토커가 감지되면 알림을 받으려면 AUVoiceIO 또는 AVAudioEngine에 리스너 블록을 제공해야 합니다.

00:08:53.000 --> 00:09:03.000
당신이 제공하는 리스너 블록은 음소거된 토커가 말을 시작하거나 말을 멈출 때마다 호출된 다음 그러한 알림에 대한 처리 코드를 구현합니다.

00:09:03.000 --> 00:09:12.000
예를 들어, 알림이 사용자가 음소거된 상태에서 말하기 시작한다는 것을 나타내면 사용자에게 음소거를 해제하라는 메시지를 표시할 수 있습니다.

00:09:12.000 --> 00:09:22.000
마지막으로, AUVoiceIO 또는 AVAudioEngine의 음소거 API를 통해 음소거를 구현해야 합니다.

00:09:22.000 --> 00:09:25.000
AUVoiceIO와 함께 몇 가지 코드 예제를 보여드리겠습니다.

00:09:25.000 --> 00:09:28.000
우리는 나중에 AVAudioEngine 예시를 얻을 것이다.

00:09:28.000 --> 00:09:34.000
먼저, 알림을 처리하는 리스너 블록을 준비하세요.

00:09:34.000 --> 00:09:50.000
이 블록에는 AUVoiceIOSpeechActivityEvent 유형의 매개 변수가 있으며, 이는 SpeechActivityHasStarted 또는 SpeechActivityHasEnded의 두 값 중 하나일 수 있습니다.

00:09:50.000 --> 00:09:57.000
음소거 중에 음성 활동 이벤트가 바뀔 때마다 리스너 블록이 호출됩니다.

00:09:57.000 --> 00:10:11.000
블록 내에서, 이것은 당신이 이 이벤트를 처리하는 방법을 구현하는 곳입니다. 예를 들어, SpeechActivityHasStarted 이벤트가 수신되면, 사용자에게 음소거를 해제하라는 메시지를 표시할 수 있습니다.

00:10:11.000 --> 00:10:24.000
이 리스너 블록이 준비되면, kAUVoiceIOProperty_MutedSpeechActivityEventListener를 통해 AUVoiceIO에 블록을 등록하세요.

00:10:24.000 --> 00:10:34.000
사용자가 음소거할 때, 음소거 API kAUVoiceIOProperty_MuteOutput을 통해 음소거를 구현하십시오.

00:10:34.000 --> 00:10:44.000
리스너 블록은 A, 사용자가 음소거되고 B가 음성 활동 상태가 변경되는 경우에만 호출됩니다.

00:10:44.000 --> 00:10:53.000
음성 활동의 지속적인 존재 또는 부족은 중복 알림을 일으키지 않을 것이다.

00:10:53.000 --> 00:10:57.000
AVAudioEngine 고객의 경우, 구현은 매우 유사하다.

00:10:57.000 --> 00:11:06.000
엔진의 입력 노드에서 음성 처리를 활성화한 후, 알림을 처리하는 리스너 블록을 준비하십시오.

00:11:06.000 --> 00:11:13.000
그런 다음 입력 노드에 리스너 블록을 등록하세요.

00:11:13.000 --> 00:11:19.000
사용자가 음소거할 때, AVAudioEngine의 음성 처리 음소거 API를 사용하여 음소거하세요.

00:11:19.000 --> 00:11:27.000
이제, 우리는 AUVoiceIO와 AVAudioEngine으로 음소거된 토커 감지 기능을 구현하는 것을 다루었습니다.

00:11:27.000 --> 00:11:37.000
아직 Apple의 음성 처리 API를 채택할 준비가 되지 않은 분들을 위해, 우리는 당신이 이 기능을 구현하는 데 도움이 되는 대안을 제공하고 있습니다.

00:11:37.000 --> 00:11:47.000
이 대안은 CoreAudio HAL API, 즉 하드웨어 추상화 계층 API를 통해 macOS에서만 사용할 수 있습니다.

00:11:47.000 --> 00:11:55.000
함께 사용할 때 음성 활동을 감지하는 데 도움이 되는 두 가지 새로운 HAL 속성이 있습니다.

00:11:55.000 --> 00:12:06.000
먼저, kAudioDevicePropertyVoiceActivityDetectionEnable을 통해 입력 장치에서 음성 활동 감지를 활성화하십시오.

00:12:06.000 --> 00:12:14.000
그런 다음 kAudioDevicePropertyVoiceActivityDetectionState에 HAL 속성 리스너를 등록하세요.

00:12:14.000 --> 00:12:21.000
이 HAL 속성 리스너는 음성 활동 상태에 변화가 있을 때마다 호출됩니다.

00:12:21.000 --> 00:12:30.000
앱이 속성 리스너로부터 알림을 받으면, 현재 값을 얻기 위해 속성을 쿼리하세요.

00:12:30.000 --> 00:12:35.000
이제 몇 가지 코드 예시로 이것을 안내해드리겠습니다.

00:12:35.000 --> 00:12:46.000
입력 장치에서 음성 활동 감지를 활성화하려면, 먼저 HAL 속성 주소를 구성하십시오.

00:12:46.000 --> 00:12:52.000
그런 다음 속성을 입력 장치에 설정하여 활성화하세요.

00:12:52.000 --> 00:13:05.000
다음으로, 음성 활동 감지 상태 속성에 리스너를 등록하려면, HAL 속성 주소를 구성한 다음, 속성 리스너를 제공하십시오.

00:13:05.000 --> 00:13:12.000
여기서 "listener_callback"은 리스너 함수의 이름입니다.

00:13:12.000 --> 00:13:18.000
이것은 속성 리스너를 구현하는 방법의 예이다.

00:13:18.000 --> 00:13:22.000
청취자는 이 기능 서명을 준수한다.

00:13:22.000 --> 00:13:37.000
이 예에서, 우리는 이 리스너가 하나의 HAL 속성에만 등록되어 있다고 가정합니다. 즉, 호출될 때 어떤 HAL 속성이 변경되었는지에 대한 모호함이 없습니다.

00:13:37.000 --> 00:13:51.000
하나 이상의 HAL 속성에 대한 알림을 위해 동일한 리스너를 등록하는 경우, 먼저 inAddresses 배열을 통해 정확히 무엇이 변경되었는지 확인해야 합니다.

00:13:51.000 --> 00:14:06.000
이 알림을 처리할 때, VoiceActivityDetectionState 속성을 쿼리하여 현재 값을 찾은 다음 해당 값을 처리할 때 자신만의 논리를 구현하십시오.

00:14:06.000 --> 00:14:13.000
이러한 음성 활동 감지 HAL API에 대한 몇 가지 중요한 세부 사항이 있습니다.

00:14:13.000 --> 00:14:24.000
우선, 에코 캔슬링 마이크 입력에서 음성 활동을 감지하므로 음성 채팅 애플리케이션에 이상적입니다.

00:14:24.000 --> 00:14:29.000
둘째, 이 탐지는 프로세스 음소거 상태에 관계없이 작동합니다.

00:14:29.000 --> 00:14:41.000
음소거된 토커 감지 기능을 구현하기 위해, 음성 활동 상태와 음소거 상태를 결합한 추가 논리를 구현하는 것은 앱에 달려 있습니다.

00:14:41.000 --> 00:14:48.000
HAL API 클라이언트가 음소거를 구현하려면 HAL의 프로세스 음소거 API를 사용하는 것이 좋습니다.

00:14:48.000 --> 00:14:58.000
그것은 메뉴 표시줄의 기록 표시등을 억제하고, 사용자에게 그들의 사생활이 음소거 상태에서 보호된다는 확신을 준다.

00:14:58.000 --> 00:15:01.000
오늘 이야기한 것에 대해 요약해 봅시다.

00:15:01.000 --> 00:15:08.000
우리는 Apple의 음성 처리 API와 IP 애플리케이션에 대한 음성을 추천하는 이유에 대해 논의했습니다.

00:15:08.000 --> 00:15:20.000
우리는 다른 오디오의 더킹과 AUVoiceIO 및 AVAudioEngine과 함께 사용하는 방법의 코드 예제로 더킹 동작을 제어하는 API에 대해 이야기했습니다.

00:15:20.000 --> 00:15:28.000
우리는 또한 AUVoiceIO와 AVAudioEngine의 코드 예제로 음소거 토커 감지를 구현하는 방법에 대해 이야기했습니다.

00:15:28.000 --> 00:15:39.000
그리고 Apple의 음성 처리 API를 채택하지 않은 고객을 위해, 우리는 또한 Core Audio HAL API를 사용하여 macOS에서 할 수 있는 대체 옵션을 보여주었습니다.

00:15:39.000 --> 00:15:44.000
우리는 당신이 Apple의 음성 처리 API로 만들 훌륭한 앱을 기대하고 있습니다.

00:15:44.000 --> 00:15:45.000
봐줘서 고마워!

00:15:45.000 --> 23:59:59.000
♪ ♪

