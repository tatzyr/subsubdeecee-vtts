WEBVTT

00:00:00.000 --> 00:00:04.000
♪ 부드러운 기악 힙합 ♪

00:00:04.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:14.000
짐 틸랜더: 안녕하세요, 저는 RealityKit 팀의 엔지니어인 Jim입니다.

00:00:14.000 --> 00:00:22.000
오늘, ARKit 팀의 동료 크리스토퍼가 나와 함께 공간 컴퓨팅을 위한 앱 구축을 시작하는 방법을 안내할 것입니다.

00:00:22.000 --> 00:00:23.000
뛰어들자!

00:00:23.000 --> 00:00:28.000
우리는 공간 컴퓨팅을 위한 새로운 플랫폼에 대해 흥분하고 있다.

00:00:28.000 --> 00:00:35.000
이 플랫폼은 사람들이 사용하고 앱을 개발할 수 있는 친숙한 기반을 기반으로 구축되었습니다.

00:00:35.000 --> 00:00:55.000
그것은 실제 콘텐츠와 가상 콘텐츠를 혼합하고 자연스러운 입력을 사용하여 앱과 상호 작용할 수 있는 새롭고 흥미로운 가능성을 열어주며, 전체 시스템은 사람들의 개인 정보를 보호하도록 설계되어 앱의 경험에 집중할 수 있는 마음의 평화를 제공합니다.

00:00:55.000 --> 00:01:02.000
공간 컴퓨팅의 어휘와 개념을 구축하기 위한 기본 사항에 대해 조금 이야기해 봅시다.

00:01:02.000 --> 00:01:07.000
그 후, 우리는 당신의 앱을 시작하는 다양한 방법을 살펴볼 것입니다.

00:01:07.000 --> 00:01:16.000
그런 다음, 제 동료 크리스토퍼는 공간 컴퓨팅의 세부 사항에 대해 더 깊이 파고들면서 앱을 만드는 방법을 안내할 것입니다.

00:01:16.000 --> 00:01:19.000
이제, 몇 가지 기본 사항을 살펴봅시다.

00:01:19.000 --> 00:01:27.000
먼저 공간 컴퓨팅에서 친숙하고 새로운 UI 개념이 무엇을 의미하는지 알아봅시다.

00:01:27.000 --> 00:01:31.000
기본적으로, 앱은 공유 공간으로 시작됩니다.

00:01:31.000 --> 00:01:36.000
이것은 Mac 데스크톱의 여러 앱과 마찬가지로 앱이 나란히 존재하는 곳이다.

00:01:36.000 --> 00:01:41.000
사람들은 통과를 통해 주변 환경과 연결되어 있다.

00:01:41.000 --> 00:01:44.000
각 앱은 하나 이상의 창을 가질 수 있다.

00:01:44.000 --> 00:01:51.000
이것들은 일반 macOS 창에서 기대하는 것처럼 크기를 조정하고 리플로우할 수 있는 SwiftUI 장면입니다.

00:01:51.000 --> 00:02:01.000
전통적인 보기와 컨트롤뿐만 아니라 3D 콘텐츠를 포함할 수 있어 2D와 3D를 믹스 앤 매치할 수 있습니다.

00:02:01.000 --> 00:02:07.000
사람들은 예상대로 현재 공간에서 원하는 대로 창문을 재배치할 수 있다.

00:02:07.000 --> 00:02:14.000
볼륨을 통해 앱은 정의된 범위에서 3D 콘텐츠를 표시하여 다른 앱과 공간을 공유할 수 있습니다.

00:02:14.000 --> 00:02:19.000
볼륨은 체스판과 같은 3D 콘텐츠를 보여주기에 좋습니다.

00:02:19.000 --> 00:02:24.000
사람들은 우주에서 볼륨을 재배치할 수 있으며, 다른 각도에서 볼 수 있다.

00:02:24.000 --> 00:02:36.000
볼륨은 SwiftUI 장면으로, 익숙한 방식으로 레이아웃을 할 수 있으며, RealityKit의 힘을 사용하여 3D 콘텐츠를 표시합니다.

00:02:36.000 --> 00:02:47.000
때때로 당신은 앱의 몰입 수준을 더 잘 제어하고 싶을 수도 있습니다... 비디오를 보거나 게임을 하는 동안 집중할 수도 있습니다.

00:02:47.000 --> 00:02:57.000
앱의 창, 볼륨 및 3D 개체가 보기 전체에 나타나는 전용 전체 공간을 열어 이를 수행할 수 있습니다.

00:02:57.000 --> 00:03:02.000
전체 공간에서 ARKit의 API를 활용할 수도 있습니다.

00:03:02.000 --> 00:03:14.000
예를 들어, 시스템이 제공하는 제스처 외에도, 사람들의 손 구조를 당신의 경험에 실제로 통합하기 위해 더 자세한 골격 손 추적을 얻을 수 있습니다.

00:03:14.000 --> 00:03:18.000
당신의 앱은 다양한 방식으로 전체 공간을 사용할 수 있습니다.

00:03:18.000 --> 00:03:25.000
현실 세계의 지상 콘텐츠에 패스스루를 사용하고 사람들을 주변 환경과 계속 연결할 수 있습니다.

00:03:25.000 --> 00:03:44.000
그리고 RealityKit을 통해 공간 오디오를 재생하고 3D를 렌더링할 때 장치가 방에 대한 이해를 지속적으로 업데이트하여 시각과 소리를 사람들의 환경에 혼합하여 이러한 가상 물체가 실제로 방에 속한다고 느끼게 한다는 사실을 자동으로 활용할 수 있습니다.

00:03:44.000 --> 00:03:51.000
또한 전체 시야를 채우기 위해 완전히 몰입형 공간으로 렌더링하도록 선택할 수 있습니다.

00:03:51.000 --> 00:04:05.000
이를 통해 앱은 가상 물체의 조명을 사용자 정의하고 오디오 특성을 선택할 수 있는 기능을 통해 앱의 창의적인 의도를 유연하게 전달할 수 있습니다.

00:04:05.000 --> 00:04:11.000
이것들은 공간 컴퓨팅의 기본 요소이다: 창문, 볼륨, 그리고 공간.

00:04:11.000 --> 00:04:17.000
그들은 당신에게 몰입의 연속성을 아우를 수 있는 앱을 만들 수 있는 유연한 도구 세트를 제공합니다.

00:04:17.000 --> 00:04:20.000
크리스토퍼는 나중에 이것에 대해 더 이야기할 것이다.

00:04:20.000 --> 00:04:30.000
이제 공간 컴퓨팅의 기본 요소를 소개했으므로, 창, 볼륨 및 공간과 상호 작용할 수 있는 방법을 살펴봅시다.

00:04:30.000 --> 00:04:36.000
이 플랫폼에서, 우리는 단순히 눈과 손을 사용하여 앱과 상호 작용할 수 있습니다.

00:04:36.000 --> 00:04:43.000
예를 들어, 사람들은 버튼을 보고 손가락을 함께 탭하여 선택하여 버튼과 상호 작용할 수 있다.

00:04:43.000 --> 00:04:49.000
사람들은 또한 3D 공간에서 같은 버튼을 손을 뻗어 물리적으로 만질 수 있다.

00:04:49.000 --> 00:05:02.000
이러한 두 종류의 상호 작용에는 탭, 길게 누르기, 드래그, 회전, 줌 등과 같은 다양한 제스처가 있습니다.

00:05:02.000 --> 00:05:09.000
시스템은 이것들을 자동으로 감지하고 앱이 응답할 수 있도록 터치 이벤트를 생성합니다.

00:05:09.000 --> 00:05:12.000
제스처는 SwiftUI와 잘 통합되어 있다.

00:05:12.000 --> 00:05:17.000
동일한 제스처 API는 RealityKit 엔티티와 원활하게 작동합니다.

00:05:17.000 --> 00:05:23.000
이것은 사람들이 당신의 3D 장면 요소와 직접 쉽게 상호 작용할 수 있게 해준다.

00:05:23.000 --> 00:05:36.000
예를 들어, 이것은 이 3D 모델에 직접 깃발을 놓거나, 가상 지퍼를 제어하는 것을 상상하거나, 상호 작용하고 가상 체스 조각을 고르는 데 유용할 수 있습니다.

00:05:36.000 --> 00:05:45.000
이제 볼링 게임을 하거나 사람들의 손을 가상 클럽으로 바꾸고 싶다면, ARKit의 골격 손 추적을 통해 할 수 있습니다.

00:05:45.000 --> 00:05:54.000
여기서 우리는 탭을 사용하여 테이블에 큐브를 쌓은 다음 손으로 테이블에 부딪히는 방법의 예를 볼 수 있습니다.

00:05:54.000 --> 00:05:59.000
이것은 앱별 손 입력을 경험에 가져올 수 있는 강력한 방법입니다.

00:05:59.000 --> 00:06:15.000
그리고 마지막으로, 시스템은 무선 키보드, 트랙패드 및 접근성 하드웨어의 입력을 자동으로 앱으로 가져오며, 게임 컨트롤러 프레임워크를 사용하면 무선 게임 컨트롤러에 대한 지원을 추가할 수 있습니다.

00:06:15.000 --> 00:06:20.000
함께 협업하고 탐구하는 것은 공간 컴퓨팅의 근본적인 부분이다.

00:06:20.000 --> 00:06:25.000
우리는 SharePlay와 그룹 활동 프레임워크를 통해 이것을 한다.

00:06:25.000 --> 00:06:32.000
이 플랫폼에서, macOS와 마찬가지로, 사람들은 이 퀵 룩 경험과 같은 모든 창을 공유할 수 있습니다.

00:06:32.000 --> 00:06:45.000
사람들이 퀵 룩 3D 모델을 공유할 때, 우리는 참가자들 간의 방향, 규모 및 애니메이션을 동기화하여 다른 위치에 있는 동안 쉽게 협업할 수 있도록 합니다.

00:06:45.000 --> 00:06:56.000
사람들이 그들의 공간에 보여지고 물리적으로 가리키는 것에 대해 협력할 때, SharePlay 세션의 모든 사람이 같은 경험을 하는 것이 중요하다.

00:06:56.000 --> 00:07:05.000
이것은 물체를 몸짓하는 것과 같은 자연스러운 참조를 가능하게 하고 육체적으로 함께 있는 느낌을 강화한다.

00:07:05.000 --> 00:07:09.000
우리는 시스템에 공유 맥락의 개념을 추가했다.

00:07:09.000 --> 00:07:20.000
이 시스템은 SharePlay 세션의 참가자들이 모두 같은 방식으로 콘텐츠를 경험할 수 있도록 이 공유 컨텍스트를 관리합니다.

00:07:20.000 --> 00:07:27.000
공간 페르소나 템플릿을 사용하여 사람들이 당신의 콘텐츠를 경험하는 방식을 더욱 맞춤화할 수 있습니다.

00:07:27.000 --> 00:07:35.000
더 자세히 알아보려면, 이 플랫폼을 위한 공간 공유 재생 경험을 설계하고 구축하는 것에 대한 세션을 시청하세요.

00:07:35.000 --> 00:07:45.000
그 장치가 주변 환경과 사람들에 대한 많은 친밀한 지식을 가지고 있다는 점을 감안할 때, 우리는 사람들의 사생활을 보호하기 위해 많은 건축물을 마련했다.

00:07:45.000 --> 00:07:47.000
그것에 뛰어들자.

00:07:47.000 --> 00:07:59.000
개인 정보 보호는 이 플랫폼의 설계를 안내하는 핵심 원칙이며, 개발자로서 API를 활용하여 장치의 많은 기능을 쉽게 활용할 수 있도록 합니다.

00:07:59.000 --> 00:08:10.000
앱이 센서의 데이터에 직접 액세스할 수 있도록 하는 대신, 시스템은 당신을 위해 그것을 하고 앱에 이벤트와 시각적 단서를 제공합니다.

00:08:10.000 --> 00:08:19.000
예를 들어, 시스템은 3D 공간에서 누군가의 손의 눈 위치와 제스처를 알고 그것을 터치 이벤트로 전달한다.

00:08:19.000 --> 00:08:28.000
또한, 시스템은 관심의 초점이지만 사람이 보고 있는 앱과 통신하지 않을 때 뷰에 호버 효과를 렌더링할 것이다.

00:08:28.000 --> 00:08:35.000
많은 상황에서, 시스템이 제공하는 행동은 앱이 상호 작용에 응답하기에 충분합니다.

00:08:35.000 --> 00:08:44.000
실제로 더 민감한 정보에 접근해야 하는 경우, 시스템은 먼저 사람들에게 허가를 요청할 것입니다.

00:08:44.000 --> 00:08:57.000
예를 들어, 벽과 가구를 감지하기 위해 장면 이해에 액세스하거나 Skeletal Hand Tracking에 액세스하여 사용자 지정 상호 작용을 앱에 가져올 수 있는 사용자 권한을 요청하는 것입니다.

00:08:57.000 --> 00:09:05.000
이제 앱에서 사용할 수 있는 몇 가지 기능을 보았으니, 우리가 그 앱을 어떻게 개발하고 있는지 탐구해 봅시다.

00:09:05.000 --> 00:09:10.000
모든 것은 애플의 통합 개발 환경인 Xcode에서 시작된다.

00:09:10.000 --> 00:09:23.000
Xcode는 프로젝트 관리 지원, UI용 시각 편집기, 디버깅 도구, 시뮬레이터 등을 포함하여 앱 개발을 위한 완벽한 도구 세트를 제공합니다.

00:09:23.000 --> 00:09:34.000
그리고 가장 중요한 것은, Xcode는 또한 앱 개발에 사용할 완전한 프레임워크와 API 세트를 제공하는 플랫폼 SDK와 함께 제공됩니다.

00:09:34.000 --> 00:09:41.000
소스 파일에 SwiftUI 미리보기 공급자가 포함된 경우, 미리보기 캔버스가 Xcode에서 자동으로 열립니다.

00:09:41.000 --> 00:09:52.000
미리보기 캔버스는 3D를 지원하도록 확장되어 애니메이션과 사용자 지정 코드를 포함하여 장면에 대한 RealityKit 코드를 시각화할 수 있습니다.

00:09:52.000 --> 00:10:03.000
이를 통해 반복 시간을 단축할 수 있으며, 라이브 코드를 편집하고 변경 및 조정 결과를 직접 볼 때 앱에 대한 올바른 모양과 느낌을 찾을 수 있습니다.

00:10:03.000 --> 00:10:11.000
궤도 속도와 위성의 크기를 변경하여 위성이 지구를 공전하는 것처럼 보이는지 여기서 조금 실험해 봅시다.

00:10:11.000 --> 00:10:20.000
미리보기는 코드 변경 사항을 반영하여 코드에서 빠른 실험 결과를 쉽게 볼 수 있습니다.

00:10:20.000 --> 00:10:31.000
Xcode Previews에는 또한 3D 레이아웃의 빠른 미리보기를 허용하는 개체 모드가 있습니다. 예를 들어, 레이아웃이 뷰의 경계에 맞는지 확인할 수 있습니다.

00:10:31.000 --> 00:10:39.000
이것은 전통적인 UI와 새로운 3D 비주얼로 긴밀하게 통합된 장면을 구축하는 데 좋습니다.

00:10:39.000 --> 00:10:46.000
Xcode Preview는 앱을 실행하기 직전에 레이아웃을 얻을 수 있는 환상적인 방법을 제공합니다.

00:10:46.000 --> 00:10:50.000
시뮬레이터는 앱과의 상호 작용을 테스트하는 좋은 방법입니다.

00:10:50.000 --> 00:10:57.000
키보드, 마우스 또는 호환 가능한 게임 컨트롤러를 사용하여 장면을 이동하고 둘러볼 수 있습니다.

00:10:57.000 --> 00:11:03.000
그리고 시뮬레이션된 시스템 제스처를 사용하여 앱과 상호 작용하는 것은 쉽습니다.

00:11:03.000 --> 00:11:10.000
시뮬레이터는 각각 낮과 밤 조명이 있는 세 가지 시뮬레이션 장면과 함께 제공됩니다.

00:11:10.000 --> 00:11:13.000
이것은 다른 조건에서 당신의 앱을 쉽게 볼 수 있게 해준다.

00:11:13.000 --> 00:11:23.000
시뮬레이터는 대부분의 앱을 실행 및 디버깅하고 매우 예측 가능한 환경에서 개발 중에 빠르게 반복할 수 있는 좋은 방법입니다.

00:11:23.000 --> 00:11:35.000
우리는 또한 단순히 장면을 보고 버그를 빠르게 이해하고 추적할 수 있도록 디버깅하는 동안 많은 런타임 시각화를 지원하기 위해 Xcode를 확장했습니다.

00:11:35.000 --> 00:11:42.000
여기서 우리는 그 비행기의 의미론적 의미와 장면의 충돌 모양을 포함하여 비행기 추정을 볼 수 있다.

00:11:42.000 --> 00:11:48.000
Xcode의 디버거에서 집중하고 싶은 시각화를 쉽게 전환할 수 있습니다.

00:11:48.000 --> 00:11:54.000
이러한 시각화는 시뮬레이터와 장치 모두에서 잘 작동합니다.

00:11:54.000 --> 00:12:01.000
응용 프로그램의 성능과 반응성을 연마할 때가 되면, 우리는 악기와 같은 친숙한 도구를 가지고 있습니다.

00:12:01.000 --> 00:12:06.000
Instruments는 Xcode에 포함된 강력한 성능 분석 도구입니다.

00:12:06.000 --> 00:12:11.000
인스트루먼트를 사용하여 실행 중인 앱에 대한 실행 가능한 통찰력을 제공할 수 있습니다.

00:12:11.000 --> 00:12:24.000
그리고 공간 컴퓨팅의 경우, Instruments 15에는 새로운 템플릿인 RealityKit Trace가 포함되어 있어 플랫폼의 새로운 행동에 대한 더 깊고 깊은 통찰력을 제공합니다.

00:12:24.000 --> 00:12:36.000
RealityKit Trace 템플릿에는 개발자가 앱의 GPU, CPU 및 시스템 전력 영향을 이해하고 성능 핫스팟을 식별할 수 있는 새로운 도구가 있습니다.

00:12:36.000 --> 00:12:47.000
프레임 병목 현상을 쉽게 관찰하고 이해하고 제출된 총 삼각형이나 시뮬레이션된 RealityKit 엔티티의 수와 같은 중요한 지표로 추적할 수 있습니다.

00:12:47.000 --> 00:12:53.000
이를 통해 잠재적인 성능 문제를 빠르게 찾고 해결할 수 있습니다.

00:12:53.000 --> 00:12:59.000
자세한 내용은 "Meet RealityKit Trace" 세션을 확인하세요.

00:12:59.000 --> 00:13:05.000
우리는 또한 Reality Composer Pro라는 새로운 개발자 도구를 도입했습니다.

00:13:05.000 --> 00:13:09.000
앱의 3D 콘텐츠를 미리 보고 준비할 수 있습니다.

00:13:09.000 --> 00:13:18.000
Reality Composer Pro는 모든 자산과 그들이 당신의 장면에 어떻게 어울리는지에 대한 개요를 얻을 수 있도록 도와줍니다.

00:13:18.000 --> 00:13:27.000
RealityKit에 추가한 새로운 기능은 입자이며, Reality Composer Pro의 워크플로우를 사용하여 작성하고 미리 볼 수 있습니다.

00:13:27.000 --> 00:13:33.000
장면에 입자를 추가하는 것은 움직임, 삶 및 무한한 가능성을 제공합니다.

00:13:33.000 --> 00:13:40.000
구름, 비, 불꽃은 짧은 시간에 만들 수 있는 몇 가지 효과일 뿐입니다.

00:13:40.000 --> 00:13:45.000
장면에 오디오를 추가하고 물체와 연관시키는 것은 쉬운 일이다.

00:13:45.000 --> 00:13:53.000
전체 장면의 모양과 맥락을 고려한 오디오를 공간적으로 미리 볼 수도 있습니다.

00:13:53.000 --> 00:14:02.000
대부분의 가상 물체는 RealityKit의 물리적 기반 자료를 사용하여 다양한 실제 자료를 나타낼 것이다.

00:14:02.000 --> 00:14:11.000
RealityKit은 센서 데이터를 사용하여 실제 조명 정보를 이러한 재료에 공급하여 사람들의 환경에 접지합니다.

00:14:11.000 --> 00:14:19.000
RealityKit에는 또한 앱이 일반적인 시나리오에서 사용할 수 있는 몇 가지 추가 표준 자료가 있습니다.

00:14:19.000 --> 00:14:32.000
창의적인 의도를 전달하기 위해 매우 특별한 필요가 있을 때, 개방형 표준 MaterialX로 Reality Composer Pro에서 사용자 지정 자료를 작성할 수 있습니다.

00:14:32.000 --> 00:14:41.000
코드를 건드리지 않고도 사용하기 쉬운 노드 그래프를 통해 이를 수행할 수 있으며, 뷰포트에서 직접 빠르게 미리 볼 수 있습니다.

00:14:41.000 --> 00:14:48.000
"Reality Composer Pro에서 자료 탐색" 세션에서 이에 대해 자세히 알아볼 수 있습니다.

00:14:48.000 --> 00:14:56.000
3D 콘텐츠에 대해 기분이 좋을 때, 장면을 장치로 보내고 콘텐츠를 직접 테스트할 수 있습니다.

00:14:56.000 --> 00:15:01.000
앱을 만들 필요조차 없기 때문에 반복 시간에 좋습니다.

00:15:01.000 --> 00:15:07.000
더 알아보려면, "Meet Reality Composer Pro" 세션을 시청하세요.

00:15:07.000 --> 00:15:11.000
이용 가능한 또 다른 옵션은 유니티이다.

00:15:11.000 --> 00:15:20.000
유니티는 친숙한 워크플로우와 플러그인 없이 공간 컴퓨팅용 앱을 작성할 수 있는 기능을 제공합니다.

00:15:20.000 --> 00:15:25.000
기존 콘텐츠를 새로운 몰입형 경험으로 끌어올릴 수 있습니다.

00:15:25.000 --> 00:15:32.000
더 알아보려면, 유니티로 몰입형 앱을 작성하는 방법을 다루는 세션을 시청하세요.

00:15:32.000 --> 00:15:40.000
이제 우리가 사용할 수 있는 기본 개념과 도구 중 일부를 이해했으므로, 어떻게 앱 구축을 시작할 수 있는지 봅시다.

00:15:40.000 --> 00:15:52.000
시작하는 방법에는 두 가지가 있습니다. 처음부터 새로운 앱을 공간적으로 디자인하거나 이 새로운 공간 플랫폼에 가져오고 싶은 기존 앱이 있을 수도 있습니다.

00:15:52.000 --> 00:15:55.000
우리가 어떻게 새로운 앱을 만드는지 살펴봅시다.

00:15:55.000 --> 00:16:05.000
처음부터 공간적으로 애플리케이션을 설계하면 공간 컴퓨팅의 새로운 독특한 기능을 빠르게 수용하는 데 도움이 됩니다.

00:16:05.000 --> 00:16:10.000
시작하려면, 이 플랫폼에 새로운 앱 템플릿을 사용할 수 있습니다.

00:16:10.000 --> 00:16:13.000
앱 템플릿에는 두 가지 새로운 중요한 옵션이 있습니다.

00:16:13.000 --> 00:16:19.000
먼저, 초기 장면 유형을 '창' 또는 '볼륨'으로 선택할 수 있습니다.

00:16:19.000 --> 00:16:25.000
이것은 당신을 위한 초기 시작 코드를 생성하며, 나중에 추가 장면을 쉽게 추가할 수 있습니다.

00:16:25.000 --> 00:16:30.000
두 번째 옵션을 사용하면 앱에 몰입형 공간의 진입점을 추가할 수 있습니다.

00:16:30.000 --> 00:16:34.000
기본적으로, 당신의 앱은 공유 공간으로 시작됩니다.

00:16:34.000 --> 00:16:46.000
몰입형 장면 유형을 '스페이스'로 선택하면, 이 전체 공간으로 시작하는 방법을 보여주는 예제 버튼과 함께 두 번째 장면이 앱에 추가됩니다.

00:16:46.000 --> 00:16:59.000
그리고 어시스턴트를 마치면, RealityKit으로 렌더링된 3D 객체와 혼합된 친숙한 버튼을 보여주는 SwiftUI의 초기 작업 앱이 표시됩니다.

00:16:59.000 --> 00:17:05.000
더 자세히 알아보려면, "첫 번째 몰입형 앱 개발" 세션을 시청하세요.

00:17:05.000 --> 00:17:13.000
우리는 또한 코드 샘플을 게시하고 있으며, 각각은 당신이 빠르게 속도를 낼 수 있도록 서로 다른 주제를 보여줍니다.

00:17:13.000 --> 00:17:23.000
데스티네이션 비디오는 3D 비디오와 공간 오디오를 통합한 공유된 몰입형 재생 경험을 구축하는 방법을 보여줍니다.

00:17:23.000 --> 00:17:34.000
해피 빔은 사용자 지정 손 제스처를 포함하여 몰입형 공간을 활용하여 친구들과 재미있는 게임을 만드는 방법의 예입니다.

00:17:34.000 --> 00:17:40.000
그리고 Hello World는 3D 글로브로 다양한 시각적 모드 사이를 전환하는 방법을 보여줍니다.

00:17:40.000 --> 00:17:45.000
크리스토퍼는 나중에 Hello World에 대해 더 자세히 이야기할 것이다.

00:17:45.000 --> 00:17:53.000
이 플랫폼에서 처음부터 앱을 구축하고 설계하는 것은 공간 컴퓨팅 개념을 쉽게 받아들일 수 있는 기회를 제공합니다.

00:17:53.000 --> 00:17:59.000
그러나, 여러분 중 일부는 공간 컴퓨팅에 가져오고 싶은 기존 앱을 가지고 있을 수 있습니다.

00:17:59.000 --> 00:18:04.000
처음부터, iPad와 iPhone 앱은 멋지게 보이고 기분이 좋다.

00:18:04.000 --> 00:18:13.000
앱이 iPad를 지원하는 경우, iPhone 전용 앱이 완전히 지원되지만 해당 변형은 iPhone보다 선호됩니다.

00:18:13.000 --> 00:18:17.000
여기 시뮬레이터에 표시된 레시피 앱을 살펴봅시다.

00:18:17.000 --> 00:18:25.000
이 플랫폼은 더 어두운 스타일을 가지고 있지만, iPad와 iPhone 앱은 라이트 모드 스타일을 유지합니다.

00:18:25.000 --> 00:18:37.000
윈도우는 쉽게 사용할 수 있도록 확장할 수 있으며, 앱의 회전이 처리되어 다른 레이아웃을 볼 수 있습니다.

00:18:37.000 --> 00:18:52.000
자세한 내용을 보려면, "공유 공간에서 iPad 및 iPhone 앱 실행" 세션을 시청하여 시스템의 내장 동작, 기능적 차이점 및 시뮬레이터로 테스트하는 방법에 대해 알아보십시오.

00:18:52.000 --> 00:18:58.000
그러나, 기존 iPad 또는 iPhone 앱을 실행하는 것은 시작에 불과합니다.

00:18:58.000 --> 00:19:05.000
클릭 한 번으로 이 플랫폼의 Xcode 프로젝트에 목적지를 쉽게 추가할 수 있습니다.

00:19:05.000 --> 00:19:20.000
그리고 그 후, 우리는 단순히 대상 장치를 선택하고, 다시 컴파일하고 실행할 수 있습니다.

00:19:20.000 --> 00:19:26.000
다시 컴파일하면, 기본 간격, 크기 조정 및 릴레이아웃을 얻을 수 있습니다.

00:19:26.000 --> 00:19:43.000
창과 재료는 모두 자동으로 플랫폼의 모양과 느낌으로 이동하여 어떤 조명 조건에서도 가독성을 보장하며, 앱은 사용자 지정 컨트롤을 위한 강조 표시와 같은 내장 기능을 활용할 수 있습니다.

00:19:43.000 --> 00:19:50.000
이제 크리스토퍼는 우리가 지금까지 다룬 개념을 사용하여 어떻게 앱을 더 발전시킬 수 있는지 보여줍니다.

00:19:50.000 --> 00:19:51.000
고마워 짐.

00:19:51.000 --> 00:19:56.000
이전에 배운 요소를 통합한 애플리케이션을 만드는 방법을 안내해 드리겠습니다.

00:19:56.000 --> 00:20:01.000
Hello World부터 시작하여 앱에 통합할 수 있는 훌륭한 기능을 살펴봅시다.

00:20:01.000 --> 00:20:03.000
여기 우리의 실행 중인 샘플이 있습니다.

00:20:03.000 --> 00:20:10.000
시뮬레이터에서 앱을 실행하면, Hello World는 우리 바로 앞에 있는 공유 공간으로 들어가는 창으로 시작됩니다.

00:20:10.000 --> 00:20:18.000
이것은 SwiftUI로 만든 친숙한 창이며, 텍스트, 이미지 및 버튼과 같은 다양한 요소를 포함합니다.

00:20:18.000 --> 00:20:21.000
탭 제스처를 사용하면 앱 내에서 탐색할 수 있습니다.

00:20:21.000 --> 00:20:25.000
우리의 새로운 뷰에 3D 콘텐츠가 어떻게 포함되었는지 관찰하세요.

00:20:25.000 --> 00:20:30.000
SwiftUI와 3D 콘텐츠는 이제 원활하게 작동합니다.

00:20:30.000 --> 00:20:35.000
메인 창으로 돌아가서 행성 지구를 선택하면 새로운 시각으로 볼 수 있습니다.

00:20:35.000 --> 00:20:37.000
새로운 요소가 나타난다. 이건 볼륨이야.

00:20:37.000 --> 00:20:43.000
그것은 몇 가지 UI 요소와 함께 지구의 3D 모델을 포함한다.

00:20:43.000 --> 00:20:52.000
창 막대를 움직이면, 볼륨의 위치는 주변 어느 곳에서나 조정할 수 있습니다.

00:20:52.000 --> 00:21:02.000
다시 메인 창으로 돌아가서 Outer Space 보기를 선택하면 태양계에 들어갈 수 있는 초대장이 나타납니다.

00:21:02.000 --> 00:21:07.000
여기에서, 우리는 '풀'의 몰입 스타일로 여기에 표시된 공간에 들어갈 수 있다.

00:21:07.000 --> 00:21:15.000
우리의 예는 행성 지구를 렌더링하고 통과를 어둡게 하여 주변 환경의 산만함 없이 콘텐츠에 집중할 수 있게 해준다.

00:21:15.000 --> 00:21:24.000
이제 이것이 어떻게 보이는지 보았으니, Hello World의 기능 중 일부를 분해하고 자신의 앱에서 이러한 개념을 사용하는 방법을 보여드리겠습니다.

00:21:24.000 --> 00:21:30.000
짐에게서 배웠듯이, 창문, 볼륨 및 공간과 같은 여러 요소가 있습니다.

00:21:30.000 --> 00:21:38.000
특정 순간에 앱을 사용하는 사람들에게 가장 적합한 것이 무엇인지에 따라 앱이 위아래로 구부릴 수 있는 스펙트럼으로 볼 수 있습니다.

00:21:38.000 --> 00:21:44.000
공유 공간에 하나 또는 여러 개의 창을 표시하도록 선택할 수 있어, 사람들이 더 많이 존재할 수 있습니다.

00:21:44.000 --> 00:21:49.000
그들은 패스스루를 볼 수 있고 다른 앱을 나란히 가질 수 있다.

00:21:49.000 --> 00:21:54.000
또는... 앱이 공간을 완전히 차지하도록 함으로써 몰입도를 높일 수 있습니다.

00:21:54.000 --> 00:22:05.000
주어진 순간에 앱의 경험에 가장 적합한 요소를 찾고 그 사이를 구부리는 것은 공간 컴퓨팅을 위한 앱을 디자인할 때 중요한 고려 사항입니다.

00:22:05.000 --> 00:22:10.000
다음으로, 당신의 경험의 일부로 창문을 사용하는 방법에 대해 더 자세히 살펴봅시다.

00:22:10.000 --> 00:22:13.000
윈도우는 앱의 출발점 역할을 합니다.

00:22:13.000 --> 00:22:18.000
그것들은 장면을 사용하여 SwiftUI로 제작되었으며, 전통적인 보기와 컨트롤을 포함합니다.

00:22:18.000 --> 00:22:23.000
이 플랫폼의 Windows는 2D 및 3D 콘텐츠 혼합을 지원합니다.

00:22:23.000 --> 00:22:28.000
이것은 당신의 3D 콘텐츠가 창에서 2D UI와 함께 표시될 수 있다는 것을 의미합니다.

00:22:28.000 --> 00:22:32.000
창문은 공간에서 크기를 조정하고 재배치할 수 있다.

00:22:32.000 --> 00:22:35.000
사람들은 그들이 원하는 대로 그것들을 정리할 수 있다.

00:22:35.000 --> 00:22:37.000
우리의 예시로 돌아가자.

00:22:37.000 --> 00:22:47.000
Hello World에서 콘텐츠 보기에는 SwiftUI 이미지, 텍스트 및 버튼이 있으며, 더 몰입감 있는 콘텐츠를 얻기 위한 행동 촉구가 있습니다.

00:22:47.000 --> 00:22:51.000
창을 만드는 것은 장면에 WindowGroup을 추가하는 것만큼 쉽다.

00:22:51.000 --> 00:22:55.000
WindowGroup 내부에서, 우리는 콘텐츠 보기를 표시할 것이다.

00:22:55.000 --> 00:23:00.000
우리의 콘텐츠 보기는 3D 콘텐츠를 추가하여 앱에 새로운 차원의 깊이를 가져올 수 있습니다.

00:23:00.000 --> 00:23:03.000
그렇게 하려면, 새로운 Model3D 보기를 사용할 수 있습니다.

00:23:03.000 --> 00:23:11.000
Model3D는 이미지와 유사하여 RealityKit에 의해 렌더링된 앱에서 아름다운 3D 콘텐츠를 쉽게 로드하고 표시할 수 있습니다.

00:23:11.000 --> 00:23:17.000
당신의 보기에 Model3D를 추가하기 위해, 우리는 위성 모델의 이름을 전달하여 Model3D를 초기화합니다.

00:23:17.000 --> 00:23:23.000
이를 통해 Model3D는 모델을 찾아 로드하여 뷰 계층 구조에 배치합니다.

00:23:23.000 --> 00:23:32.000
이제 이 창에는 위성이 시야에 내장되어 있으며 z축에서 나오는 것을 볼 수 있으며, 앱에 새로운 차원의 깊이를 추가합니다.

00:23:32.000 --> 00:23:34.000
이제 위성을 추가했으니, 상호 작용을 추가할 수 있습니다.

00:23:34.000 --> 00:23:39.000
상호 작용은 근본적으로 시스템에 내장되어 있으며 SwiftUI에 의해 제공됩니다.

00:23:39.000 --> 00:23:49.000
SwiftUI는 Tap, onHover 및 RotateGesture와 같은 Apple 플랫폼에서 이미 익숙한 제스처 인식기를 제공합니다.

00:23:49.000 --> 00:23:57.000
이 플랫폼은 3D 공간에서의 회전, 3D 물체 탭 등과 같은 3D 상호 작용을 위해 만들어진 새로운 제스처 인식기를 제공합니다.

00:23:57.000 --> 00:24:01.000
위성과의 상호 작용을 가능하게 하는 코드를 살펴봅시다.

00:24:01.000 --> 00:24:06.000
우리는 위성을 잡고 움직일 수 있도록 공간 탭 제스처를 활성화할 것이다.

00:24:06.000 --> 00:24:10.000
Model3D부터 시작하여, 우리는 이제 제스처를 추가할 수 있습니다.

00:24:10.000 --> 00:24:14.000
내부에 우리는 위성 엔티티를 겨냥한 DragGesture를 추가합니다.

00:24:14.000 --> 00:24:19.000
그런 다음 업데이트 종료에서 전달된 값을 사용하여 위성을 이동할 수 있습니다.

00:24:19.000 --> 00:24:22.000
그게 어떻게 생겼는지 보자.

00:24:22.000 --> 00:24:33.000
위성이 렌더링된 위성 보기로 돌아가서, DragGesture를 사용하면 모델을 탭하고 드래그하여 상호 작용에 따라 이동할 수 있습니다.

00:24:33.000 --> 00:24:39.000
방금 보았듯이, 2D와 3D 콘텐츠를 Model3D와 함께 혼합하는 것은 쉽습니다.

00:24:39.000 --> 00:24:41.000
이것들은 당신이 창문으로 할 수 있는 몇 가지일 뿐입니다.

00:24:41.000 --> 00:24:46.000
이제 다른 유형의 요소인 볼륨을 살펴봅시다.

00:24:46.000 --> 00:24:48.000
볼륨이 무엇을 제공해야 하는지 봅시다.

00:24:48.000 --> 00:24:53.000
볼륨은 비슷한 기능을 제공하는 창의 확장이다.

00:24:53.000 --> 00:24:58.000
볼륨은 3D 콘텐츠에 이상적인 새로운 스타일의 창이다.

00:24:58.000 --> 00:25:03.000
그들은 당신의 2D 또는 3D 콘텐츠를 포함하는 여러 SwiftUI 뷰를 호스팅할 수 있습니다.

00:25:03.000 --> 00:25:12.000
볼륨은 전체 공간에서 사용할 수 있지만, 실제로 공유 공간을 위해 만들어졌기 때문에 콘텐츠는 볼륨의 범위 내에 있어야 합니다.

00:25:12.000 --> 00:25:15.000
당신의 장면에 볼륨을 추가하는 방법을 살펴봅시다.

00:25:15.000 --> 00:25:20.000
새로운 WindowGroup을 만들고 windowStyle을 volumetric로 설정하는 것으로 시작할 것입니다.

00:25:20.000 --> 00:25:26.000
그런 다음, 너비, 높이 및 깊이 속성이 있는 defaultSize를 제공해야 합니다.

00:25:26.000 --> 00:25:30.000
부피의 단위는 점이나 미터로 지정할 수 있다.

00:25:30.000 --> 00:25:32.000
시뮬레이터에서 실행되는 것을 봅시다.

00:25:32.000 --> 00:25:37.000
신청서가 제시되면, 볼륨은 그 사람 앞에 놓입니다.

00:25:37.000 --> 00:25:57.000
이 볼륨에는 플랫폼 컨트롤과 함께 우리가 지정한 치수가 있습니다: 앱 이름을 표시하는 응용 프로그램 제목 표시줄은 이 볼륨이 어떤 앱에 속하는지 쉽게 식별할 수 있습니다; 볼륨을 배치할 수 있는 창 바; 그리고 탭할 때 앱을 일시 중지하고 볼륨을 닫는 닫기 버튼.

00:25:57.000 --> 00:26:04.000
현재, 우리의 볼륨은 지구의 3D 모델을 렌더링하지만, 더 많은 콘텐츠와 다른 행동을 추가하고 싶을 수도 있습니다.

00:26:04.000 --> 00:26:09.000
이를 위해, 당신은 앱의 일부로 RealityView를 채택할 수 있습니다.

00:26:09.000 --> 00:26:18.000
RealityView는 장면에 추가할 수 있는 새로운 뷰로, SwiftUI 내에서 원하는 수의 엔티티를 직접 관리할 수 있습니다.

00:26:18.000 --> 00:26:25.000
SwiftUI와 RealityView를 사용하면 SwiftUI의 관리 상태 및 엔티티 속성에 연결하여 앱을 쉽게 통합할 수 있습니다.

00:26:25.000 --> 00:26:31.000
이를 통해 앱의 데이터 모델에서 진실의 원천으로 3D 모델의 동작을 쉽게 구동할 수 있습니다.

00:26:31.000 --> 00:26:43.000
RealityView에서 제공하는 변환 기능으로 좌표 공간 간의 변환이 용이하며, RealityView는 첨부 파일을 통해 3D 장면 내부에 SwiftUI 요소를 배치할 수 있는 방법을 제공합니다.

00:26:43.000 --> 00:26:48.000
RealityView 내부의 첨부 파일을 어떻게 사용할 수 있는지 잠시 살펴봅시다.

00:26:48.000 --> 00:26:56.000
우리가 사용할 RealityView 이니셜라이저는 세 가지 매개 변수를 사용합니다: make closure, 업데이트 closure 및 첨부 파일 ViewBuilder.

00:26:56.000 --> 00:27:01.000
Make closure을 사용하면 엔티티를 만들고 루트 엔티티에 첨부할 수 있습니다.

00:27:01.000 --> 00:27:05.000
뷰의 상태가 바뀔 때마다 호출되는 업데이트 폐쇄.

00:27:05.000 --> 00:27:15.000
그리고 마지막으로, 첨부 파일 폐쇄는 RealityView가 우리의 뷰를 엔티티로 변환할 수 있는 태그 속성으로 SwiftUI 뷰를 추가하는 곳입니다.

00:27:15.000 --> 00:27:20.000
이제, RealityView로 첨부 파일을 사용하는 방법의 예를 살펴봅시다.

00:27:20.000 --> 00:27:26.000
첨부 파일을 추가하는 것은 RealityView의 첨부 파일 클로저 안에 SwiftUI 뷰를 넣는 것만큼 쉽습니다.

00:27:26.000 --> 00:27:31.000
이 맛있는 페이스트리 아이콘을 사용하여 3D 글로브의 위치를 표현해 봅시다.

00:27:31.000 --> 00:27:35.000
각 첨부 파일에 대해, 첨부 파일에 이름을 부여하는 태그를 추가해야 합니다.

00:27:35.000 --> 00:27:38.000
나는 이것을 '핀'이라고 부를 것이다.

00:27:38.000 --> 00:27:41.000
첨부 파일을 표시하려면, RealityView의 콘텐츠에 추가할 것입니다.

00:27:41.000 --> 00:27:46.000
나는 그것을 장면의 루트 엔티티에 추가하여 업데이트 클로저에서 그것을 할 것이다.

00:27:46.000 --> 00:27:53.000
여기서, 우리는 내가 가장 좋아하는 빵집 위치 위의 지구에서 우리가 이전에 만든 첨부 파일을 볼 수 있다.

00:27:53.000 --> 00:28:02.000
방금 보았듯이, RealityKit을 사용하면 Model3D, RealityView, 첨부 파일 등과 같은 강력한 기능을 사용할 수 있습니다.

00:28:02.000 --> 00:28:05.000
이것들은 당신의 앱에 쉽게 통합될 수 있습니다.

00:28:05.000 --> 00:28:09.000
이것은 RealityKit이 할 수 있는 일의 표면을 긁는 것일 뿐이다.

00:28:09.000 --> 00:28:20.000
더 알고 싶다면, "RealityKit으로 공간 경험 구축"과 "RealityKit으로 공간 컴퓨팅 앱 강화"를 시청하는 것이 좋습니다.

00:28:20.000 --> 00:28:23.000
우리가 지금까지 겪은 일을 요약해 봅시다.

00:28:23.000 --> 00:28:27.000
볼륨은 2D 및 3D 콘텐츠에 이상적인 컨테이너입니다.

00:28:27.000 --> 00:28:34.000
볼륨은 공유 공간을 위해 만들어지고, 창과 공존할 수 있으며, 지정된 크기로 제한됩니다.

00:28:34.000 --> 00:28:40.000
다음으로, 우리의 마지막 유형의 요소인 공간으로 뛰어들자.

00:28:40.000 --> 00:28:47.000
앱이 전용 전체 공간을 열면, 시스템은 다른 모든 앱을 숨기고 앱만 볼 수 있습니다.

00:28:47.000 --> 00:28:53.000
이제 앱의 창, 볼륨 및 콘텐츠를 주변 어디에나 배치할 수 있습니다.

00:28:53.000 --> 00:28:59.000
ARKit과 RealityKit 덕분에 가상 콘텐츠는 주변 환경과 상호 작용할 수도 있습니다.

00:28:59.000 --> 00:29:06.000
당신은 가상 공을 방에 던지고 그것이 벽에서 튀어나와 바닥에서 굴러가는 것을 볼 수 있습니다.

00:29:06.000 --> 00:29:13.000
그리고 손 추적을 추가하면, 사용자 지정 제스처와 상호 작용을 구축하거나 사람들의 손과 관련된 콘텐츠를 배치할 수 있습니다.

00:29:13.000 --> 00:29:16.000
이러한 기능의 대부분은 ARKit에서 나온다.

00:29:16.000 --> 00:29:24.000
더 깊이 들어가고 앱에서 그것들을 활용하는 방법을 배우려면, "공간 컴퓨팅을 위한 ARKit 만나기" 세션을 확인하세요.

00:29:24.000 --> 00:29:32.000
공간을 사용하면, 앱은 생성 시 어떤 스타일을 선택하느냐에 따라 다양한 수준의 몰입도를 제공할 수 있습니다.

00:29:32.000 --> 00:29:36.000
짐은 풀 스페이스에서 사용할 수 있는 몰입의 스펙트럼에 대해 조금 이야기했다.

00:29:36.000 --> 00:29:41.000
앱에 몰입도를 더할 수 있는 방법에 대해 자세히 알아봅시다.

00:29:41.000 --> 00:29:45.000
몰입 스타일은 전체 공간에서 전달할 수 있는 매개 변수입니다.

00:29:45.000 --> 00:29:49.000
.Mixed와 .full이라고 불리는 두 가지 기본 스타일이 있다.

00:29:49.000 --> 00:29:53.000
혼합 스타일은 앱의 콘텐츠를 패스스루 위에 계층합니다.

00:29:53.000 --> 00:29:58.000
풀 스타일은 패스스루를 숨기고 콘텐츠만 표시합니다.

00:29:58.000 --> 00:30:01.000
프로그레시브를 선택하여 둘을 결합할 수도 있습니다.

00:30:01.000 --> 00:30:12.000
이 스타일은 처음에 약간의 패스스루를 허용하지만, 그 사람은 장치 상단에 있는 디지털 크라운을 돌려 몰입도를 최대로 바꿀 수 있다.

00:30:12.000 --> 00:30:15.000
몰입 스타일을 탐구하기 위해 우리의 예시로 돌아가자.

00:30:15.000 --> 00:30:17.000
혼합 스타일로 시작해서 그게 어떻게 보이는지 볼게.

00:30:17.000 --> 00:30:23.000
그리고 Full Space는 SwiftUI 장면이기 때문에, RealityView를 사용하여 지구를 표시할 수 있습니다.

00:30:23.000 --> 00:30:29.000
여기 높은 궤도에서 본 지구가 있습니다... 그리고 제 앱에서 장면을 표시한 방법은 다음과 같습니다.

00:30:29.000 --> 00:30:32.000
내가 실제로 몰입 스타일을 명시하지 않았다는 것을 주목하세요.

00:30:32.000 --> 00:30:38.000
몰입형 공간을 만들 때 SwiftUI는 기본적으로 혼합 스타일을 가정하기 때문입니다.

00:30:38.000 --> 00:30:42.000
또한 다른 몰입 스타일을 추가하여 앱을 완전히 몰입하게 합시다.

00:30:42.000 --> 00:30:46.000
이번에는 몰입형 스타일 '풀'을 사용할 것이다.

00:30:46.000 --> 00:30:50.000
ImmersiveSpace의 끝에 몰입형 스타일을 추가하는 것은 쉽습니다.

00:30:50.000 --> 00:30:55.000
우리는 몰입형 스타일을 상태 변수에 저장한 다음 유형을 전체로 설정합니다.

00:30:55.000 --> 00:31:04.000
우리는 사람들이 몰입형 경험에 들어갈 때 선택권을 주고 싶기 때문에, 그 사람이 이 몰입형 스타일에 들어갈지 결정할 수 있도록 버튼을 추가하는 것이 좋습니다.

00:31:04.000 --> 00:31:08.000
이제 새로운 몰입형 스타일이 작동하는 것을 봅시다.

00:31:08.000 --> 00:31:16.000
우리 앱으로 돌아가서, 나는 Hello World를 단일 창에서 완전히 몰입하여 어떤 각도에서든 지구를 볼 수 있게 했다.

00:31:16.000 --> 00:31:20.000
그리고 그것은 당신이 공간 앱으로 할 수 있는 일의 시작에 불과합니다.

00:31:20.000 --> 00:31:22.000
네가 여기서 어디로 갈 수 있는지 보자.

00:31:22.000 --> 00:31:28.000
이 세션에서, 우리는 기본 사항을 다루었습니다: 시작하는 방법, 그리고 앱 구축의 기본 사항을 안내했습니다.

00:31:28.000 --> 00:31:41.000
우리는 당신의 다음 정류장이 되어야 할 몇 가지 훌륭한 세션이 있습니다 - 공간 디자인의 원칙에 대해, 또는 SwiftUI와 RealityKit으로 앱 구축에 대해 배우거나, 3D 콘텐츠 제작을 시작하기 위해.

00:31:41.000 --> 00:31:46.000
공간 컴퓨팅을 통해, 당신의 앱 제작은 당신의 독창성에 따라 새롭고 흥미진진한 길을 탐험할 수 있습니다.

00:31:46.000 --> 00:31:47.000
봐줘서 고마워!

00:31:47.000 --> 23:59:59.000
♪

