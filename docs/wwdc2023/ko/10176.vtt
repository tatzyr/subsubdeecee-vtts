WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:15.000
리지: 안녕! 저는 리지이고, 여기 애플에서 VisionKit에서 일하는 엔지니어입니다.

00:00:15.000 --> 00:00:20.000
오늘 당신의 앱에 주제 해제를 가져오는 방법에 대해 이야기하게 되어 기쁩니다.

00:00:20.000 --> 00:00:28.000
피사체 리프팅은 iOS 16에 도입되어 사용자가 이미지 피사체를 선택, 들어 올리고, 공유할 수 있도록 했다.

00:00:28.000 --> 00:00:32.000
먼저, 나는 주제 리프팅이 무엇인지에 대한 기초를 살펴볼 것이다.

00:00:32.000 --> 00:00:39.000
그런 다음, 새로운 VisionKit API를 사용하여 주제 리프팅을 추가하는 방법을 안내해 드리겠습니다.

00:00:39.000 --> 00:00:46.000
마지막으로, 내 동료 Saumitro는 더 깊이 파고들고 새로운 기본 비전 API를 소개할 것이다.

00:00:46.000 --> 00:00:49.000
그래서 주제가 정확히 뭐야?

00:00:49.000 --> 00:00:54.000
피사체는 사진의 전경 물체 또는 물체이다.

00:00:54.000 --> 00:00:57.000
이것은 항상 사람이나 애완동물은 아니다.

00:00:57.000 --> 00:01:03.000
그것은 건물, 음식 한 접시, 또는 신발 몇 켤레 등 무엇이든 될 수 있다.

00:01:03.000 --> 00:01:08.000
이미지는 이 세 잔의 커피와 같이 여러 피사체를 가질 수 있다.

00:01:08.000 --> 00:01:13.000
주제가 항상 개별적인 것은 아니라는 점에 유의하는 것이 중요하다.

00:01:13.000 --> 00:01:20.000
이 예에서, 남자와 그의 개는 함께 이미지의 초점이며, 그들을 하나의 결합된 피사체로 만든다.

00:01:20.000 --> 00:01:23.000
그래서 이걸 어떻게 앱에 넣을 수 있어?

00:01:23.000 --> 00:01:28.000
앱에 주제 리프팅을 추가하는 데 도움이 되는 두 가지 별도의 API가 있습니다.

00:01:28.000 --> 00:01:30.000
비전키트.

00:01:30.000 --> 00:01:31.000
그리고 비전.

00:01:31.000 --> 00:01:38.000
VisionKit을 사용하면 즉시 시스템과 같은 피사체 리프팅 동작을 매우 쉽게 채택할 수 있습니다.

00:01:38.000 --> 00:01:45.000
단 몇 줄의 코드로 우리 모두가 알고 사랑하는 주제 리프팅 UI를 쉽게 재현할 수 있습니다.

00:01:45.000 --> 00:01:54.000
VisionKit은 또한 이러한 주제에 대한 몇 가지 기본 정보를 노출하므로, 사람들에게 이미지 주제와 상호 작용할 수 있는 새로운 방법을 제공할 수 있습니다.

00:01:54.000 --> 00:02:00.000
이 모든 것은 성능상의 이점이 있지만 이미지 크기가 제한적이라는 것을 의미하는 프로세스 외부에서 발생합니다.

00:02:00.000 --> 00:02:05.000
비전은 낮은 수준의 프레임워크이며 즉시 사용할 수 있는 UI가 없습니다.

00:02:05.000 --> 00:02:10.000
이것은 그것이 전망에 묶여 있지 않다는 것을 의미하며, 당신에게 더 많은 유연성을 제공합니다.

00:02:10.000 --> 00:02:17.000
이미지 분석은 프로세스 중에 발생하며, VisionKit만큼 이미지 해상도가 제한되지 않습니다.

00:02:17.000 --> 00:02:24.000
마지막으로, 이 API는 CoreImage를 사용하는 것과 같은 고급 이미지 편집 파이프라인의 일부가 될 수 있습니다.

00:02:24.000 --> 00:02:28.000
먼저, VisionKit의 주제 리프팅 API에 대해 알아봅시다.

00:02:28.000 --> 00:02:36.000
VisionKit으로 피사체 리프팅을 추가하려면, ImageAnalysisInteraction을 초기화하고 이미지가 포함된 보기에 추가하기만 하면 됩니다.

00:02:36.000 --> 00:02:40.000
이것은 UIImageView가 될 수 있지만, 그럴 필요는 없다.

00:02:40.000 --> 00:02:41.000
그렇게 간단해.

00:02:41.000 --> 00:02:45.000
이제, 당신의 이미지는 시스템 주제 리프팅 상호 작용을 가질 것입니다.

00:02:45.000 --> 00:02:52.000
마찬가지로, macOS에서 ImageAnalysisOverlayView를 만들고 이미지가 포함된 NSView의 하위 뷰로 추가하십시오.

00:02:52.000 --> 00:03:03.000
ImageAnalysisInteraction 또는 ImageAnalysisOverlayView의 기본 상호 작용 유형을 설정하여 지원할 VisionKit 상호 작용 유형을 선택할 수 있습니다.

00:03:03.000 --> 00:03:07.000
기본 상호 작용 유형은 시스템 동작을 반영하는 .automatic이다.

00:03:07.000 --> 00:03:12.000
주제 리프팅, 라이브 텍스트 및 데이터 검출기를 원한다면 이 유형을 사용하세요.

00:03:12.000 --> 00:03:19.000
새로운 이미지 주제 유형에는 텍스트가 상호 작용하는 것을 원하지 않는 경우 주제 리프팅만 포함됩니다.

00:03:19.000 --> 00:03:27.000
이러한 UI 상호 작용 외에도, VisionKit을 사용하면 ImageAnalysis를 사용하여 이미지의 피사체에 프로그래밍 방식으로 액세스할 수 있습니다.

00:03:27.000 --> 00:03:34.000
이미지 분석을 생성하려면, ImageAnalyzer를 만든 다음 분석 함수를 호출하기만 하면 됩니다.

00:03:34.000 --> 00:03:39.000
원하는 이미지와 분석기 구성을 전달하세요.

00:03:39.000 --> 00:03:46.000
ImageAnalysis의 피사체 속성을 사용하여 이미지의 모든 피사체 목록에 비동기적으로 액세스할 수 있습니다.

00:03:46.000 --> 00:03:51.000
이것은 이미지와 그 경계를 포함하는 새로운 주제 구조를 사용한다.

00:03:51.000 --> 00:03:57.000
강조 표시된 주제 속성은 강조 표시된 주제 세트를 반환합니다.

00:03:57.000 --> 00:04:01.000
이 예에서, 아래 두 과목이 강조되었다.

00:04:01.000 --> 00:04:09.000
사용자는 길게 눌러 주제를 강조 표시할 수 있지만, 코드에 설정된 강조 표시된 주제를 업데이트하여 선택 상태를 변경할 수도 있습니다.

00:04:09.000 --> 00:04:14.000
비동기 subject(at:) 방법을 사용하여 지점별로 주제를 찾을 수 있습니다.

00:04:14.000 --> 00:04:19.000
이 예에서, 여기를 탭하면 중간 주제를 반환할 것이다.

00:04:19.000 --> 00:04:23.000
그 시점에 주제가 없다면, 이 방법은 nil을 반환할 것이다.

00:04:23.000 --> 00:04:27.000
마지막으로, 두 가지 방법으로 피사체 이미지를 생성할 수 있습니다.

00:04:27.000 --> 00:04:31.000
단일 피사체의 경우, 피사체의 이미지 속성에 접근하기만 하면 됩니다.

00:04:31.000 --> 00:04:40.000
여러 피사체로 구성된 이미지가 필요한 경우, 비동기 이미지(for:) 방법을 사용하고, 포함하고 싶은 피사체를 전달하세요.

00:04:40.000 --> 00:04:48.000
이 예에서, 하단 두 피사체의 이미지를 원한다면, 이 방법을 사용하여 이 이미지를 생성할 수 있습니다.

00:04:48.000 --> 00:04:50.000
이 모든 것이 데모로 모이는 것을 봅시다.

00:04:50.000 --> 00:04:53.000
나는 퍼즐 앱 작업을 하고 있어.

00:04:53.000 --> 00:04:57.000
나는 그 조각들을 퍼즐로 끌고 가고 싶지만, 아직 그 중 어느 것도 들어 올릴 수 없다.

00:04:57.000 --> 00:04:58.000
그걸 고치자.

00:04:58.000 --> 00:05:05.000
먼저, 조각들이 상호 작용할 수 있도록 이 이미지에서 피사체 리프팅 상호 작용을 활성화해야 합니다.

00:05:05.000 --> 00:05:10.000
저는 ImageAnalysisInteraction을 만들어 이것을 할 수 있습니다...

00:05:10.000 --> 00:05:14.000
...그리고 그냥 내 견해에 추가해.

00:05:14.000 --> 00:05:26.000
라이브 텍스트를 포함할 필요가 없기 때문에 여기서 imageSubject 상호 작용 유형을 사용했습니다.

00:05:26.000 --> 00:05:27.000
멋져!

00:05:27.000 --> 00:05:30.000
이제 나는 퍼즐 조각을 선택하고 이렇게 상호 작용할 수 있다.

00:05:30.000 --> 00:05:33.000
이 이미지는 어떤 식으로든 사전 처리되지 않았다.

00:05:33.000 --> 00:05:36.000
이것은 단지 주제 리프팅으로 이루어진다.

00:05:36.000 --> 00:05:48.000
나는 퍼즐 조각을 퍼즐에 떨어뜨리는 것을 처리하기 위해 몇 가지 코드를 추가했고, 심지어 그것들을 제자리에 조정했다.

00:05:48.000 --> 00:05:52.000
꽤 멋져 보이지만, 나는 내 앱을 훨씬 더 매력적으로 만들고 싶다.

00:05:52.000 --> 00:05:59.000
나는 약간의 3D 효과를 주기 위해 각 퍼즐 조각 아래에 그림자를 추가할까 생각 중이야.

00:05:59.000 --> 00:06:05.000
저는 이미 여기에 호버 제스처 핸들러가 있습니다, 그림자를 추가하기만 하면 됩니다.

00:06:05.000 --> 00:06:10.000
나는 이미지를 쉽게 편집할 수 없기 때문에, 대신 이미지 레이어링 트릭으로 할 것이다.

00:06:10.000 --> 00:06:18.000
먼저, imageAnalysis.subject(at point:)를 호출하여 피사체 위를 맴돌고 있는지 확인합니다.

00:06:18.000 --> 00:06:29.000
피사체 이미지의 복사본을 삽입하고, 회색으로 만들고, 원래 피사체 위치에서 약간 오프셋하는 addShadow(주제용:) 방법이 있습니다.

00:06:29.000 --> 00:06:36.000
그런 다음, 그림자 위에 피사체 이미지의 복사본을 추가하여 3차원으로 보이게 합니다.

00:06:36.000 --> 00:06:44.000
마지막으로, 호버 포인트가 피사체와 교차하지 않는다면, 나는 그림자를 지운다.

00:06:44.000 --> 00:06:49.000
한 번 해보자.

00:06:49.000 --> 00:07:00.000
굉장해. 그 조각들은 이제 내가 그 위에 맴돌면 그림자 효과를 얻는다.

00:07:00.000 --> 00:07:10.000
VisionKit을 사용하여 앱에서 피사체 리프팅을 설정할 수 있었고, 몇 줄의 코드로 재미있는 피사체 효과를 추가할 수도 있었습니다.

00:07:10.000 --> 00:07:17.000
다음으로, 저는 새로운 Vision API와 그것을 앱에 통합하는 방법에 대해 이야기할 동료 Saumitro에게 전달할 것입니다.

00:07:17.000 --> 00:07:19.000
사우미트로: 고마워, 리지!

00:07:19.000 --> 00:07:23.000
안녕하세요, 저는 Saumitro이고, Vision 팀의 엔지니어입니다.

00:07:23.000 --> 00:07:28.000
VisionKit의 API는 주제 리프팅을 시작하는 가장 쉬운 방법입니다.

00:07:28.000 --> 00:07:32.000
고급 기능이 필요한 애플리케이션의 경우, Vision이 도와드리겠습니다.

00:07:32.000 --> 00:07:40.000
주제 리프팅은 시력과 사람 세분화와 같은 Vision의 기존 세분화 API 컬렉션에 합류한다.

00:07:40.000 --> 00:07:45.000
그들의 각각의 강점을 빠르게 검토하고 주제 리프팅이 어떻게 맞는지 봅시다.

00:07:45.000 --> 00:07:52.000
관심과 객관성을 위한 것과 같은 현저한 요청은 거친 지역 기반 분석에 가장 잘 사용된다.

00:07:52.000 --> 00:07:59.000
생성된 현저성 지도는 상당히 낮은 해상도이며, 따라서 세분화에 적합하지 않다는 점에 유의하십시오.

00:07:59.000 --> 00:08:04.000
대신, 이미지를 자동 자르는 것과 같은 작업에 두드러진 영역을 사용할 수 있습니다.

00:08:04.000 --> 00:08:11.000
사람 세분화 API는 현장에 있는 사람들을 위한 상세한 세분화 마스크를 생산하는 데 빛을 발한다.

00:08:11.000 --> 00:08:16.000
특히 사람들을 세분화하는 데 집중하고 싶다면 이것을 사용하세요.

00:08:16.000 --> 00:08:24.000
새로운 사람 인스턴스 세분화 API는 장면의 각 사람에게 별도의 마스크를 제공함으로써 상황을 더욱 발전시킨다.

00:08:24.000 --> 00:08:28.000
더 알아보려면, 개인 세분화에 대한 이 세션을 확인하세요.

00:08:28.000 --> 00:08:35.000
사람 세분화와는 달리, 새로 도입된 주제 리프팅 API는 "계급 불가지론적"이다.

00:08:35.000 --> 00:08:40.000
의미론적 클래스에 관계없이 모든 전경 객체는 잠재적으로 분할될 수 있다.

00:08:40.000 --> 00:08:46.000
예를 들어, 이 이미지에 있는 사람들 외에도 차를 어떻게 픽업하는지 주목하세요.

00:08:46.000 --> 00:08:49.000
이제 관련된 몇 가지 핵심 개념을 살펴봅시다.

00:08:49.000 --> 00:08:51.000
입력 이미지로 시작하세요.

00:08:51.000 --> 00:08:59.000
피사체 리프팅 요청은 이 이미지를 처리하고 동일한 해상도로 부드러운 세분화 마스크를 생성합니다.

00:08:59.000 --> 00:09:04.000
이 마스크를 가지고 소스 이미지에 적용하면 마스크된 이미지가 생성됩니다.

00:09:04.000 --> 00:09:09.000
각각의 뚜렷한 분할된 객체는 인스턴스라고 불린다.

00:09:09.000 --> 00:09:14.000
비전은 또한 이러한 사례에 대한 픽셀별 정보를 제공합니다.

00:09:14.000 --> 00:09:19.000
이 인스턴스 마스크는 소스 이미지의 픽셀을 인스턴스 인덱스에 매핑합니다.

00:09:19.000 --> 00:09:27.000
제로 인덱스는 배경을 위해 예약되어 있으며, 각 전경 인스턴스는 1부터 순차적으로 레이블이 지정됩니다.

00:09:27.000 --> 00:09:33.000
연속적으로 라벨을 붙이는 것 외에도, 이 ID의 주문은 보장되지 않습니다.

00:09:33.000 --> 00:09:39.000
이 인덱스를 사용하여 소스 이미지의 전경 개체의 하위 집합을 분할할 수 있습니다.

00:09:39.000 --> 00:09:44.000
대화형 앱을 디자인하는 경우, 이 인스턴스 마스크는 히트 테스트에도 유용합니다.

00:09:44.000 --> 00:09:47.000
나는 이 두 가지 작업을 모두 하는 방법을 조금 보여줄 것이다.

00:09:47.000 --> 00:09:50.000
API에 대해 자세히 알아봅시다.

00:09:50.000 --> 00:09:54.000
피사체 리프팅은 비전에서 이미지 기반 요청의 친숙한 패턴을 따른다.

00:09:54.000 --> 00:10:03.000
포그라운드 인스턴스 마스크 요청을 인스턴스화한 다음 입력 이미지와 함께 이미지 요청 핸들러를 인스턴스화하는 것으로 시작합니다.

00:10:03.000 --> 00:10:05.000
그런 다음 요청을 수행하세요.

00:10:05.000 --> 00:10:11.000
후드 아래에서, 이것은 비전이 주제를 알아내기 위해 이미지를 분석할 때이다.

00:10:11.000 --> 00:10:21.000
효율성을 위해 Apple의 하드웨어를 활용하도록 최적화되어 있지만, 여전히 리소스 집약적인 작업이며 UI를 차단하지 않도록 백그라운드 스레드로 연기하는 것이 가장 좋습니다.

00:10:21.000 --> 00:10:27.000
이것을 하는 한 가지 일반적인 방법은 별도의 DispatchQueue에서 이 단계를 비동기적으로 수행하는 것입니다.

00:10:27.000 --> 00:10:35.000
입력 이미지에서 하나 이상의 피사체가 감지되면, 결과 배열은 단일 관찰로 채워질 것이다.

00:10:35.000 --> 00:10:40.000
여기서부터, 당신은 마스크와 세분화된 이미지에 대한 관찰을 쿼리할 수 있습니다.

00:10:40.000 --> 00:10:47.000
어떤 인스턴스가 분할되고 결과가 어떻게 잘려지는지 제어하는 두 가지 매개 변수를 자세히 살펴봅시다.

00:10:47.000 --> 00:10:55.000
인스턴스 매개 변수는 최종 세그먼트 이미지 또는 마스크에서 추출되는 개체를 제어하는 IndexSet입니다.

00:10:55.000 --> 00:11:01.000
예를 들어, 이 이미지에는 배경 인스턴스를 포함하지 않는 두 개의 전경 인스턴스가 포함되어 있습니다.

00:11:01.000 --> 00:11:15.000
감지된 모든 포그라운드 인스턴스를 세분화하는 것은 매우 일반적인 작업이기 때문에, Vision은 모든 포그라운드 인스턴스 인덱스를 포함하는 IndexSet을 반환하는 편리한 allInstances 속성을 제공합니다.

00:11:15.000 --> 00:11:19.000
여기 이미지의 경우, 여기에는 인덱스 1과 2가 포함됩니다.

00:11:19.000 --> 00:11:23.000
백그라운드 인스턴스 0은 포함되지 않습니다.

00:11:23.000 --> 00:11:26.000
당신은 또한 그 지수의 하위 집합만 제공할 수 있습니다.

00:11:26.000 --> 00:11:29.000
여기 예시 1이 있습니다.

00:11:29.000 --> 00:11:31.000
그리고 그냥 예시 2.

00:11:31.000 --> 00:11:34.000
또한 최종 마스킹된 이미지가 어떻게 잘려지는지 제어할 수 있습니다.

00:11:34.000 --> 00:11:40.000
이 매개 변수가 false로 설정되면, 출력 이미지 해상도는 입력 이미지와 일치합니다.

00:11:40.000 --> 00:11:48.000
이것은 다운스트림 합성 작업을 위해 세분화된 객체의 상대적인 위치를 보존하고 싶을 때 좋습니다.

00:11:48.000 --> 00:11:53.000
True로 설정하면, 선택한 인스턴스에 대해 빡빡한 작물을 얻을 수 있습니다.

00:11:53.000 --> 00:11:58.000
지금까지의 예에서, 나는 완전히 가려진 이미지 출력으로 작업해 왔다.

00:11:58.000 --> 00:12:07.000
그러나, 마스킹 효과를 적용하는 것과 같은 일부 작업의 경우, 대신 세분화 마스크로 작업하는 것이 더 편리할 수 있습니다.

00:12:07.000 --> 00:12:13.000
관찰에서 createScaledMask 방법을 호출하여 이러한 마스크를 생성할 수 있습니다.

00:12:13.000 --> 00:12:16.000
매개 변수는 이전과 동일하게 동작한다.

00:12:16.000 --> 00:12:23.000
출력은 소프트 세분화 마스크를 포함하는 단일 채널 부동 소수점 픽셀 버퍼입니다.

00:12:23.000 --> 00:12:27.000
내가 방금 만든 마스크는 CoreImage와 함께 사용하기에 완벽하게 적합하다.

00:12:27.000 --> 00:12:32.000
VisionKit과 마찬가지로 Vision은 SDR 출력을 생성합니다.

00:12:32.000 --> 00:12:38.000
그러나 CoreImage에서 마스킹을 수행하는 것은 입력의 높은 동적 범위를 보존한다.

00:12:38.000 --> 00:12:43.000
이에 대해 자세히 알아보려면, 앱에 HDR을 추가하는 세션을 확인하는 것을 고려해 보세요.

00:12:43.000 --> 00:12:47.000
이 마스크를 수행하는 한 가지 방법은 CIBlendWithMask 필터를 사용하는 것입니다.

00:12:47.000 --> 00:12:50.000
나는 마스킹이 필요한 소스 이미지로 시작할 것이다.

00:12:50.000 --> 00:12:54.000
이것은 일반적으로 당신이 비전에 전달한 것과 같은 이미지일 것입니다.

00:12:54.000 --> 00:12:58.000
Vision의 createScaledMask 호출에서 얻은 마스크.

00:12:58.000 --> 00:13:03.000
그리고 마지막으로, 피사체가 위에 합성될 새로운 배경 이미지.

00:13:03.000 --> 00:13:07.000
이를 위해 빈 이미지를 사용하면 투명한 배경이 됩니다.

00:13:07.000 --> 00:13:14.000
또는, 새로운 배경 위에 결과를 합성할 계획이라면, 여기에 직접 전달할 수 있습니다.

00:13:14.000 --> 00:13:15.000
그리고 그게 거의 다야.

00:13:15.000 --> 00:13:21.000
출력은 HDR로 보존된 마스크 및 합성 이미지가 될 것이다.

00:13:21.000 --> 00:13:26.000
이제 멋진 피사체 리프팅 시각 효과 앱을 만들기 위해 모든 것을 합치자.

00:13:26.000 --> 00:13:32.000
배경을 제거하고 그 아래의 뷰를 보여주거나, 다른 것으로 바꿀 수 있습니다.

00:13:32.000 --> 00:13:36.000
게다가, 당신은 미리 설정된 효과 중 하나를 적용할 수 있습니다.

00:13:36.000 --> 00:13:40.000
그리고 효과는 선택된 배경으로 구성된다.

00:13:40.000 --> 00:13:45.000
포그라운드 인스턴스를 탭하여 선택적으로 들어 올릴 수도 있습니다.

00:13:45.000 --> 00:13:48.000
이 앱의 생성에 어떻게 접근할 것인지에 대한 개요를 살펴봅시다.

00:13:48.000 --> 00:13:58.000
우리 앱의 핵심은 UI의 입력을 받아들이고 최종 출력을 생성하는 데 필요한 모든 작업을 수행하는 효과 파이프라인에 의존합니다.

00:13:58.000 --> 00:14:02.000
소스 이미지에서 피사체 리프팅을 수행하는 것으로 시작하겠습니다.

00:14:02.000 --> 00:14:06.000
선택적 탭을 통해 개별 인스턴스를 선택할 수 있습니다.

00:14:06.000 --> 00:14:10.000
결과 마스크는 소스 이미지에 적용될 것이다.

00:14:10.000 --> 00:14:18.000
그리고 마지막으로, 선택된 배경과 시각 효과는 최종 출력 이미지를 생성하기 위해 적용되고 합성될 것이다.

00:14:18.000 --> 00:14:21.000
이 마지막 두 단계는 CoreImage를 사용하여 수행될 것이다.

00:14:21.000 --> 00:14:31.000
우리의 최상위 기능은 입력 이미지, 선택한 배경 이미지 및 효과, 그리고 잠재적으로 인스턴스 중 하나를 선택하기 위한 사용자의 탭 위치를 취합니다.

00:14:31.000 --> 00:14:35.000
여기의 효과 유형은 사전 설정을 위한 간단한 열거형일 뿐입니다.

00:14:35.000 --> 00:14:39.000
그것의 출력은 UI에 표시할 준비가 된 최종 합성 이미지이다.

00:14:39.000 --> 00:14:43.000
이 작업은 두 단계로 해체될 수 있다.

00:14:43.000 --> 00:14:48.000
먼저, 선택된 인스턴스에 대한 주제 마스크를 생성합니다.

00:14:48.000 --> 00:14:52.000
그리고 두 번째로, 그 마스크를 사용하여 선택한 효과를 적용하세요.

00:14:52.000 --> 00:14:54.000
첫 번째 단계부터 시작합시다.

00:14:54.000 --> 00:14:59.000
이 단계에 대한 입력은 소스 이미지와 선택적 탭 위치입니다.

00:14:59.000 --> 00:15:06.000
우리는 이미 여기에서 대부분의 코드를 접했는데, 이는 단순히 비전 요청을 수행하고 마스크를 반환합니다.

00:15:06.000 --> 00:15:12.000
흥미로운 부분은 탭 위치를 라벨 마스크를 사용하여 인덱스 세트에 매핑하는 이 선이다.

00:15:12.000 --> 00:15:15.000
좀 더 자세히 살펴보자.

00:15:15.000 --> 00:15:19.000
탭이 없으면, 나는 기본적으로 모든 인스턴스를 사용할 것이다.

00:15:19.000 --> 00:15:24.000
탭 위치를 인스턴스 마스크의 픽셀에 매핑하고 싶습니다.

00:15:24.000 --> 00:15:27.000
여기에 관련된 두 가지 정보가 있다.

00:15:27.000 --> 00:15:33.000
먼저, UI는 탭 위치를 전달하기 전에 0, 1로 정상화합니다.

00:15:33.000 --> 00:15:38.000
디스플레이 해상도와 스케일링 요인과 같은 세부 사항에 대해 걱정할 필요가 없기 때문에 이것은 좋다.

00:15:38.000 --> 00:15:44.000
둘째, 왼쪽 상단에 원점이 있는 기본 UIKit 좌표계를 사용합니다.

00:15:44.000 --> 00:15:48.000
이것은 픽셀 버퍼의 이미지 공간 좌표와 일치한다.

00:15:48.000 --> 00:15:53.000
그래서 나는 기존의 비전 도우미 기능을 사용하여 이 변환을 수행할 수 있다.

00:15:53.000 --> 00:15:58.000
나는 이제 탭된 인스턴스 라벨을 찾는 데 필요한 모든 정보를 가지고 있다.

00:15:58.000 --> 00:16:04.000
이것은 픽셀 버퍼의 데이터에 직접 접근하는 것을 포함하며, 다음에 어떻게 하는지 보여드리겠습니다.

00:16:04.000 --> 00:16:08.000
라벨을 받으면, 0인지 확인한다.

00:16:08.000 --> 00:16:12.000
제로 라벨은 사용자가 배경 픽셀을 탭했다는 것을 의미한다는 것을 기억하세요.

00:16:12.000 --> 00:16:15.000
이 경우, 나는 모든 경우를 선택하는 것으로 되돌아갈 것이다.

00:16:15.000 --> 00:16:20.000
그렇지 않으면, 나는 선택한 라벨만 있는 싱글톤 세트를 반환할 것이다.

00:16:20.000 --> 00:16:24.000
이 약간의 코드는 인스턴스 라벨 조회가 어떻게 수행되는지를 채웁니다.

00:16:24.000 --> 00:16:29.000
다른 픽셀 버퍼와 마찬가지로, 데이터에 접근하기 전에 먼저 잠가야 합니다.

00:16:29.000 --> 00:16:33.000
읽기 전용 접근은 우리의 목적에 충분하다.

00:16:33.000 --> 00:16:42.000
픽셀 버퍼의 행은 정렬을 위해 패딩될 수 있으므로, 픽셀의 바이트 오프셋을 계산하는 가장 강력한 방법은 bytesPerRow 값을 사용하는 것입니다.

00:16:42.000 --> 00:16:50.000
instanceMask는 단일 채널 UInt8 버퍼이기 때문에, 추가 스케일링에 대해 걱정할 필요가 없습니다.

00:16:50.000 --> 00:16:53.000
나는 인스턴스 마스크에서 읽기를 마쳤기 때문에, 버퍼의 잠금을 해제할 수 있다.

00:16:53.000 --> 00:16:58.000
그리고 그것을 마무리하면서, 나는 선택된 인스턴스가 격리된 마스크를 가지고 있다.

00:16:58.000 --> 00:17:01.000
나는 이제 효과를 적용하는 것으로 넘어갈 수 있다.

00:17:01.000 --> 00:17:04.000
여기서 첫 번째 단계는 선택한 효과를 배경에 적용하는 것이다.

00:17:04.000 --> 00:17:11.000
그것이 완료되면, 나는 CoreImage를 사용하여 변형된 배경 위에 마스크된 피사체를 합성할 것이다.

00:17:11.000 --> 00:17:17.000
처음 몇 가지 효과는 기존 CoreImage 필터의 매우 간단하고 직접적인 적용이다.

00:17:17.000 --> 00:17:23.000
예를 들어, 주제를 강조하기 위해, 나는 배경을 어둡게 하기 위해 노출 조정 필터를 사용했다.

00:17:23.000 --> 00:17:26.000
보케 효과는 약간 더 관련이 있다.

00:17:26.000 --> 00:17:31.000
배경을 흐리게 하는 것 외에도, 나는 우리가 선택한 주제를 강조하는 후광을 원한다.

00:17:31.000 --> 00:17:35.000
흐리게 하기 전에 피사체를 위한 흰색 컷아웃이 트릭을 할 것이다.

00:17:35.000 --> 00:17:43.000
이것을 달성하는 빠른 방법은 우리의 현재 기능을 재사용하고 피사체에 대한 단단한 흰색 이미지를 전달하는 것이다.

00:17:43.000 --> 00:17:46.000
그리고 그것으로, 나는 합성을 위한 베이스 레이어를 가지고 있다.

00:17:46.000 --> 00:17:51.000
마지막으로, 나는 이전의 CoreImage 블렌딩 스니펫을 떨어뜨릴 것이다.

00:17:51.000 --> 00:17:57.000
이것은 새로 변형된 배경 위에 들어 올려진 피사체를 합성한다.

00:17:57.000 --> 00:18:02.000
그리고 효과 파이프라인의 마지막 부분과 함께, 앱은 이제 완성되었다.

00:18:02.000 --> 00:18:07.000
나는 그것이 당신에게 새로운 주제 리프팅 API로 가능한 것을 맛보게 해주기를 바랍니다.

00:18:07.000 --> 00:18:13.000
요약하자면, VisionKit은 주제에 대한 리프팅을 앱에 통합하는 가장 빠른 방법입니다.

00:18:13.000 --> 00:18:18.000
고급 애플리케이션의 경우, Vision의 API로 드롭다운할 수 있습니다.

00:18:18.000 --> 00:18:25.000
그리고 마지막으로, CoreImage는 피사체 리프팅으로 HDR 지원 이미지 처리를 수행하기 위한 완벽한 동반자입니다.

00:18:25.000 --> 00:18:30.000
리지와 나는 당신이 이 비디오를 즐겼기를 바라며, 우리는 당신이 무엇을 만드는지 보게 되어 매우 기쁩니다.

00:18:30.000 --> 23:59:59.000
♪ ♪

