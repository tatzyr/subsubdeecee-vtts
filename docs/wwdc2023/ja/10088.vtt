WEBVTT

00:00:00.000 --> 00:00:03.000
♪まろやかなインストゥルメンタルヒップホップ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:11.000
ジョン・カルスベーク:ようこそ!

00:00:11.000 --> 00:00:13.000
私はジョンで、RealityKitに取り組んでいます。

00:00:13.000 --> 00:00:15.000
ウラジミール・ヴキチェヴィッチ:そして、私はユニティ出身のヴラドです。

00:00:15.000 --> 00:00:20.000
ジョン：没入型アプリのUnityサポートを導入できることに興奮しています。

00:00:20.000 --> 00:00:25.000
UnityはAppleと協力して、この新しいプラットフォームに完全なUnity体験をもたらしました。

00:00:25.000 --> 00:00:32.000
Unityは何万ものアプリで使用されており、Unityを使用して没入型アプリを構築できるようになりました。

00:00:32.000 --> 00:00:38.000
Tribandは、Unityで構築されたApple Arcadeのタイトル「What The Golf?」をこのプラットフォームに持ち込んだ。

00:00:38.000 --> 00:00:43.000
iPhoneでプレイするのは本当に楽しいし、このようにプレイするのは素晴らしい気分です。

00:00:43.000 --> 00:00:49.000
Unityを使用して、このプラットフォームで没入型体験を作成するには、主に2つのアプローチがあります。

00:00:49.000 --> 00:00:59.000
没入型エクスペリエンスとして、または他のアプリと一緒に共有スペースで、パススルーを使用してコンテンツと現実世界のオブジェクトをミックスするエクスペリエンスを作成できます。

00:00:59.000 --> 00:01:03.000
また、完全に没入型のUnity体験をプラットフォームに持ち込むこともできます。

00:01:03.000 --> 00:01:11.000
このアプローチに興味がある場合は、「Unity VRアプリを完全に没入感のある空間に活用する」をチェックすることをお勧めします。

00:01:11.000 --> 00:01:17.000
Unityで共有スペースの体験を作成することは、アプリにエキサイティングな機会を開きます。

00:01:17.000 --> 00:01:20.000
ヴラドが詳しくお伝えします。

00:01:20.000 --> 00:01:21.000
ウラジミール:ありがとう、ジョン。

00:01:21.000 --> 00:01:27.000
UnityとAppleは、Unityのコンテンツがプラットフォーム上で素晴らしく見えるようにするために、過去2年間協力してきました。

00:01:27.000 --> 00:01:40.000
既存のプロジェクトから始める場合でも、まったく新しいものを構築する場合でも、Unityは使い慣れたツールといくつかの新しい機能を使用して没入感のある体験を作成するための素晴らしいツールです。

00:01:40.000 --> 00:01:46.000
このプラットフォームでは、Unityのシェーダーとマテリアルを使用して、必要な視覚的な外観を実現できます。

00:01:46.000 --> 00:01:52.000
デバイスに直接プレイモードに入る機能を導入し、反復時間を改善しています。

00:01:52.000 --> 00:02:00.000
また、Unityシーンのコンテンツがどのように現実世界に持ち込まれるかを制御するボリュームカメラと呼ばれる新しいコンセプトもあります。

00:02:00.000 --> 00:02:08.000
この新しいデバイスへの入力は、ルックアンドタップジェスチャーと同じくらい簡単にしたり、より複雑なインタラクションを伴うことができます。

00:02:08.000 --> 00:02:14.000
そして、空間コンピューティング用のUnityコンテンツを準備するために、今日できることがいくつかあります。

00:02:14.000 --> 00:02:17.000
以下は、これらの要素のいくつかが連携している例です。

00:02:17.000 --> 00:02:26.000
このシーンは、Unityのシェーダーグラフで構築された素材を使用し、パススルーでシミュレータの共有スペースに表示されています。

00:02:26.000 --> 00:02:32.000
後ろの鬼のように、完全に装備されたアニメーションキャラクターがいます。

00:02:32.000 --> 00:02:35.000
物理学の相互作用は、あなたが慣れているように機能します。

00:02:35.000 --> 00:02:45.000
この町のすべての住民は、キャラクターナビゲーションを使用して動き回っており、カスタムの動的スクリプト化された動作を使用して、このシーンを生き生きと感じさせます。

00:02:45.000 --> 00:02:56.000
アセットストアの助けを借りて2週間でこれをまとめました。あなたのスペースで見ると見栄えが良く、近くであらゆる角度からシーンを見ることができます。

00:02:56.000 --> 00:03:00.000
共有スペース内のすべてのコンテンツは、RealityKitを使用してレンダリングされます。

00:03:00.000 --> 00:03:05.000
Unityの素材とシェーダーは、この新しい環境に翻訳する必要があります。

00:03:05.000 --> 00:03:14.000
UnityはPolySpatialを作成しました。これは、この翻訳を処理し、この環境に多くのUnity機能をもたらします。

00:03:14.000 --> 00:03:23.000
PolySpatialは、材料、規則的およびスキンされたメッシュレンダリング、および粒子効果とスプライトを変換します。

00:03:23.000 --> 00:03:31.000
Unityシミュレーション機能がサポートされており、MonoBehaviours、スクリプト可能なオブジェクト、およびその他の標準ツールを引き続き使用します。

00:03:31.000 --> 00:03:34.000
3つのカテゴリーの資料が翻訳されています。

00:03:34.000 --> 00:03:41.000
それらは物理的ベースの材料、カスタム材料、およびいくつかの特殊効果材料です。

00:03:41.000 --> 00:03:47.000
Unityの物理ベースのシェーダーに基づく素材は、RealityKitに直接翻訳されます。

00:03:47.000 --> 00:03:55.000
ユニバーサルレンダリングパイプラインを使用している場合は、材料にLit、Simple Lit、またはComplex Litシェーダーのいずれかを使用できます。

00:03:55.000 --> 00:03:59.000
パイプラインが組み込まれているため、標準シェーダーを使用できます。

00:03:59.000 --> 00:04:04.000
これらはすべて、RealityKit PhysicallyBasedMaterialに翻訳されます。

00:04:04.000 --> 00:04:09.000
カスタムシェーダーとマテリアルタイプは、Unity Shader Graphを通じてサポートされています。

00:04:09.000 --> 00:04:17.000
Unity Shaderグラフは、複雑な材料の標準的な交換形式であるMaterialXに変換されます。

00:04:17.000 --> 00:04:22.000
MaterialXシェーダーは、RealityKitのShaderGraphMaterialになります。

00:04:22.000 --> 00:04:28.000
多くのUnity Shader Graphノードがサポートされているため、複雑で興味深い効果を作成できます。

00:04:28.000 --> 00:04:36.000
手書きシェーダーはRealityKitによるレンダリングにはサポートされていませんが、UnityのRenderTexturesで使用できます。

00:04:36.000 --> 00:04:44.000
その後、そのRenderTextureをShader Graphへのテクスチャ入力として使用して、RealityKitを介して表示することができます。

00:04:44.000 --> 00:04:47.000
2つの追加のマテリアルシェーダータイプがサポートされています。

00:04:47.000 --> 00:04:55.000
まず、Unlit Shaderで、照明の影響を受けずに単色や質感のオブジェクトを作成できます。

00:04:55.000 --> 00:05:01.000
2つ目は、オブジェクトを介してパススルーを表示できるようにするオクルージョンシェーダーです。

00:05:01.000 --> 00:05:09.000
オクルージョンシェーダーをワールドメッシュデータと一緒に使用して、コンテンツが現実世界とより統合されていると感じることができます。

00:05:09.000 --> 00:05:16.000
Unity MeshRenderersとSkinnedMeshRenderersはサポートされており、ビジュアルコンテンツを実際の空間に持ち込む主な方法です。

00:05:16.000 --> 00:05:20.000
装備されたキャラクターとアニメーションが利用可能です。

00:05:20.000 --> 00:05:29.000
ユニバーサルまたは組み込みのレンダリングパイプラインのいずれかを使用でき、コンテンツはUnity PolySpatialを介してRealityKitに翻訳されます。

00:05:29.000 --> 00:05:39.000
RealityKitが最終的なレンダリングを実行するため、後処理効果やカスタムパイプラインステージなどのレンダリング機能は利用できません。

00:05:39.000 --> 00:05:49.000
UnityのShurikenシステムを使用したパーティクルエフェクトは、互換性がある場合はRealityKitのパーティクルシステムに翻訳されるか、ベイクドメッシュに変換されます。

00:05:49.000 --> 00:05:56.000
スプライトは3Dメッシュになりますが、空間的な文脈でどのように使用するかを検討する必要があります。

00:05:56.000 --> 00:06:01.000
PolySpatialは、UnityとRealityKitの間のレンダリングを最適化し、翻訳するために機能します。

00:06:01.000 --> 00:06:15.000
Unityのシミュレーション機能は、物理学、アニメーションとタイムライン、パスファインディングとNavMesh、カスタムMonoBehaviours、その他の非レンダリング機能など、慣れているように機能します。

00:06:15.000 --> 00:06:22.000
外観を微調整し、反復を高速化するために、Unity PolySpatialは「デバイスに再生」を有効にします。

00:06:22.000 --> 00:06:27.000
デバイス上のコンテンツがどのように見えるかを確認するには、ビルドプロセスに時間がかかる場合があります。

00:06:27.000 --> 00:06:32.000
PolySpatialを使用すると、初めてデバイスに再生できます。

00:06:32.000 --> 00:06:38.000
デバイスに再生すると、シーンのインスタントプレビューを見たり、ライブで変更を加えたりできます。

00:06:38.000 --> 00:06:43.000
シミュレーターで動作し、デバイスでもうまく機能します。

00:06:43.000 --> 00:06:51.000
Play to Deviceを使用すると、要素の追加や削除など、コンテンツの配置とサイズを迅速に探索できます。

00:06:51.000 --> 00:07:00.000
マテリアル、テクスチャ、さらにはシェーダーグラフを変更して、パススルーでコンテンツを所定の位置に表示しながら外観を微調整できます。

00:07:00.000 --> 00:07:05.000
イベントがエディタに送り返されるため、インタラクションをテストできます。

00:07:05.000 --> 00:07:12.000
シミュレーションは引き続き実行されるので、エディタに添付するだけで簡単にデバッグできます。

00:07:12.000 --> 00:07:15.000
これはあなたが先ほど見たのと同じ城のシーンです。

00:07:15.000 --> 00:07:22.000
左側のUnityで開いていて、デバイスにプレイすると、右側のシミュレータで実行されているのが見えます。

00:07:22.000 --> 00:07:26.000
シーンにドラッグするだけで、さらに鬼を追加できます。

00:07:26.000 --> 00:07:30.000
それらはシミュレーターまたはデバイスで即座に表示されます。

00:07:30.000 --> 00:07:35.000
ピンクやネオングリーンの鬼がどのように見えるか見たい場合は、できます。

00:07:35.000 --> 00:07:45.000
デバイスへの再生は、コンテンツを反復するための非常に効率的なワークフローであり、現在、共有スペースでコンテンツを作成するためにのみUnityで利用可能です。

00:07:45.000 --> 00:07:57.000
Unityを使用して共有スペースに参加するボリュームコンテンツを作成しているため、ボリュームカメラと呼ばれる新しいコンセプトにより、シーンがどのように現実世界に持ち込まれるかを制御できます。

00:07:57.000 --> 00:08:05.000
ボリュームカメラは、境界と非境界の2種類のボリュームを作成でき、それぞれに異なる特性があります。

00:08:05.000 --> 00:08:09.000
アプリケーションはいつでも2つを切り替えることができます。

00:08:09.000 --> 00:08:14.000
境界付きボリュームは、他のアプリやゲームと並んで、ボリュームとして共有スペースに存在します。

00:08:14.000 --> 00:08:20.000
彼らはUnityの次元と変換、そして特定の現実世界のサイズを持っています。

00:08:20.000 --> 00:08:26.000
配置を変更できますが、サイズを変更することはできません。

00:08:26.000 --> 00:08:33.000
ボリュームカメラの寸法と変換は、アプリがボリュームで表示するシーンの領域を定義します。

00:08:33.000 --> 00:08:36.000
それらはシーンユニットで指定されています。

00:08:36.000 --> 00:08:41.000
Unityのシーンビューでは、ボリュームのプレビューを緑色で見ることができます。

00:08:41.000 --> 00:08:49.000
ボリュームカメラの寸法と変換を操作することで、シーンのさまざまな部分をボリュームに取り込むことができます。

00:08:49.000 --> 00:08:55.000
カメラを動かしたり回転したりすると、新しい物体が私の空間に見えてくります。

00:08:55.000 --> 00:09:00.000
サイズを大きくすると、より多くのシーンが視界に入ります。

00:09:00.000 --> 00:09:04.000
どちらの場合も、ボリュームは同じサイズのままです。

00:09:04.000 --> 00:09:08.000
その中に表示されているコンテンツのみが変更されます。

00:09:08.000 --> 00:09:16.000
ボリュームカメラの最初の配置では、スプリングがボリュームの側面と交差することに注意してください。コンテンツはRealityKitによってクリップされます。

00:09:16.000 --> 00:09:28.000
ボリュームの端と交差するコンテンツがある場合は、クリップされたセクションを埋めるために、後ろ向きの素材でシーンに同じメッシュをもう一度配置することを検討してください。

00:09:28.000 --> 00:09:38.000
無制限のボリュームは、このプラットフォームの完全なスペースに表示され、コンテンツがより没入感のある体験のためにパススルーと完全にブレンドすることができます。

00:09:38.000 --> 00:09:47.000
シーン全体を選択するため、ディメンションはなく、その変換はシーンユニットが現実世界のユニットにどのようにマッピングされるかを指定します。

00:09:47.000 --> 00:09:52.000
一度にアクティブになる無制限のボリュームカメラは1つだけです。

00:09:52.000 --> 00:09:57.000
インタラクションについて話すと、無制限のボリュームの例が表示されます。

00:09:57.000 --> 00:10:01.000
Unityは、このプラットフォーム上のアプリの複数の入力タイプをサポートしています。

00:10:01.000 --> 00:10:09.000
このプラットフォームでは、人々は目と手を使ってコンテンツを見て、指を合わせて選択します。

00:10:09.000 --> 00:10:14.000
フルハンドトラッキングとヘッドポーズデータにより、現実的なインタラクションを作成できます。

00:10:14.000 --> 00:10:23.000
ARKitの拡張現実データは、キーボードやゲームコントローラーなどのBluetoothデバイスと同様に利用可能です。

00:10:23.000 --> 00:10:29.000
タップジェスチャーは、このプラットフォーム上のコンテンツとやり取りする最も一般的な方法です。

00:10:29.000 --> 00:10:34.000
オブジェクトがこれらのイベントを受信するには、入力コライダーが設定されている必要があります。

00:10:34.000 --> 00:10:42.000
見てタップして遠くからオブジェクトを選択することも、手を伸ばして指でオブジェクトに直接触れることもできます。

00:10:42.000 --> 00:10:46.000
最大2つの同時タップアクションが進行中です。

00:10:46.000 --> 00:10:50.000
Unityでは、タップはWorldTouchイベントとして利用できます。

00:10:50.000 --> 00:10:56.000
それらは2Dタップイベントに似ていますが、完全な3Dポジションを持っています。

00:10:56.000 --> 00:11:06.000
手と頭のポーズトラッキングは、各ハンドジョイントとグローバルトラッキングオリジンに対する視聴者の頭の位置に関する正確な情報をアプリケーションに提供します。

00:11:06.000 --> 00:11:14.000
低レベルのハンドデータはUnityのHandsパッケージを介して提供され、ヘッドポーズは入力システムを通じて提供されます。

00:11:14.000 --> 00:11:23.000
これらは両方とも無制限のボリュームでのみ利用可能であり、ハンドトラッキングにアクセスするには、アプリケーションがデータを受け取る許可を要求する必要があります。

00:11:23.000 --> 00:11:33.000
検出された飛行機、ワールドメッシュ、画像マーカーなどの拡張現実データは、ARKitとUnityのAR Foundationを通じて入手できます。

00:11:33.000 --> 00:11:41.000
手や頭のポーズと同様に、ARデータは無制限のボリュームでのみ利用可能で、追加の許可が必要です。

00:11:41.000 --> 00:11:51.000
最後に、キーボード、コントローラー、その他のサポートされているデバイスなどのBluetoothデバイスは、Unityの入力システムからアクセスできます。

00:11:51.000 --> 00:12:00.000
一部のタイプの入力は無制限のボリュームでのみ使用できるため、構築するインタラクションの種類を決定する必要があります。

00:12:00.000 --> 00:12:15.000
ルックアンドタップを使用すると、コンテンツは他のアプリケーションと一緒に使用できる制限されたボリュームで機能しますが、ハンドトラッキングや拡張現実データにアクセスする必要がある場合は、制限されていないボリュームを使用して許可を要求する必要があります。

00:12:15.000 --> 00:12:21.000
これらのそれぞれは、適切なメカニズムを介してUnityアプリケーションに配信されます。

00:12:21.000 --> 00:12:28.000
このサンプルでは、無制限のボリュームシーンでタップ、ハンドトラッキング、平面検出を使用します。

00:12:28.000 --> 00:12:36.000
ARKitの平面検出で見つかった表面を見て、それに沿って指をドラッグして花を作ることができます。

00:12:36.000 --> 00:12:42.000
花はハンドトラッキングで描かれており、タップして花を育てることができます。

00:12:42.000 --> 00:12:47.000
あなたが育てた花は、Unityの物理システムを使って手の動きに反応します。

00:12:47.000 --> 00:12:54.000
このように現実世界をコンテンツに組み込むことで、より深い没入感を生み出すことができます。

00:12:54.000 --> 00:12:58.000
既存のインタラクションを適応させる最善の方法は、タイプによって異なります。

00:12:58.000 --> 00:13:08.000
iPhoneなど、すでにタッチで作業している場合は、適切な入力コライダーを追加し、タップを主要な入力メカニズムとして引き続き使用できます。

00:13:08.000 --> 00:13:18.000
VRコントローラーを使用している場合は、複雑さに応じて、タップまたはハンドベースの入力の観点からインタラクションを再定義する必要があります。

00:13:18.000 --> 00:13:23.000
既存のハンドベースの入力は、変更なしで機能するはずです。

00:13:23.000 --> 00:13:30.000
また、UnityのUIシステムの1つを使用して既存のUIパネルがある場合は、このプラットフォームに持ち込むことができます。

00:13:30.000 --> 00:13:36.000
uGUIとUIツールキットを使用して構築されたユーザーインターフェイス要素がサポートされています。

00:13:36.000 --> 00:13:46.000
他のUIシステムを使用している場合は、メッシュとMeshRendererを使用するか、RenderTextureに描画し、メッシュに配置される限り動作します。

00:13:46.000 --> 00:13:52.000
Appleプラットフォームでの空間コンピューティングのサポートは、Unity 2022をベースにしたベータ版で間もなく提供される予定です。

00:13:52.000 --> 00:13:57.000
しかし、今日からコンテンツの準備を始めることができます。

00:13:57.000 --> 00:14:02.000
新しいプロジェクトを開始する場合は、Unity 2022以降を使用してください。

00:14:02.000 --> 00:14:07.000
既存のプロジェクトがある場合は、2022年にアップグレードを開始してください。

00:14:07.000 --> 00:14:13.000
プロジェクトに手書きのシェーダーがある場合は、シェーダーグラフに変換し始めます。

00:14:13.000 --> 00:14:16.000
ユニバーサルレンダリングパイプラインの採用を検討してください。

00:14:16.000 --> 00:14:24.000
組み込みのグラフィックスパイプラインはサポートされていますが、将来のすべての改善はユニバーサルパイプラインで行われます。

00:14:24.000 --> 00:14:28.000
まだ使用していない場合は、入力システムパッケージの使用を開始してください。

00:14:28.000 --> 00:14:34.000
混合モード入力はサポートされていますが、プラットフォームイベントは入力システムを介してのみ配信されます。

00:14:34.000 --> 00:14:43.000
最後に、既存のアプリやゲームを空間コンピューティングに持ち込む方法、またはどのような新しい体験を作りたいかについて考え始めます。

00:14:43.000 --> 00:14:52.000
あなたのアイデアが人々により多くの柔軟性を与えるために共有スペースに収まるかどうか、またはあなたのアプリがフルスペースの力を必要とするかどうかを検討してください。

00:14:52.000 --> 00:15:01.000
このプラットフォームに対するUnityのサポートに関する詳細情報を入手し、早期ベータアクセスにサインアップするには、unity.com/spatialにアクセスしてください。

00:15:01.000 --> 00:15:08.000
私はあなたがUnityとこの新しいデバイスで作成するすべての素晴らしいものを見ることに興奮しています。

00:15:08.000 --> 00:15:12.000
ジョン：Unityは、稼働し、没入型アプリを構築する素晴らしい方法です。

00:15:12.000 --> 00:15:15.000
そして、この新しいプラットフォームでRealityKitとうまく機能します。

00:15:15.000 --> 00:15:18.000
プロジェクトの準備を今日から始めることができます。

00:15:18.000 --> 00:15:27.000
Unityで完全に没入感のある体験を作りたい場合は、「Unity VRアプリを完全に没入感のある空間に」というセッションをお勧めします。

00:15:27.000 --> 00:15:34.000
そして、このプラットフォームのゲーム開発技術の概要を知るために、「空間コンピューティングのための素晴らしいゲームを構築する」をお見逃しなく。

00:15:34.000 --> 00:15:37.000
あなたが作ったものを見るのが待ちきれません。

00:15:37.000 --> 00:15:39.000
ウラジミール:見てくれてありがとう。

00:15:39.000 --> 23:59:59.000
♪

