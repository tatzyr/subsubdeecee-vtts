WEBVTT

00:00:00.000 --> 00:00:04.000
♪まろやかなインストゥルメンタルヒップホップ♪

00:00:04.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:13.000
Lei Zhou: こんにちは、私はオブジェクトキャプチャチームのLeiです。

00:00:13.000 --> 00:00:20.000
このセッションでは、同僚のモナと私は、iOS用のオブジェクトキャプチャを紹介します。

00:00:20.000 --> 00:00:26.000
始める前に、オブジェクトキャプチャとは何か、そしてそれが今日どのように機能するかを確認しましょう。

00:00:26.000 --> 00:00:36.000
オブジェクトキャプチャは、最先端のコンピュータビジョン技術を使用して、さまざまな角度で撮影された一連の画像からリアルな3Dモデルを作成します。

00:00:36.000 --> 00:00:44.000
これらの画像はMacに転送され、Object Capture APIを使用して数分で3Dモデルを再構築します。

00:00:44.000 --> 00:00:52.000
Mac用APIのリリース以来、オブジェクトキャプチャを活用して高品質の3Dモデルを生成する多くのアプリを見てきました。

00:00:52.000 --> 00:00:55.000
私たちはあなたから多くのフィードバックを受けています。

00:00:55.000 --> 00:01:02.000
私たちは今、iOSに完全なオブジェクトキャプチャ体験をもたらすために大きな一歩を踏み出しています!

00:01:02.000 --> 00:01:11.000
これは、ユーザーフレンドリーなインターフェースとデバイス上のモデル再構築の両方でキャプチャできるようになったことを意味します。

00:01:11.000 --> 00:01:15.000
また、このワークフローをiOSで実証するためのサンプルアプリも提供しています。

00:01:15.000 --> 00:01:18.000
動作中のサンプルアプリを見てみましょう。

00:01:18.000 --> 00:01:24.000
サンプルアプリを使用して、美しい花瓶の3Dモデルを簡単に作成します。

00:01:24.000 --> 00:01:27.000
まず、サンプルアプリを開き、オブジェクトにポイントします。

00:01:27.000 --> 00:01:32.000
キャプチャを開始する前に、自動バウンディングボックスが生成されます。

00:01:32.000 --> 00:01:38.000
次に、オブジェクトを一周し、オブジェクトキャプチャが自動的に適切な画像をキャプチャします。

00:01:38.000 --> 00:01:49.000
より多くの画像が必要な地域に関する視覚的なガイダンスと、最高品質のショットをキャプチャするのに役立つ追加のフィードバックメッセージを提供します。

00:01:49.000 --> 00:01:55.000
1つの軌道を終えたら、オブジェクトをひっくり返して底を捉えることができます。

00:01:55.000 --> 00:02:04.000
3つのセグメントのスキャンが完了したら、iOSデバイスでローカルで実行される再構築段階に進みます。

00:02:04.000 --> 00:02:08.000
わずか数分で、USDZモデルが使用可能になります。

00:02:08.000 --> 00:02:18.000
開発者ドキュメントの一部として、このアプリのソースコードを提供しているので、すぐにダウンロードして自分で試すことができます。

00:02:18.000 --> 00:02:23.000
また、独自のアプリケーションを作成するための出発点として使用することもできます。

00:02:23.000 --> 00:02:32.000
新しいサンプルアプリでオブジェクトキャプチャのデモを見たので、今年はすべての新しいエキサイティングな機能に移りましょう。

00:02:32.000 --> 00:02:39.000
まず、LiDARを使用してより多くのオブジェクトのスキャンをサポートするオブジェクトキャプチャの改善点を紹介します。

00:02:39.000 --> 00:02:45.000
次に、オブジェクトのデータキャプチャを簡素化するガイド付きキャプチャ機能を実演します。

00:02:45.000 --> 00:02:52.000
次に、Object Capture APIを使用してiOSでオブジェクトキャプチャフローを作成する方法を説明します。

00:02:52.000 --> 00:02:58.000
最後に、モデル再構築機能のいくつかの新しい機能強化を強調します。

00:02:58.000 --> 00:03:02.000
まず、LiDARでより多くのオブジェクトのサポートを見てみましょう。

00:03:02.000 --> 00:03:08.000
高品質の3Dモデルを作成するには、優れた特性を持つオブジェクトを選択することが重要です。

00:03:08.000 --> 00:03:17.000
当社のオブジェクトキャプチャシステムは、十分なテクスチャの詳細を持つオブジェクトに最適ですが、今年はさらに改善しました。

00:03:17.000 --> 00:03:22.000
現在、LiDARスキャナーを活用して、低質感のオブジェクトの再構築をサポートしています。

00:03:22.000 --> 00:03:25.000
この椅子を例として見てみましょう。

00:03:25.000 --> 00:03:30.000
テクスチャの詳細が欠けているため、オブジェクトキャプチャが優れたモデルを作成するのが困難です。

00:03:30.000 --> 00:03:35.000
しかし、LiDARを使用すると、より良い品質で再構築することができます。

00:03:35.000 --> 00:03:39.000
キャプチャ中に、この椅子のRGB写真を撮ります。

00:03:39.000 --> 00:03:45.000
しかし、シートとバックはテクスチャレスであるため、その完全なモデルを回復することはできません。

00:03:45.000 --> 00:03:58.000
RGB画像に加えて、当社のAPIはLiDARで点群データも収集し、カバレッジと密度が向上したオブジェクトの3D形状の包括的な表現を生成するのに役立ちます。

00:03:58.000 --> 00:04:04.000
最後に、融合点のクラウドデータから完全な3Dモデルが生成されます。

00:04:04.000 --> 00:04:14.000
これは、当社のLiDAR対応システムによって品質が改善された追加の低テクスチャオブジェクトのモデルです。

00:04:14.000 --> 00:04:20.000
現在、低テクスチャのオブジェクトをサポートしていますが、一部のオブジェクトにはまだ課題があります。

00:04:20.000 --> 00:04:27.000
反射的、透明、または非常に薄い構造を含む物体を避けるのが最善です。

00:04:27.000 --> 00:04:36.000
どのオブジェクトがサポートされているかを見たので、ガイド付きキャプチャを使用してオブジェクトを簡単にスキャンする方法を詳しく見てみましょう。

00:04:36.000 --> 00:04:41.000
画像とLiDARデータを自動的にキャプチャするガイド付きキャプチャを提供します。

00:04:41.000 --> 00:04:45.000
また、キャプチャプロセス中に有用なフィードバックを提供します。

00:04:45.000 --> 00:04:50.000
さらに、オブジェクトを反転させるべきかどうかについてのガイダンスを提供します。

00:04:50.000 --> 00:04:58.000
良い視野角を手動で選択してボタンを押すことを要求するのではなく、データキャプチャ体験を自動化します。

00:04:58.000 --> 00:05:12.000
オブジェクトの周りを一周すると、当社のシステムは、良好なシャープネス、明瞭さ、露出を持つ画像ショットを自動的に選択し、さまざまな視野角からLiDARポイントを収集します。

00:05:12.000 --> 00:05:19.000
オブジェクトのすべての詳細をキャプチャするには、できるだけ多くの角度から写真を撮ることを強くお勧めします。

00:05:19.000 --> 00:05:25.000
オブジェクトのどの領域に十分な画像があるかを示すキャプチャダイヤルを提供します。

00:05:25.000 --> 00:05:32.000
あらゆる角度からオブジェクトをスキャンして、キャプチャダイヤルを完全に充填することをお勧めします。

00:05:32.000 --> 00:05:38.000
自動キャプチャに加えて、キャプチャプロセス中にお客様を支援するためのリアルタイムのフィードバックを提供します。

00:05:38.000 --> 00:05:44.000
まず、正確な色表現を得るために、環境に良い照明があることを確認してください。

00:05:44.000 --> 00:05:49.000
暗すぎると、照明条件を調整するためのリマインダーが届きます。

00:05:49.000 --> 00:05:55.000
物体表面の反射やハイライトを最小限に抑えるために、拡散光を使用することをお勧めします。

00:05:55.000 --> 00:06:03.000
次に、ぼやけた画像を避けるために、カメラをしっかりと持ちながら、ゆっくりとスムーズに物体の周りを移動します。

00:06:03.000 --> 00:06:09.000
動きが速すぎると、自動キャプチャが停止し、減速するように思い出させます。

00:06:09.000 --> 00:06:17.000
第三に、オブジェクトがカメラフレームに適切に収まるように、カメラとオブジェクトの間に適切な距離を維持します。

00:06:17.000 --> 00:06:23.000
距離が遠すぎたり近すぎたりすると、テキストリマインダーが表示されます。

00:06:23.000 --> 00:06:26.000
最後に、常にオブジェクトをフレーム内に保持します。

00:06:26.000 --> 00:06:39.000
オブジェクトが視野外に行くと、自動キャプチャが一時停止し、矢印記号が表示され、表示方向を調整することを思い出させます。

00:06:39.000 --> 00:06:45.000
オブジェクトの完全な3Dモデルを取得するには、そのすべての側面をキャプチャすることが重要です。

00:06:45.000 --> 00:06:48.000
オブジェクトを反転させると、これを達成するのに役立ちます。

00:06:48.000 --> 00:06:52.000
しかし、オブジェクトを反転させるかどうかは、その属性に依存します。

00:06:52.000 --> 00:06:56.000
あなたのオブジェクトが硬い場合、反転は良い考えです。

00:06:56.000 --> 00:07:02.000
しかし、変形可能なオブジェクトの場合、形状が簡単に変化する可能性があるため、動かさない方が良いです。

00:07:02.000 --> 00:07:14.000
テクスチャが豊富なオブジェクトの場合は、反転が推奨されますが、システムに誤解を招く可能性があるため、対称的または反復的なテクスチャを持つオブジェクトを反転させないようにすることが重要です。

00:07:14.000 --> 00:07:24.000
さらに、テクスチャレスオブジェクトを反転させると、異なるセグメントを縫い合わせるのに十分なテクスチャが必要なため、オブジェクトキャプチャにとって困難な場合があります。

00:07:24.000 --> 00:07:31.000
これを助けるために、オブジェクトが反転するのに十分なテクスチャであるかどうかを提案するAPIを提供します。

00:07:31.000 --> 00:07:40.000
オブジェクトを反転させる場合は、すべての側面の画像を取得できるように、3つの向きでスキャンすることをお勧めします。

00:07:40.000 --> 00:07:47.000
また、物体の表面の影と反射を最小限に抑えるために、拡散光を使用するのが最善です。

00:07:47.000 --> 00:07:51.000
異なるスキャンパス間の画像の重なりも重要です。

00:07:51.000 --> 00:07:56.000
スキャンパスのオブジェクトの一部は、以前のパスでキャプチャする必要があります。

00:07:56.000 --> 00:08:01.000
オブジェクトを適切に反転させる方法についての視覚的なガイダンスを提供します。

00:08:01.000 --> 00:08:10.000
オブジェクトを反転できない場合は、3つの異なる高さからキャプチャして、さまざまな視野角から画像を取得することをお勧めします。

00:08:10.000 --> 00:08:18.000
主にテクスチャレスオブジェクトの場合、目立つことができるテクスチャ背景に配置することをお勧めします。

00:08:18.000 --> 00:08:24.000
オブジェクトキャプチャは、iPhone 12 Pro、iPad Pro 2021、およびそれ以降のモデルで利用できます。

00:08:24.000 --> 00:08:29.000
お使いのデバイスがオブジェクトキャプチャをサポートしているかどうかを確認するために、簡単な検証のためのAPIを提供しています。

00:08:29.000 --> 00:08:35.000
次に、MononaがObject Capture APIについて詳しく説明します。

00:08:35.000 --> 00:08:36.000
モナ・ユーソフシャヒ:ありがとう、レイ!

00:08:36.000 --> 00:08:44.000
サンプルアプリの動作を見たので、Object Capture APIを使用してこのアプリを作成する方法を見てみましょう。

00:08:44.000 --> 00:08:50.000
デモで見たように、オブジェクトキャプチャには、画像キャプチャとモデル再構築の2つのステップがあります。

00:08:50.000 --> 00:08:53.000
まず、画像キャプチャを見てみましょう。

00:08:53.000 --> 00:08:58.000
Image Capture APIには、セッションとSwiftUIビューの2つの部分があります。

00:08:58.000 --> 00:09:05.000
このセッションでは、画像キャプチャ中にステートマシンの流れを観察および制御できます。

00:09:05.000 --> 00:09:14.000
SwiftUIビューはカメラフィードを表示し、セッションの状態に基づいて表示するUI要素を自動的に適応させます。

00:09:14.000 --> 00:09:18.000
私たちのSwiftUIは、2Dテキストやボタンなしで提供されます。

00:09:18.000 --> 00:09:26.000
これにより、アプリの外観をカスタマイズし、既存のアプリにオブジェクトキャプチャをより簡単に組み込むことができます。

00:09:26.000 --> 00:09:30.000
オブジェクトキャプチャステートマシンを詳しく見てみましょう。

00:09:30.000 --> 00:09:35.000
セッションは、作成時に初期化状態で開始されます。

00:09:35.000 --> 00:09:38.000
次に、状態を進めるために関数呼び出しを行います。

00:09:38.000 --> 00:09:46.000
セッションは、準備、検出、キャプチャ、および終了を通じて移行します。

00:09:46.000 --> 00:09:52.000
終了状態になると、セッションは自動的に完了した状態に移行します。

00:09:52.000 --> 00:09:57.000
この時点で、安全に取り壊して、デバイス上の再構築を続けることができます。

00:09:57.000 --> 00:10:01.000
これを実際に使う方法を見てみましょう。

00:10:01.000 --> 00:10:06.000
RealityKitとSwiftUIをインポートすることから始めます。

00:10:06.000 --> 00:10:10.000
次に、ObjectCaptureSessionのインスタンスを作成します。

00:10:10.000 --> 00:10:20.000
参照型であるため、完了するまで、セッションを地上真実データモデル内に永続状態として保存することをお勧めします。

00:10:20.000 --> 00:10:24.000
これにより、セッションは初期化状態で開始されます。

00:10:24.000 --> 00:10:32.000
キャプチャした画像を保存する場所をセッションに指示するディレクトリを使用して、start()関数を呼び出して続行します。

00:10:32.000 --> 00:10:40.000
また、構成でチェックポイントディレクトリを提供することもできます。これは、後で再構築プロセスを高速化するために使用できます。

00:10:40.000 --> 00:10:44.000
この呼び出しの後、セッションは準備完了状態に移行します。

00:10:44.000 --> 00:10:49.000
ObjectCaptureViewでセッションを使用する方法を見てみましょう。

00:10:49.000 --> 00:10:53.000
私たちは、他のSwiftUIビューと同様にObjectCaptureViewを使用します。

00:10:53.000 --> 00:11:00.000
私たちはそれを別のビューの体の中に置き、作成したばかりの地上の真実のセッションを渡します。

00:11:00.000 --> 00:11:06.000
ObjectCaptureViewは、常にセッションの現在の状態に対応するUIを表示します。

00:11:06.000 --> 00:11:15.000
ここで準備完了状態でわかるように、ビューには、キャプチャするオブジェクトを選択するためのレチクル付きのカメラフィードが表示されます。

00:11:15.000 --> 00:11:23.000
状態を進めるには、アプリはセッションにオブジェクトの検出を開始するように指示するUIを提供する必要があります。

00:11:23.000 --> 00:11:28.000
ここでは、ObjectCaptureViewの上に[続行]ボタンを積み重ねます。

00:11:28.000 --> 00:11:35.000
押すと、startDetecting()関数を呼び出してバウンディングボックスの検出状態に移動します。

00:11:35.000 --> 00:11:43.000
検出状態では、ビューは自動的に変更され、現在検出されたオブジェクトの周りにバウンディングボックスが表示されます。

00:11:43.000 --> 00:11:49.000
必要に応じて、バウンディングボックスのサイズと向きを手動で調整できます。

00:11:49.000 --> 00:11:59.000
当社のサンプルアプリは、別のオブジェクトを選択したい場合にオブジェクト選択プロセスを再開するためのリセットボタンも提供します。

00:11:59.000 --> 00:12:03.000
これにより、セッションは準備状態に戻ります。

00:12:03.000 --> 00:12:14.000
準備から検出への移行と同様に、オブジェクトの選択に満足したら、セッションにキャプチャを開始するように指示するボタンを提供する必要があります。

00:12:14.000 --> 00:12:20.000
ここでは、startCapturing()関数を呼び出すStart Captureボタンを使用します。

00:12:20.000 --> 00:12:24.000
この呼び出しの後、セッションはキャプチャ状態に移行します。

00:12:24.000 --> 00:12:31.000
キャプチャ状態では、オブジェクトの周りをゆっくりと移動しながら、セッションは自動的に画像を取得します。

00:12:31.000 --> 00:12:42.000
ビューには、ポイントクラウドとキャプチャダイヤルが表示され、オブジェクトの十分な画像を収集した場所と、さらにキャプチャする必要がある場所が表示されます。

00:12:42.000 --> 00:12:48.000
スキャンパスは、キャプチャダイヤルが完全に満たされると完了します。

00:12:48.000 --> 00:12:55.000
キャプチャダイヤルが完了すると、セッションはuserCompletedScanPassプロパティをtrueに設定します。

00:12:55.000 --> 00:13:03.000
この時点で、私たちのサンプルアプリは、セッションを終了するか、より多くの画像をキャプチャし続けるオプションを提供します。

00:13:03.000 --> 00:13:07.000
各オプションにボタンを割り当てます。

00:13:07.000 --> 00:13:12.000
最適なモデル再構築のために、3つのスキャンパスを完了することをお勧めします。

00:13:12.000 --> 00:13:16.000
次のスキャンパスに移動する方法を見てみましょう。

00:13:16.000 --> 00:13:23.000
オブジェクトを反転するかどうかに応じて、2つの方法で新しいスキャンパスを開始できます。

00:13:23.000 --> 00:13:32.000
反転を使用すると、オブジェクトの下部など、現在のパスに表示されないオブジェクトの側面をキャプチャできます。

00:13:32.000 --> 00:13:39.000
このため、beginNewScanPassAfterFlip()を呼び出すと、状態を準備完了に戻します。

00:13:39.000 --> 00:13:44.000
その後、新しい向きでボックス選択を実行する必要があります。

00:13:44.000 --> 00:13:51.000
オブジェクトを反転しないことにした場合は、代わりに別の高さでより多くの画像をキャプチャできます。

00:13:51.000 --> 00:13:55.000
このために、beginNewScanPass()を呼び出します。

00:13:55.000 --> 00:14:03.000
これにより、キャプチャダイヤルがリセットされますが、バウンディングボックスが変更されていないため、セッションはキャプチャ状態のままです。

00:14:03.000 --> 00:14:08.000
すべてのパスが完了すると、サンプルアプリは終了ボタンを提供します。

00:14:08.000 --> 00:14:18.000
このボタンは finish() 関数を呼び出し、画像のキャプチャが完了したことをセッションに伝え、仕上げプロセスを開始できます。

00:14:18.000 --> 00:14:23.000
終了状態の間、セッションはすべてのデータが保存されるのを待ちます。

00:14:23.000 --> 00:14:29.000
終了すると、セッションは自動的に完了した状態に移行します。

00:14:29.000 --> 00:14:34.000
私たちは安全にそれを取り壊し、デバイス上の再構築を開始することができます。

00:14:34.000 --> 00:14:44.000
イメージディレクトリが突然使用できなくなった場合など、回復不能なエラーが発生した場合、セッションは失敗した状態に移行します。

00:14:44.000 --> 00:14:49.000
このような場合は、新しいセッションを作成する必要があります。

00:14:49.000 --> 00:15:00.000
そして最後に、点群を表示して、最初に配置された、または最後に反転してから、オブジェクトのどの部分がスキャンされたかをプレビューすることもできます。

00:15:00.000 --> 00:15:07.000
これを行うには、ObjectCapturePointCloudViewをObjectCaptureViewに交換します。

00:15:07.000 --> 00:15:14.000
これにより、キャプチャセッションが一時停止され、ポイントクラウドと対話してあらゆる角度からプレビューできます。

00:15:14.000 --> 00:15:23.000
ここでは、このビューをいくつかのテキストとボタンと組み合わせて表示しますが、ポイントクラウドをフルスクリーンで表示することもできます。

00:15:23.000 --> 00:15:29.000
オブジェクトの画像をキャプチャしたので、その3Dモデルを作成する方法を見てみましょう。

00:15:29.000 --> 00:15:34.000
今年から、iOSで再構築APIを実行できます。

00:15:34.000 --> 00:15:40.000
これにより、同じデバイスで画像キャプチャと再構築を実行できます。

00:15:40.000 --> 00:15:45.000
以下は、非同期再構築APIの使用方法の要約です。

00:15:45.000 --> 00:15:49.000
iOSでもmacOSでも同じように動作します。

00:15:49.000 --> 00:15:54.000
まず、作成したビューにタスク修飾子を添付します。

00:15:54.000 --> 00:15:59.000
タスク修飾子では、フォトグラメトリセッションを作成し、それを画像に向けます。

00:15:59.000 --> 00:16:08.000
オプションで、画像キャプチャ中に使用したのと同じチェックポイントディレクトリを提供して、再構築プロセスを高速化できます。

00:16:08.000 --> 00:16:13.000
次に、process()関数を呼び出してmodelFileを要求します。

00:16:13.000 --> 00:16:20.000
最後に、ループ内のメッセージストリームを待ち、到着した出力メッセージを処理します。

00:16:20.000 --> 00:16:24.000
詳細については、前回の講演を必ず確認してください。

00:16:24.000 --> 00:16:33.000
モバイルデバイスでのモデルの生成と表示を最適化するために、iOSでは削減された詳細レベルのみをサポートします。

00:16:33.000 --> 00:16:41.000
再構築されたモデルには、拡散、アンビエントオクルージョン、および通常のテクスチャマップが含まれており、すべてモバイルディスプレイ用に設計されています。

00:16:41.000 --> 00:16:50.000
他の詳細レベルでモデルを生成したい場合は、再構築のために画像をMacに転送できます。

00:16:50.000 --> 00:16:56.000
今年、Macの再構築は、画像に保存したLiDARデータも利用します。

00:16:56.000 --> 00:17:00.000
新しいオブジェクトキャプチャセッションは、このフローもサポートしています。

00:17:00.000 --> 00:17:02.000
やり方を見てみましょう。

00:17:02.000 --> 00:17:11.000
デフォルトでは、iOSデバイスの再構築制限に達すると、オブジェクトキャプチャセッションは画像のキャプチャを停止します。

00:17:11.000 --> 00:17:18.000
macOSの再構築では、セッションがデバイス上の再構築が使用できるよりも多くの画像を撮影できるようにすることができます。

00:17:18.000 --> 00:17:25.000
これを行うには、セッションの設定でisOverCaptureEnabledをtrueに設定します。

00:17:25.000 --> 00:17:33.000
これらの追加ショットは、デバイス上の再構築には使用されませんが、画像フォルダに保存されます。

00:17:33.000 --> 00:17:37.000
Macで画像を再構築するには、コードを書く必要さえありません。

00:17:37.000 --> 00:17:44.000
Object Captureは、Reality Composer Proと呼ばれる新しいmacOSアプリに統合されています。

00:17:44.000 --> 00:17:51.000
画像をアプリにインポートし、詳細レベルを選択し、モデルを取得するだけです。

00:17:51.000 --> 00:17:57.000
このアプリの詳細については、Reality Composer Proのセッションを必ず見てください。

00:17:57.000 --> 00:18:08.000
新しいiOS APIで3Dモデルを作成する方法を見たので、非常に要求されたいくつかの再構築機能強化を簡単に説明しましょう。

00:18:08.000 --> 00:18:13.000
Macのモデル品質と再構築速度を改善しました。

00:18:13.000 --> 00:18:19.000
進捗率に加えて、推定再建時間を提供しています。

00:18:19.000 --> 00:18:26.000
ポーズ出力とカスタム詳細レベルなど、他の2つの追加について詳しく見てみましょう。

00:18:26.000 --> 00:18:31.000
画像ごとに高品質のポーズをリクエストできるようになりました。

00:18:31.000 --> 00:18:41.000
各ポーズには、当社のコンピュータビジョンアルゴリズムに基づいて、その画像のカメラの推定位置と向きが含まれています。

00:18:41.000 --> 00:18:47.000
ポーズを取得するには、process()関数呼び出しにポーズ要求を追加します。

00:18:47.000 --> 00:18:53.000
次に、出力メッセージストリームに到着したときにポーズ出力を処理します。

00:18:53.000 --> 00:19:00.000
ポーズは、モデルが生成される前に、再構築プロセスの早い段階で返されます。

00:19:00.000 --> 00:19:09.000
今年は、再構築されたモデルを完全に制御できるmacOSの新しいカスタム詳細レベルも追加しました。

00:19:09.000 --> 00:19:15.000
以前は、縮小、中、フル、生の詳細レベルから選択できます。

00:19:15.000 --> 00:19:25.000
カスタム詳細レベルでは、メッシュデシメーションの量、テクスチャマップの解像度、フォーマット、および含めるテクスチャマップを制御できます。

00:19:25.000 --> 00:19:29.000
そして、それはiOS用のオブジェクトキャプチャのラップです。

00:19:29.000 --> 00:19:34.000
オブジェクトキャプチャにより、LiDARサポートでより多くのオブジェクトをスキャンできるようになりました。

00:19:34.000 --> 00:19:41.000
iOSデバイスでモデルを完全にキャプチャ、再構築、表示する方法を紹介しました。

00:19:41.000 --> 00:19:51.000
iOS用オブジェクトキャプチャは、電子商取引、デザイン、教育、ゲームなど、さまざまなアプリケーションの新しいワークフローを可能にします。

00:19:51.000 --> 00:19:56.000
オブジェクトキャプチャをアプリにどのように組み込むかを楽しみにしています。

00:19:56.000 --> 00:19:58.000
見てくれてありがとう!

00:19:58.000 --> 23:59:59.000
♪

