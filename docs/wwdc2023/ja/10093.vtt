WEBVTT

00:00:00.000 --> 00:00:03.000
♪まろやかなインストゥルメンタルヒップホップ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:14.000
クリストファー・フィゲロア：こんにちは、アップルのARKitチームのクリストファー・フィゲロアです。

00:00:14.000 --> 00:00:16.000
ピーター・クーン:そして、私はユニティのピーター・クーンです。

00:00:16.000 --> 00:00:25.000
クリストファー：UnityはエンジンとXRエコシステムをこの新しいプラットフォームに持ち込み、あなたのようなUnity開発者が簡単にプロジェクトを持ち込むことができます。

00:00:25.000 --> 00:00:33.000
ピーターと私は、すでに慣れ親しんでいるUnityワークフローを使用して、ここのRec Roomのような完全に没入感のある体験を構築する方法を紹介します。

00:00:33.000 --> 00:00:37.000
完全な没入型スタイルで没入型スペースを作成することから始めます。

00:00:37.000 --> 00:00:42.000
これにより、アプリはパススルーを隠し、誰かを別の世界に転送することができます。

00:00:42.000 --> 00:00:50.000
完全に没入型の体験で、Unityはコンポジターサービスを利用し、アプリにメタルレンダリング機能のパワーを提供します。

00:00:50.000 --> 00:00:58.000
Unityはまた、ARKitを利用して、骨格のハンドトラッキングなど、あなたの体の位置と周囲を認識します。

00:00:58.000 --> 00:01:04.000
Unityはこれらの技術に基づいて構築され、Unity Engineで同じサービスを提供します。

00:01:04.000 --> 00:01:08.000
Unityを使用して、このプラットフォームで没入型体験を作成するには、主に2つのアプローチがあります。

00:01:08.000 --> 00:01:14.000
このプラットフォームに完全に没入型のUnity体験をもたらし、プレイヤーの周囲を独自の環境に置き換えることができます。

00:01:14.000 --> 00:01:21.000
または、コンテンツとパススルーを組み合わせて、周囲に溶け込む没入型体験を作成することもできます。

00:01:21.000 --> 00:01:27.000
2番目のアプローチに興味がある場合は、「没入型Unityアプリの作成」をチェックすることをお勧めします。

00:01:27.000 --> 00:01:35.000
さて、ピーターは、これらの新しいAppleテクノロジーが、Unity開発者が完全に没入型VRゲームをこのプラットフォームに持ち込むのにどのように役立つかを説明します。

00:01:35.000 --> 00:01:37.000
ピーター:ありがとう、クリストファー。

00:01:37.000 --> 00:01:40.000
まず、Against GravityのRec Roomを見せることから始めましょう。

00:01:40.000 --> 00:01:47.000
これは、ユーザーが世界中の他の人とゲームや体験を作成してプレイできる人気のあるVRソーシャルプラットフォームです。

00:01:47.000 --> 00:01:52.000
これは、ゲーム開発のための強力で柔軟なプラットフォームを提供するUnityゲームエンジン上に構築されています。

00:01:52.000 --> 00:02:00.000
Rec Roomのように、VRコンテンツをこの新しいプラットフォームに簡単に持ち込むためのツールや技術のいくつかを紹介します。

00:02:00.000 --> 00:02:06.000
Unityのコンテンツをこの新しいプラットフォームに持ち込むことを計画する際に留意すべき点をいくつかお伝えします。

00:02:06.000 --> 00:02:12.000
まず、Unityからデバイスにコンテンツをデプロイするために使用するワークフローについて説明します。

00:02:12.000 --> 00:02:17.000
このプラットフォームのグラフィックに関連して、心に留めておくべきことがいくつかあります。

00:02:17.000 --> 00:02:25.000
そして最後に、コントローラ入力をハンド入力に適応させる方法と、この移行を支援するためにUnityが提供するツールのいくつかについて話します。

00:02:25.000 --> 00:02:31.000
まず、すでに慣れているはずのビルドと実行のワークフローがあります。

00:02:31.000 --> 00:02:37.000
このプラットフォームの完全なサポートをUnityに組み込んだので、ほんの数ステップでこのデバイスで実行されているプロジェクトを確認できます。

00:02:37.000 --> 00:02:40.000
1つ目は、このプラットフォームのビルドターゲットを選択することです。

00:02:40.000 --> 00:02:46.000
次に、他のVRプラットフォームと同様に、XRプラグインを有効にします。

00:02:46.000 --> 00:02:50.000
アプリがネイティブプラグインに依存している場合は、このプラットフォーム用に再コンパイルする必要があります。

00:02:50.000 --> 00:02:57.000
一方、生のソースコードや.mmファイルを使用している場合は、すでに大丈夫です。

00:02:57.000 --> 00:03:04.000
Unityから構築すると、iOS、Mac、またはApple TVターゲットの場合と同様に、Xcodeプロジェクトが生成されるようになりました。

00:03:04.000 --> 00:03:12.000
その後、Xcode内から、より高速な反復のために、デバイスまたはデバイスシミュレータのいずれかにビルドして実行することができます。

00:03:12.000 --> 00:03:20.000
誰かの周囲を完全に没入型体験に変えるために使用するグラフィックパイプラインは、あなたにも馴染みがあるでしょう。

00:03:20.000 --> 00:03:24.000
しかし、理解することが重要な新しい概念がいくつかあります。

00:03:24.000 --> 00:03:29.000
すべてのプロジェクトが最初に行う1つの選択肢は、どのレンダリングパイプラインを使用するかです。

00:03:29.000 --> 00:03:32.000
ユニバーサルレンダリングパイプラインは理想的な選択です。

00:03:32.000 --> 00:03:41.000
これは、Foveated Renderingと呼ばれるこのプラットフォームに固有の特別な機能を可能にします。

00:03:41.000 --> 00:03:53.000
Foveated Renderingは、目が集中する可能性が高い各レンズの中央により多くのピクセル密度を集中させ、目が細部に敏感ではない画面の周辺機器の細部を少なくする技術です。

00:03:53.000 --> 00:03:58.000
これにより、デバイスを使用している人にとってはるかに高品質の体験が得られます。

00:03:58.000 --> 00:04:04.000
ユニバーサルレンダリングパイプラインを使用すると、静的フォベレーションレンダリングがパイプライン全体に適用されます。

00:04:04.000 --> 00:04:11.000
また、後処理、カメラスタッキング、HDRなど、すべてのURP機能で動作します。

00:04:11.000 --> 00:04:19.000
Foveated Renderingの恩恵を受けるカスタムレンダリングパスがある場合、Unity 2022には、この技術を活用できる新しいAPIがあります。

00:04:19.000 --> 00:04:26.000
レンダリングは非線形空間で行われるようになったので、その再マッピングを処理するシェーダーマクロもあります。

00:04:26.000 --> 00:04:34.000
静的フォベレーションレンダリングを活用することは、重要なピクセルにリソースを費やし、より高品質のビジュアル体験を生み出すことを意味します。

00:04:34.000 --> 00:04:40.000
このプラットフォームでグラフィックスを最適化するもう1つの方法は、シングルパスインスタンスレンダリングを使用することです。

00:04:40.000 --> 00:04:47.000
Unityでは、シングルパスインスタンスレンダリングがMetalグラフィックスAPIをサポートするようになり、デフォルトで有効になります。

00:04:47.000 --> 00:04:56.000
シングルパスインスタンスレンダリングでは、エンジンは両方の目に対して1つのドローコールのみを送信し、カリングやシャドウなどのレンダリングパイプラインの特定の部分のオーバーヘッドを削減します。

00:04:56.000 --> 00:05:01.000
これにより、シーンをステレオでレンダリングするCPUオーバーヘッドが削減されます。

00:05:01.000 --> 00:05:12.000
良いニュースは、アプリがすでにシングルパスインスタンスレンダリングを使用して他のVRプラットフォームで正しくレンダリングされている場合、シェーダーマクロはここでも機能することを保証することです。

00:05:12.000 --> 00:05:14.000
最後に考慮すべきことが1つあります。

00:05:14.000 --> 00:05:18.000
アプリがピクセルごとに深度バッファに正しく書き写っていることを確認してください。

00:05:18.000 --> 00:05:21.000
システムコンポジターは、再投影に深度バッファーを使用します。

00:05:21.000 --> 00:05:27.000
深度情報が欠落している場合、システムは表示としてエラー色をレンダリングします。

00:05:27.000 --> 00:05:34.000
1つの例は、通常、ユーザーから無限に離れているスカイボックスなので、逆Zでゼロの深さを書き込みます。

00:05:34.000 --> 00:05:38.000
これには、デバイスに表示されるように修正する必要があります。

00:05:38.000 --> 00:05:53.000
深度バッファに正しい値を書き込むためにUnityのすべてのシェーダーを修正しましたが、カスタムスカイボックス、または水効果や透明効果などのカスタム効果がある場合は、各ピクセルの深度に値が書き込まれていることを確認してください。

00:05:53.000 --> 00:05:57.000
グラフィックをデバイスにレンダリングしたので、インタラクティブにする時が来ました。

00:05:57.000 --> 00:06:00.000
このデバイスでのインタラクションはユニークです。

00:06:00.000 --> 00:06:04.000
人々は手と目を使ってコンテンツと対話します。

00:06:04.000 --> 00:06:09.000
このプラットフォームでUnityアプリにインタラクションを追加する方法はいくつかあります。

00:06:09.000 --> 00:06:15.000
XRインタラクションツールキットは、既存のプロジェクトを簡単に適応できるようにハンドトラッキングを追加します。

00:06:15.000 --> 00:06:20.000
Unity Input Systemを使用して、組み込みのシステムジェスチャーに反応することもできます。

00:06:20.000 --> 00:06:27.000
また、Unity Handsパッケージとのカスタムインタラクションのために、生のハンドジョイントデータにアクセスできます。

00:06:27.000 --> 00:06:33.000
XRインタラクションツールキットは、XRIとも呼ばれ、高レベルのインタラクションシステムを提供します。

00:06:33.000 --> 00:06:37.000
このツールキットは、入力をインタラクションに簡単に変換できるように設計されています。

00:06:37.000 --> 00:06:41.000
3DオブジェクトとUIオブジェクトの両方で動作します。

00:06:41.000 --> 00:06:48.000
XRIは、ハンドトラッキングなどの入力の種類を抽象化し、その入力をアプリが応答できるアクションに変換します。

00:06:48.000 --> 00:06:54.000
これは、入力コードがさまざまなタイプの入力を受け入れるプラットフォーム間で機能できることを意味します。

00:06:54.000 --> 00:07:04.000
XRIを使用すると、3D空間と3D空間世界のUIの両方で、ホバー、グラブ、選択などの一般的なインタラクションに簡単に対応できます。

00:07:04.000 --> 00:07:11.000
ツールキットには移動システムも含まれているので、人々は完全に没入型の空間をより快適に旅行することができます。

00:07:11.000 --> 00:07:15.000
人々があなたの世界と交流するとき、視覚的なフィードバックは没頭するために重要です。

00:07:15.000 --> 00:07:21.000
XRIを使用すると、各入力制約の視覚的反応を定義できます。

00:07:21.000 --> 00:07:26.000
XRIの中核は、基本的なInteractableコンポーネントとInteractorコンポーネントのセットです。

00:07:26.000 --> 00:07:29.000
インタラクティブは、入力を受信できるシーン内のオブジェクトです。

00:07:29.000 --> 00:07:34.000
インターアクタを定義し、ユーザーがインターアクタブルとどのようにやり取りできるかを指定します。

00:07:34.000 --> 00:07:38.000
インタラクションマネージャーは、これらのコンポーネントを結び付けます。

00:07:38.000 --> 00:07:46.000
最初のステップは、シーン内のどのオブジェクトと対話できるか、およびそれらの相互作用が発生したときにどのように反応するかを決定することです。

00:07:46.000 --> 00:07:49.000
これを行うには、オブジェクトにInteractableコンポーネントを追加します。

00:07:49.000 --> 00:07:52.000
3つの組み込みタイプがあります。

00:07:52.000 --> 00:07:56.000
シンプルは、オブジェクトを受信インタラクションとしてマークします。

00:07:56.000 --> 00:08:02.000
このコンポーネントを使用して、SelectEnteredやSelectExitedなどのイベントを購読できます。

00:08:02.000 --> 00:08:10.000
Grabでは、オブジェクトが選択またはつかまれると、Interactorをたどり、リリース時にその速度を継承します。

00:08:10.000 --> 00:08:19.000
TeleportAreaやTeleportAnchorなどのテレポートインタラクション機能を使用すると、プレイヤーがテレポートするエリアやポイントを定義できます。

00:08:19.000 --> 00:08:24.000
また、独自のカスタムInteractablesを作成できます。

00:08:24.000 --> 00:08:29.000
インタラクターは、インタラクティブとしてタグ付けしたオブジェクトを選択または操作する責任があります。

00:08:29.000 --> 00:08:34.000
彼らは、各フレームにカーソルを合わせたり選択したりできる可能性のあるインタラクタブルのリストを定義します。

00:08:34.000 --> 00:08:37.000
インターアクターにはいくつかの種類があります。

00:08:37.000 --> 00:08:41.000
ダイレクトインタラクターは、それに触れているインタラクタブルを選択します。

00:08:41.000 --> 00:08:50.000
人の手がいつ相互作用可能なオブジェクトに触れるか、または相互作用可能なオブジェクトに近いかを知りたい場合は、これらのいずれかを使用します。

00:08:50.000 --> 00:08:53.000
レイ・インターアクターは、遠くから対話するために使用されます。

00:08:53.000 --> 00:09:02.000
このInteractorは、曲線と直線、およびプロジェクトのビジュアルスタイルに適応させるのに役立つカスタマイズ可能な視覚化で高度に構成可能です。

00:09:02.000 --> 00:09:07.000
ユーザーがインタラクションを開始すると、そのインタラクションがどのように機能するかに関するオプションがあります。

00:09:07.000 --> 00:09:12.000
たとえば、グラブインタラクションの場合、オブジェクトをユーザーの手に移動することができます。

00:09:12.000 --> 00:09:19.000
そして、レイ・インターアクターは、あなたのゲームプレイのニーズに合うように、グラブの自由度を制限することを可能にします。

00:09:19.000 --> 00:09:26.000
完全に没入型体験における一般的な相互作用は、オブジェクトをつかみ、そのオブジェクトのコンテキストのどこかに配置することです。

00:09:26.000 --> 00:09:29.000
例えば、バッテリーをソケットに入れる。

00:09:29.000 --> 00:09:34.000
ソケットインターアクタは、特定の領域がオブジェクトを受け入れることができることをプレーヤーに示します。

00:09:34.000 --> 00:09:36.000
これらのインターアクターは手に取り付けられていません。

00:09:36.000 --> 00:09:39.000
代わりに、彼らは世界のどこかに住んでいます。

00:09:39.000 --> 00:09:45.000
ハンドトラッキングやコントローラーでさえ、ユーザーが自然に実行したい一般的なタイプのインタラクションは、ポークインタラクションです。

00:09:45.000 --> 00:09:54.000
これは、インタラクションをトリガーするために正しい動きを実行する必要があるように方向フィルタリングが含まれていることを除いて、直接のインターアクターに似ています。

00:09:54.000 --> 00:10:03.000
人々が見て交流したい場合、Gaze InteractorはRay Interactorにいくつかの拡張機能を提供し、視線を少し簡単に処理できるようにします。

00:10:03.000 --> 00:10:11.000
たとえば、Gaze Interactorsは、Interactablesのコライダーを自動的に大きくして、選択しやすくすることができます。

00:10:11.000 --> 00:10:19.000
すべてをまとめるために、インタラクションマネージャーはInteractorsとInteractablesの間の仲介者として機能し、インタラクションの交換を促進します。

00:10:19.000 --> 00:10:27.000
その主な役割は、登録されたInteractorsとInteractablesの指定されたグループ内で相互作用状態の変更を開始することです。

00:10:27.000 --> 00:10:35.000
通常、すべてのインタラクタがすべてのインタラクタブルに影響を与える可能性を可能にするために、単一のインタラクションマネージャーが確立されます。

00:10:35.000 --> 00:10:43.000
あるいは、複数の補完的なインタラクションマネージャーを利用することができ、それぞれが独自のInteractorsとInteractablesの品揃えを持っています。

00:10:43.000 --> 00:10:49.000
これらのマネージャーは、特定のインタラクションセットを有効または無効にするために有効または無効にすることができます。

00:10:49.000 --> 00:10:56.000
たとえば、シーンごとに異なるインタラクタブルのセット、またはメニューにある場合があります。

00:10:56.000 --> 00:11:01.000
最後に、XRコントローラーコンポーネントは、受信する入力データを理解するのに役立ちます。

00:11:01.000 --> 00:11:12.000
手または追跡されたデバイスから入力アクションを受け取り、インターアクタに渡して、その入力に基づいて何かを選択またはアクティブにすることを決定できます。

00:11:12.000 --> 00:11:18.000
選択など、XRインタラクション状態ごとに入力アクション参照をバインドする必要があります。

00:11:18.000 --> 00:11:27.000
ハンドまたはコントローラーごとに1つのXRコントローラーコンポーネントに限定されないため、両手とコントローラーを独立してサポートする柔軟性が得られます。

00:11:27.000 --> 00:11:32.000
XRIにバンドルされているサンプルコードは、これを行う方法を示しています。

00:11:32.000 --> 00:11:41.000
XRIの高度な機能に加えて、Unity入力システムから直接システムジェスチャー入力を使用するオプションもあります。

00:11:41.000 --> 00:11:48.000
その後、タップジェスチャーなどのプラットフォームの組み込みインタラクションを独自のインタラクションシステムにマッピングできます。

00:11:48.000 --> 00:11:54.000
Unity Input Systemのバインディングパスを使用して、これらのシステムジェスチャーにアクセスして応答できます。

00:11:54.000 --> 00:11:59.000
たとえば、ピンチジェスチャーは、アクティブなときに、位置と回転で値として表示されます。

00:11:59.000 --> 00:12:03.000
これらは入力アクションにバインドできます。

00:12:03.000 --> 00:12:10.000
その人が焦点を向けているところは、ピンチジェスチャーと同じフレームで、位置と回転で通り抜けます。

00:12:10.000 --> 00:12:20.000
さらに柔軟性を高めるために、Unity Handsサブシステムを使用して、Unity Handsパッケージを介してシステムからすべての生のハンドジョイントデータにアクセスできます。

00:12:20.000 --> 00:12:26.000
Unity Handsパッケージは、プラットフォーム間で一貫性のある低レベルのハンドジョイントデータへのアクセスを提供します。

00:12:26.000 --> 00:12:38.000
たとえば、各関節を見て、ポーズが親指や人差し指などの特定のジェスチャーにどれだけ近いかを判断し、それらをゲームプレイアクションに変換するコードを書くことができます。

00:12:38.000 --> 00:12:47.000
これは強力ですが、すべての人の手はサイズが異なり、人々はさまざまな動きを持っているので、正しく取得するのが難しい場合があります。

00:12:47.000 --> 00:12:51.000
このコードは、人差し指が拡張されているかどうかを示す方法を定義します。

00:12:51.000 --> 00:12:57.000
OnHandUpdateイベントからこのメソッドを呼び出して、片方の手に渡すことができます。

00:12:57.000 --> 00:13:02.000
まず、人差し指が伸びているかどうかを確認するために、いくつかの特定の関節を取得します。

00:13:02.000 --> 00:13:05.000
それらのいずれかが無効な場合、falseを返します。

00:13:05.000 --> 00:13:09.000
すべての関節が有効な場合は、簡単なチェックを行い、人差し指がカールしていないことを確認してください。

00:13:09.000 --> 00:13:16.000
このロジックを他の指に拡張して、基本的なジェスチャー検出を実装し始めることができます。

00:13:16.000 --> 00:13:20.000
生のハンドジョイントデータのもう1つの用途は、カスタムハンドメッシュビジュアルにマッピングすることです。

00:13:20.000 --> 00:13:24.000
これは、手があなたのゲームのアートスタイルにもっとフィットさせるのに役立ちます。

00:13:24.000 --> 00:13:30.000
たとえば、Rec Roomは生のハンドジョイントデータを使用して、ビジュアルスタイルに合った様式化されたハンドモデルを表示しました。

00:13:30.000 --> 00:13:35.000
彼らはまた、より多くの没入感のために他のプレイヤーハンドモデルを示しています。

00:13:35.000 --> 00:13:43.000
Unity Handパッケージには、生のハンドジョイントアクセスについてもっと知りたい場合は、始めるためのサンプルコードがいくつかあります。

00:13:43.000 --> 00:13:46.000
あなたのVR体験がこの新しいプラットフォームにやってくるのを楽しみにしています。

00:13:46.000 --> 00:13:56.000
このプラットフォームに対するUnityのサポートに関する詳細情報を入手し、早期ベータアクセスにサインアップするには、unity.com/spatialにアクセスしてください。

00:13:56.000 --> 00:14:04.000
クリストファー：これらは、すでに慣れ親しんでいるUnityワークフローを使用して、この新しいプラットフォームに完全に没入型のVR体験をもたらすために使用できるツールです。

00:14:04.000 --> 00:14:15.000
ピーター：要約すると、このセッションでは、Rec Roomのように、VRコンテンツをこの新しいプラットフォームに簡単に持ち込むことができるツールと技術のいくつかを紹介しました。

00:14:15.000 --> 00:14:19.000
新しいプロジェクトを開始する場合は、Unity 2022以降を使用してください。

00:14:19.000 --> 00:14:23.000
既存のプロジェクトがある場合は、2022年にアップグレードを開始してください。

00:14:23.000 --> 00:14:26.000
ユニバーサルレンダリングパイプラインの採用を検討してください。

00:14:26.000 --> 00:14:33.000
組み込みのグラフィックパイプラインはサポートされていますが、将来のすべての改善はユニバーサルパイプラインで行われます。

00:14:33.000 --> 00:14:37.000
コントローラーベースのインタラクションを手に適応させ始めます。

00:14:37.000 --> 00:14:42.000
XRインタラクションツールキットとUnity Handsパッケージから今日から始めることができます。

00:14:42.000 --> 00:14:51.000
クリストファー：最後に、Unityを使用してパススルーで没入型体験を作成する方法の詳細については、「没入型Unityアプリを作成する」ことをお勧めします。

00:14:51.000 --> 00:14:58.000
そして、「空間コンピューティングのための素晴らしいゲームを構築する」をチェックして、このプラットフォームでゲーム開発者に何が可能かの概要を確認してください。

00:14:58.000 --> 00:15:01.000
ピーター：あなたがプラットフォームに何をもたらすのか、私たちは楽しみにしています。

00:15:01.000 --> 00:15:03.000
クリストファー:見てくれてありがとう。

00:15:03.000 --> 23:59:59.000
♪

