WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:12.000
イーサン:こんにちは、私はイーサンです。

00:00:12.000 --> 00:00:17.000
私はSiri Understandingチーム出身で、音声認識のエキサイティングな開発についてお話しします。

00:00:17.000 --> 00:00:20.000
iOS 10では、Speechフレームワークを導入しました。

00:00:20.000 --> 00:00:29.000
これにより、Siriとキーボードディクテーションを強化するのと同じ技術を活用して、シンプルで直感的なインターフェイスを使用して音声対応アプリを作成することができました。

00:00:29.000 --> 00:00:34.000
ただし、音声認識器クラスは、箱から出して、すべてのアプリに適しているわけではありません。

00:00:34.000 --> 00:00:37.000
理由を説明するために、音声認識がどのように機能するかについて話しましょう。

00:00:37.000 --> 00:00:44.000
音声認識システムは、まず音声データを音響モデルに供給し、音声表現を生成します。

00:00:44.000 --> 00:00:50.000
その後、音声表現は書面形式または転写に変換されます。

00:00:50.000 --> 00:00:57.000
場合によっては、複数の音声表現がオーディオデータに適合したり、単一の音声表現が複数の転写に対応する場合があります。

00:00:57.000 --> 00:01:03.000
このような場合、複数の候補者の転写が終わり、曖昧さを解消する方法が必要です。

00:01:03.000 --> 00:01:06.000
これを行うには、言語モデルと呼ばれるものを採用しています。

00:01:06.000 --> 00:01:11.000
言語モデルは、特定の単語が一連の単語で次に来る可能性を予測します。

00:01:11.000 --> 00:01:17.000
文全体に適用すると、その文がおそらくナンセンスであるかどうかの感触を与えることができます。

00:01:17.000 --> 00:01:24.000
言語モデルは、モデルがトレーニング中にさらされた使用パターンに基づいて、ありそうもない候補者を拒否するのに役立ちます。

00:01:24.000 --> 00:01:30.000
iOS 10以降、Speechフレームワークは、使いやすいインターフェイスを提示するために、このプロセス全体をカプセル化してきました。

00:01:30.000 --> 00:01:34.000
それが理想的ではないかもしれない理由を理解するために、例を考えてみましょう。

00:01:34.000 --> 00:01:42.000
私はチェスをするのが大好きで、ユーザーが個々の動きだけでなく、一般的な開口部や防御を指示できるチェスアプリに取り組んできました。

00:01:42.000 --> 00:01:47.000
ここで、私の対戦相手は古典的なクイーンズギャンビットをプレイしました。

00:01:47.000 --> 00:01:53.000
私は勉強していて、反応E5、アルビンのカウンターギャンビットが好きです。

00:01:53.000 --> 00:01:56.000
アルビンのカウンターギャンビットをプレイする。

00:01:56.000 --> 00:01:58.000
ああ、問題があります。お困りします

00:01:58.000 --> 00:02:03.000
認識者は、私のチェスの動きを音楽リクエストとして誤って認識しています。

00:02:03.000 --> 00:02:13.000
リコグナイザが使用する言語モデルは、トレーニングプロセス中に多くの音楽リクエストにさらされたため、「アルバムを再生」の後にアルバム名が続くなどのクエリが用意されています。

00:02:13.000 --> 00:02:18.000
逆に、それはおそらく私の好きな転写に遭遇したことがないでしょう。

00:02:18.000 --> 00:02:27.000
言語モデルの動作を抽象化することで、Speechフレームワークは、異なるドメインが異なる動作を必要とするにもかかわらず、すべてのアプリに同じモデルを使用することを強制します。

00:02:27.000 --> 00:02:38.000
iOS 17では、SFSpeechRecognizerの言語モデルの動作をカスタマイズし、アプリケーションに合わせて調整し、その精度を向上させることができます。

00:02:38.000 --> 00:02:43.000
言語モデルのカスタマイズを開始するには、まずトレーニングデータのコレクションを作成します。

00:02:43.000 --> 00:02:46.000
開発プロセス中にこれを行うことができます。

00:02:46.000 --> 00:02:53.000
次に、アプリでデータを準備し、認識要求を設定してから実行します。

00:02:53.000 --> 00:02:57.000
トレーニングデータの収集を構築するプロセスについて話しましょう。

00:02:57.000 --> 00:03:05.000
高いレベルでは、トレーニングデータは、アプリのユーザーが話す可能性が高いフレーズを表すテキストのビットで構成されます。

00:03:05.000 --> 00:03:11.000
これらは、モデルにこれらのフレーズを期待し、正しく認識される可能性を高めることを教えます。

00:03:11.000 --> 00:03:18.000
認識器がどれほど有能であるか、そして時間の経過とともにどれだけ改善されるかを見るのは驚くべきことなので、頻繁に実験してください。

00:03:18.000 --> 00:03:22.000
スピーチフレームワークは、トレーニングデータのコンテナとして機能する新しいクラスを導入します。

00:03:22.000 --> 00:03:25.000
結果ビルダーDSLを使用して構築されています。

00:03:25.000 --> 00:03:30.000
PhraseCountオブジェクトを使用して、正確なフレーズまたはフレーズの一部を提供できます。

00:03:30.000 --> 00:03:36.000
PhraseCountは、サンプルを最終的なデータセットで何回表現する必要があるかも記述します。

00:03:36.000 --> 00:03:40.000
これは、特定のフレーズを他のフレーズよりも重み付けするために使用できます。

00:03:40.000 --> 00:03:47.000
システムで受け入れることができるのはそれほど多くのデータだけなので、全体的なトレーニングデータ予算に対してフレーズをブーストする必要性のバランスを取ってください。

00:03:47.000 --> 00:03:52.000
テンプレートを活用して、通常のパターンに合った多数のサンプルを生成することもできます。

00:03:52.000 --> 00:03:57.000
ここでは、一緒にチェスの動きを構成する単語の3つのクラスを定義しました。

00:03:57.000 --> 00:04:06.000
私がターゲットとしているファイルとして倍増する移動するピース、ボードのどちら側でプレイするかを定義するロイヤルピース、および移動するランク。

00:04:06.000 --> 00:04:13.000
それらをパターンにまとめることで、すべての可能な動きを表すデータサンプルを簡単に生成できます。

00:04:13.000 --> 00:04:21.000
ここでは、カウントがテンプレート全体に適用されるので、チェスの動きを表す10,000のサンプルを取得し、結果のすべてのデータサンプルに均等に分割します。

00:04:21.000 --> 00:04:28.000
データオブジェクトの構築が完了したら、それをファイルにエクスポートし、他のアセットと同様にアプリにデプロイします。

00:04:28.000 --> 00:04:41.000
アプリが専門用語、例えば医薬品の名前を含む医療アプリを使用している場合は、それらの用語のスペルと発音の両方を定義し、その使用法を示すフレーズ数を提供できます。

00:04:41.000 --> 00:04:45.000
発音はX-SAMPA文字列の形で受け入れられます。

00:04:45.000 --> 00:04:50.000
各ロケールは、発音記号の一意のサブセットをサポートしています。

00:04:50.000 --> 00:04:55.000
ロケールとサポートされているシンボルの完全なセットについては、ドキュメントを参照してください。

00:04:55.000 --> 00:05:02.000
私のアプリでは、リコグナイザがフランスの防衛の一般的な変種であるWinawerのバリエーションを理解できるようにしたい。

00:05:02.000 --> 00:05:09.000
このロケールでサポートされているX-SAMPAシンボルのサブセットを使用して発音を説明します。

00:05:09.000 --> 00:05:13.000
同じAPIを使用して、アプリが実行時にアクセスできるデータをトレーニングできます。

00:05:13.000 --> 00:05:22.000
ユーザーが学ぼうとしているチェスの開口部や防御に焦点を当てるなど、ユーザーに固有の使用パターンをサポートするためにこれを行うことができます。

00:05:22.000 --> 00:05:24.000
また、名前付きエンティティでトレーニングすることもできます。

00:05:24.000 --> 00:05:28.000
たぶん、あなたのアプリは、ユーザーの連絡先に対するネットワークプレイをサポートしています。

00:05:28.000 --> 00:05:33.000
そして、いつものように、ユーザーのプライバシーを尊重することが最も重要です。

00:05:33.000 --> 00:05:41.000
たとえば、通信アプリは、それらの連絡先が通話履歴に表示される頻度に基づいて、連絡先を呼び出すコマンドをブーストしたい場合があります。

00:05:41.000 --> 00:05:44.000
この種の情報は常にデバイスにとどまるべきです。

00:05:44.000 --> 00:05:53.000
アプリ内から同じメソッドを呼び出して、データオブジェクトを生成し、ファイルに書き込み、前述のように取り込むだけです。

00:05:53.000 --> 00:05:57.000
トレーニングデータが生成されると、単一のロケールにバインドされます。

00:05:57.000 --> 00:06:05.000
1つのスクリプト内で複数のロケールをサポートしたい場合は、NSLocalizedStringなどの標準ローカリゼーション機能を使用してサポートできます。

00:06:05.000 --> 00:06:08.000
では、モデルをアプリにデプロイすることについて話しましょう。

00:06:08.000 --> 00:06:19.000
まず、前のステップで生成したファイルを受け入れ、後で使用する2つの新しいファイルを生成する新しいメソッドprepareCustomLanguageModelを呼び出す必要があります。

00:06:19.000 --> 00:06:30.000
このメソッド呼び出しは、大量の関連するレイテンシを持つ可能性があるため、メインスレッドから呼び出し、ロード画面などのUIの背後にレイテンシーを隠すのが最善です。

00:06:30.000 --> 00:06:35.000
場合によっては、ユーザーのプライバシーを尊重するために、生成されたデバイスにデータを保持する必要があります。

00:06:35.000 --> 00:06:40.000
LMカスタマイズは、ネットワーク経由でカスタマイズデータを送信しないことで、これをサポートします。

00:06:40.000 --> 00:06:44.000
すべてのカスタマイズされた要求は、デバイス上で厳密にサービスされます。

00:06:44.000 --> 00:06:50.000
アプリが音声認識要求を作成するときは、まず認識がデバイスで実行されることを強制します。

00:06:50.000 --> 00:06:55.000
そうしないと、カスタマイズなしでリクエストが処理されます。

00:06:55.000 --> 00:06:59.000
次に、リクエストオブジェクトに言語モデルを添付します。

00:06:59.000 --> 00:07:03.000
今、私のアプリでLMカスタマイズをオンにして...

00:07:03.000 --> 00:07:06.000
アルビンのカウンターギャンビットをプレイする。

00:07:06.000 --> 00:07:08.000
私のカスタム用語も機能します。

00:07:08.000 --> 00:07:12.000
Winawerのバリエーションを再生します。

00:07:12.000 --> 00:07:19.000
言語モデルをカスタマイズすることで、リコグナイザをアプリケーションのドメインに調整し、その動作をある程度制御できるようになりました。

00:07:19.000 --> 00:07:24.000
最も重要なことは、アプリの音声認識精度を向上させたことです。

00:07:24.000 --> 00:07:32.000
スピーチフレームワークは、より多くのアプリとより多くのユーザーに適応できるようになったので、さらに強力になり、より良い体験を生み出すために使用できます。

00:07:32.000 --> 00:07:38.000
言語モデルのカスタマイズは、音声認識器を強化し、アプリに合わせてカスタマイズする方法を提供します。

00:07:38.000 --> 00:07:42.000
私はあなたがそれで達成するすべての素晴らしいことを見てとても興奮しています。

00:07:42.000 --> 00:07:44.000
ありがとう、そしてセンターのためにプレーすることを忘れないでください。

00:07:44.000 --> 23:59:59.000
♪ ♪

