WEBVTT

00:00:00.000 --> 00:00:03.000
♪まろやかなインストゥルメンタルヒップホップ♪

00:00:03.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:12.000
こんにちは、私はクリスです。

00:00:12.000 --> 00:00:16.000
私はAVFoundationチームのエンジニアであり、私たちのセッションにあなたを歓迎します。

00:00:16.000 --> 00:00:23.000
この講演では、空間体験のためにストリーミングコンテンツを準備して配信する方法を見ていきます。

00:00:23.000 --> 00:00:30.000
HTTPライブストリーミングを使用して2Dメディアを制作、準備、配信する現在の手順の簡単なレビューから始めます。

00:00:30.000 --> 00:00:32.000
HLSとしても知られています。

00:00:32.000 --> 00:00:41.000
2Dコンテンツの準備と配信をカバーするので、3Dビデオコンテンツに目を向けます - サポートされているものと、先ほど説明した手順の更新です。

00:00:41.000 --> 00:00:46.000
コンテンツパイプラインを考慮すると、ビデオ、オーディオ、キャプションのメディアエンコーディングから始めます。

00:00:46.000 --> 00:00:51.000
その後、これらのメディアリソースをパッケージ化し、HLS配信の準備ができている必要があります。

00:00:51.000 --> 00:00:54.000
これが今日の2Dコンテンツの配信方法です。

00:00:54.000 --> 00:00:58.000
3Dコンテンツを配信する目標は、現在の2Dプロセスに基づいて構築することです。

00:00:58.000 --> 00:01:05.000
HLSは、重要な適応を可能にする断片化されたMP4時付けメタデータの新しいサポートを追加します。

00:01:05.000 --> 00:01:14.000
Apple Developer WebサイトのHTTPライブストリーミングページには、ドキュメント、ツール、サンプルストリーム、開発者フォーラム、その他のリソースへのリンクがあります。

00:01:14.000 --> 00:01:19.000
これは、この講演で取り上げられた詳細が時間の経過とともに利用可能になる場所です。

00:01:19.000 --> 00:01:25.000
私たちの目標は、このプラットフォームに2D視聴覚コンテンツを配信することは、他のすべてのプラットフォームと同じであるべきです。

00:01:25.000 --> 00:01:39.000
これは、HTTPライブストリーミング、AVFoundation、Core MediaなどのApple Mediaテクノロジーと、しばしばMPEG-4と考えられているISOベースのメディアファイル形式などの標準ベースのフォーマットを構築することによって達成されます。

00:01:39.000 --> 00:01:43.000
これは、新しい空間体験のパラダイムをサポートしながら行われます。

00:01:43.000 --> 00:01:53.000
視聴覚メディアの再生を最適にサポートする方法については、「ビデオ再生のための素晴らしい空間体験を作成する」セッションを参照してください。

00:01:53.000 --> 00:01:55.000
ビデオの場合は、ソースビデオをエンコードします。

00:01:55.000 --> 00:02:00.000
適切な長さに編集し、あなたにとって重要なビットレート層の色補正します。

00:02:00.000 --> 00:02:07.000
ここでは、高効率ビデオコーディングの略であるHEVCなどのビデオエンコーダの設定方法と使用方法を選択します。

00:02:07.000 --> 00:02:15.000
他のAppleプラットフォームに配信する既存の2D視聴覚メディアのサポートは完全にサポートされていますが、これらの再生機能に注意してください。

00:02:15.000 --> 00:02:21.000
このプラットフォームは、最大4K解像度の再生をサポートし、最高品質のビデオを体験できます。

00:02:21.000 --> 00:02:29.000
ディスプレイのリフレッシュレートは90ヘルツで、24フレーム/秒のビデオでは、特別な96ヘルツモードが自動的に使用できます。

00:02:29.000 --> 00:02:33.000
標準および高ダイナミックレンジのサポートがあります。

00:02:33.000 --> 00:02:39.000
ビデオの対応するオーディオについては、必要なソースオーディオストリームの数を特定して生成します。

00:02:39.000 --> 00:02:45.000
数は、ターゲットとする話し言葉のセットとそのオーディオの役割によって異なります。

00:02:45.000 --> 00:02:49.000
1つの役割はメインの対話であり、別の役割は音声説明かもしれません。

00:02:49.000 --> 00:02:53.000
HLSを念頭に置いて配信のためにこれらのソースをエンコードします。

00:02:53.000 --> 00:02:58.000
フォールバックステレオオーディオトラックとともに、空間オーディオを提供したいと思うかもしれません。

00:02:58.000 --> 00:03:04.000
これにより、どこでも空間オーディオと信頼性の高い再生をサポートするデバイスに素晴らしい体験が保証されます。

00:03:04.000 --> 00:03:08.000
HLS開発者ページには、オーディオの準備に関するドキュメントへのリンクがあります。

00:03:08.000 --> 00:03:10.000
そして、キャプションがあります。

00:03:10.000 --> 00:03:16.000
ここでは、キャプションには、さまざまな言語と役割をカバーする字幕とクローズドキャプションの両方が含まれています。

00:03:16.000 --> 00:03:27.000
「字幕」という用語は、言語を話さない視聴者のために異なる言語で翻訳を提供する音声テキストの転写、または設定時間と場所を確立するために使用されます。

00:03:27.000 --> 00:03:32.000
クローズドキャプションは字幕に似ていますが、視聴者が音声を聞くことができない場合に意図されています。

00:03:32.000 --> 00:03:38.000
クローズキャプションは、対話だけでなく、効果音やその他の関連するオーディオキューの書き起こしも提供します。

00:03:38.000 --> 00:03:44.000
聴覚障害者のための字幕、SDHも、同じ目的を果たすかもしれません。

00:03:44.000 --> 00:03:52.000
ビデオやオーディオのエンコーディングと同様に、HLS、最も一般的にはWebVTTでサポートされているキャプションファイルとフォーマットを作成する必要があります。

00:03:52.000 --> 00:03:57.000
ソースビデオ、オーディオ、キャプションを手元に置いて、次はパッケージです。

00:03:57.000 --> 00:04:04.000
パッケージングは、信頼できる配信のために、ソースメディアをさまざまな種類のセグメントに変換するプロセスです。

00:04:04.000 --> 00:04:09.000
これは、以前のHLSストリーミングページで利用可能なAppleのHLSツールで行うことができます。

00:04:09.000 --> 00:04:14.000
一部のコンテンツプロバイダーは、独自のプロダクションツール、ハードウェア、またはワークフローを使用する場合があります。

00:04:14.000 --> 00:04:18.000
他の人は、これらのサービスやツールを最初のグループに提供するベンダーかもしれません。

00:04:18.000 --> 00:04:27.000
パッケージングの目標は、一連のメディアセグメント、その使用を促進するメディアプレイリスト、およびそれらをすべて結びつける多変量プレイリストを作成することです。

00:04:27.000 --> 00:04:32.000
今日、最も一般的に使用されている2種類のHLSメディアセグメントが使用されています。

00:04:32.000 --> 00:04:39.000
断片化されたMP4メディアセグメントは、すでにエンコードされたビデオまたはオーディオのムービーファイルから始めて、多くのリソースを生成することによって生成されます。

00:04:39.000 --> 00:04:42.000
これらのリソースはメディアセグメントとして知られています。

00:04:42.000 --> 00:04:47.000
再生中にクライアントデバイスによって取得されるのは、これらのセグメントです。

00:04:47.000 --> 00:04:50.000
字幕ファイルにはセグメント化も必要です。

00:04:50.000 --> 00:04:54.000
これは、メディアセグメントを生成するための字幕セグメントツールで行われます。

00:04:54.000 --> 00:05:01.000
ソースWebVTTファイルは、ターゲットセグメントの期間中、任意の数のWebVTTファイルに分割できます。

00:05:01.000 --> 00:05:07.000
最後に、HLSリソースのコレクションは、HTTP配信用のWebサーバーでホストされます。

00:05:07.000 --> 00:05:15.000
これは、クライアントに直接サービスを提供する1つのサーバー、またはコンテンツ配信ネットワークで使用されるオリジンサーバー、またはCDNである可能性があります。

00:05:15.000 --> 00:05:20.000
いずれにせよ、再生のためにクライアントデバイスに配信されるのはこれらのリソースです。

00:05:20.000 --> 00:05:29.000
2D生産と配信のパイプラインを見直したので、3Dコンテンツと新しい特別な機能を活用した違いに目を向けましょう。

00:05:29.000 --> 00:05:37.000
2Dコンテンツと3Dステレオスコピックコンテンツの違いに焦点を当てて、ソースエンコーディング、パッケージング、配信を再び見ていきます。

00:05:37.000 --> 00:05:40.000
だから、私たちは3Dビデオについて話しています。

00:05:40.000 --> 00:05:42.000
この用語を分解しましょう。

00:05:42.000 --> 00:05:48.000
まず、それはビデオなので、ムービートラックまたはネットワークストリームのフレームのシーケンスです。

00:05:48.000 --> 00:06:01.000
「3Dビデオ」の「3D」は、左目に画像を提供するステレオスコピックと、右目にわずかに異なる視点から別の非常に類似した画像と交換可能に使用されます。

00:06:01.000 --> 00:06:09.000
視差と呼ばれる左右の画像のこれらの違いにより、提示されたときにビデオの3次元の深さを知覚します。

00:06:09.000 --> 00:06:14.000
3Dビデオフレームの持ち運びには選択肢がありますが、役に立つと思われるいくつかの指導原則があります。

00:06:14.000 --> 00:06:21.000
すべてのステレオフレームに単一のビデオトラックを使用することで、2Dビデオトラックを使用した従来の制作が保存されます。

00:06:21.000 --> 00:06:26.000
左右の画像またはビューは、任意の表示時間に対して、単一の圧縮フレームにあります。

00:06:26.000 --> 00:06:31.000
手にフレームがある場合は、両方のビューまたはステレオペアがあります。

00:06:31.000 --> 00:06:45.000
それは効率的で、理想的には、Appleシリコンでサポートされており、可能な限り、非3D認識の再生によってデコーダ可能で、ビデオを2Dワークフローでオーディションできるようにする必要があります。

00:06:45.000 --> 00:06:52.000
ステレオフレームを提供するために、「MV-HEVC」とも呼ばれるマルチビューHEVCの使用を導入します。

00:06:52.000 --> 00:06:54.000
HEVCの延長です。

00:06:54.000 --> 00:06:56.000
「MV」はマルチビューです。

00:06:56.000 --> 00:07:03.000
各フレームに複数のビューを運ぶ各フレームには、圧縮された左右の画像のペアがあります。

00:07:03.000 --> 00:07:08.000
MV-HEVCはその中心がHEVCであるため、Appleシリコンはそれをサポートしています。

00:07:08.000 --> 00:07:14.000
MV-HEVCでは、各圧縮フレームにベースHEVC 2Dビューを保存します。

00:07:14.000 --> 00:07:18.000
エンコーディングは、左右の画像の違い、またはデルタを決定します。

00:07:18.000 --> 00:07:26.000
2Dプラスデルタとして知られるこの技術は、2Dデコーダが左目などのベース2Dビューを見つけて使用できることを意味します。

00:07:26.000 --> 00:07:31.000
しかし、3Dデコーダは他のビューを計算して、対応する目に両方のビューを提示することができます。

00:07:31.000 --> 00:07:45.000
ベース2D画像の違いは標準的なHEVC技術を使用し、左右のアイビューの違いだけがステレオフレームに記載されているため、効率が達成されます。

00:07:45.000 --> 00:08:00.000
ビデオフォーマットの説明、またはMPEG-4のビジュアルサンプルエントリは、コーディングタイプ、コーデック、各ビューの寸法、およびビデオフレームをデコードするために必要なその他の詳細を示します。

00:08:00.000 --> 00:08:03.000
ビデオフォーマットの説明の新しい拡張機能が導入されました。

00:08:03.000 --> 00:08:12.000
ビデオ拡張使用ボックスと呼ばれ、ビデオが立体的であり、どのステレオアイビューが存在するかという軽量で簡単に発見できる信号として機能します。

00:08:12.000 --> 00:08:15.000
HLS配信の場合、これは左と右の両方になります。

00:08:15.000 --> 00:08:21.000
この新しいVEXUボックスを説明する仕様は、SDKで利用可能です。

00:08:21.000 --> 00:08:25.000
その構造は進化し、それは仕様書に記載されます。

00:08:25.000 --> 00:08:33.000
2Dコンテンツと同様に、3DビデオはHEVCを使用しますが、今回はMV-HEVCと呼ばれるバリエーションです。

00:08:33.000 --> 00:08:36.000
これは、立体ビューを運ぶために必要です。

00:08:36.000 --> 00:08:43.000
2D制作と同様に、MV-HEVCを搭載したローカルムービーを使用でき、他の2Dビデオのように振る舞う必要があります。

00:08:43.000 --> 00:08:53.000
対応する目に左と右の両方の画像を提示すると、立体的な深さの知覚が生成され、相対的な深さの感覚が得られます。

00:08:53.000 --> 00:09:00.000
ビデオシーン内のオブジェクトは、視差の量が異なるため、別のオブジェクトよりも近くまたは遠くに知覚される可能性があります。

00:09:00.000 --> 00:09:03.000
立体深度の3つの主要なゾーンを定義できます。

00:09:03.000 --> 00:09:17.000
それらは、視差の手がかりのないスクリーンプレーンです。負の視差は、スクリーンプレーンの前でオブジェクトを知覚します。正の視差は、スクリーンプレーンの後ろでオブジェクトは知覚されます。

00:09:17.000 --> 00:09:27.000
キャプションのような要素が、負の視差の手がかりと同じ領域でフレームの視差なしでレンダリングされると、深さの競合が作成され、表示時に不快感が発生します。

00:09:27.000 --> 00:09:29.000
質問。

00:09:29.000 --> 00:09:35.000
立体視鏡的視差と深さの衝突の可能性を考えると、3Dビデオのキャプションの作成はどのように関与していますか?

00:09:35.000 --> 00:09:37.000
私たちは以下をサポートできますか?

00:09:37.000 --> 00:09:52.000
再生は水平キャプションで機能し、再生は垂直キャプションを含む言語間で機能し、再生はアクセシビリティ設定を使用してユーザーの好みのキャプションサイズを調整する場合に機能します。

00:09:52.000 --> 00:09:54.000
さて、答えはイエスです。

00:09:54.000 --> 00:10:05.000
次に説明するアプローチを使用したステレオスコピックビデオでは、キャプションはそのまま機能すると同時に、2Dと3Dの経験の間で同じ2Dキャプションアセットを共有できるようにする必要があります。

00:10:05.000 --> 00:10:11.000
これは、先に述べた新しい時限メタデータを含めることで可能です。

00:10:11.000 --> 00:10:17.000
ステレオスコピックビデオでは、深さの競合やビデオをオーバーレイする視覚的要素を避けることが重要です。

00:10:17.000 --> 00:10:25.000
新しいキャプションフォーマットや既存のフォーマットの変更を要求する代わりに、各ビデオフレームの視差を特徴付ける方法を提供します。

00:10:25.000 --> 00:10:30.000
これは、明らかに近く、視聴者から遠く離れたいくつかの領域で、フレーム全体で異なる場合があります。

00:10:30.000 --> 00:10:38.000
私たちはこれを視差輪郭と呼び、ビデオトラックのフレームと同期したメタデータトラックにメタデータとして記録されます。

00:10:38.000 --> 00:10:48.000
3Dビデオをタイルし、各タイルの深さの視差を示す場合、それを使用して、キャプションがステレオビデオの要素に干渉しないようにすることができます。

00:10:48.000 --> 00:10:55.000
再生中、キャプションの視差は、深さの競合を避けるために自動的に調整されます。

00:10:55.000 --> 00:11:04.000
このような視差ビデオの輪郭を持つ各メタデータ項目は、各タイルに関連付けられた最小視差値で、関連するビデオの2Dタイルを記述します。

00:11:04.000 --> 00:11:10.000
各ビデオフレームのプレゼンテーションは、ビデオフレームの輪郭を記述するメタデータ項目に関連付ける必要があります。

00:11:10.000 --> 00:11:20.000
ビデオの視差のさまざまな領域を特徴付けるために、ストレージと解像度の良いバランスとして、10×10のタイルをお勧めします。

00:11:20.000 --> 00:11:25.000
この視差メタデータがどのように生成されるかを考慮して、各フレームの左右のビューから始めます。

00:11:25.000 --> 00:11:30.000
これは、2つの同期ビデオトラックでプロダクションで行うことができ、MV-HEVCを必要としません。

00:11:30.000 --> 00:11:37.000
次に、視差または格差分析を実行して、タイルの説明に適した視差情報を作成します。

00:11:37.000 --> 00:11:42.000
ステレオフレームごとに、これは次のステップのためにメタデータペイロードにパッケージ化されます。

00:11:42.000 --> 00:11:48.000
このメタデータの形式を説明する仕様は、SDKで利用できます。

00:11:48.000 --> 00:11:53.000
この視差情報は、メタデータサンプルにパッケージ化され、時付けされたメタデータトラックに書き込まれます。

00:11:53.000 --> 00:12:00.000
メタデータトラックは、それが説明する対応するビデオに関連付けられます。

00:12:00.000 --> 00:12:10.000
HLSパッケージがビデオと視差メタデータの両方を含むビデオセグメントを生成するように、メタデータとビデオトラックをビデオと多重化する必要があります。

00:12:10.000 --> 00:12:14.000
すでに2D用に制作しているキャプションは、3Dで再利用できます。

00:12:14.000 --> 00:12:21.000
これは、今日使用されているプロセスまたはあなたが協力する可能性のあるベンダーが、3Dプロダクションで2Dで作業を続けることができることを意味します。

00:12:21.000 --> 00:12:32.000
また、これは、3Dコンテンツが言語の選択、水平および垂直レイアウト、またはユーザーによるアクセシビリティ字幕設定の潜在的な使用に依存しないことを意味します。

00:12:32.000 --> 00:12:40.000
説明された視差メタデータを追加することで、プラットフォームは構築した視差メタデータに動的に適応します。

00:12:40.000 --> 00:12:45.000
3Dビデオでのオーディオ使用については、2D配信に同じオーディオ使用を使用できます。

00:12:45.000 --> 00:12:50.000
プラットフォームはヘッドトラッキングをサポートしているため、空間オーディオ形式の使用を検討してください。

00:12:50.000 --> 00:12:57.000
2D体験と3D体験で同じオーディオを共有するには、ビデオはタイミング的に一致し、同じ編集を行う必要があります。

00:12:57.000 --> 00:13:03.000
それらが異なる場合は、2Dアセットと3Dアセットの間でオーディオトラックを分離する必要があります。

00:13:03.000 --> 00:13:12.000
3Dのパッケージングに目を向けると、更新されたHLSツールが詳細を処理し、3Dアセットでプロセスを2Dとほぼ同じにします。

00:13:12.000 --> 00:13:21.000
Appleのツールを使用しないほとんどの生産システムは、同等の機能を構築するためにリリースされている新しい仕様を使用することができます。

00:13:21.000 --> 00:13:27.000
独自のプレイリストを作成したり、検査したりする場合は、いくつかの変更に注意してください。

00:13:27.000 --> 00:13:33.000
REQ-VIDEO-LAYOUTは、ビデオがステレオスコピックであることを示すビデオストリーム用の新しいタグです。

00:13:33.000 --> 00:13:37.000
属性値は、ビデオがステレオであるかどうかを示します。

00:13:37.000 --> 00:13:42.000
アセットが3Dとしてロードされている場合、2Dに、またはその逆に切り替わらないことに注意してください。

00:13:42.000 --> 00:13:48.000
2Dビデオは変更されず、同じプレイリストで3Dビデオと混ぜることができます。

00:13:48.000 --> 00:13:53.000
REQ-VIDEO-LAYOUTにはHLS仕様の新しいバージョンが必要なため、バージョンは12に更新されます。

00:13:53.000 --> 00:13:57.000
これはSDKで文書化されています。

00:13:57.000 --> 00:14:06.000
以下は、バージョン番号を12に変更し、3DビデオストリームにREQ-VIDEO-LAYOUTを使用した多変量プレイリストの例です。

00:14:06.000 --> 00:14:15.000
最高のナビゲーション体験を得るには、サムネイルスクラブをサポートするために、多変量プレイリストに2D iFrameストリームを含める必要があります。

00:14:15.000 --> 00:14:21.000
最後に、HLS配信は3Dアセットで同じように機能します。

00:14:21.000 --> 00:14:27.000
3Dアセットの提供は、2Dアセットの提供とほぼ同じですが、エクスペリエンスを最適化するためにできることがいくつかあります。

00:14:27.000 --> 00:14:34.000
ソースアセットを準備し、3DビデオにMV-HEVCを使用し、新しい視差輪郭メタデータを含めるようにしてください。

00:14:34.000 --> 00:14:37.000
オーディオとキャプションの制作は同じです。

00:14:37.000 --> 00:14:41.000
更新されたパッケージを使用して、関連するセグメントとプレイリストを作成します。

00:14:41.000 --> 00:14:44.000
ホスティングは同じままです。

00:14:44.000 --> 00:14:50.000
閉じる前に、視覚的な快適さが3D体験の重要なコンテンツデザイン目標であることを強調したいと思います。

00:14:50.000 --> 00:14:55.000
3Dコンテンツは、十分に長い期間にわたって快適に視聴できるはずです。

00:14:55.000 --> 00:15:09.000
快適さの問題を引き起こす可能性のある3Dコンテンツの特性には、ネガティブとポジティブの両方の極端な視差、フォーカスの難しさを引き起こすコンテンツのハイモーション、および「ウィンドウ違反」と呼ばれるものに起因する深さの競合が含まれます。

00:15:09.000 --> 00:15:16.000
画面サイズは、視聴者の水平視野にある画面の量に応じて、視聴の快適さに影響を与える可能性があります。

00:15:16.000 --> 00:15:21.000
ユーザーは、より近くまたは遠くに配置することで、画面サイズに影響を与える可能性があることに注意してください。

00:15:21.000 --> 00:15:27.000
だから、私たちの旅では、HTTPライブストリーミングで2Dと3D配信を見てきました。

00:15:27.000 --> 00:15:30.000
ビデオでは、MV-HEVCを紹介しました。

00:15:30.000 --> 00:15:35.000
オーディオについては、同じオーディオストリームを2Dと3Dで使用できると指摘しました。

00:15:35.000 --> 00:15:40.000
キャプションの場合、同じストリームも同様に2Dと3Dで使用できます。

00:15:40.000 --> 00:15:49.000
最後に、3Dビデオの視差を特徴付ける新しい時差メタデータ形式が導入され、同じキャプションを使用できるようになります。

00:15:49.000 --> 00:15:55.000
最後に、既存の2Dコンテンツを空間体験にできるだけ簡単にしました。

00:15:55.000 --> 00:16:02.000
現在の2Dパイプラインにいくつかの小さな変更を加えることで、MV-HEVCを使用して3Dコンテンツをサポートできます。

00:16:02.000 --> 00:16:06.000
2Dアセットの既存のキャプションをすべて使い続けることもできます。

00:16:06.000 --> 00:16:12.000
しかし、時指定のメタデータを提供すると、それらのキャプションは隠されず、快適な視聴体験を提供することができます。

00:16:12.000 --> 00:16:18.000
ビデオの再生を実装する際の考慮事項については、コンパニオンセッションをご覧ください。

00:16:18.000 --> 00:16:21.000
私たちは、あなた達が配信する素晴らしい新しいコンテンツを楽しみにしています。

00:16:21.000 --> 00:16:23.000
今日はご参加いただきありがとうございます。

00:16:23.000 --> 23:59:59.000
♪

