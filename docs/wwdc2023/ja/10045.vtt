WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:12.000
ナディア・ズーバ:皆さん、こんにちは、ようこそ。

00:00:12.000 --> 00:00:17.000
私の名前はナディア・ズーバで、ここアップルのビジョンチームで働いています。

00:00:17.000 --> 00:00:23.000
今日は、ビジョンの新しい素晴らしいAPIについて話します:アニマルボディポーズ。

00:00:23.000 --> 00:00:28.000
また、ビジョンの重要なアップデートについても確認します。

00:00:28.000 --> 00:00:31.000
動物の体のポーズから始めましょう。

00:00:31.000 --> 00:00:36.000
動物のボディポーズは、多くの可能なアプリケーションで使用することができます。

00:00:36.000 --> 00:00:43.000
例えば、猫と犬を一人で家に置いて、仕事で一日を過ごしたと想像してみてください。

00:00:43.000 --> 00:00:48.000
仕事から戻ったとき、あなたはあなたの家でこの混乱を見つけます。

00:00:48.000 --> 00:00:49.000
心配しないでください。

00:00:49.000 --> 00:00:56.000
ビジョンフレームワークは、何が起こったのか、あなたのペットが一日中何をしていたのか、そして誰が混乱させているのかを理解するのに役立ちます。

00:00:56.000 --> 00:01:01.000
しかし、私がそれを掘り下げる前に、ポーズについて話しましょう。

00:01:01.000 --> 00:01:06.000
3年前、ビジョンは人間のポーズを検出するために人体ポーズを導入しました。

00:01:06.000 --> 00:01:13.000
このリクエストは、最大19の身体関節を検出することにより、人体のランドマークのコレクションを生成します。

00:01:13.000 --> 00:01:22.000
世界中の開発者は、このAPIを使用して、健康、フィットネスなどのための多くの有用なアプリケーションを作成しました。

00:01:22.000 --> 00:01:30.000
そして、ビジョンは現実世界と相互作用するので、私たちは人間だけでなく、動物も気にかけています。

00:01:30.000 --> 00:01:37.000
ビジョンはすでに、猫や犬を検出して認識する動物認識の要求を持っています。

00:01:37.000 --> 00:01:45.000
リクエストは、認識された動物のラベルと信頼レベルを持つバウンディングボックスを生成します。

00:01:45.000 --> 00:01:55.000
動物を見つけて識別しようとしているなら、それは素晴らしいAPIですが、動物についてもっと知りたい場合はどうですか?

00:01:55.000 --> 00:02:00.000
動物が何をしているのかを推測するのは難しいかもしれません。

00:02:00.000 --> 00:02:09.000
例えば、私が隣人のために犬の世話をするとき、隣人の犬がおやつが欲しいときや散歩が必要なときの特定のポーズを知りたいかもしれません。

00:02:09.000 --> 00:02:13.000
何だと思う？ビジョンは体のポーズを動物に広げた。

00:02:13.000 --> 00:02:15.000
それはすごい。

00:02:15.000 --> 00:02:19.000
アニマルボディポーズは、ビジョンの新しいAPIです。

00:02:19.000 --> 00:02:25.000
それはDetectAnimalBodyPoseRequestを介してビジョンで提供されています。

00:02:25.000 --> 00:02:34.000
このリクエストは、処理されると、動物の体の関節位置のコレクションを含む各動物の観察を返します。

00:02:34.000 --> 00:02:44.000
このリクエストは猫と犬をサポートし、尾と耳を含む25の動物の体のランドマークを検出します。

00:02:44.000 --> 00:02:56.000
Animal Body Pose APIは、iOS 17、iPadOS 17、tvOS 17、macOS SonomaからVisionで利用できます。

00:02:56.000 --> 00:03:02.000
アニマルボディポーズへの入力は、画像またはビデオにすることができます。

00:03:02.000 --> 00:03:14.000
ビジョンでリクエストを作成して処理した後、リクエストは動物の骨格を定義する関節のコレクションを生成します。

00:03:14.000 --> 00:03:27.000
動物のボディポーズでは、6つの関節グループが定義されています。ヘッドグループには、耳、目、鼻が含まれます。

00:03:27.000 --> 00:03:33.000
前足グループには前足が含まれます。

00:03:33.000 --> 00:03:39.000
あなたはそれを推測しました。ここに後ろ足のためのHindlegsグループが来ています。

00:03:39.000 --> 00:03:47.000
トランクグループは首を指し、テールグループには3つのテールジョイントが含まれています。

00:03:47.000 --> 00:03:54.000
最後に、すべての関節で構成されるオールグループがあります。

00:03:54.000 --> 00:04:04.000
これまでに話したすべてを実証するために、私はランドマークの場所を使用して動物の骨格を描くサンプルアプリを持っています。

00:04:04.000 --> 00:04:07.000
私はこのかわいい小さなチワワのおもちゃの犬を私の机の上に座らせています。

00:04:07.000 --> 00:04:12.000
この犬は歩くことができるので、サンプルアプリの結果を表示するために使用します。

00:04:12.000 --> 00:04:19.000
私は犬を連れて携帯電話のカメラの前に置き、サンプルアプリを起動します。

00:04:19.000 --> 00:04:23.000
アプリは動物の上に骸骨を描きます。

00:04:23.000 --> 00:04:28.000
犬が歩けるように犬の電源を入れましょう。

00:04:28.000 --> 00:04:33.000
骸骨は動物の散歩を追う。

00:04:33.000 --> 00:04:36.000
おっと！犬はカメラから離れて歩いている。

00:04:36.000 --> 00:04:41.000
それを元に戻して、携帯電話のカメラの前に置いておきましょう。

00:04:41.000 --> 00:04:45.000
骸骨はまだ犬を追いかけている。それはすごい。

00:04:45.000 --> 00:04:52.000
次に、サンプルアプリがどのように行われたかを示すためにコードに入ります。

00:04:52.000 --> 00:04:59.000
カメラストリームからCMSampleBuffersを受信するキャプチャ出力から始めます。

00:04:59.000 --> 00:05:01.000
最初のステップは、リクエストを作成することです。

00:05:01.000 --> 00:05:09.000
VNDetectAnimalBodyPoseRequestを使用します。

00:05:09.000 --> 00:05:16.000
次のステップは、imageRequestHandlerを使用してリクエストハンドラを作成することです。

00:05:16.000 --> 00:05:22.000
次に、実行する呼び出しを介してハンドラーに要求を提供します。

00:05:22.000 --> 00:05:32.000
リクエストの実行が成功すると、リクエスト結果プロパティにVNAnimalBodyPoseObservationsが返されます。

00:05:32.000 --> 00:05:36.000
それぞれに関節の位置が含まれます。

00:05:36.000 --> 00:05:49.000
動物のポーズ観察からこれらの関節にアクセスするには、.recognizedPointsを呼び出して、グループ内の認識されたポイントの辞書を要求します。

00:05:49.000 --> 00:05:57.000
動物の骨格を描くためにすべての関節が必要だったので、私はすべてのグループを使用することを選択します。

00:05:57.000 --> 00:06:04.000
動物の関節の一部にのみアクセスする必要がある場合は、別のグループを使用できます。

00:06:04.000 --> 00:06:12.000
そして最後に、動物の骨格を描くために、私は認識されたすべてのポイントを反復し、関節を接続します。

00:06:12.000 --> 00:06:23.000
以下は、ヘッドジョイントがヘッドスケルトンを描くためにどのように接続されたかの例です。

00:06:23.000 --> 00:06:26.000
心に留めておくべき考慮事項がいくつかあります。

00:06:26.000 --> 00:06:33.000
新しいアニマルボディポーズを使用すると、画像内で最大2匹の動物を検出できます。

00:06:33.000 --> 00:06:39.000
入力画像サイズは、両側で少なくとも64ピクセルである必要があります。

00:06:39.000 --> 00:06:46.000
そして、ニューラルエンジンを使用することで、パフォーマンスはライブキャプチャに追いつくことができます。

00:06:46.000 --> 00:06:50.000
動物のポーズで何ができるかの例をいくつか見てみましょう。

00:06:50.000 --> 00:07:08.000
静止画で新しいアニマルポーズAPIを使用すると、目覚めた後のストレッチなど、動物の興味深いポーズを認識するために関節に関する独自の分析を開発することができます...

00:07:08.000 --> 00:07:17.000
立って、ご褒美を懇願する...

00:07:17.000 --> 00:07:24.000
犬から逃げる...

00:07:24.000 --> 00:07:32.000
または、昼寝をするために丸くなります。

00:07:32.000 --> 00:07:43.000
前に述べたように、動物の認識は動物をローカライズして認識することを可能にし、動物のボディポーズは動物の全身のランドマークを返します。

00:07:43.000 --> 00:07:52.000
これら2つの要求を組み合わせることで、検出された動物の種類、場所、ポーズを知ることができます。

00:07:52.000 --> 00:07:57.000
今、あなたは誰がダイニングテーブルを台無しにしているかを知ることができます。

00:07:57.000 --> 00:08:12.000
これは、あなたのペットのための興味深いアプリケーションを開発する多くの機会を与えるでしょう。おそらく、動物の認識と動物のポーズ検出で活性化された犬の御馳走ディスペンサーのための何か。

00:08:12.000 --> 00:08:16.000
アニマルポーズAPIは、ビデオでも使用できます。

00:08:16.000 --> 00:08:24.000
独自のアルゴリズムをアプリに持ち込んで、動きを分析し、動物がどのような種類の活動を行っているかを判断できます。

00:08:24.000 --> 00:08:33.000
時間の経過とともにポーズを追跡することで、動物の行動を理解するために分析をさらに進めることもできます。

00:08:33.000 --> 00:08:45.000
アニマルボディポーズまで、壁のマークはすべて私の子供たちのものだと思っていましたが、それはレーザーポインターを捕まえようとしている猫でした。

00:08:45.000 --> 00:08:50.000
そして、うわー、この犬は私よりも上手にスケートボードができる！

00:08:50.000 --> 00:08:54.000
もう1つの用途は、カメラで動物を追跡することです。

00:08:54.000 --> 00:09:07.000
この種のトラッキングの詳細については、「DockKitで電動iPhoneスタンドと統合する」セッションを参照してください。ペットのために面白いアプリを書くこともできます。

00:09:07.000 --> 00:09:13.000
例えば、犬に帽子とサングラスをかける。

00:09:13.000 --> 00:09:20.000
動物の誕生日にかわいいカードを作って、家族や友人に送るのはとても楽しいことではないでしょうか？

00:09:20.000 --> 00:09:24.000
誕生日おめでとう、フレンチさん!

00:09:24.000 --> 00:09:30.000
私は、関連する動物の体のポーズ関節を見つける場所に絵文字を配置することによってこれを行います。

00:09:30.000 --> 00:09:36.000
私が持っているこのかわいいおもちゃの犬を使って、絵文字アプリを実演させてください。

00:09:36.000 --> 00:09:44.000
同じサンプルアプリを使用して、スケルトンビューから絵文字ビューに切り替えます。

00:09:44.000 --> 00:10:02.000
この小さな犬はゆっくりと歩いているので、私は彼を少しスピードアップするために彼の足の関節の上にいくつかのスケートの絵文字を追加しました。

00:10:02.000 --> 00:10:04.000
ああ、待って、安全第一!

00:10:04.000 --> 00:10:08.000
コードに戻って、彼にヘルメットをあげましょう。

00:10:08.000 --> 00:10:14.000
ここでは、私はすでに足の関節の上にスケートの絵文字を追加しました。

00:10:14.000 --> 00:10:18.000
耳関節の上にヘルメットの絵文字を追加しましょう。

00:10:18.000 --> 00:10:23.000
私は絵文字のサイズと位置を選びます。

00:10:23.000 --> 00:10:30.000
また、スタイリッシュにスケートをするためにいくつかのメガネを追加しましょう。

00:10:30.000 --> 00:10:34.000
犬の安全を大事にした後、アプリをもう一度実行します。

00:10:34.000 --> 00:10:37.000
後悔するよりは安全だ。

00:10:37.000 --> 00:10:40.000
絵文字ビューに切り替えましょう。

00:10:40.000 --> 00:10:45.000
犬は今、安全にスケートを続けるために必要なギアを持っています。

00:10:45.000 --> 00:10:50.000
かっこいいよね？行け、犬、行け!あなたはそれを釘付けにしました!

00:10:50.000 --> 00:10:52.000
それは動物の体のポーズのためでした。

00:10:52.000 --> 00:11:00.000
新しいAnimal Pose APIを使用して作成するすべての素晴らしいものをアプリに持ち込むのが待ちきれません。

00:11:00.000 --> 00:11:07.000
ビジョンにはもっと役に立つかもしれないアップデートがありますので、紹介させてください。

00:11:07.000 --> 00:11:10.000
新しいステートフルリクエストがあります。

00:11:10.000 --> 00:11:17.000
VNTargetedImageベースのリクエストは、Visionのステートフルリクエストとして利用できます。

00:11:17.000 --> 00:11:24.000
ビジョンには3つの新しい派生ステートフルリクエストがあり、すべてトラック動詞で名付けられました。

00:11:24.000 --> 00:11:28.000
これにより、追跡に使いやすくなります。

00:11:28.000 --> 00:11:34.000
VisionがMLComputeDeviceをサポートしていることを発表できることを嬉しく思います。

00:11:34.000 --> 00:11:43.000
新しいCompute Device APIを使用すると、リクエストがどこで実行されるかを照会し、使用するデバイスを指定できます。

00:11:43.000 --> 00:11:49.000
Core MLとCreate ML Multilabel Classificationは、Visionと互換性があります。

00:11:49.000 --> 00:11:56.000
これにより、複数のラベルをサポートする独自の分類器をトレーニングできます。

00:11:56.000 --> 00:12:04.000
詳細については、セッション「Create MLで機械学習の強化を発見する」を参照してください。

00:12:04.000 --> 00:12:10.000
既存のリクエストにも新しい改訂があり、大きな改善をもたらします。

00:12:10.000 --> 00:12:15.000
バーコードについては、新しいリビジョン、リビジョン4があります。

00:12:15.000 --> 00:12:23.000
新しいリビジョンには、新しいMSIPlesseyシンボルが含まれており、色の反転QRコードをサポートしています。

00:12:23.000 --> 00:12:26.000
ところで、リビジョン1は廃止されます。

00:12:26.000 --> 00:12:34.000
テキスト認識は、タイ語とベトナム語のサポートを追加しています。

00:12:34.000 --> 00:12:45.000
そして最後に、品質と精度を向上させるために、FaceCaptureQuality、リビジョン3の新しい改訂があります。

00:12:45.000 --> 00:12:52.000
Visionのすべての新しいアップデートの詳細については、開発者のドキュメントを確認してください。

00:12:52.000 --> 00:13:00.000
今日は、新しいアニマルボディポーズと、この新しいAPIでできるすべての素晴らしいことについて話しました。

00:13:00.000 --> 00:13:09.000
また、ビジョンのいくつかの重要なAPIのアップデートやその他の機能強化を紹介し、あなたの開発に役立つことを願っています。

00:13:09.000 --> 00:13:11.000
しかし、待ってください、もっとあります。

00:13:11.000 --> 00:13:24.000
ビジョンの新しい3Dボディポーズと人セグメンテーションAPIについては、「ビジョンで3Dボディポーズと人セグメンテーションを探る」セッションを確認してください。

00:13:24.000 --> 00:13:34.000
また、選択したフォアグラウンドオブジェクトをセグメント化する場合は、「アプリ内の画像から被写体を持ち上げる」セッションを参照してください。

00:13:34.000 --> 23:59:59.000
ご清聴ありがとうございました。アニマルポーズで足を手に入れるのが待ちきれません。

