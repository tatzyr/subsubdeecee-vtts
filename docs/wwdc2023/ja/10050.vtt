WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:18.000
Denis: こんにちは、私の名前はDenis Vieriuで、AppleのGPU、グラフィックス、ディスプレイソフトウェアグループのソフトウェアエンジニアです。

00:00:18.000 --> 00:00:25.000
今日は、メタルで今年機械学習に導入されたすべての新機能と機能強化を紹介します。

00:00:25.000 --> 00:00:28.000
まず、既存の機械学習バックエンドを要約します。

00:00:28.000 --> 00:00:34.000
Metal機械学習APIは、Metal Performance Shadersフレームワークを通じて公開されます。

00:00:34.000 --> 00:00:43.000
MPSは、画像処理、線形代数、機械学習など、さまざまな分野向けの高性能GPUプリミティブのコレクションです。

00:00:43.000 --> 00:00:53.000
MPSGraphは、MPSフレームワークの上にあり、多次元テンソルへのサポートを拡張する汎用計算グラフです。

00:00:53.000 --> 00:00:59.000
CoreMLのような機械学習推論フレームワークは、MPSGraphバックエンドの上に構築されています。

00:00:59.000 --> 00:01:05.000
MPSGraphは、TensorFlowやPyTorchなどのトレーニングフレームワークもサポートしています。

00:01:05.000 --> 00:01:14.000
MPSGraphとMLフレームワークの詳細については、ここにリストされている以前のMetal WWDCトークを参照してください。

00:01:14.000 --> 00:01:29.000
このセッションでは、PyTorchとTensorFlow Metalバックエンドに追加されたアップデートと機能強化、JAXの新しいGPUアクセラレーション、およびMPSGraph for ML Inferenceに今年追加された機能に焦点を当てます。

00:01:29.000 --> 00:01:36.000
PyTorchとTensorFlow Metalアクセラレーションを使用すると、MPSの高効率カーネルを使用して、Macで最高のパフォーマンスを得ることができます。

00:01:36.000 --> 00:01:42.000
PyTorch Metalアクセラレーションは、MPSバックエンドを通じてバージョン1.12から利用可能になりました。

00:01:42.000 --> 00:01:52.000
これは昨年PyTorchエコシステムに導入され、それ以来、メモリ使用量とビューテンソルを最適化するために複数の改善が行われました。

00:01:52.000 --> 00:02:00.000
今年、PyTorch 2.0 MPSバックエンドは大きな飛躍を遂げ、ベータステージの資格を取得しました。

00:02:00.000 --> 00:02:03.000
しかし、これらはすべての改善ではありませんでした。

00:02:03.000 --> 00:02:12.000
最新のPyTorchビルドには、MPS操作プロファイリング、カスタムカーネル、自動混合精度サポートなど、多くの新しいアップデートが含まれています。

00:02:12.000 --> 00:02:20.000
毎晩のビルド機能をすべてカバーする前に、PyTorch 2.0の新機能から始めます。

00:02:20.000 --> 00:02:32.000
グリッドサンプラー、三角ソルプト、topkなどの操作を含む、最も使用されているトップ60のトーチ演算子のサポートがあります。

00:02:32.000 --> 00:02:35.000
テストのカバレッジは大幅に改善されました。

00:02:35.000 --> 00:02:43.000
これには、ほとんどのトーチ演算子のテスト、勾配テスト、およびModuleInfoベースのテストが含まれます。

00:02:43.000 --> 00:02:51.000
リリース以来、複数の人気モデルがmacOSの公式バックエンドとしてMPSを採用したため、ネットワークカバレッジは拡大しました。

00:02:51.000 --> 00:03:01.000
これには、WhisperAIなどの基礎モデル、YOLOなどの物体検出モデル、安定した拡散モデルなどが含まれます。

00:03:01.000 --> 00:03:06.000
最新のPyTorch 2.0を使用して、これらのモデルの1つを実際に確認しましょう。

00:03:06.000 --> 00:03:13.000
この例では、M2 Maxで実行されている物体検出ネットワークであるYoloV5を使用しています。

00:03:13.000 --> 00:03:24.000
左側には、ネットワークが実行され、PyTorch MPSバックエンドを使用してライブイメージを生成していますが、右側にはまったく同じモデルがありますが、CPUで実行されています。

00:03:24.000 --> 00:03:31.000
左側は、MPSバックエンドを使用して、著しく高いフレームレートで実行されています。

00:03:31.000 --> 00:03:47.000
さらに、開発者は外部ネットワークでPyTorch MPSバックエンドを採用しただけでなく、ヒストグラム、group_norm、signbitなど、複数の新しい演算子のコードを貢献しました。

00:03:47.000 --> 00:03:55.000
次に、MPS操作のプロファイリングサポートから始めて、最新のPyTorchビルドで利用可能な新機能について説明します。

00:03:55.000 --> 00:04:09.000
PyTorchの夜間ビルドには、OSの標識を使用して、操作実行の正確な実行時間、CPUとGPU間のコピー、およびサポートされていない演算子によって引き起こされるCPUへのフォールバックを示すプロファイリングサポートがあります。

00:04:09.000 --> 00:04:17.000
インスツルメンツの一部である非常に使い慣れたツールであるメタルシステムトレースでプロファイリングデータを視覚化することができます。

00:04:17.000 --> 00:04:27.000
Metal System Traceを使用したMLアプリケーションのプロファイリングの詳細については、昨年のセッション「Metalで機械学習を加速する」を見ることをお勧めします。

00:04:27.000 --> 00:04:31.000
プロファイラを使用するのはとても簡単なプロセスです。

00:04:31.000 --> 00:04:40.000
MPSプロファイラパッケージのstartメソッドを呼び出してトレースを有効にし、スクリプトの最後にstopメソッドを使用してプロファイリングを終了します。

00:04:40.000 --> 00:04:45.000
次に、プロファイラを見て、例をデバッグします。

00:04:45.000 --> 00:04:56.000
このサンプルネットワークは、モデル内の合計7つのレイヤーを持つ線形変換とソフトシュリンク活性化機能で構成されるシーケンシャルモデルを使用します。

00:04:56.000 --> 00:05:00.000
このモデルの現在の性能は満足のいくものではありません。

00:05:00.000 --> 00:05:05.000
この場合、プロファイラを使用してボトルネックを見つけることができます。

00:05:05.000 --> 00:05:10.000
メタルシステムトレースで、まず、os_signpostを有効にしてください。

00:05:10.000 --> 00:05:14.000
これにより、PyTorchオペレーター情報をキャプチャできます。

00:05:14.000 --> 00:05:21.000
次に、デバイスと適切な実行可能ファイル、この場合はPythonバイナリが設定されていることを確認します。

00:05:21.000 --> 00:05:24.000
次に、録画ボタンをクリックします。

00:05:24.000 --> 00:05:28.000
Instrumentsは現在、PyTorchの実行を記録しています。

00:05:28.000 --> 00:05:32.000
十分なデータをキャプチャするために、数秒間実行します。

00:05:32.000 --> 00:05:36.000
次に、[停止]をクリックします。

00:05:36.000 --> 00:05:42.000
os_signpostタブで、PyTorch Intervalsのタイムラインを開示します。

00:05:42.000 --> 00:05:53.000
このタイムラインは、文字列識別子、データ型、コピー長などのPyTorchメタデータとともに、演算子の実行時間を表示します。

00:05:53.000 --> 00:05:58.000
タイムラインにズームインすると、この例で使用されるPyTorch演算子が明らかになります。

00:05:58.000 --> 00:06:05.000
このトレースのパターンは、7つのレイヤーで作られたカスタムシーケンシャルモデルに簡単に識別できます。

00:06:05.000 --> 00:06:11.000
トレースから、ボトルネックがCPUへのSoftshrinkフォールバックにあることは明らかです。

00:06:11.000 --> 00:06:13.000
このプロセスは非常に非効率的です。

00:06:13.000 --> 00:06:22.000
このモデルは、GPUが飢えている間、Softshrink演算子のCPU実行と追加コピーからのオーバーヘッドを負担します。

00:06:22.000 --> 00:06:29.000
GPUタイムラインのギャップのほとんどは、CPUにフォールバックするSoftshrinkアクティベーション機能から来ています。

00:06:29.000 --> 00:06:34.000
これを修正するために、パフォーマンスを向上させるためのカスタムカーネルを書きます。

00:06:34.000 --> 00:06:37.000
カスタム操作を書くには4つのステップがあります。

00:06:37.000 --> 00:06:42.000
まず、Objective-CとMetalで操作を実装します。

00:06:42.000 --> 00:06:48.000
次に、Objective-CコードのPythonバインディングを作成し、拡張機能をコンパイルします。

00:06:48.000 --> 00:06:55.000
最後に、拡張機能が構築されたら、操作をトレーニングスクリプトにインポートして使用を開始します。

00:06:55.000 --> 00:07:00.000
操作の実装から始めます。

00:07:00.000 --> 00:07:03.000
トーチ拡張ヘッダーをインポートすることから始めます。

00:07:03.000 --> 00:07:09.000
これには、C++拡張機能を書くために必要なすべてのPyTorchビットが含まれます。

00:07:09.000 --> 00:07:20.000
次に、計算関数を定義し、get_command_buffer MPSバックエンドAPIを使用して、MPSStreamコマンドバッファへの参照を取得します。

00:07:20.000 --> 00:07:26.000
同様に、get_dispatch_queue APIを使用して、シリアルキューへの参照を取得します。

00:07:26.000 --> 00:07:33.000
次に、コマンドバッファを使用してエンコーダを作成し、カスタムGPUカーネルを定義します。

00:07:33.000 --> 00:07:41.000
ディスパッチキュー内のカーネルをエンコードして、複数のスレッドからの送信がシリアル化されるようにします。

00:07:41.000 --> 00:07:50.000
すべての作業がエンコードされた後、同期APIを使用して、現在のコマンドバッファの実行が完了するまで待機し、シリアル化された送信を観察できます。

00:07:50.000 --> 00:07:55.000
または、シリアル化が不要な場合は、コミットAPIを使用してください。

00:07:55.000 --> 00:07:58.000
次に、カスタム関数をバインドします。

00:07:58.000 --> 00:08:04.000
PYBIND11を使用して、非常に簡単な方法でObjective-C関数をPythonにバインドできます。

00:08:04.000 --> 00:08:10.000
この拡張機能では、必要なバインディングコードは2行にしか及びません。

00:08:10.000 --> 00:08:14.000
バインド後、拡張機能をコンパイルします。

00:08:14.000 --> 00:08:18.000
最初にtorch.utils.cpp_extensionをインポートします。

00:08:18.000 --> 00:08:23.000
これは、拡張機能をコンパイルするために使用できるロード機能を提供します。

00:08:23.000 --> 00:08:31.000
次に、ビルドする拡張機能の名前を渡してから、ソースコードファイルへの相対パスまたは絶対パスのリストを渡します。

00:08:31.000 --> 00:08:37.000
オプションで、ビルドに転送する追加のコンパイラフラグを一覧表示できます。

00:08:37.000 --> 00:08:46.000
ロード関数は、ソースファイルを共有ライブラリにコンパイルし、その後、現在のPythonプロセスにモジュールとしてロードされます。

00:08:46.000 --> 00:08:52.000
最後に、演算子をスクリプトにインポートして使用を開始します。

00:08:52.000 --> 00:09:01.000
まず、コンパイルされたライブラリをインポートし、以前のシーケンシャルモデルを変更して、カスタムSoftshrinkカーネルを使用します。

00:09:01.000 --> 00:09:06.000
同じモデルをもう一度実行して、結果を確認しましょう。

00:09:06.000 --> 00:09:12.000
新しく追加されたカスタムオペレーターにより、モデルははるかに効率的に実行されます。

00:09:12.000 --> 00:09:20.000
CPUへのフォールバックによって作成されたすべてのコピーと中間テンソルがなくなり、シーケンシャルモデルははるかに高速に実行されます。

00:09:20.000 --> 00:09:26.000
それでは、ネットワークをさらに改善する方法をさらに探りましょう。

00:09:26.000 --> 00:09:35.000
PyTorch MPSバックエンドは自動混合精度をサポートするようになりました。これにより、より少ないメモリを使用し、品質を損なうことなく、より速くトレーニングできます。

00:09:35.000 --> 00:09:40.000
混合精度を理解するために、まずサポートされているデータ型を確認します。

00:09:40.000 --> 00:09:50.000
混合精度トレーニングは、単精度浮動小数点と半精度浮動小数点を組み合わせてディープラーニングモデルをトレーニングできるモードです。

00:09:50.000 --> 00:09:57.000
macOS Sonoma以降、MPSGraphは新しいデータタイプbfloat16のサポートを追加します。

00:09:57.000 --> 00:10:02.000
Bfloat16は、ディープラーニング用の16ビット浮動小数点形式です。

00:10:02.000 --> 00:10:08.000
1つの符号ビット、8つの指数ビット、7つのマンティサビットで構成されています。

00:10:08.000 --> 00:10:16.000
これは、ディープラーニングアプリケーションを念頭に置いて設計されていない標準のIEEE 16ビット浮動小数点形式とは異なります。

00:10:16.000 --> 00:10:23.000
自動混合精度は、float16とbfloat16の両方で有効になります。

00:10:23.000 --> 00:10:38.000
自動混合精度は、デフォルトの精度でネットワークのパフォーマンスを測定することにより、レイヤーごとに適切な精度を選択し、精度に影響を与えることなくパフォーマンスを最適化するために、混合精度設定で再び実行されます。

00:10:38.000 --> 00:10:45.000
ニューラルネットワークの一部のレイヤーは、畳み込み層や線形層など、より低い精度で実行できます。

00:10:45.000 --> 00:10:52.000
削減などの他の層は、多くの場合、より高い精度レベルを必要とします。

00:10:52.000 --> 00:10:57.000
ネットワークに自動混合精度サポートを追加するのは非常に簡単なプロセスです。

00:10:57.000 --> 00:10:59.000
まず、オートキャストを追加します。

00:10:59.000 --> 00:11:04.000
Float16とbfloat16の両方がサポートされています。

00:11:04.000 --> 00:11:12.000
オートキャストは、スクリプトの領域を混合精度で実行できるようにするコンテキストマネージャとして機能します。

00:11:12.000 --> 00:11:21.000
この地域では、MPS opsは、精度を維持しながらパフォーマンスを向上させるために、オートキャストによって選択されたデータ型で実行されます。

00:11:21.000 --> 00:11:24.000
MPSバックエンドも大幅に最適化されています。

00:11:24.000 --> 00:11:32.000
PyTorch 2.0とmacOS Sonomaでは、MPSバックエンドは以前のリリースと比較して最大5倍高速です。

00:11:32.000 --> 00:11:36.000
PyTorchはそれだけです。では、TensorFlowに移りましょう。

00:11:36.000 --> 00:11:41.000
TensorFlow Metalバックエンドは、安定した1.0リリースバージョンに成熟しました。

00:11:41.000 --> 00:11:47.000
このリリースでは、グラップラー再マッピングオプティマイザパスがプラグインに追加されました。

00:11:47.000 --> 00:11:55.000
Metalプラグインも混合精度サポートを受けており、インストールプロセスは以前よりも簡単になりました。

00:11:55.000 --> 00:12:04.000
認識された計算パターンの自動融合を追加することで、TensorFlow Metalバックエンドのパフォーマンスが向上しました。

00:12:04.000 --> 00:12:12.000
これらの計算には、融合畳み込みと行列乗算、オプティマイザ操作、およびRNNセルが含まれます。

00:12:12.000 --> 00:12:20.000
この最適化は、計算グラフが作成されると、グラップラーパスを介して自動的に行われます。

00:12:20.000 --> 00:12:25.000
ここでは、2次元畳み込み演算の一般的な計算の例を示します。

00:12:25.000 --> 00:12:32.000
畳み込みには、多くの場合、畳み込みニューラルネットワークの一般的なパターンである加算関数が続きます。

00:12:32.000 --> 00:12:39.000
このパターンを識別することで、グラップラーパスは計算を再マッピングすることができます。

00:12:39.000 --> 00:12:45.000
これにより、より最適化されたカーネルを使用して同じ出力を達成でき、パフォーマンスが向上します。

00:12:45.000 --> 00:12:50.000
PyTorchと同様に、TensorFlowも混合精度サポートを受けています。

00:12:50.000 --> 00:12:53.000
TensorFlowを使用すると、混合精度をグローバルに設定できます。

00:12:53.000 --> 00:13:06.000
これにより、要求されたデータ型ポリシーを使用してすべてのネットワーク層を自動的に作成できるため、標準ワークフローでこの変更を有効にするには、既存のコードへの最小限の変更が必要です。

00:13:06.000 --> 00:13:14.000
グローバルポリシーは、Float16またはBFloat16のいずれかを使用するように設定できます。

00:13:14.000 --> 00:13:21.000
パフォーマンスの向上に加えて、メタルアクセラレーションを有効にするユーザーエクスペリエンスが合理化されました。

00:13:21.000 --> 00:13:32.000
これからは、パッケージマネージャーを介してTensorFlowホイールとTensorFlow-Metalプラグインをインストールする通常のパスに従うだけで、メタルアクセラレーションが可能になります。

00:13:32.000 --> 00:13:41.000
TensorFlow開発の最先端にとどまりたい人のために、メタルアクセラレーションサポートはTensorFlowの夜間リリースでも利用可能になりました。

00:13:41.000 --> 00:13:46.000
それでは、JAXの新しいGPUアクセラレーションについて話しましょう。

00:13:46.000 --> 00:13:53.000
今年は、PyTorchやTensorFlowと同様に、Metalバックエンドを通じてJAX GPUアクセラレーションがサポートされます。

00:13:53.000 --> 00:14:00.000
JAXは、高性能数値計算と機械学習研究のためのPythonライブラリです。

00:14:00.000 --> 00:14:09.000
これは、機械学習研究のための3つの重要な拡張機能を備えた、大きな配列で作業するための人気のあるNumPyフレームワークに基づいています。

00:14:09.000 --> 00:14:14.000
まず、grad関数を使用した自動差別化をサポートします。

00:14:14.000 --> 00:14:21.000
それはPythonの機能の大きなサブセットを通して区別することができ、高次デリバティブを取ることさえできます。

00:14:21.000 --> 00:14:25.000
JAXは、高速で効率的なベクトル化もサポートしています。

00:14:25.000 --> 00:14:33.000
関数 apply_matrix が与えられた場合、Python ではバッチディメンションをループできますが、最適ではないパフォーマンスで実行される可能性があります。

00:14:33.000 --> 00:14:38.000
この場合、vmapを使用してバッチ処理サポートを自動的に追加できます。

00:14:38.000 --> 00:14:45.000
さらに、JAXを使用すると、jitと呼ばれるAPIを使用して、関数を最適化されたカーネルにジャストインタイムでコンパイルできます。

00:14:45.000 --> 00:14:53.000
同じ場合、jitはvmapの上に関数を変換して、より速く実行するために使用されます。

00:14:53.000 --> 00:15:03.000
M2 Maxを搭載したMacBook Proでは、JAX Metalアクセラレーションは驚くべきスピードアップを提供し、これらのネットワーク全体のCPUよりも平均10倍高速です。

00:15:03.000 --> 00:15:12.000
JAXの環境設定とインストールの詳細については、Metal Developer ResourcesのWebページを参照してください。

00:15:12.000 --> 00:15:15.000
ギアを切り替えてML推論に移りましょう。

00:15:15.000 --> 00:15:22.000
まず、ロード時間を最適化するために使用するMPSGraphの新しいシリアル化形式を導入します。

00:15:22.000 --> 00:15:28.000
この新しいシリアル化形式は、他のフレームワークから既存のシリアル化されたネットワークから生成できます。

00:15:28.000 --> 00:15:36.000
最後に、8ビットの整数量子化を活用して、ネットワークのメモリフットプリントを最適化する方法を紹介します。

00:15:36.000 --> 00:15:38.000
始めましょう。

00:15:38.000 --> 00:15:44.000
MPSGraphは、完全な柔軟性を備えた高レベルのAPIを使用して、レイヤーごとに作成できます。

00:15:44.000 --> 00:15:51.000
詳細については、メタルパフォーマンスシェーダーグラフを使用してカスタマイズされたMLモデルを構築するビデオを参照してください。

00:15:51.000 --> 00:15:59.000
カスタムグラフを定義してコンパイルした後、MPSGraphExecutableを介して実行され、結果が得られます。

00:15:59.000 --> 00:16:02.000
通常、このプロセスはうまく機能します。

00:16:02.000 --> 00:16:10.000
しかし、多くのレイヤーを持つ複雑なグラフでは、この最初のコンパイルはアプリケーションの起動時間を短縮する可能性があります。

00:16:10.000 --> 00:16:17.000
MPSGraphには、まさにこの問題に対処するために、MPSGraphPackageと呼ばれる新しいシリアル化フォーマットがあります。

00:16:17.000 --> 00:16:23.000
この新しいシリアル化形式を使用すると、MPSGraphExecutableを事前に作成できます。

00:16:23.000 --> 00:16:30.000
一度作成すると、最適化されたMPSGraphExecutableはMPSGraphPackageファイルから直接読み込むことができます。

00:16:30.000 --> 00:16:34.000
MPSGraphPackageの作成はとても簡単です。

00:16:34.000 --> 00:16:42.000
シリアル化記述子を作成し、シリアル化したいMPSGraphExecutableのシリアル化機能に渡すだけです。

00:16:42.000 --> 00:16:46.000
また、それを保存するためのパスを通過する必要があります。

00:16:46.000 --> 00:16:51.000
パッケージを作成した後、これがグラフをアプリに読み込む方法です。

00:16:51.000 --> 00:16:55.000
コンパイル記述子と、保存されたパッケージへのパスが必要です。

00:16:55.000 --> 00:16:59.000
次に、それらを使用してMPSGraphExecutableを初期化します。

00:16:59.000 --> 00:17:07.000
すでにMPSGraphを使用している場合は、提示したAPIを使用して、新しいシリアル化形式を簡単に採用できます。

00:17:07.000 --> 00:17:14.000
しかし、他のフレームワークから来ている場合は、新しいMPSGraphToolを使用してMPSGraphPackageに簡単に移行できるようになりました。

00:17:14.000 --> 00:17:22.000
CoreMLのユーザーは、MPSGraphPackageを作成するMPSGraphToolでMLプログラムを渡すことができます。

00:17:22.000 --> 00:17:26.000
ONNXでも同じで、ONNXファイルを入力として使用できます。

00:17:26.000 --> 00:17:35.000
この新しいツールを使用すると、推論モデルを手動でエンコードすることなく、既存のモデルをMPSGraphアプリケーションにすばやく含めることができます。

00:17:35.000 --> 00:17:38.000
コマンドラインツールの使い方は次のとおりです。

00:17:38.000 --> 00:17:44.000
MPSGraphToolに、入力モデルタイプ、この場合はCoreMLパッケージを宣言するフラグを付けます。

00:17:44.000 --> 00:17:50.000
また、出力先へのパスと出力モデルの名前も提供します。

00:17:50.000 --> 00:17:55.000
さらに、ターゲットプラットフォームと最小OSバージョンを定義します。

00:17:55.000 --> 00:18:02.000
変換後、生成されたMPSGraphPackagesをアプリにロードして直接実行できます。

00:18:02.000 --> 00:18:10.000
次に、8ビットの整数量子化を使用して計算の効率を向上させる方法について説明します。

00:18:10.000 --> 00:18:16.000
16ビット浮動小数点形式など、トレーニングや推論を行うために浮動小数点形式を使用するのが一般的です。

00:18:16.000 --> 00:18:23.000
しかし、推論では、これらのモデルは結果を予測するのに時間がかかるかもしれません。

00:18:23.000 --> 00:18:29.000
代わりに、多くの場合、低い精度または8ビットの整数を使用することをお勧めします。

00:18:29.000 --> 00:18:36.000
これは、メモリバンドを節約し、モデルのメモリフットプリントを減らすのに役立ちます。

00:18:36.000 --> 00:18:42.000
8ビット整数形式の場合、量子化には対称と非対称の2種類があります。

00:18:42.000 --> 00:18:46.000
MPSGraphは、両方のAPIをサポートするようになりました。

00:18:46.000 --> 00:18:55.000
対称量子化と比較して、非対称の量子化では、ここでゼロポイントで示される量子化バイアスを指定できます。

00:18:55.000 --> 00:19:05.000
それでは、入力としてInt8形式の活性化と重みから始めて、例を通して量子化された計算を使用することを掘り下げてみましょう。

00:19:05.000 --> 00:19:12.000
これらの入力は、MPSGraphのdequantizeTensor opを使用して浮動小数点形式にデ量子化されます。

00:19:12.000 --> 00:19:17.000
これで、浮動小数点入力を畳み込み操作に入力できます。

00:19:17.000 --> 00:19:23.000
結果の浮動小数点テンソルは、quantizeTensor opを使用してInt8に量子化することができます。

00:19:23.000 --> 00:19:33.000
MPSGraphは、これらすべてのカーネルを自動的に1つの操作に統合するため、メモリ帯域幅を節約し、パフォーマンスを向上させる可能性があります。

00:19:33.000 --> 00:19:39.000
そして、これはMPSGraphで量子化サポートを使用する方法です。

00:19:39.000 --> 00:19:45.000
以前の新機能に加えて、MPSGraphはさらに多くの機械学習オペレーターをサポートしています。

00:19:45.000 --> 00:19:50.000
今年から、ほとんどのグラフ操作で複雑な型がサポートされています。

00:19:50.000 --> 00:19:56.000
単精度または半精度浮動小数点形式で複素数を使用できます。

00:19:56.000 --> 00:20:02.000
複雑なデータ型に基づいて、MPSGraphは高速フーリエ変換を計算するための演算子を追加します。

00:20:02.000 --> 00:20:09.000
複雑から複雑、複雑から現実、現実から複雑な変換を最大4次元まで適用できます。

00:20:09.000 --> 00:20:15.000
これらは、オーディオ、ビデオ、および画像処理アプリケーションで非常に一般的です。

00:20:15.000 --> 00:20:30.000
さらに、MPSGraphを使用すると、3次元畳み込み、グリッドサンプリング、ソートとArgSort、および合計、製品、最小値、最大値などの累積操作を実行できるようになりました。

00:20:30.000 --> 00:20:35.000
これでMPSGraphの新機能に関する議論は終わりです。

00:20:35.000 --> 00:20:38.000
このセッションで今日発表されたものを復習しましょう。

00:20:38.000 --> 00:20:45.000
PyTorchやTensorFlowのような一般的なMLフレームワークをMetalで加速する際の改善点について調べました。

00:20:45.000 --> 00:20:51.000
これで、新しいMetalアクセラレーションJAXフレームワークを利用することもできます。

00:20:51.000 --> 00:20:59.000
また、新しいシリアル化ツールを使用して、既存のモデルを他のフレームワークからMPSGraphにシームレスに統合する方法についても説明しました。

00:20:59.000 --> 00:21:01.000
これで私たちの話は終わりです。

00:21:01.000 --> 00:21:05.000
これらすべての機能を使用して作成する素晴らしいコンテンツを見るのが待ちきれません。

00:21:05.000 --> 00:21:07.000
見てくれてありがとう。

00:21:07.000 --> 23:59:59.000
♪ ♪

