WEBVTT

00:00:00.000 --> 00:00:04.000
♪まろやかなインストゥルメンタルヒップホップ♪

00:00:04.000 --> 00:00:10.000
♪

00:00:10.000 --> 00:00:14.000
こんにちは、私はアップルのソフトウェアエンジニア、パウ・サストレ・ミゲルです。

00:00:14.000 --> 00:00:21.000
今日は、xrOSでMetalで没入型体験を作成する方法について話します。

00:00:21.000 --> 00:00:29.000
今年は、xrOSの発売により、Appleのエコシステムで使い慣れた技術で没入型体験を生み出すことができます。

00:00:29.000 --> 00:00:35.000
RealityKitを使用すると、仮想コンテンツと現実世界を融合させる体験を作成できます。

00:00:35.000 --> 00:00:47.000
一方、アプリケーションがユーザーを完全に没入型体験に連れて行く場合、xrOSでは、現実世界のコンテンツを独自の仮想コンテンツに完全に置き換えることもできます。

00:00:47.000 --> 00:00:52.000
完全に没入感のある体験を作成する場合、レンダリング方法に関してはいくつかの選択肢があります。

00:00:52.000 --> 00:00:58.000
RealityKitを引き続き使用することも、必要に応じてMetalとARKit APIを選択できます。

00:00:58.000 --> 00:01:12.000
RecRoomは、CompositorServicesを使用してレンダリングセッションを作成し、Metal APIを使用してフレームをレンダリングし、ARKitを使用して世界とハンドトラッキングを取得する完全没入型体験を提供するアプリケーションの素晴らしい例です。

00:01:12.000 --> 00:01:18.000
彼らはUnityエディタのおかげで、これらすべての技術にサポートをもたらすことができました。

00:01:18.000 --> 00:01:25.000
独自のエンジンを書きたい場合は、CompositorServices APIを使用すると、xrOS上のMetalレンダリングにアクセスできます。

00:01:25.000 --> 00:01:32.000
ワールドトラッキングとハンドトラッキングを追加するARKitと組み合わせて、完全に没入感のある体験を作り出すことができます。

00:01:32.000 --> 00:01:37.000
CompositorServicesは、xrOSで動作するようにエンジンを設定するための鍵です。

00:01:37.000 --> 00:01:42.000
レンダリングループの設定方法と、1つのフレームをレンダリングする方法を紹介します。

00:01:42.000 --> 00:01:47.000
最後に、ARKitを使って体験をインタラクティブにする方法を紹介します。

00:01:47.000 --> 00:01:52.000
xrOSアプリのアーキテクチャから始めましょう。

00:01:52.000 --> 00:01:59.000
メタルAPIとメタルレンダリング技術の経験があれば、今日のセッションを最大限に活用できます。

00:01:59.000 --> 00:02:07.000
以前にMetalを使用したことがない場合は、developer.apple.com/Metalでコードサンプルとドキュメントをチェックしてください。

00:02:07.000 --> 00:02:15.000
MetalでxrOSで没入型体験を作成するときは、SwiftUIから始めてアプリケーションとレンダリングセッションを作成します。

00:02:15.000 --> 00:02:25.000
レンダリングセッションを作成した後、CやC++など、より馴染みのある言語に切り替えて、エンジンの内部部分を定義できます。

00:02:25.000 --> 00:02:29.000
SwiftUIアプリプロトコルに準拠したタイプを作成することから始めます。

00:02:29.000 --> 00:02:34.000
このプロトコルに準拠するには、アプリでシーンのリストを定義します。

00:02:34.000 --> 00:02:37.000
xrOSには、主に3つのシーンタイプがあります。

00:02:37.000 --> 00:02:42.000
ウィンドウタイプは、macOSのような2Dプラットフォームに似た体験を提供します。

00:02:42.000 --> 00:02:48.000
ボリュームタイプは、その範囲内でコンテンツをレンダリングし、共有スペースで他のアプリケーションと共存します。

00:02:48.000 --> 00:02:53.000
また、ImmersiveSpaceを使用すると、どこにでもコンテンツをレンダリングできます。

00:02:53.000 --> 00:03:00.000
メタルで完全に没入感のある体験をレンダリングするたびに、ImmersiveSpaceタイプを選択します。

00:03:00.000 --> 00:03:05.000
ImmersiveSpaceは、xrOSで利用可能な新しいSwiftUIシーンタイプです。

00:03:05.000 --> 00:03:10.000
それは完全に没入型体験のための容器として機能します。

00:03:10.000 --> 00:03:16.000
ImmersiveSpaceの使い方を学ぶには、「SwiftUIで窓を越えて行く」セッションをチェックしてください。

00:03:16.000 --> 00:03:26.000
ImmersiveSpaceシーンを作成すると、アプリケーションはImmersiveSpaceContentプロトコルに準拠したタイプを使用してコンテンツを提供します。

00:03:26.000 --> 00:03:32.000
多くの場合、ImmersiveSpaceシーンのコンテンツを作成するとき、アプリケーションはRealityKitを使用します。

00:03:32.000 --> 00:03:35.000
ボンネットの下にCoreAnimationとMaterialXを使用しています。

00:03:35.000 --> 00:03:42.000
しかし、代わりに、Metalの力を使ってアプリケーションのコンテンツをレンダリングしたい場合は、別の選択肢があります。

00:03:42.000 --> 00:03:50.000
CompositorServices APIは、MetalとARKitを使用して、アプリケーションに没入型レンダリング機能を提供します。

00:03:50.000 --> 00:04:00.000
xrOSで導入された新しいCompositorServices APIは、ImmersiveSpaceの内容をレンダリングできるMetalレンダリングインターフェイスを提供します。

00:04:00.000 --> 00:04:05.000
CompositorServicesを使用すると、アプリケーションはコンポジターサーバーに直接レンダリングできます。

00:04:05.000 --> 00:04:14.000
レイテンシを最小限に抑えるためにIPCオーバーヘッドが低く、CとSwiftの両方のAPIをサポートするためにゼロから構築されています。

00:04:14.000 --> 00:04:20.000
CompositorServicesを使用する場合、ImmersiveSpaceContentはCompositorLayerと呼ばれます。

00:04:20.000 --> 00:04:25.000
CompositorLayerを作成するには、2つのパラメータを指定する必要があります。

00:04:25.000 --> 00:04:29.000
1つ目はCompositorLayerConfigurationプロトコルです。

00:04:29.000 --> 00:04:34.000
このプロトコルは、レンダリングセッションの動作と機能を定義します。

00:04:34.000 --> 00:04:37.000
2つ目はLayerRendererです。

00:04:37.000 --> 00:04:40.000
これは、レイヤーレンダリングセッションのインターフェースです。

00:04:40.000 --> 00:04:45.000
アプリケーションはこのオブジェクトを使用して、新しいフレームをスケジュールおよびレンダリングします。

00:04:45.000 --> 00:04:51.000
Metalで没入型体験を書くときは、アプリのタイプを定義することから始めます。

00:04:51.000 --> 00:04:54.000
シーンタイプとして、ImmersiveSpaceを使用します。

00:04:54.000 --> 00:04:58.000
コンテンツタイプには、CompositorLayerを使用してください。

00:04:58.000 --> 00:05:06.000
CompositorLayerがコンテンツをレンダリングする準備ができたら、システムはレンダリングセッションのインスタンスでアプリケーションを呼び出します。

00:05:06.000 --> 00:05:11.000
これは、カスタムエンジンのインスタンスを作成するのに適した場所です。

00:05:11.000 --> 00:05:20.000
エンジンインスタンスができ、レンダリングスレッドを作成し、startを呼び出してレンダリングループを実行できます。

00:05:20.000 --> 00:05:31.000
アプリケーションでシーンリストを定義する際に考慮すべきことの1つは、アプリの最初のシーンがImmersiveSpaceであっても、デフォルトでSwiftUIがウィンドウシーンを作成することです。

00:05:31.000 --> 00:05:35.000
そのデフォルトの動作を変更するには、アプリの情報plistを変更できます。

00:05:35.000 --> 00:05:44.000
キーUIApplicationPreferred DefaultSceneSessionRoleをアプリケーションシーンマニフェストに追加して、アプリケーションのデフォルトのシーンタイプを変更できます。

00:05:44.000 --> 00:05:52.000
Compositor SpaceContentでスペースを使用している場合は、CPSceneSessionRole ImmersiveSpaceApplicationを使用します。

00:05:52.000 --> 00:06:01.000
アプリケーションを設定した後、レンダリングループに入る前に、LayerRendererの設定方法をCompositorServicesに伝えます。

00:06:01.000 --> 00:06:08.000
CompositorLayerに構成を提供するには、CompositorLayerConfigurationプロトコルに準拠した新しいタイプを作成します。

00:06:08.000 --> 00:06:15.000
このプロトコルを使用すると、レンダリングセッションのセットアップと動作の一部を変更できます。

00:06:15.000 --> 00:06:18.000
CompositorLayerConfigurationは2つのパラメータを提供します。

00:06:18.000 --> 00:06:21.000
1つ目はレイヤー機能です。

00:06:21.000 --> 00:06:25.000
これにより、デバイスで利用可能な機能を照会できます。

00:06:25.000 --> 00:06:29.000
機能を使用して、有効な設定を作成します。

00:06:29.000 --> 00:06:32.000
そして2番目のパラメータは、LayerRendererの設定です。

00:06:32.000 --> 00:06:36.000
このタイプは、レンダリングセッションの設定を定義します。

00:06:36.000 --> 00:06:46.000
設定により、エンジンがコンテンツをレイヤーにマッピングする方法を定義し、フォベレーションレンダリングを有効にし、パイプラインの色管理を定義できます。

00:06:46.000 --> 00:06:51.000
さて、これらの各プロパティがエンジンにどのように影響するかについて話します。

00:06:51.000 --> 00:06:54.000
1つ目はフォベレーションレンダリングです。

00:06:54.000 --> 00:07:02.000
この機能の主な目的は、より大きなテクスチャサイズを使用せずに、より高いピクセル/度密度でコンテンツをレンダリングできるようにすることです。

00:07:02.000 --> 00:07:08.000
通常のディスプレイパイプラインでは、ピクセルはテクスチャに直線的に分布します。

00:07:08.000 --> 00:07:16.000
xrOSは、ディスプレイのどの領域がより低いサンプリングレートを使用できるかを定義するマップを作成することで、このワークフローを最適化します。

00:07:16.000 --> 00:07:22.000
これは、ディスプレイの視覚的な忠実度を維持しながら、フレームをレンダリングするために必要な電力を減らすのに役立ちます。

00:07:22.000 --> 00:07:28.000
より良い視覚体験につながるため、可能な限りfoveationを使用することは重要です。

00:07:28.000 --> 00:07:35.000
foveationがレンダリングパイプラインにどのように影響するかを視覚化する素晴らしい方法は、XcodeのMetal Debuggerを使用することです。

00:07:35.000 --> 00:07:43.000
Metal Debuggerを使用すると、レンダリングパイプラインで使用されているターゲットテクスチャとラスタライズレートマップを検査できます。

00:07:43.000 --> 00:07:49.000
このキャプチャは、ラスタライズレートマップのスケーリングなしでテクスチャの内容を表示します。

00:07:49.000 --> 00:07:55.000
より圧縮されたテクスチャの領域に焦点を合わせることで、異なるサンプルレートに気づくことができます。

00:07:55.000 --> 00:08:04.000
メタルデバッガの添付ファイルビューアオプションを使用すると、画像を拡大縮小して、ディスプレイに表示される最終結果を視覚化できます。

00:08:04.000 --> 00:08:11.000
コンポジターは、各フレームのMTLRasterizationRateMapを使用してフォベーションマップを提供します。

00:08:11.000 --> 00:08:15.000
フォベーションがサポートされているかどうかを常に確認することをお勧めします。

00:08:15.000 --> 00:08:17.000
これはプラットフォームによって変わります。

00:08:17.000 --> 00:08:22.000
たとえば、xrOSシミュレータでは、フォベネーションは利用できません。

00:08:22.000 --> 00:08:28.000
foveationを有効にするには、設定でisFoveationEnabledを設定できます。

00:08:28.000 --> 00:08:31.000
2番目のプロパティはLayerRendererレイアウトです。

00:08:31.000 --> 00:08:36.000
このプロパティは、エンジンにとって最も重要な構成の1つです。

00:08:36.000 --> 00:08:43.000
ヘッドセットからの各ディスプレイがアプリケーションのレンダリングされたコンテンツにどのようにマッピングされるかを定義します。

00:08:43.000 --> 00:08:48.000
それぞれの目は、コンポジターが提供するメタルテクスチャに最初にマッピングされます。

00:08:48.000 --> 00:08:53.000
次に、Compositorは、そのテクスチャ内でどのスライスを使用するかのインデックスを提供します。

00:08:53.000 --> 00:08:59.000
そして最後に、コンポジターは、そのテクスチャスライス内で使用するビューポートを提供します。

00:08:59.000 --> 00:09:04.000
LayerRendererのレイアウトでは、テクスチャスライスとビューポートの間で異なるマッピングを選択できます。

00:09:04.000 --> 00:09:10.000
レイヤーでは、コンポジターは2つのスライスと2つのビューポートを持つ1つのテクスチャを使用します。

00:09:10.000 --> 00:09:16.000
専用では、コンポジターはそれぞれ1つのスライスと1つのビューポートを持つ2つのテクスチャを使用します。

00:09:16.000 --> 00:09:24.000
そして最後に、共有では、Compositorはそのスライスに1つのテクスチャ、1つのスライス、および2つの異なるビューポートを使用します。

00:09:24.000 --> 00:09:29.000
使用するレイアウトの選択は、レンダリングパイプラインの設定方法によって異なります。

00:09:29.000 --> 00:09:38.000
たとえば、レイヤーと共有を使用すると、1回のパスでレンダリングを実行できるため、レンダリングパイプラインを最適化できます。

00:09:38.000 --> 00:09:44.000
共有レイアウトでは、フォベレーションされたレンダリングがオプションではない既存のコードベースを移植する方が簡単かもしれません。

00:09:44.000 --> 00:09:53.000
レイヤードレイアウトは、フォベレーションされたレンダリングを維持しながら、ワンパスでシーンをレンダリングできるため、最適なレイアウトです。

00:09:53.000 --> 00:09:57.000
議論する最後の構成プロパティはカラーマネジメントです。

00:09:57.000 --> 00:10:03.000
コンポジターは、コンテンツが拡張リニアディスプレイP3色空間でレンダリングされることを期待しています。

00:10:03.000 --> 00:10:06.000
xrOSは2.0のEDRヘッドルームをサポートしています。

00:10:06.000 --> 00:10:09.000
それはSDR範囲の2倍です。

00:10:09.000 --> 00:10:21.000
デフォルトでは、CompositorはHDRレンダリング可能なピクセル形式を使用しませんが、アプリケーションがHDRをサポートしている場合は、レイヤー構成でrgba16Floatを指定できます。

00:10:21.000 --> 00:10:29.000
EDRでHDRをレンダリングする方法についてもっと知りたい場合は、「EDRでHDRレンダリングを探索する」セッションをチェックしてください。

00:10:29.000 --> 00:10:37.000
アプリケーションでカスタム設定を作成するには、CompositorLayerConfigurationプロトコルに準拠した新しいタイプを定義することから始めます。

00:10:37.000 --> 00:10:42.000
このプロトコルに準拠するには、makeConfigurationメソッドを追加します。

00:10:42.000 --> 00:10:47.000
このメソッドは、レイヤーの機能と変更できる構成を提供します。

00:10:47.000 --> 00:10:52.000
前に述べた3つのプロパティを有効にするには、まずフォベーションがサポートされているかどうかを確認してください。

00:10:52.000 --> 00:10:57.000
次に、このデバイスでサポートされているレイアウトを確認してください。

00:10:57.000 --> 00:11:01.000
この情報を使用して、設定で有効なレイアウトを設定できます。

00:11:01.000 --> 00:11:08.000
コンポジターが1つのビューのみをレンダリングするシミュレータのような一部のデバイスでは、レイヤードは利用できません。

00:11:08.000 --> 00:11:12.000
Foveationの場合、デバイスがサポートしている場合はtrueに設定します。

00:11:12.000 --> 00:11:19.000
そして最後に、colorFormatをrgba16Floatに設定して、HDRコンテンツをレンダリングできるようにします。

00:11:19.000 --> 00:11:26.000
コンポジターレイヤーを作成したコードに戻ると、作成したばかりの構成タイプを追加できるようになりました。

00:11:26.000 --> 00:11:31.000
レンダリングセッションが設定されたので、レンダリングループを設定できます。

00:11:31.000 --> 00:11:35.000
まず、CompositorLayerのLayerRendererオブジェクトを使用します。

00:11:35.000 --> 00:11:42.000
まず、リソースをロードし、エンジンがフレームをレンダリングするために必要なオブジェクトを初期化します。

00:11:42.000 --> 00:11:44.000
次に、レイヤーの状態を確認します。

00:11:44.000 --> 00:11:48.000
レイヤーが一時停止している場合は、レイヤーが実行されるまで待ちます。

00:11:48.000 --> 00:11:51.000
レイヤーが待機からブロック解除されたら、レイヤーの状態をもう一度確認してください。

00:11:51.000 --> 00:11:55.000
レイヤーが実行されている場合は、フレームをレンダリングできます。

00:11:55.000 --> 00:12:00.000
そして、そのフレームがレンダリングされたら、次のフレームをレンダリングする前にレイヤーの状態をもう一度確認してください。

00:12:00.000 --> 00:12:06.000
レイヤー状態が無効になっている場合は、レンダリングループ用に作成したリソースを解放します。

00:12:06.000 --> 00:12:10.000
さて、render_loopのメイン関数を定義する時が来ました。

00:12:10.000 --> 00:12:15.000
今まで、ImmersiveSpace APIはSwiftでしか利用できないので、Swiftを使っています。

00:12:15.000 --> 00:12:20.000
しかし、ここからレンダリングループを書くためにCに切り替えます。

00:12:20.000 --> 00:12:27.000
前述したように、レンダリングループの最初のステップは、フレームをレンダリングするために必要なすべてのオブジェクトを割り当てて初期化することです。

00:12:27.000 --> 00:12:31.000
これを行うには、カスタムエンジンのセットアップ関数を呼び出すことができます。

00:12:31.000 --> 00:12:35.000
次に、ループのメインセクションです。

00:12:35.000 --> 00:12:38.000
最初のステップは、layerRendererの状態を確認することです。

00:12:38.000 --> 00:12:43.000
状態が一時停止されている場合、レイヤーレンダラーが実行されるまでスレッドはスリープ状態になります。

00:12:43.000 --> 00:12:48.000
レイヤー状態が実行されている場合、エンジンは1つのフレームをレンダリングします。

00:12:48.000 --> 00:12:53.000
そして最後に、レイヤーが無効になっている場合、レンダリングループは終了します。

00:12:53.000 --> 00:12:58.000
Render_loop関数の最後のステップは、使用したリソースをクリアすることです。

00:12:58.000 --> 00:13:03.000
アプリがレンダリングループを通過したので、1つのフレームをレンダリングする方法を説明します。

00:13:03.000 --> 00:13:08.000
xrOSでのコンテンツのレンダリングは、常にデバイスの観点からです。

00:13:08.000 --> 00:13:12.000
ARKitを使用して、デバイスの向きと翻訳を取得できます。

00:13:12.000 --> 00:13:23.000
ARKitはすでにiOSで利用可能であり、現在xrOSは、没入型体験を作成するのに役立つ追加機能を備えたまったく新しいAPIを導入しています。

00:13:23.000 --> 00:13:31.000
ARKitを使用すると、ワールドトラッキング、ハンドトラッキング、その他のワールドセンシング機能をアプリケーションに追加できます。

00:13:31.000 --> 00:13:41.000
新しいARKit APIは、CおよびSwift APIをサポートするためにゼロから構築されているため、既存のレンダリングエンジンとの統合が容易になります。

00:13:41.000 --> 00:13:47.000
xrOSのARKitの詳細については、「空間コンピューティングのためのARKitの出会い」をご覧ください。

00:13:47.000 --> 00:13:52.000
レンダリングループ内で、1つのフレームをレンダリングする時が来ました。

00:13:52.000 --> 00:13:56.000
フレームをレンダリングするとき、Compositorは2つの主要なセクションを定義します。

00:13:56.000 --> 00:13:58.000
1つ目はアップデートです。

00:13:58.000 --> 00:14:02.000
ここでは、入力遅延が重要ではない作業を行う場所です。

00:14:02.000 --> 00:14:10.000
これは、シーンのアニメーションを更新したり、キャラクターを更新したり、ハンドスケルトンのポーズのようにシステムに入力を集めたりします。

00:14:10.000 --> 00:14:13.000
フレームの2番目のセクションは提出セクションです。

00:14:13.000 --> 00:14:16.000
ここでは、レイテンシクリティカルな作業を実行する場所です。

00:14:16.000 --> 00:14:21.000
また、ヘッドセットポーズに依存するコンテンツをここでレンダリングします。

00:14:21.000 --> 00:14:27.000
これらの各セクションのタイミングを定義するために、Compositorはタイミングオブジェクトを提供します。

00:14:27.000 --> 00:14:32.000
この図は、タイミングがさまざまなフレームセクションにどのように影響するかを定義します。

00:14:32.000 --> 00:14:37.000
CPUとGPUのトラックは、アプリケーションによって行われている作業を表します。

00:14:37.000 --> 00:14:43.000
また、コンポジタートラックは、コンポジターサーバーがフレームを表示するために行った作業を表します。

00:14:43.000 --> 00:14:48.000
コンポジターサービスのタイミングタイプは、3つの主要な時間値を定義します。

00:14:48.000 --> 00:14:50.000
1つ目は最適な入力時間です。

00:14:50.000 --> 00:14:57.000
これは、レイテンシクリティカルな入力を照会し、フレームのレンダリングを開始するのに最適な時期です。

00:14:57.000 --> 00:14:59.000
2つ目はレンダリングの締め切りです。

00:14:59.000 --> 00:15:05.000
それは、CPUとGPUがフレームをレンダリングするために作業する時間です。

00:15:05.000 --> 00:15:07.000
そして3つ目はプレゼンテーションの時間です。

00:15:07.000 --> 00:15:11.000
それはあなたのフレームが展示される時間です。

00:15:11.000 --> 00:15:18.000
フレームの2つのセクションでは、更新セクションは最適な入力時間の前に行われるはずです。

00:15:18.000 --> 00:15:23.000
更新後、フレームの送信を開始する前に、最適な入力時間を待ちます。

00:15:23.000 --> 00:15:29.000
次に、フレーム送信を実行し、レンダリング作業をGPUに提出します。

00:15:29.000 --> 00:15:42.000
CPUとGPUの作業はレンダリングの締め切り前に完了する必要があることに注意することが重要です。そうしないと、Compositorサーバーはこのフレームを使用できず、代わりに以前のフレームを使用します。

00:15:42.000 --> 00:15:49.000
最後に、レンダリング期限に、コンポジターサーバーはこのフレームをシステム内の他のレイヤーと合成します。

00:15:49.000 --> 00:15:56.000
レンダリングループコードに戻ると、render_new_frame関数を定義する時が来ました。

00:15:56.000 --> 00:16:02.000
エンジンのrender_new_frame関数では、まずlayerRendererからフレームを照会します。

00:16:02.000 --> 00:16:06.000
フレームオブジェクトを使用すると、タイミング情報を予測できます。

00:16:06.000 --> 00:16:11.000
そのタイミング情報を使用して、更新をスコープし、間隔を送信します。

00:16:11.000 --> 00:16:13.000
次に、更新セクションを実装します。

00:16:13.000 --> 00:16:18.000
フレームの開始と終了の更新を呼び出して、このセクションを定義します。

00:16:18.000 --> 00:16:23.000
内部では、デバイスの入力を収集し、フレームの内容を更新します。

00:16:23.000 --> 00:16:29.000
更新が完了したら、最適な入力時間を待ってから送信を開始します。

00:16:29.000 --> 00:16:34.000
待機後、送信の開始と終了の送信を呼び出して、送信セクションを定義します。

00:16:34.000 --> 00:16:38.000
このセクション内で、まず描画可能なオブジェクトを照会します。

00:16:38.000 --> 00:16:47.000
CAMetalLayerと同様に、描画可能なオブジェクトには、ターゲットテクスチャとレンダリングパイプラインを設定するために必要な情報が含まれています。

00:16:47.000 --> 00:16:54.000
描画可能になったので、Compositorがこのフレームをレンダリングするために使用する最終的なタイミング情報を取得できます。

00:16:54.000 --> 00:16:57.000
最終的なタイミングで、ar_poseを照会できます。

00:16:57.000 --> 00:17:04.000
コンポジターがフレームに再投影を実行するために使用されるため、ドローableにポーズを設定することが重要です。

00:17:04.000 --> 00:17:10.000
ここでは、エンジンオブジェクトのget_ar_pose関数を呼び出してポーズを取得しています。

00:17:10.000 --> 00:17:15.000
ただし、ARKitワールドトラッキングAPIを使用して、この機能の内容を実装する必要があります。

00:17:15.000 --> 00:17:21.000
機能の最後のステップは、すべてのGPU作業をエンコードしてフレームを提出することです。

00:17:21.000 --> 00:17:26.000
Submit_frame内で、ドローアブルを使用して、通常どおりフレームの内容をレンダリングします。

00:17:26.000 --> 00:17:32.000
レンダリングループがフレームをレンダリングするようになったので、没入型の体験をインタラクティブにする時が来ました。

00:17:32.000 --> 00:17:42.000
このビデオは、Unityを使用するRecRoomがすでにARKitとCompositor APIを利用してアプリケーションにインタラクティブ性を追加する方法を示しています。

00:17:42.000 --> 00:17:46.000
この相互作用を推進する2つの主要な入力ソースがあります。

00:17:46.000 --> 00:17:51.000
ARKitのHandTrackingは、仮想の手をレンダリングするためのハンドスケルトンを提供しています。

00:17:51.000 --> 00:17:55.000
そして、LayerRendererからのピンチイベントがユーザーインタラクションを推進しています。

00:17:55.000 --> 00:18:03.000
体験をインタラクティブにするために、まずユーザーの入力を収集し、それをシーンの内容に適用します。

00:18:03.000 --> 00:18:07.000
この作業はすべて、フレームの更新セクションで行われます。

00:18:07.000 --> 00:18:13.000
LayerRendererとARKit HandTrackingプロバイダーの2つの主要な入力ソースがあります。

00:18:13.000 --> 00:18:18.000
LayerRendererを使用すると、アプリケーションがピンチイベントを受信するたびに更新されます。

00:18:18.000 --> 00:18:23.000
これらの更新は、空間イベントの形で公開されます。

00:18:23.000 --> 00:18:26.000
これらのイベントには3つの主要なプロパティが含まれています。

00:18:26.000 --> 00:18:32.000
フェーズは、イベントがアクティブかどうか、終了したかどうか、またはキャンセルされたかどうかを教えてくれます。

00:18:32.000 --> 00:18:38.000
選択光線を使用すると、イベントが始まったときに注目を集めたシーンの内容を判断できます。

00:18:38.000 --> 00:18:41.000
そして、最後のイベントプロパティはマニピュレーターのポーズです。

00:18:41.000 --> 00:18:47.000
これはピンチのポーズで、イベント期間中、すべてのフレームが更新されます。

00:18:47.000 --> 00:18:54.000
HandTracking APIから、左手と右手の両方のスケルトンを取得できます。

00:18:54.000 --> 00:18:57.000
さあ、コードに入力サポートを追加する時が来ました。

00:18:57.000 --> 00:19:04.000
入力を収集する前に、アプリケーションが仮想ハンドをレンダリングしているのか、パススルーハンドを使用しているのかを決定します。

00:19:04.000 --> 00:19:12.000
UpperLimbVisibilityシーン修飾子をImmersiveSpaceに追加して、パススルーの手を表示または非表示にします。

00:19:12.000 --> 00:19:18.000
空間イベントにアクセスするには、CompositorLayerレンダリングハンドラを定義した場所に戻ります。

00:19:18.000 --> 00:19:25.000
ここでは、layerRendererにブロックを登録して、新しい空間イベントがあるたびに更新を取得します。

00:19:25.000 --> 00:19:32.000
エンジンコードをCで書く場合は、SwiftUI空間イベントをCタイプにマッピングします。

00:19:32.000 --> 00:19:37.000
Cコード内で、Cイベントコレクションを受け取ることができます。

00:19:37.000 --> 00:19:44.000
空間イベントの更新を処理する際に留意すべきことの1つは、更新がメインスレッドで配信されることです。

00:19:44.000 --> 00:19:51.000
これは、エンジンでイベントを読み書きするときに、いくつかの同期メカニズムを使用することを意味します。

00:19:51.000 --> 00:19:57.000
イベントがエンジンに保存されたので、gather入力機能を実装する時が来ました。

00:19:57.000 --> 00:20:02.000
最初のステップは、このフレームの現在の入力状態を格納するオブジェクトを作成することです。

00:20:02.000 --> 00:20:07.000
この入力状態は、LayerRendererから受信したイベントを保存します。

00:20:07.000 --> 00:20:11.000
安全な方法で内部ストレージにアクセスしていることを確認してください。

00:20:11.000 --> 00:20:19.000
ハンドスケルトンについては、ARKitのハンドトラッキングプロバイダーAPIを使用して、最新のハンドアンカーを入手できます。

00:20:19.000 --> 00:20:27.000
そして、アプリケーションが入力サポートを利用できるようになったので、xrOSで完全に没入感のある体験を作成するためのすべてのツールを自由に利用できます。

00:20:27.000 --> 00:20:31.000
要約すると、SwiftUIでは、アプリケーションを定義します。

00:20:31.000 --> 00:20:36.000
CompositorServicesとMetalを使用すると、レンダリングループを設定し、3Dコンテンツを表示します。

00:20:36.000 --> 00:20:41.000
そして最後に、ARKitを使用すると、あなたの体験をインタラクティブにすることができます。

00:20:41.000 --> 00:20:43.000
見てくれてありがとう!

00:20:43.000 --> 23:59:59.000
♪

