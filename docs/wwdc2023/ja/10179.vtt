WEBVTT

00:00:00.000 --> 00:00:10.000
♪ ♪

00:00:10.000 --> 00:00:15.000
エリン：こんにちは！私の名前はエリンで、CoreMotionチームのエンジニアです。

00:00:15.000 --> 00:00:19.000
CoreMotionのクールなアップデートについてお伝えできることを嬉しく思います。

00:00:19.000 --> 00:00:24.000
CoreMotionは、慣性センサーからモーションデータにアクセスするための中心的なフレームワークとして機能します。

00:00:24.000 --> 00:00:29.000
ハードウェアが進歩するにつれて、モーション情報をキャプチャする能力も進歩しています。

00:00:29.000 --> 00:00:38.000
クラッシュ検出、転倒検出、空間オーディオは、改善されたセンシング機能に依存する機能のほんの一部です。

00:00:38.000 --> 00:00:43.000
CoreMotionを使用すると、これらの改善を自分のアプリでも活用できます。

00:00:43.000 --> 00:00:55.000
このセッションでは、モーションデータと対話できる新しい方法のいくつかに焦点を当てますが、新しいものにたどり着く前に、モーションデータを生成するセンサーを簡単に思い出させたいと思います。

00:00:55.000 --> 00:00:59.000
デバイスの移動方法をキャプチャすることは、私たちがそれらをどのように体験するかの中心です。

00:00:59.000 --> 00:01:06.000
Appleのデバイスの多くは、内蔵センサーを使用して、空間を移動する概念を作成しています。

00:01:06.000 --> 00:01:08.000
例えば、Apple Watchを考えてみましょう。

00:01:08.000 --> 00:01:23.000
内蔵センサーには、加速度を測定する加速度計、回転を測定するジャイロスコープ、磁場を測定する磁力計、圧力を測定する気圧計などがあります。

00:01:23.000 --> 00:01:28.000
一緒に、彼らはデバイスがどのように移動し、宇宙で方向づけるかを追跡するのに役立ちます。

00:01:28.000 --> 00:01:34.000
デバイスの動きのアイデアを生み出すことは、私たちが楽しむ多くの機能の基本です。

00:01:34.000 --> 00:01:40.000
これには、その日に取った歩数や、トレーニング中に消費したカロリーを追跡するなどが含まれます。

00:01:40.000 --> 00:01:48.000
それは、私たちの空の星を探索するための星空観察アプリのように、デバイスの向きに依存する経験をサポートします。

00:01:48.000 --> 00:01:57.000
自動車事故に遭ったときや転んだときに検出して私たちを安全に保つ機能も、同じセンサーを使用して動きを追跡することに依存しています。

00:01:57.000 --> 00:02:04.000
これらは可能な多くのアプリケーションのほんの一部です。CoreMotionをどのように活用するかを常に楽しみにしています。

00:02:04.000 --> 00:02:19.000
関連するいくつかのセンサーの概要を説明したので、AirPodsなどのオーディオ製品からモーションデータを取得し、水没データを更新し、最後に、より高いレートのセンサーデータをストリーミングする新しい方法について説明します。

00:02:19.000 --> 00:02:22.000
ヘッドフォンの動きから始めましょう。

00:02:22.000 --> 00:02:30.000
少し前に、ダイナミックヘッドトラッキングを備えた空間オーディオは、音楽や映画の体験方法を変えました。

00:02:30.000 --> 00:02:37.000
ダイナミックヘッドトラッキングは、iPhoneとApple Watchに存在するのと同じデバイスモーションアルゴリズムに依存しています。

00:02:37.000 --> 00:02:47.000
数年前にCMHeadphoneMotionManagerが導入されたとき、動的ヘッドトラッキングを可能にしたのと同じデータが利用可能になりました。

00:02:47.000 --> 00:02:57.000
姿勢、ユーザーの加速、回転速度データを接続されたiOSまたはiPadOSデバイスにストリーミングすることで、頭の動きを追跡できます。

00:02:57.000 --> 00:03:02.000
ヘッドトラッキングは、ゲームからフィットネスアプリケーションまで、多くのクールな機能のロックを解除しました。

00:03:02.000 --> 00:03:08.000
そして今、今年、CMHeadphoneMotionManagerがmacOSに登場します。

00:03:08.000 --> 00:03:10.000
いくつかの詳細を見てみましょう。 では。

00:03:10.000 --> 00:03:17.000
CMHeadphoneMotionManagerは、iOSとiPadOS 14で初めて利用可能になりました。

00:03:17.000 --> 00:03:21.000
そして今年から、macOS 14にも登場します。

00:03:21.000 --> 00:03:35.000
CMHeadphoneMotionManagerを使用して、AirPods Proなどの動的ヘッドトラッキングを備えた空間オーディオをサポートするオーディオ製品から、接続されたiOS、iPadOS、またはmacOSデバイスにデバイスの動きをストリーミングできます。

00:03:35.000 --> 00:03:47.000
iPhoneやApple Watchと同じように、サポートされているデバイスからのストリーミング中にCMDeviceMotionの姿勢、ユーザー加速度、回転速度データを調べます。

00:03:47.000 --> 00:03:59.000
SensorLocationなど、CMHeadphoneMotionManagerに固有の追加情報に注意してください。これは、左からであろうと右の芽からであろうと、データのソースがどこにあるかを曖昧にするのに役立ちます。

00:03:59.000 --> 00:04:05.000
データはリモートデバイスからストリーミングされるため、いつ接続されているかを理解することが重要です。

00:04:05.000 --> 00:04:11.000
CMHeadphoneMotionManagerDelegateを使用すると、接続状態の更新を簡単に聞くことができます。

00:04:11.000 --> 00:04:14.000
使い方をお見せしましょう。

00:04:14.000 --> 00:04:20.000
接続状態の更新に対応するために、CMHeadphoneMotionManagerDelegateプロトコルを採用してください。

00:04:20.000 --> 00:04:27.000
データは、オーディオデバイスがiPhone、iPad、Macなどのサポートされているストリーミングデバイスに接続されている場合に利用できます。

00:04:27.000 --> 00:04:33.000
自動耳検出が有効になっていると、ヘッドトラッキングに影響を与えるイベントも受信されます。

00:04:33.000 --> 00:04:39.000
イヤホンが耳から取り出されると切断イベントが発生し、元に戻されると接続イベントが行われます。

00:04:39.000 --> 00:04:48.000
同様に、自動ヘッド検出が有効になっている場合、イヤーヘッドフォンの着脱はこれらのイベントをトリガーします。

00:04:48.000 --> 00:04:55.000
これらのイベントをリッスンし、データをストリーミングするためにCMHeadphoneMotionManagerを設定するのは簡単です。やり方をお見せしましょう。

00:04:55.000 --> 00:05:05.000
ストリーミングを開始する前に、デバイスのモーションデータが利用可能であることを確認する必要があります。これは、isDeviceMotionAvailableプロパティを使用して確認できます。

00:05:05.000 --> 00:05:09.000
先ほど話した接続イベントを受け取るために代理人を割り当てます。

00:05:09.000 --> 00:05:11.000
次に、データのストリーミングを開始します。

00:05:11.000 --> 00:05:16.000
CMHeadphoneMotionManagerは、プッシュインターフェイスとプルインターフェイスの両方を公開してデータを取得します。

00:05:16.000 --> 00:05:19.000
この例では、プッシュインターフェイスを使用します。

00:05:19.000 --> 00:05:24.000
startDeviceMotionUpdatesを使用し、操作キューとハンドラを指定します。

00:05:24.000 --> 00:05:29.000
モーションデータにアクセスしているので、承認は重要です。

00:05:29.000 --> 00:05:38.000
アプリのユーザーは、Info.plistに追加したMotion Usage Descriptionキーを使用して、モーションデータに対してアプリを承認するように求められます。

00:05:38.000 --> 00:05:47.000
authorizationStatusプロパティをチェックして、モーションデータの許可が許可されているかどうかを確認し、許可レベルに関係なくシームレスなエクスペリエンスを提供できます。

00:05:47.000 --> 00:05:56.000
承認され、データのストリーミングが開始されると、各デバイスのモーションアップデートで提供される姿勢情報を使用して、ヘッドポーズを簡単に追跡できます。

00:05:56.000 --> 00:06:08.000
たとえば、startingPoseとして参照態度を追跡し、乗算方法を使用して、現在のサンプルの元のポーズに対する相対的な変化を便利に取得できます。

00:06:08.000 --> 00:06:18.000
姿勢、ユーザーの加速度、回転速度データに加えて、各デバイスのモーションアップデートにはセンサーの位置情報が含まれています。

00:06:18.000 --> 00:06:24.000
モーションデータは一度に1つの芽から配信されるため、これは重要です。

00:06:24.000 --> 00:06:31.000
各サンプルで配信されるSensorLocation列挙型を使用すると、どの芽がデータを調達しているかを特定できます。

00:06:31.000 --> 00:06:39.000
データをストリーミングする芽は、自動耳検出が有効になっている場合、インイヤー状態など、多くの影響を受ける可能性があります。

00:06:39.000 --> 00:06:49.000
たとえば、データが右のイヤホンからストリーミングされていたが、自動耳検出を有効にして耳から取り出すと、左のイヤホンがデータストリームを引き継ぎます。

00:06:49.000 --> 00:06:53.000
これにより、よりシームレスなヘッドトラッキング体験が可能になります。

00:06:53.000 --> 00:06:57.000
便利なヘッドトラッキングは、多くの異なる経験への扉を開きました。

00:06:57.000 --> 00:07:03.000
腕立て伏せの数を数えたり、姿勢を監視したりすることがこれまで以上に簡単になりました。

00:07:03.000 --> 00:07:12.000
そして今、macOSのサポートにより、ヘッドトラッキング対応のオーディオ製品からさらに幅広いデバイスにモーションデータをストリーミングできるようになりました。

00:07:12.000 --> 00:07:17.000
私たちは、あなたがCMHeadphoneMotionManagerを使用して構築するものを見て興奮しています。

00:07:17.000 --> 00:07:22.000
さて、あなたの頭がどのように動くかを追跡するために圧力を測定する必要はありませんが、他の何かがそうします。

00:07:22.000 --> 00:07:31.000
CMWaterSubmersionManagerのクールなアップデートを使用して、水ベースのアクティビティと対話する方法について説明します。

00:07:31.000 --> 00:07:40.000
シュノーケリングや水泳などの水ベースの活動では、水と水没状態について興味深いことがたくさんあります。

00:07:40.000 --> 00:07:45.000
あなたはおそらく、あなたがどれくらい深く、水温が何であるかに興味があるでしょう。

00:07:45.000 --> 00:07:54.000
また、水没した時期や、水から海岸やボートに戻ったかどうか、活動中の表面空気圧が何であるかを知ることも便利です。

00:07:54.000 --> 00:08:02.000
内蔵のバロメーターを使用して、CMWaterSubmersionManagerは、水ベースの活動中にこれらの指標を追跡できます。

00:08:02.000 --> 00:08:04.000
いくつか詳細をお伝えします。

00:08:04.000 --> 00:08:10.000
CMWaterSubmersionManagerは、watchOS 9を実行しているApple Watch Ultraで利用できます。

00:08:10.000 --> 00:08:18.000
CMWaterSubmersionManagerDelegateを使用して、深さ、温度、水没状態のデータを聞きます。

00:08:18.000 --> 00:08:29.000
アプリにShallow Depth and Pressure機能を追加し、アプリのユーザーが自動起動設定を構成して水ベースのアクティビティを開始するときにシームレスな体験を得るようにしてください。

00:08:29.000 --> 00:08:34.000
CMWaterSubmersionManagerを使い始める方法をお見せしましょう。

00:08:34.000 --> 00:08:42.000
水没状態の追跡を開始するには、空き状況を確認した後、CMWaterSubmersionManagerを設定します。

00:08:42.000 --> 00:08:47.000
次に、浸水状態とイベントに関する更新の受信を開始するデリゲートを割り当てます。

00:08:47.000 --> 00:08:50.000
これらのアップデートを受け取る方法について少し話しましょう。

00:08:50.000 --> 00:08:55.000
CMWaterSubmersionManagerDelegateを使用して更新を取得するのは簡単です。

00:08:55.000 --> 00:08:59.000
受信できるアップデートにはさまざまな種類があります。

00:08:59.000 --> 00:09:08.000
水に出入りするときなど、水没状態の更新は、CMWaterSubmersionEventのdidUpdateメソッドを使用して配信されます。

00:09:08.000 --> 00:09:19.000
アプリのエンタイトルメントが欠落しているとき、またはサポートされていないプラットフォーム上にあるときに更新を受信しようとした場合など、問題がある場合は、errorOccurredアップデートを受け取ります。

00:09:19.000 --> 00:09:23.000
水温の更新は、CMWaterTemperatureを使用して配信されます。

00:09:23.000 --> 00:09:30.000
時計の温度が水と等しくなるのに数秒かかるため、不確実性の概念があります。

00:09:30.000 --> 00:09:38.000
だから、最初に水没すると、不確実性が高くなり、水の中でより多くの時間を過ごすと収束し始めます。

00:09:38.000 --> 00:09:42.000
水温は水没時にのみ利用可能であることに注意してください。

00:09:42.000 --> 00:09:50.000
CMWaterSubmersionMeasurementを使用すると、深さ、圧力、表面圧力、および水没状態の更新を受け取ります。

00:09:50.000 --> 00:09:56.000
水没したアクティビティの間、測定値は定期的にアプリに配信されます。

00:09:56.000 --> 00:10:03.000
深度など、このデータの一部は、水没状態にある場合にのみ適用されるため、これらはオプションであることに注意してください。

00:10:03.000 --> 00:10:07.000
水中の深さは、特定の深さの状態に対応します。

00:10:07.000 --> 00:10:10.000
それらがどのようにマッピングされているかをお見せしましょう。

00:10:10.000 --> 00:10:14.000
あなたが水没していない状態にあるとき、水から出た状態から始めましょう。

00:10:14.000 --> 00:10:18.000
水中1メートル以上で、あなたは水没した浅い状態です。

00:10:18.000 --> 00:10:21.000
1メートルを超えると、あなたは水没した深い状態です。

00:10:21.000 --> 00:10:31.000
浅い深さと圧力機能により、アプリのユーザーが減圧病のリスクを最小限に抑える深さゾーン内にとどまるようにするのは簡単です。

00:10:31.000 --> 00:10:36.000
最大深さを6メートルに保ち、その深さに近づいたときに知らせます。

00:10:36.000 --> 00:10:41.000
最大深度プロパティを使用して、監視されている深度を確認できます。

00:10:41.000 --> 00:10:45.000
6メートルに近づくと、接近するMaxDepth状態に入ります。

00:10:45.000 --> 00:10:49.000
6メートルを超えると、あなたは過去のMaxDepth状態です。

00:10:49.000 --> 00:10:55.000
データは6メートルまで販売され、過去のMaxDepth状態にある不確実性があります。

00:10:55.000 --> 00:10:58.000
それを超えて、あなたはsensorDepthError状態です。

00:10:58.000 --> 00:11:08.000
CMWaterSubmersionManagerは、深さをゾーンに分割することで、安全性とセンサーの制限に重点を置いて、深さの変化を簡単に監視できます。

00:11:08.000 --> 00:11:17.000
最大6メートルの深さを超えるユースケースに興味がある場合は、管理対象資格の詳細については、ドキュメントをご覧ください。

00:11:17.000 --> 00:11:24.000
どちらの方法を選択しても、CMWaterSubmersionManagerを使用すると、ウォータースポーツの素晴らしい体験がこれまで以上に簡単になります。

00:11:24.000 --> 00:11:35.000
しかし、水から出るスポーツもたくさんあり、CMBatchedSensorManagerを使用して、これらの活動中に高レートモーションデータを消費する方法を共有することに興奮しています。

00:11:35.000 --> 00:11:37.000
まず、いくつかの背景から始めましょう。

00:11:37.000 --> 00:11:41.000
モーションデータがあなたに配信される方法について話しました。

00:11:41.000 --> 00:11:52.000
デバイスモーションアルゴリズムは、内蔵の加速度計とジャイロスコープからのデータを融合させ、Apple Watchのようなデバイスが宇宙を移動する方法を簡単に追跡する方法を提供します。

00:11:52.000 --> 00:12:00.000
これらのサンプルをサンプルごとにリアルタイムでアプリに配信するCMMotionManagerに精通しているかもしれません。

00:12:00.000 --> 00:12:03.000
サポートされている最大周波数は100Hzです。

00:12:03.000 --> 00:12:13.000
これは、デバイスの瞬間的な姿勢に依存するUIコンポーネントなど、低レイテンシの要件がある場合に素晴らしい選択であることを意味します。

00:12:13.000 --> 00:12:21.000
さて、これは新しいCMBatchedSensorManagerを使用して高レートデータを配信する方法とどのように比較されますか?

00:12:21.000 --> 00:12:28.000
CMBatchedSensorManagerは、固定スケジュールでセンサーデータのバッチを提供し、1秒あたりのデータのバッチを提供します。

00:12:28.000 --> 00:12:33.000
これは、より低いオーバーヘッドでより高いレートのデータをあなたのアプリに提供できることを意味します。

00:12:33.000 --> 00:12:41.000
既存のCMMotionManagerの100Hzと比較して、800Hzの加速度計と200Hzのデバイスの動きです。

00:12:41.000 --> 00:12:50.000
これで、転倒や衝突検出など、私たちを安全に保つ機能を強化するのと同じデータストリームにアクセスできます。

00:12:50.000 --> 00:12:56.000
データはバッチ処理されるため、CMBatchedSensorManagerの使用を検討する際に考慮すべきことがいくつかあります。

00:12:56.000 --> 00:13:07.000
あなたのアプリがハイレートデータの恩恵を受けることができるワークアウト中心の機能を持っているが、非常に厳しいレイテンシ要件がない場合、CMBatchedSensorManagerは適しています。

00:13:07.000 --> 00:13:15.000
私は、より高いレートのセンサーデータがどのようにあなたに配信されるか、そしてそれが既存のインターフェイスのいくつかによって提供されるものとどのように比較されるかを調べました。

00:13:15.000 --> 00:13:18.000
使い方をいくつかお見せしましょう。

00:13:18.000 --> 00:13:23.000
多くのスポーツは、短期間のインパクトベースのイベントを中心としています。

00:13:23.000 --> 00:13:30.000
これには、いくつかの例を挙げると、ゴルフ、テニス、野球などの活動が含まれます。

00:13:30.000 --> 00:13:38.000
これらでは、そのスイングの動き中により多くの情報をキャプチャすることは、フォームの評価とゲームの改善に不可欠である可能性があります。

00:13:38.000 --> 00:13:43.000
これは、より高いレートのセンサーデータのキャプチャが機能する場所です。

00:13:43.000 --> 00:13:46.000
これを具体的な例に固定することで利益を得ることができます。

00:13:46.000 --> 00:13:48.000
野球のスイングに集中しましょう。

00:13:48.000 --> 00:13:51.000
スイングにはいくつかの異なる段階があります。

00:13:51.000 --> 00:13:58.000
この図では、スイング前のセットアップ、実際のスイング、そして衝撃後のフォロースルーを見ることができます。

00:13:58.000 --> 00:14:02.000
スイング品質の重要な指標は、接触する時間です。

00:14:02.000 --> 00:14:09.000
言い換えれば、バッターがバットのスイングを開始するときと、バットがボールを打つ時間の間にどれくらいの時間が経過するか。

00:14:09.000 --> 00:14:13.000
高速センサーデータを使用して、これを3つのステップに分けることができます。

00:14:13.000 --> 00:14:19.000
バッターの手首には、x、y、zの向きのApple Watchが見えます。

00:14:19.000 --> 00:14:26.000
重力ベクトルが下を向いて、青でバッターの周りを移動する手首の経路を想像することができます。

00:14:26.000 --> 00:14:34.000
接触時間を計算するには、まず800Hzの加速度計を使用してバットとボールの間の衝撃点を検出します。

00:14:34.000 --> 00:14:41.000
次に、200 Hzのデバイスの動きで重力に沿った回転を使用して、スイングの開始を特定します。

00:14:41.000 --> 00:14:49.000
最後に、スイングの開始からインパクトまで、接触時間と呼ばれるこれらのタイムスタンプの差を計算できます。

00:14:49.000 --> 00:14:54.000
私たちが探しているものを理解するために、スイング中にセンサーデータを視覚化することから始めましょう。

00:14:54.000 --> 00:15:01.000
ここでは、1つのスイングを含む1秒のウィンドウのz方向に加速度計データをプロットしました。

00:15:01.000 --> 00:15:07.000
0.5秒から0.6秒の間に活動のバーストがあることがわかります。

00:15:07.000 --> 00:15:13.000
衝撃点を検出するアルゴリズムは、この観察を中心にします。

00:15:13.000 --> 00:15:23.000
スイング中に利用可能な信号情報の量を、上部に800Hzの加速度計、下部に100Hzの加速度計を比較してみましょう。

00:15:23.000 --> 00:15:33.000
その興味のあるセクションでは、0.5秒から0.6秒の間に、10ではなく80のデータポイントがあり、何が起こっているのかをはるかに細かく把握できます。

00:15:33.000 --> 00:15:38.000
これは、インパクトなど、私たちが興味を持っていることに焦点を合わせるのに役立ちます。

00:15:38.000 --> 00:15:43.000
さて、デバイスの動きの観点から同じスイングを見てみましょう。

00:15:43.000 --> 00:15:47.000
これは、200Hzの重力に沿った回転速度をプロットします。

00:15:47.000 --> 00:15:53.000
回転速度が0.3秒前後で変化し始める方法によって、スイングスタートを見ることができます。

00:15:53.000 --> 00:15:56.000
これらをまとめましょう。

00:15:56.000 --> 00:16:07.000
これらのプロットを時間ごとに整列させると、800Hzの加速度計と200Hzのデバイスの動きの情報が、接触時間を計算するのにどのように役立つかを感じることができます。

00:16:07.000 --> 00:16:17.000
センサーストリームにスイングがどのように表示されるかがわかったので、CMBatchedSensorManagerを使用してデータのストリーミングと処理を開始できます。

00:16:17.000 --> 00:16:20.000
まず、このプラットフォームでデータが利用可能であることを確認したい。

00:16:20.000 --> 00:16:24.000
isAccelerometerSupportedをチェックすることで、そうすることができます。

00:16:24.000 --> 00:16:28.000
同様のプロパティを使用して、デバイスのモーションサポートを確認できます。

00:16:28.000 --> 00:16:35.000
Apple Watch Series 8とUltraは、高速加速度計とデバイスの動きの両方をサポートしています。

00:16:35.000 --> 00:16:41.000
これはワークアウト中心のAPIであるため、データを取得するにはアクティブなHealthKitワークアウトセッションが必要です。

00:16:41.000 --> 00:16:45.000
HealthKitワークアウトセッションに入ったら、最新情報の受信を開始できます。

00:16:45.000 --> 00:16:51.000
Swiftの非同期サポートにより、センサーデータのバッチを簡単に受信し、各バッチを処理できます。

00:16:51.000 --> 00:16:58.000
ループを終了する条件を必ず評価してください。たとえば、ワークアウトが終了した場合などです。

00:16:58.000 --> 00:17:04.000
モーションデータまたはサポートされていないプラットフォームで許可されていない場合、エラーが表面化されることを忘れないでください。

00:17:04.000 --> 00:17:08.000
では、データのバッチごとに何をしたいのかをズームしてみましょう。

00:17:08.000 --> 00:17:14.000
バッチごとに、フィード関数を呼び出して、データに対してアルゴリズムを実行します。

00:17:14.000 --> 00:17:19.000
バットがボールと接触すると、z方向に顕著な反応が見られることが期待されます。

00:17:19.000 --> 00:17:24.000
Z軸は時計の王冠に垂直であることを覚えておいてください。

00:17:24.000 --> 00:17:28.000
この残響は、衝撃の良い近似値です。

00:17:28.000 --> 00:17:32.000
これを念頭に置いて各加速度計バッチを処理します。

00:17:32.000 --> 00:17:38.000
まず、接触時に力が移動するので、より高い周波数の応答をよりよく分離したい。

00:17:38.000 --> 00:17:43.000
これを行うには、zサンプルをfzとしてフィルタリングします。

00:17:43.000 --> 00:17:49.000
フィルタリングされたデータを使用して、フィルタリングされた信号のピークとして衝撃点を近似します。

00:17:49.000 --> 00:17:54.000
そのサンプルに関連付けられているインデックスをインパクトインデックスとして追跡しましょう。

00:17:54.000 --> 00:18:01.000
フィルタリングされた信号から引き出された impactIndexを使用して、元のデータのバッチから衝撃タイムスタンプを取得できます。

00:18:01.000 --> 00:18:11.000
これにより、接触時間を計算する方法の2番目のステップに進みます。重力に沿った回転を使用してスイングの開始を検出します。

00:18:11.000 --> 00:18:18.000
バッターがスイングするApple Watchの道を想像してみてください。ボールに会うために体の周りの道をたどります。

00:18:18.000 --> 00:18:27.000
したがって、スイング中に重力に沿って非ゼロ回転率、スイング外の重力に沿ってゼロに近い回転率を見ることを期待しています。

00:18:27.000 --> 00:18:35.000
高周波デバイスの動きをローカルバッファにストリーミングすることで、回転速度データを使用してスイングが始まった場所を特定できます。

00:18:35.000 --> 00:18:39.000
私の計算関数がどのように見えるかを詳しく見てみましょう。

00:18:39.000 --> 00:18:46.000
ローカルバッファを後方に反復して、興味のあるポイントであるインパクトタイムスタンプを調査します。

00:18:46.000 --> 00:18:54.000
スイングの開始がインパクトに先行しなければならないことを知っているので、バッファ内の各サンプルを処理する前に、一連のshouldProcessチェックを実行できます。

00:18:54.000 --> 00:19:01.000
これには、デバイスのモーションサンプルが衝撃時間前のものであることを確認するためのタイムスタンプチェックを含めることができます。

00:19:01.000 --> 00:19:04.000
スイング期間に境界を置くこともできます。

00:19:04.000 --> 00:19:11.000
スイングの開始がボールと接触する前に一定期間以上発生しないことは理にかなっています。

00:19:11.000 --> 00:19:23.000
一連の初期チェックに合格したサンプルについては、各軸の回転率と重力値の積を合計するcomputeRotation関数で重力に沿った回転を計算します。

00:19:23.000 --> 00:19:28.000
重力に沿った回転を計算すると、スイングの始まりを探し始めることができます。

00:19:28.000 --> 00:19:35.000
単純なスイングスタートチェックは、しきい値を満たすために重力に沿った回転率の一貫した失敗を探すかもしれません。

00:19:35.000 --> 00:19:43.000
重力に沿った回転率がそのしきい値を満たすのを見なくなったら、それをスイングの開始時間とループの出口として使用します。

00:19:43.000 --> 00:19:47.000
最終チェックとして、検出したスイングを検証します。

00:19:47.000 --> 00:19:55.000
ここでは、スイング中に重力に沿って蓄積された回転を見て、それが予想されるしきい値内にあることを確認することができます。

00:19:55.000 --> 00:19:59.000
そして、それで、検出した開始タイムスタンプを返すことができます。

00:19:59.000 --> 00:20:05.000
これにより、最後のステップであるステップ3に進み、連絡する時間を計算するために必要なものがすべて揃っています。

00:20:05.000 --> 00:20:08.000
最初のフィード機能に戻りましょう。

00:20:08.000 --> 00:20:14.000
CMBatchedSensorManagerを使用して、加速度計とデバイスのモーションデータをストリーミングし始めました。

00:20:14.000 --> 00:20:20.000
z方向にフィルタリングされた加速度計データを使用して、impactTimeを検出しました。

00:20:20.000 --> 00:20:27.000
次に、重力に沿った回転率を調べることで、その衝撃タイムスタンプの近くでスイングの開始を特定しました。

00:20:27.000 --> 00:20:32.000
2つのタイムスタンプの差を取って、連絡する時間を計算します。

00:20:32.000 --> 00:20:37.000
これは、センサーデータに基づいて機能を開発する方法の簡単な例でした。

00:20:37.000 --> 00:20:43.000
高周波データストリームの余分な信号情報は、他の多くの調査への扉も開きます。

00:20:43.000 --> 00:20:45.000
見てみましょう。 

00:20:45.000 --> 00:20:52.000
私たちは以前、z方向の800 Hzの加速度計ストリームでこの加速度計データのトレースを見ました。

00:20:52.000 --> 00:20:55.000
さて、2番目のプロットを見てみましょう。

00:20:55.000 --> 00:20:58.000
かなり似ていますが、まったく同じではありません。

00:20:58.000 --> 00:21:04.000
これは、バットが実際にボールと接触しなかった逃したスイングからの痕跡です。

00:21:04.000 --> 00:21:13.000
スイングモーション自体は両方に似ていますが、高レートのデータストリームがこのような違いについてどのように余分な洞察を与えるかがわかります。

00:21:13.000 --> 00:21:19.000
あなたが開発するアルゴリズムは、これらの違いを活用して、以前は不可能だったことを検出することができます。

00:21:19.000 --> 00:21:25.000
要約すると、同じデバイスモーションアルゴリズムは、いくつかの異なる方法であなたにデータを提供します。

00:21:25.000 --> 00:21:32.000
CMMotionManagerは、サンプルごとに最大100Hzでデータを販売します。

00:21:32.000 --> 00:21:42.000
これは、サブセカンドスケールで低レイテンシ要件がある場合、またはワークアウト以外のモーションベースの機能がある場合に最適です。

00:21:42.000 --> 00:21:55.000
新しいCMBatchedSensorManagerは、バッチスケジュールで200 Hzのデバイスモーションと800 Hzの加速度計のキャップで、より高いレートでデータを配信し、1秒あたりのデータのバッチを提供します。

00:21:55.000 --> 00:22:00.000
これにより、高レートのデータの恩恵を受けることができるワークアウト中心の機能に役立ちます。

00:22:00.000 --> 00:22:03.000
Apple Watch Series 8とUltraで利用できます。

00:22:03.000 --> 00:22:19.000
私はCMBatchedSensorManagerを使用するために野球のスイングに焦点を当てましたが、これらのより高いレートのデータストリームは、特に短期間やインパクトベースの活動中に、すべてのトレーニングでApple Watchの動きに関する貴重な洞察を提供することができます。

00:22:19.000 --> 00:22:25.000
それはCMBatchedSensorManagerであり、これでCoreMotionの新機能のレビューは終了です。

00:22:25.000 --> 00:22:30.000
ヘッドフォンでもApple Watchでも、モーションとやり取りする素晴らしい方法があります。

00:22:30.000 --> 00:22:35.000
モーションデータを使用するクールな方法はたくさんありますが、いくつかの例を取り上げました。

00:22:35.000 --> 00:22:40.000
それらを試してみて、詳細についてはドキュメントを確認することをお勧めします。

00:22:40.000 --> 00:22:42.000
フィードバックも必ず提供してください。

00:22:42.000 --> 00:22:53.000
モビリティの測定など、モーションデータが健康ベースの機能にどのように変換されるかの例については、WWDC 2020の「Beyond Counting Steps」セッションをチェックしてください。

00:22:53.000 --> 00:23:02.000
CMBatchedSensorManagerを活用するためのランニングワークアウトの詳細については、「WorkoutKitでカスタムワークアウトを構築する」をご覧ください。

00:23:02.000 --> 00:23:07.000
モーションデータを使用して素晴らしい新しい体験を生み出す方法を見て、とても興奮しています。

00:23:07.000 --> 23:59:59.000
ご覧いただきありがとうございます。

