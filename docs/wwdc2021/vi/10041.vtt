WEBVTT

00:00:02.000 --> 00:00:12.000
Xin chào, và chào mừng đến với WWDC.

00:00:12.000 --> 00:00:16.000
Tên tôi là Frank Doepke, và tôi là một Kỹ sư trong nhóm Tầm nhìn.

00:00:16.000 --> 00:00:20.000
Khung Tầm nhìn đã phát triển qua nhiều năm, tập trung vào phân tích hình ảnh.

00:00:20.000 --> 00:00:26.000
Để nắm bắt tốt hơn, chúng ta có thể xem xét các khả năng của Vision về trọng tâm sử dụng của nó.

00:00:26.000 --> 00:00:27.000
Thể thao.

00:00:27.000 --> 00:00:36.000
Theo dõi các đối tượng và phân tích tư thế của con người chỉ là một số yêu cầu có thể giúp bạn tạo một ứng dụng thể thao.

00:00:36.000 --> 00:00:38.000
Khả năng tiếp cận.

00:00:38.000 --> 00:00:46.000
Yêu cầu tầm nhìn như OCR hoặc phân loại hình ảnh và phát hiện đối tượng đang giúp người dùng khiếm thị.

00:00:46.000 --> 00:00:47.000
Con người.

00:00:47.000 --> 00:00:52.000
Vision cung cấp một số yêu cầu liên quan đến khuôn mặt và cơ thể mà ứng dụng của bạn có thể sử dụng.

00:00:52.000 --> 00:01:00.000
Bạn có thể tìm hiểu thêm về điều này trong phiên "Khử kiến mọi người, khuôn mặt và tư thế bằng Vision".

00:01:00.000 --> 00:01:01.000
Sức khỏe.

00:01:01.000 --> 00:01:11.000
Từ quét mã vạch và OCR đến phân tích tư thế của con người, Vision cung cấp các khối xây dựng để tạo ra một ứng dụng Sức khỏe thông minh.

00:01:11.000 --> 00:01:13.000
Nhiếp ảnh tính toán.

00:01:13.000 --> 00:01:19.000
Các tính năng như chế độ chân dung dựa vào nhận diện khuôn mặt và phân đoạn.

00:01:19.000 --> 00:01:21.000
An ninh.

00:01:21.000 --> 00:01:29.000
Các yêu cầu như phát hiện khuôn mặt và con người rất hữu ích cho các ứng dụng như phát hiện chuyển động trong camera an ninh.

00:01:29.000 --> 00:01:31.000
Và các tài liệu.

00:01:31.000 --> 00:01:36.000
Đây là những gì chúng tôi muốn tập trung vào trong phiên này.

00:01:36.000 --> 00:01:55.000
Vision cung cấp một số yêu cầu giúp bạn phân tích tài liệu: phát hiện mã vạch, nhận dạng văn bản hoặc thường được gọi là OCR, phát hiện đường viền, phát hiện hình chữ nhật và mới cho năm nay, phát hiện phân đoạn tài liệu.

00:01:55.000 --> 00:01:56.000
Đây là chương trình nghị sự của chúng tôi.

00:01:56.000 --> 00:01:59.000
Đầu tiên, chúng ta sẽ nói về phát hiện mã vạch.

00:01:59.000 --> 00:02:01.000
Sau đó, chúng ta sẽ nói về nhận dạng văn bản.

00:02:01.000 --> 00:02:04.000
Và cuối cùng, chúng ta sẽ nói về việc phát hiện tài liệu.

00:02:04.000 --> 00:02:07.000
Hãy xem xét phát hiện mã vạch.

00:02:07.000 --> 00:02:12.000
Năm nay, chúng tôi đang giới thiệu một bản sửa đổi mới của yêu cầu phát hiện mã vạch.

00:02:12.000 --> 00:02:18.000
VNDetectBarcodesRequestRevision2 cung cấp hỗ trợ cho các ký hiệu mới.

00:02:18.000 --> 00:02:40.000
Codabar, GS1Databar, bao gồm Expanded and Limited, MicroPDF và MicroQR, trong đó cái sau đặc biệt hữu ích nếu bạn muốn tạo mã QR cho URL và cần đặt nó trên một nhãn hoặc gói nhỏ, vì nó sử dụng ít dung lượng hơn rất nhiều.

00:02:40.000 --> 00:02:55.000
Chúng tôi đã thay đổi hành vi cho bản sửa đổi mới này để phù hợp với phần còn lại của Tầm nhìn liên quan đến cách các hộp giới hạn kết quả được báo cáo liên quan đến khu vực quan tâm mà khách hàng đã chỉ định.

00:02:55.000 --> 00:02:58.000
Hãy xem xét sự thay đổi đó một cách chi tiết.

00:02:58.000 --> 00:03:01.000
Ở đây, chúng tôi có một tài liệu với mã QR.

00:03:01.000 --> 00:03:10.000
Khi chúng tôi không chỉ định Khu vực quan tâm, còn được gọi là ROI, hộp giới hạn sẽ được báo cáo liên quan đến hình ảnh đầy đủ.

00:03:10.000 --> 00:03:17.000
Bây giờ, hãy chỉ định ROI, giống như chúng ta chỉ muốn tập trung vào phần trung tâm của những gì máy ảnh nhìn thấy.

00:03:17.000 --> 00:03:25.000
Bản sửa đổi 2 hiện báo cáo hộp giới hạn liên quan đến ROI, giống như các yêu cầu Vision khác.

00:03:25.000 --> 00:03:29.000
Thật không may, Bản sửa đổi 1 luôn báo cáo liên quan đến hình ảnh đầy đủ.

00:03:29.000 --> 00:03:34.000
Nhưng chúng tôi không muốn thay đổi hành vi đó, vì nó có khả năng phá vỡ các khách hàng hiện tại.

00:03:34.000 --> 00:03:45.000
Và như một lời nhắc nhở, khi bạn biên dịch ứng dụng của mình dựa trên SDK mới nhất và không chỉ định bản sửa đổi cụ thể, bạn sẽ luôn nhận được bản sửa đổi mới nhất theo yêu cầu của mình.

00:03:45.000 --> 00:03:57.000
Nhưng đối với các ứng dụng chỉ định Bản sửa đổi 1 hoặc không biên dịch lại với SDK mới, chúng vẫn sẽ nhận được hành vi Bản sửa đổi 1 cũ.

00:03:57.000 --> 00:04:03.000
Hãy để tôi nhấn mạnh một vài khía cạnh thú vị của yêu cầu phát hiện mã vạch trong Vision.

00:04:03.000 --> 00:04:07.000
Vision hỗ trợ mã vạch 1D và 2D.

00:04:07.000 --> 00:04:16.000
Nhưng điều làm cho nó thực sự thú vị là trong một hình ảnh, nó có thể phát hiện nhiều mã, cũng như nhiều ký hiệu, cùng một lúc.

00:04:16.000 --> 00:04:21.000
Điều đó có nghĩa là bạn không cần phải quét đi quét lại để nhận được nhiều mã.

00:04:21.000 --> 00:04:24.000
Đây là một lợi thế rất lớn so với hầu hết các máy quét cầm tay.

00:04:24.000 --> 00:04:32.000
Hãy nhớ rằng nếu bạn quét nhiều ký hiệu, bạn đã chỉ định càng nhiều ký hiệu sẽ mất nhiều thời gian hơn.

00:04:32.000 --> 00:04:40.000
Vì vậy, bạn muốn thiết lập yêu cầu chỉ với các ký hiệu có liên quan đến trường hợp sử dụng của bạn.

00:04:40.000 --> 00:04:47.000
Với việc mở rộng các ký hiệu mới để quét mã vạch, Vision có thể đóng một vai trò đặc biệt hữu ích trong lĩnh vực y tế.

00:04:47.000 --> 00:04:57.000
Với iPhone, bạn có thể phân tích nhiều mã cùng một lúc và nhờ kết nối với internet, hãy lấy thông tin mà không cần máy quét riêng.

00:04:57.000 --> 00:05:10.000
Và nhờ khả năng ánh sáng yếu mạnh mẽ của iPhone, bạn có thể quét mã, ngay cả trong các tình huống tối, mà không cần bắn tia laser hoặc làm phiền bệnh nhân khi họ đang nghỉ ngơi.

00:05:10.000 --> 00:05:15.000
Bây giờ, hãy xem Vision thực hiện phát hiện mã vạch như thế nào.

00:05:15.000 --> 00:05:18.000
Mã 1D sẽ được quét dưới dạng dòng.

00:05:18.000 --> 00:05:23.000
Điều đó có nghĩa là bạn có thể sẽ nhận được nhiều phát hiện cho cùng một mã.

00:05:23.000 --> 00:05:33.000
Thật dễ dàng để khử trùng lặp chúng bằng cách nhìn vào tải trọng, đó là dữ liệu thực được bao gồm trong mã vạch.

00:05:33.000 --> 00:05:35.000
Mã 2D được quét dưới dạng một đơn vị duy nhất.

00:05:35.000 --> 00:05:39.000
Điều đó có nghĩa là bạn nhận lại một hộp giới hạn cho toàn bộ mã.

00:05:39.000 --> 00:05:45.000
Một ví dụ cho mã 2D sẽ là mã QR.

00:05:45.000 --> 00:05:49.000
Mỗi mã vạch được báo cáo với sự quan sát riêng của nó.

00:05:49.000 --> 00:05:58.000
Nhưng như tôi đã đề cập trước đây, mã 1D có thể trả về nhiều quan sát, với cùng một nội dung, nhưng ở các vị trí vật lý khác nhau.

00:05:58.000 --> 00:06:05.000
Tải trọng là nội dung của mã vạch, tức là dữ liệu được bao gồm trong mã có thể đọc được bằng máy này.

00:06:05.000 --> 00:06:14.000
Đặc biệt đối với tải trọng của mã QR, bạn có thể muốn sử dụng máy dò dữ liệu để phân tích URL được mã hóa.

00:06:14.000 --> 00:06:17.000
Bây giờ, hãy xem xét điều này trong một bản demo nhỏ.

00:06:17.000 --> 00:06:24.000
Được rồi, ở đây chúng ta có một sân chơi Xcode, nơi bạn thấy rằng tôi có một hình ảnh với tất cả các mã vạch trong đó.

00:06:24.000 --> 00:06:29.000
Tôi sử dụng VNDetectBarcodesRequest, và tôi đặt Bản sửa đổi thành 2.

00:06:29.000 --> 00:06:38.000
Bây giờ, với tư cách là biểu tượng, tôi chỉ có codabar, và khi chúng ta nhìn vào cái này, chúng ta thấy codabar được tô sáng màu đỏ.

00:06:38.000 --> 00:06:46.000
Bây giờ, tôi có thể thay đổi cái này thành, giả sử, QR.

00:06:46.000 --> 00:06:52.000
Điều xảy ra bây giờ là chúng tôi chạy lại yêu cầu và chúng tôi thấy rằng mã QR được tô sáng.

00:06:52.000 --> 00:06:58.000
Nhưng đó là một mảng, vì vậy tôi cũng có thể chỉ định các yêu cầu khác với nó, giả sử ean8.

00:06:58.000 --> 00:07:06.000
Và khi tôi làm điều đó, bây giờ chúng ta sẽ thấy rằng chúng ta có cả hai, ean8 và mã QR.

00:07:06.000 --> 00:07:08.000
Nhưng nếu tôi muốn lấy tất cả chúng thì sao?

00:07:08.000 --> 00:07:13.000
Tôi chỉ đơn giản là vượt qua một mảng trống, và trong khoảnh khắc đó, tất cả các ký hiệu đều được đọc.

00:07:13.000 --> 00:07:18.000
Và như bạn thấy, tất cả được đánh dấu ngay bây giờ với mã ở dưới cùng.

00:07:18.000 --> 00:07:21.000
Hãy quay lại các trang trình bày của chúng ta.

00:07:21.000 --> 00:07:25.000
Từ mã vạch, chúng ta hiện đang chuyển sang xem xét nhận dạng văn bản.

00:07:25.000 --> 00:07:29.000
Vision đã giới thiệu nhận dạng văn bản vào năm 2019.

00:07:29.000 --> 00:07:33.000
Nó hoạt động ở hai chế độ: Nhanh và Chính xác.

00:07:33.000 --> 00:07:37.000
Kể từ đó, Vision đã mở rộng hỗ trợ ngôn ngữ của mình.

00:07:37.000 --> 00:07:42.000
Hãy xem cách nhận dạng văn bản hoạt động và vai trò của ngôn ngữ.

00:07:42.000 --> 00:07:46.000
Trong Fast path, chúng ta có một công cụ nhận dạng ký tự Latinh.

00:07:46.000 --> 00:07:54.000
Mặt khác, đường dẫn chính xác sử dụng bộ nhận dạng dựa trên máy học hoạt động trên các từ và dòng.

00:07:54.000 --> 00:07:59.000
Sau khi nhận dạng xong, mỗi con đường sẽ trải qua giai đoạn chỉnh sửa ngôn ngữ.

00:07:59.000 --> 00:08:02.000
Và, cuối cùng, chúng tôi nhận lại văn bản được nhận dạng.

00:08:02.000 --> 00:08:05.000
Việc lựa chọn ngôn ngữ ảnh hưởng đến giai đoạn nhận dạng.

00:08:05.000 --> 00:08:13.000
Trong Fast path, điều đó có nghĩa là các bộ ký tự Latinh khác nhau được hỗ trợ, giống như umlaut cho tiếng Đức.

00:08:13.000 --> 00:08:23.000
Trong con đường Chính xác, một mô hình hoàn toàn khác được sử dụng khi chúng ta phải nhận ra tiếng Trung, vì cấu trúc của nó rất khác với các ngôn ngữ dựa trên tiếng Latinh.

00:08:23.000 --> 00:08:31.000
Điều đó có nghĩa là nếu bạn cần đọc văn bản tiếng Trung, thì điều quan trọng là tiếng Trung là ngôn ngữ chính trong yêu cầu.

00:08:31.000 --> 00:08:40.000
Việc lựa chọn ngôn ngữ cũng ảnh hưởng đến việc điều chỉnh ngôn ngữ, vì nó chọn từ điển chính xác cho công việc của mình.

00:08:40.000 --> 00:08:44.000
Vậy, các phương pháp hay nhất khi sử dụng ngôn ngữ trong nhận dạng văn bản là gì?

00:08:44.000 --> 00:08:56.000
Mặc dù có vẻ như một bộ ngôn ngữ cố định được hỗ trợ, nhưng tốt hơn hết là bạn nên truy vấn ngôn ngữ nào được hỗ trợ cho một cấu hình yêu cầu nhất định bằng cách sử dụng supportedRecognitionLanguages().

00:08:56.000 --> 00:09:01.000
Bạn có thể chỉ định nhiều ngôn ngữ, và, trong trường hợp đó, thứ tự quan trọng.

00:09:01.000 --> 00:09:06.000
Khi có sự mơ hồ, nó được giải quyết theo thứ tự ngôn ngữ.

00:09:06.000 --> 00:09:13.000
Đặc biệt đối với đường dẫn Chính xác, ngôn ngữ đầu tiên quyết định mô hình nhận dạng nào được sử dụng.

00:09:13.000 --> 00:09:22.000
Điều đó có nghĩa là trường hợp sử dụng của bạn quyết định ngôn ngữ bạn muốn sử dụng trong yêu cầu.

00:09:22.000 --> 00:09:25.000
Hãy xem xét điều này trong một bản demo nhỏ.

00:09:25.000 --> 00:09:35.000
Vì vậy, bây giờ tôi có ở đây một phiên bản sửa đổi của mã mẫu của chúng tôi và bạn có thể thấy rằng tôi có một hình ảnh với các ngôn ngữ văn bản khác nhau trong đó.

00:09:35.000 --> 00:09:39.000
Bây giờ, tôi đã chỉ định Bản sửa đổi 2 và tôi có thể xem ngôn ngữ nào được hỗ trợ.

00:09:39.000 --> 00:09:45.000
Chúng tôi có tiếng Anh, tiếng Pháp, vân vân.

00:09:45.000 --> 00:09:52.000
Bây giờ, nếu tôi chuyển, ví dụ, trở lại Bản sửa đổi 1, chúng ta có thể thấy tôi chỉ có tiếng Anh.

00:09:52.000 --> 00:09:57.000
Và điều đó cũng tương tự đối với Fast cũng như đối với đường dẫn Chính xác.

00:09:57.000 --> 00:10:00.000
Bây giờ, hãy quay lại Bản sửa đổi 2.

00:10:00.000 --> 00:10:10.000
Lưu ý rằng bây giờ khi tôi chuyển sang tiếng Đức, tôi thực sự nhận được umlaut một cách chính xác ở Grüsse aus Cupertino.

00:10:10.000 --> 00:10:15.000
Nhưng tôi không có sự hỗ trợ trong con đường Nhanh cho người Trung Quốc.

00:10:15.000 --> 00:10:22.000
Trên con đường Chính xác, bây giờ tôi có thể chọn tiếng Trung.

00:10:22.000 --> 00:10:27.000
Và bây giờ, cuối cùng chúng ta cũng nhận được các chữ cái tiếng Trung chính xác cho "Hello World".

00:10:27.000 --> 00:10:30.000
Hãy quay lại các trang trình bày.

00:10:30.000 --> 00:10:34.000
Cuối cùng nhưng không kém phần quan trọng, hãy xem xét Phát hiện Tài liệu.

00:10:34.000 --> 00:10:39.000
Vision giới thiệu một yêu cầu mới được gọi là VNDocumentSegmentationRequest.

00:10:39.000 --> 00:10:49.000
Đó là một máy dò dựa trên máy học mà chúng tôi đã đào tạo trên nhiều loại tài liệu khác nhau, như tờ giấy, biển báo, ghi chú, biên lai, nhãn, v.v.

00:10:49.000 --> 00:11:00.000
Kết quả của yêu cầu là mặt nạ phân đoạn có độ phân giải thấp, trong đó mỗi pixel đại diện cho sự tự tin nếu pixel đó có phải là một phần của tài liệu được phát hiện hay không.

00:11:00.000 --> 00:11:07.000
Ngoài ra, nó cung cấp bốn điểm góc của hình tứ giác.

00:11:07.000 --> 00:11:14.000
Trên các thiết bị có Neural Engine, yêu cầu có thể chạy trong thời gian thực trên máy ảnh hoặc nguồn cấp dữ liệu video.

00:11:14.000 --> 00:11:25.000
VNDocumentCamera trong VisionKit hiện đang sử dụng yêu cầu thay vì VNDetectRectanglesRequest trên các thiết bị hiện đại với Neural Engine.

00:11:25.000 --> 00:11:33.000
Nói về VNDetectRectanglesRequest, hai yêu cầu này khác nhau như thế nào, vì cả hai đều có thể được sử dụng để phát hiện một tài liệu?

00:11:33.000 --> 00:11:40.000
DetectDocumentsRequest, như tôi đã đề cập, dựa trên máy học và hoạt động nhanh nhất trên Neural Engine.

00:11:40.000 --> 00:11:48.000
Nhưng nó cũng có thể được sử dụng trên GPU hoặc CPU, nhưng nó không đủ nhanh để có hiệu suất thời gian thực.

00:11:48.000 --> 00:12:01.000
Máy dò hình chữ nhật là một thuật toán thị giác máy tính truyền thống chỉ chạy trên CPU và có thể theo kịp hiệu suất thời gian thực, miễn là CPU không bão hòa với các tác vụ khác.

00:12:01.000 --> 00:12:09.000
Yêu cầu tài liệu được đào tạo trên nhiều loại tài liệu và chúng không nhất thiết phải là tất cả các hình chữ nhật, đó là một trong những điểm mạnh chính của nó.

00:12:09.000 --> 00:12:22.000
Mặt khác, máy dò hình chữ nhật hoạt động bằng cách tìm các cạnh và giao điểm tạo thành hình tứ giác, đây có thể là một thách thức với các góc hoặc nếp gấp bị che khuất trong tài liệu.

00:12:22.000 --> 00:12:31.000
Các yêu cầu tài liệu cung cấp mặt nạ phân đoạn và các điểm góc, trong khi máy dò hình chữ nhật chỉ cung cấp các điểm góc.

00:12:31.000 --> 00:12:35.000
Và máy dò tài liệu được đào tạo để chỉ tìm kiếm một tài liệu.

00:12:35.000 --> 00:12:39.000
Với máy dò hình chữ nhật sẽ trả về nhiều hình chữ nhật.

00:12:39.000 --> 00:12:42.000
Những hình chữ nhật này thậm chí có thể được lồng vào nhau.

00:12:42.000 --> 00:12:46.000
Hãy xem xét điều này nhiều hơn một chút.

00:12:46.000 --> 00:12:55.000
Như tôi đã đề cập, máy dò tài liệu tìm thấy một tài liệu, mà chúng ta thấy ở đây với hình tứ giác của vật thể được phát hiện.

00:12:55.000 --> 00:13:04.000
Nhưng máy dò hình chữ nhật sẽ cung cấp lại nhiều quan sát về tất cả các hình chữ nhật mà nó tìm thấy trong hình ảnh và tôi đã đánh dấu một vài ở đây.

00:13:04.000 --> 00:13:08.000
Tùy thuộc vào ứng dụng để quyết định hình chữ nhật nào là tài liệu.

00:13:08.000 --> 00:13:12.000
Làm thế nào về việc chúng ta thử tất cả những điều này trong một bản demo?

00:13:12.000 --> 00:13:17.000
Được rồi, chúng tôi muốn tạo một cuộc khảo sát nhỏ, chúng tôi đang làm tốt như thế nào tại WWDC.

00:13:17.000 --> 00:13:22.000
Bây giờ, thật không may, bạn không ở bên tôi, vì vậy tôi đã phải yêu cầu nhóm quay phim ở đây điền vào bản khảo sát cho bạn.

00:13:22.000 --> 00:13:27.000
Vì vậy, tôi đã tạo ra một ứng dụng nhỏ mà bây giờ tôi có thể quét thẻ khảo sát của chúng tôi.

00:13:27.000 --> 00:13:28.000
Và chúng ta nhận được gì?

00:13:28.000 --> 00:13:31.000
QuickDraw cho người mới bắt đầu cảm thấy lỗi thời.

00:13:31.000 --> 00:13:36.000
Chà, bây giờ nó hơi cũ rồi.

00:13:36.000 --> 00:13:38.000
Hãy đi cho cái tiếp theo.

00:13:38.000 --> 00:13:45.000
À, Vision rất thú vị và nhiều thông tin.

00:13:45.000 --> 00:13:49.000
Và cuối cùng nhưng không kém phần quan trọng, Cobol, chỉ là những gì tôi cần.

00:13:49.000 --> 00:13:52.000
Ai đó đang ở sai phiên ở đây.

00:13:52.000 --> 00:13:56.000
Được rồi, bây giờ hãy xem chúng ta đã làm điều này như thế nào trong mã.

00:13:56.000 --> 00:14:01.000
Vì vậy, tôi đã tạo lại một sân chơi nhỏ ở đây vì việc xây dựng những thứ này cho chúng tôi dễ dàng hơn.

00:14:01.000 --> 00:14:10.000
Những gì bạn có thể thấy là tôi đã tải lên một hình ảnh và tôi đã sử dụng CIImage, bởi vì tôi cần thực hiện một số thao tác hình ảnh trên đó.

00:14:10.000 --> 00:14:15.000
Tôi đã tạo một requestHandler, và tôi đã sử dụng VNDetectDocument SegmentationRequest() mới.

00:14:15.000 --> 00:14:33.000
Khi tôi thực hiện yêu cầu, bây giờ tôi nhận lại kết quả và tôi đã tạo một chức năng trợ giúp nhỏ mà tôi đã sử dụng hình ảnh cốt lõi để sử dụng bây giờ làm hình ảnh đã sửa phối cảnh và chúng tôi nhận lại chỉ là một thẻ đã cắt ở dạng đã sửa phối cảnh.

00:14:33.000 --> 00:14:35.000
Vì vậy, điều đó thật dễ dàng.

00:14:35.000 --> 00:14:37.000
Vậy, chúng ta phải làm gì tiếp theo?

00:14:37.000 --> 00:14:44.000
Chúng ta cần phát hiện mã vạch, phát hiện các hình chữ nhật và nhận dạng văn bản.

00:14:44.000 --> 00:14:50.000
Khi chúng tôi thực hiện yêu cầu này, chúng tôi phải quét các hộp kiểm để xem cái nào đã được đánh dấu.

00:14:50.000 --> 00:14:58.000
Được rồi, tôi đã chuẩn bị điều này một chút, vì vậy hãy bắt đầu với việc phát hiện mã vạch.

00:14:58.000 --> 00:15:02.000
Và tôi đang sử dụng, như những ký hiệu, chỉ là mã QR.

00:15:02.000 --> 00:15:09.000
Tôi đã tải vào tiêu đề tài liệu vì tôi biết đó là-- nội dung mã QR của tôi sẽ là tiêu đề của những gì chúng tôi nhận được từ nó.

00:15:09.000 --> 00:15:12.000
Tiếp theo, chúng ta cần phát hiện các hình chữ nhật.

00:15:12.000 --> 00:15:18.000
Một lần nữa, chúng tôi có một đoạn mã hình chữ nhật nhỏ cho điều đó.

00:15:18.000 --> 00:15:20.000
Vì vậy, tôi tạo ra hai mảng.

00:15:20.000 --> 00:15:25.000
Tôi muốn lấy tất cả các checkBoxImages, đó là dữ liệu cần thiết cho việc phân tích.

00:15:25.000 --> 00:15:27.000
Và tôi lấy tất cả các hình chữ nhật ra.

00:15:27.000 --> 00:15:30.000
Vì vậy, tôi đã sử dụng VNDetectRectanglesRequest.

00:15:30.000 --> 00:15:39.000
Bây giờ, những gì tôi làm ở đây là tôi sắp xếp chúng theo thứ tự dọc để tôi nhận lại kết quả theo đúng thứ tự.

00:15:39.000 --> 00:15:44.000
Được rồi, bây giờ chúng ta cần nhận ra văn bản của mình.

00:15:44.000 --> 00:15:45.000
Điều đó thật đơn giản.

00:15:45.000 --> 00:15:51.000
Chúng tôi lưu trữ tất cả các khối văn bản kết quả và chúng tôi sử dụng VNRecognizeTextRequest.

00:15:51.000 --> 00:15:56.000
Vì vậy, bây giờ, những gì chúng ta phải làm chỉ đơn giản là thực hiện yêu cầu.

00:15:56.000 --> 00:16:05.000
Và như bạn có thể thấy, tôi đã sử dụng documentRequestHandler, đây là tài liệu đã sử dụng hình ảnh được cắt ra và thực hiện các yêu cầu trên đó.

00:16:05.000 --> 00:16:14.000
Và nếu tôi quay lại đây, tôi đã có thể thấy rằng tôi đã nhận được mã QR chính xác của mình, nhưng có điều gì đó không ổn với hình chữ nhật của tôi.

00:16:14.000 --> 00:16:16.000
Tôi không nhận được bất kỳ hình chữ nhật nào.

00:16:16.000 --> 00:16:18.000
Vậy, tôi phải làm gì?

00:16:18.000 --> 00:16:25.000
Chà, theo mặc định, máy dò hình chữ nhật chỉ tìm kiếm các hình chữ nhật có ít nhất 20% hình ảnh.

00:16:25.000 --> 00:16:26.000
Vì vậy, chúng ta cần phải sửa chữa điều đó.

00:16:26.000 --> 00:16:41.000
Vì vậy, tôi đi vào và đặt Kích thước tối thiểu thành, giả sử, khoảng 10%.

00:16:41.000 --> 00:16:45.000
Và một khi chúng ta làm điều đó, chúng ta sẽ có một hình chữ nhật.

00:16:45.000 --> 00:16:48.000
Được rồi, đó chỉ là một.

00:16:48.000 --> 00:16:53.000
Chà, một điều khác với máy dò hình chữ nhật là tôi cần nói cho nó biết nó sẽ trả lại bao nhiêu.

00:16:53.000 --> 00:16:59.000
Theo mặc định, phát hiện hình chữ nhật sẽ chỉ trả về một, hình chữ nhật nổi bật nhất.

00:16:59.000 --> 00:17:00.000
Nhưng tôi muốn có được tất cả chúng.

00:17:00.000 --> 00:17:05.000
Tôi làm điều này bằng cách đặt maximumObservations thành 0.

00:17:05.000 --> 00:17:16.000
Và một khi tôi đã làm điều đó, bây giờ tôi nhận được tất cả các hộp kiểm của chúng tôi và mã vạch, bởi vì nó trông giống như một hình chữ nhật.

00:17:16.000 --> 00:17:18.000
Được rồi, vậy là chúng tôi ổn.

00:17:18.000 --> 00:17:23.000
Bây giờ đến phần cuối cùng, và tôi thực sự cần quét các hộp kiểm.

00:17:23.000 --> 00:17:28.000
Vì vậy, vì điều đó, tôi thực sự đã chuẩn bị một bản demo học máy nhỏ.

00:17:28.000 --> 00:17:31.000
Tôi có một mô hình ở đây mà tôi đã đào tạo trước đó với Create ML.

00:17:31.000 --> 00:17:40.000
Đó là một trình phân loại hình ảnh và tất cả những gì tôi làm là tôi đã sử dụng một số hình ảnh hộp kiểm này, được đánh dấu và một số trong số chúng không được đánh dấu, cho nhãn "có" và "không" của tôi.

00:17:40.000 --> 00:17:43.000
Và tôi cũng đã thu thập được một vài hình ảnh không phải là cả hai.

00:17:43.000 --> 00:17:47.000
Đó là NotIt của tôi.

00:17:47.000 --> 00:17:56.000
Một lần nữa, chúng ta có thể sử dụng cái này trong mã của mình.

00:17:56.000 --> 00:17:58.000
Vậy, chúng ta có gì?

00:17:58.000 --> 00:18:03.000
Chúng tôi tạo yêu cầu của mình bằng cách tải mô hình và tạo yêu cầu Tạo ML của chúng tôi.

00:18:03.000 --> 00:18:12.000
Và sau đó chúng tôi lặp lại, trên tất cả các hình ảnh hộp kiểm, tạo một ImageRequestHandler từ nó và thực hiện phân loại của chúng tôi.

00:18:12.000 --> 00:18:14.000
Bây giờ, tôi có thể nhìn vào phân loại hàng đầu của mình.

00:18:14.000 --> 00:18:22.000
Nếu đó là "Có", thì tôi chỉ cần tìm dòng văn bản nào với hộp kiểm mà tôi có, và cuối cùng chúng ta sẽ nhận được gì?

00:18:22.000 --> 00:18:26.000
Tầm nhìn mang tính giải trí và nhiều thông tin.

00:18:26.000 --> 00:18:29.000
Hãy quay lại các trang trình bày.

00:18:29.000 --> 00:18:31.000
Hãy tóm tắt lại những gì chúng ta đã thấy.

00:18:31.000 --> 00:18:35.000
Phân tích tài liệu là trọng tâm trong Vision API.

00:18:35.000 --> 00:18:42.000
Phát hiện mã vạch trong Vision linh hoạt hơn máy quét và chúng tôi đang giới thiệu một phát hiện phân đoạn tài liệu mới.

00:18:42.000 --> 00:18:49.000
Nếu bạn muốn tìm hiểu thêm về cách sử dụng OCR, vui lòng xem phiên của chúng tôi từ WWDC 2019.

00:18:49.000 --> 00:19:02.000
Phiên "Tầm nhìn và hình ảnh cốt lõi" từ WWDC 2020 cung cấp cho bạn những hiểu biết bổ sung trong việc thực hiện phân tích tài liệu tùy chỉnh của riêng bạn bằng cách xử lý trước hình ảnh và phát hiện các đường viền.

00:19:02.000 --> 00:19:05.000
Cảm ơn bạn, và tận hưởng phần còn lại của WWDC.

00:19:05.000 --> 23:59:59.000
[Âm nhạc].

