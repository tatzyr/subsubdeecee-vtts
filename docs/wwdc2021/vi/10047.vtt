WEBVTT

00:00:00.000 --> 00:00:05.000
♪ Nhạc bass đang phát ♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:13.000
Brad Ford: Xin chào và chào mừng đến với "Có gì mới trong việc chụp ảnh."

00:00:13.000 --> 00:00:16.000
Tôi là Brad Ford từ nhóm Phần mềm Máy ảnh.

00:00:16.000 --> 00:00:37.000
Tôi sẽ giới thiệu một loạt các tính năng máy ảnh mới bắt đầu với báo cáo khoảng cách lấy nét tối thiểu; cách quay video HDR 10-bit; khóa học chính, Hiệu ứng video trong Trung tâm điều khiển; và sau đó - thời gian nghỉ ngơi ngắn từ các tính năng mới - Tôi sẽ xem xét các chiến lược để có được hiệu suất tốt nhất từ ứng dụng máy ảnh của bạn

00:00:37.000 --> 00:00:44.000
Và cuối cùng, tôi sẽ giới thiệu một thủ thuật hiệu suất hoàn toàn mới cho túi của bạn, nén bề mặt IOS.

00:00:44.000 --> 00:00:52.000
Tất cả các tính năng tôi sẽ mô tả hôm nay đều được tìm thấy trong khung AVFoundation - cụ thể là các lớp có tiền tố AVCapture.

00:00:52.000 --> 00:01:13.000
Để xem xét ngắn gọn, các đối tượng chính là AVCaptureDevices, đại diện cho máy ảnh hoặc micrô; AVCaptureDeviceInputs, bao bọc các thiết bị, cho phép chúng được cắm vào AVCaptureSession, là đối tượng điều khiển trung tâm của biểu đồ AVCapture.

00:01:13.000 --> 00:01:17.000
AVCaptureOutputs hiển thị dữ liệu từ đầu vào theo nhiều cách khác nhau.

00:01:17.000 --> 00:01:21.000
MovieFileOutput ghi lại các bộ phim QuickTime.

00:01:21.000 --> 00:01:26.000
PhotoOutput chụp ảnh tĩnh chất lượng cao và Ảnh trực tiếp.

00:01:26.000 --> 00:01:35.000
Đầu ra dữ liệu, chẳng hạn như VideoDataOutput hoặc AudioDataOutput, cung cấp bộ đệm video hoặc âm thanh từ máy ảnh hoặc micrô đến ứng dụng của bạn.

00:01:35.000 --> 00:01:43.000
Có một số loại đầu ra dữ liệu khác, chẳng hạn như Siêu dữ liệu và Độ sâu.

00:01:43.000 --> 00:01:53.000
Để xem trước camera trực tiếp, có một loại đầu ra đặc biệt, AVCaptureVideoPreviewLayer, là một lớp con của CALayer.

00:01:53.000 --> 00:02:04.000
Luồng dữ liệu từ đầu vào chụp đến đầu ra chụp tương thích thông qua AVCaptureConnections, được biểu thị ở đây bằng các mũi tên này.

00:02:04.000 --> 00:02:13.000
Nếu bạn chưa quen với chụp ảnh AVFoundation, tôi mời bạn tìm hiểu thêm tại trang bắt đầu Chụp ảnh và Chụp phương tiện trên developer.apple.com.

00:02:13.000 --> 00:02:17.000
Được rồi, hãy đi sâu vào tính năng đầu tiên trong số các tính năng mới của chúng tôi.

00:02:17.000 --> 00:02:24.000
Khoảng cách lấy nét tối thiểu là khoảng cách từ ống kính đến điểm gần nhất nơi có thể lấy nét sắc nét.

00:02:24.000 --> 00:02:29.000
Đó là một thuộc tính của tất cả các ống kính, có thể là trên máy ảnh DSLR hoặc điện thoại thông minh.

00:02:29.000 --> 00:02:36.000
Máy ảnh iPhone cũng có khoảng cách lấy nét tối thiểu, chúng tôi chưa bao giờ xuất bản nó trước đây...

00:02:36.000 --> 00:02:38.000
...Cho đến bây giờ, đó là.

00:02:38.000 --> 00:02:46.000
Bắt đầu từ iOS 15, khoảng cách lấy nét tối thiểu là một thuộc tính được công bố của máy ảnh lấy nét tự động iPhone.

00:02:46.000 --> 00:02:48.000
Đây là một mẫu của những chiếc iPhone gần đây.

00:02:48.000 --> 00:02:56.000
Biểu đồ minh họa khoảng cách lấy nét tối thiểu của máy ảnh Wide và tele thay đổi như thế nào giữa các kiểu máy.

00:02:56.000 --> 00:03:09.000
Có một sự khác biệt đáng chú ý giữa máy ảnh iPhone 12 Pro và 12 Pro Max Wide, Pro Max lấy nét ở khoảng cách tối thiểu 15 cm so với 12 trên Pro.

00:03:09.000 --> 00:03:16.000
Điều này là do công nghệ ổn định dịch chuyển cảm biến trong iPhone 12 Pro Max.

00:03:16.000 --> 00:03:23.000
Tương tự như vậy, khoảng cách lấy nét tối thiểu của tele xa hơn trên 12 Pro Max so với 12 Pro.

00:03:23.000 --> 00:03:27.000
Điều này là do tầm với dài hơn của ống kính tele.

00:03:27.000 --> 00:03:32.000
Nó có zoom 2.5x so với zoom 2x.

00:03:32.000 --> 00:03:42.000
Hãy để tôi chỉ cho bạn một bản demo nhanh về lý do tại sao báo cáo khoảng cách lấy nét tối thiểu lại quan trọng.

00:03:42.000 --> 00:03:45.000
Đây là một ứng dụng mẫu có tên AVCamBarcode.

00:03:45.000 --> 00:03:48.000
Nó giới thiệu các API phát hiện mã vạch AVFoundation của chúng tôi.

00:03:48.000 --> 00:03:54.000
Giao diện người dùng hướng dẫn người dùng định vị một đối tượng bên trong hình chữ nhật để quét.

00:03:54.000 --> 00:03:59.000
Trong ví dụ này, tôi đã chọn một mã QR khá nhỏ trên một tờ giấy.

00:03:59.000 --> 00:04:02.000
Mã vạch chỉ rộng 20 mm.

00:04:02.000 --> 00:04:10.000
Bằng cách nhấn vào nút Siêu dữ liệu, tôi thấy danh sách tất cả các loại đối tượng khác nhau được AVCaptureMetadataOutput hỗ trợ.

00:04:10.000 --> 00:04:12.000
Có rất nhiều người trong số họ.

00:04:12.000 --> 00:04:21.000
Tôi sẽ chọn QRCodes và sau đó định vị máy ảnh iPhone 12 Pro Max của mình để lấp đầy hình chữ nhật bằng QRCode.

00:04:21.000 --> 00:04:27.000
Thật không may, nó nhỏ đến mức tôi phải đến rất gần trang để điền vào bản xem trước.

00:04:27.000 --> 00:04:30.000
Nó gần hơn khoảng cách lấy nét tối thiểu của máy ảnh.

00:04:30.000 --> 00:04:33.000
Mã bị mờ, vì vậy nó không quét.

00:04:33.000 --> 00:04:42.000
Để hướng dẫn người dùng lùi lại, tôi cần áp dụng hệ số thu phóng cho bản xem trước máy ảnh...

00:04:42.000 --> 00:04:44.000
...Như vậy.

00:04:44.000 --> 00:04:49.000
Nhìn thấy hình ảnh được phóng to trên màn hình sẽ nhắc họ di chuyển máy ảnh ra xa giấy hơn.

00:04:49.000 --> 00:04:58.000
Tôi có thể làm điều đó với một nút trượt, nhưng sẽ tốt hơn nhiều nếu ứng dụng tự động thu phóng.

00:04:58.000 --> 00:05:03.000
Đó là nơi thuộc tính minimumFocusDistance mới của AVCaptureDevice xuất hiện.

00:05:03.000 --> 00:05:06.000
Nó mới trong iOS 15.

00:05:06.000 --> 00:05:26.000
Với trường nhìn ngang của máy ảnh, kích thước mã vạch tối thiểu bạn muốn quét - ở đây tôi đã đặt nó thành 20 mm - và chiều rộng của cửa sổ xem trước máy ảnh theo tỷ lệ phần trăm, chúng ta có thể thực hiện một phép toán nhỏ để tính toán khoảng cách đối tượng tối thiểu cần thiết để lấp đầy chiều rộng xem trước đó.

00:05:26.000 --> 00:05:39.000
Sau đó, sử dụng thuộc tính minimumFocusDistance mới của máy ảnh, chúng ta có thể phát hiện khi máy ảnh của chúng ta không thể lấy nét gần đó và tính toán hệ số thu phóng đủ lớn để hướng dẫn người dùng lùi lại.

00:05:39.000 --> 00:05:48.000
Và cuối cùng, chúng tôi áp dụng nó vào máy ảnh bằng cách khóa nó để cấu hình, cài đặt hệ số thu phóng và sau đó mở khóa nó.

00:05:48.000 --> 00:05:58.000
Sau khi biên dịch lại ứng dụng demo của chúng tôi, giao diện người dùng hiện tự động áp dụng lượng thu phóng chính xác.

00:05:58.000 --> 00:06:02.000
Khi ứng dụng khởi chạy, nó đã được phóng to đến đúng không gian.

00:06:02.000 --> 00:06:05.000
Không còn mã vạch mờ nữa!

00:06:05.000 --> 00:06:10.000
Và nếu tôi chạm vào nó, chúng ta có thể thấy nó đưa tôi đến đâu.

00:06:10.000 --> 00:06:14.000
À! "Nắm bắt chiều sâu trong nhiếp ảnh iPhone" - một người già nhưng một người tốt.

00:06:14.000 --> 00:06:20.000
Tôi đánh giá cao phiên đó.

00:06:20.000 --> 00:06:31.000
Vui lòng xem mẫu AVCamBarcode mới để biết các phương pháp hay nhất về cách kết hợp khoảng cách lấy nét tối thiểu, cũng như nhiều phương pháp hay nhất khác để quét mã vạch.

00:06:31.000 --> 00:06:35.000
Tiếp theo là video HDR 10-bit.

00:06:35.000 --> 00:06:43.000
HDR là viết tắt của High Dynamic Range, và nó đã xuất hiện như một công nghệ hình ảnh tĩnh kể từ khi trở lại iOS 4.1.

00:06:43.000 --> 00:06:53.000
Việc duy trì Dải động cao thường được thực hiện bằng cách thực hiện nhiều lần phơi sáng của một cảnh và sau đó pha trộn chúng để bảo tồn cả điểm sáng và bóng tối.

00:06:53.000 --> 00:06:56.000
Nhưng còn video HDR thì sao?

00:06:56.000 --> 00:07:02.000
Đó là một thách thức vì bạn phải cung cấp 30 hoặc 60 khung hình một giây.

00:07:02.000 --> 00:07:13.000
Không hẳn là Video HDR - nhưng gần - vào năm 2018, Apple đã giới thiệu EDR, hoặc Dải động mở rộng, cho dòng máy ảnh iPhone XS.

00:07:13.000 --> 00:07:18.000
EDR là một giải pháp giống như HDR cho video.

00:07:18.000 --> 00:07:30.000
Về cơ bản, nó tăng gấp đôi tốc độ khung hình chụp, xen kẽ giữa phơi sáng tiêu chuẩn và phơi sáng ngắn, nhưng theo thời gian nên hầu như không có khoảng trống dọc giữa các lần chụp.

00:07:30.000 --> 00:07:38.000
Khi chụp trên danh nghĩa 30 khung hình mỗi giây, video EDR thực sự đang chạy máy ảnh ở tốc độ 60 khung hình một giây.

00:07:38.000 --> 00:07:50.000
Khi cảnh yêu cầu, bản đồ màu sắc từ EV- được áp dụng động cho hình ảnh EV0 để khôi phục các điểm nổi bật được cắt bớt, nhưng không làm mất chi tiết trong bóng tối.

00:07:50.000 --> 00:08:00.000
Nó không phải là một giải pháp HDR đầy đủ, vì hiệu quả của nó giảm dần trong điều kiện ánh sáng yếu, nhưng nó cung cấp kết quả đáng kinh ngạc trong điều kiện ánh sáng trung bình đến tốt.

00:08:00.000 --> 00:08:02.000
Bây giờ đây là phần khó hiểu.

00:08:02.000 --> 00:08:10.000
EDR được trình bày như một bộ thuộc tính AVCaptureDevice dưới biệt danh videoHDR.

00:08:10.000 --> 00:08:19.000
Bất cứ nơi nào bạn thấy videoHDRSupported hoặc videoHDREnabled trong AVCapture API, bạn nên thay thế EDR về mặt tinh thần.

00:08:19.000 --> 00:08:22.000
Đó là những gì nó là.

00:08:22.000 --> 00:08:30.000
AVCaptureDevice cũng có một thuộc tính được gọi là "automaticallyAdjusts VideoHDREnabled", mặc định là true.

00:08:30.000 --> 00:08:35.000
Vì vậy EDR được kích hoạt tự động bất cứ khi nào nó có sẵn.

00:08:35.000 --> 00:08:48.000
Nếu vì lý do nào đó bạn muốn vô hiệu hóa nó, bạn cần đặt tự độngAdjustsVideo HDREnabled thành false, và sau đó đặt videoHDREnabled thành false.

00:08:48.000 --> 00:08:50.000
Bây giờ câu chuyện thậm chí còn tốt hơn.

00:08:50.000 --> 00:08:58.000
Tôi cần nói với bạn về EDR để tôi có thể nói với bạn về Video HDR 10-bit.

00:08:58.000 --> 00:09:04.000
Video HDR 10-bit thực sự là Dải động cao vì nó có nhiều bit hơn!

00:09:04.000 --> 00:09:07.000
Điều đó có nghĩa là tăng khả năng chỉnh sửa.

00:09:07.000 --> 00:09:12.000
Nó có EDR để phục hồi điểm nổi bật và nó luôn bật.

00:09:12.000 --> 00:09:23.000
Nó sử dụng các đường cong gamma log lai cũng như không gian màu BT.2020, cho phép độ tương phản màu sắc thậm chí còn lớn hơn - độ sáng sáng hơn Rec 709.

00:09:23.000 --> 00:09:39.000
Và cho dù bạn sử dụng AVCaptureMovieFileOutput hay AVCaptureVideoDataOutput cộng với AVAssetWriter, chúng tôi sẽ tự động chèn siêu dữ liệu Dolby Vision trên mỗi khung hình vào phim của bạn, làm cho chúng tương thích với màn hình Dolby Vision.

00:09:39.000 --> 00:09:45.000
Video HDR 10-bit lần đầu tiên được giới thiệu trên iPhone 12.

00:09:45.000 --> 00:09:50.000
Các định dạng video HDR 10-bit có thể được xác định bằng loại định dạng pixel duy nhất của chúng.

00:09:50.000 --> 00:09:56.000
Trên các mẫu iPhone cũ hơn, máy ảnh có AVCaptureDeviceFormats luôn đi kèm theo cặp.

00:09:56.000 --> 00:10:03.000
Đối với mỗi độ phân giải và phạm vi tốc độ khung hình, có định dạng 420v và 420f.

00:10:03.000 --> 00:10:07.000
Đây là các định dạng 8-bit, biplanar, YUV.

00:10:07.000 --> 00:10:21.000
V trong 420v là viết tắt của phạm vi video - hoặc 16 đến 235 - và F trong 420f là viết tắt của toàn dải - hoặc 0 đến 255.

00:10:21.000 --> 00:10:26.000
Trên các mẫu iPhone 12, một số định dạng có ba định dạng.

00:10:26.000 --> 00:10:34.000
Sau các định dạng 420v và 420f xuất hiện định dạng x420 có cùng độ phân giải và phạm vi tốc độ khung hình.

00:10:34.000 --> 00:10:46.000
Giống như 420v, x420 là định dạng 420 hai mặt phẳng trong phạm vi video, nhưng x trong x420 là viết tắt của 10 bit thay vì 8.

00:10:46.000 --> 00:11:06.000
Để tìm và chọn định dạng video HDR 10-bit trong mã, chỉ cần lặp qua các định dạng AVCaptureDevice cho đến khi bạn tìm thấy định dạng pixel phù hợp với x420 hoặc - hít thở sâu - 420YpCbCr10BiPlanarVideoRange.

00:11:06.000 --> 00:11:13.000
Tất nhiên bạn có thể bao gồm các tiêu chí tìm kiếm khác, chẳng hạn như chiều rộng, chiều cao và tốc độ khung hình tối đa.

00:11:13.000 --> 00:11:18.000
Chúng tôi đã cập nhật mã mẫu AVCam của mình để hỗ trợ video HDR 10-bit khi có sẵn.

00:11:18.000 --> 00:11:29.000
Có một chức năng tiện ích tiện dụng trong đó được gọi là "tenBitVariantOfFormat" có thể tìm thấy biến thể HDR 10-bit của bất kỳ định dạng hoạt động của thiết bị hiện được chọn nào.

00:11:29.000 --> 00:11:32.000
Vui lòng xem qua.

00:11:32.000 --> 00:11:41.000
Video HDR 10-bit được hỗ trợ ở tất cả các định dạng video phổ biến nhất, bao gồm 720p, 1080p và 4K.

00:11:41.000 --> 00:11:53.000
Và chúng tôi cũng bao gồm định dạng 4 x 3 - 1920 x 1440 - hỗ trợ ảnh 12 megapixel, độ phân giải cao.

00:11:53.000 --> 00:12:00.000
Mặc dù quay video HDR 10-bit rất đơn giản, nhưng việc chỉnh sửa và phát lại đúng cách rất khó khăn.

00:12:00.000 --> 00:12:10.000
Tôi mời bạn xem một phiên đồng hành từ năm 2020 có tựa đề "Chỉnh sửa và phát lại video HDR với AVFoundation."

00:12:10.000 --> 00:12:14.000
Được rồi, đó là nó cho video HDR.

00:12:14.000 --> 00:12:20.000
Bây giờ đến sự kiện chính: Hiệu ứng video trong Trung tâm điều khiển.

00:12:20.000 --> 00:12:28.000
Nói một cách đơn giản, đây là những tính năng máy ảnh cấp hệ thống có sẵn trong ứng dụng của bạn mà không có thay đổi mã.

00:12:28.000 --> 00:12:32.000
Và người dùng đang kiểm soát.

00:12:32.000 --> 00:12:34.000
Đây là một chút khởi đầu cho chúng tôi.

00:12:34.000 --> 00:12:42.000
Theo truyền thống, khi chúng tôi giới thiệu một tính năng máy ảnh mới trong iOS hoặc macOS, các ứng dụng của Apple sẽ áp dụng nó ngay lập tức.

00:12:42.000 --> 00:12:51.000
Chúng tôi giới thiệu các API AVCapture mới, bạn tìm hiểu về chúng - giống như bạn đang làm bây giờ - và sau đó bạn áp dụng tính năng này theo tốc độ của riêng mình.

00:12:51.000 --> 00:13:01.000
Đây là một cách tiếp cận an toàn và bảo thủ, nhưng thường dẫn đến thời gian chờ lâu, trong đó người dùng bỏ lỡ một tính năng tuyệt vời trong các ứng dụng máy ảnh yêu thích của họ.

00:13:01.000 --> 00:13:16.000
Với Hiệu ứng Video trong Trung tâm Điều khiển, chúng tôi đang giới thiệu các tính năng máy ảnh được đóng gói sẵn cấp hệ thống có sẵn cho mọi người ngay lập tức mà không thay đổi mã và người dùng có quyền kiểm soát được.

00:13:16.000 --> 00:13:26.000
Chúng tôi tiếp tục giới thiệu các API mới cho các tính năng này, vì vậy bạn có thể điều chỉnh trải nghiệm trong ứng dụng của mình ngay khi lịch phát hành của bạn cho phép.

00:13:26.000 --> 00:13:28.000
Hãy cùng xem những hiệu ứng này.

00:13:28.000 --> 00:13:34.000
Lần đầu tiên được công bố tại sự kiện Apple tải mùa xuân tháng 5 của chúng tôi và nó được gọi là "Giai đoạn trung tâm".

00:13:34.000 --> 00:13:44.000
Nó có sẵn trên các mẫu M1 iPad Pro được phát hành gần đây và nó sử dụng máy ảnh mặt trước Ultra Wide 12 megapixel đáng kinh ngạc của họ.

00:13:44.000 --> 00:13:49.000
Center Stage thực sự nâng cao giá trị sản xuất của các cuộc gọi video FaceTime của bạn.

00:13:49.000 --> 00:13:53.000
Nó cũng hoạt động tốt ngay lập tức trong mọi ứng dụng hội nghị truyền hình khác.

00:13:53.000 --> 00:13:55.000
Đây, để tôi chỉ cho bạn.

00:13:55.000 --> 00:14:03.000
Tôi vừa tải xuống Skype từ App Store; đây là phiên bản chứng khoán của ứng dụng.

00:14:03.000 --> 00:14:08.000
Khi tôi bắt đầu một cuộc gọi Skype, bạn ngay lập tức thấy Sân khấu Trung tâm bắt đầu hoạt động.

00:14:08.000 --> 00:14:12.000
Nó giống như có người điều khiển máy ảnh cá nhân của riêng bạn.

00:14:12.000 --> 00:14:22.000
Nó đóng khung bạn khi bạn di chuyển xung quanh khung cảnh để giữ cho bạn được đóng khung hoàn hảo, cho dù bạn đến chặt chẽ hay bạn di chuyển trở lại và thích tăng tốc.

00:14:22.000 --> 00:14:26.000
Nó thậm chí có thể theo dõi bạn khi bạn quay mặt ra khỏi máy ảnh.

00:14:26.000 --> 00:14:31.000
Đó là bởi vì nó theo dõi cơ thể, không chỉ khuôn mặt.

00:14:31.000 --> 00:14:43.000
Là người dùng, tôi có thể điều khiển Giai đoạn Trung tâm bằng cách chỉ cần vuốt xuống Trung tâm Điều khiển, nhấn vào mô-đun Hiệu ứng Video mới và thực hiện lựa chọn của tôi.

00:14:43.000 --> 00:14:49.000
Khi tôi tắt Center Stage và quay lại ứng dụng, tôi không còn nhận được hiệu ứng Center Stage nữa.

00:14:49.000 --> 00:14:52.000
Không có thay đổi nào trong ứng dụng.

00:14:52.000 --> 00:14:59.000
Có một tính năng mới đồng hành mà tất cả các ứng dụng hội nghị truyền hình cũng nhận được và được gọi là "Chân dung".

00:14:59.000 --> 00:15:03.000
Chế độ chân dung cung cấp cho tôi hiệu ứng độ sâu trường ảnh nông được hiển thị đẹp mắt.

00:15:03.000 --> 00:15:16.000
Nó không chỉ là một sự mờ nhạt riêng tư đơn giản; nó sử dụng Neural Engine của Apple cộng với mạng lưới độ sâu một mắt được đào tạo để ước tính một máy ảnh thực sự với ống kính mở rộng.

00:15:16.000 --> 00:15:33.000
Bây giờ cuối cùng chúng ta hãy xem xét các chế độ micrô bằng cách vuốt xuống và chọn mô-đun Chế độ Mic, tôi có thể đưa ra lựa chọn của mình giữa Tiêu chuẩn, Cách ly giọng nói hoặc Phổ rộng.

00:15:33.000 --> 00:15:37.000
Các chế độ micrô nâng cao chất lượng âm thanh trong các cuộc trò chuyện video của bạn.

00:15:37.000 --> 00:15:39.000
Nhiều hơn về những thứ này trong một phút.

00:15:39.000 --> 00:15:48.000
Trong khi các Chế độ Center Stage, Portrait và Mic chia sẻ bất động sản màn hình trong Control Center, chúng có phần khác nhau về cách xử lý API.

00:15:48.000 --> 00:15:54.000
Tôi sẽ giới thiệu cho bạn các API Sân khấu Trung tâm trước và sau đó là Chế độ Chân dung và Mic.

00:15:54.000 --> 00:15:59.000
Center Stage có sẵn trên tất cả các camera trước của M1 iPad Pros.

00:15:59.000 --> 00:16:13.000
Cho dù bạn đang sử dụng máy ảnh Ultra Wide mặt trước mới, máy ảnh Virtual Wide - trình bày trường nhìn thông thường, được cắt xén - hay máy ảnh TrueDepth ảo, Center Stage đều có sẵn.

00:16:13.000 --> 00:16:19.000
Máy ảnh TrueDepth đi kèm với một số điều kiện, mà tôi sẽ đề cập trong giây lát.

00:16:19.000 --> 00:16:24.000
Mô-đun Hiệu ứng Video Trung tâm Điều khiển trình bày chuyển đổi bật/tắt cho mỗi ứng dụng.

00:16:24.000 --> 00:16:34.000
Điều này cho phép bạn mặc định Center Stage được bật trong ứng dụng hội nghị, trong khi mặc định tắt nó trong ứng dụng chụp ảnh chuyên nghiệp, nơi bạn muốn đóng khung ảnh của mình theo cách thủ công.

00:16:34.000 --> 00:16:40.000
Có một trạng thái cho mỗi ứng dụng, không phải một trạng thái cho mỗi máy ảnh.

00:16:40.000 --> 00:16:50.000
Bởi vì nút chuyển đổi bật/tắt Giai đoạn Trung tâm là trên mỗi ứng dụng, không phải trên mỗi máy ảnh, nó được trình bày trong API dưới dạng một tập hợp các thuộc tính lớp trên AVCaptureDevice.

00:16:50.000 --> 00:16:55.000
Chúng có thể đọc được, ghi và có thể quan sát được giá trị khóa.

00:16:55.000 --> 00:17:01.000
centerStageEnabled khớp với trạng thái bật/tắt của giao diện người dùng Sân khấu Trung tâm trong Trung tâm điều khiển.

00:17:01.000 --> 00:17:07.000
Chế độ điều khiển Giai đoạn Trung tâm ra lệnh ai được phép chuyển đổi trạng thái được bật.

00:17:07.000 --> 00:17:10.000
Nhiều hơn về điều đó trong một phút.

00:17:10.000 --> 00:17:13.000
Không phải tất cả các máy ảnh hoặc định dạng đều hỗ trợ Sân khấu Trung tâm.

00:17:13.000 --> 00:17:22.000
Bạn có thể lặp lại thông qua mảng định dạng của bất kỳ máy ảnh nào để tìm định dạng hỗ trợ tính năng này và đặt nó làm Định dạng hoạt động của bạn.

00:17:22.000 --> 00:17:34.000
Ngoài ra, bạn có thể tìm hiểu xem Giai đoạn Trung tâm hiện đang hoạt động cho một máy ảnh cụ thể hay không bằng cách truy vấn hoặc quan sát thuộc tính hoạt động Giai đoạn Trung tâm của nó.

00:17:34.000 --> 00:17:37.000
Bạn nên nhận thức được những hạn chế của Sân khấu Trung tâm.

00:17:37.000 --> 00:17:48.000
Center Stage sử dụng định dạng 12 megapixel đầy đủ của máy ảnh Ultra Wide, có định dạng 30 khung hình / giây, vì vậy tốc độ khung hình tối đa được giới hạn ở mức 30.

00:17:48.000 --> 00:17:59.000
Center Stage tránh nâng cấp để duy trì chất lượng hình ảnh, vì vậy nó bị giới hạn ở độ phân giải đầu ra tối đa là 1920 bởi 1440.

00:17:59.000 --> 00:18:07.000
Xoay và thu phóng phải nằm dưới điều khiển Sân khấu Trung tâm, vì vậy hệ số thu phóng video bị khóa tại một.

00:18:07.000 --> 00:18:23.000
Hiệu chỉnh biến dạng hình học là không thể thiếu đối với khung người của Center Stage và việc phân phối độ sâu phải được tắt, vì việc tạo độ sâu yêu cầu khớp với toàn bộ trường nhìn của hình ảnh từ RGB và camera hồng ngoại.

00:18:23.000 --> 00:18:27.000
Bây giờ chúng ta hãy đi vào khái niệm về các chế độ điều khiển.

00:18:27.000 --> 00:18:36.000
Center Stage có ba chế độ được hỗ trợ: người dùng, ứng dụng và hợp tác xã.

00:18:36.000 --> 00:18:40.000
Chế độ người dùng là chế độ điều khiển Giai đoạn Trung tâm mặc định cho tất cả các ứng dụng.

00:18:40.000 --> 00:18:44.000
Trong chế độ này, chỉ người dùng mới có thể bật và tắt tính năng.

00:18:44.000 --> 00:18:52.000
Nếu ứng dụng của bạn cố gắng thay đổi trạng thái bật Giai đoạn Trung tâm theo chương trình, một ngoại lệ sẽ được ném ra.

00:18:52.000 --> 00:18:57.000
Tiếp theo là chế độ ứng dụng, trong đó chỉ ứng dụng của bạn mới được phép kiểm soát tính năng này.

00:18:57.000 --> 00:19:02.000
Người dùng không thể sử dụng Trung tâm điều khiển vì nút chuyển đổi có màu xám ngoài kia.

00:19:02.000 --> 00:19:04.000
Không khuyến khích sử dụng chế độ này.

00:19:04.000 --> 00:19:08.000
Bạn chỉ nên sử dụng nó nếu Center Stage không tương thích với ứng dụng của bạn.

00:19:08.000 --> 00:19:18.000
Nếu bạn cần chọn không tham gia, bạn có thể đặt chế độ điều khiển thành ứng dụng, sau đó đặt isCenterStageEnabled thành false.

00:19:18.000 --> 00:19:31.000
Trải nghiệm người dùng tốt nhất có thể cho Center Stage là chế độ hợp tác, trong đó người dùng có thể kiểm soát tính năng trong Control Center và ứng dụng của bạn có thể điều khiển nó bằng giao diện người dùng của riêng bạn.

00:19:31.000 --> 00:19:33.000
Tuy nhiên, bạn cần phải làm thêm một số công việc.

00:19:33.000 --> 00:19:44.000
Bạn phải quan sát thuộc tính AVCaptureDevice .isCenterStageEnabled và cập nhật giao diện người dùng của bạn để đảm bảo Center Stage được bật khi người dùng muốn.

00:19:44.000 --> 00:19:54.000
Sau khi đặt chế độ điều khiển thành hợp tác, bạn có thể đặt giai đoạn trung tâm được bật thành đúng hoặc sai - ví dụ như dựa trên một nút trong ứng dụng của bạn.

00:19:54.000 --> 00:19:58.000
Đứa trẻ áp phích cho chế độ hợp tác là FaceTime.

00:19:58.000 --> 00:20:16.000
Trong khi tôi đang thực hiện cuộc gọi FaceTime, tôi có thể sử dụng một nút ngay trong ứng dụng để bật Center Stage để nó theo dõi tôi hoặc tôi có thể sử dụng phương pháp thông thường là vuốt xuống trong Control Center và bật hoặc tắt Center Stage.

00:20:16.000 --> 00:20:23.000
FaceTime và Trung tâm điều khiển hợp tác về trạng thái của Giai đoạn Trung tâm để nó luôn phù hợp với ý định của người dùng.

00:20:23.000 --> 00:20:27.000
FaceTime cũng đủ thông minh để biết khi nào các tính năng không tương thích lẫn nhau.

00:20:27.000 --> 00:20:38.000
Vì vậy, nếu, ví dụ, tôi đã cố gắng bật Animoji, yêu cầu độ sâu...

00:20:38.000 --> 00:20:44.000
...Nó biết tắt Center Stage, bởi vì hai tính năng đó không tương thích với nhau.

00:20:44.000 --> 00:20:52.000
Nếu tôi nhấn để bật lại Center Stage, FaceTime biết tắt Animoji.

00:20:52.000 --> 00:20:54.000
Điều đó kết thúc API Giai đoạn Trung tâm.

00:20:54.000 --> 00:21:00.000
Hãy chuyển sang bạn cùng phòng của Center Stage trong Control Center, Portrait.

00:21:00.000 --> 00:21:08.000
Nói một cách đơn giản, đó là một hiệu ứng độ sâu trường ảnh nông được hiển thị đẹp mắt, được thiết kế để trông giống như một ống kính khẩu độ rộng.

00:21:08.000 --> 00:21:17.000
Trên iOS, Portrait được hỗ trợ trên tất cả các thiết bị với Apple Neural Engine - đó là năm 2018 và các điện thoại và miếng đệm mới hơn.

00:21:17.000 --> 00:21:20.000
Chỉ có camera mặt trước được hỗ trợ.

00:21:20.000 --> 00:21:27.000
Nó cũng được hỗ trợ trên tất cả các máy Mac M1, cũng chứa Neural Engine của Apple.

00:21:27.000 --> 00:21:30.000
Chân dung là một thuật toán phức tạp về mặt tính toán.

00:21:30.000 --> 00:21:46.000
Do đó, để giữ cho hiệu suất kết xuất video đáp ứng, nó bị giới hạn ở độ phân giải tối đa 1920 x 1440 và độ phân giải tối đa 30 khung hình mỗi giây.

00:21:46.000 --> 00:21:52.000
Giống như Center Stage, hiệu ứng Portrait có trạng thái bật/tắt dính trên mỗi ứng dụng.

00:21:52.000 --> 00:22:04.000
API của nó đơn giản hơn Center Stage, người dùng luôn kiểm soát thông qua Control Center và nó chỉ khả dụng theo mặc định trong một số lớp ứng dụng nhất định.

00:22:04.000 --> 00:22:14.000
Trên iOS, các ứng dụng sử dụng VoIP UIBackgroundMode sẽ tự động được chọn tham gia - người dùng có thể bật hoặc tắt hiệu ứng trong Trung tâm điều khiển.

00:22:14.000 --> 00:22:26.000
Tất cả các ứng dụng iOS khác phải chọn tham gia để tuyên bố đủ điều kiện cho hiệu ứng Chân dung bằng cách thêm khóa mới vào Info.plist của ứng dụng của họ: NSCameraPortraitEffectEnabled.

00:22:26.000 --> 00:22:33.000
Trên macOS, tất cả các ứng dụng đều được chọn tham gia tự động và có thể sử dụng hiệu ứng ngay lập tức.

00:22:33.000 --> 00:22:38.000
Hiệu ứng Chân dung luôn nằm dưới sự kiểm soát của người dùng chỉ thông qua Trung tâm điều khiển.

00:22:38.000 --> 00:22:43.000
Như với Sân khấu Trung tâm, không phải tất cả các máy ảnh hoặc định dạng đều hỗ trợ Chân dung.

00:22:43.000 --> 00:22:52.000
Bạn có thể lặp lại thông qua mảng định dạng của bất kỳ máy ảnh nào để tìm định dạng hỗ trợ tính năng này và đặt nó làm định dạng hoạt động của bạn.

00:22:52.000 --> 00:23:03.000
Bạn cũng có thể tìm hiểu xem Portrait hiện đang hoạt động cho một máy ảnh cụ thể hay không bằng cách truy vấn hoặc quan sát thuộc tính isPortraitEffectActive của nó.

00:23:03.000 --> 00:23:08.000
Mic Mode APIs tương tự như Portrait.

00:23:08.000 --> 00:23:11.000
Lựa chọn người dùng gắn bó với mỗi ứng dụng.

00:23:11.000 --> 00:23:17.000
Người dùng luôn kiểm soát; ứng dụng của bạn không thể đặt Chế độ Mic trực tiếp.

00:23:17.000 --> 00:23:21.000
Một số ứng dụng cần chọn tham gia để sử dụng tính năng này.

00:23:21.000 --> 00:23:52.000
Chế độ Mic được trình bày trong giao diện AVCaptureDevice của AVFoundation và có ba hương vị: tiêu chuẩn, sử dụng DSP âm thanh tiêu chuẩn; phổ rộng, giảm thiểu quá trình xử lý để thu tất cả âm thanh xung quanh thiết bị nhưng nó vẫn bao gồm hủy tiếng vang; và cách ly giọng nói, giúp tăng cường lời nói và loại bỏ tiếng

00:23:52.000 --> 00:24:17.000
Những hương vị này chỉ có thể được đặt bởi người dùng trong Trung tâm điều khiển, nhưng bạn có thể đọc và quan sát trạng thái của chúng bằng cách sử dụng MicrophoneMode ưa thích của AVCaptureDevice - là chế độ do người dùng chọn - và activeMicrophoneMode - là chế độ hiện đang được sử dụng, có tính đến tuyến âm thanh hiện tại,

00:24:17.000 --> 00:24:24.000
Để sử dụng Chế độ Mic, ứng dụng của bạn phải sử dụng đơn vị âm thanh Core Audio AUVoiceIO.

00:24:24.000 --> 00:24:30.000
Đây là một giao diện phổ biến trong các ứng dụng hội nghị truyền hình, vì nó thực hiện hủy tiếng vang.

00:24:30.000 --> 00:24:38.000
Và xử lý Chế độ Mic chỉ khả dụng trên các thiết bị iOS và macOS 2018 trở lên.

00:24:38.000 --> 00:24:51.000
Với Chế độ Chân dung và Mic, người dùng luôn kiểm soát, nhưng bạn có thể nhắc họ tắt hoặc bật tính năng bằng cách gọi phương thức AVCaptureDevice .showSystemUserInterface mới.

00:24:51.000 --> 00:24:57.000
Và bạn có thể chuyển nó hoặc videoEffects hoặc microphoneModes.

00:24:57.000 --> 00:25:02.000
Gọi API này sẽ mở Trung tâm điều khiển và các liên kết sâu đến mô-đun con thích hợp.

00:25:02.000 --> 00:25:12.000
Ở đây, chúng tôi đang đi sâu vào mô-đun Hiệu ứng Video, nơi người dùng có thể chọn tắt Chân dung.

00:25:12.000 --> 00:25:17.000
Điều đó kết thúc Chân dung và kết thúc Hiệu ứng Video trong Trung tâm Điều khiển.

00:25:17.000 --> 00:25:26.000
Tôi vừa cho bạn xem các ví dụ về các tính năng máy ảnh cấp hệ thống được đưa vào ứng dụng của bạn mà không cần bạn thay đổi một dòng mã - một khái niệm khá mạnh mẽ!

00:25:26.000 --> 00:25:38.000
Có một phiên đồng hành với phiên này được gọi là "Chụp ảnh chất lượng cao bằng định dạng video", nơi bạn sẽ tìm hiểu về những cải tiến mà chúng tôi đã thực hiện để giữ chất lượng hình ảnh trong ứng dụng của mình mà không cần bạn thay đổi dòng mã.

00:25:38.000 --> 00:25:41.000
Vui lòng kiểm tra nó.

00:25:41.000 --> 00:25:43.000
Chúng tôi đã đề cập đến rất nhiều tính năng mới.

00:25:43.000 --> 00:25:48.000
Tại thời điểm này trong phiên, tôi muốn nghỉ ngơi và nói về hiệu suất.

00:25:48.000 --> 00:25:56.000
Center Stage và Portrait là những tính năng tuyệt vời của người dùng, nhưng chúng có thêm chi phí hiệu suất.

00:25:56.000 --> 00:26:04.000
Vì vậy, hãy xem lại các phương pháp hay nhất về hiệu suất để đảm bảo các ứng dụng máy ảnh của bạn đã sẵn sàng cho các tính năng mới như Chân dung và Sân khấu Trung tâm.

00:26:04.000 --> 00:26:09.000
Các ứng dụng máy ảnh sử dụng các lớp AVCapture để cung cấp một loạt các tính năng.

00:26:09.000 --> 00:26:21.000
Giao diện phổ biến nhất là AVCaptureVideoDataOutput, cho phép bạn lấy khung hình video trực tiếp đến quy trình thao tác, hiển thị, mã hóa, ghi...

00:26:21.000 --> 00:26:23.000
Bạn đặt tên cho nó.

00:26:23.000 --> 00:26:31.000
Khi sử dụng VideoDataOutput, điều quan trọng là phải đảm bảo rằng ứng dụng của bạn luôn cập nhật thời hạn theo thời gian thực để không bị rơi khung hình.

00:26:31.000 --> 00:26:40.000
Theo mặc định, VideoDataOutput ngăn bạn quay lại phía sau bằng cách đặt thuộc tính alwaysDiscardsLateVideoFrames của nó thành true.

00:26:40.000 --> 00:26:55.000
Điều này thực thi kích thước hàng đợi bộ đệm ở cuối đường ống xử lý đầu ra dữ liệu video và giúp bạn tránh khỏi quá trình xử lý chậm định kỳ hoặc mãn tính bằng cách luôn cung cấp cho bạn khung hình mới nhất và thả các khung hình mà bạn chưa sẵn sàng xử lý.

00:26:55.000 --> 00:27:00.000
Nó không giúp ích gì cho bạn nếu bạn cần ghi lại các khung hình bạn đang nhận được, chẳng hạn như với AVAssetWriter.

00:27:00.000 --> 00:27:12.000
Nếu bạn có ý định ghi lại kết quả đã xử lý của mình, bạn nên tắt alwaysDiscardsLateVideoFrames và chú ý đến thời gian xử lý của mình.

00:27:12.000 --> 00:27:21.000
VideoDataOutput cho bạn biết khi nào khung hình bị rớt xảy ra bằng cách gọi cuộc gọi lại đại diện captureOutput didDrop sampleBuffer được cung cấp của bạn.

00:27:21.000 --> 00:27:29.000
Khi bạn nhận được cuộc gọi lại didDrop, bạn có thể kiểm tra các tệp đính kèm của sampleBuffer để tìm một lý do Khung bị bỏ rơi.

00:27:29.000 --> 00:27:33.000
Điều này có thể thông báo phải làm gì để giảm thiểu sự sụt giảm khung hình tiếp theo.

00:27:33.000 --> 00:27:53.000
Có ba lý do: FrameWasLate, có nghĩa là quá trình xử lý của bạn mất quá nhiều thời gian; OutOfBuffers, có nghĩa là bạn có thể đang giữ quá nhiều bộ đệm; và Discontinuity, có nghĩa là hệ thống chậm lại hoặc lỗi phần cứng không phải lỗi của bạn.

00:27:53.000 --> 00:27:56.000
Bây giờ hãy nói về cách phản ứng với việc rơi khung hình.

00:27:56.000 --> 00:28:00.000
Một trong những cách tốt nhất là giảm tốc độ khung hình thiết bị một cách linh hoạt.

00:28:00.000 --> 00:28:04.000
Làm như vậy không phát sinh trục trặc trong bản xem trước hoặc đầu ra.

00:28:04.000 --> 00:28:10.000
Bạn chỉ cần đặt một activeMinVideoFrameDuration mới trên AVCaptureDevice của mình trong thời gian chạy.

00:28:10.000 --> 00:28:18.000
Cách thứ hai là đơn giản hóa khối lượng công việc của bạn để bạn không mất quá nhiều thời gian.

00:28:18.000 --> 00:28:26.000
Bây giờ hãy nói về áp lực hệ thống, một chỉ số hiệu suất khác cực kỳ quan trọng đối với trải nghiệm người dùng tốt trong ứng dụng máy ảnh của bạn.

00:28:26.000 --> 00:28:32.000
Áp suất hệ thống có nghĩa là, hệ thống có thể bị căng thẳng hoặc áp lực.

00:28:32.000 --> 00:28:40.000
AVCaptureDevice có một thuộc tính được gọi là systemPressureState, bao gồm các yếu tố và mức tổng thể.

00:28:40.000 --> 00:28:47.000
Các yếu tố đóng góp của SystemPressureState là một chút mặt nạ của ba người đóng góp có thể.

00:28:47.000 --> 00:28:51.000
Nhiệt độ hệ thống đề cập đến mức độ nóng của thiết bị.

00:28:51.000 --> 00:29:00.000
peakPower là tất cả về sự lão hóa pin và liệu pin có khả năng tăng điện áp đủ nhanh để đáp ứng nhu cầu năng lượng cực đại hay không.

00:29:00.000 --> 00:29:08.000
Và depthModuleTemperature, đề cập đến mức độ nóng của cảm biến hồng ngoại của máy ảnh TrueDepth.

00:29:08.000 --> 00:29:16.000
Cấp độ của SystemPressureState là một chỉ báo có thể giúp bạn hành động trước khi trải nghiệm người dùng của bạn bị xâm phạm.

00:29:16.000 --> 00:29:19.000
Khi nó là danh nghĩa, mọi thứ đều là copacetic.

00:29:19.000 --> 00:29:23.000
Công bằng chỉ ra rằng áp suất hệ thống tăng nhẹ.

00:29:23.000 --> 00:29:29.000
Điều này có thể xảy ra ngay cả khi bạn đang xử lý rất ít nhưng nhiệt độ môi trường cao.

00:29:29.000 --> 00:29:35.000
Ở mức độ nghiêm trọng, áp suất hệ thống tăng cao; hiệu suất chụp có thể bị ảnh hưởng.

00:29:35.000 --> 00:29:38.000
Nên điều chỉnh tốc độ khung hình.

00:29:38.000 --> 00:29:47.000
Một khi bạn đạt đến mức quan trọng, áp lực hệ thống sẽ tăng lên nghiêm trọng; chất lượng và hiệu suất chụp được ảnh hưởng đáng kể.

00:29:47.000 --> 00:29:50.000
Điều chỉnh tốc độ khung hình rất được khuyến khích.

00:29:50.000 --> 00:29:57.000
Và bạn không bao giờ muốn để mọi thứ leo thang đến mức tắt máy, nơi mà áp lực hệ thống vượt quá mức quan trọng.

00:29:57.000 --> 00:30:05.000
Ở cấp độ này, AVCaptureSession dừng tự động để cứu thiết bị khỏi bẫy nhiệt.

00:30:05.000 --> 00:30:09.000
Bạn có thể phản ứng với áp lực tăng cao theo nhiều cách khác nhau.

00:30:09.000 --> 00:30:14.000
Giảm tốc độ khung hình chụp; điều này sẽ luôn giúp áp lực hệ thống.

00:30:14.000 --> 00:30:22.000
Nếu giảm tốc độ khung hình không phải là một lựa chọn, hãy cân nhắc giảm khối lượng công việc của bạn trên CPU hoặc GPU, chẳng hạn như tắt một số tính năng nhất định.

00:30:22.000 --> 00:30:31.000
Bạn cũng có thể giữ các tính năng nhưng làm giảm chất lượng, có lẽ chỉ bằng cách xử lý độ phân giải nhỏ hơn hoặc ít thường xuyên hơn.

00:30:31.000 --> 00:30:41.000
AVCaptureSession không bao giờ thay mặt bạn điều chỉnh tốc độ khung hình, vì chúng tôi không biết đó có phải là chiến lược suy giảm chất lượng chấp nhận được cho ứng dụng của bạn hay không.

00:30:41.000 --> 00:30:43.000
Điều đó kết thúc các phương pháp hay nhất về hiệu suất.

00:30:43.000 --> 00:30:49.000
Bây giờ vào khóa học tráng miệng của chúng tôi, nén bề mặt IOS.

00:30:49.000 --> 00:31:04.000
Tôi cẩn thận tránh nói về băng thông bộ nhớ trong phần hiệu suất, vì bạn không thể làm gì nhiều về các yêu cầu băng thông bộ nhớ tổng thể của video chảy qua ISP và cuối cùng là ảnh, phim, bản xem trước hoặc bộ đệm của bạn.

00:31:04.000 --> 00:31:12.000
Tuy nhiên, băng thông bộ nhớ có thể là một giới hạn quan trọng trong việc xác định tính năng máy ảnh nào có thể chạy đồng thời.

00:31:12.000 --> 00:31:18.000
Khi làm việc với video không nén trên iOS và macOS, có rất nhiều lớp liên quan.

00:31:18.000 --> 00:31:21.000
Nó hơi giống một con búp bê làm tổ của Nga.

00:31:21.000 --> 00:31:31.000
Ở cấp độ cao nhất là CMSampleBuffer, có thể bao bọc tất cả các loại dữ liệu phương tiện, cũng như thời gian và siêu dữ liệu.

00:31:31.000 --> 00:31:40.000
Xuống một cấp độ, có CVPixelBuffer, đặc biệt bọc dữ liệu bộ đệm pixel cùng với các tệp đính kèm siêu dữ liệu.

00:31:40.000 --> 00:31:52.000
Cuối cùng, bạn đạt đến mức thấp nhất đó, bề mặt IOS, cho phép bộ nhớ được kết nối với hạt nhân, cũng như cung cấp một giao diện để chia sẻ bộ đệm video lớn giữa các quy trình.

00:31:52.000 --> 00:31:54.000
Bề mặt IOS rất lớn.

00:31:54.000 --> 00:31:59.000
Chúng giải thích cho các yêu cầu băng thông bộ nhớ tuyệt vời của video không nén.

00:31:59.000 --> 00:32:05.000
Rất may, nén bề mặt IOS cung cấp giải pháp cho các vấn đề về băng thông bộ nhớ.

00:32:05.000 --> 00:32:12.000
Mới trong iOS 15, chúng tôi đang giới thiệu hỗ trợ cho định dạng nén video trong bộ nhớ không mất dữ liệu.

00:32:12.000 --> 00:32:17.000
Đó là một sự tối ưu hóa để giảm tổng băng thông bộ nhớ cho video trực tiếp.

00:32:17.000 --> 00:32:23.000
Đó là một định dạng trao đổi được hiểu bởi các khối phần cứng chính trên các thiết bị iOS và Mac.

00:32:23.000 --> 00:32:36.000
Nó có sẵn trên tất cả các biến thể iPhone 12, iPad Airs mùa thu 2020 và iPad Pro M1 mùa xuân 2021.

00:32:36.000 --> 00:32:40.000
Những khối phần cứng chính nào giao dịch trong các bề mặt IOS nén?

00:32:40.000 --> 00:32:43.000
Chà, có rất nhiều.

00:32:43.000 --> 00:32:51.000
Tất cả các dịch vụ được liệt kê ở đây đều hiểu cách đọc hoặc ghi các bề mặt IOS nén.

00:32:51.000 --> 00:32:56.000
Tại thời điểm này bạn có thể nói, "Tuyệt vời, làm thế nào để tôi đăng ký?"

00:32:56.000 --> 00:32:57.000
Chà, tin tốt.

00:32:57.000 --> 00:33:12.000
Nếu bạn đang quay video trên phần cứng được hỗ trợ và AVCaptureSession không cần cung cấp bất kỳ bộ đệm nào cho quy trình của bạn, xin chúc mừng, phiên của bạn đã tận dụng khả năng nén bề mặt IOS bất cứ khi nào có thể để giảm băng thông bộ nhớ.

00:33:12.000 --> 00:33:20.000
Nếu bạn muốn các bề mặt nén được phân phối đến đầu ra dữ liệu video của mình, bạn cần biết về một vài quy tắc.

00:33:20.000 --> 00:33:35.000
Bố cục bộ nhớ vật lý không rõ ràng và có thể thay đổi, vì vậy đừng ghi vào đĩa, đừng giả định bố cục giống nhau trên tất cả các nền tảng, không đọc hoặc ghi bằng CPU.

00:33:35.000 --> 00:33:40.000
AVCaptureVideoDataOutput hỗ trợ một số hương vị nén bề mặt IOS.

00:33:40.000 --> 00:33:51.000
Trước đó trong cuộc nói chuyện, bạn đã biết rằng máy ảnh iOS tự nhiên hỗ trợ các định dạng YUV 420v và 420f - 8-bit; một video và một phạm vi đầy đủ.

00:33:51.000 --> 00:33:57.000
Và sau đó, bạn đã học về x420, một định dạng video HDR 10-bit.

00:33:57.000 --> 00:34:05.000
Đầu ra dữ liệu video cũng có thể mở rộng nội bộ thành BGRA 16-bits-per-pixel nếu được yêu cầu.

00:34:05.000 --> 00:34:14.000
Mỗi cái trong số này có một bề mặt nén tương đương IOS, bắt đầu từ iOS 15, bạn có thể yêu cầu thông qua AVCaptureVideoDataOutput.

00:34:14.000 --> 00:34:20.000
Nếu bạn là một fan hâm mộ của ampersands trong mã bốn ký tự của mình, đây là ngày may mắn của bạn.

00:34:20.000 --> 00:34:23.000
Đây là một lần nữa ở định dạng biểu đồ mắt.

00:34:23.000 --> 00:34:28.000
Đây là những hằng số thực tế bạn nên sử dụng trong mã của mình.

00:34:28.000 --> 00:34:33.000
Hai năm trước, chúng tôi đã phát hành một đoạn mã mẫu có tên là "AVMultiCamPiP".

00:34:33.000 --> 00:34:53.000
Trong mẫu này, các camera trước và sau được truyền đồng thời đến VideoDataOutputs bằng cách sử dụng phiên multicam, sau đó được tổng hợp dưới dạng Picture in Picture bằng cách sử dụng bộ đổ bóng Metal, sau đó hiển thị hỗn hợp để xem trước và ghi vào phim bằng AVAssetWriter.

00:34:53.000 --> 00:35:01.000
Đây là ứng cử viên hoàn hảo cho việc nén bề mặt IOS vì tất cả các thao tác này được thực hiện trên phần cứng.

00:35:01.000 --> 00:35:06.000
Đây là mã thiết lập VideoDataOutput hiện có trong AVMultiCamPiP.

00:35:06.000 --> 00:35:16.000
Nó thích làm việc với BGRA, vì vậy nó định cấu hình Cài đặt video của VideoDataOutput để tạo ra loại định dạng pixel đó.

00:35:16.000 --> 00:35:19.000
Mã mới chỉ kết hợp một số kiểm tra.

00:35:19.000 --> 00:35:25.000
Đầu tiên nó xem liệu phiên bản nén bề mặt IOS của BGRA có khả dụng hay không.

00:35:25.000 --> 00:35:31.000
Và nếu vậy, nó chọn điều đó; mệnh đề else chỉ ở đó như một dự phòng.

00:35:31.000 --> 00:35:35.000
Và cứ như vậy, chúng ta đã đi đến cuối cùng.

00:35:35.000 --> 00:35:52.000
Bạn đã học về báo cáo khoảng cách lấy nét tối thiểu, cách quay video HDR 10-bit, Hiệu ứng video và Chế độ Mic trong Trung tâm điều khiển, các phương pháp hay nhất về hiệu suất và nén bề mặt IOS.

00:35:52.000 --> 00:35:54.000
Tôi hy vọng bạn thích nó!

00:35:54.000 --> 00:35:55.000
Cảm ơn vì đã xem.

00:35:55.000 --> 23:59:59.000
♪

