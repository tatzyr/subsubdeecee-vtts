WEBVTT

00:00:00.000 --> 00:00:05.000
♪ Nhạc bass đang phát ♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:12.000
Sergey Kamensky: Xin chào mọi người và chào mừng đến với WWDC.

00:00:12.000 --> 00:00:15.000
Tên tôi là Sergey Kamensky và tôi là một kỹ sư phần mềm trong nhóm khung Vision.

00:00:15.000 --> 00:00:20.000
Chủ đề của phiên hôm nay là chỉ ra cách khung Tầm nhìn có thể giúp phân tích con người.

00:00:20.000 --> 00:00:23.000
Chương trình nghị sự của chúng tôi hôm nay bao gồm hai mục chính.

00:00:23.000 --> 00:00:27.000
Đầu tiên chúng ta sẽ có một cái nhìn tổng quan về công nghệ phân tích con người trong khuôn khổ Tầm nhìn.

00:00:27.000 --> 00:00:31.000
Trong khi làm điều đó, chúng tôi sẽ đặc biệt tập trung vào những bổ sung mới.

00:00:31.000 --> 00:00:37.000
Và thứ hai, chúng ta sẽ có đánh giá chuyên sâu về tính năng phân khúc người mới.

00:00:37.000 --> 00:00:40.000
Trước tiên hãy bắt đầu với công nghệ phân tích con người.

00:00:40.000 --> 00:00:44.000
Nền tảng của phân tích con người trong Tầm nhìn là phân tích khuôn mặt con người.

00:00:44.000 --> 00:00:49.000
Kể từ khi bắt đầu khuôn khổ Tầm nhìn, chúng tôi đã bổ sung và nâng cao khả năng phân tích khuôn mặt con người.

00:00:49.000 --> 00:00:56.000
Chúng tôi hiện đang cung cấp tính năng phát hiện khuôn mặt, phát hiện mốc khuôn mặt và phát hiện chất lượng chụp khuôn mặt.

00:00:56.000 --> 00:01:02.000
Chức năng phát hiện khuôn mặt trong khung Vision được hiển thị bằng phương tiện DetectFaceRectanglesRequest.

00:01:02.000 --> 00:01:11.000
Máy dò khuôn mặt của chúng tôi cung cấp các chỉ số thu hồi và độ chính xác cao, nó có thể tìm thấy các khuôn mặt có hướng tùy ý, kích thước khác nhau và cũng bị che khuất một phần.

00:01:11.000 --> 00:01:15.000
Cho đến nay chúng tôi đã hỗ trợ các tắc nghẽn như kính và mũ.

00:01:15.000 --> 00:01:26.000
Bây giờ chúng tôi đang nâng cấp máy dò khuôn mặt của mình lên bản sửa đổi số ba, ngoài việc cải thiện tất cả các phẩm chất tuyệt vời hiện có, giờ đây cũng có thể phát hiện các khuôn mặt được che bởi mặt nạ.

00:01:26.000 --> 00:01:33.000
Chức năng chính của máy dò khuôn mặt của chúng tôi tất nhiên là tìm hộp giới hạn khuôn mặt, nhưng nó cũng có thể phát hiện các chỉ số tư thế khuôn mặt.

00:01:33.000 --> 00:01:36.000
Trước đây, chúng tôi chỉ cung cấp các chỉ số liệu cuộn và ngáp.

00:01:36.000 --> 00:01:41.000
Hầu hết các số liệu được báo cáo bằng radian và giá trị của chúng được trả về trong các thùng rời rạc.

00:01:41.000 --> 00:01:47.000
Với phần giới thiệu sửa đổi mới, chúng tôi cũng đang thêm một số liệu cao độ và do đó hoàn thành bức tranh đầy đủ.

00:01:47.000 --> 00:01:49.000
Nhưng chúng tôi đã không dừng lại ở đó.

00:01:49.000 --> 00:01:54.000
Chúng tôi cũng đang báo cáo cả ba số liệu trong không gian liên tục.

00:01:54.000 --> 00:02:03.000
Tất cả các chỉ số tư thế khuôn mặt được trả về dưới dạng thuộc tính của đối tượng FaceObservation của chúng tôi, đó là kết quả của việc thực hiện Yêu cầu DetectFaceRectangles.

00:02:03.000 --> 00:02:08.000
Hãy xem ứng dụng demo được thiết kế để hiển thị chức năng phát hiện tư thế khuôn mặt.

00:02:08.000 --> 00:02:16.000
Ứng dụng xử lý nguồn cấp dữ liệu máy ảnh bằng cách chạy máy dò khuôn mặt Vision và trình bày số liệu tư thế khuôn mặt cho người dùng sau khi chuyển đổi kết quả từ radian sang độ.

00:02:16.000 --> 00:02:28.000
Để theo dõi tốt hơn các thay đổi số liệu, ứng dụng sử dụng gradient màu đỏ để hiển thị khi số liệu tư thế khuôn mặt tăng theo hướng dương và gradient màu xanh lam để hiển thị khi số liệu tăng theo hướng âm.

00:02:28.000 --> 00:02:33.000
Trong cả hai trường hợp, màu càng nhạt, số liệu càng gần vị trí 0.

00:02:33.000 --> 00:02:41.000
Vị trí 0 cho mỗi số liệu là cái mà bạn sẽ gọi là vị trí trung lập của đầu người, khi người đó nhìn thẳng - giống như thế này.

00:02:41.000 --> 00:02:46.000
Như chúng ta đã thảo luận, chúng ta có ba chỉ số tư thế khuôn mặt: cuộn, ngáp và cao độ.

00:02:46.000 --> 00:02:53.000
Những thuật ngữ này xuất phát từ động lực bay và chúng mô tả các trục nguyên lý của máy bay đối với trọng tâm của máy bay.

00:02:53.000 --> 00:02:57.000
Các thuật ngữ tương tự cũng đã được áp dụng để mô tả tư thế đầu của con người.

00:02:57.000 --> 00:03:03.000
Khi áp dụng cho tư thế đầu - hoặc như chúng ta cũng gọi nó, tư thế khuôn mặt - chúng theo dõi chuyển động đầu của con người như sau.

00:03:03.000 --> 00:03:09.000
Roll đang theo dõi chuyển động của đầu theo hướng này.

00:03:09.000 --> 00:03:25.000
Khi tôi chuyển từ giá trị tiêu cực nhất sang tích cực nhất của cuộn, bạn có thể thấy rằng màu nền thay đổi từ xanh đậm sang xanh nhạt, trung tính, sau đó là đỏ nhạt và cuối cùng là đỏ sẫm.

00:03:25.000 --> 00:03:33.000
Những thay đổi màu sắc tương tự đang xảy ra với số liệu ngáp, đang theo dõi góc khi đầu quay sang phải hoặc trái.

00:03:33.000 --> 00:03:40.000
Và cuối cùng, số liệu cao độ đang theo dõi chuyển động đầu của tôi khi đầu tôi gật đầu lên hoặc xuống.

00:03:40.000 --> 00:03:50.000
Ở đây bạn có thể thấy lại những thay đổi màu sắc tương tự khi tôi đi từ đầu tiêu cực nhất đến đầu tích cực nhất của quang phổ.

00:03:50.000 --> 00:03:55.000
Phát hiện mốc khuôn mặt là một chức năng quan trọng khác của bộ phân tích khuôn mặt của chúng tôi.

00:03:55.000 --> 00:04:02.000
Phát hiện mốc khuôn mặt được cung cấp bằng phương tiện DetectFaceLandmarksRequest và bản sửa đổi mới nhất là bản sửa đổi số ba.

00:04:02.000 --> 00:04:12.000
Bản sửa đổi này cung cấp chòm sao 76 điểm để thể hiện tốt hơn các vùng khuôn mặt chính và cũng cung cấp khả năng phát hiện đồng tử chính xác.

00:04:12.000 --> 00:04:16.000
Bộ phân tích khuôn mặt cũng bao gồm phát hiện chất lượng chụp khuôn mặt.

00:04:16.000 --> 00:04:25.000
Biện pháp tổng thể này tính đến các thuộc tính như biểu cảm khuôn mặt con người, ánh sáng, tắc nghẽn, mờ, lấy nét, v.v.

00:04:25.000 --> 00:04:33.000
Nó được hiển thị thông qua DetectFaceCaptureQualityRequest API và bản sửa đổi mới nhất của yêu cầu này là bản sửa đổi số hai.

00:04:33.000 --> 00:04:38.000
Điều quan trọng cần nhớ là chất lượng chụp khuôn mặt là thước đo so sánh của cùng một chủ đề.

00:04:38.000 --> 00:04:46.000
Tính năng này hoạt động rất tốt, ví dụ, để chọn bức ảnh đẹp nhất trong loạt ảnh bùng nổ hoặc để chọn bức ảnh đẹp nhất để đại diện cho một người trong thư viện ảnh.

00:04:46.000 --> 00:04:52.000
Tính năng này không được thiết kế để so sánh khuôn mặt của những người khác nhau.

00:04:52.000 --> 00:04:57.000
Phân tích cơ thể con người là một phần lớn khác của công nghệ phân tích con người được cung cấp bởi khung Tầm nhìn.

00:04:57.000 --> 00:05:07.000
Tầm nhìn cung cấp một số chức năng trong lĩnh vực này, bao gồm phát hiện cơ thể người, phát hiện tư thế người và cuối cùng nhưng không kém phần quan trọng, phát hiện tư thế bàn tay người.

00:05:07.000 --> 00:05:10.000
Đầu tiên chúng ta hãy xem xét việc phát hiện cơ thể con người.

00:05:10.000 --> 00:05:17.000
Chức năng này được cung cấp thông qua DetectHumanRectanglesRequest và hiện tại nó chỉ phát hiện phần thân trên của con người.

00:05:17.000 --> 00:05:25.000
Chúng tôi đang thêm chức năng mới vào yêu cầu này, và do đó nâng cấp bản sửa đổi này lên bản sửa đổi số hai.

00:05:25.000 --> 00:05:31.000
Với bản sửa đổi mới, ngoài tính năng phát hiện phần thân trên, chúng tôi cũng cung cấp tính năng phát hiện toàn thân.

00:05:31.000 --> 00:05:39.000
Sự lựa chọn giữa phát hiện phần thân trên và phần thân trên được kiểm soát thông qua thuộc tính upperBodyOnly mới của DetectHumanRectanglesRequest.

00:05:39.000 --> 00:05:45.000
Giá trị mặc định cho thuộc tính này được đặt thành true để duy trì khả năng tương thích ngược.

00:05:45.000 --> 00:05:50.000
Phát hiện tư thế cơ thể con người được cung cấp trong khuôn khổ Tầm nhìn thông qua DetectHumanBodyPoseRequest.

00:05:50.000 --> 00:05:55.000
Xử lý yêu cầu này cung cấp một bộ sưu tập các vị trí khớp của cơ thể người.

00:05:55.000 --> 00:06:02.000
Bản sửa đổi số một là bản sửa đổi mới nhất và duy nhất có sẵn của yêu cầu này.

00:06:02.000 --> 00:06:07.000
Khung tầm nhìn cũng cung cấp khả năng phát hiện tư thế bàn tay người dưới dạng DetectHumanHandPoseRequest.

00:06:07.000 --> 00:06:16.000
Tương tự như phát hiện tư thế cơ thể con người, việc xử lý yêu cầu tư thế tay trả về một bộ sưu tập các vị trí khớp tay người.

00:06:16.000 --> 00:06:23.000
Chúng tôi đang nâng cấp chức năng của yêu cầu này bằng cách thêm một thuộc tính quan trọng vào kết quả quan sát, tính chirality bằng tay.

00:06:23.000 --> 00:06:30.000
Thuộc tính chirality mới của HumanHandPoseObservation sẽ chứa thông tin cho dù bàn tay được phát hiện là trái hay phải.

00:06:30.000 --> 00:06:41.000
Nếu bạn muốn tìm hiểu thêm chi tiết về phát hiện tư thế tay, tôi khuyên bạn nên xem phiên "Phân loại tư thế và hành động tay với Tạo ML".

00:06:41.000 --> 00:06:46.000
Điều này kết thúc tổng quan của chúng tôi về các nâng cấp mới cho bộ công nghệ phân tích con người.

00:06:46.000 --> 00:06:53.000
Bây giờ là lúc chuyển sang chủ đề thứ hai trong phiên của chúng tôi, đó là phân khúc người.

00:06:53.000 --> 00:06:55.000
Phân khúc người là gì?

00:06:55.000 --> 00:07:00.000
Nói một cách rất đơn giản, đó là khả năng tách mọi người khỏi hiện trường.

00:07:00.000 --> 00:07:04.000
Ngày nay có rất nhiều ứng dụng của công nghệ phân khúc con người.

00:07:04.000 --> 00:07:09.000
Ví dụ, tất cả các bạn đều quen thuộc với tính năng nền ảo trên các ứng dụng hội nghị truyền hình.

00:07:09.000 --> 00:07:13.000
Nó cũng được sử dụng trong phân tích thể thao trực tiếp, lái xe tự động và nhiều nơi khác.

00:07:13.000 --> 00:07:19.000
Phân đoạn người cũng cung cấp năng lượng cho chế độ Chân dung nổi tiếng của chúng tôi.

00:07:19.000 --> 00:07:23.000
Phân đoạn người trong khung Tầm nhìn là một tính năng được thiết kế để hoạt động với một khung duy nhất.

00:07:23.000 --> 00:07:28.000
Bạn có thể sử dụng nó trong đường ống phát trực tuyến và nó cũng phù hợp cho việc xử lý ngoại tuyến.

00:07:28.000 --> 00:07:38.000
Tính năng này được hỗ trợ trên nhiều nền tảng như macOS, iOS, iPadOS và tvOS.

00:07:38.000 --> 00:07:48.000
Khung tầm nhìn thực hiện phân đoạn người ngữ nghĩa, có nghĩa là nó sẽ trả lại một mặt nạ duy nhất cho tất cả mọi người trong khung.

00:07:48.000 --> 00:07:56.000
Vision API cho phân khúc người được triển khai bằng GeneratePersonSegmentationRequest, Đây là một yêu cầu trạng thái.

00:07:56.000 --> 00:08:03.000
Trái ngược với các yêu cầu truyền thống trong khung Vision, các đối tượng yêu cầu trạng thái được sử dụng lại trong toàn bộ chuỗi khung.

00:08:03.000 --> 00:08:10.000
Trong trường hợp cụ thể của chúng tôi, việc sử dụng đối tượng yêu cầu giúp làm mịn các thay đổi thời gian giữa các khung trong mô hình mức chất lượng nhanh.

00:08:10.000 --> 00:08:15.000
Chúng ta hãy xem API Phân đoạn Cá nhân được cung cấp bởi khung Tầm nhìn.

00:08:15.000 --> 00:08:18.000
API này tuân theo một mô hình đã quen thuộc và đã được thiết lập.

00:08:18.000 --> 00:08:27.000
Tạo một yêu cầu, tạo một trình xử lý yêu cầu, xử lý yêu cầu của bạn với trình xử lý yêu cầu và cuối cùng, xem lại kết quả.

00:08:27.000 --> 00:08:37.000
Khởi tạo mặc định của đối tượng GeneratePersonSegmentationRequest tương đương với việc thiết lập các thuộc tính sửa đổi, qualityLevel và outputPixelFormat thành các giá trị mặc định của chúng.

00:08:37.000 --> 00:08:41.000
Hãy xem lại từng tài sản một.

00:08:41.000 --> 00:08:43.000
Đầu tiên là thuộc tính sửa đổi.

00:08:43.000 --> 00:08:46.000
Ở đây chúng tôi đặt bản sửa đổi thành bản sửa đổi số một.

00:08:46.000 --> 00:08:51.000
Đây là bản sửa đổi mặc định và duy nhất có sẵn, vì chúng tôi đang xử lý loại yêu cầu mới.

00:08:51.000 --> 00:08:58.000
Mặc dù về mặt kỹ thuật không có lựa chọn nào ở đây ngày hôm nay, chúng tôi luôn khuyên bạn nên thiết lập rõ ràng để đảm bảo hành vi xác định trong tương lai.

00:08:58.000 --> 00:09:06.000
Điều này là do nếu các bản sửa đổi mới được giới thiệu, mặc định cũng sẽ thay đổi để đại diện cho bản sửa đổi mới nhất có sẵn.

00:09:06.000 --> 00:09:09.000
Thứ hai là tài sản qualityLevel.

00:09:09.000 --> 00:09:16.000
Vision API cung cấp ba cấp độ khác nhau: chính xác, cũng là cấp độ mặc định; cân bằng; và nhanh chóng.

00:09:16.000 --> 00:09:22.000
Theo như các trường hợp sử dụng, chúng tôi khuyên bạn nên sử dụng mức độ chính xác để chụp ảnh tính toán.

00:09:22.000 --> 00:09:29.000
Đây là trường hợp sử dụng mà bạn muốn đạt được chất lượng cao nhất có thể và thường không bị giới hạn về thời gian.

00:09:29.000 --> 00:09:37.000
Sử dụng logic tương tự, mức cân bằng được khuyến nghị cho phân đoạn video theo từng khung hình và nhanh chóng để xử lý phát trực tuyến.

00:09:37.000 --> 00:09:40.000
Thuộc tính thứ ba là định dạng mặt nạ đầu ra.

00:09:40.000 --> 00:09:50.000
Chúng tôi sẽ xem xét chi tiết mặt nạ kết quả, nhưng ở đây tôi muốn đề cập rằng, với tư cách là khách hàng, bạn có thể chỉ định định dạng mặt nạ kết quả sẽ được trả lại.

00:09:50.000 --> 00:10:02.000
Có ba lựa chọn ở đây: mặt nạ nguyên 8 bit không dấu với phạm vi lượng tử hóa từ 0 đến 255 điển hình và hai định dạng mặt nạ dấu phẩy động - một định dạng có độ chính xác đầy đủ 32 bit và một định dạng khác có độ chính xác một nửa 16 bit.

00:10:02.000 --> 00:10:14.000
Độ chính xác một nửa 16 bit nhằm cung cấp cho bạn định dạng dấu phẩy động bộ nhớ giảm có thể được chèn trực tiếp vào quá trình xử lý dựa trên GPU hơn nữa với Metal.

00:10:14.000 --> 00:10:19.000
Cho đến nay chúng tôi đã học được cách tạo, cấu hình và thực hiện yêu cầu phân đoạn người của mình.

00:10:19.000 --> 00:10:22.000
Bây giờ là lúc để xem kết quả.

00:10:22.000 --> 00:10:28.000
Kết quả của việc xử lý yêu cầu phân đoạn người đến dưới dạng đối tượng PixelBufferObservation.

00:10:28.000 --> 00:10:35.000
PixelBufferObservation bắt nguồn từ quan sát và nó bổ sung một thuộc tính pixelBuffer quan trọng.

00:10:35.000 --> 00:10:45.000
Đối tượng CVPixelBuffer thực tế được lưu trữ trong thuộc tính này có cùng định dạng pixel với yêu cầu phân đoạn người của chúng tôi đã được định cấu hình.

00:10:45.000 --> 00:10:49.000
Việc xử lý yêu cầu phân đoạn người sẽ tạo ra mặt nạ phân đoạn.

00:10:49.000 --> 00:10:57.000
Hãy nhìn vào hình ảnh gốc và ba mặt nạ mức chất lượng khác nhau được tạo ra bằng cách thực hiện yêu cầu phân đoạn người.

00:10:57.000 --> 00:11:02.000
Nhanh chóng, cân bằng và chính xác.

00:11:02.000 --> 00:11:05.000
Hãy phóng to để xem chi tiết của từng mặt nạ.

00:11:05.000 --> 00:11:15.000
Đúng như dự đoán, khi chúng ta đi từ nhanh đến cân bằng và cuối cùng đến chính xác, chất lượng của mặt nạ tăng lên và chúng ta sẽ bắt đầu thấy ngày càng nhiều chi tiết.

00:11:15.000 --> 00:11:21.000
Bây giờ hãy kiểm tra các mức mặt nạ khác nhau như một chức năng của chất lượng so với hiệu suất.

00:11:21.000 --> 00:11:30.000
Khi chúng ta chuyển từ nhanh sang cân bằng, và cuối cùng sang chính xác, chất lượng của mặt nạ sẽ tăng lên nhưng việc sử dụng tài nguyên cũng vậy.

00:11:30.000 --> 00:11:36.000
Phạm vi động, độ phân giải mặt nạ, mức tiêu thụ bộ nhớ, thời gian xử lý đều tăng lên khi chất lượng mặt nạ tăng lên.

00:11:36.000 --> 00:11:46.000
Điều này thể hiện sự đánh đổi giữa chất lượng của mặt nạ phân đoạn và mức tiêu thụ tài nguyên cần thiết để tính toán mặt nạ.

00:11:46.000 --> 00:11:50.000
Vì vậy, bạn đã biết mọi thứ về việc tạo mặt nạ và tính chất của chúng.

00:11:50.000 --> 00:11:54.000
Bạn thực sự có thể làm gì với mặt nạ?

00:11:54.000 --> 00:11:56.000
Hãy bắt đầu với ba hình ảnh.

00:11:56.000 --> 00:12:03.000
Hình ảnh đầu vào, mặt nạ phân đoạn thu được bằng cách xử lý hình ảnh đầu vào và hình nền.

00:12:03.000 --> 00:12:12.000
Những gì chúng tôi muốn làm là thay thế nền trong hình ảnh gốc ở khu vực bên ngoài vùng mặt nạ bằng nền từ một hình ảnh khác.

00:12:12.000 --> 00:12:22.000
Khi bạn thực hiện thao tác pha trộn như vậy, chúng tôi kết thúc với chàng trai trẻ trong hình ảnh gốc được vận chuyển từ lối đi dạo trên bãi biển vào rừng.

00:12:22.000 --> 00:12:26.000
Trình tự pha trộn này trông như thế nào trong mã?

00:12:26.000 --> 00:12:35.000
Trước tiên, giả sử chúng ta đã thực hiện tất cả các quá trình xử lý có liên quan và đã có ba hình ảnh của mình: hình ảnh đầu vào, mặt nạ và nền.

00:12:35.000 --> 00:12:40.000
Bây giờ chúng ta cần chia tỷ lệ cả mặt nạ và nền theo kích thước của hình ảnh gốc.

00:12:40.000 --> 00:12:45.000
Sau đó, chúng tôi sẽ tạo và khởi tạo bộ lọc pha trộn Core Image.

00:12:45.000 --> 00:12:48.000
Bạn có thể nhận thấy rằng tôi đã tạo ra bộ lọc pha trộn của mình với mặt nạ màu đỏ.

00:12:48.000 --> 00:12:58.000
Điều này là do khi CIImage được khởi tạo với một thành phần PixelBuffer - như tất cả các mặt nạ của chúng tôi - nó sẽ tạo ra một đối tượng với kênh màu đỏ theo mặc định.

00:12:58.000 --> 00:13:04.000
Cuối cùng, chúng tôi thực hiện thao tác pha trộn để có được kết quả của mình.

00:13:04.000 --> 00:13:09.000
Hãy xem cách chúng ta có thể sử dụng tính năng phân đoạn người trong khuôn khổ Tầm nhìn.

00:13:09.000 --> 00:13:16.000
Ứng dụng demo thứ hai của chúng tôi, có sẵn để tải xuống, kết hợp phát hiện số liệu tư thế khuôn mặt với khả năng phân đoạn người mới.

00:13:16.000 --> 00:13:20.000
Ứng dụng xử lý nguồn cấp dữ liệu máy ảnh bằng cách chạy tính năng nhận diện khuôn mặt và phân đoạn người.

00:13:20.000 --> 00:13:28.000
Sau đó, điều đó chiếm mặt nạ phân đoạn cuối và sử dụng nó để thay thế nền trong khu vực bên ngoài các điểm ảnh mặt nạ bằng một màu khác.

00:13:28.000 --> 00:13:36.000
Quyết định sử dụng màu nền nào đến từ sự kết hợp của các giá trị cho cuộn, ngáp và cao độ tại bất kỳ thời điểm nào.

00:13:36.000 --> 00:13:46.000
Tôi hiện đang ở trong một căn phòng có bàn ghế, và ứng dụng demo hiển thị hình bóng được phân đoạn của tôi trên nền mới, đó là sự pha trộn màu sắc tương ứng với vị trí đầu của tôi.

00:13:46.000 --> 00:13:49.000
Hãy xem liệu nó có theo dõi sự thay đổi của cuộn, ngáp và cao độ hay không.

00:13:49.000 --> 00:13:58.000
Khi tôi quay đầu lại như thế này, roll là một đóng góp chính cho quyết định pha trộn màu nền.

00:13:58.000 --> 00:14:04.000
Khi tôi quay đầu sang trái và phải, ngáp trở thành người đóng góp chính.

00:14:04.000 --> 00:14:12.000
Và cuối cùng, gật đầu lên xuống khiến quảng cáo chiêu hàng trở thành người đóng góp chính.

00:14:12.000 --> 00:14:15.000
Khung tầm nhìn không phải là nơi duy nhất cung cấp API phân khúc người.

00:14:15.000 --> 00:14:20.000
Có một số khuôn khổ khác cung cấp chức năng tương tự được cung cấp bởi cùng một công nghệ.

00:14:20.000 --> 00:14:23.000
Chúng ta hãy xem xét ngắn gọn từng người trong số họ.

00:14:23.000 --> 00:14:26.000
Đầu tiên là AVFoundation.

00:14:26.000 --> 00:14:33.000
AVFoundation có thể trả lại mặt nạ phân đoạn người trong một số thiết bị thế hệ mới hơn trong phiên chụp ảnh.

00:14:33.000 --> 00:14:39.000
Mặt nạ phân đoạn được trả về thông qua thuộc tính PortraitEffectsMatte của AVCapturePhoto.

00:14:39.000 --> 00:14:45.000
Để có được nó, trước tiên bạn sẽ cần kiểm tra xem nó có được hỗ trợ hay không; và nếu có, hãy kích hoạt việc phân phối nó.

00:14:45.000 --> 00:14:50.000
Khung thứ hai cung cấp API phân đoạn người là ARKit.

00:14:50.000 --> 00:14:56.000
Chức năng này được hỗ trợ trên A12 Bionic và các thiết bị mới hơn, và được tạo ra khi xử lý nguồn cấp dữ liệu máy ảnh.

00:14:56.000 --> 00:15:01.000
Mặt nạ phân đoạn được trả về thông qua thuộc tính segmentationBuffer của ARFrame.

00:15:01.000 --> 00:15:12.000
Trước khi cố gắng truy xuất nó, bạn cần kiểm tra xem nó có được hỗ trợ hay không bằng cách kiểm tra thuộc tính supportsFrameSemantics của lớp ARWorldTrackingConfiguration.

00:15:12.000 --> 00:15:14.000
Khung thứ ba là Core Image.

00:15:14.000 --> 00:15:22.000
Core Image cung cấp một trình bao bọc mỏng trên API phân đoạn người Vision, vì vậy bạn có thể thực hiện toàn bộ trường hợp sử dụng trong miền Core Image.

00:15:22.000 --> 00:15:28.000
Bây giờ chúng ta hãy xem cách phân đoạn người có thể được triển khai bằng cách sử dụng Core Image API.

00:15:28.000 --> 00:15:32.000
Chúng ta sẽ bắt đầu với việc ghi lại một hình ảnh để thực hiện phân đoạn.

00:15:32.000 --> 00:15:43.000
Sau đó, chúng tôi sẽ tạo một CIFilter phân đoạn người, gán một Hình ảnh đầu vào cho nó và thực hiện bộ lọc để lấy mặt nạ phân đoạn của chúng tôi.

00:15:43.000 --> 00:15:47.000
Chúng tôi vừa xem xét nhiều phiên bản của API phân đoạn người và Apple SDK.

00:15:47.000 --> 00:15:51.000
Hãy tóm tắt để xem mỗi cái có thể được sử dụng ở đâu.

00:15:51.000 --> 00:15:56.000
AVFoundation có sẵn trên một số thiết bị iOS với AVCaptureSession.

00:15:56.000 --> 00:16:00.000
Nếu bạn có một phiên chụp đang chạy, đây sẽ là lựa chọn của bạn.

00:16:00.000 --> 00:16:06.000
Nếu bạn đang phát triển một ứng dụng ARKit, bạn nên có một phiên AR nơi bạn có thể lấy mặt nạ phân đoạn của mình.

00:16:06.000 --> 00:16:10.000
Trong trường hợp này, ARKit API là API được khuyến nghị sử dụng.

00:16:10.000 --> 00:16:16.000
Vision API có sẵn trên nhiều nền tảng để xử lý khung hình đơn trực tuyến và ngoại tuyến.

00:16:16.000 --> 00:16:24.000
Và cuối cùng, Core Image cung cấp một trình bao bọc mỏng xung quanh Vision API, đây là một lựa chọn thuận tiện nếu bạn muốn ở trong miền Core Image.

00:16:24.000 --> 00:16:31.000
Như bất kỳ thuật toán nào, phân đoạn người có các phương pháp hay nhất - hay nói cách khác, tập hợp các điều kiện mà nó hoạt động tốt nhất.

00:16:31.000 --> 00:16:37.000
Nếu bạn dự định sử dụng tính năng phân đoạn người, ứng dụng của bạn sẽ hoạt động tốt hơn nếu bạn cố gắng tuân theo các quy tắc này.

00:16:37.000 --> 00:16:45.000
Đầu tiên, bạn nên cố gắng phân đoạn tối đa bốn người trong cảnh mà hầu hết mọi người đều có thể nhìn thấy, trong khi có thể có tắc nghẽn tự nhiên.

00:16:45.000 --> 00:16:53.000
Thứ hai, chiều cao của mỗi người nên ít nhất bằng một nửa chiều cao hình ảnh, lý tưởng nhất là có độ tương phản tốt so với hậu cảnh.

00:16:53.000 --> 00:17:02.000
Và thứ ba, chúng tôi cũng khuyên bạn nên tránh những điều mơ hồ như tượng, hình ảnh của mọi người, những người ở khoảng cách xa.

00:17:02.000 --> 00:17:03.000
Điều này kết thúc phiên họp của chúng tôi.

00:17:03.000 --> 00:17:07.000
Chúng ta hãy xem ngắn gọn những gì chúng ta đã học được ngày hôm nay.

00:17:07.000 --> 00:17:19.000
Đầu tiên, chúng tôi đã có một cái nhìn tổng quan về công nghệ phân tích con người trong khuôn khổ Tầm nhìn trong khi tập trung vào các nâng cấp như phát hiện khuôn mặt đeo mặt nạ, thêm số liệu cao độ khuôn mặt và làm cho tất cả các chỉ số tư thế khuôn mặt được báo cáo trong không gian liên tục.

00:17:19.000 --> 00:17:25.000
Chúng tôi cũng đã giới thiệu số liệu chirality tay mới để phát hiện tư thế bàn tay người.

00:17:25.000 --> 00:17:30.000
Trong phần thứ hai, chúng tôi đã đi sâu vào API phân đoạn người mới được thêm vào khung Tầm nhìn.

00:17:30.000 --> 00:17:37.000
Chúng tôi cũng đã xem xét các API khác cung cấp chức năng tương tự và cung cấp hướng dẫn nơi mỗi API có thể được sử dụng.

00:17:37.000 --> 00:17:44.000
Tôi thực sự hy vọng rằng bằng cách xem phiên này, bạn đã học được các công cụ mới để phát triển ứng dụng của mình và thực sự mong muốn thử chúng ngay lập tức.

00:17:44.000 --> 00:17:50.000
Trước khi chúng ta kết thúc ngày hôm nay, tôi muốn cảm ơn bạn đã xem, chúc bạn may mắn và có một phần còn lại tuyệt vời của WWDC.

00:17:50.000 --> 23:59:59.000
♪

