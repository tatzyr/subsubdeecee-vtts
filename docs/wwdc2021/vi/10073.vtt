WEBVTT

00:00:02.000 --> 00:00:10.000
Xin chào.

00:00:10.000 --> 00:00:13.000
Tôi là David, một kỹ sư từ nhóm ARKit.

00:00:13.000 --> 00:00:17.000
Hôm nay Christopher và tôi sẽ chia sẻ một loạt các cải tiến cho ARKit 5.

00:00:17.000 --> 00:00:21.000
Chúng tôi rất vui khi thảo luận về những thay đổi sắp tới đối với iOS 15.

00:00:21.000 --> 00:00:27.000
Năm nay, chúng tôi đã thực hiện nhiều nâng cấp trên diện rộng và chúng tôi sẽ thảo luận về nhiều tính năng.

00:00:27.000 --> 00:00:32.000
Trước khi chúng tôi làm điều đó, chúng tôi muốn giới thiệu những trải nghiệm mà tất cả các bạn đã xây dựng với LiDAR.

00:00:32.000 --> 00:00:43.000
Chúng tôi đã thấy nhiều ứng dụng hỗ trợ LiDAR sử dụng API độ sâu và tái tạo cảnh: năng suất, hiệu ứng bộ lọc ảnh, giải trí và thậm chí cả các trò chơi mà bạn có thể chơi trong phòng khách của mình.

00:00:43.000 --> 00:00:48.000
Chúng tôi thực sự vui khi thấy sự sáng tạo và tháo vát được thể hiện bởi cộng đồng ARKit.

00:00:48.000 --> 00:00:56.000
Trong khi bạn đang tạo các ứng dụng này, chúng tôi đang làm việc chăm chỉ để mang đến cho bạn khuôn khổ AR tốt nhất thế giới và vượt qua ranh giới của những gì có thể.

00:00:56.000 --> 00:01:00.000
Hãy xem qua những thay đổi sắp tới trong ARKit 5.

00:01:00.000 --> 00:01:10.000
Đầu tiên, chúng tôi sẽ chia sẻ một số cập nhật và phương pháp hay nhất cho neo vị trí, cho phép trải nghiệm AR ở các địa điểm ngoài trời trong thế giới thực.

00:01:10.000 --> 00:01:18.000
Tiếp theo, chúng tôi sẽ đề cập đến Mã clip ứng dụng, đây là một cách tuyệt vời để khám phá các clip ứng dụng và cũng cho phép bạn định vị nội dung của mình trong AR.

00:01:18.000 --> 00:01:26.000
Chúng tôi sẽ nêu bật một số cải tiến để theo dõi khuôn mặt bằng cách sử dụng camera trước siêu rộng trên iPad Pro mới.

00:01:26.000 --> 00:01:31.000
Và chúng ta sẽ kết thúc với một số cải tiến để chụp chuyển động ARKit.

00:01:31.000 --> 00:01:38.000
Chúng tôi sẽ bắt đầu với các neo vị trí, nơi chúng tôi đã làm việc để mở rộng hỗ trợ khu vực và cung cấp một số cải tiến về chất lượng cuộc sống.

00:01:38.000 --> 00:01:42.000
Chúng tôi cũng sẽ đề xuất một số phương pháp hay nhất để tạo ứng dụng.

00:01:42.000 --> 00:01:50.000
Các neo vị trí đã được giới thiệu vào năm ngoái để cho phép đặt nội dung AR ở một vĩ độ và kinh độ cụ thể.

00:01:50.000 --> 00:01:56.000
Mục đích của họ là cho phép tạo ra các trải nghiệm AR gắn liền với các vị trí địa lý.

00:01:56.000 --> 00:01:58.000
Hãy xem xét một ví dụ.

00:01:58.000 --> 00:02:05.000
Đây là trải nghiệm New Nature từ ứng dụng ScavengAR, được xây dựng bằng API neo vị trí.

00:02:05.000 --> 00:02:13.000
ScavengAR lưu trữ nội dung AR tại các địa điểm trong thế giới thực và cho phép tạo ra các hoạt động và sắp đặt nghệ thuật công cộng ảo.

00:02:13.000 --> 00:02:19.000
Đó là một ví dụ điển hình về cách neo vị trí có thể cung cấp năng lượng cho trải nghiệm ngoài trời khi thế giới mở cửa trở lại.

00:02:19.000 --> 00:02:24.000
Ứng dụng Bản đồ cũng đang giới thiệu một tính năng AR mới sử dụng API trong iOS 15.

00:02:24.000 --> 00:02:26.000
Hãy cùng xem nào.

00:02:26.000 --> 00:02:32.000
Năm nay Bản đồ đang thêm các chỉ dẫn đi bộ từng bước được hiển thị trong AR, sử dụng API neo vị trí.

00:02:32.000 --> 00:02:35.000
Họ kết hợp một số phương pháp mà chúng tôi đề xuất.

00:02:35.000 --> 00:02:39.000
Chúng tôi sẽ đề cập đến những điều này sau để chỉ ra cách bạn có thể xây dựng các ứng dụng tuyệt vời.

00:02:39.000 --> 00:02:49.000
Bây giờ chúng ta đã thấy một vài mẫu, hãy tóm tắt lại cách các neo vị trí có thể được sử dụng để tạo chúng, bắt đầu với các bước cần thiết để thiết lập Cấu hình theo dõi địa lý.

00:02:49.000 --> 00:02:53.000
Đầu tiên, xác minh rằng tính năng này được hỗ trợ trên thiết bị.

00:02:53.000 --> 00:02:59.000
Các neo vị trí yêu cầu chip A12 hoặc mới hơn và hỗ trợ di động và GPS.

00:02:59.000 --> 00:03:04.000
Tiếp theo, hãy kiểm tra xem tính năng có sẵn tại địa điểm trước khi khởi chạy hay không.

00:03:04.000 --> 00:03:08.000
Quyền sử dụng máy ảnh và vị trí phải được chủ sở hữu thiết bị chấp thuận.

00:03:08.000 --> 00:03:11.000
ARKit sẽ nhắc nhở các quyền nếu cần.

00:03:11.000 --> 00:03:23.000
Bài thuyết trình năm ngoái giới thiệu ARKit 4 và dự án mẫu, "Theo dõi vị trí địa lý trong AR", bao gồm tất cả các chủ đề này và việc sử dụng API sâu hơn.

00:03:23.000 --> 00:03:28.000
Chúng tôi thực sự khuyên bạn nên tự làm quen với cả hai nguồn này.

00:03:28.000 --> 00:03:32.000
Mẫu mã này cho thấy cách thực hiện kiểm tra từ trang chiếu trước đó.

00:03:32.000 --> 00:03:42.000
Nó truy vấn hỗ trợ thiết bị và sau đó xác minh xem tính năng có khả dụng tại vị trí hiện tại hay không trước khi cố gắng chạy Cấu hình theo dõi địa lý.

00:03:42.000 --> 00:03:47.000
GeoAnchors sau đó có thể được thêm vào ARSession giống như các loại neo khác.

00:03:47.000 --> 00:03:52.000
Chúng được chỉ định với tọa độ vĩ độ-kinh độ và, tùy chọn, độ cao.

00:03:52.000 --> 00:04:01.000
Điều quan trọng là phải theo dõi trạng thái của GeoTrackingConfiguration để xem liệu tính năng đó có được bản địa hóa hay không và những vấn đề nào có thể vẫn cần được giải quyết.

00:04:01.000 --> 00:04:07.000
Mẫu nhà phát triển chứa một ví dụ về cách triển khai phương pháp nhận cập nhật trạng thái.

00:04:07.000 --> 00:04:13.000
Kiểm tra tính khả dụng gần vị trí thiết bị rất quan trọng để bắt đầu một ứng dụng với theo dõi địa lý.

00:04:13.000 --> 00:04:16.000
Chúng tôi liên tục làm việc để hỗ trợ nhiều khu vực hơn.

00:04:16.000 --> 00:04:27.000
Các mỏ neo vị trí bị giới hạn ở năm khu vực đô thị để phát hành ban đầu và kể từ đó, hỗ trợ đã mở rộng đến hơn 25 thành phố trên khắp Hoa Kỳ.

00:04:27.000 --> 00:04:31.000
Chúng tôi cũng đang làm việc chăm chỉ để đưa các mỏ neo vị trí đến các thành phố trên toàn cầu.

00:04:31.000 --> 00:04:36.000
Lần đầu tiên, chúng tôi vui mừng thông báo một thị trường bên ngoài Hoa Kỳ.

00:04:36.000 --> 00:04:39.000
Các mỏ neo địa điểm đang đến London.

00:04:39.000 --> 00:04:43.000
Chúng tôi sẽ tiếp tục làm việc để thêm các khu vực mới theo thời gian.

00:04:43.000 --> 00:04:52.000
Nếu bạn không sống trong khu vực tàu điện ngầm được hỗ trợ, bạn cũng có thể bắt đầu thử nghiệm với các neo vị trí thông qua việc sử dụng ghi âm và phát lại, chúng tôi sẽ đề cập sau trong phiên này.

00:04:52.000 --> 00:04:59.000
Để biết danh sách các khu vực được hỗ trợ, hãy tham khảo tài liệu trực tuyến cho ARGeoTrackingConfiguration bất cứ lúc nào.

00:04:59.000 --> 00:05:06.000
Khi các neo vị trí có sẵn ở nhiều khu vực hơn, chúng tôi nhận ra sự cần thiết phải có một ngôn ngữ hình ảnh chung để hướng dẫn mọi người.

00:05:06.000 --> 00:05:14.000
Để hỗ trợ quy trình giới thiệu nhất quán, chúng tôi đang thêm mục tiêu .geoTracking mới để sử dụng với ARCoachingOverlayView.

00:05:14.000 --> 00:05:21.000
Tương tự như lớp phủ hiện có để theo dõi thế giới, nó hiển thị một hình ảnh động để giúp mọi người đạt được trải nghiệm tốt.

00:05:21.000 --> 00:05:30.000
Vì lớp phủ huấn luyện được sử dụng trên nhiều ứng dụng AR khác nhau, bao gồm cả Bản đồ, mọi người sẽ quen thuộc với chúng và biết cách phản hồi.

00:05:30.000 --> 00:05:35.000
Chúng tôi khuyến khích bạn bao gồm lớp phủ huấn luyện để giảm bớt đường cong học tập cho tính năng này.

00:05:35.000 --> 00:05:45.000
Ngay cả khi sử dụng lớp phủ huấn luyện, vẫn nên theo dõi các cập nhật trạng thái .geoTracking, chứa thông tin chi tiết hơn về trạng thái theo dõi.

00:05:45.000 --> 00:05:48.000
Đây là lớp phủ huấn luyện .geoTracking trông như thế nào.

00:05:48.000 --> 00:05:55.000
Giao diện người dùng hiển thị hướng dẫn hướng thiết bị ra khỏi mặt đất và sau đó hướng tới mặt tiền tòa nhà.

00:05:55.000 --> 00:06:01.000
Sau vài giây, theo dõi thành công và ứng dụng của bạn có thể đặt nội dung được theo dõi theo địa lý.

00:06:01.000 --> 00:06:06.000
Mã để hiển thị hình ảnh động này rất giống với mã được sử dụng cho các lớp phủ huấn luyện khác.

00:06:06.000 --> 00:06:10.000
Điều độc đáo là sự ra đời của mục tiêu .geoTracking cho lớp phủ.

00:06:10.000 --> 00:06:14.000
Đảm bảo đặt mục tiêu này để hiển thị hướng dẫn chính xác.

00:06:14.000 --> 00:06:18.000
Chúng tôi đã thấy lớp phủ huấn luyện có thể tạo ra một quy trình giới thiệu đồng phục như thế nào.

00:06:18.000 --> 00:06:24.000
Bây giờ chúng ta sẽ xem xét một số phương pháp hay nhất khác sẽ giúp bạn tạo ra trải nghiệm AR được theo dõi theo địa lý.

00:06:24.000 --> 00:06:29.000
Đề xuất đầu tiên của chúng tôi là sử dụng ghi âm và phát lại để phát triển nhanh hơn.

00:06:29.000 --> 00:06:36.000
Các phiên ARKit có thể được ghi lại trên các thiết bị sử dụng Reality Composer, có sẵn trên App Store.

00:06:36.000 --> 00:06:42.000
Điều này đặc biệt hữu ích cho việc neo vị trí nên bạn không cần phải ra ngoài thường xuyên để kiểm tra.

00:06:42.000 --> 00:06:46.000
Nó cũng cho phép cộng tác với những người sáng tạo nằm ở xa.

00:06:46.000 --> 00:06:49.000
Các bản ghi âm có thể được phát lại trên một thiết bị sử dụng Xcode.

00:06:49.000 --> 00:06:56.000
Để tránh các vấn đề không tương thích, bạn nên sử dụng cùng một thiết bị và phiên bản iOS.

00:06:56.000 --> 00:06:59.000
Điều này cũng hoạt động cho các loại ứng dụng ARKit khác.

00:06:59.000 --> 00:07:03.000
Phát lại không dành riêng cho các neo vị trí.

00:07:03.000 --> 00:07:07.000
Hãy cùng xem qua quy trình ghi lại bản ghi âm.

00:07:07.000 --> 00:07:13.000
Để ghi lại, hãy mở Reality Composer và nhấn để có thêm tùy chọn ở phía trên bên phải.

00:07:13.000 --> 00:07:17.000
Sau đó mở ngăn Nhà phát triển và chọn Ghi lại Phiên AR.

00:07:17.000 --> 00:07:20.000
Đảm bảo rằng các dịch vụ định vị được bật.

00:07:20.000 --> 00:07:25.000
Nhấn vào nút màu đỏ để bắt đầu và dừng ghi âm.

00:07:25.000 --> 00:07:29.000
Để phát lại bản ghi âm, hãy kết nối thiết bị với máy tính đang chạy Xcode.

00:07:29.000 --> 00:07:35.000
Nhấp vào Chỉnh sửa Sơ đồ và đặt tùy chọn Dữ liệu Phát lại ARKit cho cấu hình đang chạy.

00:07:35.000 --> 00:07:37.000
Sau đó chạy ứng dụng.

00:07:37.000 --> 00:07:43.000
Mặc dù ghi âm và phát lại có thể giúp tăng tốc độ phát triển, nhưng có những phương pháp khác mà chúng tôi đề xuất cho việc đặt nội dung.

00:07:43.000 --> 00:07:46.000
Đây là một video minh họa những điều này.

00:07:46.000 --> 00:07:55.000
Lưu ý cách nội dung AR lớn và có thể nhìn thấy rõ ràng, và thông tin được truyền tải mà không cần phải phủ một cấu trúc trong môi trường.

00:07:55.000 --> 00:08:05.000
Như một sự đánh đổi giữa thời gian phát triển và độ chính xác của vị trí, hãy cân nhắc việc tạo ra nội dung trôi nổi trong không khí thay vì cố gắng chồng chéo chặt chẽ các vật thể trong thế giới thực.

00:08:05.000 --> 00:08:09.000
Chúng tôi có một vài đề xuất khác để đặt nội dung.

00:08:09.000 --> 00:08:18.000
Để có được tọa độ vĩ độ và kinh độ để đặt các đối tượng, hãy sử dụng ứng dụng Apple Maps và sao chép tọa độ với độ chính xác ít nhất sáu chữ số.

00:08:18.000 --> 00:08:25.000
Các bước cho việc này đã được hiển thị trong video giới thiệu ARKit 4, vì vậy vui lòng tham khảo ở đó để biết thêm chi tiết.

00:08:25.000 --> 00:08:35.000
Khi tạo một ứng dụng, điều quan trọng là phải điều chỉnh độ cao của nội dung so với neo vị trí khi cần thiết để tạo ra trải nghiệm tốt.

00:08:35.000 --> 00:08:44.000
Nếu ứng dụng yêu cầu vị trí nội dung chính xác hơn, hãy thêm neo địa lý khi thiết bị cách vị trí của nó trong vòng 50 mét.

00:08:44.000 --> 00:08:52.000
Nếu ARKit đặt mỏ neo với độ cao chính xác, nó sẽ cập nhật trường nguồn độ cao của mỏ neo để chỉ ra điều này.

00:08:52.000 --> 00:08:58.000
Lớp CLLocation có một phương pháp có thể được sử dụng để tính toán khoảng cách tính bằng mét giữa hai điểm.

00:08:58.000 --> 00:09:03.000
Điều này có thể được sử dụng để xác minh rằng ai đó đang ở gần một vị trí trước khi thêm neo.

00:09:03.000 --> 00:09:06.000
Điều này kết thúc phiên họp của chúng tôi về vị trí neo đậu.

00:09:06.000 --> 00:09:10.000
Có nhiều cách hơn để đặt nội dung AR trong ứng dụng của bạn bằng ARKit 5.

00:09:10.000 --> 00:09:13.000
Vì vậy, hãy để tôi giao nó cho Christopher, người sẽ cho bạn biết thêm.

00:09:13.000 --> 00:09:14.000
Cảm ơn bạn, David.

00:09:14.000 --> 00:09:17.000
Xin chào, tên tôi là Christopher, và tôi là một kỹ sư trong nhóm ARKit.

00:09:17.000 --> 00:09:20.000
Tôi rất vui được cho bạn biết thêm về các tính năng mới tuyệt vời khác trong ARKit 5.

00:09:20.000 --> 00:09:23.000
Hãy để tôi bắt đầu với App Clip Codes trong ARKit.

00:09:23.000 --> 00:09:26.000
Bạn có thể nhớ rằng chúng tôi đã giới thiệu App Clips tại WWDC vào năm ngoái.

00:09:26.000 --> 00:09:33.000
Clip ứng dụng là một phần nhỏ của ứng dụng đưa mọi người qua một quy trình làm việc theo ngữ cảnh của ứng dụng của bạn mà không cần phải cài đặt toàn bộ ứng dụng.

00:09:33.000 --> 00:09:42.000
Do kích thước tệp nhỏ, một clip ứng dụng tiết kiệm thời gian tải xuống và ngay lập tức đưa mọi người trực tiếp đến một phần cụ thể của ứng dụng có liên quan cao đến ngữ cảnh của họ vào lúc này.

00:09:42.000 --> 00:09:47.000
Chúng tôi cũng đã giới thiệu App Clip Codes, đây là một cách tuyệt vời để mọi người khám phá và khởi chạy trực quan các clip ứng dụng của bạn.

00:09:47.000 --> 00:09:50.000
Không cần chuyến đi đến App Store.

00:09:50.000 --> 00:09:51.000
Đây là mã clip ứng dụng trông như thế nào.

00:09:51.000 --> 00:09:54.000
Chúng có thể có nhiều hình dạng và màu sắc khác nhau.

00:09:54.000 --> 00:09:58.000
Với tư cách là nhà phát triển, bạn có thể tạo ra một giao diện phù hợp nhất với kịch bản của mình.

00:09:58.000 --> 00:10:05.000
Bạn cũng quyết định dữ liệu nào cần mã hóa trong Mã clip ứng dụng và clip ứng dụng nào được liên kết với mã nào.

00:10:05.000 --> 00:10:15.000
Tất cả các mã clip ứng dụng đều chứa mẫu có thể quét trực quan và một số mã màu đỏ, xanh dương và cam được hiển thị ở đây, cũng chứa thẻ NFC để thuận tiện cho người dùng.

00:10:15.000 --> 00:10:21.000
Mọi người có thể quét mã bằng máy ảnh của họ hoặc giữ điện thoại vào thẻ NFC được nhúng để khởi chạy clip ứng dụng liên quan của bạn.

00:10:21.000 --> 00:10:26.000
Và bây giờ, bạn cũng có thể nhận ra và theo dõi Mã Clip Ứng dụng trong trải nghiệm AR của mình.

00:10:26.000 --> 00:10:29.000
Chúng ta sẽ xem xét điều đó được thực hiện như thế nào sau trong phiên này.

00:10:29.000 --> 00:10:36.000
Nhưng trước tiên, chúng ta hãy xem clip ứng dụng này được phát triển bởi Primer, nơi họ sử dụng Mã clip ứng dụng để khởi chạy trải nghiệm AR.

00:10:36.000 --> 00:10:43.000
Primer hợp tác với Cle Tile để cho mọi người thấy các mẫu của họ sẽ trông như thế nào trong AR với sự trợ giúp của App Clip Codes.

00:10:43.000 --> 00:10:47.000
Chỉ cần đặt iPhone và iPad của bạn qua App Clip Code để gọi trải nghiệm AR.

00:10:47.000 --> 00:10:53.000
Giờ đây, mọi người có thể xem trước mẫu gạch trên tường của họ mà không cần tải xuống ứng dụng.

00:10:53.000 --> 00:10:54.000
Điều đó khá tuyệt, phải không?

00:10:54.000 --> 00:11:00.000
Vì vậy, bắt đầu với iOS và iPad 14.3, bạn có thể phát hiện và theo dõi Mã clip ứng dụng trong trải nghiệm AR.

00:11:00.000 --> 00:11:07.000
Lưu ý rằng việc theo dõi Mã Clip Ứng dụng yêu cầu các thiết bị có bộ xử lý A12 Bionic trở lên, như iPhone XS.

00:11:07.000 --> 00:11:10.000
Chúng ta hãy xem xét kỹ hơn cách sử dụng Mã Clip Ứng dụng trong ARKit.

00:11:10.000 --> 00:11:16.000
Trong iOS 14.3, chúng tôi đã giới thiệu một loại ARAnchor mới, ARAppClipCodeAnchor.

00:11:16.000 --> 00:11:26.000
Neo này có ba thuộc tính mới: URL được nhúng trong App Clip Code, trạng thái giải mã URL và bán kính của App Clip Code tính bằng mét.

00:11:26.000 --> 00:11:29.000
Để tôi giải thích.

00:11:29.000 --> 00:11:33.000
Mỗi App Clip Code chứa một URL được giải mã để hiển thị nội dung chính xác.

00:11:33.000 --> 00:11:36.000
Giải mã URL không phải là ngay lập tức.

00:11:36.000 --> 00:11:39.000
ARKit có thể phát hiện sự hiện diện của Mã Clip Ứng dụng một cách nhanh chóng.

00:11:39.000 --> 00:11:48.000
Nhưng có thể mất nhiều thời gian hơn một chút để ARKit giải mã URL, tùy thuộc vào khoảng cách của người dùng đến mã và các yếu tố khác như ánh sáng.

00:11:48.000 --> 00:11:56.000
Đây là lý do tại sao neo App Clip Code chứa thuộc tính trạng thái .decoding và nó có thể ở một trong ba trạng thái.

00:11:56.000 --> 00:12:00.000
Trạng thái ban đầu .decoding chỉ ra rằng ARKit vẫn đang giải mã URL.

00:12:00.000 --> 00:12:05.000
Ngay sau khi ARKit giải mã thành công URL, trạng thái sẽ chuyển sang .decoded.

00:12:05.000 --> 00:12:10.000
Khi không thể giải mã URL, thay vào đó trạng thái sẽ chuyển sang .failed.

00:12:10.000 --> 00:12:16.000
Ví dụ, điều này có thể xảy ra khi ai đó quét Mã clip ứng dụng không được liên kết với clip ứng dụng.

00:12:16.000 --> 00:12:21.000
Để sử dụng theo dõi Mã Clip Ứng dụng, trước tiên bạn nên kiểm tra xem nó có được hỗ trợ trên thiết bị hay không.

00:12:21.000 --> 00:12:26.000
Hãy nhớ rằng việc theo dõi Mã Clip Ứng dụng chỉ được hỗ trợ trên các thiết bị có bộ xử lý A12 Bionic trở lên.

00:12:26.000 --> 00:12:34.000
Sau đó đặt thuộc tính appClipCodeTrackingEnabled trên cấu hình của bạn thành true và chạy phiên.

00:12:34.000 --> 00:12:44.000
Để đọc URL của Mã Clip Ứng dụng, hãy theo dõi các phiên AR đã cập nhật lệnh gọi lại Anchors và kiểm tra trạng thái giải mã của bất kỳ neo Mã Clip Ứng dụng nào được phát hiện.

00:12:44.000 --> 00:12:57.000
Trong khi ARKit đang giải mã mã App Clip Code, bạn có thể muốn hiển thị hình ảnh trình giữ chỗ trên đầu App Clip Code để cung cấp cho người dùng phản hồi tức thì rằng App Clip Code đã được phát hiện nhưng vẫn cần được giải mã.

00:12:57.000 --> 00:13:06.000
Như đã đề cập trước đây, giải mã mã App Clip cũng có thể thất bại. Ví dụ, khi ai đó chĩm điện thoại vào Mã clip ứng dụng không thuộc về clip ứng dụng của bạn.

00:13:06.000 --> 00:13:10.000
Chúng tôi khuyên bạn cũng nên đưa ra phản hồi trong trường hợp đó.

00:13:10.000 --> 00:13:17.000
Khi Mã Clip Ứng dụng đã được giải mã, cuối cùng bạn có thể truy cập URL của nó và bắt đầu hiển thị nội dung phù hợp cho Mã Clip Ứng dụng này.

00:13:17.000 --> 00:13:25.000
Ví dụ, trong trường hợp clip ứng dụng Primer mà bạn đã thấy trước đó, URL chứa thông tin về mẫu gạch nào sẽ hiển thị.

00:13:25.000 --> 00:13:31.000
Khi Mã Clip Ứng dụng đã được giải mã, câu hỏi đặt ra là, bạn nên hiển thị nội dung được liên kết với mã này ở đâu?

00:13:31.000 --> 00:13:34.000
Một lựa chọn là hiển thị nó trực tiếp trên đầu neo App Clip Code.

00:13:34.000 --> 00:13:40.000
Tuy nhiên, tùy thuộc vào trường hợp sử dụng của bạn, bản thân App Clip Code có thể không phải là nơi tốt nhất để hiển thị nội dung.

00:13:40.000 --> 00:13:46.000
Vì vậy, ví dụ, bạn có thể định vị nội dung gần Mã clip ứng dụng với vị trí tương đối cố định.

00:13:46.000 --> 00:13:57.000
Điều này hoạt động tốt khi App Clip Code được in trên một đối tượng, chẳng hạn như máy pha cà phê và bạn muốn hiển thị hướng dẫn ảo về cách vận hành nó trên các nút của máy.

00:13:57.000 --> 00:14:02.000
Hoặc bạn có thể kết hợp theo dõi App Clip Code với các công nghệ theo dõi khác được hỗ trợ bởi ARKit.

00:14:02.000 --> 00:14:04.000
Ví dụ, theo dõi hình ảnh.

00:14:04.000 --> 00:14:07.000
Chúng ta hãy xem xét việc thực hiện điều đó.

00:14:07.000 --> 00:14:16.000
Các video và mã mà bạn thấy tiếp theo dựa trên mã mẫu "Tương tác với mã clip ứng dụng trong AR" mà bạn có thể tải xuống trên developer.apple.com.

00:14:16.000 --> 00:14:20.000
Những gì bạn thấy bây giờ là bản ghi lại trải nghiệm AR của mẫu.

00:14:20.000 --> 00:14:24.000
Đầu tiên, tôi đang bắt đầu trong ứng dụng Camera, quét một gói hạt hướng dương.

00:14:24.000 --> 00:14:28.000
Có lẽ tôi đang mua sắm trong cửa hàng làm vườn, cố gắng quyết định nên mua hạt giống cây trồng nào.

00:14:28.000 --> 00:14:34.000
iOS nhận ra Mã Clip Ứng dụng trên gói và khởi chạy clip ứng dụng Seed Shop được liên kết.

00:14:34.000 --> 00:14:40.000
Ở đây, tôi đang quét App Clip Code lần thứ hai, và sau đó hoa hướng dương đã trưởng thành xuất hiện trên gói hạt giống.

00:14:40.000 --> 00:14:45.000
Lưu ý rằng clip ứng dụng sử dụng theo dõi hình ảnh của toàn bộ gói hạt giống và đặt hoa hướng dương lên đó.

00:14:45.000 --> 00:14:54.000
Cách tiếp cận này có ý nghĩa trong trường hợp sử dụng này, vì sự chú ý của người đó rất có thể là trên toàn bộ gói hạt giống chứ không phải trên Mã clip ứng dụng nhỏ hơn ở trên cùng bên phải.

00:14:54.000 --> 00:14:57.000
Nhưng nếu ai đó muốn nhìn thấy cây mọc trong vườn của họ thì sao?

00:14:57.000 --> 00:14:59.000
Đây là những gì có thể trông như thế nào.

00:14:59.000 --> 00:15:04.000
Ở đây chúng ta thấy rằng khi mã được quét lần đầu tiên, nó sẽ gọi tải xuống clip ứng dụng.

00:15:04.000 --> 00:15:13.000
Sau đó, khi cùng một mã được quét lại từ bên trong clip ứng dụng, nó sẽ liên kết mã với hộp hạt hướng dương và sau đó chạm vào bãi cỏ sẽ làm cho hoa hướng dương xuất hiện ở đó.

00:15:13.000 --> 00:15:18.000
Thay vào đó, nếu clip ứng dụng nhìn thấy mã trên hộp hạt giống hoa hồng, nó sẽ sinh ra một cây hoa hồng trên bãi cỏ.

00:15:18.000 --> 00:15:22.000
Lưu ý rằng các clip ứng dụng được cho là chỉ chứa một quy trình làm việc.

00:15:22.000 --> 00:15:28.000
Nhưng clip ứng dụng có thể cung cấp một nút để tải xuống ứng dụng Seed Shop đầy đủ để trải nghiệm các loại cây khác mà họ có thể xem trước trong không gian của mình.

00:15:28.000 --> 00:15:32.000
Hãy nhớ rằng, theo dõi Mã Clip Ứng dụng cũng hoạt động trong ứng dụng mẹ của App Clip.

00:15:32.000 --> 00:15:37.000
Chúng ta hãy xem mã mà chúng ta cần để đặt hoa hướng dương trên bãi cỏ.

00:15:37.000 --> 00:15:42.000
Đầu tiên, bạn thêm một tapGestureRecognizer vào chế độ xem để phát hiện các vòi trên màn hình.

00:15:42.000 --> 00:15:51.000
Khi người đó chạm vào màn hình, bạn có thể chiếu một tia vào thế giới và lấy lại vị trí kết quả trên mặt phẳng nằm ngang phía trước thiết bị của họ.

00:15:51.000 --> 00:15:55.000
Trong kịch bản của chúng tôi, đây sẽ là bãi cỏ của người đó.

00:15:55.000 --> 00:16:04.000
Sau đó, bạn lấy URL Mã Clip Ứng dụng cuối cùng đã được giải mã và thêm một ARAnchor mới trên bãi cỏ.

00:16:04.000 --> 00:16:09.000
Cuối cùng, bạn tải xuống mô hình 3D hướng dương và hiển thị nó trên bãi cỏ.

00:16:09.000 --> 00:16:14.000
Bây giờ, hãy nói về một số phương pháp hay nhất cho App Clip Codes trong ARKit.

00:16:14.000 --> 00:16:18.000
Các clip ứng dụng có thể được sử dụng trong các môi trường khác nhau và cho các trường hợp sử dụng khác nhau.

00:16:18.000 --> 00:16:22.000
Xem xét liệu đó có phải là một lựa chọn để bạn tạo Mã Clip Ứng dụng NFC hay không.

00:16:22.000 --> 00:16:27.000
Chúng tôi đề xuất Mã kẹp ứng dụng NFC cho các môi trường mà mọi người có thể truy cập mã một cách vật lý.

00:16:27.000 --> 00:16:39.000
Khi sử dụng Mã kẹp ứng dụng NFC, hãy sử dụng văn bản kêu gọi hành động thích hợp hướng dẫn mọi người nhấn vào thẻ hoặc, cách khác, cung cấp khả năng rõ ràng để quét mã.

00:16:39.000 --> 00:16:46.000
Cuối cùng nhưng không kém phần quan trọng, bạn cần đảm bảo rằng Mã clip ứng dụng của bạn được in trên kích thước phù hợp với môi trường của người dùng.

00:16:46.000 --> 00:16:57.000
Ví dụ, thực đơn nhà hàng có thể được in trên giấy A4 và mọi người sẽ cảm thấy thoải mái khi quét Mã kẹp ứng dụng 2,5 cm trên thực đơn đó từ khoảng cách lên đến 50 cm.

00:16:57.000 --> 00:17:07.000
Tuy nhiên, một áp phích phim thường lớn hơn nhiều và có thể có đủ không gian cho Mã clip ứng dụng 12 cm mà mọi người có thể quét bằng điện thoại của họ từ khoảng cách lên đến 2,5 mét.

00:17:07.000 --> 00:17:14.000
Vui lòng xem Hướng dẫn Giao diện Con người của chúng tôi về Mã Kẹp Ứng dụng để biết thêm thông tin về kích thước mã được đề xuất.

00:17:14.000 --> 00:17:17.000
Vậy đó là cách bạn sử dụng App Clip Codes trong ARKit.

00:17:17.000 --> 00:17:26.000
Nếu bạn muốn đi sâu hơn vào các clip ứng dụng và Mã clip ứng dụng, hãy nhớ xem các phiên "Có gì mới trong clip ứng dụng" và "Xây dựng clip ứng dụng nhẹ và nhanh".

00:17:26.000 --> 00:17:29.000
Bây giờ chúng ta hãy chuyển sang theo dõi khuôn mặt.

00:17:29.000 --> 00:17:36.000
Theo dõi khuôn mặt cho phép bạn phát hiện khuôn mặt trong camera phía trước, phủ nội dung ảo và tạo hiệu ứng động cho biểu cảm khuôn mặt trong thời gian thực.

00:17:36.000 --> 00:17:41.000
Kể từ khi ra mắt iPhone X, ARKit đã thấy rất nhiều ứng dụng tuyệt vời tận dụng tính năng theo dõi khuôn mặt.

00:17:41.000 --> 00:17:50.000
Từ việc theo dõi nhiều khuôn mặt đến chạy theo dõi khuôn mặt trong trường hợp sử dụng camera trước và sau đồng thời, API này đã nhận được một số tiến bộ trong những năm qua.

00:17:50.000 --> 00:17:57.000
Năm ngoái, chúng tôi đã giới thiệu tính năng theo dõi khuôn mặt trên các thiết bị không có cảm biến TrueDepth, miễn là chúng có bộ xử lý A12 Bionic trở lên.

00:17:57.000 --> 00:18:05.000
Và đầu năm nay, chúng tôi đã ra mắt iPad Pro mới cung cấp cho bạn camera mặt trước trường nhìn cực rộng cho trải nghiệm theo dõi khuôn mặt AR của bạn.

00:18:05.000 --> 00:18:07.000
Hãy cùng xem nào.

00:18:07.000 --> 00:18:12.000
Ở đây bạn thấy trường nhìn của máy ảnh mặt trước thông thường.

00:18:12.000 --> 00:18:15.000
Và đây là trường nhìn siêu rộng mới trên iPad Pro mới.

00:18:15.000 --> 00:18:18.000
Nó thực sự tạo ra sự khác biệt, phải không?

00:18:18.000 --> 00:18:22.000
Lưu ý rằng các ứng dụng hiện tại của bạn sẽ tiếp tục sử dụng máy ảnh bình thường để theo dõi khuôn mặt.

00:18:22.000 --> 00:18:32.000
Nếu bạn muốn nâng cấp trải nghiệm của người dùng lên trường nhìn siêu rộng trên iPad Pro mới, bạn phải kiểm tra định dạng video nào có sẵn và chọn tham gia định dạng siêu rộng mới.

00:18:32.000 --> 00:18:39.000
Bạn có thể làm điều này bằng cách lặp lại tất cả các định dạng video được hỗ trợ và kiểm tra tùy chọn builtInUltraWideCamera.

00:18:39.000 --> 00:18:45.000
Sau đó, bạn đặt định dạng này trên cấu hình AR của mình và chạy phiên.

00:18:45.000 --> 00:18:51.000
Một điều cần lưu ý là camera siêu rộng của iPad Pro mới có trường nhìn lớn hơn nhiều so với cảm biến TrueDepth.

00:18:51.000 --> 00:18:57.000
Do đó, bạn sẽ không nhận được bộ đệm capturedDepthData trên ARFrame khi sử dụng định dạng video siêu rộng.

00:18:57.000 --> 00:18:59.000
Cuối cùng nhưng không kém phần quan trọng, hãy nói về chụp chuyển động.

00:18:59.000 --> 00:19:10.000
Kể từ khi ra mắt vào năm 2019, chụp chuyển động đã cho phép tích hợp mạnh mẽ người thật trong các cảnh AR, chẳng hạn như tạo hoạt ảnh cho các nhân vật ảo cùng với việc được sử dụng trong mô phỏng 2D và 3D.

00:19:10.000 --> 00:19:13.000
Trong iOS 15, chụp chuyển động thậm chí còn tốt hơn.

00:19:13.000 --> 00:19:20.000
Trên các thiết bị có bộ xử lý Apple A14 Bionic như iPhone 12, tính năng chụp chuyển động hiện hỗ trợ nhiều tư thế cơ thể hơn.

00:19:20.000 --> 00:19:23.000
Và điều này không yêu cầu thay đổi mã nào cả.

00:19:23.000 --> 00:19:27.000
Tất cả các ứng dụng chụp chuyển động trên iOS 15 sẽ được hưởng lợi từ điều này.

00:19:27.000 --> 00:19:33.000
Đáng chú ý nhất, các vòng quay chính xác hơn bao giờ hết, giúp bạn theo dõi các hành động thể thao với độ chính xác cao hơn nhiều.

00:19:33.000 --> 00:19:38.000
Một cải tiến lớn khác là máy ảnh thiết bị của bạn giờ đây có thể theo dõi các khớp cơ thể từ một khoảng cách xa hơn nhiều.

00:19:38.000 --> 00:19:43.000
Ngoài ra, đã có sự gia tăng đáng kể trong việc theo dõi phạm vi chuyển động của chi.

00:19:43.000 --> 00:19:45.000
Hãy xem xét một ví dụ.

00:19:45.000 --> 00:19:50.000
Đây là một trong những đồng nghiệp của tôi, Ejler, theo dõi quá trình tập luyện của anh ấy với ứng dụng Driven2win.

00:19:50.000 --> 00:19:54.000
Kết quả trên iOS 15 chính xác hơn bao giờ hết.

00:19:54.000 --> 00:19:57.000
Tóm lại, ARKit 5 mang đến rất nhiều tính năng và cải tiến mới.

00:19:57.000 --> 00:20:01.000
Các mỏ neo vị trí có sẵn ở các thành phố mới và có lớp phủ huấn luyện mới.

00:20:01.000 --> 00:20:08.000
Theo dõi mã clip ứng dụng hỗ trợ dễ dàng khám phá và sử dụng AR trong clip ứng dụng của bạn, cũng như định vị chính xác nội dung ảo của bạn.

00:20:08.000 --> 00:20:16.000
Theo dõi khuôn mặt hoạt động với trường nhìn siêu rộng mới trên iPad Pro mới và chụp chuyển động tăng thêm độ chính xác tốt hơn và phạm vi chuyển động lớn hơn.

00:20:16.000 --> 00:20:21.000
Tôi rất hào hứng khi thấy tất cả những trải nghiệm tuyệt vời mà bạn sẽ tạo ra với ARKit 5.

00:20:21.000 --> 23:59:59.000
[Âm nhạc].

