WEBVTT

00:00:00.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:13.000
Xin chào. Tôi là Amanda, và tôi sẽ được tham gia một chút bởi đồng nghiệp của tôi, Olivier.

00:00:13.000 --> 00:00:18.000
Trong buổi nói chuyện này, chúng ta sẽ khám phá các tính năng mà chúng ta đã thêm vào RealityKit vào năm 2021.

00:00:18.000 --> 00:00:27.000
RealityKit là một khung tác giả thực tế tăng cường được giới thiệu vào năm 2019 tập trung vào kết xuất thực tế và giúp dễ dàng tạo các ứng dụng AR.

00:00:27.000 --> 00:00:38.000
Tận dụng ARKit để đọc dữ liệu cảm biến của thiết bị, RealityKit cho phép bạn đặt nội dung 3D trong môi trường thế giới thực và làm cho nội dung đó trông chân thực nhất có thể.

00:00:38.000 --> 00:00:42.000
Dưới đây là một số ví dụ tuyệt vời về trải nghiệm RealityKit trong hành động.

00:00:42.000 --> 00:00:52.000
Đi săn xác thối trong thế giới thực, ném bóng hầu như chống lại bạn bè của bạn, thậm chí trở thành một tác phẩm điêu khắc trong bảo tàng và tìm thấy một số con bọ đầy màu sắc.

00:00:52.000 --> 00:01:01.000
Trong vài năm qua, chúng tôi đã thấy một số ứng dụng tuyệt vời được tạo bằng RealityKit và nhận được phản hồi thực sự tốt để làm cho khuôn khổ này thậm chí còn tốt hơn.

00:01:01.000 --> 00:01:03.000
Và chúng tôi đã lắng nghe phản hồi của bạn.

00:01:03.000 --> 00:01:10.000
Chúng tôi rất vui khi chia sẻ rằng RealityKit 2 giới thiệu một loạt các tính năng mới để giúp bạn tạo ra các ứng dụng và trò chơi AR nhập vai hơn nữa.

00:01:10.000 --> 00:01:21.000
Trong phiên này, chúng tôi sẽ làm nổi bật một số trong số chúng, bao gồm các tính năng được yêu cầu nhiều nhất của chúng tôi, như đổ bóng và vật liệu tùy chỉnh, hệ thống tùy chỉnh và khái niệm bộ điều khiển ký tự mới của chúng tôi.

00:01:21.000 --> 00:01:25.000
Vì vậy, hãy đeo mặt nạ ống thở của bạn và đi sâu vào.

00:01:25.000 --> 00:01:30.000
Khi tôi lớn lên ở Trung Đông, tôi đã học lặn biển ở vùng Vịnh.

00:01:30.000 --> 00:01:36.000
Mặc dù tôi không được đội một trong những chiếc mũ bảo hiểm steampunk siêu dễ thương này, nhưng tôi thích nhìn thấy tất cả các trường học về cá đầy màu sắc.

00:01:36.000 --> 00:01:41.000
Tôi nghĩ sẽ rất thú vị khi tạo lại sự rung cảm dưới nước ngay tại đây trong phòng khách của tôi.

00:01:41.000 --> 00:01:49.000
Olivier và tôi đã viết bản demo này bằng cách sử dụng một loạt các tính năng mà chúng tôi sẽ giới thiệu cho bạn trong phiên này và trong phiên RealityKit thứ hai của chúng tôi vào cuối tuần này.

00:01:49.000 --> 00:01:59.000
Chúng tôi đã xử lý hậu kỳ để tạo ra hiệu ứng sương mù sâu và chất ăn da nước, một công cụ sửa đổi hình học tùy chỉnh để làm cho rong biển nhảy múa trên sóng và nhiều hơn nữa.

00:01:59.000 --> 00:02:04.000
Về cơ bản, RealityKit 2 cho phép bạn tùy chỉnh rất nhiều thứ ngay bây giờ.

00:02:04.000 --> 00:02:09.000
Mã mẫu này có sẵn để bạn dùng thử tại developer.apple.com.

00:02:09.000 --> 00:02:12.000
Có năm chủ đề chính mà chúng ta sẽ đề cập hôm nay.

00:02:12.000 --> 00:02:20.000
Chúng tôi sẽ tóm tắt lại ECS là gì và cách chúng tôi sử dụng tính năng hệ thống tùy chỉnh mới của mình để thực hiện hành vi đánh bắt cá trong ứng dụng của chúng tôi.

00:02:20.000 --> 00:02:36.000
Chúng tôi sẽ cho bạn thấy những tiến bộ trong những gì bạn có thể làm với vật liệu cũng như hình ảnh động, bộ điều khiển nhân vật mới, đó là cách chúng tôi khiến thợ lặn tương tác liền mạch với lưới AR của phòng khách và cách bạn có thể tạo tài nguyên trong thời gian chạy.

00:02:36.000 --> 00:02:38.000
Vậy hãy bắt đầu với ECS.

00:02:38.000 --> 00:02:47.000
ECS, viết tắt của hệ thống thành phần thực thể, là một cách cấu trúc dữ liệu và hành vi, và nó thường được sử dụng trong các trò chơi và mô phỏng.

00:02:47.000 --> 00:02:57.000
Nó khác với lập trình hướng đối tượng, trong đó bạn có xu hướng mô hình hóa một mục như một gói đóng gói của cả chức năng của nó và trạng thái được liên kết với mục đó.

00:02:57.000 --> 00:03:11.000
Nhưng với ECS, bạn có ba ngạnh: thực thể, thành phần và hệ thống, nơi chức năng đi vào hệ thống, trạng thái đi vào các thành phần và thực thể là số nhận dạng cho một nhóm các thành phần.

00:03:11.000 --> 00:03:22.000
Năm nay, với RealityKit 2, chúng tôi đang hướng tới việc triển khai ECS thuần túy hơn, hướng dẫn bạn giữ nhiều chức năng hơn trong lớp hệ thống với các hệ thống tùy chỉnh mới của chúng tôi.

00:03:22.000 --> 00:03:24.000
Thực thể có ý nghĩa gì với chúng ta?

00:03:24.000 --> 00:03:28.000
Một thực thể đại diện cho một điều trong khung cảnh của bạn.

00:03:28.000 --> 00:03:31.000
Đây là những thực thể đại diện cho các sinh vật biển trong khung cảnh của chúng ta.

00:03:31.000 --> 00:03:35.000
Một thực thể có thể có các thực thể con, cung cấp cho bạn một cấu trúc đồ thị để làm việc.

00:03:35.000 --> 00:03:42.000
Ví dụ, thành phần biến đổi sử dụng biến đổi của thực thể mẹ để thêm vị trí riêng của nó vào.

00:03:42.000 --> 00:03:46.000
Bản thân một thực thể không hiển thị bất cứ thứ gì trên màn hình.

00:03:46.000 --> 00:03:51.000
Đối với điều đó, bạn cần cung cấp cho nó một thành phần mô hình hoặc tạo một thực thể mô hình, điều này sẽ làm điều đó cho bạn.

00:03:51.000 --> 00:03:56.000
Để thêm các thuộc tính, thuộc tính và hành vi, bạn thêm các thành phần vào thực thể của mình.

00:03:56.000 --> 00:04:00.000
Nói về điều đó, hãy nói về các thành phần.

00:04:00.000 --> 00:04:06.000
Các thành phần dùng để lưu trữ trạng thái giữa các khung và để đánh dấu sự tham gia của một thực thể vào một hệ thống.

00:04:06.000 --> 00:04:10.000
Tuy nhiên, bạn không cần phải bao gồm bất kỳ logic nào để xử lý trạng thái đó ở đây.

00:04:10.000 --> 00:04:14.000
Logic và hành vi của bạn đi vào hệ thống tùy chỉnh của bạn.

00:04:14.000 --> 00:04:18.000
Có một số thành phần sẽ có mặt trên bất kỳ thực thể nào bạn tạo.

00:04:18.000 --> 00:04:24.000
Không được hiển thị ở đây là các thành phần tích hợp sẵn: các thành phần chuyển đổi và đồng bộ hóa.

00:04:24.000 --> 00:04:26.000
Họ ở trên cả ba thực thể này.

00:04:26.000 --> 00:04:34.000
Có những thứ khác mà bạn thường muốn thêm vào, như thành phần mô hình, chứa lưới và vật liệu làm cho thực thể của bạn hiển thị trên màn hình.

00:04:34.000 --> 00:04:41.000
Bạn cũng có thể thêm và xóa các thành phần khỏi các thực thể của mình trong thời gian chạy, nếu bạn muốn tự động thay đổi hành vi của chúng.

00:04:41.000 --> 00:04:47.000
Chúng tôi sẽ đánh dấu con cá đầu tiên này là tham gia vào Hệ thống đổ xô và chúng tôi sẽ nói với nó rằng nó thích ăn tảo.

00:04:47.000 --> 00:04:53.000
Con cá thứ hai này, nó cũng sẽ đổ đàn với con cá đầu tiên, nhưng nó thích ăn sinh vật phù du hơn ngay bây giờ.

00:04:53.000 --> 00:04:55.000
Anh chàng thứ ba này là một sinh vật phù du.

00:04:55.000 --> 00:04:57.000
Nó sẽ là thức ăn cho con cá thứ hai.

00:04:57.000 --> 00:05:02.000
Nó nên xem lại, bởi vì trong ứng dụng của chúng tôi, chúng tôi có một số sinh vật đói.

00:05:02.000 --> 00:05:07.000
Chúng tôi biết những người nào đang đói vì chúng có các thành phần AlgaeEater hoặc PlanktonEater trên đó.

00:05:07.000 --> 00:05:11.000
Mỗi khung hình, Hệ thống Ăn uống của chúng tôi đều có chức năng cập nhật được gọi.

00:05:11.000 --> 00:05:22.000
Ở đây, nó tìm thấy tất cả các thực thể trong cảnh có một trong hai thành phần này, cộng với tất cả các thực thể là thức ăn, vì vậy nó có thể hướng dẫn cá đói về phía thức ăn mà chúng thích ăn.

00:05:22.000 --> 00:05:30.000
Nhưng cách hiệu quả để Hệ thống Ăn uống tìm ra thực thể nào đang đói, thực thể nào là thực phẩm và thực thể nào không?

00:05:30.000 --> 00:05:35.000
Chúng tôi không muốn phải đi qua biểu đồ thực thể của mình và kiểm tra các thành phần của từng thành phần.

00:05:35.000 --> 00:05:38.000
Thay vào đó, chúng tôi thực hiện một truy vấn thực thể.

00:05:38.000 --> 00:05:41.000
Hãy để RealityKit làm sổ sách kế toán cho bạn.

00:05:41.000 --> 00:05:46.000
Hệ thống Flocking muốn tìm tất cả các thực thể có FlockingComponent trên đó.

00:05:46.000 --> 00:05:53.000
Trong khi Hệ thống Ăn uống muốn cả hai loại thực thể đói, cộng với thực thể đó là một loại thực phẩm.

00:05:53.000 --> 00:05:58.000
Vì vậy, chúng ta hãy xem xét kỹ hơn chính xác những gì đang xảy ra khi một hệ thống sử dụng một truy vấn thực thể.

00:05:58.000 --> 00:06:03.000
Các hệ thống có chức năng cập nhật của chúng được gọi là mọi khung hình.

00:06:03.000 --> 00:06:05.000
Hãy xem xét Hệ thống đổ xô cho cá Tang vàng của chúng ta.

00:06:05.000 --> 00:06:09.000
Chúng tôi sẽ tạm dừng ở khung hình này để xem chuyện gì đang xảy ra.

00:06:09.000 --> 00:06:18.000
Trong chức năng cập nhật của Hệ thống Flocking, chúng tôi truy vấn tất cả các thực thể trong cảnh có cả FlockingComponent và MotionComponent trên đó.

00:06:18.000 --> 00:06:24.000
Rất nhiều thứ có MotionComponent, nhưng chúng tôi không muốn tất cả chúng, chúng tôi chỉ muốn đàn của mình.

00:06:24.000 --> 00:06:32.000
Truy vấn của chúng tôi trả về cá đàn của chúng tôi, vì vậy bây giờ chúng tôi có thể điều khiển vật lý trò chơi tùy chỉnh của mình bằng cách áp dụng mô phỏng Boids cổ điển cho từng con cá trong đàn.

00:06:32.000 --> 00:06:46.000
Chúng tôi thêm lực lên MotionComponent của mỗi con cá, nơi chúng tôi giữ trạng thái giữa các khung hình, lực dính vào nhau, thích cách nhau một khoảng cách nhất định và cố gắng hướng mũi của chúng theo cùng một hướng.

00:06:46.000 --> 00:06:57.000
Khi Hệ thống chuyển động chạy, trong cùng một khung hình nhưng sau khi Hệ thống đổ xô chạy, nó cuộn tất cả các lực này lại để quyết định gia tốc, vận tốc và vị trí mới của cá.

00:06:57.000 --> 00:06:59.000
Nó không quan tâm hệ thống nào khác đã thêm chúng.

00:06:59.000 --> 00:07:07.000
Có những người khác, như Hệ thống Ăn uống và Hệ thống Sợ hãi cũng hoạt động trên MotionComponent để đẩy cá theo nhiều hướng khác nhau.

00:07:07.000 --> 00:07:10.000
Vậy hãy xem mã.

00:07:10.000 --> 00:07:13.000
Đây là phác thảo về Hệ thống đổ xô của chúng tôi.

00:07:13.000 --> 00:07:18.000
Đó là một lớp phù hợp với giao thức RealityKit.System.

00:07:18.000 --> 00:07:26.000
Khi bạn đăng ký hệ thống tùy chỉnh của mình tại thời điểm khởi chạy ứng dụng, bạn đang nói với công cụ rằng bạn muốn nó khởi tạo một trong những loại này cho mỗi cảnh trong ứng dụng của bạn.

00:07:26.000 --> 00:07:30.000
Init là bắt buộc, và bạn cũng có thể cung cấp một thiết kế.

00:07:30.000 --> 00:07:32.000
Chúng tôi có thể chỉ định các phụ thuộc.

00:07:32.000 --> 00:07:39.000
Hệ thống này phải luôn chạy trước MotionSystem, đó là lý do tại sao chúng tôi đã sử dụng giá trị liệt kê.trước đây.

00:07:39.000 --> 00:07:54.000
Trong chức năng cập nhật của chúng tôi, chúng tôi sẽ thay đổi trạng thái được lưu trữ trong MotionComponent và MotionSystem sẽ hoạt động theo trạng thái mà chúng tôi cung cấp, vì vậy chúng tôi cần đảm bảo FlockingSystem chạy trước MotionSystem, giống như mối quan hệ giữa nhà sản xuất và người tiêu dùng.

00:07:54.000 --> 00:07:57.000
Bạn cũng có thể sử dụng tùy chọn .after.

00:07:57.000 --> 00:08:05.000
Nếu bạn không chỉ định các phụ thuộc, các chức năng cập nhật hệ thống của bạn sẽ được thực hiện theo thứ tự bạn đã đăng ký chúng.

00:08:05.000 --> 00:08:10.000
EntityQuery của chúng tôi nói rằng chúng tôi muốn tất cả các thực thể có Thành phần Flocking và Motion.

00:08:10.000 --> 00:08:15.000
Đó là một phép tĩnh vì nó sẽ không thay đổi trong suốt thời gian mô phỏng của chúng tôi.

00:08:15.000 --> 00:08:22.000
Trong trải nghiệm AR nhiều người chơi, các thành phần phù hợp với mã hóa được tự động đồng bộ hóa qua mạng.

00:08:22.000 --> 00:08:27.000
Tuy nhiên, dữ liệu trong hệ thống không được tự động đồng bộ hóa qua mạng.

00:08:27.000 --> 00:08:30.000
Dữ liệu thường nên được lưu trữ trong các thành phần.

00:08:30.000 --> 00:08:34.000
Bây giờ chúng ta hãy đi sâu vào chức năng cập nhật của FlockingSystem của chúng ta.

00:08:34.000 --> 00:08:42.000
Nó cần một SceneUpdateContext, trong đó có deltaTime cho khung đó và một tham chiếu đến chính cảnh đó.

00:08:42.000 --> 00:08:52.000
Đầu tiên, chúng tôi thực hiện EntityQuery của mình trên hiện trường, trả về kết quả truy vấn mà chúng tôi có thể lặp lại cho các thực thể có FlockingComponent trên đó.

00:08:52.000 --> 00:08:57.000
Chúng tôi nhận được MotionComponent của mỗi người, mà chúng tôi sẽ sửa đổi.

00:08:57.000 --> 00:08:59.000
Tại sao chúng ta không nhận được FlockingComponent?

00:08:59.000 --> 00:09:02.000
Bởi vì nó không có bất kỳ dữ liệu nào liên quan đến nó.

00:09:02.000 --> 00:09:07.000
Chúng tôi sử dụng cái đó như một thẻ để biểu thị tư cách thành viên trong đàn.

00:09:07.000 --> 00:09:15.000
Sau đó, chúng tôi chạy mô phỏng Boids tiêu chuẩn của mình trên chúng để hướng dẫn đàn, sửa đổi tập hợp lực trong MotionComponent.

00:09:15.000 --> 00:09:28.000
Cuối cùng, vì chúng tôi đã thêm lực cho mỗi con cá để đẩy nó theo hướng mong muốn và bởi vì các thành phần là cấu trúc Swift là các loại giá trị, chúng tôi cần lưu trữ MotionComponent của mình trở lại thực thể mà nó đến từ.

00:09:28.000 --> 00:09:31.000
Các hệ thống không cần phải thực hiện chức năng cập nhật tùy chỉnh.

00:09:31.000 --> 00:09:39.000
Nó cũng có thể hữu ích để tạo ra một hệ thống chỉ cung cấp một init, như đăng ký trình xử lý sự kiện cho các sự kiện cảnh.

00:09:39.000 --> 00:09:45.000
Cho đến nay, chúng tôi đã xem xét các mối quan hệ giữa các thực thể, thành phần và hệ thống tùy chỉnh.

00:09:45.000 --> 00:09:52.000
Bây giờ hãy thu nhỏ một chút và nói về một số thay đổi kiến trúc cấp cao mà chúng tôi đã mang đến trong RealityKit 2.

00:09:52.000 --> 00:09:59.000
Trước đây, bạn sẽ đăng ký sự kiện SceneEvents.update bằng cách sử dụng đóng cửa sẽ được gọi là mọi khung hình.

00:09:59.000 --> 00:10:05.000
Những loại người xử lý sự kiện này thường sẽ sống, hoặc ít nhất là được đăng ký vào, các lớp học giống như Trình quản lý trò chơi của bạn.

00:10:05.000 --> 00:10:15.000
Thay vì đóng cửa như vậy, giờ đây bạn có thể tách logic cập nhật của mình một cách rõ ràng và được đặt hàng chính thức trong các chức năng cập nhật hệ thống riêng biệt.

00:10:15.000 --> 00:10:19.000
Vì vậy, điều đó có nghĩa là Người quản lý trò chơi của bạn có thể đóng ít vai trò hơn.

00:10:19.000 --> 00:10:36.000
Thay vì thực hiện tất cả các đăng ký của bạn để cập nhật sự kiện ở đó và sau đó quản lý thứ tự mà bạn gọi cập nhật tất cả mọi thứ trong trò chơi của mình, bây giờ Người quản lý trò chơi chỉ phải thêm các thành phần vào các thực thể để biểu thị cho hệ thống của bạn rằng các thực thể đó nên được đưa vào các truy vấn của họ.

00:10:36.000 --> 00:10:45.000
Trước đây, bạn sẽ khai báo sự phù hợp giao thức trên các lớp con thực thể của mình để thể hiện rằng loại thực thể đó có các thành phần nhất định.

00:10:45.000 --> 00:10:51.000
Bây giờ bạn không cần phải phân lớp thực thể nữa, vì nó cũng có thể đóng ít vai trò hơn.

00:10:51.000 --> 00:10:57.000
Nó có thể chỉ đơn thuần là một mã định danh cho một đối tượng và các thuộc tính của nó có thể được mô hình hóa như các thành phần.

00:10:57.000 --> 00:11:03.000
Bởi vì khi bạn không thực thể lớp con, bạn không ràng buộc đối tượng của mình mãi mãi giữ các thành phần đó.

00:11:03.000 --> 00:11:06.000
Bạn có thể tự do thêm và xóa các thành phần trong quá trình trải nghiệm.

00:11:06.000 --> 00:11:13.000
Vì vậy, với RealityKit 2, các thành phần tùy chỉnh của bạn hữu ích hơn rất nhiều vì bạn có các hệ thống tùy chỉnh.

00:11:13.000 --> 00:11:15.000
Nhưng bạn vẫn có thể làm điều đó theo cách nào đó.

00:11:15.000 --> 00:11:17.000
Đó là vẻ đẹp của sự phát triển trò chơi.

00:11:17.000 --> 00:11:19.000
Thế giới là con hàu của bạn.

00:11:19.000 --> 00:11:23.000
Trong bản demo dưới nước của chúng tôi, chúng tôi đang sử dụng cả hai phương pháp.

00:11:23.000 --> 00:11:27.000
Chúng tôi cũng đã thêm một loại thành phần mới: TransientComponent.

00:11:27.000 --> 00:11:33.000
Giả sử, ví dụ, cá của bạn sợ bạch tuộc, nhưng chỉ khi chúng đã từng nhìn vào nó.

00:11:33.000 --> 00:11:39.000
Khi bạn nhân bản một thực thể cá mới, bạn có thể không muốn bản sao thừa hưởng nỗi sợ bạch tuộc của con cá đó.

00:11:39.000 --> 00:11:43.000
Bạn có thể làm cho FearComponent của mình phù hợp với TransientComponent.

00:11:43.000 --> 00:11:47.000
Bằng cách đó, nó sẽ không có mặt trên thực thể mới.

00:11:47.000 --> 00:11:56.000
Tuy nhiên, TransientComponent vẫn được bao gồm trong đồng bộ hóa mạng, nếu nó phù hợp với mã hóa, giống như bất kỳ loại thành phần nào khác làm như vậy.

00:11:56.000 --> 00:11:59.000
Một bổ sung khác là tiện ích mở rộng mới của chúng tôi trên cancellable.

00:11:59.000 --> 00:12:04.000
Bạn không cần phải quản lý thủ công việc hủy đăng ký các sự kiện cho một thực thể nữa.

00:12:04.000 --> 00:12:08.000
Chúng tôi sẽ làm điều đó cho bạn khi bạn sử dụng storeWhileEntityActive.

00:12:08.000 --> 00:12:12.000
Ở đây, chúng tôi đang xử lý các sự kiện va chạm cho một thực thể cá.

00:12:12.000 --> 00:12:18.000
Chúng tôi không cần đăng ký này để tồn tại lâu hơn chính con cá, vì vậy chúng tôi sử dụng storeWhileEntityActive.

00:12:18.000 --> 00:12:25.000
Như mọi khi, khi xây dựng một trò chơi, có rất nhiều cài đặt mà bạn muốn điều chỉnh nhanh chóng mà không cần phải biên dịch lại.

00:12:25.000 --> 00:12:36.000
Trong trò chơi của chúng tôi, chúng tôi đã xây dựng chế độ xem Cài đặt trong SwiftUI và chúng tôi chuyển mô hình sao lưu của nó xuống các Hệ thống Tùy chỉnh khác nhau của mình bằng cách gói chúng trong CustomComponents.

00:12:36.000 --> 00:12:47.000
Chúng tôi tạo phiên bản Cài đặt của mình dưới dạng @StateObject và chuyển nó vào cả chế độ xem ARViewContainer và SwiftUI của chúng tôi dưới dạng environmentObject.

00:12:47.000 --> 00:12:51.000
Chúng tôi bọc đối tượng Cài đặt trong một Thành phần Tùy chỉnh, một Thành phần Cài đặt.

00:12:51.000 --> 00:12:56.000
Sau đó, khi chúng tôi tạo thực thể cá của mình, chúng tôi cung cấp cho nó một Thành phần Cài đặt.

00:12:56.000 --> 00:13:06.000
Bằng cách đó, khi bất kỳ Hệ thống Tùy chỉnh nào xuất hiện muốn các cài đặt đó, nó có thể đọc chúng từ đó, như lấy giá trị "tốc độ tối đa" và sử dụng nó để giới hạn vận tốc của mỗi con cá.

00:13:06.000 --> 00:13:12.000
Và bây giờ tôi sẽ giao nó cho đồng nghiệp của tôi, Olivier, để nói với bạn về tài liệu.

00:13:12.000 --> 00:13:14.000
Cảm ơn, Amanda.

00:13:14.000 --> 00:13:17.000
Năm nay, chúng tôi đã thêm các API mới cho các tài liệu.

00:13:17.000 --> 00:13:24.000
Chúng tôi đã có một vài loại, chẳng hạn như SimpleMaterial, với màu cơ bản, độ nhám và đặc tính kim loại.

00:13:24.000 --> 00:13:29.000
Chúng tôi cũng có UnlitMaterial, chỉ với một màu và không có ánh sáng.

00:13:29.000 --> 00:13:35.000
Chúng tôi đã có OcclusionMaterials, có thể được sử dụng như một mặt nạ để ẩn các đối tượng ảo.

00:13:35.000 --> 00:13:42.000
Và năm ngoái, chúng tôi đã giới thiệu VideoMaterials, đó là UnlitMaterials sử dụng video làm màu của chúng.

00:13:42.000 --> 00:13:45.000
Lưu ý rằng năm nay chúng tôi đã thêm hỗ trợ cho sự minh bạch.

00:13:45.000 --> 00:13:51.000
Nếu tệp video chứa độ trong suốt, nó sẽ được sử dụng để hiển thị đối tượng.

00:13:51.000 --> 00:14:03.000
Năm nay, chúng tôi đã thêm các API mới cung cấp cho bạn quyền kiểm soát vật liệu nâng cao hơn, bắt đầu với loại Vật liệu dựa trên vật lý, rất giống với lược đồ cho vật liệu bằng USD.

00:14:03.000 --> 00:14:10.000
Nó là một siêu tập hợp của SimpleMaterial và có hầu hết các thuộc tính PBR tiêu chuẩn mà bạn có thể tìm thấy trong các trình kết xuất khác.

00:14:10.000 --> 00:14:14.000
Đây là tài liệu mà bạn sẽ tìm thấy trên các thực thể đã được nạp từ một USD.

00:14:14.000 --> 00:14:24.000
Ví dụ, bạn có thể nạp USD của cá hề và sau đó sửa đổi các thuộc tính riêng lẻ trên vật liệu của nó để làm cho nó thành vàng hoặc tím.

00:14:24.000 --> 00:14:31.000
Trong số các thuộc tính của vật liệu, ví dụ, bạn có thể thay đổi bản đồ bình thường để thêm các chi tiết nhỏ không phải là một phần của lưới.

00:14:31.000 --> 00:14:35.000
Bạn cũng có thể chỉ định một kết cấu xác định độ trong suốt của mô hình.

00:14:35.000 --> 00:14:46.000
Theo mặc định, độ trong suốt đang sử dụng pha trộn alpha, nhưng nếu bạn cũng chỉ định ngưỡng mờ, tất cả các đoạn dưới ngưỡng đó sẽ bị loại bỏ.

00:14:46.000 --> 00:14:52.000
Bạn có thể thiết lập kết cấu cho sự tắc nghẽn môi trường xung quanh, xác định các bóng mờ trong mô hình.

00:14:52.000 --> 00:14:59.000
Và một ví dụ về đặc tính tiên tiến hơn là lớp phủ trong suốt, sẽ mô phỏng một lớp sơn phản chiếu bổ sung trên vật liệu.

00:14:59.000 --> 00:15:05.000
Và có nhiều thuộc tính khác có sẵn trên loại Vật liệu dựa trên vật lý.

00:15:05.000 --> 00:15:11.000
Chúng tôi cũng đã thêm một loại mới gọi là vật liệu tùy chỉnh để tạo ra vật liệu bằng mã kim loại của riêng bạn.

00:15:11.000 --> 00:15:15.000
Đây là những gì chúng tôi đã sử dụng để tạo hiệu ứng chuyển đổi màu sắc trên mô hình bạch tuộc này.

00:15:15.000 --> 00:15:21.000
Chúng tôi sẽ giải thích bộ đổ bóng này và các tài liệu tùy chỉnh trong buổi nói chuyện thứ hai về kết xuất.

00:15:21.000 --> 00:15:27.000
Ngoài các tài liệu, chúng tôi cũng đã thêm nhiều quyền kiểm soát hơn đối với hoạt ảnh trong RealityKit.

00:15:27.000 --> 00:15:35.000
Đầu tiên, hãy xem qua API hiện có cho hoạt ảnh, chủ yếu là về việc phát lại hoạt ảnh được tải từ USD.

00:15:35.000 --> 00:15:38.000
Nếu bạn tải một hình ảnh động từ một USD, bạn có thể chơi nó một lần.

00:15:38.000 --> 00:15:45.000
Bạn cũng có thể lặp lại nó để nó lặp lại vô hạn, đó là những gì chúng tôi muốn cho hoạt hình nhàn rỗi của thợ lặn của chúng tôi ở đây.

00:15:45.000 --> 00:15:49.000
Bạn cũng có thể tạm dừng, tiếp tục và dừng hoạt ảnh.

00:15:49.000 --> 00:15:55.000
Cuối cùng, khi phát một hình ảnh động mới, bạn có thể chỉ định thời lượng chuyển tiếp.

00:15:55.000 --> 00:16:00.000
Nếu bạn không chỉ định một cái, nhân vật sẽ ngay lập tức chuyển sang hình ảnh động mới.

00:16:00.000 --> 00:16:07.000
Nếu bạn chỉ định thời lượng chuyển tiếp, RealityKit sẽ pha trộn giữa hoạt ảnh cũ và mới trong thời gian đó.

00:16:07.000 --> 00:16:13.000
Điều này rất hữu ích, ví dụ, khi chuyển đổi giữa chu kỳ Đi bộ và Nhàn rỗi của thợ lặn.

00:16:13.000 --> 00:16:17.000
Nhưng chúng ta vẫn có thể cải thiện hình ảnh động của bàn chân ở đó.

00:16:17.000 --> 00:16:22.000
Chúng ta có thể sử dụng API mới cho các lớp pha trộn để làm cho hình ảnh động chân thực hơn.

00:16:22.000 --> 00:16:32.000
Chúng tôi phát hoạt hình Đi bộ và hoạt hình nhàn rỗi trên hai lớp pha trộn riêng biệt, và vì chúng tôi đã phát hoạt hình Đi bộ ở lớp trên cùng, đó là hoạt hình duy nhất mà chúng tôi hiện đang thấy.

00:16:32.000 --> 00:16:38.000
Nhưng chúng ta có thể thay đổi yếu tố pha trộn của hoạt ảnh Đi bộ để tiết lộ hoạt hình Nhàn rỗi bên dưới.

00:16:38.000 --> 00:16:45.000
Chú ý làm thế nào, khi yếu tố pha trộn trở nên nhỏ hơn, bước chân cũng trở nên nhỏ hơn.

00:16:45.000 --> 00:16:51.000
Và chúng ta cũng có thể thay đổi tốc độ phát lại của hình ảnh động để làm cho thợ lặn đi nhanh hơn hoặc chậm hơn.

00:16:51.000 --> 00:16:55.000
Ở đây, thợ lặn đang đi bộ với tốc độ một nửa.

00:16:55.000 --> 00:17:01.000
Cuối cùng, chúng tôi sử dụng tốc độ của ký tự so với mặt đất để kiểm soát cả hai giá trị này.

00:17:01.000 --> 00:17:08.000
Bằng cách này, chúng ta có thể làm cho hình ảnh động mượt mà hơn và giảm độ trượt của bàn chân so với mặt đất.

00:17:08.000 --> 00:17:14.000
Cho đến nay, chúng tôi đã sử dụng nhiều clip hoạt hình, chẳng hạn như chu kỳ Nhàn rỗi và Đi bộ.

00:17:14.000 --> 00:17:18.000
Chúng được lưu trữ dưới dạng Tài nguyên Hoạt hình trong RealityKit.

00:17:18.000 --> 00:17:21.000
Và có nhiều cách để tải chúng từ các tệp USD.

00:17:21.000 --> 00:17:25.000
Cách đầu tiên là có một tệp USD cho mỗi clip.

00:17:25.000 --> 00:17:31.000
Chúng ta có thể tải mỗi USD như một thực thể và nhận hoạt ảnh của nó dưới dạng AnimationResources.

00:17:31.000 --> 00:17:39.000
AnimationResource sau đó có thể được phát trên bất kỳ thực thể nào, miễn là tên của các khớp trong bộ xương của nó khớp với hoạt hình.

00:17:39.000 --> 00:17:50.000
Một cách khác để tải nhiều clip hoạt hình là có chúng trong một USD duy nhất trên cùng một dòng thời gian và sau đó sử dụng AnimationViews để cắt dòng thời gian này thành nhiều clip.

00:17:50.000 --> 00:17:54.000
Điều này đòi hỏi phải biết mã thời gian giữa mỗi clip.

00:17:54.000 --> 00:18:01.000
Mỗi AnimationView sau đó có thể được chuyển đổi thành AnimationResource và được sử dụng chính xác giống hệt như phương pháp trước đó.

00:18:01.000 --> 00:18:05.000
Bây giờ chúng ta hãy xem qua hình ảnh động của bạch tuộc trong ứng dụng.

00:18:05.000 --> 00:18:11.000
Con bạch tuộc đang trốn, nhưng khi người chơi đến gần, nó sẽ sợ hãi và di chuyển đến một nơi ẩn náu mới.

00:18:11.000 --> 00:18:13.000
Hãy xem làm thế nào để tạo hiệu ứng động cho nó.

00:18:13.000 --> 00:18:18.000
Chúng tôi bắt đầu với việc tải các hình ảnh động xương của bạch tuộc: nhảy, bơi và hạ cánh.

00:18:18.000 --> 00:18:24.000
Những hình ảnh động này được tải từ một USD, giống như những gì chúng tôi đã làm cho thợ lặn.

00:18:24.000 --> 00:18:29.000
Nhưng chúng tôi cũng muốn làm sinh động sự biến đổi của bạch tuộc để di chuyển nó từ vị trí này sang vị trí khác.

00:18:29.000 --> 00:18:38.000
Để tạo hiệu ứng động cho việc chuyển đổi, chúng tôi sử dụng một API mới để tạo một hình ảnh động kiểu FromToByAnimation theo chương trình.

00:18:38.000 --> 00:18:41.000
Bằng cách này, chúng ta có thể tạo hiệu ứng động cho vị trí.

00:18:41.000 --> 00:18:46.000
Hãy xem nó trông như thế nào trên bạch tuộc.

00:18:46.000 --> 00:18:53.000
Để làm cho nó thú vị hơn, chúng ta cũng hãy tạo hiệu ứng động cho vòng quay.

00:18:53.000 --> 00:18:59.000
Bạch tuộc bây giờ quay trong khi nó di chuyển, nhưng nó đang bơi sang một bên, điều này không thực tế lắm.

00:18:59.000 --> 00:19:03.000
Chúng ta có thể cải thiện điều này bằng cách tạo ra một chuỗi các hình ảnh động.

00:19:03.000 --> 00:19:07.000
Đầu tiên, chúng tôi xoay con bạch tuộc về phía vị trí mới.

00:19:07.000 --> 00:19:10.000
Sau đó chúng tôi dịch nó sang vị trí mới.

00:19:10.000 --> 00:19:15.000
Và cuối cùng, chúng tôi xoay con bạch tuộc trở lại phía máy ảnh.

00:19:15.000 --> 00:19:22.000
Và đây là hình ảnh động đầy đủ.

00:19:22.000 --> 00:19:29.000
Ngoài các API mới cho hoạt ảnh, chúng tôi cũng đã thêm một cách để quản lý vật lý của các nhân vật.

00:19:29.000 --> 00:19:31.000
Nó được gọi là bộ điều khiển nhân vật.

00:19:31.000 --> 00:19:36.000
Điều này cho phép chúng tôi tạo ra các nhân vật có thể tương tác vật lý với các máy va chạm trong cảnh.

00:19:36.000 --> 00:19:41.000
Ở đây, chúng ta thấy thợ lặn nhảy từ sàn lên đi văng và đi trên đó.

00:19:41.000 --> 00:19:45.000
Điều này đạt được bằng cách thêm một bộ điều khiển ký tự vào thợ lặn.

00:19:45.000 --> 00:19:52.000
Với điều đó, thợ lặn sẽ tự động tương tác với lưới môi trường, được tạo ra từ cảm biến LiDAR.

00:19:52.000 --> 00:19:55.000
Tạo một bộ điều khiển ký tự rất đơn giản.

00:19:55.000 --> 00:19:59.000
Tất cả những gì bạn cần làm là xác định một viên nang phù hợp với hình dạng nhân vật của bạn.

00:19:59.000 --> 00:20:05.000
Khi sáng tạo, bạn phải chỉ định chiều cao của viên nang và bán kính của nó.

00:20:05.000 --> 00:20:11.000
Sau khi bộ điều khiển ký tự đã được gán cho thực thể, bạn có thể gọi hàm di chuyển (đến:) mọi khung hình.

00:20:11.000 --> 00:20:17.000
Nó sẽ khiến nhân vật di chuyển đến vị trí mong muốn, nhưng không vượt qua chướng ngại vật.

00:20:17.000 --> 00:20:22.000
Mặt khác, nếu bạn muốn bỏ qua chướng ngại vật, bạn có thể sử dụng chức năng dịch chuyển tức thời.

00:20:22.000 --> 00:20:29.000
Bây giờ tôi sẽ giao nó cho Amanda, người sẽ đưa bạn qua một vài tính năng thú vị hơn mà chúng tôi đã thêm vào bản phát hành RealityKit này.

00:20:29.000 --> 00:20:31.000
Tuyệt vời. Cảm ơn, Olivier.

00:20:31.000 --> 00:20:40.000
Được rồi, vì vậy tôi sẽ làm nổi bật hai API mới có sẵn để tạo tài nguyên một cách nhanh chóng mà không cần phải tải chúng từ đĩa.

00:20:40.000 --> 00:20:47.000
Đầu tiên tôi sẽ chỉ cho bạn cách bạn có thể lấy lưới khuôn mặt của một người từ SceneUnderstanding, và sau đó tôi sẽ hướng dẫn bạn cách tạo âm thanh.

00:20:47.000 --> 00:20:52.000
Có một biển khả năng mà những thứ này mở ra cho nghệ thuật được tạo ra theo thủ tục.

00:20:52.000 --> 00:20:55.000
Đầu tiên, lưới mặt.

00:20:55.000 --> 00:21:06.000
Tôi đã rất lấy cảm hứng từ vẻ ngoài của bạch tuộc màu tím và cam mà chúng tôi có trong ứng dụng demo của mình, tôi đã thử vẽ một con trên khuôn mặt của mình, nhưng hầu như, sử dụng khả năng lưới mặt mới.

00:21:06.000 --> 00:21:18.000
SceneUnderstanding giờ đây có thể cung cấp cho bạn các thực thể đại diện cho khuôn mặt của mọi người và các thực thể đó có ModelComponents trên đó, có nghĩa là bạn có thể hoán đổi các thuộc tính của vật liệu trên lưới của thực thể khuôn mặt.

00:21:18.000 --> 00:21:24.000
Chúng tôi đã có rất nhiều niềm vui khi tạo ra các kết cấu để áp dụng cho lưới mặt một cách nhanh chóng với các bản vẽ trực tiếp của chúng tôi.

00:21:24.000 --> 00:21:26.000
Hãy nhìn vào mã.

00:21:26.000 --> 00:21:44.000
SceneUnderstandingComponent hiện có một thuộc tính enum được gọi là entityType, được thiết lập bởi SceneUnderstandingSystem và có thể lấy một trong hai giá trị: face, có nghĩa là nó đại diện cho khuôn mặt của một người trong thế giới thực, hoặc meshChunk, có nghĩa là nó là một số phần khác của lưới thế giới được tái tạo lại.

00:21:44.000 --> 00:21:48.000
Nó cũng có thể là số không, có nghĩa là loại của nó vẫn chưa được biết đến.

00:21:48.000 --> 00:21:50.000
Đây là một EntityQuery một lần nữa.

00:21:50.000 --> 00:21:57.000
Bạn có thể truy vấn các thực thể có SceneUnderstandingComponent và kiểm tra entityType của chúng để tìm khuôn mặt.

00:21:57.000 --> 00:22:02.000
Sau đó, bạn có thể lấy ModelComponents từ các thực thể đó và làm bất cứ điều gì bạn muốn với chúng.

00:22:02.000 --> 00:22:14.000
Trong mẫu vẽ mặt của chúng tôi, chúng tôi đang sử dụng PencilKit để cho phép mọi người vẽ trên khung vẽ và sau đó gói CGImage kết quả lên khuôn mặt Entity bằng cách tạo TextureResource từ CGImage đó.

00:22:14.000 --> 00:22:25.000
Chúng tôi đang sử dụng Vật liệu dựa trên vật lý để có thể làm cho lớp sơn mặt này trông chân thực nhất có thể và chúng tôi đang thiết lập một vài thuộc tính trên đó để quay số cho giao diện của chúng tôi.

00:22:25.000 --> 00:22:36.000
Để tạo hiệu ứng sơn lấp lánh, chúng tôi sử dụng kết cấu bản đồ bình thường cho trình kết xuất dựa trên vật lý biết nó sẽ phản chiếu ánh sáng khác nhau như thế nào trên bề mặt này so với khi chúng tôi chỉ đơn giản rời khỏi vật liệu kim loại.

00:22:36.000 --> 00:22:43.000
Sau đó, chúng tôi cung cấp TextureResource được vẽ bằng bút chì cho vật liệu và đặt nó trên thực thể.

00:22:43.000 --> 00:22:47.000
Vì vậy, đó là một cách để làm việc với các tài nguyên được tạo mới của chúng tôi.

00:22:47.000 --> 00:22:51.000
Một loại tài nguyên khác mà bây giờ bạn có thể tạo ra là AudioBufferResource.

00:22:51.000 --> 00:23:01.000
Bạn có thể nhận AVAudioBuffer theo cách bạn muốn: bằng cách ghi lại đầu vào micrô, tự tạo nó theo thủ tục hoặc sử dụng AVSpeechSynthesizer.

00:23:01.000 --> 00:23:08.000
Sau đó, bạn có thể sử dụng AVAudioBuffer để tạo Tài nguyên AudioBuffer và sử dụng nó để phát âm thanh trong ứng dụng của mình.

00:23:08.000 --> 00:23:14.000
Đây là cách chúng tôi biến văn bản thành lời nói bằng cách viết AVSpeechUtterance thành AVSpeechSynthesizer.

00:23:14.000 --> 00:23:17.000
Chúng tôi nhận được AVAudioBuffer trong một cuộc gọi lại.

00:23:17.000 --> 00:23:26.000
Ở đây, chúng tôi đang tạo một AudioBufferResource và đặt inputMode của nó thành .spatial để sử dụng âm thanh vị trí 3D.

00:23:26.000 --> 00:23:30.000
Các chế độ đầu vào có sẵn khác là không gian và môi trường xung quanh.

00:23:30.000 --> 00:23:33.000
Sau đó, chúng tôi yêu cầu một thực thể phát âm thanh đó.

00:23:33.000 --> 00:23:43.000
Tất nhiên, bạn có thể xử lý bộ đệm âm thanh bằng các thủ thuật lạ mắt để làm cho nó có vẻ như cá của bạn đang thổi bong bóng khi chúng nói chuyện dưới nước hoặc bất cứ điều gì thú vị mà bạn có thể nghĩ ra.

00:23:43.000 --> 00:23:47.000
Vì vậy, đây là tổng quan về một số tính năng mới trong RealityKit năm nay.

00:23:47.000 --> 00:23:52.000
Chúng tôi đã thực sự tập trung vào việc giúp bạn kiểm soát nhiều hơn sự xuất hiện và hành vi của các cảnh của bạn.

00:23:52.000 --> 00:24:00.000
Chúng tôi đã sửa đổi ECS của mình để cung cấp cho bạn các hệ thống tùy chỉnh, điều này giúp bạn linh hoạt hơn trong việc cấu trúc các hành vi của ứng dụng.

00:24:00.000 --> 00:24:04.000
Chúng tôi đã thêm rất nhiều tiến bộ vào tài liệu và API hoạt hình của mình.

00:24:04.000 --> 00:24:10.000
Chúng tôi đã giới thiệu bộ điều khiển ký tự để giúp các thực thể của bạn dễ dàng tương tác với môi trường thế giới thực.

00:24:10.000 --> 00:24:15.000
Cuối cùng, chúng tôi đã nêu bật một số cách mà bạn có thể tạo tài nguyên một cách nhanh chóng.

00:24:15.000 --> 00:24:19.000
Nhưng đó chắc chắn không phải là một danh sách đầy đủ mọi thứ mới trong RealityKit 2.

00:24:19.000 --> 00:24:29.000
Trong phiên RealityKit thứ hai của chúng tôi vào cuối tuần này, bạn có thể tìm hiểu thêm về khả năng kết xuất mới và xem cách chúng tôi triển khai một số thứ trong bản demo dưới nước của mình.

00:24:29.000 --> 00:24:32.000
Công cụ sửa đổi hình học là những gì chúng ta sử dụng để tạo hiệu ứng động cho rong biển của mình.

00:24:32.000 --> 00:24:37.000
Bạch tuộc sử dụng các bộ đổ bóng bề mặt để chuyển đổi đẹp mắt giữa các màu sắc của nó.

00:24:37.000 --> 00:24:43.000
Hiệu ứng sương mù có độ sâu xanh lam cũng như các chất ăn da dưới nước được tạo ra bằng cách sử dụng xử lý hậu kỳ.

00:24:43.000 --> 00:24:48.000
Và trong chủ đề tài nguyên tổng hợp, bạn sẽ học cách sử dụng các mắt lưới động.

00:24:48.000 --> 00:24:55.000
Để bồi dưỡng, bạn cũng có thể muốn xem phiên "Xây dựng ứng dụng với RealityKit" từ năm 2019.

00:24:55.000 --> 00:25:01.000
Cảm ơn bạn, và chúng tôi mong muốn được nhìn thấy chiều sâu sáng tạo của bạn với các API này.

00:25:01.000 --> 23:59:59.000
[Nhạc lạc quan].

