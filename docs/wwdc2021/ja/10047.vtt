WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:13.000
ブラッド・フォード:こんにちは、「カメラキャプチャの新機能」へようこそ。

00:00:13.000 --> 00:00:16.000
私はカメラソフトウェアチームのブラッド・フォードです。

00:00:16.000 --> 00:00:37.000
最小焦点距離レポートから始まる新しいカメラ機能のホストを紹介します。 10ビットHDRビデオをキャプチャする方法。 メインコース、コントロールセンターのビデオエフェクト。 そして、新機能からの短い休息 - カメラアプリから最高のパフォーマンスを得るための戦略を確認します。

00:00:37.000 --> 00:00:44.000
そして最後に、あなたのバッグにまったく新しいパフォーマンストリック、IOSurface圧縮を紹介します。

00:00:44.000 --> 00:00:52.000
今日説明するすべての機能は、AVFoundationフレームワークにあります。具体的には、AVCaptureの接頭辞が付いたクラスです。

00:00:52.000 --> 00:01:13.000
簡単に確認するために、主なオブジェクトは、カメラまたはマイクを表すAVCaptureDevicesです。 AVCaptureDeviceInputsは、デバイスをラップし、AVCaptureグラフの中央制御オブジェクトであるAVCaptureSessionに接続できるようにします。

00:01:13.000 --> 00:01:17.000
AVCaptureOutputsは、さまざまな方法で入力からデータをレンダリングします。

00:01:17.000 --> 00:01:21.000
MovieFileOutputはQuickTimeムービーを記録します。

00:01:21.000 --> 00:01:26.000
PhotoOutputは、高品質の静止画とLive Photosをキャプチャします。

00:01:26.000 --> 00:01:35.000
VideoDataOutputやAudioDataOutputなどのデータ出力は、カメラやマイクからアプリにビデオまたはオーディオバッファを配信します。

00:01:35.000 --> 00:01:43.000
メタデータや深度など、他にもいくつかの種類のデータ出力があります。

00:01:43.000 --> 00:01:53.000
ライブカメラのプレビューには、CALayerのサブクラスであるAVCaptureVideoPreviewLayerという特別なタイプの出力があります。

00:01:53.000 --> 00:02:04.000
データは、これらの矢印で表されるAVCaptureConnectionsを介して、キャプチャ入力から互換性のあるキャプチャ出力に流れます。

00:02:04.000 --> 00:02:13.000
AVFoundationカメラキャプチャを初めてご利用になる場合は、developer.apple.comのカメラとメディアキャプチャのスタートページで詳細をご覧ください。

00:02:13.000 --> 00:02:17.000
さて、最初の新機能に飛び込みましょう。

00:02:17.000 --> 00:02:24.000
最小焦点距離は、レンズからシャープな焦点を達成できる最も近いポイントまでの距離です。

00:02:24.000 --> 00:02:29.000
これは、デジタル一眼レフカメラやスマートフォンなど、すべてのレンズの属性です。

00:02:29.000 --> 00:02:36.000
iPhoneのカメラにも最小の焦点距離がありますが、これまでに公開したことがありません...

00:02:36.000 --> 00:02:38.000
...今まで、それは。

00:02:38.000 --> 00:02:46.000
iOS 15以降、最小焦点距離はiPhoneのオートフォーカスカメラの公開プロパティです。

00:02:46.000 --> 00:02:48.000
これは最近のiPhoneのサンプルです。

00:02:48.000 --> 00:02:56.000
このチャートは、広角カメラと望遠カメラの最小焦点距離がモデルによってどのように異なるかを示しています。

00:02:56.000 --> 00:03:09.000
iPhone 12 Proと12 Pro Max Wideカメラには顕著な違いがあり、Pro MaxはProの12と比較して15センチメートルの最小距離に焦点を合わせています。

00:03:09.000 --> 00:03:16.000
これは、iPhone 12 Pro Maxのセンサーシフト安定化技術によるものです。

00:03:16.000 --> 00:03:23.000
同様に、テレの最小焦点距離は12 Pro Maxで12 Proよりも遠いです。

00:03:23.000 --> 00:03:27.000
これは、望遠レンズのリーチが長くなったためです。

00:03:27.000 --> 00:03:32.000
それは2.5倍対2倍のズームを持っています。

00:03:32.000 --> 00:03:42.000
最小焦点距離の報告が重要な理由の簡単なデモをお見せしましょう。

00:03:42.000 --> 00:03:45.000
これはAVCamBarcodeというサンプルアプリです。

00:03:45.000 --> 00:03:48.000
AVFoundationバーコード検出APIを紹介しています。

00:03:48.000 --> 00:03:54.000
UIは、スキャンのために長方形の中にオブジェクトを配置するようにユーザーを導きます。

00:03:54.000 --> 00:03:59.000
この例では、紙にかなり小さなQRコードを選択しました。

00:03:59.000 --> 00:04:02.000
バーコードの幅はわずか20ミリメートルです。

00:04:02.000 --> 00:04:10.000
メタデータボタンをタップすると、AVCaptureMetadataOutputでサポートされているさまざまなオブジェクトタイプのリストが表示されます。

00:04:10.000 --> 00:04:12.000
たくさんありますよ

00:04:12.000 --> 00:04:21.000
QRコードを選択し、iPhone 12 Pro Maxカメラを配置して、長方形をQRコードで埋めます。

00:04:21.000 --> 00:04:27.000
残念ながら、それはとても小さいので、プレビューを埋めるためにページに非常に近づかなければなりません。

00:04:27.000 --> 00:04:30.000
それはカメラの最小焦点距離よりも近いです。

00:04:30.000 --> 00:04:33.000
コードがぼやけているので、スキャンされません。

00:04:33.000 --> 00:04:42.000
ユーザーを後退させるには、カメラのプレビューにズームファクターを適用する必要があります...

00:04:42.000 --> 00:04:44.000
...そうであるように。

00:04:44.000 --> 00:04:49.000
画面上でズームされた画像を見ると、カメラを紙から遠くに物理的に動かすように促されます。

00:04:49.000 --> 00:04:58.000
スライダーボタンでできますが、アプリが自動的にズームを処理した方がはるかに良いでしょう。

00:04:58.000 --> 00:05:03.000
そこで、AVCaptureDeviceの新しいminimumFocusDistanceプロパティが登場します。

00:05:03.000 --> 00:05:06.000
iOS 15では新機能です。

00:05:06.000 --> 00:05:26.000
カメラの水平視野、スキャンしたい最小バーコードサイズ（ここでは20ミリメートルに設定しました）、カメラプレビューウィンドウの幅をパーセンテージとして、そのプレビュー幅を埋めるために必要な最小被写体距離を計算するために少し計算することができます。

00:05:26.000 --> 00:05:39.000
次に、カメラの新しいminimumFocusDistanceプロパティを使用して、カメラが近くにフォーカスできないときを検出し、ユーザーを後退させるのに十分な大きさのズーム係数を計算することができます。

00:05:39.000 --> 00:05:48.000
そして最後に、設定のためにロックし、ズーム係数を設定してからロックを解除することで、カメラに適用します。

00:05:48.000 --> 00:05:58.000
デモアプリを再コンパイルした後、UIは自動的に正しいズーム量を適用します。

00:05:58.000 --> 00:06:02.000
アプリが起動すると、すでに正しいスペースにズームされています。

00:06:02.000 --> 00:06:05.000
ぼやけたバーコードはもうありません!

00:06:05.000 --> 00:06:10.000
そして、私がそれをタップすると、それが私をどこに連れて行くかを見ることができます。

00:06:10.000 --> 00:06:14.000
ああ！「iPhone写真で奥行きを捉える」 - オールディーだがグッディだ。

00:06:14.000 --> 00:06:20.000
私はそのセッションに深く感謝しています。

00:06:20.000 --> 00:06:31.000
最小焦点距離を組み込む方法のベストプラクティスと、バーコードをスキャンするための他の多くのベストプラクティスについては、新しいAVCamBarcodeサンプルをチェックしてください。

00:06:31.000 --> 00:06:35.000
次は10ビットHDRビデオです。

00:06:35.000 --> 00:06:43.000
HDRはハイダイナミックレンジの略で、iOS 4.1にさかのぼって以来、静止画技術として存在しています。

00:06:43.000 --> 00:06:53.000
ハイダイナミックレンジの維持は、通常、シーンの複数の露出を取り、ハイライトとシャドウの両方を維持するためにそれらをブレンドすることによって達成されます。

00:06:53.000 --> 00:06:56.000
しかし、ビデオHDRはどうですか?

00:06:56.000 --> 00:07:02.000
1秒間に30または60フレームを配信しなければならないので、それは挑戦です。

00:07:02.000 --> 00:07:13.000
正確にはビデオHDRではありませんが、2018年、AppleはiPhone XSのカメララインにEDRまたは拡張ダイナミックレンジを導入しました。

00:07:13.000 --> 00:07:18.000
EDRは、ビデオ用のHDRのようなソリューションです。

00:07:18.000 --> 00:07:30.000
基本的にキャプチャフレームレートを2倍にし、標準露出と短い露出を交互にしますが、キャプチャ間に垂直ブランキングが事実上ないため、タイミングが設定されています。

00:07:30.000 --> 00:07:38.000
名目上毎秒30フレームをキャプチャする場合、EDRビデオは実際には毎秒60フレームでカメラを実行しています。

00:07:38.000 --> 00:07:50.000
シーンで必要な場合、EV-からの色相マップはEV0画像に動的に適用され、クリップされたハイライトを回復しますが、影の細部を犠牲にすることなく。

00:07:50.000 --> 00:08:00.000
暗い場所では効果が低下するため、完全なHDRソリューションではありませんが、中程度から良好な光で驚くべき結果が得られます。

00:08:00.000 --> 00:08:02.000
さて、ここに紛らわしい部分があります。

00:08:02.000 --> 00:08:10.000
EDRは、videoHDRのあだ名でAVCaptureDeviceプロパティのスイートとして提示されました。

00:08:10.000 --> 00:08:19.000
AVCapture APIでvideoHDRSupportedまたはvideoHDREnabledが表示される場合は、精神的にEDRを置き換える必要があります。

00:08:19.000 --> 00:08:22.000
それがそれです。

00:08:22.000 --> 00:08:30.000
AVCaptureDeviceには「automaticallyAdjusts VideoHDREnabled」というプロパティもあり、デフォルトはtrueです。

00:08:30.000 --> 00:08:35.000
したがって、EDRは利用可能なときはいつでも自動的に有効になります。

00:08:35.000 --> 00:08:48.000
何らかの理由で無効にしたい場合は、automaticAdjustsVideo HDREnabledをfalseに設定し、videoHDREnabledもfalseに設定する必要があります。

00:08:48.000 --> 00:08:50.000
今、物語はさらに良くなっています。

00:08:50.000 --> 00:08:58.000
10ビットHDRビデオについてあなたに話すことができるように、EDRについてあなたに話す必要がありました。

00:08:58.000 --> 00:09:04.000
10ビットHDRビデオは、より多くのビットを持っているので、本当にハイダイナミックレンジです!

00:09:04.000 --> 00:09:07.000
それは編集性の向上を意味します。

00:09:07.000 --> 00:09:12.000
それはハイライト回復のためのEDRを持っており、それは常にオンです。

00:09:12.000 --> 00:09:23.000
ハイブリッド対数ガンマ曲線とBT.2020色空間を使用し、Rec 709よりも明るい明るい色のコントラストをさらに高めます。

00:09:23.000 --> 00:09:39.000
また、AVCaptureMovieFileOutputまたはAVCaptureVideoDataOutputとAVAssetWriterを使用する場合でも、フレームごとのドルビービジョンメタデータをムービーに自動的に挿入し、ドルビービジョンディスプレイと互換性があります。

00:09:39.000 --> 00:09:45.000
10ビットHDRビデオは、iPhone 12で初めて導入されました。

00:09:45.000 --> 00:09:50.000
10ビットHDRビデオフォーマットは、独自のピクセルフォーマットタイプで識別できます。

00:09:50.000 --> 00:09:56.000
古いiPhoneモデルでは、カメラには常にペアで来るAVCaptureDeviceFormatsがあります。

00:09:56.000 --> 00:10:03.000
解像度とフレームレートの範囲ごとに、420vと420fのフォーマットがあります。

00:10:03.000 --> 00:10:07.000
これらは8ビット、バイプラナー、YUVフォーマットです。

00:10:07.000 --> 00:10:21.000
420vのVはビデオ範囲（または16〜235）を表し、420fのFはフルレンジ（または0〜255）を表します。

00:10:21.000 --> 00:10:26.000
iPhone 12モデルでは、いくつかのフォーマットは3つのクラスターで提供されます。

00:10:26.000 --> 00:10:34.000
420vフォーマットと420fフォーマットの後、同じ解像度とフレームレート範囲のx420フォーマットが登場します。

00:10:34.000 --> 00:10:46.000
420vと同様に、x420はビデオ範囲のバイプレーナー420フォーマットですが、x420のxは8ビットではなく10ビットを表します。

00:10:46.000 --> 00:11:06.000
コード内の10ビットHDRビデオフォーマットを見つけて選択するには、ピクセルフォーマットがx420、または-深呼吸-420YpCbCr10BiPlanarVideoRangeに一致するものが見つかるまで、AVCaptureDeviceフォーマットを反復するだけです。

00:11:06.000 --> 00:11:13.000
もちろん、幅、高さ、最大フレームレートなど、他の検索条件を含めることができます。

00:11:13.000 --> 00:11:18.000
AVCamのサンプルコードを更新して、利用可能な場合は10ビットHDRビデオをサポートしました。

00:11:18.000 --> 00:11:29.000
「tenBitVariantOfFormat」と呼ばれる便利なユーティリティ機能があり、現在選択されているデバイスのアクティブフォーマットが何であれ、10ビットHDRバリアントを見つけることができます。

00:11:29.000 --> 00:11:32.000
見てください。

00:11:32.000 --> 00:11:41.000
10ビットHDRビデオは、720p、1080p、4Kなど、最も人気のあるすべてのビデオフォーマットでサポートされています。

00:11:41.000 --> 00:11:53.000
また、12メガピクセルの高解像度写真をサポートする4×3フォーマット（1920×1440）も含めました。

00:11:53.000 --> 00:12:00.000
10ビットHDRビデオのキャプチャは簡単ですが、適切に編集して再生するのは難しいです。

00:12:00.000 --> 00:12:10.000
「AVFoundationでHDRビデオを編集して再生する」と題した2020年のコンパニオンセッションをご覧ください。

00:12:10.000 --> 00:12:14.000
よし、HDRビデオはそれだけだ。

00:12:14.000 --> 00:12:20.000
では、メインイベント：コントロールセンターのビデオエフェクト。

00:12:20.000 --> 00:12:28.000
簡単に言えば、これらはコードの変更なしでアプリで利用できるシステムレベルのカメラ機能です。

00:12:28.000 --> 00:12:32.000
そして、ユーザーがコントロールしています。

00:12:32.000 --> 00:12:34.000
これは私たちにとってちょっとした出発です。

00:12:34.000 --> 00:12:42.000
伝統的に、iOSやmacOSに新しいカメラ機能を導入すると、Appleのアプリは箱から出してそれを採用しています。

00:12:42.000 --> 00:12:51.000
私たちは新しいAVCapture APIを公開し、あなたは今やっているのと同じようにそれらについて学び、自分のペースで機能を採用します。

00:12:51.000 --> 00:13:01.000
これは安全で保守的なアプローチですが、多くの場合、ユーザーがお気に入りのカメラアプリの素晴らしい機能を逃す長いリードタイムになります。

00:13:01.000 --> 00:13:16.000
コントロールセンターのビデオエフェクトでは、コードの変更なしで誰でもすぐに利用できるシステムレベルのパッケージ化されたカメラ機能を導入し、ユーザーがコントロールできます。

00:13:16.000 --> 00:13:26.000
これらの機能の新しいAPIを公開し続けているので、リリーススケジュールが許せばすぐにアプリのエクスペリエンスを調整できます。

00:13:26.000 --> 00:13:28.000
これらの効果を見てみましょう。 では、これらの効果を見てみましょう

00:13:28.000 --> 00:13:34.000
1つ目は、5月のSpring Loaded Appleイベントで発表され、「センターステージ」と呼ばれています。

00:13:34.000 --> 00:13:44.000
最近リリースされたM1 iPad Proモデルで利用可能で、信じられないほどの12メガピクセルの超広角フロントカメラを利用しています。

00:13:44.000 --> 00:13:49.000
センターステージは、FaceTimeビデオ通話の制作価値を本当に高めます。

00:13:49.000 --> 00:13:53.000
また、他のすべてのビデオ会議アプリで箱から出してすぐに機能します。

00:13:53.000 --> 00:13:55.000
ほら、お見せしましょう。

00:13:55.000 --> 00:14:03.000
App StoreからSkypeをダウンロードしたところです。これはアプリのストックバージョンです。

00:14:03.000 --> 00:14:08.000
Skype通話を開始すると、すぐにセンターステージが行動を起こすのが見えます。

00:14:08.000 --> 00:14:12.000
それはあなた自身の個人的なカメラオペレーターを持っているようなものです。

00:14:12.000 --> 00:14:22.000
あなたがタイトに来るか、戻ってペースが好きかにかかわらず、あなたを完璧にフレームに保つために、あなたがシーンを動き回っているときにあなたをフレーミングします。

00:14:22.000 --> 00:14:26.000
カメラから顔をそらすと、あなたを追跡することさえできます。

00:14:26.000 --> 00:14:31.000
それは、顔だけでなく、体を追跡するからです。

00:14:31.000 --> 00:14:43.000
ユーザーとして、コントロールセンターを下にスワイプし、新しいビデオエフェクトモジュールをタップして選択するだけで、センターステージを制御できます。

00:14:43.000 --> 00:14:49.000
センターステージをオフにしてアプリに戻ると、センターステージ効果がなくなります。

00:14:49.000 --> 00:14:52.000
アプリに変更はありません。

00:14:52.000 --> 00:14:59.000
すべてのビデオ会議アプリにも得られるコンパニオン新機能があり、それは「ポートレート」と呼ばれています。

00:14:59.000 --> 00:15:03.000
ポートレートモードは、美しくレンダリングされた浅い被写界深度効果を提供します。

00:15:03.000 --> 00:15:16.000
単純なプライバシーのぼかしだけではありません。Appleのニューラルエンジンと訓練された単眼深度ネットワークを使用して、ワイドオープンレンズで実際のカメラを近似します。

00:15:16.000 --> 00:15:33.000
最後に、下にスワイプしてマイクモードモジュールを選択して、マイクモードを見てみましょう。標準、音声分離、またはワイドスペクトラムのどちらかを選択できます。

00:15:33.000 --> 00:15:37.000
マイクモードは、ビデオチャットのオーディオ品質を向上させます。

00:15:37.000 --> 00:15:39.000
これらについては1分で詳しく。

00:15:39.000 --> 00:15:48.000
センターステージ、ポートレート、マイクモードはコントロールセンターで画面の不動産を共有しますが、API処理は多少異なります。

00:15:48.000 --> 00:15:54.000
最初にセンターステージAPIを紹介し、次にポートレートモードとマイクモードを紹介します。

00:15:54.000 --> 00:15:59.000
センターステージは、M1 iPad Proのすべてのフロントカメラで利用できます。

00:15:59.000 --> 00:16:13.000
新しい前面の超広角カメラ、トリミングされた従来の視野を示すバーチャルワイドカメラ、または仮想TrueDepthカメラを使用しているかどうかにかかわらず、センターステージが利用可能です。

00:16:13.000 --> 00:16:19.000
TrueDepthカメラにはいくつかの条件が付属しており、すぐに説明します。

00:16:19.000 --> 00:16:24.000
コントロールセンターのビデオエフェクトモジュールは、アプリごとにオン/オフの切り替えを表示します。

00:16:24.000 --> 00:16:34.000
これにより、会議アプリでセンターステージをデフォルトでオンにしながら、手動でショットをフレーミングしたいプロ写真アプリでデフォルトでオフにすることができます。

00:16:34.000 --> 00:16:40.000
アプリごとに1つの状態があり、カメラごとに1つの状態ではありません。

00:16:40.000 --> 00:16:50.000
センターステージのオン/オフトグルはカメラごとではなくアプリごとであるため、AVCaptureDeviceのクラスプロパティのセットとしてAPIに表示されます。

00:16:50.000 --> 00:16:55.000
これらは読み取り可能で、書き込み可能で、キー値が観察可能です。

00:16:55.000 --> 00:17:01.000
centerStageEnabledは、コントロールセンターのセンターステージUIのオン/オフ状態と一致します。

00:17:01.000 --> 00:17:07.000
センターステージコントロールモードは、誰が有効な状態を切り替えることができるかを決定します。

00:17:07.000 --> 00:17:10.000
それについては1分で詳しく。

00:17:10.000 --> 00:17:13.000
すべてのカメラやフォーマットがセンターステージをサポートしているわけではありません。

00:17:13.000 --> 00:17:22.000
任意のカメラのフォーマット配列を反復して、その機能をサポートするフォーマットを見つけ、アクティブフォーマットとして設定できます。

00:17:22.000 --> 00:17:34.000
さらに、センターステージのアクティブなプロパティを照会または観察することで、特定のカメラでセンターステージが現在アクティブであるかどうかを知ることができます。

00:17:34.000 --> 00:17:37.000
センターステージの限界に注意する必要があります。

00:17:37.000 --> 00:17:48.000
センターステージは、30fpsフォーマットであるウルトラワイドカメラのフル12メガピクセルフォーマットを使用しているため、最大フレームレートは30に制限されています。

00:17:48.000 --> 00:17:59.000
センターステージは、画質を維持するためにアップスケーリングを回避するため、1440年までに1920の最大出力解像度に制限されています。

00:17:59.000 --> 00:18:07.000
パンとズームはセンターステージコントロールの下にとどまらなければならないので、ビデオズームファクターは1つにロックされます。

00:18:07.000 --> 00:18:23.000
幾何学的歪み補正はセンターステージの人々のフレーミングに不可欠であり、深度生成にはRGBおよび赤外線カメラからの完全な視野画像を一致させる必要があるため、深度配信はオフにする必要があります。

00:18:23.000 --> 00:18:27.000
では、コントロールモードの概念に入りましょう。

00:18:27.000 --> 00:18:36.000
センターステージには、ユーザー、アプリ、協力の3つのサポートモードがあります。

00:18:36.000 --> 00:18:40.000
ユーザーモードは、すべてのアプリのデフォルトのセンターステージコントロールモードです。

00:18:40.000 --> 00:18:44.000
このモードでは、ユーザーのみが機能のオンとオフを切り替えることができます。

00:18:44.000 --> 00:18:52.000
アプリがセンターステージの有効状態をプログラムで変更しようとすると、例外がスローされます。

00:18:52.000 --> 00:18:57.000
次はアプリモードです。ここでは、アプリのみが機能を制御できます。

00:18:57.000 --> 00:19:02.000
トグルがグレー表示されているため、ユーザーはコントロールセンターを使用できません。

00:19:02.000 --> 00:19:04.000
このモードの使用はお勧めできません。

00:19:04.000 --> 00:19:08.000
センターステージがアプリと互換性がない場合にのみ使用してください。

00:19:08.000 --> 00:19:18.000
オプトアウトする必要がある場合は、コントロールモードをappに設定し、isCenterStageEnabledをfalseに設定できます。

00:19:18.000 --> 00:19:31.000
センターステージの可能な限り最高のユーザーエクスペリエンスは、ユーザーがコントロールセンターの機能を制御でき、アプリが独自のUIで制御できる協力モードです。

00:19:31.000 --> 00:19:33.000
しかし、あなたはいくつかの余分な仕事をする必要があります。

00:19:33.000 --> 00:19:44.000
AVCaptureDevice .isCenterStageEnabledプロパティを観察し、UIを更新して、ユーザーがオンにしたいときにセンターステージがオンになっていることを確認する必要があります。

00:19:44.000 --> 00:19:54.000
コントロールモードを協力的に設定した後、たとえば、アプリのボタンに基づいて、センターステージを有効にしてtrueまたはfalseに設定できます。

00:19:54.000 --> 00:19:58.000
協力モードのポスターチャイルドはFaceTimeです。

00:19:58.000 --> 00:20:16.000
FaceTime通話中に、アプリ内のボタンを使用してセンターステージをオンにして追跡したり、コントロールセンターで下にスワイプしてセンターステージのオン/オフを切り替えたりする従来の方法を使用できます。

00:20:16.000 --> 00:20:23.000
FaceTimeとコントロールセンターは、センターステージの状態に協力しているため、常にユーザーの意図と一致します。

00:20:23.000 --> 00:20:27.000
FaceTimeはまた、機能が相互に互換性がないときを知るのに十分スマートです。

00:20:27.000 --> 00:20:38.000
だから、例えば、深さを必要とするアニ文字をオンにしようとしたら...

00:20:38.000 --> 00:20:44.000
...これら2つの機能は相互に互換性がないため、センターステージをオフにすることを知っています。

00:20:44.000 --> 00:20:52.000
タップしてセンターステージをオンに戻すと、FaceTimeはアニ文字を無効にすることを知っています。

00:20:52.000 --> 00:20:54.000
それはセンターステージAPIを締めくくります。

00:20:54.000 --> 00:21:00.000
コントロールセンター、ポートレートのセンターステージのルームメイトに移行しましょう。

00:21:00.000 --> 00:21:08.000
簡単に言えば、それは美しくレンダリングされた浅い被写界深度効果で、広絞りレンズのように見えるように設計されています。

00:21:08.000 --> 00:21:17.000
iOSでは、ポートレートはApple Neural Engineを搭載したすべてのデバイスでサポートされています。これは2018年以降の携帯電話とパッドです。

00:21:17.000 --> 00:21:20.000
フロントカメラのみがサポートされています。

00:21:20.000 --> 00:21:27.000
また、同様にAppleのNeural Engineを含むすべてのM1 Macでもサポートされています。

00:21:27.000 --> 00:21:30.000
ポートレートは計算的に複雑なアルゴリズムです。

00:21:30.000 --> 00:21:46.000
したがって、ビデオレンダリングのパフォーマンスをレスポンシブに保つために、最大解像度は1920×1440、最大解像度は毎秒30フレームに制限されています。

00:21:46.000 --> 00:21:52.000
センターステージと同様に、ポートレートエフェクトはアプリごとにスティッキーオン/オフ状態になります。

00:21:52.000 --> 00:22:04.000
そのAPIはセンターステージよりも簡単で、ユーザーはコントロールセンターを通じて常に制御でき、特定のクラスのアプリでのみデフォルトで利用できます。

00:22:04.000 --> 00:22:14.000
iOSでは、VoIP UIBackgroundModeを使用するアプリは自動的にオプトインされます。ユーザーはコントロールセンターでエフェクトのオン/オフを切り替えることができます。

00:22:14.000 --> 00:22:26.000
他のすべてのiOSアプリは、アプリのInfo.plist: NSCameraPortraitEffectEnabledに新しいキーを追加して、ポートレート効果の対象であることを宣言するためにオプトインする必要があります。

00:22:26.000 --> 00:22:33.000
macOSでは、すべてのアプリが自動的にオプトインされ、すぐに使用できる効果を使用できます。

00:22:33.000 --> 00:22:38.000
ポートレート効果は、常にコントロールセンターを通じてのみユーザー制御下にあります。

00:22:38.000 --> 00:22:43.000
センターステージと同様に、すべてのカメラやフォーマットがポートレートをサポートしているわけではありません。

00:22:43.000 --> 00:22:52.000
任意のカメラのフォーマット配列を反復して、その機能をサポートするフォーマットを見つけ、アクティブなフォーマットとして設定できます。

00:22:52.000 --> 00:23:03.000
また、isPortraitEffectActiveプロパティを照会または観察することで、ポートレートが特定のカメラで現在アクティブであるかどうかを調べることもできます。

00:23:03.000 --> 00:23:08.000
マイクモードAPIはポートレートに似ています。

00:23:08.000 --> 00:23:11.000
ユーザー選択はアプリごとにスティッキーです。

00:23:11.000 --> 00:23:17.000
ユーザーはいつでもコントロールできます。アプリはマイクモードを直接設定することはできません。

00:23:17.000 --> 00:23:21.000
一部のアプリは、この機能を使用するためにオプトインする必要があります。

00:23:21.000 --> 00:23:52.000
マイクモードはAVFoundationのAVCaptureDeviceインターフェイスで提示され、3つのフレーバーがあります。標準のオーディオDSPを使用する標準。デバイス周辺のすべての音をキャプチャするための処理を最小限に抑える広いスペクトルですが、エコーキャンセルも含まれています。音声を強化し、キーボードでの入力、マウスクリック、または近所のどこかで実行されているリーフブロワーなどの不要なバックグラウンドノイズを除去する音声分離。

00:23:52.000 --> 00:24:17.000
これらのフレーバーは、コントロールセンターでユーザーのみ設定できますが、ユーザーが選択したモードであるAVCaptureDeviceの優先マイクモードと、現在のオーディオルートを考慮して、現在使用されているモードであるactiveMicrophoneModeを使用して、その状態を読み取って観察することができます。これは、ユーザーの好みのマイクモードをサポートしていない可能性があります。

00:24:17.000 --> 00:24:24.000
マイクモードを使用するには、アプリがCore Audio AUVoiceIOオーディオユニットを採用する必要があります。

00:24:24.000 --> 00:24:30.000
これは、エコーキャンセルを実行するため、ビデオ会議アプリで人気のあるインターフェースです。

00:24:30.000 --> 00:24:38.000
また、マイクモード処理は、2018年以降のiOSおよびmacOSデバイスでのみ利用可能です。

00:24:38.000 --> 00:24:51.000
ポートレートモードとマイクモードでは、ユーザーが常に制御できますが、新しいAVCaptureDevice .showSystemUserInterfaceメソッドを呼び出すことで、機能をオンまたはオンにするように促すことができます。

00:24:51.000 --> 00:24:57.000
そして、videoEffectsまたはmicrophoneModesのいずれかを渡すことができます。

00:24:57.000 --> 00:25:02.000
このAPIを呼び出すと、コントロールセンターが開き、適切なサブモジュールにディープリンクされます。

00:25:02.000 --> 00:25:12.000
ここでは、ユーザーがポートレートをオフにすることを選択できるビデオエフェクトモジュールにドリルダウンしています。

00:25:12.000 --> 00:25:17.000
それはポートレートをラップし、コントロールセンターのビデオエフェクトをラップします。

00:25:17.000 --> 00:25:26.000
コードの行を変更せずにアプリに注入されたシステムレベルのカメラ機能の例をお見せしました - かなり強力なコンセプトです!

00:25:26.000 --> 00:25:38.000
「ビデオフォーマットを使用して高品質の写真をキャプチャする」と呼ばれるコンパニオンセッションでは、コードを変更せずにアプリの画質を静止させるための改善について学びます。

00:25:38.000 --> 00:25:41.000
それをチェックしてください。

00:25:41.000 --> 00:25:43.000
私たちは多くの新機能を取り上げました。

00:25:43.000 --> 00:25:48.000
セッションのこの時点で、一息ついてパフォーマンスについて話したいと思います。

00:25:48.000 --> 00:25:56.000
センターステージとポートレートは素晴らしい新しいユーザー機能ですが、パフォーマンスコストがかかります。

00:25:56.000 --> 00:26:04.000
それでは、カメラアプリがポートレートやセンターステージなどの新機能の準備ができていることを確認するために、パフォーマンスのベストプラクティスを確認しましょう。

00:26:04.000 --> 00:26:09.000
カメラアプリは、AVCaptureクラスを使用して幅広い機能を提供します。

00:26:09.000 --> 00:26:21.000
最も一般的なインターフェイスはAVCaptureVideoDataOutputです。これにより、ビデオフレームを操作、表示、エンコード、録画のプロセスに直接取得できます。

00:26:21.000 --> 00:26:23.000
何でも。

00:26:23.000 --> 00:26:31.000
VideoDataOutputを使用する場合は、フレームドロップがないように、アプリがリアルタイムの締め切りに追いついていることを確認することが重要です。

00:26:31.000 --> 00:26:40.000
デフォルトでは、VideoDataOutputは、常にDiscardsLateVideoFramesプロパティをtrueに設定することで、遅れるのを防ぎます。

00:26:40.000 --> 00:26:55.000
これにより、ビデオデータ出力の処理パイプラインの最後に1のバッファキューサイズが強制され、常に最も新鮮なフレームを提供し、処理する準備ができていなかったフレームをドロップすることで、定期的または慢性的な遅い処理からあなたを救います。

00:26:55.000 --> 00:27:00.000
AVAssetWriterなど、受信しているフレームを記録する必要がある場合は役に立ちません。

00:27:00.000 --> 00:27:12.000
処理された結果を記録する場合は、常にDiscardsLateVideoFramesをオフにし、処理時間に細心の注意を払う必要があります。

00:27:12.000 --> 00:27:21.000
VideoDataOutputは、提供されたcaptureOutput didDrop sampleBufferデリゲートコールバックを呼び出すことで、フレームドロップが発生したときに通知します。

00:27:21.000 --> 00:27:29.000
didDropコールバックを受け取ったら、含まれているsampleBufferの添付ファイルでdropFrameReasonを検査できます。

00:27:29.000 --> 00:27:33.000
これは、さらなるフレームドロップを軽減するために何をすべきかを知らせることができます。

00:27:33.000 --> 00:27:53.000
3つの理由があります。FrameWasLateは、処理に時間がかかりすぎていることを意味します。OutOfBuffersは、あまりにも多くのバッファを保持している可能性があることを意味します。そして、不連続性は、システムが遅くなるか、ハードウェアの障害があることを意味します。

00:27:53.000 --> 00:27:56.000
では、フレームドロップにどのように反応するかについて話しましょう。

00:27:56.000 --> 00:28:00.000
最良の方法の1つは、デバイスのフレームレートを動的に下げることです。

00:28:00.000 --> 00:28:04.000
そうすることで、プレビューや出力に不具合が発生することはありません。

00:28:04.000 --> 00:28:10.000
実行時にAVCaptureDeviceに新しいactiveMinVideoFrameDurationを設定するだけです。

00:28:10.000 --> 00:28:18.000
2番目の方法は、作業負荷を簡素化して、それほど時間がかからないようにすることです。

00:28:18.000 --> 00:28:26.000
それでは、カメラアプリの優れたユーザーエクスペリエンスにとって非常に重要な別のパフォーマンス指標であるシステムプレッシャーについて話しましょう。

00:28:26.000 --> 00:28:32.000
システム圧力とは、システムがひずみや圧力にさらされることを意味します。

00:28:32.000 --> 00:28:40.000
AVCaptureDeviceには、要因と全体的なレベルで構成されるsystemPressureStateと呼ばれるプロパティがあります。

00:28:40.000 --> 00:28:47.000
SystemPressureStateの寄与要因は、3つの可能性のある貢献者のビットマスクです。

00:28:47.000 --> 00:28:51.000
システム温度とは、デバイスがどれだけ熱くなっているかを指します。

00:28:51.000 --> 00:29:00.000
peakPowerは、バッテリーの経年劣化と、バッテリーがピーク電力需要を満たすのに十分な速さで電圧を上げることができるかどうかに関するものです。

00:29:00.000 --> 00:29:08.000
そして、depthModuleTemperatureは、TrueDepthカメラの赤外線センサーの熱さを指します。

00:29:08.000 --> 00:29:16.000
SystemPressureStateのレベルは、ユーザーエクスペリエンスが損なわれる前に行動を起こすのに役立つ指標です。

00:29:16.000 --> 00:29:19.000
名目上の場合、すべてが順調です。

00:29:19.000 --> 00:29:23.000
フェアは、システム圧力がわずかに上昇していることを示しています。

00:29:23.000 --> 00:29:29.000
これは、処理をほとんど行わなくても発生する可能性がありますが、周囲温度は高いです。

00:29:29.000 --> 00:29:35.000
深刻な場合、システム圧力は非常に高くなります。キャプチャ性能が影響を受ける可能性があります。

00:29:35.000 --> 00:29:38.000
フレームレートのスロットリングをお勧めします。

00:29:38.000 --> 00:29:47.000
クリティカルに達すると、システムの圧力は大幅に高まります。キャプチャの品質とパフォーマンスは大きな影響を受けます。

00:29:47.000 --> 00:29:50.000
フレームレートのスロットリングを強くお勧めします。

00:29:50.000 --> 00:29:57.000
そして、システムの圧力が重大を超えているシャットダウンに物事をエスカレートさせたくありません。

00:29:57.000 --> 00:30:05.000
このレベルでは、AVCaptureSessionは自動的に停止し、デバイスをサーマルトラップから解放します。

00:30:05.000 --> 00:30:09.000
さまざまな方法で高気圧に反応できます。

00:30:09.000 --> 00:30:14.000
キャプチャフレームレートを下げます。これは常にシステム圧力に役立ちます。

00:30:14.000 --> 00:30:22.000
フレームレートを下げることがオプションでない場合は、特定の機能をオフにするなど、CPUまたはGPUのワークロードを軽減することを検討してください。

00:30:22.000 --> 00:30:31.000
また、機能をオンにしておくかもしれませんが、おそらくより小さな解像度またはより少ない頻度で処理することによって、品質を低下させるかもしれません。

00:30:31.000 --> 00:30:41.000
AVCaptureSessionは、それがあなたのアプリの許容可能な品質劣化戦略であるかどうかわからないので、あなたに代わってフレームレートスロットルを決してしません。

00:30:41.000 --> 00:30:43.000
それはパフォーマンスのベストプラクティスを締めくくります。

00:30:43.000 --> 00:30:49.000
さて、私たちのデザートコース、IOSurface圧縮。

00:30:49.000 --> 00:31:04.000
ISPを経由し、最終的には写真、映画、プレビュー、またはバッファに流れるビデオの全体的なメモリ帯域幅要件についてできることはあまりないので、パフォーマンスセクションでメモリ帯域幅について話すことを慎重に避けました。

00:31:04.000 --> 00:31:12.000
しかし、それでも、メモリ帯域幅は、どのカメラ機能が同時に実行できるかを決定する上で重要なリミッターになる可能性があります。

00:31:12.000 --> 00:31:18.000
iOSとmacOSで非圧縮ビデオを操作する場合、多くのレイヤーが関係しています。

00:31:18.000 --> 00:31:21.000
それはロシアの巣作り人形に少し似ています。

00:31:21.000 --> 00:31:31.000
トップレベルには、あらゆる種類のメディアデータ、タイミング、メタデータをラップできるCMSampleBufferがあります。

00:31:31.000 --> 00:31:40.000
1つのレベル下に、メタデータの添付ファイルとともにピクセルバッファデータを具体的にラップするCVPixelBufferがあります。

00:31:40.000 --> 00:31:52.000
最後に、その最低レベルであるIOSurfaceに到達し、メモリをカーネルに配線し、プロセス間で大きなビデオバッファを共有するためのインターフェイスを提供します。

00:31:52.000 --> 00:31:54.000
IOSurfacesは巨大です。

00:31:54.000 --> 00:31:59.000
それらは、非圧縮ビデオの大きなメモリ帯域幅の要件を考慮しています。

00:31:59.000 --> 00:32:05.000
ありがたいことに、IOSurface圧縮はメモリ帯域幅の問題に対する解決策を提供します。

00:32:05.000 --> 00:32:12.000
iOS 15の新機能では、ロスレスインメモリビデオ圧縮フォーマットのサポートを導入しています。

00:32:12.000 --> 00:32:17.000
これは、ライブビデオの総メモリ帯域幅を下げるための最適化です。

00:32:17.000 --> 00:32:23.000
これは、iOSデバイスとMacの主要なハードウェアブロックによって理解される交換形式です。

00:32:23.000 --> 00:32:36.000
すべてのiPhone 12のバリエーション、2020年秋のiPad Air、2021年春のM1 iPad Proで利用できます。

00:32:36.000 --> 00:32:40.000
圧縮されたIOSurfacesを扱う主要なハードウェアブロックはどれですか?

00:32:40.000 --> 00:32:43.000
まあ、たくさんあります。

00:32:43.000 --> 00:32:51.000
ここにリストされているすべてのサービスは、圧縮されたIOSurfacesの読み書き方法を理解しています。

00:32:51.000 --> 00:32:56.000
この時点で、あなたは「素晴らしい、どうやってサインアップすればよいですか?」と言っているかもしれません。

00:32:56.000 --> 00:32:57.000
さて、良いニュースです。

00:32:57.000 --> 00:33:12.000
サポートされているハードウェアでビデオをキャプチャしていて、AVCaptureSessionがプロセスにバッファを配信する必要がない場合、おめでとうございます。セッションは、メモリ帯域幅を削減できるときはいつでもIOSurface圧縮を利用しています。

00:33:12.000 --> 00:33:20.000
圧縮されたサーフェスをビデオデータ出力に配信したい場合は、いくつかのルールについて知っておく必要があります。

00:33:20.000 --> 00:33:35.000
物理メモリのレイアウトは不透明で変更される可能性があるため、ディスクに書き込むことはせず、すべてのプラットフォームで同じレイアウトを想定せず、CPUを使用して読み書きしないでください。

00:33:35.000 --> 00:33:40.000
AVCaptureVideoDataOutputは、いくつかのフレーバーのIOSurface圧縮をサポートしています。

00:33:40.000 --> 00:33:51.000
講演の先ほど、iOSカメラが420vと420fをネイティブにサポートしていることを学びました - 8ビットYUVフォーマット。1つのビデオと1つのフルレンジ。

00:33:51.000 --> 00:33:57.000
そしてその後、10ビットHDRビデオフォーマットであるx420について学びました。

00:33:57.000 --> 00:34:05.000
ビデオデータ出力は、要求された場合、内部的に16ビット/ピクセルBGRAに拡張することもできます。

00:34:05.000 --> 00:34:14.000
これらのそれぞれには、iOS 15以降、AVCaptureVideoDataOutputを通じてリクエストできるIOSurface圧縮同等物があります。

00:34:14.000 --> 00:34:20.000
あなたが4文字のコードのアンパサンドのファンなら、これはあなたの幸運な日です。

00:34:20.000 --> 00:34:23.000
これは再びアイチャート形式です。

00:34:23.000 --> 00:34:28.000
これらは、コードで使用するべき実際の定数です。

00:34:28.000 --> 00:34:33.000
2年前、私たちは「AVMultiCamPiP」というサンプルコードをリリースしました。

00:34:33.000 --> 00:34:53.000
このサンプルでは、フロントカメラとバックカメラはマルチカムセッションを使用してVideoDataOutputsに同時にストリーミングされ、メタルシェーダーを使用してピクチャインピクチャとして合成され、複合をレンダリングしてプレビューし、AVAssetWriterを使用してムービーに書き込みます。

00:34:53.000 --> 00:35:01.000
これは、これらの操作はすべてハードウェアで実行されるため、IOSurface圧縮の完璧な候補です。

00:35:01.000 --> 00:35:06.000
AVMultiCamPiPの既存のVideoDataOutputセットアップコードは次のとおりです。

00:35:06.000 --> 00:35:16.000
BGRAで作業するのが好きなので、そのピクセルフォーマットタイプを生成するようにVideoDataOutputのvideoSettingsを構成します。

00:35:16.000 --> 00:35:19.000
新しいコードには、いくつかのチェックが組み込まれているだけです。

00:35:19.000 --> 00:35:25.000
まず、IOSurface圧縮バージョンのBGRAが利用可能かどうかがわかります。

00:35:25.000 --> 00:35:31.000
もしそうなら、それを選択します。else句はフォールバックとしてそこにあります。

00:35:31.000 --> 00:35:35.000
そして、ちょうどそのように、私たちは終わりにたどり着きました。

00:35:35.000 --> 00:35:52.000
最小フォーカス距離のレポート、10ビットHDRビデオのキャプチャ方法、コントロールセンターのビデオエフェクトとマイクモード、パフォーマンスのベストプラクティス、IOSurface圧縮について学びました。

00:35:52.000 --> 00:35:54.000
楽しんでいただけたでしょうか!

00:35:54.000 --> 00:35:55.000
見てくれてありがとう。

00:35:55.000 --> 23:59:59.000
♪

