WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:10.000
マイケル・パトリック・ジョンソン:こんにちは!

00:00:10.000 --> 00:00:14.000
私の名前はマイケル・パトリック・ジョンソンで、オブジェクトキャプチャチームのエンジニアです。

00:00:14.000 --> 00:00:24.000
今日、同僚のデイブ・マッキノンと私は、macOSの新しいフォトグラメトリAPIを使用して、現実世界のオブジェクトを3Dモデルに変える方法を紹介します。

00:00:24.000 --> 00:00:31.000
ARKitとRealityKitフレームワークを使用して拡張現実アプリを作成することにすでに精通しているかもしれません。

00:00:31.000 --> 00:00:38.000
また、Reality ComposerとReality Converterを使用して、AR用の3Dモデルを作成した可能性があります。

00:00:38.000 --> 00:00:46.000
そして今、Object Capture APIを使用すると、現実世界のオブジェクトの画像を詳細な3Dモデルに簡単に切り替えることができます。

00:00:46.000 --> 00:00:50.000
キッチンテーブルの前に焼きたてのピザがあるとしましょう。

00:00:50.000 --> 00:00:52.000
美味しそうですよね？

00:00:52.000 --> 00:00:57.000
前景のピザを3Dモデルとしてキャプチャしたいとします。

00:00:57.000 --> 00:01:03.000
通常、形状と質感をモデル化するには、プロのアーティストを何時間も雇う必要があります。

00:01:03.000 --> 00:01:07.000
でも、待って、自分のオーブンで焼くのに数分しかかからなかった！

00:01:07.000 --> 00:01:12.000
オブジェクトキャプチャでは、あらゆる角度からオブジェクトの写真を撮ることから始めます。

00:01:12.000 --> 00:01:18.000
次に、新しいオブジェクトキャプチャAPIをサポートするMacに画像をコピーします。

00:01:18.000 --> 00:01:26.000
「フォトグラメトリ」と呼ばれるコンピュータビジョン技術を使用して、2D画像のスタックはわずか数分で3Dモデルに変換されます。

00:01:26.000 --> 00:01:35.000
出力モデルには、幾何学的なメッシュとさまざまなマテリアルマップの両方が含まれており、アプリに直接ドロップするか、ARクイックルックで表示する準備ができています。

00:01:35.000 --> 00:01:39.000
では、これらの各ステップをもう少し詳しく見てみましょう。

00:01:39.000 --> 00:01:43.000
まず、あらゆる側面から物体の写真を撮ります。

00:01:43.000 --> 00:01:49.000
画像は、iPhoneやiPad、デジタル一眼レフ、さらにはドローンでも撮影できます。

00:01:49.000 --> 00:01:54.000
オブジェクトの周りのあらゆる角度から鮮明な写真を取得することを確認する必要があります。

00:01:54.000 --> 00:01:58.000
セッションの後半でキャプチャのベストプラクティスを提供します。

00:01:58.000 --> 00:02:13.000
iPhoneまたはiPadでキャプチャする場合、サポートされているデバイスからのステレオ深度データを使用して、実際のオブジェクトサイズと重力ベクトルを回復できるため、モデルが自動的に右向きに作成されます。

00:02:13.000 --> 00:02:22.000
画像のフォルダをキャプチャしたら、それらをMacにコピーし、Object Capture APIを使用してわずか数分で3Dモデルに変換する必要があります。

00:02:22.000 --> 00:02:34.000
このAPIは最近のIntelベースのMacでサポートされていますが、Apple Neural Engineを利用してコンピュータビジョンアルゴリズムを高速化できるため、すべての最新のAppleシリコンMacで最速で動作します。

00:02:34.000 --> 00:02:40.000
また、始めるのに役立つサンプルコマンドラインアプリであるHelloPhotogrammetryも提供しています。

00:02:40.000 --> 00:02:47.000
また、画像のフォルダで直接使用して、コードを書く前に自分でモデルを構築してみることもできます。

00:02:47.000 --> 00:02:52.000
最後に、USDZ出力モデルをMacでプレビューできます。

00:02:52.000 --> 00:03:00.000
さまざまなユースケースに最適化された4つの詳細レベルでモデルを提供できます。これについては、後で詳しく説明します。

00:03:00.000 --> 00:03:07.000
縮小、中、および完全な詳細は、ここに示されているピザのように、箱から出してすぐに使用できます。

00:03:07.000 --> 00:03:11.000
Rawはカスタムワークフローを対象としています。

00:03:11.000 --> 00:03:20.000
ミディアムディテールレベルでUSDZ出力を選択すると、iPhoneまたはiPadのARクイックルックで新しいモデルを表示できます。

00:03:20.000 --> 00:03:25.000
そして、AR用に最適化されたリアルなオブジェクトを手に入れるのはそれだけです!

00:03:25.000 --> 00:03:28.000
待って、前のピザを覚えてる？

00:03:28.000 --> 00:03:29.000
私たちは白状しなければならない。

00:03:29.000 --> 00:03:35.000
この画像は実際には写真ではありませんでしたが、実際にはいくつかのピザでオブジェクトキャプチャを使用して作成されました。

00:03:35.000 --> 00:03:43.000
その後、これらのモデルはポストプロダクションツールでこのシーンに結合され、高度なマテリアルマップでレイトレーサーを使用してレンダリングされました。

00:03:43.000 --> 00:03:53.000
したがって、Object Captureは、iPhoneやiPadのARアプリから映画対応の制作資産まで、さまざまなターゲットユースケースをサポートできます。

00:03:53.000 --> 00:04:03.000
このセッションの残りの部分では、Object Capture APIの使用を開始する方法を紹介し、最高品質の結果を達成するためのベストプラクティスを提供します。

00:04:03.000 --> 00:04:14.000
はじめにセクションでは、Object Capture APIについて詳しく説明し、アプリを作成するために不可欠なコードの概念を紹介します。

00:04:14.000 --> 00:04:22.000
次に、画像キャプチャ、オブジェクト選択、詳細レベル選択のベストプラクティスについて説明します。

00:04:22.000 --> 00:04:28.000
macOSでAPIを使用する上で重要なステップに取り組むことから始めましょう。

00:04:28.000 --> 00:04:35.000
このセクションでは、Object Capture APIの基本的なコンポーネントと、それらをまとめる方法を学びます。

00:04:35.000 --> 00:04:40.000
ARで見るために3Dモデルに変えたいこのクールな新しいスニーカーを持っているとしましょう。

00:04:40.000 --> 00:04:46.000
ここでは、このセクションで検討する基本的なワークフローのグラフィカルな図を紹介します。

00:04:46.000 --> 00:04:58.000
このプロセスには2つの主要なステップがあります。オブジェクトの画像のセットを指すセットアップ。次に、構築したいモデルの生成を要求するプロセスです。

00:04:58.000 --> 00:05:08.000
まず、セッションを作成し、関連する出力ストリームを接続する2つのサブステップで構成されるセットアップブロックに焦点を当てます。

00:05:08.000 --> 00:05:13.000
有効なセッションを取得したら、それを使用してモデルを生成できます。

00:05:13.000 --> 00:05:17.000
最初にする必要があるのは、PhotogrammetrySessionを作成することです。

00:05:17.000 --> 00:05:22.000
セッションを作成するには、オブジェクトの画像のフォルダがすでにあることを前提としています。

00:05:22.000 --> 00:05:29.000
すぐに始めるために、APIドキュメントにいくつかのサンプル画像キャプチャフォルダを提供しました。

00:05:29.000 --> 00:05:35.000
PhotogrammetrySessionは、APIの主要なトップレベルクラスであり、主な制御ポイントです。

00:05:35.000 --> 00:05:45.000
セッションは、結果の3Dモデルを生成するために写真測量アルゴリズムが適用される固定画像セットのコンテナと考えることができます。

00:05:45.000 --> 00:05:54.000
ここには、iPhone 12 Pro Maxを使用して撮影されたスニーカーの123枚のHEIC画像があります。

00:05:54.000 --> 00:05:58.000
現在、使用する画像のセットを指定する方法はいくつかあります。

00:05:58.000 --> 00:06:03.000
最も簡単なのは、画像のディレクトリへのファイルURLです。

00:06:03.000 --> 00:06:08.000
セッションでは、これらを1つずつ取り込み、発生した問題を報告します。

00:06:08.000 --> 00:06:16.000
HEIC画像に深度データが埋め込まれている場合は、オブジェクトの実際のスケールを回復するために自動的に使用されます。

00:06:16.000 --> 00:06:26.000
ほとんどの人がフォルダ入力を好むことを期待していますが、一連のカスタムサンプルを提供するための高度なワークフローのインターフェースも提供しています。

00:06:26.000 --> 00:06:36.000
PhotogrammetrySampleには、画像に加えて、深度マップ、重力ベクトル、カスタムセグメンテーションマスクなどの他のオプションデータが含まれています。

00:06:36.000 --> 00:06:42.000
入力ソースからセッションを作成したら、モデル再構築のリクエストを行います。

00:06:42.000 --> 00:06:49.000
セッションは、結果のモデルとステータスメッセージを出力メッセージストリームに出力します。

00:06:49.000 --> 00:06:54.000
セッションとは何かわかったので、APIを使用してセッションを作成する方法を見てみましょう。

00:06:54.000 --> 00:07:00.000
ここでは、画像のフォルダからセッションの初期設定を実行するためのコードを参照してください。

00:07:00.000 --> 00:07:05.000
PhotogrammetrySessionはRealityKitフレームワーク内にあります。

00:07:05.000 --> 00:07:10.000
まず、入力フォルダをファイルURLとして指定します。

00:07:10.000 --> 00:07:16.000
ここでは、すでにローカルディスクにスニーカーの画像を含むフォルダがあると仮定します。

00:07:16.000 --> 00:07:21.000
最後に、入力ソースとしてURLを渡してセッションを作成します。

00:07:21.000 --> 00:07:26.000
パスが存在しない場合、または読み取ることができない場合、初期化子はエラーをスローします。

00:07:26.000 --> 00:07:33.000
オプションで高度な設定パラメータを提供できますが、ここではデフォルトのみを使用します。

00:07:33.000 --> 00:07:36.000
セッションを作成するのに必要なのはそれだけです!

00:07:36.000 --> 00:07:44.000
セッションオブジェクトを正常に作成したので、メッセージが到着したときにメッセージを処理できるように、セッションの出力ストリームを接続する必要があります。

00:07:44.000 --> 00:07:52.000
メッセージストリームが接続されたら、そのストリームに到着するモデルをリクエストする方法を確認します。

00:07:52.000 --> 00:07:59.000
今年のSwiftの新しい機能であるAsyncSequenceを使用して、出力のストリームを提供します。

00:07:59.000 --> 00:08:06.000
出力メッセージには、リクエストの結果や、進捗状況の更新などのステータスメッセージが含まれます。

00:08:06.000 --> 00:08:12.000
最初のプロセスコールを行うと、メッセージは出力メッセージストリームで流れ始めます。

00:08:12.000 --> 00:08:16.000
セッションが生きている間、出力メッセージシーケンスは終了しません。

00:08:16.000 --> 00:08:23.000
セッションが初期化解除されるか、致命的なエラーが発生するまで、メッセージが生成され続けます。

00:08:23.000 --> 00:08:28.000
では、受信するメッセージの種類を詳しく見てみましょう。

00:08:28.000 --> 00:08:37.000
リクエストが行われた後、各リクエストの見積もりが完了した定期的なリクエストプログレスメッセージを受け取る予定です。

00:08:37.000 --> 00:08:46.000
Object Capture APIを呼び出すアプリを構築している場合は、これらを使用して、各リクエストのステータスを示すプログレスバーを駆動できます。

00:08:46.000 --> 00:08:55.000
リクエストの処理が完了すると、モデルやバウンディングボックスなど、結果のペイロードを含むrequestCompleteメッセージを受け取ります。

00:08:55.000 --> 00:09:03.000
処理中に何か問題が発生した場合、代わりにそのリクエストに対してrequestErrorが出力されます。

00:09:03.000 --> 00:09:10.000
便宜上、キューに入れられたすべてのリクエストが処理を完了すると、processingCompleteメッセージが出力されます。

00:09:10.000 --> 00:09:20.000
セッション出力ストリームの概念が紹介され、主要な出力メッセージを見たので、メッセージストリームを処理するコードの例を見てみましょう。

00:09:20.000 --> 00:09:24.000
これを手に入れたら、モデルをリクエストする方法を見ていきます。

00:09:24.000 --> 00:09:30.000
以下は、メッセージが到着したときに処理する非同期タスクを作成するコードです。

00:09:30.000 --> 00:09:37.000
それは多くのコードのように思えるかもしれませんが、私たちが見るように、そのほとんどは単にメッセージの送信です。

00:09:37.000 --> 00:09:47.000
「For try await」ループを使用して、session.outputsのメッセージが到着したときに非同期に反復します。

00:09:47.000 --> 00:09:52.000
コードの大部分は、出力メッセージを切り替えるメッセージディスパッチャです。

00:09:52.000 --> 00:09:57.000
出力は、異なるメッセージタイプとペイロードを持つ列挙型です。

00:09:57.000 --> 00:10:00.000
各ケースステートメントは異なるメッセージを処理します。

00:10:00.000 --> 00:10:02.000
それらを通り抜けましょう。

00:10:02.000 --> 00:10:07.000
まず、進捗メッセージが表示されたら、値を印刷するだけです。

00:10:07.000 --> 00:10:11.000
リクエストごとに進捗メッセージが届くことに注意してください。

00:10:11.000 --> 00:10:21.000
たとえば、リクエストが完了すると、結果のペイロードは、モデルが保存された場所へのURLを持つmodelFileであることを期待します。

00:10:21.000 --> 00:10:24.000
そのような要求をすぐに行う方法を見ていきます。

00:10:24.000 --> 00:10:31.000
フォトグラメトリエラーのためにリクエストが失敗した場合、代わりにエラーメッセージが表示されます。

00:10:31.000 --> 00:10:38.000
プロセスコールからのリクエストのセット全体が終了すると、processingCompleteメッセージが生成されます。

00:10:38.000 --> 00:10:41.000
コマンドラインアプリの場合、ここでアプリを終了することができます。

00:10:41.000 --> 00:10:50.000
最後に、読み込めなかったフォルダ内の画像に関する警告など、ドキュメントで読むことができる他のステータスメッセージがあります。

00:10:50.000 --> 00:10:52.000
そして、それはメッセージ処理のためです!

00:10:52.000 --> 00:11:00.000
このメッセージ処理タスクは、セッションが生きている限り、メッセージを非同期に反復および処理し続けます。

00:11:00.000 --> 00:11:04.000
さて、私たちがワークフローのどこにいるか見てみましょう。

00:11:04.000 --> 00:11:08.000
セットアップフェーズを完全に完了し、セッションの準備が整いました。

00:11:08.000 --> 00:11:12.000
これで、モデルを処理するためのリクエストを行う準備が整いました。

00:11:12.000 --> 00:11:18.000
コードに飛び込む前に、私たちができるさまざまな種類のリクエストを詳しく見てみましょう。

00:11:18.000 --> 00:11:26.000
セッションから受信できるデータには、ModelFile、ModelEntity、BoundingBoxの3つの異なるデータタイプがあります。

00:11:26.000 --> 00:11:36.000
これらのタイプには、リクエスト列挙型に関連付けられたケースがあります: modelFile、modelEntity、および境界。それぞれ異なるパラメータを持ちます。

00:11:36.000 --> 00:11:41.000
modelFileリクエストは最も一般的であり、基本的なワークフローで使用するものです。

00:11:41.000 --> 00:11:51.000
USDZ拡張子と詳細レベルを持つファイルURLを指定するmodelFileリクエストを作成するだけです。

00:11:51.000 --> 00:11:58.000
インタラクティブなワークフローで使用するオプションのジオメトリパラメータがありますが、ここでは使用しません。

00:11:58.000 --> 00:12:11.000
USDAまたはOBJの出力形式が必要になる可能性のある、より複雑な後処理パイプラインについては、代わりに詳細レベルとともに出力ディレクトリURLを提供できます。

00:12:11.000 --> 00:12:21.000
その後、セッションは、テクスチャや素材などのすべての参照アセットとともに、USDAとOBJファイルをそのフォルダに書き込みます。

00:12:21.000 --> 00:12:29.000
GUIアプリは、インタラクティブなプレビューと洗練のためにRealityKit ModelEntityとBoundingBoxをリクエストすることもできます。

00:12:29.000 --> 00:12:35.000
modelEntityリクエストは、詳細レベルとオプションのジオメトリも取ります。

00:12:35.000 --> 00:12:41.000
境界要求は、オブジェクトの推定キャプチャボリュームBoundingBoxを返します。

00:12:41.000 --> 00:12:50.000
このボックスはUIで調整し、再構成ボリュームを調整するための後続の要求のジオメトリ引数で渡すことができます。

00:12:50.000 --> 00:12:54.000
これがどのように機能するかは、セッションの後半で見てみましょう。

00:12:54.000 --> 00:12:57.000
ほとんどのリクエストには詳細レベルも必要です。

00:12:57.000 --> 00:13:01.000
プレビューレベルは、インタラクティブなワークフローのみを対象としています。

00:13:01.000 --> 00:13:06.000
視覚品質は非常に低いですが、最速で作成されます。

00:13:06.000 --> 00:13:14.000
品質とサイズを向上させる順の主な詳細レベルは、削減、中、およびフルです。

00:13:14.000 --> 00:13:18.000
これらのレベルはすべて箱から出してすぐに使用できます。

00:13:18.000 --> 00:13:26.000
さらに、Rawレベルはプロの使用のために提供されており、適切に使用するためにポストプロダクションワークフローが必要になります。

00:13:26.000 --> 00:13:30.000
これらについては、ベストプラクティスのセクションで詳しく説明します。

00:13:30.000 --> 00:13:36.000
さて、どのようなリクエストができるかを見たので、コードでこれを行う方法を見てみましょう。

00:13:36.000 --> 00:13:44.000
1回の呼び出しで2つのモデルを同時に生成する方法を見ていきます。それぞれに異なる出力ファイル名と詳細レベルがあります。

00:13:44.000 --> 00:13:48.000
ここでは、セッションで処理する最初の呼び出しが表示されます。

00:13:48.000 --> 00:13:51.000
一連のリクエストが必要であることに注意してください。

00:13:51.000 --> 00:13:55.000
これは、一度に2つのモデルをリクエストする方法です。

00:13:55.000 --> 00:14:04.000
削減された詳細レベルで1つのモデルとMediumで1つのモデルを要求し、それぞれが異なるUSDZファイルに保存します。

00:14:04.000 --> 00:14:17.000
1回の呼び出しでオブジェクトキャプチャのすべての必要な詳細レベルを同時に要求すると、エンジンは計算を共有でき、すべてのモデルを順番に要求するよりも速く生成されます。

00:14:17.000 --> 00:14:20.000
すべての詳細レベルを一度に尋ねることもできます。

00:14:20.000 --> 00:14:27.000
出力場所を書き込むことができない場合など、要求が無効な場合、プロセスはすぐにエラーをスローする可能性があります。

00:14:27.000 --> 00:14:34.000
この呼び出しはすぐに返され、すぐにメッセージが出力ストリームに表示され始めます。

00:14:34.000 --> 00:14:37.000
そして、それは基本的なワークフローの終わりです!

00:14:37.000 --> 00:14:43.000
画像でセッションを作成し、出力ストリームを接続してから、モデルを要求します。

00:14:43.000 --> 00:14:49.000
各モデルの処理時間は、画像の数と品質レベルによって異なります。

00:14:49.000 --> 00:14:55.000
処理が完了すると、モデルが利用可能であるという出力メッセージが届きます。

00:14:55.000 --> 00:15:06.000
作成したスニーカーの結果のUSDZファイルをMacで開き、底面を含むあらゆる角度から3Dで結果を調べることができます。

00:15:06.000 --> 00:15:16.000
このセッションの後半では、複数のキャプチャを組み合わせる必要性を避けて、1回のキャプチャセッションでオブジェクトのすべての側面のカバレッジを実現する方法を紹介します。

00:15:16.000 --> 00:15:18.000
すごく良さそうだね！

00:15:18.000 --> 00:15:28.000
基本的なワークフローを見たので、Object Capture APIもサポートする、より高度なインタラクティブワークフローの概要を説明します。

00:15:28.000 --> 00:15:42.000
インタラクティブなワークフローは、最終的な再構築の前にプレビューモデルでいくつかの調整を行うことができるように設計されています。これにより、ポストプロダクションモデルの編集の必要性を排除し、メモリの使用を最適化することができます。

00:15:42.000 --> 00:15:49.000
まず、このワークフローの両端にあるセットアップステップとプロセスステップは以前と同じであることに注意してください。

00:15:49.000 --> 00:15:52.000
引き続きセッションを作成し、出力ストリームを接続します。

00:15:52.000 --> 00:15:55.000
また、以前と同様に最終モデルをリクエストします。

00:15:55.000 --> 00:16:04.000
ただし、プレビューモデルのインタラクティブな編集のために3D UIが提示される中央にブロックを追加したことに注意してください。

00:16:04.000 --> 00:16:09.000
このプロセスは、プレビューに満足するまで反復されます。

00:16:09.000 --> 00:16:13.000
その後、以前と同じように最終的なモデル要求を続行できます。

00:16:13.000 --> 00:16:20.000
まず、プレビューの詳細レベルのモデルリクエストを指定して、プレビューモデルをリクエストします。

00:16:20.000 --> 00:16:25.000
プレビューモデルは視覚品質が低く、できるだけ早く生成されます。

00:16:25.000 --> 00:16:32.000
モデルファイルをリクエストして自分でロードするか、RealityKit ModelEntityの表示を直接リクエストできます。

00:16:32.000 --> 00:16:39.000
通常、キャプチャボリュームをプレビューおよび編集するために、境界要求も同時に行われます。

00:16:39.000 --> 00:16:49.000
キャプチャボリュームを調整して、キャプチャ中にオブジェクトを直立させるために必要な台座など、キャプチャ内の不要なジオメトリを削除できます。

00:16:49.000 --> 00:16:55.000
ルート変換を調整して、モデルをスケーリング、変換、回転させることもできます。

00:16:55.000 --> 00:17:05.000
先ほど見たリクエストのジオメトリプロパティでは、モデルが生成される前にキャプチャボリュームと相対ルート変換を提供できます。

00:17:05.000 --> 00:17:08.000
これにより、すぐに使用できる3Dモデルが出力されます。

00:17:08.000 --> 00:17:10.000
このプロセスの実行を見てみましょう。 

00:17:10.000 --> 00:17:18.000
ここでは、このインタラクティブなワークフローを実証するためにAPIを使用して作成したインタラクティブなオブジェクトキャプチャアプリの例を示します。

00:17:18.000 --> 00:17:29.000
まず、装飾的な岩の画像を含む画像フォルダと、最終的なUSDZが書き込まれる出力フォルダを選択します。

00:17:29.000 --> 00:17:35.000
次に、プレビューを押して、プレビューモデルと推定キャプチャボリュームを要求します。

00:17:35.000 --> 00:17:41.000
しばらくすると、私たちの岩のプレビューモデルとそのキャプチャボリュームが現れます。

00:17:41.000 --> 00:17:47.000
しかし、底が地下にあるかのように、出力に岩の上部だけが欲しいとしましょう。

00:17:47.000 --> 00:17:51.000
モデルの底を再構築しないように、バウンディングボックスを調整できます。

00:17:51.000 --> 00:17:59.000
満足したら、リファインモデルを押して、この変更されたキャプチャボリュームに制限された新しいプレビューを生成します。

00:17:59.000 --> 00:18:03.000
これはまた、この部分だけに対して出力モデルを最適化します。

00:18:03.000 --> 00:18:08.000
洗練されたモデルの準備が整うと、新しいプレビューが表示されます。

00:18:08.000 --> 00:18:13.000
新しいモデルのジオメトリが箱の中にとどまるようにクリップされているのを見ることができます。

00:18:13.000 --> 00:18:19.000
これは、オブジェクトを保持する台座などのキャプチャ内の不要なアイテムを削除するのに便利です。

00:18:19.000 --> 00:18:26.000
トリミングされたプレビューに満足したら、作成プロセスを開始する完全な詳細の最終レンダリングを選択できます。

00:18:26.000 --> 00:18:32.000
しばらくすると、フルディテールモデルが完成し、プレビューモデルを置き換えます。

00:18:32.000 --> 00:18:37.000
今、私たちは実際のモデルの完全な詳細を見ることができ、それは素晴らしく見えます。

00:18:37.000 --> 00:18:43.000
モデルは出力ディレクトリに保存され、追加の後処理を必要とせずにすぐに使用できます。

00:18:43.000 --> 00:18:48.000
そして、新しいオブジェクトキャプチャAPIを使い始めるのはそれだけです。

00:18:48.000 --> 00:18:53.000
画像のフォルダなどの入力ソースからセッションを作成する方法を見ました。

00:18:53.000 --> 00:18:57.000
非同期出力ストリームをディスパッチメッセージに接続する方法を見ました。

00:18:57.000 --> 00:19:03.000
次に、2つの異なるレベルの詳細モデルを同時にリクエストする方法を見ました。

00:19:03.000 --> 00:19:10.000
最後に、ObjectCapture用のRealityKit GUIアプリの例を使用して、インタラクティブなワークフローについて説明しました。

00:19:10.000 --> 00:19:17.000
次に、同僚のDave McKinnonに渡します。Dave McKinnonは、Object Captureでベストプラクティスについて話し合います。

00:19:17.000 --> 00:19:19.000
デイブ・マッキノン:ありがとう、マイケル。

00:19:19.000 --> 00:19:23.000
こんにちは、私はデイブ・マッキノンで、オブジェクトキャプチャチームで働くエンジニアです。

00:19:23.000 --> 00:19:30.000
次のセクションでは、最高品質の結果を達成するためのベストプラクティスについて説明します。 

00:19:30.000 --> 00:19:35.000
まず、適切な特性を持つオブジェクトを選択するためのヒントとコツを見ていきます。

00:19:35.000 --> 00:19:42.000
最良の結果を得るために環境条件とカメラを制御する方法についての議論が続きます。

00:19:42.000 --> 00:19:45.000
次に、CaptureSampleアプリの使い方を説明します。

00:19:45.000 --> 00:19:54.000
このアプリでは、深度データと重力情報に加えて画像をキャプチャして、オブジェクトの真のスケールと向きを回復できます。

00:19:54.000 --> 00:20:00.000
手持ちとターンテーブルのキャプチャの両方でこのアプリの使用を説明します。

00:20:00.000 --> 00:20:08.000
最後に、ユースケースに適した出力詳細レベルを選択する方法と、さらに読むためのリンクについて説明します。

00:20:08.000 --> 00:20:13.000
スキャンを行う際に最初に考慮すべきことは、適切な特性を持つオブジェクトを選ぶことです。

00:20:13.000 --> 00:20:17.000
最良の結果を得るには、適切なテクスチャディテールを持つオブジェクトを選択してください。

00:20:17.000 --> 00:20:24.000
オブジェクトにテクスチャレスまたは透明な領域が含まれている場合、結果のスキャンには詳細が欠けている可能性があります。

00:20:24.000 --> 00:20:28.000
さらに、反射率の高い領域を含むオブジェクトを避けるようにしてください。

00:20:28.000 --> 00:20:34.000
物体が反射している場合は、スキャン時に照明を拡散することで最良の結果が得られます。

00:20:34.000 --> 00:20:40.000
キャプチャ全体を通してオブジェクトを反転させる予定がある場合は、形状が変わらないように硬質であることを確認してください。

00:20:40.000 --> 00:20:52.000
最後に、細かい表面の詳細を含むオブジェクトをスキャンする場合は、詳細を回復するために表面の多くのクローズアップ写真に加えて、高解像度カメラを使用する必要があります。

00:20:52.000 --> 00:20:56.000
では、典型的なスキャンプロセスを実演します。

00:20:56.000 --> 00:21:03.000
まず、最良の結果を得るには、オブジェクトがはっきりと目立つように、オブジェクトを整頓された背景に配置します。

00:21:03.000 --> 00:21:10.000
基本的なプロセスには、オブジェクトの周りをゆっくりと移動し、すべての側面から均一にキャプチャすることが含まれます。

00:21:10.000 --> 00:21:16.000
オブジェクトの下部を再構築したい場合は、それを反転して画像をキャプチャし続けます。

00:21:16.000 --> 00:21:21.000
画像を撮影するときは、オブジェクトをキャプチャする視野の部分を最大化するようにしてください。

00:21:21.000 --> 00:21:26.000
これは、APIができるだけ多くの詳細を回復するのに役立ちます。

00:21:26.000 --> 00:21:33.000
これを行う1つの方法は、オブジェクトの寸法と向きに応じて縦向きまたは横向きモードを使用することです。

00:21:33.000 --> 00:21:38.000
また、画像間の高度な重複を維持するようにしてください。

00:21:38.000 --> 00:21:44.000
オブジェクトによっては、20〜200枚のクローズアップ画像が良い結果を得るのに十分であるはずです。

00:21:44.000 --> 00:21:51.000
iOSで深度と重力で高品質の写真を撮影し始めるのを助けるために、CaptureSampleアプリを提供しています。

00:21:51.000 --> 00:21:54.000
これは、あなた自身のアプリの出発点として使用できます。

00:21:54.000 --> 00:21:59.000
SwiftUIで書かれており、開発者ドキュメントの一部です。

00:21:59.000 --> 00:22:03.000
このアプリは、オブジェクトキャプチャのために高品質の写真を撮る方法を示しています。

00:22:03.000 --> 00:22:06.000
手動シャッターモードと時時モードがあります。

00:22:06.000 --> 00:22:09.000
ターンテーブルと同期するようにアプリを変更することもできます。

00:22:09.000 --> 00:22:18.000
iPhoneとiPadをデュアルカメラで使用して深度データをキャプチャし、出力HEICファイルに直接埋め込む方法を示しています。

00:22:18.000 --> 00:22:22.000
このアプリは、重力データを保存する方法も示します。

00:22:22.000 --> 00:22:29.000
ギャラリーを表示して、深さと重力を備えたすべての良質の写真を持っていることをすばやく確認し、悪いショットを削除することができます。

00:22:29.000 --> 00:22:37.000
キャプチャフォルダはアプリのドキュメントフォルダに保存され、iCloudまたはAirDropを使用してMacに簡単にコピーできます。

00:22:37.000 --> 00:22:45.000
また、このセクションで説明する良いキャプチャを得るためのベストプラクティスガイドラインのいくつかをまとめたヘルプ画面もあります。

00:22:45.000 --> 00:22:49.000
この情報は、開発者ドキュメントでも確認できます。

00:22:49.000 --> 00:22:53.000
可能な限り最良の結果を得るために、ターンテーブルキャプチャをお勧めします。

00:22:53.000 --> 00:22:57.000
始めるには、ここにあるようなセットアップが必要です。

00:22:57.000 --> 00:23:10.000
これにはキャプチャ用のiOSデバイスが含まれていますが、デジタル一眼レフ、オブジェクトを回転させるための機械式ターンテーブル、ライトテントに加えていくつかの照明パネルを使用することもできます。

00:23:10.000 --> 00:23:14.000
目標は、均一な照明を持ち、硬い影を避けることです。

00:23:14.000 --> 00:23:17.000
軽いテントはこれを達成するための良い方法です。

00:23:17.000 --> 00:23:24.000
この場合、CaptureSampleアプリは、ターンテーブルの動きと同期した時差シャッターモードを使用して画像をキャプチャします。

00:23:24.000 --> 00:23:31.000
また、オブジェクトを反転させ、複数のターンテーブルパスを行い、あらゆる側面からオブジェクトをキャプチャすることもできます。

00:23:31.000 --> 00:23:37.000
これは、macOSのプレビューに表示されるターンテーブルキャプチャから得られたUSDZファイルです。

00:23:37.000 --> 00:23:45.000
画像をキャプチャするためのヒントとコツを説明したので、正しい出力を選択する方法に関する最後のセクションに移りましょう。

00:23:45.000 --> 00:23:49.000
スキャンにはさまざまな出力詳細設定があります。

00:23:49.000 --> 00:23:51.000
見てみましょう。 

00:23:51.000 --> 00:23:54.000
これは、詳細レベルを示す表です。

00:23:54.000 --> 00:23:58.000
サポートされているレベルは左側に沿って表示されます。

00:23:58.000 --> 00:24:06.000
ReducedとMediumは、AR Quick Lookで3Dコンテンツを表示するなど、Webベースおよびモバイルエクスペリエンスでの使用に最適化されています。

00:24:06.000 --> 00:24:12.000
三角形やマテリアルチャンネルが少なく、その結果、メモリの消費が少なくなります。

00:24:12.000 --> 00:24:20.000
FullとRawは、コンピュータゲームやポストプロダクションワークフローなどのハイエンドのインタラクティブな使用を目的としています。

00:24:20.000 --> 00:24:28.000
彼らは最高の幾何学的ディテールを含み、焼きたての材料と未焼成の材料の間で選択する柔軟性を与えます。

00:24:28.000 --> 00:24:35.000
縮小および中程度の詳細レベルは、インターネットやモバイルデバイスに表示したいコンテンツに最適です。

00:24:35.000 --> 00:24:48.000
この場合、Object Captureは、Raw結果からの幾何学的および材料情報を、ARアプリまたはARクイックルックでの表示に適したレベルに圧縮します。

00:24:48.000 --> 00:24:56.000
削減と中の両方の詳細レベルには、拡散、正常、および周囲の閉塞PBR材料チャネルが含まれています。

00:24:56.000 --> 00:25:08.000
1回のスキャンを詳細に表示したい場合、Mediumはファイルサイズに対して品質を最大化し、幾何学的および材料の詳細の両方を提供します。

00:25:08.000 --> 00:25:15.000
ただし、同じシーンで複数のスキャンを表示したい場合は、縮小された詳細設定を使用する必要があります。

00:25:15.000 --> 00:25:25.000
オブジェクトキャプチャを使用してモバイルまたはWeb ARエクスペリエンスを作成する方法の詳細については、「ARクイックルック、オブジェクトキャプチャを満たす」セッションを参照してください。

00:25:25.000 --> 00:25:30.000
フル出力レベルでのエクスポートは、プロのワークフローに最適です。

00:25:30.000 --> 00:25:35.000
この場合、スキャンに利用可能な最大限の詳細を取得しています。

00:25:35.000 --> 00:25:47.000
フルは、スキャンのジオメトリを最適化し、拡散、ノーマル、アンビエントオクルージョン、粗さ、および変位情報を含むPBR材料に詳細を焼きます。

00:25:47.000 --> 00:25:53.000
この出力レベルは、最も困難なレンダリングに必要なものすべてを提供すると思います。

00:25:53.000 --> 00:26:06.000
最後に、材料ベーキングを必要としない場合、またはこれのための独自のパイプラインがある場合、Rawレベルは、さらなる処理のために最大拡散テクスチャの詳細とともに最大ポリカウントを返します。

00:26:06.000 --> 00:26:15.000
macOSのプロワークフローでオブジェクトキャプチャを使用する方法の詳細については、「USDで3Dワークフローを作成する」セッションを参照してください。

00:26:15.000 --> 00:26:29.000
最後に、そして最も重要なことは、iOSとmacOSの両方でスキャンを使用する予定がある場合は、複数の詳細レベルを選択して、現在および将来のユースケースに適した出力を確認できます。

00:26:29.000 --> 00:26:30.000
そして、それはラップです。

00:26:30.000 --> 00:26:32.000
私たちが学んだことをまとめましょう。

00:26:32.000 --> 00:26:38.000
まず、例を通して、オブジェクトキャプチャAPIの背後にある主な概念を取り上げました。

00:26:38.000 --> 00:26:47.000
オブジェクトキャプチャセッションを作成し、このセッションを使用して画像のコレクションを処理して3Dモデルを作成する方法を紹介しました。

00:26:47.000 --> 00:26:56.000
キャプチャボリュームとモデル変換を調整できるように、APIがインタラクティブなプレビューアプリケーションをサポートする方法の例を紹介しました。

00:26:56.000 --> 00:26:59.000
次に、スキャンのベストプラクティスを取り上げました。

00:26:59.000 --> 00:27:06.000
最適な結果をもたらす環境、照明、カメラの設定だけでなく、使用するオブジェクトの種類についても議論しました。

00:27:06.000 --> 00:27:11.000
最後に、アプリケーションに適した出力詳細設定を選択する方法について説明しました。

00:27:11.000 --> 00:27:20.000
オブジェクトキャプチャを自分のアプリに持ち込む方法を学びたい場合は、iOSキャプチャとmacOS CLI処理アプリの両方をチェックして始めましょう。

00:27:20.000 --> 00:27:29.000
これらのアプリに加えて、ベストプラクティスを体現し、独自のスキャンをキャプチャする方法を計画する際に役立つさまざまなサンプルデータが付属しています。

00:27:29.000 --> 00:27:41.000
さらに、developer.apple.comでオンラインでのベストプラクティスに関する詳細なドキュメントと、これらの関連するWWDCセッションをチェックしてください。

00:27:41.000 --> 00:27:45.000
残っているのは、外に出て自分のスキャンにオブジェクトキャプチャを使用することだけです。

00:27:45.000 --> 00:27:49.000
私たちは、あなたがスキャンして共有するオブジェクトを見ることに興奮しています。

00:27:49.000 --> 23:59:59.000
♪

