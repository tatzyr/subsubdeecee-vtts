WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:11.000
タオ・ジア：こんにちは、私の名前はタオです。

00:00:11.000 --> 00:00:18.000
今日、同僚のジャックと私は、Create MLフレームワークを使用した動的iOSアプリの構築について話します。

00:00:18.000 --> 00:00:21.000
では、アプリが動的であるとはどういう意味ですか?

00:00:21.000 --> 00:00:28.000
ダイナミックアプリは、ユーザーにアプリの特定の要素をカスタマイズする柔軟性を与えるアプリです。

00:00:28.000 --> 00:00:34.000
ダイナミックアプリはまた、さまざまなユーザーのニーズに合わせてコンテンツを調整します。

00:00:34.000 --> 00:00:42.000
これらの適応可能なアプリ内機能は、ユーザーに合わせて、よりインテリジェントでパーソナライズされた体験を提供します。

00:00:42.000 --> 00:00:48.000
単純なヒューリスティックと事前定義されたルールによって、そのような特定の体験を提供できます。

00:00:48.000 --> 00:00:58.000
しかし、多くの場合、これらのアプローチは、背景や好みが異なる可能性があるため、すべてのアプリユーザーにとって最高の体験を提供できない場合があります。

00:00:58.000 --> 00:01:05.000
一方、機械学習技術を使用すると、ユーザーデータから直接学習するモデルを作成できます。

00:01:05.000 --> 00:01:12.000
これは多くの場合、より一般化可能であり、ヒューリスティックや事前定義されたルールよりも多くのユーザーに適している可能性が高い。

00:01:12.000 --> 00:01:16.000
では、そのような経験を提供するためにどのようなツールを使用できますか?

00:01:16.000 --> 00:01:26.000
Macで利用可能なCreate MLアプリを使用すると、トレーニングデータを選択して列車ボタンを押すだけで、モデルを簡単に作成できます。

00:01:26.000 --> 00:01:32.000
豊富なテンプレートセットを通じて、あらゆる種類のモデルタイプをサポートしています。

00:01:32.000 --> 00:01:40.000
このアプリは、機械学習モデルの加速トレーニングを提供するCreate MLフレームワークの上に構築されています。

00:01:40.000 --> 00:01:51.000
Create ML FrameworkはもともとmacOS Mojaveで導入され、モデルをSwiftコードとmacOSアプリ内からトレーニングできるようにしました。

00:01:51.000 --> 00:01:58.000
そして今、私たちはそのフレームワークをiOS 15とiPadOS 15に導入しています。

00:01:58.000 --> 00:02:04.000
デバイスで利用可能で、アプリはあらゆる種類の新しくてダイナミックなことを行うことができます。

00:02:04.000 --> 00:02:12.000
言い換えれば、デバイス上のモデルを作成するために、アプリケーションから直接プログラマティックAPIにアクセスできます。

00:02:12.000 --> 00:02:18.000
それはあなたのアプリにあなたのユーザーから学び、したがってあなたのユーザーに適応する機能を与えます。

00:02:18.000 --> 00:02:25.000
最後になりましたが、最も重要なことは、ユーザーデータがデバイスを離れる必要がないことです。したがって、ユーザーのプライバシーは保持されます。

00:02:25.000 --> 00:02:27.000
さあ、飛び込みましょう。

00:02:27.000 --> 00:02:30.000
Create MLにはさまざまなタスクがあります。

00:02:30.000 --> 00:02:38.000
これがmacOSで利用可能なすべてのものであり、これらは現在iOSで利用可能です。

00:02:38.000 --> 00:02:43.000
その中には、画像、音声、テキストの分類器などの一般的なタスクがあります。

00:02:43.000 --> 00:02:52.000
最近追加されたものには、スタイル転送だけでなく、今年のハンドポーズとハンドアクション分類器の新しい追加が含まれます。

00:02:52.000 --> 00:02:57.000
これらのツールを使用すると、多くの興味深いアイデアやユースケースがあります。

00:02:57.000 --> 00:02:59.000
ここにいくつかの例があります。

00:02:59.000 --> 00:03:13.000
画像分類を使用すると、アプリは子供のお気に入りのぬいぐるみがどのように見えるかを学び、一緒に彼らの冒険についての物語を作成するのを助けるために、それらのより多くの写真を見つけるのに役立ちます。

00:03:13.000 --> 00:03:24.000
テキスト分類器は、ユーザーが過去のアクションから学んだ提案されたタグとフォルダで書いたメモをすばやく整理するのに役立ちます。

00:03:24.000 --> 00:03:34.000
今年新しく追加されたハンドアクション分類器は、カスタムハンドアクションでアプリ内の視覚効果をトリガーする力をユーザーに与えることができます。

00:03:34.000 --> 00:03:42.000
iOSのCreate MLでできるクールなことはたくさんありますが、デモで私が何を意味するのかを示す方が良いです。

00:03:42.000 --> 00:03:51.000
私はフォトブースアプリに少し似ているアプリを持っていますが、カスタマイズされたフォトフィルターを作成できるため、よりダイナミックです。

00:03:51.000 --> 00:03:55.000
それがどのように機能するかをお見せしましょう。

00:03:55.000 --> 00:04:04.000
ここ私のiPadでは、Create MLスタイルの転送タスクを使用してMacでトレーニングした既存のフィルターのリストが上部に表示されます。

00:04:04.000 --> 00:04:09.000
それらのそれぞれは、フィルターの作成に使用される特定のスタイル画像で表されます。

00:04:09.000 --> 00:04:17.000
下部にあるアプリは、写真を撮ったり選択したりして、これらのフィルターを試す写真を待っています。

00:04:17.000 --> 00:04:20.000
今すぐ写真を撮らせてください。

00:04:20.000 --> 00:04:22.000
自撮りはいかがですか？

00:04:22.000 --> 00:04:28.000
これらのフィルターがどのように見えるか見てみましょう。

00:04:28.000 --> 00:04:32.000
まず、この波形の最初の写真をクリックしてください。

00:04:32.000 --> 00:04:40.000
ああ、顔と髪に水滴が滴り落ちました。昔のマイアミでの休暇を思い出します。

00:04:40.000 --> 00:04:42.000
このバーディーの写真はどうですか？

00:04:42.000 --> 00:04:45.000
私がどれほどカラフルか見てください。

00:04:45.000 --> 00:04:50.000
割れた氷のように見えるこの3枚目の写真はどうですか？

00:04:50.000 --> 00:04:54.000
ああ、私はかっこよくて凍って見える。

00:04:54.000 --> 00:04:59.000
今、これらは本当に楽しそうに見えますが、私はまだ何かを見逃していると感じています。

00:04:59.000 --> 00:05:04.000
選択した写真を使ってフィルターを作成できるとしたら？

00:05:04.000 --> 00:05:07.000
これにより、このアプリを使うのが本当に楽しくなるでしょう。

00:05:07.000 --> 00:05:14.000
試してみましょう。

00:05:14.000 --> 00:05:17.000
私は娘が3歳の時に描いたこの絵を持っています。

00:05:17.000 --> 00:05:20.000
私は本当に質感と色が大好きです。

00:05:20.000 --> 00:05:28.000
私は娘の芸術的なスタイルでどのように見えるか興味があります。

00:05:28.000 --> 00:05:37.000
この「+フィルター」ボタンをクリックし、カメラを選択して写真を撮ります。

00:05:37.000 --> 00:05:43.000
「写真を使う」

00:05:43.000 --> 00:05:45.000
今、フィルターが作成されています。

00:05:45.000 --> 00:05:49.000
ボンネットの下では、カスタマイズされたスタイル転送モデルをトレーニングしています。

00:05:49.000 --> 00:05:52.000
それがどのように機能するか説明しましょう。

00:05:52.000 --> 00:05:55.000
まず、単一のスタイル画像を選択します。

00:05:55.000 --> 00:05:59.000
私が使ったスタイルイメージは娘の絵です。

00:05:59.000 --> 00:06:10.000
次に、これらの画像の元のコンテンツを保存しながらスタイルを適用する方法を学ぶために、モデル用のコンテンツ画像のセットを提供する必要があります。

00:06:10.000 --> 00:06:18.000
このデモでは、風光明媚な写真やセルフィーなど、アルバムから数十枚の写真を使用しました。

00:06:18.000 --> 00:06:29.000
ペットの写真など、他の写真タイプにスタイルを適用したい場合は、コンテンツセットにそのような写真をいくつか含めることもできます。

00:06:29.000 --> 00:06:36.000
次に、アプリケーションのシナリオに応じて、フィルタータイプを画像またはビデオとして選択します。

00:06:36.000 --> 00:06:43.000
このデモでは、静的な写真にスタイルを適用したいので、画像を選びました。

00:06:43.000 --> 00:06:56.000
また、スタイルの強さとスタイル密度、および反復回数を試して、スタイル化とオリジナルのコンテンツのお気に入りの組み合わせを得ることもできます。

00:06:56.000 --> 00:07:04.000
これらのパラメータの設定方法の詳細については、昨年のWWDCセッションを参照してください。

00:07:04.000 --> 00:07:09.000
では、新しく作成したフィルターを私の写真で試してみましょう。

00:07:09.000 --> 00:07:13.000
うわー、それが私の娘の絵の見方です。

00:07:13.000 --> 00:07:17.000
それは実際にこれらの質感と色を拾いました。

00:07:17.000 --> 00:07:24.000
別の写真を試してみるのはどうですか？

00:07:24.000 --> 00:07:27.000
私は娘が一緒に遊ぶのが本当に大好きなこのウサギを持っています。

00:07:27.000 --> 00:07:32.000
バニーと一緒にセルフィーを撮ってフィルターを塗るのはどうですか？

00:07:32.000 --> 00:07:40.000
バニーも彼女の絵によって様式化されました。

00:07:40.000 --> 00:07:44.000
これを彼女に見せて、彼女の他の絵を試着するのが待ちきれません。

00:07:44.000 --> 00:07:46.000
とても楽しいでしょう。とても楽しいでしょう

00:07:46.000 --> 00:07:55.000
このデモでは、iOSのCreate MLフレームワークで利用可能なスタイル転送モデルを活用して、カスタマイズされた写真フィルターを作成する方法を紹介しました。

00:07:55.000 --> 00:07:58.000
それで、それはコードでどのように見えますか?

00:07:58.000 --> 00:08:05.000
まず、1つのスタイル画像と一連のコンテンツ画像を指定するトレーニングデータソースを定義します。

00:08:05.000 --> 00:08:13.000
次に、セッションパラメータを定義して、チェックポイントを保存する場所などを指定します。

00:08:13.000 --> 00:08:18.000
次に、これらのパラメータを使用してトレーニングジョブを定義します。

00:08:18.000 --> 00:08:33.000
最後に、トレーニングジョブを派遣し、正常に完了したら、トレーニングされたモデルを保存して画像を様式化し、Core MLモデルをコンパイルしてインスタンス化し、予測を開始します。

00:08:33.000 --> 00:08:34.000
そして、それだけです。

00:08:34.000 --> 00:08:41.000
これは、Create MLフレームワークのスタイル転送APIを使用して、カスタマイズされた写真フィルターを作成するために使用したものです。

00:08:41.000 --> 00:08:45.000
他のタスクは、同様のAPIパターンに従います。

00:08:45.000 --> 00:08:54.000
これまでのところ、画像、テキスト、オーディオ、ビデオなどのリッチメディアデータタイプからモデルを作成できるタスクについて話しました。

00:08:54.000 --> 00:08:58.000
しかし、あなたのアプリがそのようなデータタイプと相互作用しない場合はどうなりますか?

00:08:58.000 --> 00:09:05.000
同僚のジャックを招待して、このような場合にアプリをダイナミックにする方法について話しましょう。

00:09:05.000 --> 00:09:06.000
ジャック・カックラー:ありがとう、タオ。

00:09:06.000 --> 00:09:15.000
これまでに取り上げたタスクに加えて、iOSのCreate MLフレームワークは、構造化された表形式データの分類器と回帰器もサポートしています。

00:09:15.000 --> 00:09:20.000
これらがよりダイナミックなアプリ体験を生み出す方法の例を見てみましょう。

00:09:20.000 --> 00:09:23.000
まず、分類器と回帰器に関するいくつかの背景。

00:09:23.000 --> 00:09:29.000
分類器は、トレーニングデータセットのデータから特定のクラスを予測することを学習します。

00:09:29.000 --> 00:09:35.000
回帰器は似ていますが、離散クラスラベルの代わりに数値を予測することを学習します。

00:09:35.000 --> 00:09:43.000
ここでは、一般的な表形式データから分類器と回帰器を訓練するためのAPIがあり、さまざまなシナリオで使用できます。

00:09:43.000 --> 00:09:49.000
特に、iOSでのCreate MLは、これらのそれぞれに4つの異なるアルゴリズムを提供します。

00:09:49.000 --> 00:09:58.000
一般的な表形式モデルでの作業は、モデルで使用する機能と目標値を決定する必要があるため、使用するにはもう少し作業が必要です。

00:09:58.000 --> 00:10:00.000
しかし、これはしばしば簡単です。

00:10:00.000 --> 00:10:07.000
パーソナライズされたエクスペリエンスを追加するために、表形式の回帰を使用するアプリを考えてみましょう。

00:10:07.000 --> 00:10:10.000
これは、レストランから食事を注文するためのシンプルなアプリです。

00:10:10.000 --> 00:10:12.000
このアプリには、その地域にレストランがあります。

00:10:12.000 --> 00:10:15.000
これはアメージング・タイという地元のタイ料理レストランです。

00:10:15.000 --> 00:10:21.000
選択すると、アプリにはレストランから注文できる料理と各料理に関する情報が表示されます。

00:10:21.000 --> 00:10:24.000
シンプルなアプリですが、もっと良くできるとしたらどうでしょうか？

00:10:24.000 --> 00:10:32.000
本当に素晴らしいのは、時間が経つにつれて私のアプリが私の行動を学び、私が好もうと思うかもしれないインテリジェントなレストランや料理の提案を表面化させるのに役立った場合です。

00:10:32.000 --> 00:10:37.000
これは、シンプルなアプリから本当にダイナミックな体験にこれを取るでしょう。

00:10:37.000 --> 00:10:41.000
アプリで表形式の回帰をトレーニングすることで、これを達成できます。

00:10:41.000 --> 00:10:50.000
私は3種類の情報を取り、それらを構造化されたテーブルにまとめてモデルを訓練し、新しいダイナミックな体験を提供します。

00:10:50.000 --> 00:10:54.000
1つ目はコンテンツで、これは私がアプリにロードしたデータです。

00:10:54.000 --> 00:10:57.000
私たちのレストランアプリの場合、それは料理に関する情報です。

00:10:57.000 --> 00:10:59.000
2つ目は文脈です。

00:10:59.000 --> 00:11:03.000
この場合、ユーザーが注文している時刻です。

00:11:03.000 --> 00:11:10.000
最後に、ユーザーの注文履歴を追加し、デバイス上でユーザーのためだけに調整されたエクスペリエンスを作成します。

00:11:10.000 --> 00:11:24.000
コンテンツとコンテキスト、および過去のユーザーインタラクションを組み合わせることで、将来のインタラクションを予測できます。パーソナライゼーションの絶好の機会であり、この場合、ユーザーが将来気に入るかもしれない料理を予測するのに役立ちます。

00:11:24.000 --> 00:11:27.000
モデルが追加されたアプリに戻りましょう。 ではモデルが追加されています。

00:11:27.000 --> 00:11:30.000
今日は昼食を注文して、ピザが食べたい気分です。

00:11:30.000 --> 00:11:39.000
私は食事をランチに設定し、ピザパーラーを選択し、マルゲリータピザを選んで注文します。

00:11:39.000 --> 00:11:44.000
このウィンドウには、表形式の回帰を訓練している情報がいくつかあります。

00:11:44.000 --> 00:11:55.000
内容は、この料理のキーワードです。材料のようなもの - トマト、モッツァレラ - だけでなく、レストラン自体 - ピザパーラー - そして食べ物のジャンル - ピザ。

00:11:55.000 --> 00:11:58.000
このモデルのコンテキストは時間帯です。

00:11:58.000 --> 00:12:03.000
これは昼食からのものです、そして今、私はこれらが昼食時に好きかもしれないものであることを私のモデルに教えました。

00:12:03.000 --> 00:12:07.000
最後に、私の相互作用は、他の料理ではなく、この料理を注文したということです。

00:12:07.000 --> 00:12:16.000
私が訓練している回帰者は、私が注文するかもしれない各料理の好みのスコアを予測しています、そして今日、私は他の料理ではなく、この料理を注文したことを学びました。

00:12:16.000 --> 00:12:25.000
メイン画面に戻ると、モデルはすでに訓練されており、私だけの料理を提案する新しいウィンドウがあります。

00:12:25.000 --> 00:12:33.000
私が実際に注文した料理 - マルゲリータピザ - は最初のお勧めですが、次のお勧めは全く別のレストランのカプレーゼサンドイッチです。

00:12:33.000 --> 00:12:36.000
他のいくつかのピザも一番上にあります。

00:12:36.000 --> 00:12:38.000
別の例を挙げてみましょう。

00:12:38.000 --> 00:12:42.000
今、夕食を注文していると言ってください。

00:12:42.000 --> 00:12:48.000
今回はアメージングタイからイエローカレーを注文します。

00:12:48.000 --> 00:12:50.000
これで、モデルが再び更新されました。

00:12:50.000 --> 00:12:53.000
それは私が注文している時間帯の文脈で、私の新しい好みを学びました。

00:12:53.000 --> 00:12:59.000
注文したばかりのイエローカレーが今一番のおすすめで、似たようなカレーが2番目のおすすめです。

00:12:59.000 --> 00:13:02.000
次のおすすめはベジタリアンピザです。

00:13:02.000 --> 00:13:10.000
注文したばかりのカレーと同じようにキノコとピーマンが入っていて、アプリは夕食の最初の選択ではないかもしれないとしても、私がピザが好きかもしれないことを知っています。

00:13:10.000 --> 00:13:18.000
翌日昼食を注文しに行くと、モデルは昼食に注文するものと夕食に注文するものを区別することを学びました。

00:13:18.000 --> 00:13:26.000
これは、私が欲しい時に欲しいものを正確に見つけるのに役立つ本当にパーソナライズされた経験を与え、それはたった2つの注文です。

00:13:26.000 --> 00:13:36.000
表形式の分類器または回帰器をアプリに追加するには、データの設定、トレーニング、予測の3つの実際のステップがあります。

00:13:36.000 --> 00:13:42.000
ここでの最初の機能は、食事とキーワードからこの回帰器で活用される機能を作成します。

00:13:42.000 --> 00:13:57.000
私は各料理に関連付けられたキーワードを取り、それらを現在の食事(コンテキスト)と組み合わせて、モデルがコンテンツ(皿)キーワードとコンテキスト(食事)キーワードの間の相互作用をキャプチャすることを可能にする新しいキーワードを作成します。

00:13:57.000 --> 00:14:07.000
辞書に1.0の値を入れて、単に特定のキーワードがデータ入力に存在することを示します。

00:14:07.000 --> 00:14:14.000
まず、ユーザーが注文した料理ごとに、以前に生成された機能と正の目標値を持つエントリを追加します。

00:14:14.000 --> 00:14:21.000
しかし、これを含めるだけでは、モデルは私が好きな料理と嫌いな料理を見分けることを学ばないでしょう。

00:14:21.000 --> 00:14:29.000
これを行うには、ディッシュに存在しないすべてのキーワードを使用して、負の目標値が-1のエントリも追加します。

00:14:29.000 --> 00:14:35.000
これにより、モデルはユーザーの好みに最も適したキーワードを学習できます。

00:14:35.000 --> 00:14:42.000
この結合された情報をDataFrameに変換し、キーワードとターゲットの両方を指定します。

00:14:42.000 --> 00:14:51.000
最後に、予測しようとしている列が1または-1に設定したターゲット列であることを指定して、モデルをトレーニングします。

00:14:51.000 --> 00:14:58.000
この場合、モデルは単純な線形回帰器であり、アプリで使用できる有意義な結果を生成します。

00:14:58.000 --> 00:15:06.000
予測時には、推論を実行したいデータを取り、トレーニングしたモデルから予測を呼び出すだけです。

00:15:06.000 --> 00:15:14.000
これまでのところ、iPadOSとiOSアプリでスタイル転送モデルと表形式の回帰をトレーニングする方法を示しました。

00:15:14.000 --> 00:15:19.000
機械学習トレーニングをアプリに統合するためのベストプラクティスについて話しましょう。

00:15:19.000 --> 00:15:22.000
一般的に機械学習のベストプラクティスに従うことを忘れないでください。

00:15:22.000 --> 00:15:28.000
たとえば、トレーニングデータセットにないデータに対してモデルのパフォーマンスを常にテストします。

00:15:28.000 --> 00:15:36.000
長時間のトレーニングタスクでは、非同期トレーニング制御とチェックポイントメカニズムを活用して、モデル作成ワークフローをカスタマイズします。

00:15:36.000 --> 00:15:45.000
モデル作成のいくつかの側面は、計算集約的であったり、追加のメモリを消費したり、追加の資産をダウンロードしたりする必要があります。

00:15:45.000 --> 00:15:49.000
アプリに統合するときは、これらを考慮してください。

00:15:49.000 --> 00:15:53.000
詳細については、APIとドキュメントを参照してください。

00:15:53.000 --> 00:16:07.000
ベストプラクティスについてもっと知りたい場合は、「素晴らしいMLエクスペリエンスの設計」と「SwiftでMLを作成する際のコントロールトレーニング」に関する過去数年間の他のWWDCセッションを確認することを強くお勧めします。

00:16:07.000 --> 00:16:12.000
このセッションでは、iOSでCreate MLフレームワークを使用する方法について説明しました。

00:16:12.000 --> 00:16:21.000
スタイル転送と表形式の回帰を使用して例を挙げましたが、Create MLテンプレートのほとんどは、iPhoneまたはiPadで直接トレーニングできるようになりました。

00:16:21.000 --> 00:16:30.000
iOSのトレーニングを通じて、ユーザーのプライバシーを維持しながら、ユーザーにカスタマイズされたパーソナライズされた体験を提供するダイナミックなアプリを作成できます。

00:16:30.000 --> 00:16:36.000
トレーニングと推論は完全にアプリ内であるため、どちらも心配するモデルの展開はありません。

00:16:36.000 --> 00:16:39.000
私たちはあなたが思いつくものを見るのを本当に楽しみにしています。

00:16:39.000 --> 00:16:42.000
聞いてくれてありがとう、WWDCの残りの部分を楽しんでください。

00:16:42.000 --> 23:59:59.000
♪

