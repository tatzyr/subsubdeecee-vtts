WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:11.000
ユージン・ジドコフ:こんにちは、WWDCへようこそ。

00:00:11.000 --> 00:00:14.000
私の名前はユージン・ジドコフです。私はGPUソフトウェアの出身です。

00:00:14.000 --> 00:00:24.000
そして、MacシステムアーキテクチャのHarsh Patilと一緒に、Appleシリコン上のMetalを搭載した画像処理アプリケーションを作成する方法を紹介します。

00:00:24.000 --> 00:00:35.000
まず、ベストプラクティスと教訓に焦点を当て、昨年の開発者エンゲージメントに基づいてM1の画像処理アプリケーションを最適化します。

00:00:35.000 --> 00:00:44.000
そして、Harshは、Appleシリコンで最適なパフォーマンスを得るために画像処理パイプラインを再設計する方法のステップバイステップガイドを提供します。

00:00:44.000 --> 00:00:46.000
だから、すぐに飛び込みましょう!

00:00:46.000 --> 00:00:52.000
まず、Appleのシステムオンザチップアーキテクチャとその利点を簡単に再検討しましょう。

00:00:52.000 --> 00:00:57.000
多くの画像処理およびビデオ編集アプリは、ディスクリートGPUを念頭に置いて設計されています。

00:00:57.000 --> 00:01:02.000
したがって、Apple GPUの何がそんなに違うのかを強調することが重要です。

00:01:02.000 --> 00:01:06.000
まず、すべてのAppleチップはUnified Memory Architectureを使用しています。

00:01:06.000 --> 00:01:15.000
CPU、GPU、ニューラル、メディアエンジンなどのすべてのブロックは、ユニファイドメモリインターフェイスを使用して同じシステムメモリにアクセスできます。

00:01:15.000 --> 00:01:21.000
そして第二に、私たちのGPUはタイルベースの遅延レンダラー、またはTBDRです。

00:01:21.000 --> 00:01:35.000
TBDRには2つの主要なフェーズがあります。レンダリングサーフェス全体がタイルに分割され、処理されたジオメトリが独立して処理されるタイリングと、すべてのピクセルが各タイルに対して処理されるレンダリングです。

00:01:35.000 --> 00:01:51.000
したがって、Appleシリコンで最も効率的であるためには、画像処理アプリは、パイプラインがかつて持っていたコピーを避けるために統一メモリと、タイルメモリとローカル画像ブロックを利用してTBDRアーキテクチャを活用する必要があります。

00:01:51.000 --> 00:02:00.000
Apple TBDRが低レベルでどのように機能し、シェーダーコアをターゲットにする方法の詳細については、昨年のこれらのセッションをご覧ください。

00:02:00.000 --> 00:02:08.000
そして今、Appleシリコンの画像処理コンピューティングワークロードを最適化するために私たちがやろうとしている正確なことについて話しましょう。

00:02:08.000 --> 00:02:14.000
昨年、私たちは多くの優れた開発者と画像パイプラインの移行に緊密に協力してきました。

00:02:14.000 --> 00:02:17.000
私たちは共有する6つの最もやりがいのあるヒントを選びました。

00:02:17.000 --> 00:02:22.000
まず、不要なメモリコピーやブリットを回避する方法について説明します。

00:02:22.000 --> 00:02:27.000
現在、最大8Kの画像に取り組んでいることを考えると、これは本当に重要です。

00:02:27.000 --> 00:02:38.000
次に、バッファでコンピューティングを使用する代わりにレンダリングパイプラインとテクスチャを使用する利点と、独自の画像処理パイプラインでそれを行う方法を強調したいと思います。

00:02:38.000 --> 00:02:46.000
レンダリングとテクスチャのパスを稼働させたら、適切なロード/ストアアクションとメモリレスアタッチメントの重要性を紹介したいと思いました。

00:02:46.000 --> 00:02:50.000
これは、タイルのメモリを最大限に活用するのに役立ちます。

00:02:50.000 --> 00:03:03.000
次に、動的制御フローでUber-shadersにアプローチする方法と、短いデータタイプや半分などの小さなデータタイプを活用してパフォーマンスと効率を向上させる方法について話します。

00:03:03.000 --> 00:03:08.000
そして、最高のスループットを得るために、テクスチャフォーマットに関する重要なアドバイスで締めくくります。

00:03:08.000 --> 00:03:09.000
わかった。

00:03:09.000 --> 00:03:15.000
それでは、最もやりがいのあるヒントの1つから始めましょう。Appleシリコンの不要なブリッツを避けることです。

00:03:15.000 --> 00:03:20.000
ほとんどの画像処理アプリは、ディスクリートGPUを中心に設計されています。

00:03:20.000 --> 00:03:25.000
ディスクリートGPUを使用すると、システムメモリとビデオメモリが分離されます。

00:03:25.000 --> 00:03:31.000
フレーム画像をGPUに表示または常駐させるには、明示的なコピーが必要です。

00:03:31.000 --> 00:03:37.000
さらに、通常、GPUがそれを処理するためのデータをアップロードし、それを引き戻すために2回必要です。

00:03:37.000 --> 00:03:43.000
8Kビデオをデコードし、処理し、ディスクに保存することを考えてみましょう。

00:03:43.000 --> 00:03:48.000
したがって、この場合、これはCPUスレッド、デコードです。

00:03:48.000 --> 00:03:53.000
そこで、デコードされたフレームをGPU VRAMにコピーする必要があります。

00:03:53.000 --> 00:03:58.000
そして、これはすべてのエフェクトとフィルターが適用されるGPUタイムラインです。

00:03:58.000 --> 00:04:03.000
さらに一歩進んで、結果をディスクに保存する必要があることを思い出しましょう。

00:04:03.000 --> 00:04:12.000
したがって、処理されたフレームをシステムメモリに戻し、フレームの実際のエンコーディングも検討する必要があります。

00:04:12.000 --> 00:04:21.000
したがって、これらは「コピー」または「ブリットギャップ」として知られており、高度な画像処理アプリケーションは、それらを埋めるために深いパイプラインやその他のスマートなことをしなければなりませんでした。

00:04:21.000 --> 00:04:28.000
さて、良いニュースは、Apple GPUでは、居住のためのブリットはもはや必要ないということです。

00:04:28.000 --> 00:04:33.000
メモリは共有されているため、CPUとGPUの両方が直接アクセスできます。

00:04:33.000 --> 00:04:40.000
したがって、ユニファイドメモリシステムで実行しているかどうかを検出し、不要なコピーを避けるために、簡単なチェックを追加してください。

00:04:40.000 --> 00:04:45.000
それはあなたの記憶、時間を節約し、絶対的な最初のステップです。

00:04:45.000 --> 00:04:51.000
だから、これは私たちがブリットを削除したユニファイドメモリアーキテクチャに着陸する場所です。

00:04:51.000 --> 00:04:58.000
ブリットを取り除くことで、コピーのギャップを完全に回避し、すぐに処理を開始できます。

00:04:58.000 --> 00:05:03.000
これにより、より少ない手間でより良いCPUとGPUのパイプラインも提供されます。

00:05:03.000 --> 00:05:07.000
コピーを伴わない統一されたメモリパスを実装しましょう。

00:05:07.000 --> 00:05:18.000
ブリットコピーをディスクリートGPUとまったく同じままにしておくと、システムメモリ帯域幅、実際の処理のためのGPU時間の短縮、および潜在的なスケジューリングオーバーヘッドで支払います。

00:05:18.000 --> 00:05:24.000
言うまでもなく、個別のVRAMイメージを割り当てる必要がなくなりました。

00:05:24.000 --> 00:05:28.000
GPUフレームキャプチャは、大きなブリットを見つけるのに役立ちます。

00:05:28.000 --> 00:05:34.000
アプリケーションのブリットを検査し、必要なコピーのみを行うことを確認してください。

00:05:34.000 --> 00:05:40.000
さて、画像処理にApple GPU TBDRアーキテクチャをどのように活用すべきかについて話しましょう。

00:05:40.000 --> 00:05:47.000
ほとんどの画像処理アプリケーションは、一連のコンピューティングカーネルをディスパッチすることによって画像バッファで動作します。

00:05:47.000 --> 00:05:55.000
デフォルトのシリアルモードでコンピューティングカーネルをディスパッチすると、Metalは後続のすべてのディスパッチがすべてのメモリ書き込みを見ることを保証します。

00:05:55.000 --> 00:06:06.000
この保証は、すべてのシェーダーコアのメモリの一貫性を意味するため、すべてのメモリ書き込みは、次のディスパッチが開始されるまでに他のすべてのコアに表示されます。

00:06:06.000 --> 00:06:12.000
これはまた、メモリトラフィックが本当に高くなる可能性があることを意味します。画像全体を読み取り、書きする必要があります。

00:06:12.000 --> 00:06:17.000
M1では、Apple GPUはMacOSでタイルディスパッチを可能にします。

00:06:17.000 --> 00:06:23.000
通常のコンピューティングとは対照的に、タイルのみの同期ポイントを持つタイルメモリで動作します。

00:06:23.000 --> 00:06:29.000
畳み込みのような一部のフィルターはタイルパラダイムにマッピングできませんが、他の多くのフィルターはできます!

00:06:29.000 --> 00:06:35.000
エンコーダのエンドポイントが堅実な効率向上になるまで、システムメモリのフラッシュを延期します。

00:06:35.000 --> 00:06:41.000
システムメモリ帯域幅に制限されていない場合、より有用なGPU作業を実行できます。

00:06:41.000 --> 00:06:52.000
さらに、多くのピクセルごとの操作は近隣のピクセルへのアクセスを必要としないため、タイル同期ポイントは必要ありません。

00:06:52.000 --> 00:06:55.000
これはフラグメント関数に本当によくマッピングされます。

00:06:55.000 --> 00:07:05.000
フラグメント関数は、暗黙のタイル同期なしで実行でき、エンコーダ境界でのみ、またはタイルカーネルがフラグメントカーネルの後に連続してディスパッチされる場合にのみ同期する必要があります。

00:07:05.000 --> 00:07:11.000
Apple GPUは、より効率的な画像処理のためにフラグメント機能とタイルカーネルを可能にすることを学びました。

00:07:11.000 --> 00:07:14.000
それをどう使うか見てみましょう。

00:07:14.000 --> 00:07:21.000
バッファ上の通常の計算ディスパッチを変換して、テクスチャにコマンドエンコーダをレンダリングすることによってそれを行います。

00:07:21.000 --> 00:07:25.000
先ほど説明したように、経験則は次のとおりです。

00:07:25.000 --> 00:07:31.000
ピクセル間の依存関係のないピクセルごとの操作は、フラグメント関数を使用して実装する必要があります。

00:07:31.000 --> 00:07:39.000
スレッドグループスコープ操作を持つフィルタは、タイル内のネイバーピクセルアクセスが必要なため、タイルシェーディングで実装する必要があります。

00:07:39.000 --> 00:07:49.000
スキャッターギャザーと畳み込みフィルタは、ランダムアクセスを必要とするため、タイルパラダイムにマッピングできないため、これらはまだコンピューティングディスパッチのままである必要があります。

00:07:49.000 --> 00:07:56.000
レンダリングコマンドエンコーダは、独自のApple GPU機能も可能にします。テクスチャとレンダリングターゲットのロスレス帯域幅圧縮です。

00:07:56.000 --> 00:08:04.000
これは、特に画像処理パイプラインにとって、本当に素晴らしい帯域幅の節約なので、どのように使用すべきか見てみましょう。

00:08:04.000 --> 00:08:10.000
さて、可逆圧縮を有効にすることといえば、実際にはあなたがすべきではないことを言う方が簡単です。

00:08:10.000 --> 00:08:15.000
まず、すでに圧縮されているテクスチャフォーマットは、ロスレスの恩恵を受けることはできません。

00:08:15.000 --> 00:08:24.000
第二に、この圧縮では動作しない3つの特定のテクスチャフラグがあるので、偶然に設定しないようにしてください。

00:08:24.000 --> 00:08:31.000
そして第三に、線形テクスチャ、またはMTLBufferに裏打ちされたテクスチャも許可されていません。

00:08:31.000 --> 00:08:41.000
非プライベートテクスチャにも特別な処理が必要です。最速のパスにとどまるには、必ずOptimizeContentsForGPUAccessを呼び出してください。

00:08:41.000 --> 00:08:49.000
GPUフレームキャプチャサマリーペインに、ロスレス圧縮警告が表示され、テクスチャがオプトアウトした理由が強調表示されます。

00:08:49.000 --> 00:08:54.000
この例では、PixelFormatViewフラグが設定されました。

00:08:54.000 --> 00:08:58.000
多くの場合、開発者は意図せずにこれらのフラグを設定しています。

00:08:58.000 --> 00:09:05.000
必要なのはコンポーネントのスウィズルまたはsRGB変換だけの場合は、PixelFormatViewを設定しないでください。

00:09:05.000 --> 00:09:08.000
さて、レンダリングとテクスチャのパスが稼働しています。

00:09:08.000 --> 00:09:11.000
では、タイルメモリを適切に使用しましょう。

00:09:11.000 --> 00:09:19.000
ロード/ストアアクションやメモリレスアタッチメントなどのタイルメモリTBDRの概念は、デスクトップの世界ではまったく新しいものです。

00:09:19.000 --> 00:09:22.000
だから、それらを適切に使用するようにしましょう。

00:09:22.000 --> 00:09:25.000
ロード/ストアアクションから始めましょう!

00:09:25.000 --> 00:09:29.000
すでに知っているように、レンダリングターゲット全体がタイルに分割されています。

00:09:29.000 --> 00:09:36.000
ロード/ストアは、メモリ階層を通じて最適なパスを取ることが保証されたタイルごとのバルクアクションです。

00:09:36.000 --> 00:09:48.000
それらはレンダリングパスの開始時に実行され、GPUにタイルメモリの初期化方法を指示し、パスの最後にどの添付ファイルを書き戻す必要があるかをGPUに通知します。

00:09:48.000 --> 00:09:52.000
ここで重要なのは、必要のないものをロードするのを避けることです。

00:09:52.000 --> 00:09:59.000
画像全体を上書きしている場合、またはリソースが一時的である場合は、ロードアクションをLoadActionDontCareに設定します。

00:09:59.000 --> 00:10:09.000
レンダリングエンコーダを使用すると、専用のコンピューティングパスまたはfillBufferコールで以前に行ったように、出力または一時データをクリアする必要がなくなります。

00:10:09.000 --> 00:10:14.000
LoadActionClearを設定することで、クリア値を効率的に指定できます。

00:10:14.000 --> 00:10:16.000
そして、同じことが店の行動にも当てはまります。

00:10:16.000 --> 00:10:23.000
メインの添付ファイルのように、後で必要なデータのみを保存し、一時的なものは保存しないでください。

00:10:23.000 --> 00:10:30.000
明示的なロードとストアアクションに加えて、Apple GPUはメモリレスアタッチメントでメモリフットプリントを節約します。

00:10:30.000 --> 00:10:35.000
添付ファイルをメモリレスストレージモードとして明示的に定義できます。

00:10:35.000 --> 00:10:43.000
これにより、タイルのみのメモリ割り当てが可能になります。つまり、リソースはエンコーダの寿命内にのみ、すべてのタイルに対して持続します。

00:10:43.000 --> 00:10:51.000
これにより、特にすべてのフレームが数百メガバイトかかる6K / 8K画像の場合、メモリフットプリントを大幅に削減できます。

00:10:51.000 --> 00:10:54.000
このすべてをコードでどのように行うことができるか見てみましょう。

00:10:54.000 --> 00:11:00.000
まず、textureDescriptorを作成し、次にoutputTextureを作成します。

00:11:00.000 --> 00:11:02.000
次に、一時的なテクスチャを作成します。

00:11:02.000 --> 00:11:07.000
ここにストレージが欲しくないので、メモリレスとマークしたことに注意してください。

00:11:07.000 --> 00:11:14.000
次に、最初に添付ファイルが何であるか、次にロード/ストアアクションが何であるかを記述して、レンダリングパスを作成します。

00:11:14.000 --> 00:11:20.000
完全に上書きされているため、出力の読み込みは気にしませんが、保存する必要があります。

00:11:20.000 --> 00:11:26.000
一時的なテクスチャについては、ロードするのではなくクリアし、保存する必要もありません。

00:11:26.000 --> 00:11:31.000
最後に、記述子からrenderPassを作成します。

00:11:31.000 --> 00:11:32.000
それでおそれ。

00:11:32.000 --> 00:11:41.000
そのため、ユニファイドメモリを使用し、画像処理パイプラインを移動してコマンドエンコーダをレンダリングし、タイルメモリを適切に活用しています。

00:11:41.000 --> 00:11:44.000
さて、ウーバーシェーダーについて話しましょう。

00:11:44.000 --> 00:11:50.000
Uber-shaders、またはuber-kernelsは、開発者の生活を楽にするための非常に人気のある方法です。

00:11:50.000 --> 00:12:03.000
ホストコードは制御構造を設定し、シェーダーは、トーンマッピングが有効になっている場合や、入力がHDRまたはSDR形式の場合など、一連のif/elseステートメントをループするだけです。

00:12:03.000 --> 00:12:11.000
このアプローチは「ubers-shader」とも呼ばれ、パイプライン状態オブジェクトの総数を下げるのが本当に得意です。

00:12:11.000 --> 00:12:14.000
しかし、それには欠点があります。

00:12:14.000 --> 00:12:19.000
主なものは、より複雑な制御フローに追いつくためのレジスタ圧力の増加です。

00:12:19.000 --> 00:12:25.000
より多くのレジスタを使用すると、シェーダーが実行されている最大占有率を簡単に制限できます。

00:12:25.000 --> 00:12:29.000
制御構造体を渡す単純なカーネルを考えてみましょう。

00:12:29.000 --> 00:12:33.000
構造体内のフラグを使用して、何をするかを制御します。

00:12:33.000 --> 00:12:38.000
ここには2つの機能があります。入力がHDRの場合とトーンマッピングが有効になっている場合です。

00:12:38.000 --> 00:12:40.000
みんな良さそうだよね？

00:12:40.000 --> 00:12:44.000
さて、これがGPUで起こることです。

00:12:44.000 --> 00:12:54.000
コンパイル時には何も推測できないため、HDRと非HDRの両方のパスを取り、フラグに基づいて組み合わせることができると仮定する必要があります。

00:12:54.000 --> 00:12:56.000
トーンマッピングも同様です。

00:12:56.000 --> 00:13:02.000
私たちはそれを評価し、入力フラグに基づいてマスクインまたはマスクアウトします。

00:13:02.000 --> 00:13:04.000
ここでの問題はレジスタです。

00:13:04.000 --> 00:13:07.000
すべての制御フローパスにはライブレジスタが必要です。

00:13:07.000 --> 00:13:10.000
これは、ユーバーシェーダーがそれほど良くないところです。

00:13:10.000 --> 00:13:17.000
思い出すように、カーネルで使用されるレジスタは、シェーダーが実行できる最大占有率を定義します。

00:13:17.000 --> 00:13:22.000
これは、レジスタファイルがシェーダーコア上のすべてのsimdlanesによって共有されているために発生します。

00:13:22.000 --> 00:13:30.000
必要なものだけを実行できれば、simdgroupの並行性とGPUの使用率を高めることができます。

00:13:30.000 --> 00:13:32.000
これを修正する方法について話しましょう。

00:13:32.000 --> 00:13:37.000
Metal APIには仕事に適したツールがあり、「function_constants」と呼ばれています。

00:13:37.000 --> 00:13:43.000
両方の制御パラメータをfunction_constantsとして定義し、それに応じてコードを変更します。

00:13:43.000 --> 00:13:46.000
ここでは、修正されたカーネルコードを表示しています。

00:13:46.000 --> 00:13:52.000
パイプライン作成時にfunction_constant値を提供するために、ホスト側も更新する必要があります。

00:13:52.000 --> 00:13:59.000
レジスタ圧力を下げるもう1つの素晴らしい方法は、シェーダーで16ビットタイプを使用することです。

00:13:59.000 --> 00:14:03.000
Apple GPUは、ネイティブの16ビット型をサポートしています。

00:14:03.000 --> 00:14:10.000
したがって、より小さなデータ型を使用する場合、シェーダーはレジスタが少なくなり、占有率が増加します。

00:14:10.000 --> 00:14:16.000
ハーフタイプとショートタイプもより少ないエネルギーを必要とし、より高いピークレートを達成する可能性があります。

00:14:16.000 --> 00:14:24.000
したがって、タイプ変換は通常無料であるため、可能であればfloatとintの代わりにハーフタイプとショートタイプを使用してください。

00:14:24.000 --> 00:14:32.000
この例では、いくつかの計算のためにthreadgroupのthread_positionを使用するカーネルを考えてみましょう。

00:14:32.000 --> 00:14:40.000
私たちはunsigned intを使用していますが、Metalがサポートする最大スレッドグループサイズは、unsigned shortに簡単に収まります。

00:14:40.000 --> 00:14:46.000
ただし、threadgroup_position_in_gridは、より大きなデータ型が必要になる可能性があります。

00:14:46.000 --> 00:14:54.000
しかし、画像処理で使用しているグリッドサイズ（最大8Kまたは16K）では、符号なしショートでも十分です。

00:14:54.000 --> 00:15:02.000
代わりに16ビット型を使用すると、結果のコードは少数のレジスタを使用し、占有率が増加する可能性があります。

00:15:02.000 --> 00:15:07.000
さて、レジスタの詳細をすべて表示できる場所をお見せしましょう。

00:15:07.000 --> 00:15:15.000
Xcode13のGPUフレームデバッガには、レンダリング、タイル、およびコンピューティングPSO用の高度なパイプライン状態オブジェクトビューが追加されました。

00:15:15.000 --> 00:15:22.000
詳細なパイプライン統計（レジスタの使用状況）を検査し、すべてのシェーダーを微調整できます。

00:15:22.000 --> 00:15:28.000
レジスタの懸念をカバーして、テクスチャフォーマットについて話しましょう。

00:15:28.000 --> 00:15:33.000
まず、ピクセルフォーマットによってサンプリングレートが異なる可能性があることに注意してください。

00:15:33.000 --> 00:15:40.000
ハードウェアの生成とチャネルの数によっては、より広い浮動小数点タイプにより、ポイントサンプリングレートが低下する可能性があります。

00:15:40.000 --> 00:15:49.000
特にRGBA32Fなどの浮動小数点形式は、フィルタリングされた値をサンプリングする場合、FP16バリアントよりも遅くなります。

00:15:49.000 --> 00:15:53.000
小規模なタイプは、メモリストレージ、帯域幅、キャッシュフットプリントも削減します。

00:15:53.000 --> 00:15:59.000
したがって、繰り返しますが、可能な限り最小のタイプを使用することをお勧めしますが、この場合は、テクスチャストレージに使用します。

00:15:59.000 --> 00:16:12.000
これは実際には、画像処理における3D LUTの一般的なケースでした。私たちが取り組んだほとんどのアプリケーションは、バイリニアフィルタリングが有効になっている3D LUTアプリケーションフェーズにfloat RGBAを使用していました。

00:16:12.000 --> 00:16:17.000
アプリが代わりに半分を使用でき、精度で十分であるかどうかを検討してください。

00:16:17.000 --> 00:16:22.000
その場合は、すぐにFP16に切り替えてピークサンプリングレートを取得します。

00:16:22.000 --> 00:16:39.000
半分の精度が十分でない場合、固定小数点符号なしショートが大きな均一な値範囲を提供することがわかったので、LUTを単位スケールでエンコードし、シェーダーにLUT範囲を提供することは、ピークサンプリングレートと十分な数値精度の両方を得るための素晴らしい方法でした。

00:16:39.000 --> 00:16:48.000
さて、Apple GPUアーキテクチャを活用して、画像処理パイプラインをできるだけ効率的に実行する方法について説明しました。

00:16:48.000 --> 00:16:50.000
すぐに適用するには、ハーシュに会ってください!

00:16:50.000 --> 00:16:52.000
厳しいパティル:ありがとう、ユージーン。

00:16:52.000 --> 00:16:59.000
それでは、これまでに学んだすべてのベストプラクティスに基づいて、Appleシリコンの画像処理パイプラインを再設計してみましょう。

00:16:59.000 --> 00:17:05.000
具体的には、Apple GPU用のビデオ処理パイプラインの画像処理フェーズを調整します。

00:17:05.000 --> 00:17:10.000
リアルタイムの画像処理は、非常にGPUコンピューティングとメモリ帯域幅集約的です。

00:17:10.000 --> 00:17:16.000
まず、それが通常どのように設計されているかを理解し、次にAppleシリコン用に最適化する方法を理解します。

00:17:16.000 --> 00:17:22.000
このセクションでは、ビデオ編集ワークフローの詳細については説明しませんので、2年前の講演を参照してください。

00:17:22.000 --> 00:17:27.000
画像処理の計算部分をレンダリングパスに移行することだけに焦点を当てます。

00:17:27.000 --> 00:17:33.000
始める前に、典型的なビデオ処理パイプラインで画像処理フェーズがどこにあるかをすばやく見てみましょう。

00:17:33.000 --> 00:17:37.000
ProResでエンコードされた入力ファイルを例に挙げます。

00:17:37.000 --> 00:17:41.000
まず、ディスクまたは外部ストレージからProResエンコードされたフレームを読みました。

00:17:41.000 --> 00:17:50.000
次に、CPU上のフレームをデコードし、画像処理フェーズはGPU上のこのデコードされたフレームで実行され、最終的な出力フレームをレンダリングします。

00:17:50.000 --> 00:17:53.000
最後に、この出力フレームを表示します。

00:17:53.000 --> 00:17:57.000
さらに、配信のために最終的なレンダリングされたフレームをエンコードすることもできます。

00:17:57.000 --> 00:18:02.000
次に、画像処理パイプラインを構成するものを見てみましょう。

00:18:02.000 --> 00:18:09.000
画像処理は、最初にアルファのソース画像RGBの異なるチャンネルを別々のバッファに解凍することから始まります。

00:18:09.000 --> 00:18:15.000
これらの各チャネルは、画像処理パイプラインで、一緒にまたは別々に処理します。

00:18:15.000 --> 00:18:21.000
次に、目的の色管理環境で動作する色空間変換があるかもしれません。

00:18:21.000 --> 00:18:31.000
次に、3D LUTを適用し、色補正を行い、空間的・時間的ノイズリダクション、畳み込み、ぼかし、その他の効果を適用します。

00:18:31.000 --> 00:18:36.000
そして最後に、最終出力のために個別に処理されたチャネルを一緒にパックします。

00:18:36.000 --> 00:18:39.000
これらの選択されたステップの共通点は何ですか?

00:18:39.000 --> 00:18:43.000
それらはすべてポイントフィルタであり、ピクセル間の依存関係のない単一のピクセルでのみ動作します。

00:18:43.000 --> 00:18:47.000
これらは、フラグメントシェーダーの実装によくマップされます。

00:18:47.000 --> 00:18:54.000
空間および畳み込みスタイルの操作には、大きな半径のピクセルへのアクセスが必要であり、読み取り/書き込みアクセスパターンも散在しています。

00:18:54.000 --> 00:18:57.000
これらはコンピューティングカーネルに適しています。 

00:18:57.000 --> 00:18:58.000
この知識は後で使います。

00:18:58.000 --> 00:19:02.000
とりあえず、これらの操作がどのように実行されるかを見てみましょう。

00:19:02.000 --> 00:19:06.000
アプリケーションは、画像に適用される効果の連鎖をフィルターグラフとして表します。

00:19:06.000 --> 00:19:12.000
すべてのフィルタは独自のカーネルであり、前段階からの入力を処理し、次の段階の出力を生成します。

00:19:12.000 --> 00:19:20.000
ここのすべての矢印は、あるステージの出力との間で書き込まれ、次のステージの入力として読み込まれるバッファを意味します。

00:19:20.000 --> 00:19:26.000
メモリは限られているため、アプリケーションは通常、トポロジカルソートを行うことでグラフを線形化します。

00:19:26.000 --> 00:19:33.000
これは、競争条件を避けながら、中間リソースの総数をできるだけ低く保つために行われます。

00:19:33.000 --> 00:19:41.000
この例のこの単純なフィルタグラフは、競合条件なしで動作し、最終的な出力を生成するには、2つの中間バッファが必要です。

00:19:41.000 --> 00:19:46.000
ここでの線形化されたグラフは、GPUコマンドバッファエンコーディングも大まかに表しています。

00:19:46.000 --> 00:19:52.000
このフィルタグラフが非常にデバイスメモリ帯域幅集約的である理由を詳しく見てみましょう。

00:19:52.000 --> 00:20:01.000
すべてのフィルタ操作は、デバイスメモリからレジスタに画像全体をロードし、結果をデバイスメモリに書き戻す必要があります。

00:20:01.000 --> 00:20:03.000
そして、それはかなりのメモリトラフィックです。

00:20:03.000 --> 00:20:11.000
画像処理グラフの例に基づいて、4Kフレームの画像処理のメモリフットプリントを推定しましょう。

00:20:11.000 --> 00:20:25.000
4Kデコードされたフレーム自体は、浮動小数点16精度には67メガバイトのメモリ、浮動小数点32精度には135メガバイトのメモリが必要で、プロのワークフローには浮動小数点32精度が絶対に必要です。

00:20:25.000 --> 00:20:36.000
この画像処理グラフを介して浮動小数点32精度で1つの4Kフレームを処理するために、デバイスメモリへの2ギガバイト以上の読み取り/書き込みトラフィックについて話しています。

00:20:36.000 --> 00:20:43.000
また、中間出力を保持するバッファへの書き込みは、キャッシュ階層をスラッシュし、チップ上の他のブロックにも影響を与えます。

00:20:43.000 --> 00:20:48.000
通常のコンピューティングカーネルは、暗黙的にオンチップタイルメモリの恩恵を受けません。

00:20:48.000 --> 00:20:54.000
カーネルは、オンチップタイルメモリによってバックアップされるスレッドグループスコープのメモリを明示的に割り当てることができます。

00:20:54.000 --> 00:21:00.000
ただし、そのタイルメモリは、コンピューティングエンコーダ内のディスパッチ間で永続的ではありません。

00:21:00.000 --> 00:21:06.000
対照的に、タイルメモリは実際には1つのレンダリングコマンドエンコーダ内のドローパス全体で永続的です。

00:21:06.000 --> 00:21:12.000
タイルメモリを活用するために、この代表的な画像処理パイプラインを再設計する方法を見てみましょう。

00:21:12.000 --> 00:21:15.000
私たちは3つのステップでこれに対処します。

00:21:15.000 --> 00:21:21.000
まず、計算パスをレンダリングパスに変更し、すべての中間出力バッファをテクスチャに変更します。

00:21:21.000 --> 00:21:34.000
次に、1つのレンダリングコマンドエンコーダ内のフラグメントシェーダー呼び出しとして、ピクセル間の依存関係のないピクセルごとの操作をエンコードし、すべての中間結果を考慮し、適切なロード/ストアアクションを設定します。

00:21:34.000 --> 00:21:40.000
そして最後に、単なるポイントフィルターよりも複雑な状況で何をするかについて話し合います。

00:21:40.000 --> 00:21:45.000
最初のステップは、個別のMTLRenderCommandEncoderを使用して、適格なシェーダーをエンコードすることです。

00:21:45.000 --> 00:21:59.000
このフィルターグラフでは、アンパック、色空間変換、LUT、および色補正フィルターはすべてピクセルごとのポイントフィルターであり、フラグメントシェーダーに変換し、1つのレンダリングコマンドエンコーダを使用してエンコードできます。

00:21:59.000 --> 00:22:11.000
同様に、この画像処理パイプラインの終わりに向かっているミキサーとパックシェーダーは、フラグメントシェーダーに変換し、別のMTLRenderCommandEncoderを使用してエンコードすることもできます。

00:22:11.000 --> 00:22:15.000
その後、それぞれのレンダリングパス内でこれらのシェーダーを呼び出すことができます。

00:22:15.000 --> 00:22:22.000
レンダリングパスを作成すると、そのレンダリングパスのカラーアタッチメントに添付されているすべてのリソースが暗黙的にタイル化されます。

00:22:22.000 --> 00:22:29.000
フラグメントシェーダーは、タイル内のフラグメントの位置に関連付けられた画像ブロックデータのみを更新できます。

00:22:29.000 --> 00:22:35.000
同じレンダリングパスの次のシェーダーは、タイルメモリから直接前のシェーダーの出力を拾うことができます。

00:22:35.000 --> 00:22:41.000
次のセクションでは、これらのフィルタにマップするフラグメントシェーダーを構造化する方法を見ていきます。

00:22:41.000 --> 00:22:50.000
また、これらのフラグメントシェーダー内から基礎となるタイルメモリへのアクセスを可能にするために定義し、使用する必要がある構造も見ていきます。

00:22:50.000 --> 00:23:02.000
最後に、1つのフラグメントシェーダーによってタイルメモリで生成された出力が、同じレンダリングコマンドエンコーダ内の次のフラグメントシェーダーによってタイルメモリから直接消費される方法を見ていきます。

00:23:02.000 --> 00:23:05.000
これはあなたのコードでしなければならないことです。

00:23:05.000 --> 00:23:11.000
ここでは、レンダリングパス記述子のカラーアタッチメント0に添付されたテクスチャとして出力画像を添付しました。

00:23:11.000 --> 00:23:17.000
レンダリングパス記述子のカラーアタッチメント1に中間結果を保持するテクスチャを添付しました。

00:23:17.000 --> 00:23:21.000
これらは両方ともあなたのために暗黙的にタイル張りになります。

00:23:21.000 --> 00:23:26.000
先ほどの講演で説明したように、適切な負荷/店舗のプロパティを設定してください。

00:23:26.000 --> 00:23:30.000
次に、フラグメントシェーダーでこれらのテクスチャにアクセスするための構造を設定します。

00:23:30.000 --> 00:23:35.000
今後の例では、フラグメントシェーダー内でこの構造を使用する方法を紹介します。

00:23:35.000 --> 00:23:43.000
先ほど定義した構造を使用して、強調表示されているように、フラグメントシェーダー内の出力と中間テクスチャにアクセスするだけです。

00:23:43.000 --> 00:23:49.000
これらのテクスチャへの書き込みは、フラグメントに対応する適切なタイルメモリ位置に行われます。

00:23:49.000 --> 00:23:57.000
アンパックシェーダーによって生成された出力は、以前に定義したのと同じ構造を使用して、色空間変換シェーダーによる入力として消費されます。

00:23:57.000 --> 00:24:06.000
このフラグメントシェーダーは、独自の処理を行い、出力と中間テクスチャを更新し、対応するタイルメモリの位置を再度更新できます。

00:24:06.000 --> 00:24:12.000
同じレンダリングエンコーダパス内の他のすべてのフラグメントシェーダーに対して同じ手順を続行します。

00:24:12.000 --> 00:24:17.000
次に、これらの変更で、この一連の操作がどのように見えるかを視覚化しましょう。

00:24:17.000 --> 00:24:30.000
ご覧のとおり、開梱、色空間変換、3D LUTの適用、および色補正ステップがすべてタイルメモリで実行され、その間にデバイスメモリが通過することはありません。

00:24:30.000 --> 00:24:36.000
レンダリングパスの最後に、メモリレスではないレンダリングターゲットがデバイスメモリにフラッシュされます。

00:24:36.000 --> 00:24:39.000
その後、次のクラスのフィルタを実行できます。

00:24:39.000 --> 00:24:43.000
スキャターギャザーアクセスパターンを持つフィルタについて少し話しましょう。

00:24:43.000 --> 00:24:49.000
このようなフィルタを表すカーネルは、デバイスメモリ内のデータを直接操作できます。

00:24:49.000 --> 00:24:54.000
畳み込みフィルタは、コンピューティングカーネルのタイルベースの操作に非常に適しています。

00:24:54.000 --> 00:25:00.000
ここでは、スレッドグループスコープのメモリを宣言することで、タイルメモリを使用する意図を表現できます。

00:25:00.000 --> 00:25:11.000
次に、フィルター半径に応じて、必要なすべてのハローピクセルとともにピクセルのブロックをタイルメモリに取り込み、タイルメモリで直接畳み込み操作を実行します。

00:25:11.000 --> 00:25:17.000
タイルメモリは、コンピューティングエンコーダ内のコンピューティングディスパッチ全体では永続的ではないことを覚えておいてください。

00:25:17.000 --> 00:25:23.000
したがって、Filter1を実行した後、タイルメモリの内容をデバイスメモリに明示的にフラッシュする必要があります。

00:25:23.000 --> 00:25:27.000
そうすれば、Filter2はFilter1の出力を消費することができます。

00:25:27.000 --> 00:25:30.000
では、これらすべての変更を加えたら、どこに着陸しますか?

00:25:30.000 --> 00:25:39.000
再構築された画像処理グラフの例を使用して、浮動小数点32の精度で1つの4Kフレームを処理するために、私たちが今持っているものは次のとおりです。

00:25:39.000 --> 00:25:48.000
帯域幅は2.16ギガバイトから810メガバイト相当のロードとストアに低下し、デバイスメモリへのメモリトラフィックが62%減少します。

00:25:48.000 --> 00:25:54.000
フレームあたり270メガバイトのメモリを節約する2つの中間デバイスバッファは必要ありません。

00:25:54.000 --> 00:26:02.000
そして最後に、キャッシュスラッシングを減らしました。それは、そのレンダリングパス内のすべてのフラグメントシェーダーがタイルメモリ上で直接動作しているためです。

00:26:02.000 --> 00:26:07.000
Appleシリコンの主な特徴の1つは、ユニファイドメモリアーキテクチャです。

00:26:07.000 --> 00:26:15.000
Appleシリコン上の異なるブロック間の相互作用のために、このユニファイドメモリアーキテクチャを活用する方法の例を見てみましょう。

00:26:15.000 --> 00:26:21.000
GPUによってレンダリングされた最終的なビデオフレームのHEVCエンコーディングをケーススタディとして取ります。

00:26:21.000 --> 00:26:27.000
このエンコーディングは、Appleシリコン上の専用のハードウェアメディアエンジンを使用して行われます。

00:26:27.000 --> 00:26:33.000
GPUによってレンダリングされた最終的な出力フレームは、余分なメモリコピーなしで当社のメディアエンジンによって直接消費することができます。

00:26:33.000 --> 00:26:43.000
次のセクションでは、GPUによって生成された最終出力フレームのHEVCエンコーディングのパイプラインを最も効率的な方法で設定する方法の例を説明します。

00:26:43.000 --> 00:26:51.000
そのために、まずCoreVideo APIを活用して、IOSurfacesに裏打ちされたピクセルバッファのプールを作成します。

00:26:51.000 --> 00:26:59.000
次に、Metal APIを使用して、作成したばかりのプールからIOSurfacesに裏打ちされたMetalテクスチャに最終的なフレームをレンダリングします。

00:26:59.000 --> 00:27:09.000
そして最後に、これらのピクセルバッファをメディアエンジンに直接ディスパッチして、GPUによって生成された出力フレームの追加コピーなしでエンコードし、ユニファイドメモリアーキテクチャを活用します。

00:27:09.000 --> 00:27:15.000
この方法を段階的に実行し、このフローを有効にするために必要なすべての構造をカバーしましょう。

00:27:15.000 --> 00:27:21.000
まず、IOSurfaceに裏打ちされたCVPixelBufferPoolを目的のピクセル形式で作成します。

00:27:21.000 --> 00:27:28.000
ここでは、HEVCエンコードにバイプラナークロマサブサンプリングピクセルフォーマットを使用します。

00:27:28.000 --> 00:27:32.000
今、あなたはこのCVPixelBufferPoolからCVPixelBufferを取得します。

00:27:32.000 --> 00:27:39.000
このCVPixelBufferを正しい平面インデックスでMetalTextureCacheに渡して、CVMetalTextureReferenceを取得します。

00:27:39.000 --> 00:27:45.000
二平面ピクセル形式を使用しているため、二平面ピクセルバッファの両方の平面に対してこのステップを実行する必要があります。

00:27:45.000 --> 00:27:50.000
次に、CVMetalTextureReferenceオブジェクトから基礎となるMetalテクスチャを取得します。

00:27:50.000 --> 00:27:53.000
ルマ面とクロマ面の両方でこのステップを実行します。

00:27:53.000 --> 00:28:00.000
これらのメタルテクスチャは、CVPixelBuffer平面もバックアップしている同じIOSurfacesによって裏打ちされていることを忘れないでください。

00:28:00.000 --> 00:28:06.000
Metal APIを使用して、ルミナンス面とクロマ平面に対応するテクスチャにレンダリングします。

00:28:06.000 --> 00:28:10.000
これにより、これらのメタルテクスチャもバックアップするIOSurfaceが更新されます。

00:28:10.000 --> 00:28:18.000
画像処理パイプライン内のシェーダーパスとして、GPU自体のクロマプレーンでクロマサブサンプリングステップを行うことを強くお勧めします。

00:28:18.000 --> 00:28:29.000
注意すべき重要なことは、CVPixelBufferと、レンダリングしたばかりのMetalテクスチャの両方が、システムメモリ内の同じ基礎となるIOSurfaceコピーによって裏付けられていることです。

00:28:29.000 --> 00:28:33.000
このCVPixelBufferをメディアエンジンに直接送信してエンコードできるようになりました。

00:28:33.000 --> 00:28:41.000
ご覧のとおり、ユニファイドメモリアーキテクチャにより、メモリコピーなしでGPUとメディアエンジンブロック間でデータをシームレスに移動できます。

00:28:41.000 --> 00:28:48.000
そして最後に、すべてのフレームの後にCVPixelBufferとCVMetalTextureリファレンスをリリースすることを忘れないでください。

00:28:48.000 --> 00:28:53.000
CVPixelBufferをリリースすることで、このバッファを将来のフレームにリサイクルできます。

00:28:53.000 --> 00:29:16.000
まとめに、もう一度次のことを行うことをお勧めします。ユニファイドメモリアーキテクチャを活用し、該当する場合は計算の代わりにMTLRenderCommandEncoderを使用し、単一のレンダリングコマンドエンコーダ内ですべての適格なレンダリングパスをマージし、適切なロード/ストアアクションを設定し、一時的なリソースにメモリレスを使用し、該当する場合はタイルシェーディングを活用し、ゼロコピーのために他のAPIとバッファプールを使用します。

00:29:16.000 --> 00:29:19.000
本日、このセッションにご参加いただき、ありがとうございます。

00:29:19.000 --> 00:29:22.000
WWDC 2021の残りの部分をお楽しみください!

00:29:22.000 --> 23:59:59.000
♪

