WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:14.000
Rokhini Prabhu：こんにちは、「Swift Concurrency Behind the Scenes」へようこそ。

00:00:14.000 --> 00:00:18.000
私の名前はロキニで、ダーウィンランタイムチームで働いています。

00:00:18.000 --> 00:00:28.000
今日、同僚のVarunと私は、Swiftの並行性に関する根本的なニュアンスのいくつかについてお話しできることを非常に楽しみにしています。

00:00:28.000 --> 00:00:35.000
これは、Swiftの並行性に関する以前の話し合いのいくつかに基づいて構築された高度な講演です。

00:00:35.000 --> 00:00:46.000
非同期/待機、構造化並行性、および俳優の概念に慣れていない場合は、これらの他のトークを最初に見ることをお勧めします。

00:00:46.000 --> 00:00:56.000
Swiftの並行性に関する前回の講演では、今年Swiftネイティブで利用可能なさまざまな言語機能と、それらの使用方法について学びました。

00:00:56.000 --> 00:01:07.000
この講演では、これらのプリミティブが言語の安全性だけでなく、パフォーマンスと効率性のためにも、なぜそのように設計されているのかを理解するために、より深く掘り下げます。

00:01:07.000 --> 00:01:25.000
独自のアプリでSwift並行性を実験して採用する際に、この講演が、Swift並行性について推論する方法と、Grand Central Dispatchなどの既存のスレッドライブラリとどのように連携するかについて、より良いメンタルモデルが提供できることを願っています。

00:01:25.000 --> 00:01:28.000
今日はいくつかのことを話し合うつもりです。

00:01:28.000 --> 00:01:36.000
まず、Swift並行性の背後にあるスレッドモデルについて話し、Grand Central Dispatchと対比します。

00:01:36.000 --> 00:01:47.000
並行性言語機能を活用してSwiftの新しいスレッドプールを構築し、より良いパフォーマンスと効率を達成した方法について説明します。

00:01:47.000 --> 00:01:56.000
最後に、このセクションでは、コードをSwift並行性を使用する際に留意すべき考慮事項について説明します。

00:01:56.000 --> 00:02:02.000
その後、Varunはアクターを介したSwift並行性での同期について話します。

00:02:02.000 --> 00:02:17.000
俳優が内部でどのように機能するか、シリアルディスパッチキューなど、あなたがすでに慣れ親しんでいるかもしれない既存の同期プリミティブとどのように比較するか、そして最後に、俳優とコードを書くときに心に留めておくべきいくつかのことについて話します。

00:02:17.000 --> 00:02:22.000
今日はカバーすべきことがたくさんあるので、すぐに飛び込みましょう。

00:02:22.000 --> 00:02:33.000
今日のスレッドモデルに関する議論では、Grand Central Dispatchのような今日利用可能な技術で書かれたサンプルアプリを見ることから始めます。

00:02:33.000 --> 00:02:39.000
次に、Swift並行性で書き換えると、同じアプリケーションがどのように機能するかを見ていきます。

00:02:39.000 --> 00:02:43.000
自分のニュースフィードリーダーアプリを書きたいとします。

00:02:43.000 --> 00:02:48.000
私のアプリケーションの高レベルのコンポーネントが何であるかについて話しましょう。

00:02:48.000 --> 00:02:53.000
私のアプリには、ユーザーインターフェイスを駆動するメインスレッドがあります。

00:02:53.000 --> 00:03:07.000
ユーザーが購読しているニュースフィードを追跡するデータベースと、最後に、フィードから最新のコンテンツを取得するためのネットワークロジックを処理するサブシステムがあります。

00:03:07.000 --> 00:03:12.000
グランドセントラルディスパッチキューでこのアプリをどのように構成するかを考えてみましょう。

00:03:12.000 --> 00:03:16.000
ユーザーが最新のニュースを見るように頼んだとしましょう。

00:03:16.000 --> 00:03:21.000
メインスレッドでは、ユーザーイベントのジェスチャーを処理します。

00:03:21.000 --> 00:03:28.000
ここから、データベース操作を処理するシリアルキューにリクエストを非同期にディスパッチします。

00:03:28.000 --> 00:03:30.000
この理由は2つあります。

00:03:30.000 --> 00:03:43.000
まず、作業を別のキューにディスパッチすることで、潜在的に大量の作業が起こるのを待っている間でも、メインスレッドがユーザーの入力に応答し続けることができるようにします。

00:03:43.000 --> 00:03:51.000
第二に、シリアルキューは相互排除を保証するため、データベースへのアクセスは保護されています。

00:03:51.000 --> 00:04:06.000
データベースキューでは、ユーザーが購読しているニュースフィードを反復し、それぞれについて、URLSessionにネットワーク要求をスケジュールして、そのフィードの内容をダウンロードします。

00:04:06.000 --> 00:04:16.000
ネットワーク要求の結果が入ると、URLSessionコールバックは、同時キューであるデリゲートキューで呼び出されます。

00:04:16.000 --> 00:04:27.000
各結果の完了ハンドラでは、これらの各フィードからの最新のリクエストでデータベースを同期的に更新し、将来の使用のためにキャッシュします。

00:04:27.000 --> 00:04:33.000
そして最後に、メインスレッドをウェイクアップしてUIを更新します。

00:04:33.000 --> 00:04:38.000
これは、そのようなアプリケーションを構造化するための完全に合理的な方法のように思えます。

00:04:38.000 --> 00:04:42.000
リクエストの作業中にメインスレッドをブロックしないようにしました。

00:04:42.000 --> 00:04:49.000
また、ネットワーク要求を同時に処理することで、プログラムに固有の並列性を利用しました。

00:04:49.000 --> 00:04:58.000
ネットワーク要求の結果をどのように処理するかを示すコードスニペットを詳しく見てみましょう。

00:04:58.000 --> 00:05:04.000
まず、ニュースフィードからダウンロードを実行するためのURLSessionを作成しました。

00:05:04.000 --> 00:05:10.000
ご覧のとおり、このURLSessionのデリゲートキューを同時キューに設定しました。

00:05:10.000 --> 00:05:20.000
次に、更新する必要があるすべてのニュースフィードを反復し、それぞれについて、URLSessionでデータタスクをスケジュールします。

00:05:20.000 --> 00:05:31.000
デリゲートキューで呼び出されるデータタスクの完了ハンドラでは、ダウンロードの結果をデシリアライズし、記事にフォーマットします。

00:05:31.000 --> 00:05:38.000
次に、フィードの結果を更新する前に、データベースキューに対して同期をディスパッチします。

00:05:38.000 --> 00:05:49.000
ここでは、かなり簡単なことをするために直線的なコードを書いたことがわかりますが、このコードにはいくつかの隠されたパフォーマンスの落とし穴があります。

00:05:49.000 --> 00:05:58.000
これらのパフォーマンスの問題について詳しく理解するには、まず、GCDキューの作業を処理するためにスレッドがどのように取り上げられるかを掘り下げる必要があります。

00:05:58.000 --> 00:06:08.000
グランドセントラルディスパッチでは、作業がキューにキューに入れられると、システムはその作業項目にサービスを提供するスレッドを呼び出します。

00:06:08.000 --> 00:06:19.000
同時キューは一度に複数の作業項目を処理できるため、すべてのCPUコアを飽和させるまで、システムはいくつかのスレッドを呼び出します。

00:06:19.000 --> 00:06:33.000
ただし、ここで最初のCPUコアに見られるように、スレッドがブロックされ、同時キューでより多くの作業がある場合、GCDは残りの作業項目を消耗するためにより多くのスレッドを呼び出します。

00:06:33.000 --> 00:06:36.000
この理由は2つあります。

00:06:36.000 --> 00:06:47.000
まず、プロセスに別のスレッドを与えることで、各コアがいつでも作業を実行するスレッドを持ち続けることを保証することができます。

00:06:47.000 --> 00:06:53.000
これにより、アプリケーションに良好で継続的なレベルの並行性が得られます。

00:06:53.000 --> 00:07:00.000
第二に、ブロックされたスレッドは、さらなる進歩を遂げる前に、セマフォのようなリソースを待っている可能性があります。

00:07:00.000 --> 00:07:10.000
キューの作業を続けるために持ち込まれた新しいスレッドは、最初のスレッドで待機されているリソースのブロックを解除するのに役立つかもしれません。

00:07:10.000 --> 00:07:22.000
GCDのスレッドブアップについてもう少し理解したので、戻って、ニュースアプリからコードのCPU実行を見てみましょう。

00:07:22.000 --> 00:07:30.000
Apple Watchのような2コアデバイスでは、GCDは最初に2つのスレッドを表示してフィードの更新結果を処理します。

00:07:30.000 --> 00:07:39.000
スレッドがデータベースキューへのアクセスをブロックすると、ネットワークキューの作業を続行するために、より多くのスレッドが作成されます。

00:07:39.000 --> 00:07:51.000
CPUは、さまざまなスレッド間の白い垂直線で示されるように、ネットワーク結果を処理する異なるスレッド間でコンテキストを切り替える必要があります。

00:07:51.000 --> 00:07:58.000
これは、私たちのニュースアプリケーションでは、非常に多数のスレッドで簡単に終わる可能性があることを意味します。

00:07:58.000 --> 00:08:10.000
ユーザーが更新する必要がある100のフィードを持っている場合、ネットワーク要求が完了すると、これらのURLデータタスクのそれぞれが同時キューに完了ブロックを持つことになります。

00:08:10.000 --> 00:08:20.000
GCDは、各コールバックがデータベースキューでブロックされると、より多くのスレッドを表示し、アプリケーションに多くのスレッドを持つことになります。

00:08:20.000 --> 00:08:26.000
今、あなたは尋ねるかもしれません、私たちのアプリケーションに多くのスレッドを持つことの何がそんなに悪いのですか?

00:08:26.000 --> 00:08:34.000
アプリケーションに多くのスレッドがあるということは、システムがCPUコアよりも多くのスレッドで過大コミットされていることを意味します。

00:08:34.000 --> 00:08:37.000
6つのCPUコアを搭載したiPhoneを考えてみましょう。

00:08:37.000 --> 00:08:48.000
ニュースアプリケーションに処理が必要な100のフィードアップデートがある場合、これはコアの16倍のスレッドでiPhoneを過剰にコミットしたことを意味します。

00:08:48.000 --> 00:08:52.000
これは私たちがスレッド爆発と呼ぶ現象です。

00:08:52.000 --> 00:09:03.000
以前のWWDCの講演のいくつかは、アプリケーションのデッドロックの可能性など、これに関連するリスクについてさらに詳しく説明しました。

00:09:03.000 --> 00:09:13.000
スレッドの爆発には、すぐには明らかではないかもしれないメモリとスケジューリングのオーバーヘッドも付属しているので、これについてさらに調べてみましょう。

00:09:13.000 --> 00:09:23.000
ニュースアプリケーションを振り返ってみると、ブロックされた各スレッドは、再び実行されるのを待っている間、貴重なメモリとリソースを保持しています。

00:09:23.000 --> 00:09:29.000
ブロックされた各スレッドには、スレッドを追跡するためのスタックと関連するカーネルデータ構造があります。

00:09:29.000 --> 00:09:35.000
これらのスレッドのいくつかは、実行されている他のスレッドが必要とするかもしれないロックを保持しているかもしれません。

00:09:35.000 --> 00:09:43.000
これは、進歩していないスレッドのために保持する多数のリソースとメモリです。

00:09:43.000 --> 00:09:48.000
また、スレッドの爆発の結果として、より大きなスケジューリングオーバーヘッドがあります。

00:09:48.000 --> 00:10:00.000
新しいスレッドが起動されると、CPUは新しいスレッドの実行を開始するために古いスレッドから切り替えるために、完全なスレッドコンテキストスイッチを実行する必要があります。

00:10:00.000 --> 00:10:10.000
ブロックされたスレッドが再び実行可能になると、スケジューラはすべて前進できるように、CPU上のスレッドをタイムシェアする必要があります。

00:10:10.000 --> 00:10:17.000
さて、それが数回起こる場合、スレッドのタイムシェアリングは問題ありません - それは並行性の力です。

00:10:17.000 --> 00:10:28.000
しかし、スレッドの爆発がある場合、コアが限られているデバイスで何百ものスレッドをタイムシェアしなければならないと、過剰なコンテキスト切り替えにつながる可能性があります。

00:10:28.000 --> 00:10:38.000
これらのスレッドのスケジューリングレイテンシーは、有用な作業の量を上回るため、CPUの実行効率も低下します。

00:10:38.000 --> 00:10:52.000
これまで見てきたように、GCDキューでアプリケーションを書くときのスレッド衛生に関するこれらのニュアンスのいくつかを見逃すのは簡単です。その結果、パフォーマンスが低下し、オーバーヘッドが大きくなります。

00:10:52.000 --> 00:10:59.000
この経験に基づいて、Swiftは言語への並行性を設計する際に異なるアプローチを取りました。

00:10:59.000 --> 00:11:11.000
アプリが制御され、構造化され、安全な並行性を享受できるように、パフォーマンスと効率性を念頭に置いてSwift並行性を構築しました。

00:11:11.000 --> 00:11:24.000
Swiftでは、アプリの実行モデルを、多くのスレッドとコンテキストスイッチを持つ次のモデルからこれに変更したいと考えています。

00:11:24.000 --> 00:11:31.000
ここでは、2コアシステムで実行されているスレッドが2つしかなく、スレッドコンテキストスイッチがないことがわかります。

00:11:31.000 --> 00:11:41.000
ブロックされたスレッドはすべて消え、代わりに作業の再開を追跡するための継続として知られる軽量オブジェクトがあります。

00:11:41.000 --> 00:11:49.000
スレッドがSwift並行性の下で作業を実行すると、フルスレッドコンテキストスイッチを実行するのではなく、継続を切り替えます。

00:11:49.000 --> 00:11:56.000
これは、代わりに関数呼び出しの費用のみを支払うことを意味します。

00:11:56.000 --> 00:12:10.000
したがって、Swiftの並行性に望むランタイムの動作は、CPUコアがあるのと同じくらい多くのスレッドのみを作成し、スレッドがブロックされたときに作業項目間を安価かつ効率的に切り替えることです。

00:12:10.000 --> 00:12:20.000
私たちは、あなたが推論しやすく、安全で制御された並行性を提供する直線コードを書くことができることを望んでいます。

00:12:20.000 --> 00:12:33.000
私たちが求めているこの動作を達成するために、オペレーティングシステムはスレッドがブロックしないランタイムコントラクトを必要とし、それは言語が私たちにそれを提供できる場合にのみ可能です。

00:12:33.000 --> 00:12:42.000
したがって、Swiftの並行性モデルとその周りのセマンティクスは、この目標を念頭に置いて設計されています。

00:12:42.000 --> 00:12:50.000
そのために、ランタイムとの契約を維持できるSwiftの2つの言語レベルの機能について掘り下げたいと思います。

00:12:50.000 --> 00:12:59.000
1つ目はawaitのセマンティクスから、2つ目はSwiftランタイムでのタスク依存関係の追跡から来ています。

00:12:59.000 --> 00:13:05.000
例のニュースアプリケーションの文脈で、これらの言語機能を考えてみましょう。

00:13:05.000 --> 00:13:11.000
これは、ニュースフィードの更新の結果を処理する、先ほどのコードスニペットです。

00:13:11.000 --> 00:13:18.000
代わりにSwift並行性プリミティブで書かれたとき、このロジックがどのように見えるか見てみましょう。

00:13:18.000 --> 00:13:23.000
まず、ヘルパー関数の非同期実装を作成することから始めます。

00:13:23.000 --> 00:13:35.000
次に、同時ディスパッチキューでネットワーク要求の結果を処理する代わりに、並行性を管理する代わりにタスクグループを使用しています。

00:13:35.000 --> 00:13:41.000
タスクグループでは、更新が必要なフィードごとに子タスクを作成します。

00:13:41.000 --> 00:13:47.000
各子タスクは、共有URLSessionを使用してフィードのURLからダウンロードを実行します。

00:13:47.000 --> 00:13:58.000
次に、ダウンロードの結果をデシリアライズし、記事にフォーマットし、最後に非同期関数を呼び出してデータベースを更新します。

00:13:58.000 --> 00:14:04.000
ここでは、非同期関数を呼び出すときに、awaitキーワードで注釈を付けます。

00:14:04.000 --> 00:14:11.000
「Swiftで非同期/待機を満たす」トークから、待機は非同期待機であることを学びました。

00:14:11.000 --> 00:14:17.000
つまり、非同期関数の結果を待っている間、現在のスレッドをブロックしません。

00:14:17.000 --> 00:14:25.000
代わりに、関数は一時停止され、スレッドは他のタスクを実行するために解放されます。

00:14:25.000 --> 00:14:26.000
これはどのように起こりますか?

00:14:26.000 --> 00:14:28.000
どうやって糸をあきらめるのですか?

00:14:28.000 --> 00:14:37.000
私の同僚のVarunは、これを可能にするために、Swiftランタイムでボンネットの下で何が行われているかに光を当てます。

00:14:37.000 --> 00:14:38.000
ヴァルン・ガンジー:ありがとう、ロキニ。

00:14:38.000 --> 00:14:46.000
非同期関数の実装方法に飛び込む前に、非非同期関数がどのように機能するかを簡単に復習しましょう。

00:14:46.000 --> 00:14:52.000
実行中のプログラムのすべてのスレッドには1つのスタックがあり、関数呼び出しの状態を格納するために使用します。

00:14:52.000 --> 00:14:55.000
とりあえず1つのスレッドに集中しましょう。

00:14:55.000 --> 00:15:00.000
スレッドが関数呼び出しを実行すると、新しいフレームがスタックにプッシュされます。

00:15:00.000 --> 00:15:09.000
この新しく作成されたスタックフレームは、関数によってローカル変数、リターンアドレス、および必要なその他の情報を格納するために使用できます。

00:15:09.000 --> 00:15:16.000
関数の実行が終了して戻ると、そのスタックフレームがポップされます。

00:15:16.000 --> 00:15:19.000
では、非同期関数を考えてみましょう。

00:15:19.000 --> 00:15:24.000
updateDatabase関数からフィードタイプのadd(_:)メソッドを呼び出すスレッドを想定します。

00:15:24.000 --> 00:15:29.000
この段階では、最新のスタックフレームはadd(_:)用になります。

00:15:29.000 --> 00:15:35.000
スタックフレームは、サスペンションポイント全体で利用可能である必要のないローカル変数を格納します。

00:15:35.000 --> 00:15:39.000
Add(_:)の本体には、awaitでマークされた1つのサスペンションポイントがあります。

00:15:39.000 --> 00:15:49.000
ローカル変数、idとarticleは、定義後すぐにforループの本体で使用され、その間にサスペンションポイントはありません。

00:15:49.000 --> 00:15:53.000
したがって、それらはスタックフレームに格納されます。

00:15:53.000 --> 00:16:00.000
さらに、ヒープには2つの非同期フレームがあり、1つはupdateDatabase用、もう1つはadd用です。

00:16:00.000 --> 00:16:06.000
非同期フレームは、サスペンションポイント間で利用できるようにする必要がある情報を保存します。

00:16:06.000 --> 00:16:13.000
newArticles引数は待機前に定義されていますが、待機後に利用可能である必要があることに注意してください。

00:16:13.000 --> 00:16:19.000
これは、追加用の非同期フレームが新しい記事を追跡することを意味します。

00:16:19.000 --> 00:16:22.000
スレッドが引き続き実行されると仮定します。

00:16:22.000 --> 00:16:30.000
保存関数の実行が開始されると、追加用のスタックフレームは保存用のスタックフレームに置き換えられます。

00:16:30.000 --> 00:16:42.000
新しいスタックフレームを追加する代わりに、将来必要とされる変数がすでに非同期フレームのリストに保存されているため、一番上のスタックフレームが置き換えられます。

00:16:42.000 --> 00:16:48.000
保存関数はまた、その使用のために非同期フレームを取得します。

00:16:48.000 --> 00:16:55.000
記事がデータベースに保存されている間は、スレッドがブロックされるのではなく、いくつかの有用な作業を行うことができれば良いでしょう。

00:16:55.000 --> 00:17:00.000
保存関数の実行が中断されているとします。

00:17:00.000 --> 00:17:08.000
そして、スレッドはブロックされるのではなく、他の有用な作業を行うために再利用されます。

00:17:08.000 --> 00:17:18.000
サスペンションポイント全体で保持されるすべての情報はヒープに保存されるため、後の段階で実行を継続するために使用できます。

00:17:18.000 --> 00:17:25.000
この非同期フレームのリストは、継続のランタイム表現です。

00:17:25.000 --> 00:17:32.000
しばらくすると、データベース要求が完了し、いくつかのスレッドが解放されたとします。

00:17:32.000 --> 00:17:38.000
これは以前と同じスレッドかもしれないし、別のスレッドかもしれない。

00:17:38.000 --> 00:17:42.000
保存関数がこのスレッドで実行を再開するとします。

00:17:42.000 --> 00:17:52.000
実行が終了し、いくつかのIDを返すと、保存用のスタックフレームは再び追加用のスタックフレームに置き換えられます。

00:17:52.000 --> 00:17:56.000
その後、スレッドはzipの実行を開始できます。

00:17:56.000 --> 00:18:03.000
2つの配列を圧縮することは非非同期操作であるため、新しいスタックフレームが作成されます。

00:18:03.000 --> 00:18:12.000
Swiftはオペレーティングシステムスタックを使用し続けているため、非同期と非同期の両方のSwiftコードは、CとObjective-Cを効率的に呼び出すことができます。

00:18:12.000 --> 00:18:18.000
さらに、CおよびObjective-Cコードは、非非非同期Swiftコードを効率的に呼び出し続けることができます。

00:18:18.000 --> 00:18:27.000
Zip機能が終了すると、スタックフレームがポップされ、実行が続行されます。

00:18:27.000 --> 00:18:37.000
これまでのところ、他の作業を行うためにスレッドのリソースを解放しながら、効率的なサスペンションと再開を確保するためにawaitがどのように設計されているかを説明しました。

00:18:37.000 --> 00:18:44.000
次に、Rokhiniは、タスク間の依存関係のランタイムの追跡である第二言語機能について説明します。

00:18:44.000 --> 00:18:46.000
ロヒニ:ありがとう、ヴァルン。

00:18:46.000 --> 00:18:55.000
先に説明したように、関数は待機時に継続に分割することができ、潜在的なサスペンションポイントとも呼ばれます。

00:18:55.000 --> 00:19:03.000
この場合、URLSessionデータタスクは非同期関数であり、その後の残りの作業は継続です。

00:19:03.000 --> 00:19:09.000
継続は、非同期関数が完了した後にのみ実行できます。

00:19:09.000 --> 00:19:14.000
これは、Swift並行性ランタイムによって追跡される依存関係です。

00:19:14.000 --> 00:19:26.000
同様に、タスクグループ内では、親タスクがいくつかの子タスクを作成することがあり、親タスクが続行する前に、それらの子タスクのそれぞれを完了する必要があります。

00:19:26.000 --> 00:19:38.000
これは、タスクグループのスコープによってコードで表現される依存関係であり、したがって、Swiftコンパイラとランタイムに明示的に知られています。

00:19:38.000 --> 00:19:46.000
Swiftでは、タスクは、継続タスクや子タスクなど、Swiftランタイムに知られている他のタスクのみを待つことができます。

00:19:46.000 --> 00:19:58.000
したがって、Swiftの並行性プリミティブで構造化されたコードは、タスク間の依存関係チェーンを明確に理解してランタイムを提供します。

00:19:58.000 --> 00:20:05.000
これまでのところ、Swiftの言語機能により、待機中にタスクを中断する方法を学びました。

00:20:05.000 --> 00:20:13.000
代わりに、実行スレッドはタスクの依存関係について推論し、代わりに別のタスクを拾うことができます。

00:20:13.000 --> 00:20:23.000
これは、Swift並行性で書かれたコードが、スレッドが常に前進できるランタイム契約を維持できることを意味します。

00:20:23.000 --> 00:20:31.000
このランタイム契約を利用して、Swift並行性の統合OSサポートを構築しました。

00:20:31.000 --> 00:20:39.000
これは、デフォルトの実行者としてSwift並行性をバックアップするための新しい共同スレッドプールの形式です。

00:20:39.000 --> 00:20:48.000
新しいスレッドプールは、CPUコアがあるのと同じくらい多くのスレッドしか生成しないため、システムをオーバーコミットしないようにします。

00:20:48.000 --> 00:20:58.000
ワークアイテムがブロックされたときにより多くのスレッドを生成するGCDの同時キューとは異なり、Swiftスレッドは常に前進することができます。

00:20:58.000 --> 00:21:05.000
したがって、デフォルトのランタイムは、生成されるスレッドの数を制御することについて賢明です。

00:21:05.000 --> 00:21:15.000
これにより、過度の並行性の既知の落とし穴を避けながら、アプリケーションに必要な並行性を与えることができます。

00:21:15.000 --> 00:21:33.000
以前のWWDCでは、グランドセントラルディスパッチとの並行性について、アプリケーションを異なるサブシステムに統合し、サブシステムごとに1つのシリアルディスパッチキューを維持して、アプリケーションの並行性を制御することをお勧めします。

00:21:33.000 --> 00:21:43.000
これは、スレッド爆発のリスクを冒すことなく、サブシステム内で1つより大きい並行性を得ることが困難であることを意味しました。

00:21:43.000 --> 00:21:59.000
Swiftでは、この言語はランタイムが活用した強力な不変量を与え、デフォルトのランタイムでより制御された並行性を透過的に提供することができます。

00:21:59.000 --> 00:22:12.000
Swift並行性のスレッドモデルについてもう少し理解したので、コードにこれらのエキサイティングな新機能を採用する際に留意すべきいくつかの考慮事項を見ていきます。

00:22:12.000 --> 00:22:20.000
心に留めておく必要がある最初の考慮事項は、同期コードを非同期コードに変換するときのパフォーマンスに関係しています。

00:22:20.000 --> 00:22:29.000
先ほど、Swiftランタイムにおける追加のメモリ割り当てやロジックなど、並行性に関連するコストのいくつかについて話しました。

00:22:29.000 --> 00:22:43.000
そのため、コードに並行性を導入するコストが管理コストを上回る場合にのみ、Swift並行性を使用して新しいコードを書くように注意する必要があります。

00:22:43.000 --> 00:22:53.000
ここのコードスニペットは、単にユーザーのデフォルトから値を読み取るために子タスクを生成するという追加の並行性から実際には恩恵を受けないかもしれません。

00:22:53.000 --> 00:23:02.000
これは、子タスクによって行われる有用な作業が、タスクの作成と管理のコストによって削減されるためです。

00:23:02.000 --> 00:23:12.000
したがって、Swift並行性を採用する際にパフォーマンス特性を理解するために、Instrumentsシステムトレースでコードをプロファイリングすることをお勧めします。

00:23:12.000 --> 00:23:18.000
2番目に注意すべきことは、待機の周りの原子性の概念です。

00:23:18.000 --> 00:23:28.000
Swiftは、待機前にコードを実行したスレッドが、継続を拾うのと同じスレッドであることを保証するものではありません。

00:23:28.000 --> 00:23:39.000
実際、awaitは、タスクが自発的にスケジュール解除される可能性があるため、原子性が壊れていることを示すコードの明示的なポイントです。

00:23:39.000 --> 00:23:44.000
そのため、待ち時間を越えてロックを保持しないように注意する必要があります。

00:23:44.000 --> 00:23:50.000
同様に、スレッド固有のデータは、待機中にも保存されません。

00:23:50.000 --> 00:24:00.000
スレッドの局所性を期待するコード内の仮定は、待機の一時停止動作を考慮して再検討する必要があります。

00:24:00.000 --> 00:24:10.000
そして最後に、最終的な考慮事項は、Swiftの効率的なスレッドモデルの基礎であるランタイム契約に関係しています。

00:24:10.000 --> 00:24:20.000
Swiftでは、この言語により、スレッドが常に前進できるランタイム契約を維持できることを思い出してください。

00:24:20.000 --> 00:24:28.000
この契約に基づいて、Swiftのデフォルトの実行者となる協力的なスレッドプールを構築しました。

00:24:28.000 --> 00:24:40.000
Swiftの並行性を採用する際には、協力的なスレッドプールが最適に機能できるように、この契約をコードで引き続き維持することが重要です。

00:24:40.000 --> 00:24:51.000
コード内の依存関係を明示的かつ既知にする安全なプリミティブを使用することで、この契約を共同スレッドプール内で維持することが可能です。

00:24:51.000 --> 00:25:00.000
await、アクター、タスクグループなどのSwift並行性プリミティブを使用すると、これらの依存関係はコンパイル時に認識されます。

00:25:00.000 --> 00:25:07.000
したがって、Swiftコンパイラはこれを強制し、ランタイムコントラクトを維持するのに役立ちます。

00:25:07.000 --> 00:25:16.000
os_unfair_locksやNSLocksのようなプリミティブも安全ですが、使用する際には注意が必要です。

00:25:16.000 --> 00:25:25.000
同期コードでロックを使用することは、タイトでよく知られている重要なセクションの周りのデータ同期に使用する場合、安全です。

00:25:25.000 --> 00:25:33.000
これは、ロックを保持しているスレッドが常にロックの解除に向けて前進できるためです。

00:25:33.000 --> 00:25:44.000
そのため、プリミティブは競合の下で短期間スレッドをブロックする可能性がありますが、フォワードプログレスのランタイム契約に違反しません。

00:25:44.000 --> 00:25:58.000
Swiftの並行性プリミティブとは異なり、ロックの正しい使用を支援するコンパイラのサポートがないため、このプリミティブを正しく使用するのはあなたの責任です。

00:25:58.000 --> 00:26:06.000
一方、セマフォや条件変数などのプリミティブは、Swiftの並行性で使用するには安全ではありません。

00:26:06.000 --> 00:26:15.000
これは、Swiftランタイムから依存関係情報を隠すが、コードの実行に依存関係を導入するためです。

00:26:15.000 --> 00:26:23.000
ランタイムはこの依存関係を認識していないため、正しいスケジューリングの決定を下して解決することはできません。

00:26:23.000 --> 00:26:36.000
特に、非構造化タスクを作成し、セマフォまたは安全でないプリミティブを使用してタスク境界を越えて依存関係を遡及的に導入するプリミティブを使用しないでください。

00:26:36.000 --> 00:26:45.000
このようなコードパターンは、別のスレッドがブロックを解除できるまで、スレッドがセマフォに対して無期限にブロックできることを意味します。

00:26:45.000 --> 00:26:51.000
これは、スレッドのフォワードプログレスのランタイム契約に違反しています。

00:26:51.000 --> 00:27:01.000
コードベースでこのような安全でないプリミティブの使用を特定するために、次の環境変数を使用してアプリをテストすることをお勧めします。

00:27:01.000 --> 00:27:11.000
これは、変更されたデバッグランタイムの下でアプリを実行し、フォワードプログレスの不変量を強制します。

00:27:11.000 --> 00:27:21.000
この環境変数は、ここに示すように、プロジェクトスキームの「引数の実行」ペインでXcodeで設定できます。

00:27:21.000 --> 00:27:33.000
この環境変数でアプリを実行する場合、ハングしているように見える協力スレッドプールのスレッドが表示された場合は、安全でないブロッキングプリミティブの使用を示します。

00:27:33.000 --> 00:27:47.000
さて、スレッドモデルがSwift並行性のためにどのように設計されたかについて学んだので、この新しい世界で状態を同期するために利用できるプリミティブについてもう少し発見しましょう。

00:27:47.000 --> 00:27:54.000
Varun：アクターに関するSwift並行性トークでは、アクターを使用して同時アクセスから可変状態を保護する方法を見てきました。

00:27:54.000 --> 00:28:01.000
言い換えれば、アクターはあなたが使用できる強力な新しい同期プリミティブを提供します。

00:28:01.000 --> 00:28:08.000
アクターが相互排除を保証することを思い出してください。アクターは一度に最大1つのメソッドコールを実行している可能性があります。

00:28:08.000 --> 00:28:15.000
相互排除とは、アクターの状態が同時にアクセスされないことを意味し、データレースを防ぎます。

00:28:15.000 --> 00:28:21.000
俳優が他の形態の相互排除とどのように比較されるかを見てみましょう。

00:28:21.000 --> 00:28:28.000
シリアルキューに同期して、いくつかの記事でデータベースを更新する以前の例を考えてみましょう。

00:28:28.000 --> 00:28:32.000
キューがまだ実行されていない場合は、競合がないと言います。

00:28:32.000 --> 00:28:39.000
この場合、呼び出しスレッドは、コンテキストスイッチなしでキューで新しい作業項目を実行するために再利用されます。

00:28:39.000 --> 00:28:45.000
代わりに、シリアルキューがすでに実行されている場合、キューは競合中であると言われます。

00:28:45.000 --> 00:28:49.000
この状況では、呼び出しスレッドはブロックされます。

00:28:49.000 --> 00:28:55.000
このブロッキング動作は、Rokhiniが講演の前半で説明したように、スレッドの爆発を引き起こしたものです。

00:28:55.000 --> 00:28:58.000
ロックも同じ動作をします。

00:28:58.000 --> 00:29:05.000
ブロッキングに関連する問題のため、一般的にはディスパッチ非同期の使用を好むことをお勧めします。

00:29:05.000 --> 00:29:10.000
ディスパッチ非同期の主な利点は、ノンブロッキングであることです。

00:29:10.000 --> 00:29:14.000
したがって、競合下でも、スレッドの爆発にはつながりません。

00:29:14.000 --> 00:29:27.000
シリアルキューでディスパッチ非同期を使用する欠点は、競合がない場合、ディスパッチは非同期作業を行うために新しいスレッドを要求する必要があり、呼び出しスレッドが何か他のことを続けることです。

00:29:27.000 --> 00:29:34.000
したがって、ディスパッチ非同期を頻繁に使用すると、過剰なスレッドウェイクアップやコンテキストスイッチが発生する可能性があります。

00:29:34.000 --> 00:29:37.000
これは私たちを俳優に導きます。

00:29:37.000 --> 00:29:45.000
スウィフトの俳優は、効率的なスケジューリングのために協力的なスレッドプールを利用して、両方の長所を組み合わせています。

00:29:45.000 --> 00:29:52.000
実行されていないアクターでメソッドを呼び出すと、呼び出しスレッドを再利用してメソッド呼び出しを実行できます。

00:29:52.000 --> 00:30:00.000
呼び出されたアクターがすでに実行されている場合、呼び出し元のスレッドは実行している関数を一時停止し、他の作業を拾うことができます。

00:30:00.000 --> 00:30:07.000
サンプルニュースアプリの文脈で、これら2つのプロパティがどのように機能するかを見てみましょう。

00:30:07.000 --> 00:30:11.000
データベースとネットワークサブシステムに焦点を当てましょう。

00:30:11.000 --> 00:30:19.000
Swift並行性を使用するようにアプリケーションを更新すると、データベースのシリアルキューはデータベースアクターに置き換えられます。

00:30:19.000 --> 00:30:25.000
ネットワーキングの同時キューは、ニュースフィードごとに1つのアクターに置き換えることができます。

00:30:25.000 --> 00:30:34.000
簡単にするために、私はここでスポーツフィード、天気フィード、健康フィードの3つのフィードアクターしか示していませんが、実際にはもっとたくさんあるでしょう。

00:30:34.000 --> 00:30:39.000
これらの俳優は、協力的なスレッドプールで実行されます。

00:30:39.000 --> 00:30:45.000
フィードアクターはデータベースと対話して記事を保存し、他のアクションを実行します。

00:30:45.000 --> 00:30:49.000
この相互作用には、あるアクターから別のアクターへの実行切り替えが含まれます。

00:30:49.000 --> 00:30:52.000
私たちはこのプロセスを俳優ホッピングと呼んでいます。

00:30:52.000 --> 00:30:55.000
俳優ホッピングの仕組みについて話し合いましょう。

00:30:55.000 --> 00:31:04.000
スポーツフィードのアクターが協力プールのスレッドで実行され、いくつかの記事をデータベースに保存することを決定したとします。

00:31:04.000 --> 00:31:08.000
今のところ、データベースが使用されていないことを考えてみましょう。

00:31:08.000 --> 00:31:10.000
これは議論されていないケースです。

00:31:10.000 --> 00:31:15.000
スレッドは、スポーツフィードアクターからデータベースアクターに直接ホップできます。

00:31:15.000 --> 00:31:18.000
ここで気づくべきことが2つあります。

00:31:18.000 --> 00:31:22.000
まず、俳優をホッピングしている間、スレッドはブロックされませんでした。

00:31:22.000 --> 00:31:34.000
第二に、ホッピングは別のスレッドを必要としませんでした。ランタイムは、スポーツフィードアクターの作業項目を直接中断し、データベースアクターの新しい作業項目を作成できます。

00:31:34.000 --> 00:31:39.000
データベースアクターがしばらく実行されているが、最初の作業項目を完了していないとします。

00:31:39.000 --> 00:31:46.000
この瞬間、天気フィードアクターがデータベースにいくつかの記事を保存しようとしていると仮定します。

00:31:46.000 --> 00:31:51.000
これにより、データベースアクターの新しい作業項目が作成されます。

00:31:51.000 --> 00:31:58.000
俳優は、相互排除を保証することにより、安全を確保します。最大で、特定の時間に1つの作業項目がアクティブになる可能性があります。

00:31:58.000 --> 00:32:05.000
すでにアクティブな作業項目D1が1つあるため、新しい作業項目D2は保留されます。

00:32:05.000 --> 00:32:07.000
俳優もノンブロッキングです。

00:32:07.000 --> 00:32:17.000
このような状況では、ウェザーフィードアクターが中断され、実行していたスレッドが他の作業を行うために解放されます。

00:32:17.000 --> 00:32:26.000
しばらくすると、最初のデータベース要求が完了し、データベースアクターのアクティブな作業項目が削除されます。

00:32:26.000 --> 00:32:31.000
この時点で、ランタイムはデータベースアクターの保留中の作業項目の実行を開始することを選択できます。

00:32:31.000 --> 00:32:34.000
または、フィードアクターの1つを再開することを選択するかもしれません。

00:32:34.000 --> 00:32:39.000
または、解放されたスレッドで他の作業を行うこともできます。

00:32:39.000 --> 00:32:47.000
非同期作業が多く、特に競合が多い場合、システムはどのような作業がより重要かに基づいてトレードオフを行う必要があります。

00:32:47.000 --> 00:32:55.000
理想的には、ユーザーインタラクションを含むような優先度の高い作業は、バックアップの保存などのバックグラウンド作業よりも優先されます。

00:32:55.000 --> 00:33:01.000
アクターは、再入の概念により、システムが作業に優先順位を付けることができるように設計されています。

00:33:01.000 --> 00:33:09.000
しかし、なぜここで再参入が重要なのかを理解するために、まずGCDが優先順位をどのように処理するかを見てみましょう。

00:33:09.000 --> 00:33:14.000
シリアルデータベースキューでオリジナルのニュースアプリケーションを検討してください。

00:33:14.000 --> 00:33:19.000
データベースが、UIを更新するために最新のデータを取得するなど、優先度の高い作業を受け取るとします。

00:33:19.000 --> 00:33:24.000
また、データベースをiCloudにバックアップするなど、優先順位の低い作業も受け取ります。

00:33:24.000 --> 00:33:29.000
これはある時点で行う必要がありますが、必ずしもすぐに行う必要はありません。

00:33:29.000 --> 00:33:36.000
コードが実行されると、新しい作業項目が作成され、インターリーブされた順序でデータベースキューに追加されます。

00:33:36.000 --> 00:33:42.000
ディスパッチキューは、厳密な先入れ先出し順で受信したアイテムを実行します。

00:33:42.000 --> 00:33:51.000
残念ながら、これは、アイテムAが実行した後、次の優先度の高いアイテムにたどり着く前に、5つの低優先度アイテムを実行する必要があることを意味します。

00:33:51.000 --> 00:33:54.000
これは優先度反転と呼ばれます。

00:33:54.000 --> 00:34:02.000
シリアルキューは、優先度の高い作業に先立つキュー内のすべての作業の優先度を高めることで、優先度の反転を回避します。

00:34:02.000 --> 00:34:08.000
実際には、これはキュー内の作業が早く行われることを意味します。

00:34:08.000 --> 00:34:17.000
ただし、主な問題は解決しません。つまり、項目Bの実行を開始する前に、項目1から5はまだ完了する必要があるということです。

00:34:17.000 --> 00:34:24.000
この問題を解決するには、セマンティックモデルを厳密な先着順から変更する必要があります。

00:34:24.000 --> 00:34:27.000
これは私たちを俳優の再参入に導きます。

00:34:27.000 --> 00:34:34.000
再入が注文にどのように関連しているかを例で探りましょう。

00:34:34.000 --> 00:34:37.000
スレッドで実行されているデータベースアクターを検討してください。

00:34:37.000 --> 00:34:46.000
それが中断され、いくつかの作業を待っていて、スポーツフィードアクターがそのスレッドで実行を開始するとします。

00:34:46.000 --> 00:34:53.000
しばらくすると、スポーツフィードアクターがデータベースアクターを呼び出して、いくつかの記事を保存するとします。

00:34:53.000 --> 00:35:03.000
データベースアクターは未指定であるため、保留中の作業項目が1つあるにもかかわらず、スレッドはデータベースアクターにホップできます。

00:35:03.000 --> 00:35:09.000
保存操作を実行するには、データベースアクター用の新しい作業項目が作成されます。

00:35:09.000 --> 00:35:18.000
これが俳優の再入を意味します。俳優の新しい作業項目は、1つ以上の古い作業項目が中断されている間、進歩する可能性があります。

00:35:18.000 --> 00:35:25.000
俳優はまだ相互排除を維持しています:最大で1つの作業項目を特定の時間に実行することができます。

00:35:25.000 --> 00:35:29.000
しばらくすると、アイテムD2は実行を終了します。

00:35:29.000 --> 00:35:35.000
D2は、D1の後に作成されたにもかかわらず、D1の前に実行が終了したことに注意してください。

00:35:35.000 --> 00:35:45.000
したがって、俳優の再入のサポートは、俳優が厳密に先入れ先出しではない順序でアイテムを実行できることを意味します。

00:35:45.000 --> 00:35:51.000
以前の例を再検討しましょうが、シリアルキューの代わりにデータベースアクターを使ってください。

00:35:51.000 --> 00:35:55.000
まず、作業項目Aは優先度が高いため実行されます。

00:35:55.000 --> 00:36:00.000
それが終わったら、以前と同じ優先順位の反転があります。

00:36:00.000 --> 00:36:10.000
俳優は再参入用に設計されているため、ランタイムは優先度の高いアイテムを優先度の低いアイテムよりも先にキューの先頭に移動することを選択できます。

00:36:10.000 --> 00:36:17.000
このようにして、優先度の高い作業が最初に実行され、優先度の低い作業が後で実行されます。

00:36:17.000 --> 00:36:26.000
これは、優先順位の反転の問題に直接対処し、より効果的なスケジューリングとリソースの利用を可能にします。

00:36:26.000 --> 00:36:35.000
協力プールを使用するアクターが相互排除を維持し、仕事の効果的な優先順位付けをサポートするためにどのように設計されているかについて少し話しました。

00:36:35.000 --> 00:36:47.000
別の種類の俳優、主役者があり、システム内の既存の概念であるメインスレッドを抽象化するため、その特徴は多少異なります。

00:36:47.000 --> 00:36:50.000
俳優を使ったニュースアプリの例を考えてみましょう。

00:36:50.000 --> 00:36:56.000
ユーザーインターフェイスを更新するときは、MainActorとの間で電話をかける必要があります。

00:36:56.000 --> 00:37:02.000
メインスレッドは協力プールのスレッドから切り離されているため、これにはコンテキストスイッチが必要です。

00:37:02.000 --> 00:37:08.000
これのパフォーマンスへの影響をコード例で見てみましょう。

00:37:08.000 --> 00:37:19.000
データベースから記事をロードし、各記事のUIを更新するMainActorの機能updateArticlesがある次のコードを検討してください。

00:37:19.000 --> 00:37:27.000
ループの各反復には、少なくとも2つのコンテキストスイッチが必要です。1つはメインアクターからデータベースアクターにホップし、もう1つはホップバックします。

00:37:27.000 --> 00:37:33.000
このようなループのCPU使用率がどのように見えるか見てみましょう。

00:37:33.000 --> 00:37:43.000
各ループ反復には2つのコンテキストスイッチが必要なため、2つのスレッドが短期間で次々に実行される繰り返しパターンがあります。

00:37:43.000 --> 00:37:51.000
ループ反復の数が少なく、各反復で実質的な作業が行われている場合、それはおそらく大丈夫です。

00:37:51.000 --> 00:38:01.000
ただし、実行がメインアクターを頻繁にオン/オフすると、スイッチングスレッドのオーバーヘッドが加算され始める可能性があります。

00:38:01.000 --> 00:38:12.000
アプリケーションがコンテキストの切り替えに大部分の時間を費やす場合は、メインアクターの作業がバッチ処理されるようにコードを再構築する必要があります。

00:38:12.000 --> 00:38:21.000
ループをloadArticlesとupdateUIメソッド呼び出しにプッシュし、一度に1つの値ではなく配列を処理することを確認することで、バッチ作業をすることができます。

00:38:21.000 --> 00:38:25.000
バッチ処理により、コンテキストスイッチの数が減少します。

00:38:25.000 --> 00:38:35.000
協同組合プールでの俳優間のホッピングは速いですが、アプリを書くときは、メイン俳優との間のホップに注意する必要があります。

00:38:35.000 --> 00:38:48.000
振り返ってみると、この講演では、ノンブロッキングサスペンションのメカニズムである協調スレッドプールの設計から、アクターの実装方法まで、システムを最も効率的にするためにどのように取り組んできたかを学びました。

00:38:48.000 --> 00:38:55.000
各ステップでは、ランタイム契約のいくつかの側面を使用して、アプリケーションのパフォーマンスを向上させています。

00:38:55.000 --> 00:39:03.000
これらの信じられないほどの新しい言語機能を使用して、明確で効率的で楽しいSwiftコードを書く方法に興奮しています。

00:39:03.000 --> 00:39:06.000
ご覧いただきありがとうございます。素晴らしいWWDCをお過ごしください。

00:39:06.000 --> 23:59:59.000
♪

