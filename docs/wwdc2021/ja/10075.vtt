WEBVTT

00:00:00.000 --> 00:00:05.000
♪ベース音楽の演奏♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:14.000
コートランド・イドストローム:こんにちは、私の名前はコートランド・イドストロームで、RealityKitチームのエンジニアです。

00:00:14.000 --> 00:00:19.000
このビデオでは、RealityKit 2の新しいレンダリング機能の使い方を紹介します。

00:00:19.000 --> 00:00:24.000
RealityKitは、ARアプリをシンプルで直感的に構築できるように設計されたフレームワークです。

00:00:24.000 --> 00:00:30.000
レンダリングは、非常に現実的で物理ベースのレンダリングを中心としたRealityKitの重要な部分です。

00:00:30.000 --> 00:00:36.000
2019年の最初のリリース以来、私たちはあなたのフィードバックに取り組んでおり、RealityKitのメジャーアップデートを出荷しています。

00:00:36.000 --> 00:00:52.000
「Dive into Reality Kit 2」セッションでは、RealityKitの進化を取り上げ、ECSシステムへのアップデート、より進化した素材とアニメーション機能、実行時のオーディオとテクスチャリソースの生成など、多くの機能強化を提供しました。

00:00:52.000 --> 00:00:58.000
これらの改善を紹介するために、私たちはあなたのリビングルームを水中水族館に変えるアプリを構築しました。

00:00:58.000 --> 00:01:02.000
この講演では、アプリに入った新しいレンダリング機能のいくつかを紹介します。

00:01:02.000 --> 00:01:10.000
RealityKit 2は、オブジェクトのレンダリング方法の制御と柔軟性を提供し、さらに優れたAR体験を作成できます。

00:01:10.000 --> 00:01:18.000
今年は、材料システムに進歩をもたらし、カスタムメタルシェーダーをオーサーディングすることで、独自の材料を追加することができます。

00:01:18.000 --> 00:01:24.000
カスタムポストエフェクトを使用すると、RealityKitのポストエフェクトを独自のポストエフェクトで拡張できます。

00:01:24.000 --> 00:01:31.000
新しいメッシュAPIは、実行時にメッシュの作成、検査、および変更を可能にします。

00:01:31.000 --> 00:01:37.000
RealityKit 2で最も要求された機能から始めましょう。カスタムシェーダーのサポート。

00:01:37.000 --> 00:01:41.000
RealityKitのレンダリングは、物理ベースのレンダリングモデルを中心にしています。

00:01:41.000 --> 00:01:47.000
内蔵のシェーダーにより、さまざまな照明条件で実際のオブジェクトの隣で自然に見えるモデルを簡単に作成できます。

00:01:47.000 --> 00:01:56.000
今年は、これらの物理ベースのシェーダーを構築し、シェーダーを使用してモデルのジオメトリと表面をカスタマイズする機能を公開します。

00:01:56.000 --> 00:01:59.000
最初のシェーダーAPIはジオメトリ修飾子です。

00:01:59.000 --> 00:02:10.000
ジオメトリ修飾子は、Metal Shading Languageで書かれたプログラムで、GPUでレンダリングされるすべてのフレームでオブジェクトの頂点を変更する機会を提供します。

00:02:10.000 --> 00:02:16.000
これには、それらを移動し、色、通常、UVなどの属性をカスタマイズすることが含まれます。

00:02:16.000 --> 00:02:24.000
RealityKitの頂点シェーダー内で実行され、アンビエントアニメーション、変形、パーティクルシステム、看板に最適です。

00:02:24.000 --> 00:02:27.000
私たちの海藻は、アンビエントアニメーションの素晴らしい例です。

00:02:27.000 --> 00:02:31.000
海藻は周りの水の動きでゆっくりと動いている。

00:02:31.000 --> 00:02:33.000
詳しく見てみましょう。 

00:02:33.000 --> 00:02:41.000
ここでは、私たちのアーティストによって作成された海藻のワイヤーフレームを見ることができます。これは、メッシュを構成する頂点と三角形を示しています。

00:02:41.000 --> 00:02:46.000
モーションを作成するために各頂点で実行されるシェーダープログラムを作成します。

00:02:46.000 --> 00:02:50.000
単純な周期関数である正弦波を使用して、動きを作成します。

00:02:50.000 --> 00:02:59.000
私たちは水流をシミュレートしているので、モデルの規模や向きに関係なく、近くの頂点が同じように振る舞うことを望んでいます。

00:02:59.000 --> 00:03:04.000
このため、頂点の世界位置を正弦関数の入力として使用します。

00:03:04.000 --> 00:03:08.000
時間の経過とともに移動するように、時間値も含めます。

00:03:08.000 --> 00:03:12.000
私たちの最初の正弦波は、上下の動きを作成するためにY次元にあります。

00:03:12.000 --> 00:03:16.000
動きの期間を制御するために、空間スケールを追加します。

00:03:16.000 --> 00:03:21.000
そして、私たちはその動きの量を振幅で制御することができます。

00:03:21.000 --> 00:03:26.000
3つの軸すべてで移動するように、XとZの次元に同じ関数を適用します。

00:03:26.000 --> 00:03:30.000
では、モデル全体を見てみましょう。

00:03:30.000 --> 00:03:39.000
私たちがまだ説明していないことの1つは、茎の基部に近い頂点には移動の余地がほとんどなく、上部の頂点は移動する自由度が高いことです。

00:03:39.000 --> 00:03:53.000
これをシミュレートするために、オブジェクトの原点に対する頂点のy座標を3つの軸すべてのスケーリング係数として使用することができ、最終的な公式が得られます。

00:03:53.000 --> 00:03:58.000
シェーダーの計画を立てたので、これらのパラメータを見つける場所を見てみましょう。

00:03:58.000 --> 00:04:02.000
ジオメトリパラメータは、いくつかのカテゴリに分類されます。

00:04:02.000 --> 00:04:07.000
1つ目はユニフォームで、1つのフレーム内のオブジェクトのすべての頂点に対して同じ値です。

00:04:07.000 --> 00:04:10.000
私たちは海藻のための時間が必要です。

00:04:10.000 --> 00:04:18.000
テクスチャには、モデルの一部として作成されたすべてのテクスチャと、必要に応じて使用できる追加のカスタムスロットが含まれています。

00:04:18.000 --> 00:04:26.000
マテリアル定数には、ティントや不透明度スケールなどのパラメータがあり、オブジェクトで作成されたか、コードで設定されています。

00:04:26.000 --> 00:04:32.000
ジオメトリには、現在の頂点のモデル位置や頂点IDなど、いくつかの読み取り専用値が含まれています。

00:04:32.000 --> 00:04:38.000
海藻運動には、モデルと世界の両方のポジションが必要です。

00:04:38.000 --> 00:04:44.000
ジオメトリには、法線、UV、モデル位置オフセットなどの読み取り/書き込み値もあります。

00:04:44.000 --> 00:04:49.000
オフセットを計算したら、ここに保存して頂点を移動します。

00:04:49.000 --> 00:04:52.000
メタルシェーダーに飛び込みましょう。

00:04:52.000 --> 00:04:55.000
RealityKit.hを含めることから始めます。

00:04:55.000 --> 00:04:59.000
次に、可視関数属性を持つ関数を宣言します。

00:04:59.000 --> 00:05:04.000
これは、他の関数とは別に使用できるようにコンパイラに指示します。

00:05:04.000 --> 00:05:09.000
この関数は、RealityKitのgeometry_parametersである単一のパラメータを取ります。

00:05:09.000 --> 00:05:12.000
このオブジェクトを介してすべての値を取得します。

00:05:12.000 --> 00:05:18.000
パラメータのジオメトリメンバーを使用して、世界位置とモデル位置の両方を求めます。

00:05:18.000 --> 00:05:24.000
次に、頂点と時刻の世界位置に基づいて、位相オフセットを計算します。

00:05:24.000 --> 00:05:29.000
次に、この頂点のオフセットを計算するために数式を適用します。

00:05:29.000 --> 00:05:34.000
オフセットをジオメトリに保存し、頂点のモデル位置に追加されます。

00:05:34.000 --> 00:05:39.000
私たちはジオメトリ修飾子を持っていますが、まだ海藻に接続されていません。

00:05:39.000 --> 00:05:43.000
Swiftで書かれたARViewサブクラスに切り替えましょう。

00:05:43.000 --> 00:05:47.000
シェーダーを含むアプリのデフォルトのMetalライブラリをロードすることから始めます。

00:05:47.000 --> 00:05:52.000
次に、シェーダーの名前とライブラリを使用してgeometryModifierを構築します。

00:05:52.000 --> 00:05:56.000
海藻の素材ごとに、新しいカスタム素材を作成します。

00:05:56.000 --> 00:06:07.000
既存のマテリアルを最初のパラメータとしてCustomMaterialに渡し、ジオメトリ修飾子を追加しながら、ベースマテリアルからテクスチャとマテリアルプロパティを継承します。

00:06:07.000 --> 00:06:12.000
かなり素敵に見えます!私たちは水中にいるので、アニメーションをかなり遅くしてきました。

00:06:12.000 --> 00:06:19.000
振幅と位相を微調整することで、同じ効果を草、木、または他の葉に拡張することができます。

00:06:19.000 --> 00:06:23.000
ジオメトリを変更する方法を示したので、シェーディングについて話しましょう。

00:06:23.000 --> 00:06:28.000
これは水中シーンのタコで、内蔵のシェーダーで見栄えがします。

00:06:28.000 --> 00:06:32.000
彼らがそうであるように、私たちのタコは複数のルックスの間で移行します。

00:06:32.000 --> 00:06:35.000
2番目の外観は赤みを帯びた色です。

00:06:35.000 --> 00:06:40.000
私たちのアーティストは、ルックごとに1つずつ、2つのベースカラーテクスチャを執筆しました。

00:06:40.000 --> 00:06:46.000
色の変化に加えて、赤いタコは粗さの値が高く、反射性が低くなります。

00:06:46.000 --> 00:06:52.000
そして、私たちのタコをさらに特別なものにするために、私たちはルックスの間に素敵な移行を作りたかった。

00:06:52.000 --> 00:06:56.000
ここでは、実際の移行を見ることができます。

00:06:56.000 --> 00:06:58.000
魅惑的な。

00:06:58.000 --> 00:07:05.000
各ルックは物理的ベースの素材として記述できますが、トランジション自体については、サーフェスシェーダーを書く必要があります。

00:07:05.000 --> 00:07:07.000
では、サーフェスシェーダーとは何ですか?

00:07:07.000 --> 00:07:11.000
サーフェスシェーダーを使用すると、オブジェクトの外観を定義できます。

00:07:11.000 --> 00:07:15.000
オブジェクトの目に見えるピクセルごとにフラグメントシェーダー内で実行されます。

00:07:15.000 --> 00:07:22.000
色に加えて、これには法線、鏡面、粗さなどの表面特性が含まれます。

00:07:22.000 --> 00:07:28.000
オブジェクトの外観を強化したり、完全に置き換えたりして新しい効果を生み出すシェーダーを書くことができます。

00:07:28.000 --> 00:07:31.000
私たちはタコの2つのベースカラーのテクスチャを見てきました。

00:07:31.000 --> 00:07:36.000
トランジション効果のために、私たちのアーティストは私たちのために特別なテクスチャをエンコードしました。

00:07:36.000 --> 00:07:40.000
このテクスチャは、実際には3つの異なるレイヤーの組み合わせです。

00:07:40.000 --> 00:07:44.000
上部にノイズレイヤーがあり、ローカライズされたトランジションパターンを作成します。

00:07:44.000 --> 00:07:51.000
頭から始めて触手に向かって移動する全体的な動きを指示する遷移層があります。

00:07:51.000 --> 00:07:59.000
そして、目や触手の下側など、色を変えたくない領域のマスク層があります。

00:07:59.000 --> 00:08:06.000
これらの3つのレイヤーは、カスタムテクスチャスロットに割り当てるテクスチャの赤、緑、青のチャンネルに組み合わされます。

00:08:06.000 --> 00:08:12.000
テクスチャを設定して、サーフェスシェーダーからこれらにアクセスする方法を見てみましょう。

00:08:12.000 --> 00:08:18.000
ジオメトリ修飾子と同様に、サーフェスシェーダーはユニフォーム、テクスチャ、およびマテリアル定数にアクセスできます。

00:08:18.000 --> 00:08:21.000
時間はタコの移行への入力です。

00:08:21.000 --> 00:08:29.000
モデルで作成されたテクスチャをサンプリングし、マテリアル定数を読み取り、アーティストがモデル全体の調整を行うことができます。

00:08:29.000 --> 00:08:33.000
位置、法線、UVなどのジオメトリは、ジオメトリ構造に表示されます。

00:08:33.000 --> 00:08:37.000
これらは、頂点シェーダーからの補間出力です。

00:08:37.000 --> 00:08:40.000
テクスチャ座標としてUV0を使用します。

00:08:40.000 --> 00:08:42.000
サーフェスシェーダーはサーフェス構造を書き込みます。

00:08:42.000 --> 00:08:48.000
プロパティはデフォルト値で始まり、これらの値を自由に計算できます。

00:08:48.000 --> 00:08:51.000
ベースカラーとノーマルを計算します。

00:08:51.000 --> 00:08:56.000
次に、4つの表面パラメータ：粗さ、金属、周囲閉塞、鏡面。

00:08:56.000 --> 00:09:00.000
私たちの価値観がどこにあるかがわかったので、シェーダーを書き始めましょう。

00:09:00.000 --> 00:09:02.000
これを3つのステップで行います。

00:09:02.000 --> 00:09:09.000
まず、遷移値を計算します。0は完全に紫色のタコで、1は完全に赤色です。

00:09:09.000 --> 00:09:16.000
遷移値を使用して、色と法線を計算し、材料特性を割り当てて微調整します。

00:09:16.000 --> 00:09:17.000
始めましょう。

00:09:17.000 --> 00:09:19.000
最初のステップ: 移行。

00:09:19.000 --> 00:09:24.000
私たちは、surface_parameters引数を取るタコサーフェス関数を構築しています。

00:09:24.000 --> 00:09:27.000
テクスチャを使用しているので、サンプラーを宣言します。

00:09:27.000 --> 00:09:33.000
右側では、私たちのタコが空の表面シェーダーでどのように見えるかを見ることができます - それは灰色で少し光沢があります。

00:09:33.000 --> 00:09:38.000
RealityKitを使用すると、モデルの外観に貢献するもの、または貢献しないものを完全に制御できます。

00:09:38.000 --> 00:09:41.000
色を計算するには、最初にやらなければならないことがいくつかあります。

00:09:41.000 --> 00:09:44.000
いくつかの便利な変数を保存します。

00:09:44.000 --> 00:09:48.000
UV0にアクセスし、テクスチャ座標として使用します。

00:09:48.000 --> 00:09:56.000
金属とUSDはテクスチャ座標系が異なるため、USDからロードされたテクスチャに合わせてy座標を反転します。

00:09:56.000 --> 00:10:01.000
次に、トランジションテクスチャをサンプリングします - アーティストが作成した3層のテクスチャです。

00:10:01.000 --> 00:10:09.000
私たちのアーティストは、マスク値と時間を取る小さな関数を設定し、ブレンドとcolorBlendの0から1の値を返します。

00:10:09.000 --> 00:10:13.000
2番目のステップ:色と普通。

00:10:13.000 --> 00:10:19.000
以前に計算されたブレンド変数を使用して、タコの色を計算し、遷移を確認できるようになりました。

00:10:19.000 --> 00:10:27.000
これを行うには、emissive_colorに保存したベースカラーとセカンダリベースカラーの2つのテクスチャをサンプリングします。

00:10:27.000 --> 00:10:32.000
次に、以前に計算したcolorBlendを使用して2つの色をブレンドします。

00:10:32.000 --> 00:10:38.000
素材の値であるbase_color_tintを乗算し、表面にベースカラーを設定します。

00:10:38.000 --> 00:10:46.000
次に、頭と触手に最も顕著な表面偏差を追加するノーマルマップを適用します。

00:10:46.000 --> 00:10:52.000
通常のマップテクスチャをサンプリングし、その値を解凍し、サーフェスオブジェクトに設定します。

00:10:52.000 --> 00:10:55.000
材料の特性について。

00:10:55.000 --> 00:10:58.000
これはこれまでのタコで、色と普通です。

00:10:58.000 --> 00:11:01.000
表面特性がその外観にどのように影響するかを見てみましょう。

00:11:01.000 --> 00:11:13.000
下半身に見られる粗さ、下部を暗くする周囲の閉塞、そして鏡面は、私たちに目に素敵な反射と体にいくつかの追加の定義を与えます。

00:11:13.000 --> 00:11:15.000
これらをシェーダーに追加しましょう。

00:11:15.000 --> 00:11:19.000
モデル上の4つのテクスチャをサンプリングし、プロパティごとに1つずつ。

00:11:19.000 --> 00:11:23.000
次に、材料設定でこれらの値をスケーリングします。

00:11:23.000 --> 00:11:29.000
さらに、紫から赤に移行するにつれて、粗さも増加しています。

00:11:29.000 --> 00:11:32.000
次に、表面に4つの値を設定します。

00:11:32.000 --> 00:11:36.000
以前と同様に、シェーダーをモデルに適用する必要があります。

00:11:36.000 --> 00:11:41.000
このマテリアルをARViewサブクラスのモデルに割り当てます。

00:11:41.000 --> 00:11:46.000
まず、2つの追加のテクスチャをロードし、次にサーフェスシェーダーをロードします。

00:11:46.000 --> 00:11:55.000
以前と同様に、今回は表面シェーダーと2つの追加のテクスチャを使用して、オブジェクトの基材から新しい材料を構築しています。

00:11:55.000 --> 00:11:57.000
そして、私たちは終わりました。

00:11:57.000 --> 00:12:05.000
要約すると、ジオメトリ修飾子を使用した海藻アニメーションと、サーフェスシェーダーでタコの遷移を構築する方法を示しました。

00:12:05.000 --> 00:12:11.000
私たちはそれらを別々に実演しましたが、さらに興味深い効果を得るために2つを組み合わせることができます。

00:12:11.000 --> 00:12:18.000
別の非常に要求された機能に移り、カスタム後処理効果を追加するためのサポート。

00:12:18.000 --> 00:12:29.000
RealityKitには、モーションブラー、カメラノイズ、被写界深度など、カメラにマッチしたポストエフェクトの豊富なセットが付属しています。

00:12:29.000 --> 00:12:35.000
これらの効果はすべて、仮想オブジェクトと実際のオブジェクトが同じ環境の一部であるように感じるように設計されています。

00:12:35.000 --> 00:12:38.000
これらはARViewでカスタマイズできます。

00:12:38.000 --> 00:12:43.000
今年は、独自のフルスクリーンエフェクトを作成する機能も公開します。

00:12:43.000 --> 00:12:50.000
これにより、PhotoリアリズムにRealityKitを活用し、新しいエフェクトを追加してアプリの結果を調整できます。

00:12:50.000 --> 00:12:52.000
では、投稿プロセスとは何ですか?

00:12:52.000 --> 00:13:00.000
ポストプロセスは、オブジェクトがレンダリングされて点灯した後に実行されるシェーダーまたは一連のシェーダーです。

00:13:00.000 --> 00:13:04.000
また、RealityKitのポストエフェクトの後にも発生します。

00:13:04.000 --> 00:13:09.000
その入力は、色と深度バッファの2つのテクスチャです。

00:13:09.000 --> 00:13:16.000
深度バッファはここでグレースケールとして表示されます。カメラに対する各ピクセルの距離値が含まれています。

00:13:16.000 --> 00:13:20.000
ポストプロセスは、結果をターゲットカラーテクスチャに書き込みます。

00:13:20.000 --> 00:13:25.000
最も単純な投稿効果は、ソース色をターゲット色にコピーします。

00:13:25.000 --> 00:13:27.000
私たちはいくつかの方法でこれらを構築することができます。

00:13:27.000 --> 00:13:36.000
Appleのプラットフォームには、Core Image、Metal Performance Shaders、SpriteKitなど、ポストエフェクトとうまく統合する多くのテクノロジーが搭載されています。

00:13:36.000 --> 00:13:39.000
メタルシェーディング言語で自分で書くこともできます。

00:13:39.000 --> 00:13:42.000
コアイメージエフェクトから始めましょう。

00:13:42.000 --> 00:13:45.000
Core Imageは、画像処理のためのAppleのフレームワークです。

00:13:45.000 --> 00:13:53.000
画像やビデオに適用できる何百もの色処理、様式化、変形効果があります。

00:13:53.000 --> 00:13:58.000
サーマルはきちんとした効果です - あなたが水中の魚群探知機のためにオンにするかもしれないものです。

00:13:58.000 --> 00:14:01.000
RealityKitとの統合がどれほど簡単か見てみましょう。

00:14:01.000 --> 00:14:04.000
私たちのポストエフェクトはすべて同じパターンに従います。

00:14:04.000 --> 00:14:13.000
レンダリングコールバックを設定し、デバイスで準備するために応答し、ポストプロセスはすべてのフレームが呼び出されます。

00:14:13.000 --> 00:14:16.000
レンダリングコールバックはRealityKitのARViewに存在します。

00:14:16.000 --> 00:14:20.000
prepareWithDeviceとpostProcessの両方のコールバックが必要です。

00:14:20.000 --> 00:14:24.000
デバイスで準備すると、MTLDeviceで一度呼び出されます。

00:14:24.000 --> 00:14:30.000
これは、テクスチャを作成し、コンピューティングまたはレンダリングパイプラインをロードし、デバイスの機能をチェックする良い機会です。

00:14:30.000 --> 00:14:33.000
これは、コアイメージのコンテキストを作成する場所です。

00:14:33.000 --> 00:14:36.000
postProcessコールバックは各フレームで呼び出されます。

00:14:36.000 --> 00:14:40.000
ソースカラーテクスチャを参照して、CIImageを作成します。

00:14:40.000 --> 00:14:43.000
次に、サーマルフィルターを作成します。

00:14:43.000 --> 00:14:48.000
別のコアイメージフィルターを使用している場合は、ここで他のパラメータを設定します。

00:14:48.000 --> 00:14:56.000
次に、出力カラーテクスチャをターゲットにし、コンテキストのコマンドバッファを利用するレンダリング先を作成します。

00:14:56.000 --> 00:15:01.000
Core Imageに、画像の向きを維持し、タスクを開始するよう依頼します。

00:15:01.000 --> 00:15:02.000
それでおそれ！

00:15:02.000 --> 00:15:07.000
Core Imageを使用すると、使用できる何百もの事前構築されたエフェクトのロックを解除しました。

00:15:07.000 --> 00:15:12.000
それでは、メタルパフォーマンスシェーダーを使用して新しいエフェクトを構築する方法を見てみましょう。

00:15:12.000 --> 00:15:13.000
ブルームについて話しましょう。

00:15:13.000 --> 00:15:22.000
ブルームは、現実世界のレンズ効果をシミュレートし、明るく照らされたオブジェクトの周りに輝きを作り出すスクリーンスペーステクニックです。

00:15:22.000 --> 00:15:28.000
コアイメージにはブルーム効果が含まれていますが、プロセスのすべてのステップを制御できるように、独自の効果を構築します。

00:15:28.000 --> 00:15:35.000
高度に最適化されたコンピューティングとグラフィックスシェーダーのコレクションであるメタルパフォーマンスシェーダーでエフェクトを構築します。

00:15:35.000 --> 00:15:40.000
このシェーダーを構築するには、色をソースとしてフィルターのグラフを作成します。

00:15:40.000 --> 00:15:43.000
まず、明るい領域を隔離したい。

00:15:43.000 --> 00:15:47.000
これを行うには、「ゼロへのしきい値」という操作を使用します。

00:15:47.000 --> 00:15:52.000
色を輝度に変換し、特定の輝度レベル以下のすべてのピクセルを0に設定します。

00:15:52.000 --> 00:15:58.000
次に、ガウスぼかしを使用して結果をぼかし、隣接する領域に光を広げます。

00:15:58.000 --> 00:16:02.000
効率的なぼかしは実装が困難であり、多くの場合、複数の段階を必要とします。

00:16:02.000 --> 00:16:05.000
メタルパフォーマンスシェーダーは私たちのためにこれを処理します。

00:16:05.000 --> 00:16:11.000
次に、このぼやけたテクスチャを元の色に追加し、明るい領域の周りに輝きを加えます。

00:16:11.000 --> 00:16:15.000
このグラフをポストエフェクトとして実装しましょう。

00:16:15.000 --> 00:16:18.000
中間のbloomTextureを作成することから始めます。

00:16:18.000 --> 00:16:24.000
次に、ThresholdToZero操作を実行し、sourceColorから読み取り、bloomTextureに書き込みます。

00:16:24.000 --> 00:16:28.000
次に、gaussianBlurを所定の位置に実行します。

00:16:28.000 --> 00:16:32.000
最後に、元の色とこの咲いた色を一緒に追加します。

00:16:32.000 --> 00:16:33.000
それでおそれ！

00:16:33.000 --> 00:16:41.000
ポストエフェクトを作成する方法をいくつか見てきたので、SpriteKitを使用して出力の上にエフェクトを置く方法について話しましょう。

00:16:41.000 --> 00:16:46.000
SpriteKitは、高性能でバッテリー効率の高い2DゲームのためのAppleのフレームワークです。

00:16:46.000 --> 00:16:49.000
3Dビューの上にいくつかの効果を追加するのに最適です。

00:16:49.000 --> 00:16:57.000
同じprepareWithDeviceとpostProcessコールバックを使用して、ポストエフェクトとして画面にいくつかのバブルを追加します。

00:16:57.000 --> 00:16:59.000
以前と同じ2つのステップがあります。

00:16:59.000 --> 00:17:04.000
prepareWithDeviceでは、SpriteKitレンダラーを作成し、バブルを含むシーンをロードします。

00:17:04.000 --> 00:17:13.000
次に、ポストプロセスコールバックで、ソースカラーをターゲットカラーにコピーし、SpriteKitシーンを更新し、3Dコンテンツの上にレンダリングします。

00:17:13.000 --> 00:17:20.000
prepareWithDeviceはかなり簡単です - レンダラーを作成し、ファイルからシーンをロードします。

00:17:20.000 --> 00:17:26.000
これをARシーンに描くので、SpriteKitの背景を透明にする必要があります。

00:17:26.000 --> 00:17:34.000
postProcessでは、まずソースカラーをtargetColorTextureにブリットします。これはSpriteKitが前でレンダリングする背景になります。

00:17:34.000 --> 00:17:40.000
その後、SpriteKitのシーンを新しい時間に進め、泡が上に移動します。

00:17:40.000 --> 00:17:44.000
RenderPassDescriptorを設定し、それにレンダリングします。

00:17:44.000 --> 00:17:45.000
そして、それだけです!

00:17:45.000 --> 00:17:53.000
既存のフレームワークを活用してポストエフェクトを作成する方法を示しましたが、実際にはゼロから作成する必要がある場合があります。

00:17:53.000 --> 00:17:58.000
コンピューティングシェーダーを書くことで、フルスクリーンエフェクトを作成することもできます。

00:17:58.000 --> 00:18:05.000
水中デモでは、仮想オブジェクトとカメラのパススルーに適用されるフォグ効果が必要でした。

00:18:05.000 --> 00:18:11.000
霧は媒体を通る光の散乱をシミュレートします。その強度は距離に比例します。

00:18:11.000 --> 00:18:17.000
この効果を生み出すには、各ピクセルがデバイスからどれくらい離れているかを知る必要がありました。

00:18:17.000 --> 00:18:23.000
幸いなことに、ARKitとRealityKitはどちらも深度情報へのアクセスを提供します。

00:18:23.000 --> 00:18:31.000
LiDAR対応デバイスの場合、ARKitはカメラからメートル単位の距離を含むsceneDepthへのアクセスを提供します。

00:18:31.000 --> 00:18:36.000
これらの値は、フルスクリーンよりも低い解像度で非常に正確です。

00:18:36.000 --> 00:18:42.000
この深さを直接使用できますが、仮想オブジェクトは含まれていないため、正しく曇りません。

00:18:42.000 --> 00:18:53.000
ポストプロセスでは、RealityKitは仮想コンテンツの深さへのアクセスを提供し、シーンの理解が有効になっている場合、現実世界のオブジェクトの近似メッシュを提供します。

00:18:53.000 --> 00:18:59.000
メッシュは移動するにつれて徐々に構築されるため、現在スキャンしていない穴がいくつかあります。

00:18:59.000 --> 00:19:03.000
これらの穴は、まるで無限に遠く離れているかのように霧を示すだろう。

00:19:03.000 --> 00:19:08.000
この不一致を解決するために、これら2つの深度テクスチャからのデータを結合します。

00:19:08.000 --> 00:19:11.000
ARKitはテクスチャとして深度値を提供します。

00:19:11.000 --> 00:19:16.000
各ピクセルは、サンプリングされた点の距離（メートル単位）です。

00:19:16.000 --> 00:19:28.000
センサーはiPhoneまたはiPadの固定方向にあるため、ARKitにセンサーの向きから現在の画面の向きへの変換を構築し、結果を反転させるように依頼します。

00:19:28.000 --> 00:19:34.000
仮想コンテンツの深さを読むには、RealityKitがどのように深さをパックするかについて少し情報が必要です。

00:19:34.000 --> 00:19:40.000
ARKitのシーンデプスとは異なり、より明るい値がカメラに近いことに気づくでしょう。

00:19:40.000 --> 00:19:46.000
値は、Infinite Reverse-Z投影を使用して、0から1の範囲で格納されます。

00:19:46.000 --> 00:19:52.000
これは、0が無限に遠くを意味し、1がカメラの飛行機の近くにあることを意味します。

00:19:52.000 --> 00:19:58.000
ほぼ平面の深さをサンプリングされた深さで割ることで、この変換を簡単に逆転させることができます。

00:19:58.000 --> 00:20:01.000
これを行うためのヘルパー関数を書いてみましょう。

00:20:01.000 --> 00:20:05.000
サンプルの深さと投影マトリックスを取る金属関数があります。

00:20:05.000 --> 00:20:08.000
仮想コンテンツのないピクセルは正確に0です。

00:20:08.000 --> 00:20:12.000
ゼロで割るのを防ぐために、小さなイプシロンにクランプします。

00:20:12.000 --> 00:20:19.000
遠近法分割を元に戻すには、最後の列のz値を取り、サンプリングされた深さで割ります。

00:20:19.000 --> 00:20:20.000
すごい！

00:20:20.000 --> 00:20:26.000
2つの深度値がわかったので、2つの最小値をフォグ関数の入力として使用できます。

00:20:26.000 --> 00:20:35.000
私たちの霧には、最大距離、その距離での最大強度、パワーカーブ指数など、いくつかのパラメータがあります。

00:20:35.000 --> 00:20:38.000
正確な値は実験的に選ばれました。

00:20:38.000 --> 00:20:42.000
彼らは私たちの望ましい霧密度を達成するために私たちの深さの値を形作ります。

00:20:42.000 --> 00:20:44.000
今、私たちはピースをまとめる準備が整いました。

00:20:44.000 --> 00:20:51.000
ARKitの深度値、RealityKitの線形化された深度値、およびフォグの関数があります。

00:20:51.000 --> 00:20:53.000
計算シェーダーを書いてみましょう。

00:20:53.000 --> 00:20:57.000
各ピクセルについて、両方の線形深度値をサンプリングから始めます。

00:20:57.000 --> 00:21:04.000
次に、チューニングパラメータを使用してフォグ関数を適用し、線形深度を0対1の値に変換します。

00:21:04.000 --> 00:21:12.000
次に、fogBlendの値に応じて、ソースカラーとフォグカラーをブレンドし、結果をoutColorに格納します。

00:21:12.000 --> 00:21:19.000
要約すると、RealityKitの新しいポストプロセスAPIは、幅広いポストエフェクトを可能にします。

00:21:19.000 --> 00:21:23.000
Core Imageでは、何百もの既製のエフェクトのロックを解除しました。

00:21:23.000 --> 00:21:33.000
メタルパフォーマンスシェーダーで新しいものを簡単に構築したり、SpriteKitでスクリーンオーバーレイを追加したり、Metalでゼロから自分で書いたりできます。

00:21:33.000 --> 00:21:40.000
コアイメージまたはメタルパフォーマンスシェーダーの詳細については、リストされているセッションを参照してください。

00:21:40.000 --> 00:21:46.000
レンダリング効果について説明したので、次のトピックであるダイナミックメッシュに移りましょう。

00:21:46.000 --> 00:21:49.000
RealityKitでは、メッシュリソースはメッシュデータを保存します。

00:21:49.000 --> 00:21:54.000
以前は、この不透明なタイプでは、エンティティにメッシュを割り当てることができました。

00:21:54.000 --> 00:22:01.000
今年は、実行時にメッシュを検査し、作成し、更新する機能を提供します。

00:22:01.000 --> 00:22:05.000
ダイバーに特殊効果を追加する方法を見てみましょう。

00:22:05.000 --> 00:22:10.000
このデモでは、スパイラルがダイバーの周りの輪郭を描くスパイラル効果を見せたい。

00:22:10.000 --> 00:22:16.000
また、スパイラルがその動きをアニメーション化するために、時間の経過とともにメッシュをどのように変化させているかを見ることができます。

00:22:16.000 --> 00:22:20.000
新しいメッシュAPIを使用してこれを作成する方法を見てみましょう。 

00:22:20.000 --> 00:22:24.000
効果は3つのステップに集約されます。

00:22:24.000 --> 00:22:29.000
メッシュ検査を使用して、頂点を調べてモデルを測定します。

00:22:29.000 --> 00:22:33.000
次に、測定値をガイドとして使用して、スパイラルを構築します。

00:22:33.000 --> 00:22:38.000
そして最後に、時間の経過とともにスパイラルを更新することができます。

00:22:38.000 --> 00:22:40.000
メッシュ検査から始めます。

00:22:40.000 --> 00:22:44.000
メッシュの保存方法を説明するために、ダイバーモデルを見てみましょう。

00:22:44.000 --> 00:22:48.000
RealityKitでは、ダイバーのメッシュはメッシュリソースとして表されます。

00:22:48.000 --> 00:22:53.000
今年のリリースにより、MeshResourceにはContentsというメンバーが含まれるようになりました。

00:22:53.000 --> 00:22:57.000
処理されたすべてのメッシュジオメトリが存在する場所があります。

00:22:57.000 --> 00:23:02.000
コンテンツには、インスタンスとモデルのリストが含まれています。

00:23:02.000 --> 00:23:08.000
モデルには生の頂点データが含まれていますが、インスタンスはそれらを参照して変換を追加します。

00:23:08.000 --> 00:23:13.000
インスタンスを使用すると、データをコピーせずに同じジオメトリを複数回表示できます。

00:23:13.000 --> 00:23:15.000
モデルは複数の部品を持つことができます。

00:23:15.000 --> 00:23:19.000
部品は、1つの材料を持つジオメトリのグループです。

00:23:19.000 --> 00:23:28.000
最後に、各部分には、位置、法線、テクスチャ座標、インデックスなど、関心のある頂点データが含まれています。

00:23:28.000 --> 00:23:32.000
まず、コードでこのデータにアクセスする方法を見てみましょう。

00:23:32.000 --> 00:23:38.000
MeshResource.Contentsを拡張し、各頂点の位置でクロージャを呼び出します。

00:23:38.000 --> 00:23:41.000
私たちはすべてのインスタンスを通過することから始めます。

00:23:41.000 --> 00:23:43.000
これらの各インスタンスはモデルにマッピングされます。

00:23:43.000 --> 00:23:47.000
インスタンスごとに、エンティティに対する相対的な変換を見つけます。

00:23:47.000 --> 00:23:53.000
その後、モデルの各部品に入り、部品の属性にアクセスできます。

00:23:53.000 --> 00:23:56.000
この機能のために、私たちはポジションにしか興味がありません。

00:23:56.000 --> 00:24:02.000
その後、頂点をエンティティ空間の位置に変換し、コールバックを呼び出すことができます。

00:24:02.000 --> 00:24:07.000
頂点を訪問できるので、このデータをどのように使用したいかを見てみましょう。

00:24:07.000 --> 00:24:10.000
ダイバーを水平スライスに分割します。

00:24:10.000 --> 00:24:18.000
スライスごとに、モデルの境界半径を見つけ、スライスごとにこれを行います。

00:24:18.000 --> 00:24:23.000
これを実装するには、numSlices要素でゼロで満たされた配列を作成することから始めます。

00:24:23.000 --> 00:24:28.000
次に、y軸に沿ったメッシュの境界を把握して、スライスを作成します。

00:24:28.000 --> 00:24:38.000
先ほど作成した関数を使用して、モデル内の各頂点について、どのスライスに入るかを把握し、そのスライスの最大の半径で半径を更新します。

00:24:38.000 --> 00:24:44.000
最後に、半径と境界を含むスライスオブジェクトを返します。

00:24:44.000 --> 00:24:49.000
メッシュの大きさを知るためにメッシュを分析したので、スパイラルメッシュの作成方法を見てみましょう。

00:24:49.000 --> 00:24:52.000
スパイラルは動的に生成されたメッシュです。

00:24:52.000 --> 00:24:57.000
このメッシュを作成するには、RealityKitにデータを記述する必要があります。

00:24:57.000 --> 00:24:59.000
メッシュ記述子でこれを行います。

00:24:59.000 --> 00:25:06.000
メッシュ記述子には、位置、法線、テクスチャ座標、プリミティブ、およびマテリアルインデックスが含まれています。

00:25:06.000 --> 00:25:09.000
メッシュ記述子があれば、メッシュリソースを生成できます。

00:25:09.000 --> 00:25:14.000
これは、メッシュを最適化するRealityKitのメッシュプロセッサを呼び出します。

00:25:14.000 --> 00:25:23.000
重複した頂点をマージし、クワッドとポリゴンを三角測量し、レンダリングのための最も効率的な形式でメッシュを表現します。

00:25:23.000 --> 00:25:28.000
この処理の結果、エンティティに割り当てることができるメッシュリソースが得られます。

00:25:28.000 --> 00:25:32.000
法線、テクスチャ座標、およびマテリアルはオプションであることに注意してください。

00:25:32.000 --> 00:25:37.000
当社のメッシュプロセッサは、自動的に正しい法線を生成し、それらを入力します。

00:25:37.000 --> 00:25:43.000
最適化プロセスの一環として、RealityKitはメッシュのトポロジを再生成します。

00:25:43.000 --> 00:25:48.000
特定のトポロジが必要な場合は、MeshResource.Contentsを直接使用できます。

00:25:48.000 --> 00:25:52.000
メッシュの作成方法がわかったので、スパイラルを作成する方法を見てみましょう。

00:25:52.000 --> 00:25:58.000
スパイラルをモデル化するために、セクションを詳しく見てみましょう。

00:25:58.000 --> 00:26:01.000
スパイラルはらせんとも呼ばれます。

00:26:01.000 --> 00:26:04.000
これを均等に間隔をあけたセグメントで構築します。

00:26:04.000 --> 00:26:12.000
らせんの数学的定義と分析されたメッシュの半径を使用して、各点を計算できます。

00:26:12.000 --> 00:26:17.000
らせん上の各セグメントにこの関数を使用して、4つの頂点を定義できます。

00:26:17.000 --> 00:26:21.000
P0 と P1 はまさに p() が返す値です。

00:26:21.000 --> 00:26:28.000
P2とP3を計算するには、与えられた厚さでP0とP1を垂直にオフセットすることができます。

00:26:28.000 --> 00:26:31.000
三角形を作っているので、対角線が必要です。

00:26:31.000 --> 00:26:34.000
これらの点を使って2つの三角形を作ります。

00:26:34.000 --> 00:26:37.000
すべてをまとめる時間です。

00:26:37.000 --> 00:26:41.000
当社のgenerateSpiral関数は、ポジションとインデックスを保存する必要があります。

00:26:41.000 --> 00:26:44.000
インデックスは、ポジションの値を参照します。

00:26:44.000 --> 00:26:53.000
セグメントごとに、4つの位置を計算し、そのインデックスを保存します。i0は、配列に追加されたp0のインデックスです。

00:26:53.000 --> 00:26:59.000
次に、2つの三角形の4つの位置と6つのインデックスを配列に追加します。

00:26:59.000 --> 00:27:03.000
ジオメトリを取得したら、メッシュの作成は簡単です。

00:27:03.000 --> 00:27:06.000
まず、新しいMeshDescriptorを作成します。

00:27:06.000 --> 00:27:08.000
次に、位置とプリミティブを割り当てます。

00:27:08.000 --> 00:27:13.000
三角形のプリミティブを使用していますが、クワッドやポリゴンを選択することもできます。

00:27:13.000 --> 00:27:17.000
これら2つのフィールドが入力されると、MeshResourceを生成するのに十分です。

00:27:17.000 --> 00:27:24.000
法線、テクスチャ座標、マテリアル割り当てなど、他の頂点属性を提供することもできます。

00:27:24.000 --> 00:27:26.000
メッシュの作成方法を取り上げました。

00:27:26.000 --> 00:27:30.000
私たちのスパイラルの例の最後のものは、メッシュの更新です。

00:27:30.000 --> 00:27:34.000
メッシュの更新を使用して、スパイラルを取得してダイバーの周りを移動します。

00:27:34.000 --> 00:27:37.000
メッシュを更新するには、2つの方法があります。

00:27:37.000 --> 00:27:42.000
MeshDescriptors APIを使用して、各フレームに新しいMeshResourceを作成できます。

00:27:42.000 --> 00:27:48.000
しかし、これは各フレームのメッシュオプティマイザを通過するため、効率的なルートではありません。

00:27:48.000 --> 00:27:52.000
より効率的なルートは、MeshResourceの内容を更新することです。

00:27:52.000 --> 00:27:56.000
新しいMeshContentsを生成し、それを使用してメッシュを置き換えることができます。

00:27:56.000 --> 00:27:58.000
しかし、注意点が1つあります。

00:27:58.000 --> 00:28:05.000
MeshDescriptorを使用してオリジナルのメッシュを作成した場合、RealityKitのメッシュプロセッサはデータを最適化します。

00:28:05.000 --> 00:28:08.000
トポロジーも三角形に縮小されます。

00:28:08.000 --> 00:28:14.000
その結果、更新を適用する前に、メッシュがどのように影響を受けるかを確認してください。

00:28:14.000 --> 00:28:17.000
スパイラルを更新する方法のコードを見てみましょう。

00:28:17.000 --> 00:28:21.000
既存のスパイラルの内容を格納することから始めます。

00:28:21.000 --> 00:28:24.000
既存のモデルから新しいモデルを作成します。

00:28:24.000 --> 00:28:29.000
次に、各部分について、triangleIndicesをインデックスのサブセットに置き換えます。

00:28:29.000 --> 00:28:34.000
最後に、新しいコンテンツでは、既存のMeshResourceの置き換えを呼び出すことができます。

00:28:34.000 --> 00:28:36.000
そして、それはダイナミックメッシュのためのものです。

00:28:36.000 --> 00:28:43.000
動的メッシュに関する重要なことを要約するために、MeshResourceに新しいコンテンツフィールドを導入しました。

00:28:43.000 --> 00:28:48.000
このコンテナを使用すると、メッシュの生データを検査および変更できます。

00:28:48.000 --> 00:28:50.000
MeshDescriptorを使用して新しいメッシュを作成できます。

00:28:50.000 --> 00:28:59.000
この柔軟なルートでは、三角形、クワッド、さらにはポリゴンを使用でき、RealityKitはレンダリング用に最適化されたメッシュを生成します。

00:28:59.000 --> 00:29:07.000
最後に、メッシュを更新するために、MeshResourceのコンテンツを更新する機能を提供しました。これは、頻繁な更新に最適です。

00:29:07.000 --> 00:29:13.000
最後に、今日はRealityKit 2の新しいレンダリング機能のいくつかを披露しました。

00:29:13.000 --> 00:29:17.000
ジオメトリ修飾子を使用すると、頂点を移動および変更できます。

00:29:17.000 --> 00:29:21.000
サーフェスシェーダーを使用すると、モデルの表面の外観を定義できます。

00:29:21.000 --> 00:29:31.000
ポストエフェクトを使用して最終的なフレームにエフェクトを適用でき、ダイナミックメッシュを使用すると、実行時にメッシュを簡単に作成および変更できます。

00:29:31.000 --> 00:29:36.000
今年の機能をもっと見るには、「Dive into RealityKit 2」をお見逃しなく。

00:29:36.000 --> 00:29:41.000
また、RealityKitの詳細については、「RealityKitでアプリを構築する」をご覧ください。

00:29:41.000 --> 00:29:46.000
私たちは今年のリリースに非常に興奮しており、あなたがそれで構築する経験を見るのが待ちきれません。

00:29:46.000 --> 00:29:47.000
ありがとうございます。

00:29:47.000 --> 23:59:59.000
♪

