WEBVTT

00:00:02.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:11.000
こんにちは、私の名前はロイです。

00:00:11.000 --> 00:00:13.000
私はカメラソフトウェアチームのエンジニアです。

00:00:13.000 --> 00:00:24.000
今日は、最も人気のあるビデオフォーマットで行ったエキサイティングな写真品質の改善と、アプリケーションがそれらを利用してさらに優れた体験を提供する方法について説明します。

00:00:24.000 --> 00:00:38.000
iPhoneは世界で最も人気のあるカメラであり、長年にわたり、開発者は強力なカメラシステムを活用して、プロの写真アプリからビデオストリーミングツールまで、多様な世界クラスの体験を提供してきました。

00:00:38.000 --> 00:00:41.000
異なるシナリオでは、異なるレベルの写真品質が必要です。

00:00:41.000 --> 00:00:48.000
たとえば、静止画の撮影専用のアプリは、カメラが提供できる絶対的な最高の品質を要求します。

00:00:48.000 --> 00:00:54.000
一方、ソーシャルアプリは、ストリーミングされるビデオフレームの上にフェイスエフェクトオーバーレイを適用する必要があるかもしれません。

00:00:54.000 --> 00:00:58.000
そして、このカスタムレンダリングは計算コストがかかるかもしれません。

00:00:58.000 --> 00:01:05.000
フレームのドロップを避けるために、開発者は低解像度のフレームを好むかもしれないので、フレームごとに処理するピクセルが少なくなります。

00:01:05.000 --> 00:01:13.000
ユースケースのこの多様性は、品質とパフォーマンスの規模で着地したい場所を指定する簡単な方法を必要とします。

00:01:13.000 --> 00:01:19.000
しかし、写真の品質に飛び込む前に、一般的にiOSで写真がどのように撮影されるかについて簡単に復習しましょう。

00:01:19.000 --> 00:01:25.000
AVCaptureSessionオブジェクトから始めて、その周りにオブジェクトグラフを作成できます。

00:01:25.000 --> 00:01:29.000
写真を撮っているので、AVCaptureDeviceとしてカメラを使用します。

00:01:29.000 --> 00:01:38.000
次に、AVCaptureDeviceInputがそのデバイスに基づいてインスタンス化され、セッションに入力データを提供します。

00:01:38.000 --> 00:01:44.000
その後、AVCapturePhotoOutputが写真の受信者としてグラフに追加されます。

00:01:44.000 --> 00:01:49.000
そして、これらの要素はすべて、AVCaptureConnectionを使用して一緒に接続されます。

00:01:49.000 --> 00:01:57.000
セッションの実行が開始されたら、AVCapturePhotoOutputインスタンスでcapturePhotoメソッドを呼び出すことで写真をキャプチャできます。

00:01:57.000 --> 00:02:04.000
さらなるカスタマイズは、capturePhotoメソッドに渡されたAVCapturePhotoSettingsオブジェクトを使用して行うことができます。

00:02:04.000 --> 00:02:11.000
キャプチャされた写真は、デリゲートメソッドで受け取るAVCapturePhotoオブジェクトとして表されます。

00:02:11.000 --> 00:02:18.000
2016年のセッション「iOS写真の進歩」で、これらのAPIについて非常に詳細な議論を行いました。

00:02:18.000 --> 00:02:21.000
まだチェックしていない場合は、チェックしてください。

00:02:21.000 --> 00:02:27.000
iOSで一般的に写真を撮る方法がわかったので、高品質の写真がどのように撮れるか見てみましょう。

00:02:27.000 --> 00:02:42.000
歴史的に、可能な限り最高の品質の写真をキャプチャしたい場合は、AVCapturePhotoSettingsのisAutoStillImageStabilization Enabledプロパティをtrueに設定します。これは、静止画像の安定化が高品質の写真を得るための主な方法だったためです。

00:02:42.000 --> 00:02:48.000
しかし、長年にわたり、私たちは写真の品質向上アルゴリズムを継続的に進化させてきました。

00:02:48.000 --> 00:02:59.000
静止画安定化に加えて、スマートHDRやディープフュージョンなど、さまざまなマルチ画像融合技術など、はるかに豊富な技術が手ぶれています。

00:02:59.000 --> 00:03:07.000
その結果、AutoStillImageStabilization Enabledという名前は、高画質のプロキシとしてかなり時代遅れになっています。

00:03:07.000 --> 00:03:14.000
この問題を解決するために、iOS 13ではAVCapturePhotoOutput.QualityPrio ritizationを導入しました。

00:03:14.000 --> 00:03:20.000
写真撮影の品質に優先順位を付ける方法をAVCapturePhotoOutputに伝えるのはとても簡単な方法です。

00:03:20.000 --> 00:03:28.000
以前のWWDCでは、この重要なAPIについて話す機会がなかったので、少し時間を取って、それがどのように機能するかを見てみましょう。

00:03:28.000 --> 00:03:34.000
速度、バランス、品質の3つの品質優先順位付けレベルから選択できます。

00:03:34.000 --> 00:03:42.000
スピードでは、写真の品質を犠牲にしても、キャプチャの速度が最も気にかけていることをフレームワークに伝えています。

00:03:42.000 --> 00:03:48.000
写真の品質と配信速度のバランスを取る必要がある場合は、バランスを取る必要があります。

00:03:48.000 --> 00:03:50.000
品質はスピードとは正反対です。

00:03:50.000 --> 00:03:58.000
キャプチャプロセスの潜在的な遅さは許容されるが、画質は何よりも優先されるべきであると述べている。

00:03:58.000 --> 00:04:08.000
指定された品質の優先順位付けは、AVCapturePhotoOutputのヒントとしてのみ機能し、使用するアルゴリズムを指示しないことに注意してください。

00:04:08.000 --> 00:04:16.000
最終的に、AVCapturePhotoOutputはさまざまな制約を考慮し、現在のシーンに最も適したアルゴリズムを選択します。

00:04:16.000 --> 00:04:22.000
たとえば、薄暗い状況では、明るい空間とは異なる方法を選択するかもしれません。

00:04:22.000 --> 00:04:29.000
そうは言っても、異なるキャプチャ期間に基づいて、ユーザーエクスペリエンスを異なる方法で計画したいと思うかもしれないことを理解しています。

00:04:29.000 --> 00:04:43.000
したがって、AVCapturePhotoOutputDelegateメソッドの一部に渡されたAVCaptureResolvedPhotoSettingsオブジェクトでは、写真をデリゲートに配信するのにかかる時間を示すphotoProcessingTimeRangeというプロパティを提供します。

00:04:43.000 --> 00:04:49.000
これは、たとえば、キャプチャに時間がかかる場合、スピナーを出すかどうかを判断するのに役立ちます。

00:04:49.000 --> 00:04:51.000
コードでどのように機能するか見てみましょう。

00:04:51.000 --> 00:04:59.000
AVCapturePhotoOutputを設定するときは、特定のキャプチャセッションで必要とされる最大品質の優先順位付けを指定できます。

00:04:59.000 --> 00:05:02.000
そうしないことを選択した場合、デフォルト値はバランスが取れています。

00:05:02.000 --> 00:05:04.000
これは一度だけ設定する必要があります。

00:05:04.000 --> 00:05:11.000
そうすることの重要性は、異なる設定に応じて、キャプチャパイプラインを異なる方法で設定することです。

00:05:11.000 --> 00:05:21.000
たとえば、速度の優先順位付けを超えないことがわかっている場合は、バランスの取れた優先順位付けよりもはるかに少ないメモリと電力を消費するキャプチャパイプラインを構築できます。

00:05:21.000 --> 00:05:26.000
そのため、責任を持って選択し、必要なものだけを取ることをお勧めします。

00:05:26.000 --> 00:05:37.000
capturePhotoメソッドを呼び出す前に、AVCapturePhotoSettingsオブジェクトにphotoQualityPrioritizationプロパティを設定することで、この特定のキャプチャの品質優先順位付けをカスタマイズできます。

00:05:37.000 --> 00:05:39.000
デフォルト値はバランスが取れています。

00:05:39.000 --> 00:05:44.000
ここで示されているように、私たちは2つの異なる状況で2つの異なるレベルを使用しています。

00:05:44.000 --> 00:05:54.000
キャプチャごとの品質の優先順位付けは、AVCapturePhotoOutputの最大品質の優先順位付けを超えることはできません。そうしないと、例外が発生します。

00:05:54.000 --> 00:06:00.000
3つのレベルのパフォーマンス特性は、使用する基礎となるアルゴリズムによって決定されます。

00:06:00.000 --> 00:06:08.000
マッピングは使用するフォーマットの種類によって異なり、写真とビデオフォーマットの違いについて少し説明します。

00:06:08.000 --> 00:06:18.000
写真フォーマットでは、スピードはWYSIWYG写真を取得します--それはあなたが見るものはあなたが得るものです写真です--これは、いくつかのノイズリダクションが適用された場合にのみ軽く処理されます。

00:06:18.000 --> 00:06:28.000
Balancedが指定されている場合は、やや遅いキャプチャレートでWYSIWYG写真よりもはるかに優れた写真品質を生成する高速融合アルゴリズムのコレクションから選択します。

00:06:28.000 --> 00:06:38.000
品質については、現在のデバイスとルクスレベルに応じて、フレームワークは可能な限り最高の写真品質を提供するために、ディープフュージョンなどのいくつかの重い機械を使用します。

00:06:38.000 --> 00:06:41.000
写真は素晴らしく見えますが、無料のランチはありません。

00:06:41.000 --> 00:06:43.000
あなたはより多くの時間を使ってそれを支払います。

00:06:43.000 --> 00:06:50.000
一方、ビデオフォーマットの場合、すべてのレベルは、可能な限り迅速に写真を配信するために最も軽い処理を使用します。

00:06:50.000 --> 00:06:53.000
私たちはしばらくの間、写真やビデオのフォーマットについて話してきました。

00:06:53.000 --> 00:06:56.000
それらの違いを詳しく見てみましょう。

00:06:56.000 --> 00:07:02.000
写真フォーマットを使用することで、静止画を撮ることが最も気にかけていることがフレームワークに合図されます。

00:07:02.000 --> 00:07:20.000
たとえば、AVCaptureVideoDataOutputを写真形式で使用している場合、デフォルトで取得するサンプルバッファはプレビュー解像度のみになります。これは、写真を撮ることが最優先事項であることを知っているため、これらのフレームはビデオ録画ではなくプレビューに使用されると仮定できます。

00:07:20.000 --> 00:07:30.000
写真フォーマットを選択する正当な理由は、いくつかの写真中心の機能が、Live PhotoやProRAWなどの写真フォーマット専用であることです。

00:07:30.000 --> 00:07:34.000
それがあなたがやりたいことなら、写真フォーマットが進むべき道です。

00:07:34.000 --> 00:07:41.000
写真フォーマットには利用可能な最高の解像度が付属していますが、フレームレートは毎秒30フレームに制限されています。

00:07:41.000 --> 00:07:44.000
写真のフォーマットを選択するには、セッションのプリセットを写真に設定できます。

00:07:44.000 --> 00:07:49.000
または、isHighestPhotoQualitySupportedがtrueであるフォーマットを選択することもできます。

00:07:49.000 --> 00:07:55.000
一方、ビデオフォーマットの使用は、経験がビデオを中心にすることを示しています。

00:07:55.000 --> 00:08:02.000
録画やストリーミングに適した解像度を取得し、60fpsなどの高いフレームレートを使用できるようになります。

00:08:02.000 --> 00:08:07.000
フォーマットが写真フォーマットでない場合、それはビデオフォーマットと見なされます。

00:08:07.000 --> 00:08:14.000
したがって、写真以外のセッションプリセットを使用するか、isHighestPhotoQualitySupportedがfalseであるフォーマットを選択することで、1つを選択できます。

00:08:14.000 --> 00:08:19.000
なぜ強力なアルゴリズムのいくつかをビデオフォーマットに適用していないのか疑問に思うかもしれません。

00:08:19.000 --> 00:08:20.000
それは私たちが怠け者だからではありません。

00:08:20.000 --> 00:08:22.000
それには正当な理由があります。

00:08:22.000 --> 00:08:32.000
多くのアプリは、重いカスタム処理を行う必要があるため、ビデオフォーマットを使用することを選択し、ビデオフォーマットはオーバーヘッドが低いため、この目的に適しています。

00:08:32.000 --> 00:08:39.000
前述の写真強化技術のいくつかを活用すれば、これらのアプリの体験に劣化をもたらす可能性があります。

00:08:39.000 --> 00:08:46.000
たとえば、ARアプリを使用すると、ユーザーが操作している3Dシーンの写真を撮ることができます。

00:08:46.000 --> 00:08:54.000
この時点で既存のフュージョンアルゴリズムを実行すると、アプリのカメラフィードにフレームドロップが導入され、コア機能が中断される可能性があります。

00:08:54.000 --> 00:09:05.000
そのため、品質とスピードの微妙なバランスを非常に意識しており、最も厳しい条件下でも反応して動作するようにビデオフォーマットを設計しました。

00:09:05.000 --> 00:09:08.000
しかし、これらの妥協はiOS 15で今日停止します。

00:09:08.000 --> 00:09:13.000
私たちは、最も人気のあるビデオフォーマットで写真品質に大きな飛躍を遂げています。

00:09:13.000 --> 00:09:21.000
いくつかの改良されたアルゴリズムにより、アプリのエクスペリエンスの他の側面に影響を与えることなく、写真の品質を根本的に改善できるようになりました。

00:09:21.000 --> 00:09:31.000
この新機能により、アプリは洗練されたカスタム計算を実行するための同じ柔軟性を維持しながら、素晴らしい写真を撮ることができます。

00:09:31.000 --> 00:09:34.000
では、ここでどれだけ大きな品質の飛躍について話しているのでしょうか？

00:09:34.000 --> 00:09:39.000
前後の比較を見てみましょう。 比較後の比較を見てみましょう。

00:09:39.000 --> 00:09:41.000
改善はかなり大きいです。

00:09:41.000 --> 00:09:46.000
右側の小さな男の子の顔は騒音がはるかに少ないので、はるかに自然に見えます。

00:09:46.000 --> 00:09:52.000
そして、私たちは彼の髪から出てくる光をよりよく知覚することができます。

00:09:52.000 --> 00:09:59.000
被写体の目のキャッチライトは、単により鮮やかで活発です。

00:09:59.000 --> 00:10:05.000
この屋外の低照度の状況では、彼女の顔と服に優れたノイズ除去があります。

00:10:05.000 --> 00:10:08.000
最後に、環境も良く見えます。

00:10:08.000 --> 00:10:13.000
椅子の革の質感ははるかによく保存されています。

00:10:13.000 --> 00:10:19.000
魅了されたので、サポートされているビデオフォーマットのアルゴリズムマッピングを見てみましょう。

00:10:19.000 --> 00:10:23.000
スピードは、まだあなたに軽く処理されたWYSIWYG写真を取得します。

00:10:23.000 --> 00:10:30.000
彼らはまだ写真を取得する最速の方法であり、スピードが今あなたの最優先事項であるため、これは法案に完全に適合するので、私たちはそれを変更しませんでした。

00:10:30.000 --> 00:10:37.000
ビデオ録画のフレームドロップやプレビューフィードの中断は得られないでしょう。

00:10:37.000 --> 00:10:45.000
しかし、Balancedを使用すると、品質が大幅に向上しますが、写真の処理時間がわずかに増加するだけです。

00:10:45.000 --> 00:10:49.000
そして、スピードと同じように、ビデオ録画にはフレームドロップはありません。

00:10:49.000 --> 00:10:54.000
それらの見栄えの良い写真が撮影され、処理されても、プレビューフィードは中断されません。

00:10:54.000 --> 00:10:59.000
最後に、品質のために、私たちはさらに優れた品質を得るために、より高価なアルゴリズムを実行しています。

00:10:59.000 --> 00:11:04.000
これにより、デバイスの最新さに応じて、フレームがドロップされたり、プレビューフィードが中断されたりする可能性があります。

00:11:04.000 --> 00:11:10.000
この機能は、iPhone XSまでサポートされているすべてのiPhoneで利用できます。

00:11:10.000 --> 00:11:20.000
このアップグレードを受けているビデオフォーマットは、最も人気のあるものです:毎秒30フレームと60フレームの両方をサポートする1280x720。

00:11:20.000 --> 00:11:24.000
1920x1080、また30fpsと60fpsの両方。

00:11:24.000 --> 00:11:28.000
1920x1440、30fps。

00:11:28.000 --> 00:11:32.000
また、30fpsの4Kのサポートも追加しました。

00:11:32.000 --> 00:11:35.000
では、コードで正しいフォーマットを使用していることを確認するにはどうすればよいですか?

00:11:35.000 --> 00:11:37.000
それはとても簡単です。

00:11:37.000 --> 00:11:44.000
iOS 15では、AVCaptureDevice.FormatタイプにisHighPhotoQualitySupportedという新しいプロパティを導入しています。

00:11:44.000 --> 00:11:48.000
この機能をサポートするフォーマットでは、このプロパティはtrueになります。

00:11:48.000 --> 00:11:57.000
このプロパティが真である任意のフォーマットは、ビデオフォーマットであることが保証されているので、誤って写真のフォーマットを選ぶことを心配する必要はありません。

00:11:57.000 --> 00:12:00.000
そのようなフォーマットを手に入れたいとしましょう。

00:12:00.000 --> 00:12:04.000
AVCaptureDeviceインスタンスで利用可能なフォーマットを入手するだけです。

00:12:04.000 --> 00:12:09.000
次に、isHighPhotoQualitySupportedがtrueであるものを選択してください。

00:12:09.000 --> 00:12:12.000
この機能を使用するようにサンプルコードAVCamを更新しました。

00:12:12.000 --> 00:12:16.000
実用的な例を見たい場合は、それをチェックしてください。

00:12:16.000 --> 00:12:24.000
新しいプロパティisHighPhotoQualitySupportedと既存のisHighestPhotoQualitySupportedを混同する可能性があります。

00:12:24.000 --> 00:12:32.000
先に述べたように、後者はフォーマットが写真フォーマットであるかどうかを教えてくれ、ビデオフォーマットが高写真品質をサポートしているかどうかは教えてくれません。

00:12:32.000 --> 00:12:36.000
さて、この新機能を取得するには、何か作業を行う必要がありますか?

00:12:36.000 --> 00:12:38.000
答えは多分です。

00:12:38.000 --> 00:12:48.000
すでにAVCapturePhotoOutputと.balanced優先順位付けを使用している場合は、おめでとうございます。iOS 15で自動的に見栄えの良い写真を取得します。

00:12:48.000 --> 00:12:57.000
アプリが速度の優先順位付けを使用している場合は、バランスに更新するだけで、フレームのドロップを心配することなく、より良い写真を受け取ることができます。

00:12:57.000 --> 00:13:05.000
非推奨のAVCaptureStillImageOutputをまだ使用している場合は、これが切り替える大きなインセンティブを与えることを願っています。

00:13:05.000 --> 00:13:14.000
現在、品質の優先順位付けを使用すると、ビデオにフレームドロップが発生する可能性があるため、オプトインせずにアプリに新しい動作を課したくありません。

00:13:14.000 --> 00:13:25.000
そのため、リンク時間チェックを入れて、アプリがビデオ形式で品質の優先順位付けを使用していて、iOS 15より前にコンパイルされている場合は、自動的にバランスの取れたものに変更します。

00:13:25.000 --> 00:13:33.000
本当に最高の品質を手に入れたい場合は、iOS 15 SDKでアプリを再コンパイルするだけです。

00:13:33.000 --> 00:13:36.000
注意すべき点がいくつかあります。注意点があります。

00:13:36.000 --> 00:13:43.000
この機能は現在、AVCaptureSessionでのみ動作し、AVCaptureMultiCamSessionでは動作しません。

00:13:43.000 --> 00:13:48.000
非推奨のAVCaptureStillImageOutputは、この機能をサポートしません。

00:13:48.000 --> 00:13:57.000
.Balancedまたは.quality優先順位付けを使用している場合、使用するアルゴリズムのいくつかは、ダイナミックレンジを改善するために、いくつかの異なる露出画像を融合させる可能性があります。

00:13:57.000 --> 00:14:03.000
写真は素晴らしい品質ですが、同時に録画されるビデオとは違って見えるかもしれません。

00:14:03.000 --> 00:14:07.000
ビデオと写真がまったく同じに見えるようにする必要がある場合は、代わりに.speedを使用してください。

00:14:07.000 --> 00:14:11.000
最後に、今取り上げたことをまとめましょう。

00:14:11.000 --> 00:14:18.000
アプリのエクスペリエンスを設計するときは、品質とスピードのどちらかを選択する決定に注意してください。

00:14:18.000 --> 00:14:24.000
ユースケースで写真の品質が果たす役割を理解したら、それを達成するために適切な優先順位付けレベルを使用してください。

00:14:24.000 --> 00:14:31.000
そして、最小限の作業で、時にはまったく作業なしで、あなたは今、ビデオフォーマットで素晴らしい写真を得るでしょう。

00:14:31.000 --> 00:14:32.000
どうもありがとうございます。

00:14:32.000 --> 23:59:59.000
[パーカッシブミュージック]。

