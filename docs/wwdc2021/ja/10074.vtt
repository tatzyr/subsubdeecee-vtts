WEBVTT

00:00:00.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:13.000
こんにちは。私はアマンダで、同僚のオリヴィエが少し加わります。

00:00:13.000 --> 00:00:18.000
この講演では、2021年にRealityKitに追加した機能について説明します。

00:00:18.000 --> 00:00:27.000
RealityKitは、2019年に導入された拡張現実オーサリングフレームワークで、現実的なレンダリングに焦点を当て、ARアプリを簡単に作成できます。

00:00:27.000 --> 00:00:38.000
ARKitを活用してデバイスのセンサーデータを読み取り、RealityKitを使用すると、3Dコンテンツを現実世界の環境に配置し、そのコンテンツをできるだけリアルに見せることができます。

00:00:38.000 --> 00:00:42.000
実際のRealityKit体験の素晴らしい例をいくつか紹介します。

00:00:42.000 --> 00:00:52.000
現実世界でスカベンジャーハントに行き、事実上あなたの友人に対してボウリングし、博物館で彫刻になり、いくつかのカラフルなバグを見つけます。

00:00:52.000 --> 00:01:01.000
過去数年間、私たちはRealityKitで作成されたいくつかの素晴らしいアプリを見て、このフレームワークをさらに良くするために本当に良いフィードバックを受けました。

00:01:01.000 --> 00:01:03.000
そして、私たちはあなたのフィードバックに耳を傾けました。

00:01:03.000 --> 00:01:10.000
RealityKit 2は、さらに没入感のあるARアプリやゲームを作るのに役立つ多くの新機能を導入していることを共有できることを嬉しく思います。

00:01:10.000 --> 00:01:21.000
このセッションでは、カスタムシェーダーやマテリアル、カスタムシステム、新しいキャラクターコントローラーのコンセプトなど、最も要求された機能など、それらのいくつかを強調します。

00:01:21.000 --> 00:01:25.000
だから、シュノーケルマスクを着用して、飛び込みましょう。

00:01:25.000 --> 00:01:30.000
中東で育ったとき、私は湾岸でスキューバダイビングを学びました。

00:01:30.000 --> 00:01:36.000
私はこれらの超かわいいスチームパンクヘルメットの1つを着用することはできませんでしたが、私はすべてのカラフルな魚のスクーリングを見るのが大好きでした。

00:01:36.000 --> 00:01:41.000
私のリビングルームでその水中の雰囲気を再現するのは楽しいかもしれないと思いました。

00:01:41.000 --> 00:01:49.000
オリヴィエと私は、このセッションと今週後半の2回目のRealityKitセッションで紹介する多くの機能を使って、このデモを書きました。

00:01:49.000 --> 00:01:59.000
私たちは、深霧効果と水苛材を作成するための後処理、海藻を波の中で踊らせるためのカスタムジオメトリ修飾子などを持っています。

00:01:59.000 --> 00:02:04.000
基本的に、RealityKit 2では、今では非常に多くのものをカスタマイズできます。

00:02:04.000 --> 00:02:09.000
このサンプルコードは、developer.apple.comで試すことができます。

00:02:09.000 --> 00:02:12.000
今日取り上げる5つの主要なトピックがあります。

00:02:12.000 --> 00:02:20.000
ECSとは何か、新しいカスタムシステム機能を使用して、アプリで魚の群れ行動を実装する方法についてまとめを行います。

00:02:20.000 --> 00:02:36.000
素材やアニメーション、新しいキャラクターコントローラーでできることの進歩を紹介します。これは、ダイバーがリビングルームのARメッシュとシームレスに対話できるようにし、実行時にリソースを生成する方法を紹介します。

00:02:36.000 --> 00:02:38.000
では、ECSから始めましょう。

00:02:38.000 --> 00:02:47.000
ECSは、エンティティコンポーネントシステムの略で、データと動作を構造化する方法であり、ゲームやシミュレーションで一般的に使用されています。

00:02:47.000 --> 00:02:57.000
これは、アイテムの機能と、そのアイテムに関連する状態の両方のカプセル化されたバンドルとしてモデル化する傾向があるオブジェクト指向プログラミングとは異なります。

00:02:57.000 --> 00:03:11.000
しかし、ECSでは、エンティティ、コンポーネント、システムの3つのプロングがあり、機能はシステムに入り、状態はコンポーネントに入り、エンティティはコンポーネントのグループの識別子です。

00:03:11.000 --> 00:03:22.000
今年は、RealityKit 2で、より純粋なECS実装に移行し、新しいカスタムシステムでシステムレイヤーでより多くの機能を維持するように導きます。

00:03:22.000 --> 00:03:24.000
エンティティは私たちにとって何を意味しますか?

00:03:24.000 --> 00:03:28.000
エンティティは、あなたのシーンで1つのことを表します。

00:03:28.000 --> 00:03:31.000
ここに私たちのシーンで海の生き物を表すエンティティがあります。

00:03:31.000 --> 00:03:35.000
エンティティは子エンティティを持つことができ、作業するグラフ構造を提供します。

00:03:35.000 --> 00:03:42.000
たとえば、変換コンポーネントは、親エンティティの変換を使用して独自の位置を追加します。

00:03:42.000 --> 00:03:46.000
エンティティ自体は画面上に何もレンダリングしません。

00:03:46.000 --> 00:03:51.000
そのために、モデルコンポーネントを与えるか、モデルエンティティを作成する必要があります。

00:03:51.000 --> 00:03:56.000
属性、プロパティ、および動作を追加するには、エンティティにコンポーネントを追加します。

00:03:56.000 --> 00:04:00.000
そういえば、コンポーネントについて話しましょう。

00:04:00.000 --> 00:04:06.000
コンポーネントは、フレーム間に状態を保存し、エンティティのシステムへの参加をマークするためのものです。

00:04:06.000 --> 00:04:10.000
ただし、ここではその状態に対処するためのロジックを含める必要はありません。

00:04:10.000 --> 00:04:14.000
あなたの論理と行動は、あなたのカスタムシステムに行きます。

00:04:14.000 --> 00:04:18.000
作成したエンティティにすでに存在するコンポーネントがいくつかあります。

00:04:18.000 --> 00:04:24.000
ここに示されていないのは、組み込みコンポーネントです。変換コンポーネントと同期コンポーネントです。

00:04:24.000 --> 00:04:26.000
彼らはこれらの3つのエンティティすべてにいます。

00:04:26.000 --> 00:04:34.000
エンティティを画面に表示させるメッシュと素材を含むモデルコンポーネントなど、頻繁に追加したいものが他にもあります。

00:04:34.000 --> 00:04:41.000
動作を動的に変更したい場合は、実行時にエンティティからコンポーネントを追加および削除することもできます。

00:04:41.000 --> 00:04:47.000
この最初の魚を群れシステムに参加しているとマークし、藻類を食べるのが好きだと伝えます。

00:04:47.000 --> 00:04:53.000
この2番目の魚は、最初の魚と一緒に群がるつもりですが、今はプランクトンを食べることを好みます。

00:04:53.000 --> 00:04:55.000
この3人目の男はプランクトンです。

00:04:55.000 --> 00:04:57.000
それは2番目の魚の餌になります。

00:04:57.000 --> 00:05:02.000
私たちのアプリには、いくつかの空腹の生き物がいるので、それはその背中を見るべきです。

00:05:02.000 --> 00:05:07.000
AlgaeEaterまたはPlanktonEaterのコンポーネントが載っているので、どれが空腹か知っています。

00:05:07.000 --> 00:05:11.000
すべてのフレーム、私たちの食事システムには更新機能があります。

00:05:11.000 --> 00:05:22.000
ここでは、これらのコンポーネントのいずれかを持つシーン内のすべてのエンティティに加えて、食べ物であるすべてのエンティティを見つけるので、空腹の魚を彼らが好む食べ物に導くことができます。

00:05:22.000 --> 00:05:30.000
しかし、食事システムがどのエンティティが空腹であるか、どのエンティティが食べ物であり、どのエンティティがどちらでもないかを把握するためのパフォーマンスの高い方法は何ですか?

00:05:30.000 --> 00:05:35.000
エンティティグラフを横断して、それぞれのコンポーネントをチェックしたくありません。

00:05:35.000 --> 00:05:38.000
代わりに、エンティティクエリを実行します。

00:05:38.000 --> 00:05:41.000
RealityKitに簿記をさせてください。

00:05:41.000 --> 00:05:46.000
Flocking Systemは、FlockingComponentを持つすべてのエンティティを見つけたいと考えています。

00:05:46.000 --> 00:05:53.000
食事システムは、両方の種類の空腹のエンティティに加えて、食品の一種であるエンティティを望んでいます。

00:05:53.000 --> 00:05:58.000
それでは、システムがエンティティクエリを使用するときに正確に何が起こっているのかを詳しく見てみましょう。

00:05:58.000 --> 00:06:03.000
システムには、すべてのフレームと呼ばれる更新機能があります。

00:06:03.000 --> 00:06:05.000
黄色い唐の魚のフロックシステムを見てみましょう。

00:06:05.000 --> 00:06:09.000
このフレームで一時停止して、何が起こっているのかを確認します。

00:06:09.000 --> 00:06:18.000
Flocking Systemの更新機能では、FlockingComponentとMotionComponentの両方を持つシーン内のすべてのエンティティを照会します。

00:06:18.000 --> 00:06:24.000
多くのものにはMotionComponentがありますが、私たちはそれらのすべてを望んでいません、私たちはただ私たちの群れが欲しいだけです。

00:06:24.000 --> 00:06:32.000
私たちのクエリは群がる魚を返すので、今、私たちは群れの各魚に古典的なBoidsシミュレーションを適用することによって、私たちのカスタムゲーム物理学を駆動することができます。

00:06:32.000 --> 00:06:46.000
私たちは、各魚のMotionComponentに力を追加し、フレームの間に状態を保ち、一緒に固執し、一定の距離を保つことを好む力、鼻を同じ方向に向けようとします。

00:06:46.000 --> 00:06:57.000
モーションシステムが実行されると、同じフレームで、フロッキングシステムが実行された後、これらすべての力をロールアップして、魚の新しい加速度、速度、位置を決定します。

00:06:57.000 --> 00:06:59.000
他のどのシステムがそれらを追加したかは気にしません。

00:06:59.000 --> 00:07:07.000
食事システムや恐怖システムなど、モーションコンポーネントで動作して魚をさまざまな方向にプッシュするものもあります。

00:07:07.000 --> 00:07:10.000
では、コードを見てみましょう。

00:07:10.000 --> 00:07:13.000
これが私たちのフロッキングシステムの概要です。

00:07:13.000 --> 00:07:18.000
RealityKit.Systemプロトコルに準拠したクラスです。

00:07:18.000 --> 00:07:26.000
アプリの起動時にカスタムシステムを登録すると、アプリのシーンごとにこのタイプの1つをインスタンス化したいとエンジンに伝えます。

00:07:26.000 --> 00:07:30.000
Initが必要で、deinitを提供することもできます。

00:07:30.000 --> 00:07:32.000
依存関係を指定できます。

00:07:32.000 --> 00:07:39.000
このシステムは常にMotionSystemの前に実行する必要があります。そのため、ここで列挙値を使用しました。

00:07:39.000 --> 00:07:54.000
更新機能では、MotionComponentに保存されている状態を変更し、MotionSystemは提供する状態に基づいて動作するため、生産者と消費者の関係のように、MotionSystemの前にFlockingSystemが実行されていることを確認する必要があります。

00:07:54.000 --> 00:07:57.000
.Afterオプションを使用することもできます。

00:07:57.000 --> 00:08:05.000
依存関係を指定しない場合、システムの更新機能は登録した順序で実行されます。

00:08:05.000 --> 00:08:10.000
EntityQueryは、フロックコンポーネントとモーションコンポーネントを持つすべてのエンティティが欲しいと言っています。

00:08:10.000 --> 00:08:15.000
シミュレーション期間中は変更されないため、静的レットです。

00:08:15.000 --> 00:08:22.000
マルチプレイヤーAR体験では、codableに準拠したコンポーネントがネットワーク上で自動的に同期されます。

00:08:22.000 --> 00:08:27.000
ただし、システム内のデータはネットワーク上で自動的に同期されません。

00:08:27.000 --> 00:08:30.000
データは一般的にコンポーネントに保存する必要があります。

00:08:30.000 --> 00:08:34.000
それでは、FlockingSystemの更新機能に飛び込みましょう。

00:08:34.000 --> 00:08:42.000
そのフレームのデルタタイムとシーン自体への参照を含むSceneUpdateContextが必要です。

00:08:42.000 --> 00:08:52.000
まず、シーンでEntityQueryを実行し、FlockingComponentを持つエンティティに対して反復処理できるクエリ結果を返します。

00:08:52.000 --> 00:08:57.000
それぞれのMotionComponentを取得し、それを修正します。

00:08:57.000 --> 00:08:59.000
なぜFlockingComponent自体を入手しないのですか?

00:08:59.000 --> 00:09:02.000
なぜなら、それに関連付けられたデータがないからです。

00:09:02.000 --> 00:09:07.000
私たちは、群れのメンバーシップを示すためにタグのようにそれを使用します。

00:09:07.000 --> 00:09:15.000
次に、標準のBoidsシミュレーションを実行して群れを誘導し、MotionComponentの力の収集を変更します。

00:09:15.000 --> 00:09:28.000
最後に、各魚に力を追加して目的の方向にプッシュし、コンポーネントは値タイプであるSwift構造体であるため、MotionComponentを元のものに戻す必要があります。

00:09:28.000 --> 00:09:31.000
システムはカスタム更新機能を実装する必要はありません。

00:09:31.000 --> 00:09:39.000
また、シーンイベントのイベントハンドラを登録するなど、initのみを提供するシステムを作成すると便利です。

00:09:39.000 --> 00:09:45.000
これまでのところ、エンティティ、コンポーネント、およびカスタムシステム間の関係を見てきました。

00:09:45.000 --> 00:09:52.000
では、少しズームアウトして、RealityKit 2にもたらした高レベルのアーキテクチャの変更について話しましょう。

00:09:52.000 --> 00:09:59.000
以前は、すべてのフレームが呼び出されるクロージャを使用してSceneEvents.updateイベントをサブスクライブしました。

00:09:59.000 --> 00:10:05.000
この種のイベントハンドラーは、多くの場合、ゲームマネージャーのようなクラスに住んでいるか、少なくとも登録されます。

00:10:05.000 --> 00:10:15.000
そのようなクロージャの代わりに、更新ロジックをきれいに分離し、別々のシステム更新機能で正式に注文できるようになりました。

00:10:15.000 --> 00:10:19.000
つまり、ゲームマネージャーは役割をあまり果たせないということです。

00:10:19.000 --> 00:10:36.000
そこでイベントの更新のためにすべての登録を行い、ゲーム内のすべてのものについて更新を呼び出す順序を管理する代わりに、ゲームマネージャーはエンティティにコンポーネントを追加して、それらのエンティティがクエリに含めるべきであることをシステムに示すだけです。

00:10:36.000 --> 00:10:45.000
以前は、エンティティサブクラスでプロトコルの適合性を宣言して、そのエンティティタイプに特定のコンポーネントがあることを表現していました。

00:10:45.000 --> 00:10:51.000
これで、エンティティをサブクラスにする必要はありません。なぜなら、それもあまり役割を果たさないからです。

00:10:51.000 --> 00:10:57.000
それは単なるオブジェクトの識別子であり、その属性はコンポーネントとしてモデル化することができます。

00:10:57.000 --> 00:11:03.000
なぜなら、サブクラスエンティティをしない場合、オブジェクトをそれらのコンポーネントを永遠に保持するために結び付けないからです。

00:11:03.000 --> 00:11:06.000
体験中にコンポーネントを自由に追加および削除できます。

00:11:06.000 --> 00:11:13.000
したがって、RealityKit 2では、カスタムシステムを持っているので、カスタムコンポーネントははるかに便利です。

00:11:13.000 --> 00:11:15.000
しかし、あなたはまだどちらの方法でもそれを行うことができます。

00:11:15.000 --> 00:11:17.000
それがゲーム開発の美しさです。

00:11:17.000 --> 00:11:19.000
世界はあなたの牡蠣です。

00:11:19.000 --> 00:11:23.000
水中デモでは、両方の方法を使用しています。

00:11:23.000 --> 00:11:27.000
また、新しいタイプのコンポーネント、TransientComponentも追加しました。

00:11:27.000 --> 00:11:33.000
例えば、あなたの魚はタコを恐れていましたが、彼らがそれを見たことがある場合に限ります。

00:11:33.000 --> 00:11:39.000
新しい魚の実体をクローンアップすると、クローンがその魚のタコの恐怖を継承したくないかもしれません。

00:11:39.000 --> 00:11:43.000
FearComponentをTransientComponentに適合させることができます。

00:11:43.000 --> 00:11:47.000
そうすれば、新しいエンティティには存在しません。

00:11:47.000 --> 00:11:56.000
ただし、TransientComponentは、他の種類のコンポーネントと同様に、codableに準拠している場合は、ネットワーク同期にまだ含まれています。

00:11:56.000 --> 00:11:59.000
もう1つの追加は、キャンセル可能な新しい拡張機能です。

00:11:59.000 --> 00:12:04.000
エンティティのイベントの購読解除を手動で管理する必要はもうありません。

00:12:04.000 --> 00:12:08.000
あなたがstoreWhileEntityActiveを使用するとき、私たちはあなたのためにそれを行います。

00:12:08.000 --> 00:12:12.000
ここでは、魚の実体の衝突イベントを扱っています。

00:12:12.000 --> 00:12:18.000
魚自体よりも長生きするためにこのサブスクリプションを必要としないので、storeWhileEntityActiveを使用しています。

00:12:18.000 --> 00:12:25.000
いつものように、ゲームを構築するときは、再コンパイルすることなく、その場で微調整したい設定がたくさんあります。

00:12:25.000 --> 00:12:36.000
私たちのゲームでは、SwiftUIで設定ビューを構築し、CustomComponentsでラップすることで、そのバッキングモデルをさまざまなCustomSystemsに渡します。

00:12:36.000 --> 00:12:47.000
Settingsインスタンスを@StateObjectとして作成し、ARViewContainerとSwiftUIビューの両方に環境オブジェクトとして渡します。

00:12:47.000 --> 00:12:51.000
SettingsオブジェクトをCustomComponent、SettingsComponentでラップします。

00:12:51.000 --> 00:12:56.000
次に、魚のエンティティを作成するときに、設定コンポーネントを与えます。

00:12:56.000 --> 00:13:06.000
そうすれば、これらの設定を望むカスタムシステムが登場すると、「最高速度」の値を取り、それを使用して各魚の速度を上限として、そこから読み取ることができます。

00:13:06.000 --> 00:13:12.000
そして今、私はそれを同僚のオリヴィエに渡して、材料についてあなたに話します。

00:13:12.000 --> 00:13:14.000
ありがとう、アマンダ。

00:13:14.000 --> 00:13:17.000
今年は、材料用の新しいAPIを追加しました。

00:13:17.000 --> 00:13:24.000
ベースカラー、粗さ、金属特性を持つSimpleMaterialなど、すでにいくつかのタイプがありました。

00:13:24.000 --> 00:13:29.000
また、色だけで照明のないUnlitMaterialもありました。

00:13:29.000 --> 00:13:35.000
仮想オブジェクトを隠すためのマスクとして使用できるOclusionMaterialsがありました。

00:13:35.000 --> 00:13:42.000
そして昨年、ビデオを色として使用するUnlitMaterialsであるVideoMaterialsを導入しました。

00:13:42.000 --> 00:13:45.000
今年は透明性のサポートを追加したことに注意してください。

00:13:45.000 --> 00:13:51.000
ビデオファイルに透明度が含まれている場合は、オブジェクトをレンダリングするために使用されます。

00:13:51.000 --> 00:14:03.000
今年は、USDでの材料のスキーマと非常によく似たPhysicallyBasedMaterialタイプから始めて、材料をより高度に制御できる新しいAPIを追加しました。

00:14:03.000 --> 00:14:10.000
これはSimpleMaterialのスーパーセットであり、他のレンダラーで見つけることができる標準的なPBRプロパティのほとんどを持っています。

00:14:10.000 --> 00:14:14.000
これは、米ドルからロードされたエンティティで見つけることができる資料です。

00:14:14.000 --> 00:14:24.000
たとえば、ピエロの魚のUSDをロードし、その材料の個々の特性を変更して金または紫にすることができます。

00:14:24.000 --> 00:14:31.000
素材の特性の中で、たとえば、通常のマップを変更して、メッシュの一部ではない小さな詳細を追加できます。

00:14:31.000 --> 00:14:35.000
モデルの透明度を定義するテクスチャを割り当てることもできます。

00:14:35.000 --> 00:14:46.000
デフォルトでは、透明度はアルファブレンドを使用していますが、不透明度Thresholdも割り当てると、そのしきい値以下のすべてのフラグメントが破棄されます。

00:14:46.000 --> 00:14:52.000
アンビエントオクルージョンのテクスチャを設定し、モデル内のあいまいな影を定義できます。

00:14:52.000 --> 00:14:59.000
そして、より高度な特性の例は、材料上の反射塗料の追加層をシミュレートするクリアコートです。

00:14:59.000 --> 00:15:05.000
また、PhysicallyBasedMaterialタイプには他にも多くのプロパティがあります。

00:15:05.000 --> 00:15:11.000
また、独自の金属コードを使用して材料を作るために、カスタム材料と呼ばれる新しいタイプを追加しました。

00:15:11.000 --> 00:15:15.000
これは、このタコモデルに色遷移効果をもたらすために使用したものです。

00:15:15.000 --> 00:15:21.000
レンダリングに関する2番目の講演では、このシェーダーとカスタムマテリアルについて説明します。

00:15:21.000 --> 00:15:27.000
素材に加えて、RealityKitのアニメーションのコントロールも強化しました。

00:15:27.000 --> 00:15:35.000
まず、アニメーションの既存のAPIについて調べてみましょう。これは主にUSDからロードされたアニメーションの再生に関するものです。

00:15:35.000 --> 00:15:38.000
USDからアニメーションを読み込むと、一度再生できます。

00:15:38.000 --> 00:15:45.000
また、無限にループするように繰り返すこともできます。これは、ここでダイバーのアイドルアニメーションに望むものです。

00:15:45.000 --> 00:15:49.000
アニメーションを一時停止、再開、停止することもできます。

00:15:49.000 --> 00:15:55.000
最後に、新しいアニメーションを再生するときは、トランジション時間を指定することができます。

00:15:55.000 --> 00:16:00.000
指定しないと、キャラクターは即座に新しいアニメーションに切り替わります。

00:16:00.000 --> 00:16:07.000
トランジション期間を指定すると、その間にRealityKitは古いアニメーションと新しいアニメーションをブレンドします。

00:16:07.000 --> 00:16:13.000
これは、例えば、ダイバーのウォークサイクルとアイドルサイクルの間を移行するときに便利です。

00:16:13.000 --> 00:16:17.000
しかし、私たちはまだそこの足のアニメーションを改善することができます。

00:16:17.000 --> 00:16:22.000
ブレンドレイヤーに新しいAPIを使用して、アニメーションをよりリアルにすることができます。

00:16:22.000 --> 00:16:32.000
私たちは2つの別々のブレンドレイヤーでウォーキングアニメーションとアイドルアニメーションを再生し、最上層でウォーキングアニメーションを再生したので、それは私たちが現在見ている唯一のアニメーションです。

00:16:32.000 --> 00:16:38.000
しかし、ウォーキングアニメーションのブレンドファクターを変更して、下のアイドルアニメーションを明らかにすることができます。

00:16:38.000 --> 00:16:45.000
ブレンド係数が小さくなるにつれて、足音も小さくなることに注意してください。

00:16:45.000 --> 00:16:51.000
また、アニメーションの再生速度を変更して、ダイバーの歩行を速くまたは遅くすることもできます。

00:16:51.000 --> 00:16:55.000
ここでは、ダイバーは半分の速度で歩いています。

00:16:55.000 --> 00:17:01.000
最後に、地面に対する文字の速度を使用して、これらの値の両方を制御します。

00:17:01.000 --> 00:17:08.000
このようにして、地面と比較してアニメーションをより滑らかにし、足の滑りを減らすことができます。

00:17:08.000 --> 00:17:14.000
これまでのところ、アイドルサイクルやウォークサイクルなど、複数のアニメーションクリップを使用してきました。

00:17:14.000 --> 00:17:18.000
これらはRealityKitのAnimationResourcesとして保存されます。

00:17:18.000 --> 00:17:21.000
また、USDファイルから読み込む方法は複数あります。

00:17:21.000 --> 00:17:25.000
最初の方法は、クリップごとに1つのUSDファイルを持つことです。

00:17:25.000 --> 00:17:31.000
各USDをエンティティとしてロードし、そのアニメーションをAnimationResourcesとして取得できます。

00:17:31.000 --> 00:17:39.000
AnimationResourceは、スケルトン内のジョイントの名前がアニメーションと一致する限り、任意のエンティティで再生できます。

00:17:39.000 --> 00:17:50.000
複数のアニメーションクリップをロードするもう1つの方法は、同じタイムラインで1つのUSDにそれらを持ち、AnimationViewsを使用してこのタイムラインを複数のクリップにスライスすることです。

00:17:50.000 --> 00:17:54.000
これには、各クリップ間のタイムコードを知る必要があります。

00:17:54.000 --> 00:18:01.000
その後、各AnimationViewをAnimationResourceに変換し、前の方法とまったく同じ方法で使用できます。

00:18:01.000 --> 00:18:05.000
それでは、アプリでタコのアニメーションを見てみましょう。 タコのアニメーションを見てみましょう。

00:18:05.000 --> 00:18:11.000
タコは隠れていますが、プレイヤーが近づくと怖くなり、新しい隠れ場所に移動します。

00:18:11.000 --> 00:18:13.000
それをアニメーション化する方法を見てみましょう。

00:18:13.000 --> 00:18:18.000
タコの骨格アニメーションをロードすることから始めます:ジャンプ、水泳、着陸。

00:18:18.000 --> 00:18:24.000
これらのアニメーションは、私たちがダイバーのためにやったのと同じように、米ドルから読み込まれます。

00:18:24.000 --> 00:18:29.000
しかし、私たちはまた、ある場所から次の場所に移動するためにタコの変換をアニメーション化したいと考えています。

00:18:29.000 --> 00:18:38.000
変換をアニメーション化するには、新しいAPIを使用して、FromToByAnimationタイプのアニメーションをプログラムで作成します。

00:18:38.000 --> 00:18:41.000
このようにして、位置をアニメーション化できます。

00:18:41.000 --> 00:18:46.000
タコがどのように見えるか見てみましょう。 タコでどのように見えるか見てみましょう

00:18:46.000 --> 00:18:53.000
もっと面白くするために、回転もアニメーション化しましょう。

00:18:53.000 --> 00:18:59.000
タコは動いている間に回転しますが、横向きに泳いでいますが、あまり現実的ではありません。

00:18:59.000 --> 00:19:03.000
一連のアニメーションを作ることで、これを改善できます。

00:19:03.000 --> 00:19:07.000
まず、タコを新しい場所に向かって回転させます。

00:19:07.000 --> 00:19:10.000
その後、それを新しい場所に翻訳します。

00:19:10.000 --> 00:19:15.000
そして最後に、タコをカメラに向かって回転させます。

00:19:15.000 --> 00:19:22.000
そして、これが完全なアニメーションです。

00:19:22.000 --> 00:19:29.000
アニメーション用の新しいAPIに加えて、キャラクターの物理を管理する方法も追加しました。

00:19:29.000 --> 00:19:31.000
それはキャラクターコントローラーと呼ばれています。

00:19:31.000 --> 00:19:36.000
これにより、シーン内のコライダーと物理的に対話できるキャラクターを作成できます。

00:19:36.000 --> 00:19:41.000
ここでは、ダイバーが床からソファに飛び降りてその上を歩いているのが見えます。

00:19:41.000 --> 00:19:45.000
これは、ダイバーにキャラクターコントローラーを追加することで達成されます。

00:19:45.000 --> 00:19:52.000
これにより、ダイバーはLiDARセンサーから生成された環境のメッシュと自動的に相互作用します。

00:19:52.000 --> 00:19:55.000
キャラクターコントローラーの作成は簡単です。

00:19:55.000 --> 00:19:59.000
あなたがする必要があるのは、あなたのキャラクターの形に合ったカプセルを定義することだけです。

00:19:59.000 --> 00:20:05.000
作成時に、カプセルの高さとその半径を指定する必要があります。

00:20:05.000 --> 00:20:11.000
キャラクターコントローラーがエンティティに割り当てられた後、すべてのフレームでmove(to:)関数を呼び出すことができます。

00:20:11.000 --> 00:20:17.000
キャラクターを目的の場所に移動させますが、障害物を通り抜けることはありません。

00:20:17.000 --> 00:20:22.000
一方、障害物を無視したい場合は、テレポート機能を使用できます。

00:20:22.000 --> 00:20:29.000
今、私はそれをアマンダに渡します。アマンダは、私たちがRealityKitのこのリリースに追加したいくつかの楽しい機能を通してあなたを連れて行きます。

00:20:29.000 --> 00:20:31.000
すごい。ありがとう、オリヴィエ。

00:20:31.000 --> 00:20:40.000
さて、ディスクからロードすることなく、その場でリソースを作成できる2つの新しいAPIを強調します。

00:20:40.000 --> 00:20:47.000
まず、SceneUnderstandingから人の顔のメッシュを取得する方法を紹介し、次にオーディオを生成する方法を説明します。

00:20:47.000 --> 00:20:52.000
これらが手続き的に生成された芸術のために開く可能性の海があります。

00:20:52.000 --> 00:20:55.000
まず、フェイスメッシュ。

00:20:55.000 --> 00:21:06.000
私はデモアプリにある紫とオレンジのタコの外観にとても触発され、私は私の顔に1つをペイントしようとしましたが、事実上、新しいフェイスメッシュ機能を使用していました。

00:21:06.000 --> 00:21:18.000
SceneUnderstandingは、人々の顔を表すエンティティを提供することができ、それらのエンティティにはModelComponentsがあります。つまり、フェイスエンティティのメッシュ上の材料のプロパティを交換できます。

00:21:18.000 --> 00:21:24.000
私たちは、ライブドローイングでその場でフェイスメッシュに適用するテクスチャを生成するのがとても楽しかったです。

00:21:24.000 --> 00:21:26.000
コードを見てみましょう。 

00:21:26.000 --> 00:21:44.000
SceneUnderstandingComponentには、EntityTypeと呼ばれる列挙プロパティがあります。これはSceneUnderstandingSystemによって設定され、2つの値のいずれかを取ることができます。顔、つまり、現実世界の人の顔の表現、またはmeshChunk、つまり再構築された世界メッシュの他の部分です。

00:21:44.000 --> 00:21:48.000
また、そのタイプがまだ知られていないことを意味する、nilである可能性があります。

00:21:48.000 --> 00:21:50.000
これは再びEntityQueryです。

00:21:50.000 --> 00:21:57.000
SceneUnderstandingComponentを持つエンティティを照会し、そのentityTypeをチェックして顔を見つけることができます。

00:21:57.000 --> 00:22:02.000
その後、これらのエンティティからModelComponentsを取得し、それらを使って好きなことをすることができます。

00:22:02.000 --> 00:22:14.000
フェイスペイントのサンプルでは、PencilKitを使用してキャンバスに描画し、そのCGImageからTextureResourceを作成して、結果のCGImageをfaceEntityにラップしています。

00:22:14.000 --> 00:22:25.000
私たちは、このフェイスペイントをできるだけ現実的に見せることができるようにPhysicallyBasedMaterialを使用しており、私たちの外観のためにそれをダイヤルインするためにいくつかのプロパティを設定しています。

00:22:25.000 --> 00:22:36.000
キラキラペイント効果を作るために、物理的ベースのレンダラーに、単に材料を金属のままにした場合とは異なる方法でこの表面に光を反射する方法を伝える通常のマップテクスチャを使用します。

00:22:36.000 --> 00:22:43.000
次に、鉛筆で描かれたTextureResourceを素材に渡し、エンティティに設定します。

00:22:43.000 --> 00:22:47.000
だから、それは私たちの新しく生成されたリソースで作業する1つの方法です。

00:22:47.000 --> 00:22:51.000
生成できるもう1つのタイプのリソースは、AudioBufferResourceです。

00:22:51.000 --> 00:23:01.000
AVAudioBufferは、マイク入力を録音したり、自分で生成したり、AVSpeechSynthesizerを使用したりすることで、好きなように入手できます。

00:23:01.000 --> 00:23:08.000
その後、AVAudioBufferを使用してAudioBufferResourceを作成し、それを使用してアプリでサウンドを再生できます。

00:23:08.000 --> 00:23:14.000
AVSpeechSynthesizerにAVSpeechUtteranceを書くことで、テキストをスピーチに変える方法は次のとおりです。

00:23:14.000 --> 00:23:17.000
コールバックでAVAudioBufferを受け取ります。

00:23:17.000 --> 00:23:26.000
ここでは、AudioBufferResourceを作成し、3D位置オーディオを利用するためにinputModeを.spatialに設定しています。

00:23:26.000 --> 00:23:30.000
他の利用可能な入力モードは、非空間とアンビエントです。

00:23:30.000 --> 00:23:33.000
次に、エンティティにそのオーディオを再生するように指示します。

00:23:33.000 --> 00:23:43.000
もちろん、派手なトリックでオーディオバッファを処理して、魚が水中で話すときに泡を吹いているように聞こえるようにすることができます。

00:23:43.000 --> 00:23:47.000
これは、今年のRealityKitの新機能の概要でした。

00:23:47.000 --> 00:23:52.000
私たちは、あなたのシーンの外観と行動をよりコントロールすることに重点を置いています。

00:23:52.000 --> 00:24:00.000
ECSを修正してカスタムシステムを提供し、アプリの動作をより柔軟に構築できるようにしました。

00:24:00.000 --> 00:24:04.000
素材とアニメーションAPIに多くの進歩を加えました。

00:24:04.000 --> 00:24:10.000
エンティティが現実世界の環境と簡単にやり取りできるように、キャラクターコントローラーを導入しました。

00:24:10.000 --> 00:24:15.000
最後に、その場でリソースを生成できる方法のいくつかを強調しました。

00:24:15.000 --> 00:24:19.000
しかし、それは間違いなくRealityKit 2で新しいすべての完全なリストではありません。

00:24:19.000 --> 00:24:29.000
今週後半の2回目のRealityKitセッションでは、新しいレンダリング機能の詳細を学び、水中デモでいくつかのものを実装した方法を見ることができます。

00:24:29.000 --> 00:24:32.000
ジオメトリ修飾子は、海藻をアニメーション化するために使用するものです。

00:24:32.000 --> 00:24:37.000
タコは表面シェーダーを使用して、その色間を美しく遷移します。

00:24:37.000 --> 00:24:43.000
青い深さの霧効果と水腐食作用は、後処理を使用して作成されました。

00:24:43.000 --> 00:24:48.000
そして、生成リソースのテーマでは、動的メッシュの使い方を学びます。

00:24:48.000 --> 00:24:55.000
復習のために、2019年のセッション「RealityKitでアプリを構築する」もチェックしてみてください。

00:24:55.000 --> 00:25:01.000
ありがとう、そして私たちはこれらのAPIであなたの創造性の深さを見ることを楽しみにしています。

00:25:01.000 --> 23:59:59.000
[明るい音楽]。

