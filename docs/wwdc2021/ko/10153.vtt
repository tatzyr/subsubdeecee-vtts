WEBVTT

00:00:00.000 --> 00:00:05.000
♪ 베이스 음악 연주 ♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:11.000
유진 지드코프: 안녕하세요, WWDC에 오신 것을 환영합니다.

00:00:11.000 --> 00:00:14.000
제 이름은 유진 지드코프입니다. 저는 GPU 소프트웨어에서 왔어요.

00:00:14.000 --> 00:00:24.000
그리고 Mac 시스템 아키텍처의 Harsh Patil과 함께, 우리는 Apple 실리콘에서 Metal으로 구동되는 이미지 처리 애플리케이션을 만드는 방법을 보여줄 것입니다.

00:00:24.000 --> 00:00:35.000
먼저, 저는 작년에 있었던 개발자 참여를 기반으로 M1용 이미지 처리 애플리케이션을 최적화하는 모범 사례와 교훈에 초점을 맞출 것입니다.

00:00:35.000 --> 00:00:44.000
그런 다음 Harsh는 Apple 실리콘에서 최적의 성능을 위해 이미지 처리 파이프라인을 재설계하는 방법에 대한 단계별 가이드를 제공할 것입니다.

00:00:44.000 --> 00:00:46.000
그러니까 바로 뛰어들자!

00:00:46.000 --> 00:00:52.000
시작하려면, Apple 시스템 온더칩 아키텍처와 그 이점을 간단히 다시 살펴봅시다.

00:00:52.000 --> 00:00:57.000
많은 이미지 처리 및 비디오 편집 앱은 개별 GPU를 염두에 두고 설계되었습니다.

00:00:57.000 --> 00:01:02.000
그래서 애플 GPU의 차이점을 강조하는 것이 중요하다.

00:01:02.000 --> 00:01:06.000
첫째, 모든 애플 칩은 통합 메모리 아키텍처를 사용한다.

00:01:06.000 --> 00:01:15.000
CPU, GPU, 신경 및 미디어 엔진과 같은 모든 블록은 통합 메모리 인터페이스를 사용하여 동일한 시스템 메모리에 액세스할 수 있습니다.

00:01:15.000 --> 00:01:21.000
그리고 둘째, 우리의 GPU는 타일 기반 지연 렌더러 또는 TBDR입니다.

00:01:21.000 --> 00:01:35.000
TBDR에는 두 가지 주요 단계가 있습니다: 전체 렌더링 표면이 타일로 분할되고 처리된 지오메트리가 독립적으로 처리되는 타일링; 그리고 각 타일에 대해 모든 픽셀이 처리되는 렌더링.

00:01:35.000 --> 00:01:51.000
따라서 Apple 실리콘에서 가장 효율적이려면 이미지 처리 앱은 파이프라인에 사용된 복사본을 피하기 위해 통합 메모리와 타일 메모리와 로컬 이미지 블록을 활용하여 TBDR 아키텍처를 활용하기 시작해야 합니다.

00:01:51.000 --> 00:02:00.000
Apple TBDR이 낮은 수준에서 어떻게 작동하는지, 그리고 셰이더 코어를 타겟팅하는 방법에 대해 자세히 알아보려면, 작년의 이 세션을 시청하세요.

00:02:00.000 --> 00:02:08.000
그리고 이제, 애플 실리콘을 위한 이미지 처리 컴퓨팅 워크로드를 최적화하기 위해 우리가 할 정확한 일에 대해 이야기해 봅시다.

00:02:08.000 --> 00:02:14.000
작년에, 우리는 이미지 파이프라인 전환에 대해 많은 훌륭한 개발자들과 긴밀히 협력해 왔습니다.

00:02:14.000 --> 00:02:17.000
우리는 공유할 가장 보람 있는 여섯 가지 팁을 골랐다.

00:02:17.000 --> 00:02:22.000
먼저, 우리는 불필요한 메모리 복사본이나 블리트를 피하는 방법에 대해 논의할 것이다.

00:02:22.000 --> 00:02:27.000
우리가 현재 최대 8K의 이미지로 작업하고 있다는 점을 감안할 때 이것은 정말 중요합니다.

00:02:27.000 --> 00:02:38.000
그런 다음, 우리는 버퍼에서 컴퓨팅을 사용하는 대신 렌더링 파이프라인과 텍스처를 사용하는 이점과 자신의 이미지 처리 파이프라인에서 어떻게 할 수 있는지 강조하고 싶었습니다.

00:02:38.000 --> 00:02:46.000
렌더링과 텍스처 경로가 실행되면, 적절한 로드/저장 작업과 메모리 없는 첨부 파일의 중요성을 보여주고 싶었습니다.

00:02:46.000 --> 00:02:50.000
이것은 당신이 타일 메모리를 최대한 활용하는 데 도움이 될 것입니다.

00:02:50.000 --> 00:03:03.000
그런 다음, 우리는 동적 제어 흐름으로 우버 셰이더에 가장 잘 접근하는 방법과 성능과 효율성을 개선하기 위해 짧은 절반과 같은 더 작은 데이터 유형을 활용하는 방법에 대해 이야기할 것입니다.

00:03:03.000 --> 00:03:08.000
그리고 우리는 최고의 처리량을 얻기 위해 텍스처 형식에 대한 중요한 조언으로 마무리할 것입니다.

00:03:08.000 --> 00:03:09.000
알았어.

00:03:09.000 --> 00:03:15.000
그래서 가장 보람 있는 팁 중 하나로 시작합시다: 애플 실리콘에서 불필요한 블리트를 피하는 것.

00:03:15.000 --> 00:03:20.000
대부분의 이미지 처리 앱은 개별 GPU를 중심으로 설계되었습니다.

00:03:20.000 --> 00:03:25.000
개별 GPU를 사용하면 별도의 시스템 메모리와 비디오 메모리가 있습니다.

00:03:25.000 --> 00:03:31.000
프레임 이미지를 GPU에 표시하거나 상주하려면 명시적인 복사본이 필요합니다.

00:03:31.000 --> 00:03:37.000
게다가, 그것은 보통 두 번 필요하다; GPU가 그것을 처리하기 위해 데이터를 업로드하고, 다시 가져오는 것이다.

00:03:37.000 --> 00:03:43.000
8K 비디오를 디코딩하고, 처리하고, 디스크에 저장하는 것을 고려해 봅시다.

00:03:43.000 --> 00:03:48.000
그래서 이것은 이 경우 디코딩하는 CPU 스레드입니다.

00:03:48.000 --> 00:03:53.000
그것이 우리가 디코딩된 프레임을 GPU VRAM에 복사해야 하는 곳이다.

00:03:53.000 --> 00:03:58.000
그리고 여기 모든 효과와 필터가 적용되는 GPU 타임라인이 있습니다.

00:03:58.000 --> 00:04:03.000
한 걸음 더 나아가서 결과를 디스크에 저장해야 한다는 것을 기억합시다, 그렇죠?

00:04:03.000 --> 00:04:12.000
그래서 우리는 또한 처리된 프레임을 시스템 메모리와 프레임의 실제 인코딩으로 다시 가져오는 것을 고려해야 한다.

00:04:12.000 --> 00:04:21.000
그래서, 이것들은 "복사" 또는 "블릿 갭"로 알려져 있으며, 고급 이미지 처리 응용 프로그램은 그것들을 채우기 위해 깊은 파이프라이닝과 다른 현명한 것들을 해야 했다.

00:04:21.000 --> 00:04:28.000
음, 좋은 소식은 애플 GPU에서 거주를 위해 블릿팅이 더 이상 필요하지 않다는 것이다.

00:04:28.000 --> 00:04:33.000
메모리가 공유되기 때문에, CPU와 GPU 모두 직접 액세스할 수 있습니다.

00:04:33.000 --> 00:04:40.000
따라서 통합 메모리 시스템에서 실행 중인지 감지하고 불필요한 복사본을 피하기 위해 간단한 검사를 추가하십시오.

00:04:40.000 --> 00:04:45.000
그것은 당신의 기억과 시간을 절약할 것이며, 해야 할 절대적인 첫 번째 단계입니다.

00:04:45.000 --> 00:04:51.000
그래서 이것은 우리가 blits가 제거된 통합 메모리 아키텍처에 착륙하는 곳이다.

00:04:51.000 --> 00:04:58.000
블리트를 제거함으로써, 우리는 복사 간격을 완전히 피하고 즉시 처리를 시작할 수 있습니다.

00:04:58.000 --> 00:05:03.000
이것은 또한 더 적은 번거로움으로 더 나은 CPU와 GPU 파이프라인을 제공한다.

00:05:03.000 --> 00:05:07.000
복사본 없이 통합 메모리 경로를 구현하도록 합시다.

00:05:07.000 --> 00:05:18.000
개별 GPU에 있던 그대로 blit 사본을 남겨두면, 시스템 메모리 대역폭, 실제 처리를 위한 더 적은 GPU 시간 및 잠재적인 스케줄링 오버헤드로 비용을 지불하게 됩니다.

00:05:18.000 --> 00:05:24.000
말할 것도 없이 우리는 더 이상 별도의 VRAM 이미지를 할당할 필요가 없습니다.

00:05:24.000 --> 00:05:28.000
GPU 프레임 캡처는 큰 블릿을 발견하는 데 도움이 될 수 있습니다.

00:05:28.000 --> 00:05:34.000
신청서를 검사하고 필요한 사본만 했는지 확인하세요.

00:05:34.000 --> 00:05:40.000
이제, 이미지 처리를 위해 Apple GPU TBDR 아키텍처를 어떻게 활용하기 시작해야 하는지에 대해 이야기해 봅시다.

00:05:40.000 --> 00:05:47.000
대부분의 이미지 처리 애플리케이션은 일련의 컴퓨팅 커널을 파견하여 이미지 버퍼에서 작동합니다.

00:05:47.000 --> 00:05:55.000
기본 직렬 모드에서 컴퓨팅 커널을 디스패치할 때, 메탈은 모든 후속 디스패치가 모든 메모리 쓰기를 볼 수 있도록 보장합니다.

00:05:55.000 --> 00:06:06.000
이 보증은 모든 셰이더 코어에 대한 메모리 일관성을 의미하므로, 모든 메모리 쓰기는 다음 디스패치가 시작될 때까지 다른 모든 코어에서 볼 수 있습니다.

00:06:06.000 --> 00:06:12.000
이것은 또한 메모리 트래픽이 정말 높을 수 있다는 것을 의미한다; 전체 이미지를 읽고 써야 한다.

00:06:12.000 --> 00:06:17.000
M1을 사용하면, Apple GPU는 MacOS에서 타일 디스패치를 가능하게 한다.

00:06:17.000 --> 00:06:23.000
일반 컴퓨팅과 달리, 그들은 타일 전용 동기화 포인트가 있는 타일 메모리에서 작동합니다.

00:06:23.000 --> 00:06:29.000
컨벌루션과 같은 일부 필터는 타일 패러다임에 매핑할 수 없지만, 다른 많은 필터는 할 수 있습니다!

00:06:29.000 --> 00:06:35.000
인코더 엔드포인트가 확실한 효율성 향상을 제공할 때까지 시스템 메모리 플러시를 연기합니다.

00:06:35.000 --> 00:06:41.000
시스템 메모리 대역폭에 제한되지 않을 때 더 유용한 GPU 작업을 실행할 수 있습니다.

00:06:41.000 --> 00:06:52.000
더 나아가, 많은 픽셀당 작업은 이웃 픽셀에 대한 액세스가 필요하지 않으므로 타일 동기화 포인트가 필요하지 않습니다.

00:06:52.000 --> 00:06:55.000
이것은 조각 기능에 정말 잘 매핑된다.

00:06:55.000 --> 00:07:05.000
조각 함수는 암시적 타일 동기화 없이 실행할 수 있으며, 인코더 경계에서만 동기화가 필요하거나 타일 커널이 조각 커널 이후에 연속적으로 파견될 때 동기화가 필요합니다.

00:07:05.000 --> 00:07:11.000
우리는 이제 Apple GPU가 더 효율적인 이미지 처리를 위해 조각 기능과 타일 커널을 가능하게 한다는 것을 알게 되었다.

00:07:11.000 --> 00:07:14.000
우리가 그걸 어떻게 사용할 수 있는지 보자.

00:07:14.000 --> 00:07:21.000
우리는 텍스처에 명령 인코더를 렌더링하기 위해 버퍼의 일반 컴퓨팅 디스패치를 변환하여 그렇게 합니다.

00:07:21.000 --> 00:07:25.000
우리가 방금 논의했듯이, 경험 법칙은 다음과 같다.

00:07:25.000 --> 00:07:31.000
픽셀 간 종속성이 없는 픽셀당 작업은 프래그먼트 함수를 사용하여 구현되어야 합니다.

00:07:31.000 --> 00:07:39.000
스레드 그룹 범위 작업이 있는 모든 필터는 타일 내의 이웃 픽셀 액세스가 필요하기 때문에 타일 셰이딩으로 구현되어야 합니다.

00:07:39.000 --> 00:07:49.000
분산 수집 및 컨벌루션 필터는 무작위 액세스가 필요하기 때문에 타일 패러다임에 매핑할 수 없으므로, 이것들은 여전히 컴퓨팅 디스패치로 남아 있어야 합니다.

00:07:49.000 --> 00:07:56.000
렌더링 명령 인코더는 또한 고유한 Apple GPU 기능을 가능하게 합니다: 텍스처와 렌더링 대상을 위한 무손실 대역폭 압축.

00:07:56.000 --> 00:08:04.000
이것은 특히 이미지 처리 파이프라인을 위한 정말 훌륭한 대역폭 절약이므로, 우리가 그것을 어떻게 사용해야 하는지 봅시다.

00:08:04.000 --> 00:08:10.000
음, 무손실 압축을 가능하게 하는 것에 대해 말하자면, 실제로 당신이 하지 말아야 할 것을 말하는 것이 더 쉽습니다.

00:08:10.000 --> 00:08:15.000
첫째, 이미 압축된 텍스처 형식은 무손실로 이익을 얻을 수 없다.

00:08:15.000 --> 00:08:24.000
둘째, 이 압축으로 작동할 수 없는 세 가지 특정 텍스처 플래그가 있으므로, 우연히 설정하지 않도록 하십시오.

00:08:24.000 --> 00:08:31.000
그리고 셋째, 선형 텍스처 - 또는 MTLBuffer에 의해 뒷받침되는 - 또한 허용되지 않습니다.

00:08:31.000 --> 00:08:41.000
비공개 텍스처에도 몇 가지 특별한 처리가 필요합니다. 가장 빠른 경로를 유지하려면 optimizeContentsForGPUAccess를 호출해야 합니다.

00:08:41.000 --> 00:08:49.000
GPU 프레임 캡처 요약 창은 이제 무손실 압축 경고를 보여주고 텍스처가 거부된 이유를 강조합니다.

00:08:49.000 --> 00:08:54.000
이 예에서, PixelFormatView 플래그가 설정되었다.

00:08:54.000 --> 00:08:58.000
많은 경우, 개발자들은 의도치 않게 이러한 플래그를 설정하고 있다.

00:08:58.000 --> 00:09:05.000
구성 요소 스위즐 또는 sRGB 변환만 있으면 PixelFormatView를 설정하지 마세요.

00:09:05.000 --> 00:09:08.000
좋아요, 우리는 렌더링과 텍스처 경로를 실행하고 있습니다.

00:09:08.000 --> 00:09:11.000
이제, 타일 메모리를 제대로 사용하는지 확인해 봅시다.

00:09:11.000 --> 00:09:19.000
로드/저장 작업 및 메모리 없는 첨부 파일과 같은 타일 메모리 TBDR 개념은 데스크톱 세계에서 완전히 새로운 것이다.

00:09:19.000 --> 00:09:22.000
그러니 우리가 그것들을 제대로 사용하는지 확인합시다.

00:09:22.000 --> 00:09:25.000
로드/저장 작업부터 시작합시다!

00:09:25.000 --> 00:09:29.000
우리가 이미 알고 있듯이, 전체 렌더링 대상은 타일로 나뉜다.

00:09:29.000 --> 00:09:36.000
로드/스토어는 메모리 계층 구조를 통해 가장 최적의 경로를 취할 수 있도록 보장된 타일당 벌크 작업입니다.

00:09:36.000 --> 00:09:48.000
그것들은 GPU에 타일 메모리를 초기화하는 방법을 알려주는 렌더링 패스의 시작 부분에서 실행되며, 패스의 끝에서 GPU에 어떤 첨부 파일을 다시 작성해야 하는지 알려줍니다.

00:09:48.000 --> 00:09:52.000
여기서 중요한 것은 우리가 필요하지 않은 것을 적재하는 것을 피하는 것이다.

00:09:52.000 --> 00:09:59.000
전체 이미지를 덮어쓰거나 리소스가 일시적이라면, 로드 액션을 LoadActionDontCare로 설정하세요.

00:09:59.000 --> 00:10:09.000
렌더링 인코더를 사용하면 이전에 전용 컴퓨팅 패스 또는 fillBuffer 호출로 했던 것처럼 더 이상 출력이나 임시 데이터를 지울 필요가 없습니다.

00:10:09.000 --> 00:10:14.000
LoadActionClear를 설정하면, 클리어 값을 효율적으로 지정할 수 있습니다.

00:10:14.000 --> 00:10:16.000
그리고 가게 행동도 마찬가지입니다.

00:10:16.000 --> 00:10:23.000
메인 첨부 파일과 같이 나중에 필요한 데이터만 저장하고 일시적인 것은 저장하지 마세요.

00:10:23.000 --> 00:10:30.000
명시적인 로드 및 저장 작업 외에도, Apple GPU는 메모리 없는 첨부 파일로 메모리 풋프린트를 저장합니다.

00:10:30.000 --> 00:10:35.000
우리는 첨부 파일을 메모리 없는 저장 모드로 명시적으로 정의할 수 있습니다.

00:10:35.000 --> 00:10:43.000
이것은 타일 전용 메모리 할당을 가능하게 하며, 이는 리소스가 인코더 수명 내에서만 모든 타일에 대해 지속된다는 것을 의미합니다.

00:10:43.000 --> 00:10:51.000
이것은 특히 모든 프레임이 수백 메가바이트가 걸리는 6K/8K 이미지의 경우 메모리 공간을 크게 줄일 수 있습니다.

00:10:51.000 --> 00:10:54.000
이 모든 것이 코드로 어떻게 이루어질 수 있는지 봅시다.

00:10:54.000 --> 00:11:00.000
우리는 textureDescriptor를 만든 다음 outputTexture를 만드는 것으로 시작합니다.

00:11:00.000 --> 00:11:02.000
그런 다음 우리는 일시적인 질감을 만듭니다.

00:11:02.000 --> 00:11:07.000
우리가 여기에 어떤 저장 공간도 원하지 않기 때문에, 내가 그것을 기억 없이 표시했다는 것을 주목하세요.

00:11:07.000 --> 00:11:14.000
그런 다음 먼저 첨부 파일이 무엇인지 그리고 로드/저장 작업이 무엇인지 설명하여 렌더링 패스를 만듭니다.

00:11:14.000 --> 00:11:20.000
우리는 출력을 완전히 덮어쓰기 때문에 출력을 로드하는 것에 신경 쓰지 않지만, 우리는 그것을 저장해야 한다.

00:11:20.000 --> 00:11:26.000
임시 텍스처에 관해서는, 우리는 로드하지 않고 지우고, 저장할 필요도 없습니다.

00:11:26.000 --> 00:11:31.000
마지막으로, 우리는 설명자에서 renderPass를 만듭니다.

00:11:31.000 --> 00:11:32.000
그게 다야.

00:11:32.000 --> 00:11:41.000
그래서 우리는 통합 메모리를 사용하고, 명령 인코더를 렌더링하기 위해 이미지 처리 파이프라인을 이동했으며, 타일 메모리를 적절하게 활용하고 있습니다.

00:11:41.000 --> 00:11:44.000
이제, 우버 셰이더에 대해 이야기해 봅시다.

00:11:44.000 --> 00:11:50.000
우버 셰이더 또는 우버 커널은 개발자의 삶을 더 쉽게 만드는 꽤 인기 있는 방법이다.

00:11:50.000 --> 00:12:03.000
호스트 코드는 제어 구조를 설정하고, 셰이더는 톤 매핑이 활성화되어 있거나 입력이 HDR 또는 SDR 형식인 경우와 같이 일련의 if/else 문을 반복합니다.

00:12:03.000 --> 00:12:11.000
이 접근 방식은 "우버스 셰이더"로도 알려져 있으며 파이프라인 상태 객체의 총 수를 낮추는 데 정말 능숙하다.

00:12:11.000 --> 00:12:14.000
하지만, 그것은 단점이 있다.

00:12:14.000 --> 00:12:19.000
주요 것은 더 복잡한 제어 흐름을 따라잡기 위해 증가된 레지스터 압력이다.

00:12:19.000 --> 00:12:25.000
더 많은 레지스터를 사용하면 셰이더가 실행 중인 최대 수용 인원을 쉽게 제한할 수 있습니다.

00:12:25.000 --> 00:12:29.000
우리가 제어 구조를 전달하는 간단한 커널을 생각해 보세요.

00:12:29.000 --> 00:12:33.000
우리는 우리가 하는 일을 통제하기 위해 구조체 내부의 깃발을 사용한다.

00:12:33.000 --> 00:12:38.000
여기에 두 가지 기능이 있습니다: 입력이 HDR인 경우와 톤매핑이 활성화된 경우.

00:12:38.000 --> 00:12:40.000
다 좋아 보여, 그렇지?

00:12:40.000 --> 00:12:44.000
음, 여기 GPU에서 일어나는 일이 있습니다.

00:12:44.000 --> 00:12:54.000
컴파일 타임에 아무것도 추론할 수 없기 때문에, HDR과 비HDR의 두 경로를 모두 취할 수 있다고 가정한 다음 플래그에 따라 결합해야 합니다.

00:12:54.000 --> 00:12:56.000
톤 매핑도 마찬가지입니다.

00:12:56.000 --> 00:13:02.000
우리는 그것을 평가한 다음 입력 플래그에 따라 안팎으로 가린다.

00:13:02.000 --> 00:13:04.000
여기서 문제는 등록부이다.

00:13:04.000 --> 00:13:07.000
모든 제어 흐름 경로는 실시간 레지스터가 필요하다.

00:13:07.000 --> 00:13:10.000
이곳은 우버 셰이더가 그렇게 좋지 않은 곳이다.

00:13:10.000 --> 00:13:17.000
기억하시겠지만, 커널에서 사용하는 레지스터는 셰이더가 실행할 수 있는 최대 점유율을 정의합니다.

00:13:17.000 --> 00:13:22.000
그것은 레지스터 파일이 셰이더 코어의 모든 심드레인에 의해 공유되기 때문에 발생한다.

00:13:22.000 --> 00:13:30.000
우리가 필요한 것만 실행할 수 있다면, 그것은 더 높은 simdgroup 동시성과 GPU 활용도를 가능하게 할 것이다.

00:13:30.000 --> 00:13:32.000
이걸 고치는 방법에 대해 이야기해 봅시다.

00:13:32.000 --> 00:13:37.000
Metal API는 작업에 적합한 도구를 가지고 있으며, "function_constants"라고 불린다.

00:13:37.000 --> 00:13:43.000
우리는 두 제어 매개 변수를 function_constants로 정의하고, 그에 따라 코드를 수정합니다.

00:13:43.000 --> 00:13:46.000
여기서, 우리는 수정된 커널 코드를 보여주고 있다.

00:13:46.000 --> 00:13:52.000
파이프라인 생성 시간에 function_constant 값을 제공하기 위해 호스트 측도 업데이트되어야 합니다.

00:13:52.000 --> 00:13:59.000
레지스터 압력을 줄이는 또 다른 좋은 방법은 셰이더에 16비트 유형을 사용하는 것입니다.

00:13:59.000 --> 00:14:03.000
애플 GPU는 기본 16비트 유형을 지원합니다.

00:14:03.000 --> 00:14:10.000
따라서, 더 작은 데이터 유형을 사용할 때, 셰이더는 레지스터가 덜 필요하여 점유가 증가합니다.

00:14:10.000 --> 00:14:16.000
절반과 짧은 유형은 또한 더 적은 에너지를 필요로 하며 더 높은 피크 속도를 달성할 수 있다.

00:14:16.000 --> 00:14:24.000
따라서, 유형 변환은 일반적으로 무료이기 때문에 가능한 경우 float와 int 대신 절반과 짧은 유형을 사용하십시오.

00:14:24.000 --> 00:14:32.000
이 예에서, 일부 계산을 위해 threadgroup의 thread_position을 사용하는 커널을 고려하십시오.

00:14:32.000 --> 00:14:40.000
우리는 서명되지 않은 int를 사용하고 있지만, Metal이 지원하는 최대 스레드 그룹 크기는 서명되지 않은 짧은 시간에 쉽게 들어갈 수 있습니다.

00:14:40.000 --> 00:14:46.000
그러나 threadgroup_position_in_grid는 잠재적으로 더 큰 데이터 유형이 필요할 수 있다.

00:14:46.000 --> 00:14:54.000
하지만 우리가 이미지 처리에 사용하는 그리드 크기의 경우 - 최대 8K 또는 16K까지 - 서명되지 않은 짧은 것도 충분합니다.

00:14:54.000 --> 00:15:02.000
대신 16비트 유형을 사용하면, 결과 코드는 더 적은 수의 레지스터를 사용하여 잠재적으로 점유율을 증가시킬 것이다.

00:15:02.000 --> 00:15:07.000
이제, 등록부에 대한 모든 세부 사항을 어디서 알 수 있는지 보여드리겠습니다.

00:15:07.000 --> 00:15:15.000
Xcode13의 GPU 프레임 디버거는 이제 렌더링, 타일 및 컴퓨팅 PSO를 위한 고급 파이프라인 상태 개체 보기를 제공합니다.

00:15:15.000 --> 00:15:22.000
이제 레지스터 사용으로 자세한 파이프라인 통계를 검사하고 모든 셰이더를 미세 조정할 수 있습니다.

00:15:22.000 --> 00:15:28.000
등록 문제를 다루면서, 텍스처 형식에 대해 이야기해 봅시다.

00:15:28.000 --> 00:15:33.000
먼저, 우리는 다른 픽셀 형식이 다른 샘플링 속도를 가질 수 있다는 점에 유의하고 싶습니다.

00:15:33.000 --> 00:15:40.000
하드웨어 생성과 채널 수에 따라, 더 넓은 부동 소수점 유형은 포인트 샘플링 속도를 감소시켰을 수 있다.

00:15:40.000 --> 00:15:49.000
특히 RGBA32F와 같은 부동 소수점 형식은 필터링된 값을 샘플링할 때 FP16 변형보다 느릴 것이다.

00:15:49.000 --> 00:15:53.000
더 작은 유형은 메모리 저장, 대역폭 및 캐시 공간을 줄인다.

00:15:53.000 --> 00:15:59.000
그래서 우리는 다시 한 번 가능한 가장 작은 유형을 사용하는 것을 권장하지만, 이 경우에는 텍스처 저장을 위해 사용합니다.

00:15:59.000 --> 00:16:12.000
이것은 실제로 이미지 처리에서 3D LUT의 일반적인 사례였다; 우리가 작업한 대부분의 응용 프로그램은 이중선형 필터링이 활성화된 3D LUT 응용 단계에 float RGBA를 사용하고 있었다.

00:16:12.000 --> 00:16:17.000
앱이 대신 절반을 사용할 수 있고 정밀도가 충분한지 고려하십시오.

00:16:17.000 --> 00:16:22.000
만약 그렇다면, 피크 샘플링 속도를 얻기 위해 즉시 FP16으로 전환하세요.

00:16:22.000 --> 00:16:39.000
절반 정밀도가 충분하지 않다면, 우리는 고정 소수점 서명되지 않은 쇼트가 값의 균일한 범위를 제공한다는 것을 발견했기 때문에, 단위 규모로 LUT를 인코딩하고 셰이더에 LUT 범위를 제공하는 것은 피크 샘플링 속도와 충분한 수치 정확도를 모두 얻을 수 있는 좋은 방법이었습니다.

00:16:39.000 --> 00:16:48.000
좋아요, 그래서 우리는 이미지 처리 파이프라인을 가능한 한 효율적으로 실행하기 위해 Apple GPU 아키텍처를 어떻게 활용해야 하는지 검토했습니다.

00:16:48.000 --> 00:16:50.000
모든 것을 바로 적용하려면, Harsh를 만나세요!

00:16:50.000 --> 00:16:52.000
가혹한 패틸: 고마워, 유진.

00:16:52.000 --> 00:16:59.000
이제 지금까지 배운 모든 모범 사례를 바탕으로 Apple 실리콘용 이미지 처리 파이프라인을 재설계해 봅시다.

00:16:59.000 --> 00:17:05.000
구체적으로 말하자면, 우리는 Apple GPU를 위한 비디오 처리 파이프라인의 이미지 처리 단계를 조정할 것입니다.

00:17:05.000 --> 00:17:10.000
실시간 이미지 처리는 매우 GPU 컴퓨팅과 메모리 대역폭 집약적이다.

00:17:10.000 --> 00:17:16.000
우리는 먼저 그것이 보통 어떻게 설계되었는지 이해한 다음 Apple 실리콘을 위해 어떻게 최적화할 수 있는지 이해할 것이다.

00:17:16.000 --> 00:17:22.000
우리는 이 섹션에서 비디오 편집 워크플로우의 세부 사항을 다루지 않을 것이므로, 2년 전의 우리의 이야기를 참조하십시오.

00:17:22.000 --> 00:17:27.000
우리는 이미지 처리의 컴퓨팅 부분을 렌더링 경로로 전환하는 데에만 집중할 것입니다.

00:17:27.000 --> 00:17:33.000
시작하기 전에, 일반적인 비디오 처리 파이프라인에서 이미지 처리 단계가 어디에 있는지 빠르게 살펴봅시다.

00:17:33.000 --> 00:17:37.000
우리는 ProRes로 인코딩된 입력 파일을 예로 들 것이다.

00:17:37.000 --> 00:17:41.000
우리는 먼저 디스크나 외부 저장소에서 ProRes로 인코딩된 프레임을 읽습니다.

00:17:41.000 --> 00:17:50.000
그런 다음 CPU의 프레임을 디코딩하고, 이제 이미지 처리 단계는 GPU의 이 디코딩된 프레임에서 실행되고 최종 출력 프레임을 렌더링합니다.

00:17:50.000 --> 00:17:53.000
마지막으로, 우리는 이 출력 프레임을 표시합니다.

00:17:53.000 --> 00:17:57.000
우리는 또한 배달을 위해 최종 렌더링 프레임을 인코딩할 수 있다.

00:17:57.000 --> 00:18:02.000
다음으로, 이미지 처리 파이프라인을 구성하는 것을 살펴봅시다.

00:18:02.000 --> 00:18:09.000
이미지 처리는 처음에 알파에서 소스 이미지 RGB의 다른 채널을 별도의 버퍼로 푸는 것으로 시작됩니다.

00:18:09.000 --> 00:18:15.000
우리는 이미지 처리 파이프라인에서 이러한 각 채널을 함께 또는 개별적으로 처리할 것입니다.

00:18:15.000 --> 00:18:21.000
다음으로, 원하는 색상 관리 환경에서 작동하는 색상 공간 변환이 있을 수 있습니다.

00:18:21.000 --> 00:18:31.000
그런 다음 3D LUT를 적용하고, 색상 보정을 수행한 다음, 공간-시간 노이즈 감소, 컨벌루션, 블러 및 기타 효과를 적용합니다.

00:18:31.000 --> 00:18:36.000
그리고 마지막으로, 우리는 최종 출력을 위해 개별적으로 처리된 채널을 함께 포장합니다.

00:18:36.000 --> 00:18:39.000
이 선택된 단계들의 공통점은 무엇인가요?

00:18:39.000 --> 00:18:43.000
그것들은 모두 픽셀 간 의존성 없이 단일 픽셀에서만 작동하는 포인트 필터입니다.

00:18:43.000 --> 00:18:47.000
이것들은 조각 셰이더 구현에 잘 매핑된다.

00:18:47.000 --> 00:18:54.000
공간 및 컨벌루션 스타일 작업은 큰 픽셀 반경에 대한 액세스가 필요하며, 읽기-쓰기 액세스 패턴도 흩어져 있습니다.

00:18:54.000 --> 00:18:57.000
이것들은 컴퓨팅 커널에 적합합니다.

00:18:57.000 --> 00:18:58.000
우리는 나중에 이 지식을 사용할 것이다.

00:18:58.000 --> 00:19:02.000
지금은, 이 작업들이 어떻게 실행되는지 봅시다.

00:19:02.000 --> 00:19:06.000
응용 프로그램은 필터 그래프로 이미지에 적용된 효과의 사슬을 나타낸다.

00:19:06.000 --> 00:19:12.000
모든 필터는 자체 커널이며, 이전 단계의 입력을 처리하고 다음 단계를 위한 출력을 생성합니다.

00:19:12.000 --> 00:19:20.000
여기에 있는 모든 화살표는 한 단계의 출력으로/에서 기록되고 다음 단계의 입력으로 읽히는 버퍼를 의미합니다.

00:19:20.000 --> 00:19:26.000
메모리가 제한되어 있기 때문에, 애플리케이션은 일반적으로 위상 정렬을 수행하여 그래프를 선형화한다.

00:19:26.000 --> 00:19:33.000
이것은 경쟁 조건을 피하면서 중간 자원의 총 수를 가능한 한 낮게 유지하기 위해 수행됩니다.

00:19:33.000 --> 00:19:41.000
그 예에서 이 간단한 필터 그래프는 경쟁 조건 없이 작동하고 최종 출력을 생성하기 위해 두 개의 중간 버퍼가 필요합니다.

00:19:41.000 --> 00:19:46.000
여기서 선형화된 그래프는 대략 GPU 명령 버퍼 인코딩을 나타낸다.

00:19:46.000 --> 00:19:52.000
이 필터 그래프가 왜 장치 메모리 대역폭 집약적인지 더 자세히 살펴봅시다.

00:19:52.000 --> 00:20:01.000
모든 필터 작업은 장치 메모리의 전체 이미지를 레지스터로 로드하고 결과를 장치 메모리에 다시 기록해야 합니다.

00:20:01.000 --> 00:20:03.000
그리고 그것은 꽤 많은 메모리 트래픽이다.

00:20:03.000 --> 00:20:11.000
예시 이미지 처리 그래프를 기반으로 4K 프레임 이미지 처리의 메모리 풋프린트를 추정해 봅시다.

00:20:11.000 --> 00:20:25.000
4K 디코딩된 프레임 자체는 부동 소수점 16 정밀도를 위해 67메가바이트의 메모리 또는 부동 소수점 32 정밀도를 위해 135메가바이트의 메모리를 필요로 하며, 전문적인 워크플로우는 부동 소수점 32 정밀도가 절대적으로 필요합니다.

00:20:25.000 --> 00:20:36.000
이 이미지 처리 그래프를 통해 부동 소수점 32 정밀도로 하나의 4K 프레임을 처리하기 위해, 우리는 장치 메모리에 대한 2GB 이상의 읽기-쓰기 트래픽에 대해 이야기하고 있습니다.

00:20:36.000 --> 00:20:43.000
또한, 중간 출력을 보유하고 있는 버퍼에 쓰는 것은 캐시 계층 구조를 스래시하고 칩의 다른 블록에도 영향을 미친다.

00:20:43.000 --> 00:20:48.000
일반 컴퓨팅 커널은 온칩 타일 메모리의 혜택을 암시적으로 받지 않는다.

00:20:48.000 --> 00:20:54.000
커널은 온칩 타일 메모리에 의해 백업될 스레드 그룹 범위 메모리를 명시적으로 할당할 수 있다.

00:20:54.000 --> 00:21:00.000
그러나, 그 타일 메모리는 컴퓨팅 인코더 내의 디스패치에서 지속되지 않는다.

00:21:00.000 --> 00:21:06.000
대조적으로, 타일 메모리는 실제로 하나의 렌더링 명령 인코더 내에서 드로우 패스에서 지속된다.

00:21:06.000 --> 00:21:12.000
타일 메모리를 활용하기 위해 이 대표적인 이미지 처리 파이프라인을 어떻게 재설계할 수 있는지 봅시다.

00:21:12.000 --> 00:21:15.000
우리는 세 단계를 따라 이 문제를 해결할 것이다.

00:21:15.000 --> 00:21:21.000
우리는 먼저 컴퓨팅 패스를 렌더링 패스와 모든 중간 출력 버퍼를 텍스처로 변경합니다.

00:21:21.000 --> 00:21:34.000
그런 다음 픽셀 간 의존성 없이 픽셀당 작업을 하나의 렌더링 명령 인코더 내에서 프래그먼트 셰이더 호출로 인코딩하여 모든 중간 결과를 설명하고 적절한 로드/저장 작업을 설정합니다.

00:21:34.000 --> 00:21:40.000
그리고 마지막으로, 우리는 단순한 포인트 필터보다 더 복잡한 상황에서 우리가 무엇을 하는지 논의한다.

00:21:40.000 --> 00:21:45.000
우리의 첫 번째 단계는 별도의 MTLRenderCommandEncoder를 사용하여 적격 셰이더를 인코딩하는 것입니다.

00:21:45.000 --> 00:21:59.000
이 필터 그래프에서 압축 해제, 색상 공간 변환, LUT 및 색상 보정 필터는 모두 조각 셰이더로 변환하고 하나의 렌더링 명령 인코더를 사용하여 인코딩할 수 있는 픽셀당 포인트 필터입니다.

00:21:59.000 --> 00:22:11.000
마찬가지로, 이 이미지 처리 파이프라인의 끝에 있는 믹서 및 팩 셰이더는 프래그먼트 셰이더로 변환하고 다른 MTLRenderCommandEncoder를 사용하여 인코딩할 수 있습니다.

00:22:11.000 --> 00:22:15.000
그런 다음 각각의 렌더링 패스 내에서 이러한 셰이더를 호출할 수 있습니다.

00:22:15.000 --> 00:22:22.000
렌더링 패스를 만들 때, 해당 렌더링 패스의 색상 첨부 파일에 첨부된 모든 리소스는 암시적으로 타일링됩니다.

00:22:22.000 --> 00:22:29.000
프래그먼트 셰이더는 타일에서 프래그먼트의 위치와 관련된 이미지 블록 데이터만 업데이트할 수 있습니다.

00:22:29.000 --> 00:22:35.000
동일한 렌더링 패스의 다음 셰이더는 타일 메모리에서 직접 이전 셰이더의 출력을 선택할 수 있습니다.

00:22:35.000 --> 00:22:41.000
다음 섹션에서, 우리는 이 필터에 매핑되는 프래그먼트 셰이더를 어떻게 구성할 수 있는지 살펴볼 것이다.

00:22:41.000 --> 00:22:50.000
우리는 또한 이러한 프래그먼트 셰이더 내에서 기본 타일 메모리에 액세스할 수 있도록 정의하고 사용해야 하는 구조를 살펴볼 것입니다.

00:22:50.000 --> 00:23:02.000
그리고 마지막으로, 우리는 하나의 조각 셰이더에 의해 타일 메모리에서 생성된 출력이 동일한 렌더링 명령 인코더 내의 다음 조각 셰이더에 의해 타일 메모리에서 직접 소비되는 방법을 살펴볼 것입니다.

00:23:02.000 --> 00:23:05.000
이것이 당신이 코드에서 해야 할 일입니다.

00:23:05.000 --> 00:23:11.000
여기에 렌더링 패스 설명자의 색상 첨부 0에 첨부된 텍스처로 출력 이미지를 첨부했습니다.

00:23:11.000 --> 00:23:17.000
렌더링 패스 설명자의 색상 첨부 1에 중간 결과를 유지하는 텍스처를 첨부했습니다.

00:23:17.000 --> 00:23:21.000
이 두 가지 모두 당신을 위해 암묵적으로 타일링될 것입니다.

00:23:21.000 --> 00:23:26.000
대화의 앞부분에서 논의한 대로 적절한 로드/스토어 속성을 설정해 주세요.

00:23:26.000 --> 00:23:30.000
이제, 프래그먼트 셰이더에서 이러한 텍스처에 접근할 수 있는 구조를 설정하세요.

00:23:30.000 --> 00:23:35.000
다음 예제에서, 우리는 당신의 조각 셰이더 내에서 이 구조를 사용하는 방법을 보여줄 것입니다.

00:23:35.000 --> 00:23:43.000
앞서 정의한 구조를 사용하여 강조 표시된 대로 조각 셰이더 내의 출력과 중간 텍스처에 액세스하기만 하면 됩니다.

00:23:43.000 --> 00:23:49.000
이 텍스처에 대한 쓰기는 조각에 해당하는 적절한 타일 메모리 위치에 수행됩니다.

00:23:49.000 --> 00:23:57.000
언팩 셰이더에 의해 생성된 출력은 우리가 이전에 정의한 것과 동일한 구조를 사용하여 색 공간 변환 셰이더에 의해 입력으로 소비됩니다.

00:23:57.000 --> 00:24:06.000
이 조각 셰이더는 자체 처리를 하고 출력과 중간 텍스처를 업데이트하여 해당 타일 메모리 위치를 다시 한 번 업데이트할 수 있습니다.

00:24:06.000 --> 00:24:12.000
동일한 렌더링 인코더 패스 내의 다른 모든 조각 셰이더에 대해 동일한 단계를 계속해야 합니다.

00:24:12.000 --> 00:24:17.000
다음으로, 이러한 변화와 함께 이 일련의 작업이 어떻게 보이는지 시각화해 봅시다.

00:24:17.000 --> 00:24:30.000
보시다시피, 이제 팩 풀기, 색상 공간 변환, 3D LUT 적용 및 색상 보정 단계가 있으며, 모두 장치 메모리 패스 없이 하나의 렌더링 패스를 사용하여 타일 메모리에서 실행됩니다.

00:24:30.000 --> 00:24:36.000
렌더링 패스가 끝날 때, 메모리가 없는 렌더링 대상은 장치 메모리로 플러시됩니다.

00:24:36.000 --> 00:24:39.000
그런 다음 다음 클래스의 필터를 실행할 수 있습니다.

00:24:39.000 --> 00:24:43.000
분산 수집 액세스 패턴이 있는 필터에 대해 조금 이야기해 봅시다.

00:24:43.000 --> 00:24:49.000
이러한 필터를 나타내는 커널은 장치 메모리의 데이터에서 직접 작동할 수 있다.

00:24:49.000 --> 00:24:54.000
컨벌루션 필터는 컴퓨팅 커널의 타일 기반 작업에 매우 적합합니다.

00:24:54.000 --> 00:25:00.000
여기서, 스레드 그룹 범위 메모리를 선언하여 타일 메모리를 사용하려는 의도를 표현할 수 있습니다.

00:25:00.000 --> 00:25:11.000
이제 필터 반경에 따라 필요한 모든 후광 픽셀과 함께 픽셀 블록을 타일 메모리에 가져오고 타일 메모리에서 직접 컨벌루션 작업을 수행합니다.

00:25:11.000 --> 00:25:17.000
타일 메모리는 컴퓨팅 인코더 내의 컴퓨팅 디스패치에서 지속되지 않는다는 것을 기억하십시오.

00:25:17.000 --> 00:25:23.000
따라서 필터1을 실행한 후, 타일 메모리 내용을 장치 메모리로 명시적으로 플러시해야 합니다.

00:25:23.000 --> 00:25:27.000
그렇게 하면, Filter2는 Filter1의 출력을 소비할 수 있다.

00:25:27.000 --> 00:25:30.000
그래서 우리가 이 모든 변화를 만들면 우리는 어디에 착륙해야 하나요?

00:25:30.000 --> 00:25:39.000
재구성된 이미지 처리 그래프를 통해 부동 소수점 32 정밀도로 하나의 4K 프레임을 처리하기 위해, 우리가 지금 가지고 있는 것은 다음과 같습니다.

00:25:39.000 --> 00:25:48.000
대역폭은 2.16기가바이트에서 810메가바이트의 가치가 있는 로드 및 저장으로 감소하며, 이는 장치 메모리에 대한 메모리 트래픽의 62% 감소이다.

00:25:48.000 --> 00:25:54.000
우리는 프레임당 270메가바이트의 메모리를 절약하는 두 개의 중간 장치 버퍼가 필요하지 않습니다.

00:25:54.000 --> 00:26:02.000
그리고 마지막으로, 우리는 캐시 스래싱을 줄였고, 그것은 렌더링 패스 내의 모든 프래그먼트 셰이더가 타일 메모리에서 직접 작동하기 때문입니다.

00:26:02.000 --> 00:26:07.000
애플 실리콘의 주요 특징 중 하나는 통합 메모리 아키텍처이다.

00:26:07.000 --> 00:26:15.000
Apple 실리콘의 다른 블록 간의 상호 작용을 위해 이 통합 메모리 아키텍처를 활용하는 방법의 예를 봅시다.

00:26:15.000 --> 00:26:21.000
우리는 GPU에 의해 렌더링된 최종 비디오 프레임의 HEVC 인코딩을 사례 연구로 가져갈 것이다.

00:26:21.000 --> 00:26:27.000
이 인코딩은 Apple 실리콘의 전용 하드웨어 미디어 엔진을 사용하여 수행됩니다.

00:26:27.000 --> 00:26:33.000
GPU에 의해 렌더링된 최종 출력 프레임은 추가 메모리 복사본 없이 미디어 엔진에서 직접 사용할 수 있습니다.

00:26:33.000 --> 00:26:43.000
다음 섹션에서는 GPU가 가장 효율적으로 생성한 최종 출력 프레임의 HEVC 인코딩을 위한 파이프라인을 설정하는 방법에 대한 예를 살펴볼 것입니다.

00:26:43.000 --> 00:26:51.000
그것을 위해, 먼저 우리는 CoreVideo API를 활용하여 IOSurfaces가 지원하는 픽셀 버퍼 풀을 만들 것입니다.

00:26:51.000 --> 00:26:59.000
그런 다음, Metal API를 사용하여, 우리는 방금 만든 풀에서 IOSurfaces에 의해 뒷받침되는 금속 텍스처로 최종 프레임을 렌더링합니다.

00:26:59.000 --> 00:27:09.000
그리고 마지막으로, 우리는 GPU에서 생성된 출력 프레임의 추가 복사본 없이 인코딩하기 위해 이러한 픽셀 버퍼를 미디어 엔진에 직접 파견하여 통합 메모리 아키텍처를 활용합니다.

00:27:09.000 --> 00:27:15.000
이 단계를 단계별로 수행하는 방법을 살펴보고 이 흐름을 가능하게 하는 데 필요한 모든 구성을 다루도록 합시다.

00:27:15.000 --> 00:27:21.000
먼저, 우리는 IOSurface가 지원하는 CVPixelBufferPool을 원하는 픽셀 형식으로 만듭니다.

00:27:21.000 --> 00:27:28.000
여기서, 우리는 HEVC 인코딩을 위해 이중 평면 크로마 서브샘플링 픽셀 형식을 사용할 것이다.

00:27:28.000 --> 00:27:32.000
이제, 당신은 이 CVPixelBufferPool에서 CVPixelBuffer를 얻을 수 있습니다.

00:27:32.000 --> 00:27:39.000
이 CVPixelBuffer를 올바른 평면 인덱스로 MetalTextureCache에 전달하여 CVMetalTextureReference를 받으세요.

00:27:39.000 --> 00:27:45.000
우리는 이중 평면 픽셀 형식을 사용하고 있기 때문에, 이중 평면 픽셀 버퍼의 두 평면 모두에 대해 이 단계를 수행해야 합니다.

00:27:45.000 --> 00:27:50.000
다음으로, CVMetalTextureReference 객체에서 기본 금속 텍스처를 가져옵니다.

00:27:50.000 --> 00:27:53.000
루마면과 크로마면 모두에서 이 단계를 수행하세요.

00:27:53.000 --> 00:28:00.000
이 금속 텍스처는 CVPixelBuffer 평면을 지원하는 동일한 IOSurfaces에 의해 뒷받침된다는 것을 기억하십시오.

00:28:00.000 --> 00:28:06.000
금속 API를 사용하여, 루마와 크로마 평면에 해당하는 텍스처로 렌더링하세요.

00:28:06.000 --> 00:28:10.000
이것은 이 금속 질감을 뒷받침하는 IOSurface도 업데이트할 것이다.

00:28:10.000 --> 00:28:18.000
이미지 처리 파이프라인 내에서 셰이더 패스로 GPU 자체의 크로마 평면에서 크로마 서브샘플링 단계를 수행하는 것이 좋습니다.

00:28:18.000 --> 00:28:29.000
주목해야 할 중요한 점은 우리가 방금 렌더링한 CVPixelBuffer와 Metal 텍스처가 모두 시스템 메모리의 동일한 기본 IOSurface 복사본에 의해 뒷받침된다는 것입니다.

00:28:29.000 --> 00:28:33.000
이제 인코딩을 위해 이 CVPixelBuffer를 미디어 엔진으로 직접 보낼 수 있습니다.

00:28:33.000 --> 00:28:41.000
보시다시피, 통합 메모리 아키텍처로 인해 메모리 복사본 없이 GPU와 미디어 엔진 블록 간에 데이터를 원활하게 이동할 수 있습니다.

00:28:41.000 --> 00:28:48.000
그리고 마지막으로, 매 프레임마다 CVPixelBuffer와 CVMetalTexture 참조를 공개하는 것을 잊지 마세요.

00:28:48.000 --> 00:28:53.000
CVPixelBuffer를 출시하면 향후 프레임을 위해 이 버퍼를 재활용할 수 있습니다.

00:28:53.000 --> 00:29:16.000
마무리하기 위해, 통합 메모리 아키텍처를 활용하고, 해당되는 경우 컴퓨팅 대신 MTLRenderCommandEncoder를 사용하고, 단일 렌더링 명령 인코더 내에서 모든 적격 렌더링 패스를 병합하고, 적절한 로드/저장 작업을 설정하고, 일시적인 리소스에 메모리를 사용하고, 해당되는 경우 타일 셰이딩을 활용하고, 제로 카피를 위해 다른 API와 버퍼 풀을 사용하는 것이 좋습니다.

00:29:16.000 --> 00:29:19.000
오늘 이 세션에 참여해 주셔서 감사합니다.

00:29:19.000 --> 00:29:22.000
WWDC 2021의 나머지를 즐기세요!

00:29:22.000 --> 23:59:59.000
♪

