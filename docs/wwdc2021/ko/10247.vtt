WEBVTT

00:00:02.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:11.000
안녕, 내 이름은 로이야.

00:00:11.000 --> 00:00:13.000
저는 카메라 소프트웨어 팀의 엔지니어입니다.

00:00:13.000 --> 00:00:24.000
오늘 저는 우리가 가장 인기 있는 비디오 포맷으로 만든 몇 가지 흥미로운 사진 품질 개선과 당신의 응용 프로그램이 더 나은 경험을 제공하기 위해 그것들을 어떻게 사용할 수 있는지 안내할 것입니다.

00:00:24.000 --> 00:00:38.000
아이폰은 세계에서 가장 인기 있는 카메라이며, 수년 동안 개발자들은 강력한 카메라 시스템을 활용하여 전문 사진 앱에서 비디오 스트리밍 도구에 이르기까지 다양한 세계적 수준의 경험을 제공해 왔습니다.

00:00:38.000 --> 00:00:41.000
다른 시나리오는 다른 수준의 사진 품질을 요구한다.

00:00:41.000 --> 00:00:48.000
예를 들어, 스틸 사진 촬영 전용 앱은 카메라가 제공할 수 있는 최고의 품질을 요구할 것이다.

00:00:48.000 --> 00:00:54.000
반면에 소셜 앱은 스트리밍되는 비디오 프레임 위에 얼굴 효과 오버레이를 적용해야 할 수도 있습니다.

00:00:54.000 --> 00:00:58.000
그리고 이 사용자 지정 렌더링은 계산적으로 비쌀 수 있다.

00:00:58.000 --> 00:01:05.000
프레임 드롭을 피하기 위해, 개발자는 더 낮은 해상도의 프레임을 선호할 수 있으므로 프레임당 처리할 픽셀이 적을 수 있습니다.

00:01:05.000 --> 00:01:13.000
이러한 사용 사례의 다양성은 품질 대 성능의 규모에서 어디에 착륙하고 싶은지 지정할 수 있는 쉬운 방법을 요구합니다.

00:01:13.000 --> 00:01:19.000
그러나 사진 품질에 뛰어들기 전에, 일반적으로 iOS에서 사진을 찍는 방법에 대해 간단히 재교육해 봅시다.

00:01:19.000 --> 00:01:25.000
우리는 객체 그래프를 만들 수 있는 AVCaptureSession 객체로 시작할 것이다.

00:01:25.000 --> 00:01:29.000
우리가 사진을 찍고 있기 때문에, 우리는 카메라를 AVCaptureDevice로 사용할 것이다.

00:01:29.000 --> 00:01:38.000
그런 다음, AVCaptureDeviceInput은 해당 장치를 기반으로 인스턴스화되며, 세션에 입력 데이터를 제공합니다.

00:01:38.000 --> 00:01:44.000
그러면 AVCapturePhotoOutput이 사진의 수신자로 그래프에 추가됩니다.

00:01:44.000 --> 00:01:49.000
그리고 이 모든 요소는 AVCaptureConnection을 사용하여 함께 연결됩니다.

00:01:49.000 --> 00:01:57.000
세션이 실행되기 시작한 후, AVCapturePhotoOutput 인스턴스에서 capturePhoto 메소드를 호출하여 사진을 캡처할 수 있습니다.

00:01:57.000 --> 00:02:04.000
capturePhoto 방법으로 전달된 AVCapturePhotoSettings 객체를 사용하여 추가 사용자 지정을 수행할 수 있습니다.

00:02:04.000 --> 00:02:11.000
캡처된 사진은 위임 방법에서 받게 될 AVCapturePhoto 객체로 표시됩니다.

00:02:11.000 --> 00:02:18.000
우리는 2016년 세션인 Advances in iOS Photography에서 이러한 API에 대해 매우 자세한 논의를 했습니다.

00:02:18.000 --> 00:02:21.000
아직 확인하지 않았다면 확인해 주세요.

00:02:21.000 --> 00:02:27.000
이제 우리는 일반적으로 iOS에서 사진을 찍는 방법을 알았으니, 어떻게 고품질 사진을 찍을 수 있는지 봅시다.

00:02:27.000 --> 00:02:42.000
역사적으로, 최상의 품질의 사진을 캡처하고 싶다면, AVCapturePhotoSettings의 isAutoStillImageStabilization Enabled 속성을 true로 설정할 수 있으며, 이는 여전히 이미지 안정화가 고품질 사진을 얻는 주요 방법이었기 때문입니다.

00:02:42.000 --> 00:02:48.000
하지만 수년에 걸쳐, 우리는 사진 품질 향상 알고리즘을 지속적으로 발전시켜 왔습니다.

00:02:48.000 --> 00:02:59.000
스틸 이미지 안정화 외에도, 우리는 이제 스마트 HDR과 딥 퓨전을 포함한 다양한 다중 이미지 융합 기술과 같은 훨씬 더 풍부한 기술을 가지고 있습니다.

00:02:59.000 --> 00:03:07.000
결과적으로, IsAutoStillImageStabilization Enabled라는 이름은 높은 사진 품질의 프록시로서 상당히 쓸모없게 되었다.

00:03:07.000 --> 00:03:14.000
이 문제를 해결하기 위해 iOS 13에서 AVCapturePhotoOutput.QualityPrio ritization을 도입했습니다.

00:03:14.000 --> 00:03:20.000
AVCapturePhotoOutput에게 사진 캡처의 품질을 우선시하는 방법을 알려주는 매우 쉬운 방법입니다.

00:03:20.000 --> 00:03:28.000
우리는 이전 WWDC에서 이 중요한 API에 대해 이야기할 기회가 없었기 때문에, 이제 그것이 어떻게 작동하는지 잠시 봅시다.

00:03:28.000 --> 00:03:34.000
선택할 수 있는 세 가지 품질 우선 순위 수준이 있습니다: 속도, 균형 및 품질.

00:03:34.000 --> 00:03:42.000
속도로, 당신은 캡처 속도가 사진 품질을 희생시키더라도 당신이 가장 신경 쓰는 것이라고 프레임워크에 말하고 있습니다.

00:03:42.000 --> 00:03:48.000
사진 품질과 배달 속도 사이에서 균형을 맞춰야 한다면, 균형을 맞춰야 한다.

00:03:48.000 --> 00:03:50.000
품질은 속도의 반대이다.

00:03:50.000 --> 00:03:58.000
캡처 프로세스의 잠재적인 느림은 용인될 수 있는 반면, 이미지 품질을 우선시해야 한다고 말한다.

00:03:58.000 --> 00:04:08.000
지정된 품질 우선 순위는 AVCapturePhotoOutput에 대한 힌트 역할을 하며, 어떤 알고리즘을 사용할지 지시하지 않는다는 점에 유의하십시오.

00:04:08.000 --> 00:04:16.000
궁극적으로, AVCapturePhotoOutput은 다양한 제약을 고려하고 현재 장면에 가장 적합한 알고리즘을 선택할 것이다.

00:04:16.000 --> 00:04:22.000
예를 들어, 조명이 잘 켜진 공간보다 저조도 상황에 대해 다른 방법을 선택할 수 있다.

00:04:22.000 --> 00:04:29.000
그렇긴 하지만, 우리는 다른 캡처 기간에 따라 사용자 경험을 다르게 계획하고 싶을 수도 있다는 것을 이해합니다.

00:04:29.000 --> 00:04:43.000
따라서 AVCapturePhotoOutputDelegate 메소드 중 일부에 전달된 AVCaptureResolvedPhotoSettings 객체에서, 우리는 당신의 대리인에게 사진을 전달하는 데 걸리는 시간을 나타내는 photoProcessingTimeRange라는 속성을 제공합니다.

00:04:43.000 --> 00:04:49.000
예를 들어, 이것은 캡처에 시간이 걸릴 경우 스피너를 내놓을지 여부를 결정하는 데 도움이 될 수 있습니다.

00:04:49.000 --> 00:04:51.000
코드에서 어떻게 작동하는지 봅시다.

00:04:51.000 --> 00:04:59.000
AVCapturePhotoOutput을 설정할 때, 특정 캡처 세션에 필요한 최대 품질 우선 순위를 지정할 수 있습니다.

00:04:59.000 --> 00:05:02.000
그렇게 하지 않기로 선택하면, 기본값은 균형을 이룬다.

00:05:02.000 --> 00:05:04.000
이것은 한 번만 설정하면 됩니다.

00:05:04.000 --> 00:05:11.000
그렇게 하는 것의 중요성은 다른 설정에 따라 캡처 파이프라인을 다르게 구성할 것이라는 것이다.

00:05:11.000 --> 00:05:21.000
예를 들어, 당신이 속도 우선순위를 넘어서지 않을 것이라는 것을 안다면, 우리는 균형 잡힌 우선순위보다 훨씬 적은 메모리와 전력을 소비하는 캡처 파이프라인을 구성할 수 있습니다.

00:05:21.000 --> 00:05:26.000
그래서 우리는 당신이 책임감 있게 선택하고 필요한 것만 가져갈 것을 권장합니다.

00:05:26.000 --> 00:05:37.000
capturePhoto 메소드를 호출하기 전에, AVCapturePhotoSettings 객체에서 photoQualityPrioritization 속성을 설정하여 이 특정 캡처의 품질 우선 순위를 사용자 정의할 수 있습니다.

00:05:37.000 --> 00:05:39.000
기본값은 균형을 이룬다.

00:05:39.000 --> 00:05:44.000
여기서 입증된 바와 같이, 우리는 두 가지 다른 상황에서 두 가지 다른 수준을 사용하고 있다.

00:05:44.000 --> 00:05:54.000
캡처당 품질 우선 순위는 AVCapturePhotoOutput의 최대 품질 우선 순위를 초과할 수 없습니다. 그렇지 않으면 예외가 발생합니다.

00:05:54.000 --> 00:06:00.000
세 단계의 성능 특성은 우리가 사용하는 기본 알고리즘에 의해 결정된다.

00:06:00.000 --> 00:06:08.000
매핑은 당신이 사용하는 형식의 종류에 따라 다르며, 우리는 사진과 비디오 형식의 차이점에 대해 잠시 더 이야기할 것입니다.

00:06:08.000 --> 00:06:18.000
사진 형식을 사용하면 Speed는 WYSIWYG 사진을 얻을 수 있습니다. 즉, What You See is What You Get 사진입니다. 이 사진은 약간의 노이즈 감소가 적용된 상태에서만 가볍게 처리됩니다.

00:06:18.000 --> 00:06:28.000
Balanced가 지정되면, 우리는 다소 느린 캡처 속도로 WYSIWYG 사진보다 훨씬 더 나은 사진 품질을 생성하는 빠른 융합 알고리즘 모음 중에서 선택할 것입니다.

00:06:28.000 --> 00:06:38.000
품질을 위해, 현재 장치와 럭스 수준에 따라, 프레임워크는 최상의 사진 품질을 제공하기 위해 딥 퓨전과 같은 무거운 기계를 사용할 것이다.

00:06:38.000 --> 00:06:41.000
그 사진들은 멋져 보일 것이지만, 공짜 점심은 없다.

00:06:41.000 --> 00:06:43.000
당신은 더 많은 시간을 사용하여 비용을 지불합니다.

00:06:43.000 --> 00:06:50.000
반면에 비디오 포맷의 경우, 모든 레벨은 가능한 한 빨리 사진을 전달하기 위해 가장 가벼운 처리를 사용할 것이다.

00:06:50.000 --> 00:06:53.000
우리는 한동안 사진과 비디오 형식에 대해 이야기해 왔다.

00:06:53.000 --> 00:06:56.000
그들 사이의 차이점을 좀 더 자세히 살펴봅시다.

00:06:56.000 --> 00:07:02.000
사진 형식을 사용함으로써, 당신은 스틸 사진을 찍는 것이 당신이 가장 신경 쓰는 것이라는 프레임워크에 신호를 보내고 있습니다.

00:07:02.000 --> 00:07:20.000
예를 들어, AVCaptureVideoDataOutput을 사진 형식으로 사용하는 경우, 기본적으로 얻는 샘플 버퍼는 미리보기 해상도일 뿐이며, 사진을 찍는 것이 최우선 순위라는 것을 알기 때문에 이러한 프레임이 비디오 녹화가 아닌 미리보기에 사용될 것이라고 가정할 수 있습니다.

00:07:20.000 --> 00:07:30.000
사진 형식을 선택하는 좋은 이유는 일부 사진 중심 기능이 Live Photo 및 ProRAW 등과 같은 사진 형식에만 해당하기 때문입니다.

00:07:30.000 --> 00:07:34.000
그것이 당신이 하고 싶은 일이라면, 사진 형식이 가장 좋은 방법입니다.

00:07:34.000 --> 00:07:41.000
사진 포맷은 사용 가능한 가장 높은 해상도로 제공되지만, 프레임 속도는 초당 30프레임으로 제한됩니다.

00:07:41.000 --> 00:07:44.000
사진 형식을 선택하려면, 세션 프리셋을 사진으로 설정할 수 있습니다.

00:07:44.000 --> 00:07:49.000
또는 isHighestPhotoQualitySupported가 사실인 형식을 선택할 수 있습니다.

00:07:49.000 --> 00:07:55.000
반면에 비디오 형식의 사용은 경험이 이제 비디오에 중점을 둘 것임을 나타냅니다.

00:07:55.000 --> 00:08:02.000
녹화 및 스트리밍에 더 적합한 해상도를 얻을 수 있으며, 60fps와 같은 높은 프레임 속도를 사용할 수 있습니다.

00:08:02.000 --> 00:08:07.000
포맷이 사진 포맷이 아니라면, 비디오 포맷으로 간주됩니다.

00:08:07.000 --> 00:08:14.000
따라서 사진이 아닌 세션 사전 설정을 사용하거나 isHighestPhotoQualitySupported가 거짓인 형식을 선택하여 하나를 선택할 수 있습니다.

00:08:14.000 --> 00:08:19.000
당신은 왜 우리가 비디오 포맷에 강력한 알고리즘을 적용하지 않는지 궁금할 것입니다.

00:08:19.000 --> 00:08:20.000
우리가 게으르기 때문이 아니야.

00:08:20.000 --> 00:08:22.000
우리는 그것에 대한 타당한 이유가 있다.

00:08:22.000 --> 00:08:32.000
많은 앱은 무거운 사용자 지정 처리를 해야 하기 때문에 비디오 형식을 사용하기로 선택하며, 비디오 형식은 오버헤드가 적기 때문에 이러한 목적에 적합합니다.

00:08:32.000 --> 00:08:39.000
앞서 언급한 사진 향상 기술 중 일부를 활용한다면, 이러한 앱의 경험에 저하를 도입할 수 있습니다.

00:08:39.000 --> 00:08:46.000
예를 들어, AR 앱을 사용하면 사용자가 상호 작용하는 3D 장면의 사진을 찍을 수 있습니다.

00:08:46.000 --> 00:08:54.000
이 시점에서 기존 융합 알고리즘을 실행하면 앱의 카메라 피드에 프레임 드롭을 도입하여 핵심 기능을 방해할 수 있습니다.

00:08:54.000 --> 00:09:05.000
그래서 우리는 품질과 속도 사이의 섬세한 균형을 매우 의식해 왔으며, 가장 까다로운 조건에서도 반응적으로 작동하도록 비디오 형식을 설계했습니다.

00:09:05.000 --> 00:09:08.000
하지만 그 타협은 오늘 iOS 15에서 멈춘다.

00:09:08.000 --> 00:09:13.000
우리는 가장 인기 있는 비디오 포맷으로 사진 품질에서 큰 도약을 하고 있습니다.

00:09:13.000 --> 00:09:21.000
개선된 알고리즘을 통해, 우리는 이제 앱 경험의 다른 측면에 영향을 미치지 않으면서 사진 품질을 근본적으로 향상시킬 수 있습니다.

00:09:21.000 --> 00:09:31.000
이 새로운 기능을 통해, 당신의 앱은 이제 정교한 사용자 지정 계산을 수행할 수 있는 동일한 유연성을 유지하면서 놀라운 사진을 찍을 수 있습니다.

00:09:31.000 --> 00:09:34.000
그래서 우리는 여기서 얼마나 큰 품질 도약에 대해 이야기하고 있나요?

00:09:34.000 --> 00:09:39.000
몇 가지 전후 비교를 살펴봅시다.

00:09:39.000 --> 00:09:41.000
개선은 꽤 상당하다.

00:09:41.000 --> 00:09:46.000
오른쪽에 있는 어린 소년의 얼굴은 소음이 훨씬 적고, 따라서 훨씬 더 자연스러워 보인다.

00:09:46.000 --> 00:09:52.000
그리고 우리는 그의 머리카락에서 나오는 빛을 더 잘 인식할 수 있다.

00:09:52.000 --> 00:09:59.000
피사체의 눈의 포착 조명은 단순히 더 활기차고 활기차다.

00:09:59.000 --> 00:10:05.000
이 야외 저조도 상황에서, 그녀의 얼굴과 옷에 뛰어난 디노이즈가 있다.

00:10:05.000 --> 00:10:08.000
마지막으로, 환경도 더 좋아 보인다.

00:10:08.000 --> 00:10:13.000
의자의 가죽 질감은 훨씬 더 잘 보존되어 있다.

00:10:13.000 --> 00:10:19.000
이제 당신이 유혹을 했으니, 지원되는 비디오 형식에 대한 알고리즘 매핑을 살펴봅시다.

00:10:19.000 --> 00:10:23.000
속도는 여전히 가볍게 처리된 WYSIWYG 사진을 얻을 것이다.

00:10:23.000 --> 00:10:30.000
그들은 여전히 사진을 찍는 가장 빠른 방법이며, 속도가 이제 당신의 최우선 과제이기 때문에, 이것은 청구서에 완벽하게 맞기 때문에, 우리는 그것을 바꾸지 않았습니다.

00:10:30.000 --> 00:10:37.000
비디오 녹화에서 프레임 드롭이나 미리보기 피드에 중단이 없을 것입니다.

00:10:37.000 --> 00:10:45.000
그러나 Balanced를 사용하면 이제 품질이 크게 향상되고 있으며, 사진의 처리 시간이 약간만 증가하고 있습니다.

00:10:45.000 --> 00:10:49.000
그리고 스피드와 마찬가지로, 당신의 비디오 녹화에는 프레임 드롭이 없을 것입니다.

00:10:49.000 --> 00:10:54.000
멋진 사진을 찍고 처리하더라도 미리보기 피드가 중단되지 않습니다.

00:10:54.000 --> 00:10:59.000
마지막으로, 품질을 위해, 우리는 더 나은 품질을 얻기 위해 더 비싼 알고리즘을 실행하고 있다.

00:10:59.000 --> 00:11:04.000
이것은 당신의 장치가 얼마나 최근에 있는지에 따라 프레임을 떨어뜨리거나 미리보기 피드 중단을 일으킬 수 있습니다.

00:11:04.000 --> 00:11:10.000
이 기능은 iPhone XS까지 지원되는 모든 iPhone에서 사용할 수 있습니다.

00:11:10.000 --> 00:11:20.000
이 업그레이드를 받고 있는 비디오 포맷은 가장 인기 있는 포맷입니다: 초당 30프레임과 60프레임을 모두 지원하는 1280x720.

00:11:20.000 --> 00:11:24.000
1920x1080, 또한 30fps와 60fps 모두.

00:11:24.000 --> 00:11:28.000
1920x1440, 30fps.

00:11:28.000 --> 00:11:32.000
그리고 우리는 심지어 30fps로 4K에 대한 지원을 추가했습니다.

00:11:32.000 --> 00:11:35.000
그렇다면 코드에서 올바른 형식을 사용하고 있는지 어떻게 확인할 수 있나요?

00:11:35.000 --> 00:11:37.000
그건 아주 간단해.

00:11:37.000 --> 00:11:44.000
iOS 15에서 우리는 AVCaptureDevice.Format 유형에서 isHighPhotoQualitySupported라는 새로운 속성을 도입하고 있습니다.

00:11:44.000 --> 00:11:48.000
이 기능을 지원하는 형식의 경우, 이 속성은 사실입니다.

00:11:48.000 --> 00:11:57.000
이 속성이 사실인 모든 형식은 비디오 형식이 보장되므로, 실수로 사진 형식을 선택하는 것에 대해 걱정할 필요가 없습니다.

00:11:57.000 --> 00:12:00.000
당신이 그런 형식을 얻고 싶다고 가정해 봅시다.

00:12:00.000 --> 00:12:04.000
AVCaptureDevice 인스턴스에서 사용할 수 있는 형식을 얻기만 하면 됩니다.

00:12:04.000 --> 00:12:09.000
그런 다음 isHighPhotoQualitySupported가 사실인 것을 선택하세요.

00:12:09.000 --> 00:12:12.000
이 기능을 사용하기 위해 샘플 코드 AVCam을 업데이트했습니다.

00:12:12.000 --> 00:12:16.000
작업 예시를 보고 싶다면 확인해 주세요.

00:12:16.000 --> 00:12:24.000
새로운 속성 isHighPhotoQualitySupported를 기존 isHighestPhotoQualitySupported와 혼동할 수 있습니다.

00:12:24.000 --> 00:12:32.000
앞서 언급했듯이, 후자는 형식이 사진 형식인지 여부를 알려주며, 비디오 형식이 높은 사진 품질을 지원하는지 여부를 알려주지 않습니다.

00:12:32.000 --> 00:12:36.000
이제, 이 새로운 기능을 얻기 위해 어떤 일을 해야 하나요?

00:12:36.000 --> 00:12:38.000
답은 아마도.

00:12:38.000 --> 00:12:48.000
이미 AVCapturePhotoOutput과 .balanced 우선 순위를 사용하고 있다면, 축하합니다. iOS 15에서 자동으로 더 멋진 사진을 얻을 수 있습니다.

00:12:48.000 --> 00:12:57.000
앱이 속도 우선 순위를 사용하는 경우, 단순히 균형으로 업데이트하면 프레임 드롭에 대해 걱정할 필요 없이 더 나은 사진을 받을 수 있습니다.

00:12:57.000 --> 00:13:05.000
여전히 더 이상 사용되지 않는 AVCaptureStillImageOutput을 사용하고 있다면, 이것이 전환할 수 있는 큰 인센티브를 제공하기를 바랍니다.

00:13:05.000 --> 00:13:14.000
이제 품질 우선 순위를 사용하면 비디오에 프레임 드롭이 발생할 수 있기 때문에, 우리는 당신이 선택하지 않고 앱에 새로운 행동을 부과하고 싶지 않습니다.

00:13:14.000 --> 00:13:25.000
그래서 우리는 당신의 앱이 비디오 형식으로 품질 우선 순위를 사용하고 있고 iOS 15 이전에 컴파일되었는지 확인하기 위해 링크 시간 확인을 넣었습니다. 그러면 우리는 자동으로 균형 잡힌 것으로 변경할 것입니다.

00:13:25.000 --> 00:13:33.000
정말로 최고의 품질을 얻고 싶다면, iOS 15 SDK로 앱을 다시 컴파일하기만 하면 됩니다.

00:13:33.000 --> 00:13:36.000
알아야 할 몇 가지 주의 사항이 있다.

00:13:36.000 --> 00:13:43.000
이 기능은 현재 AVCaptureSession에서만 작동하며 AVCaptureMultiCamSession에서는 작동하지 않습니다.

00:13:43.000 --> 00:13:48.000
더 이상 사용되지 않는 AVCaptureStillImageOutput은 이 기능을 지원하지 않습니다.

00:13:48.000 --> 00:13:57.000
.Balanced 또는 .quality 우선 순위를 사용하는 경우, 우리가 사용하는 알고리즘 중 일부는 동적 범위를 개선하기 위해 몇 가지 다르게 노출된 이미지를 융합할 수 있습니다.

00:13:57.000 --> 00:14:03.000
사진은 훌륭한 품질을 가질 것이지만, 동시에 녹화되는 비디오와는 다르게 보일 수 있다.

00:14:03.000 --> 00:14:07.000
비디오와 사진이 정확히 똑같아 보이려면, 대신 .speed를 사용하세요.

00:14:07.000 --> 00:14:11.000
마지막으로, 우리가 방금 다룬 것을 요약해 봅시다.

00:14:11.000 --> 00:14:18.000
앱의 경험을 디자인할 때, 품질과 속도 중에서 선택하는 결정에 유의하십시오.

00:14:18.000 --> 00:14:24.000
사용 사례에서 사진 품질이 어떤 역할을 할 것인지 알아내면, 적절한 우선 순위 지정 수준을 사용하여 이를 달성하십시오.

00:14:24.000 --> 00:14:31.000
그리고 최소한의 작업과 때로는 전혀 작업하지 않으면, 이제 비디오 형식으로 놀라운 사진을 얻을 수 있습니다.

00:14:31.000 --> 00:14:32.000
정말 고마워.

00:14:32.000 --> 23:59:59.000
[타격적인 음악].

