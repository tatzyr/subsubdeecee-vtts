WEBVTT

00:00:02.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:10.000
안녕.

00:00:10.000 --> 00:00:14.000
제 이름은 페이캉이고, 저는 비디오 코딩과 프로세싱 팀 출신입니다.

00:00:14.000 --> 00:00:27.000
"비디오 툴박스로 저지연 비디오 인코딩 탐색"에 오신 것을 환영합니다. 저지연 인코딩은 많은 비디오 애플리케이션, 특히 실시간 비디오 통신 앱에서 매우 중요하다.

00:00:27.000 --> 00:00:35.000
이 강연에서, 저는 저지연 인코딩을 달성하기 위해 비디오 툴박스에 새로운 인코딩 모드를 소개할 것입니다.

00:00:35.000 --> 00:00:42.000
이 새로운 모드의 목표는 실시간 애플리케이션을 위해 기존 인코더 파이프라인을 최적화하는 것이다.

00:00:42.000 --> 00:00:47.000
그래서 실시간 비디오 애플리케이션은 무엇을 요구하나요?

00:00:47.000 --> 00:00:54.000
우리는 사람들이 서로에 대해 이야기하지 않도록 통신에서 엔드 투 엔드 대기 시간을 최소화해야 합니다.

00:00:54.000 --> 00:01:01.000
우리는 비디오 앱이 더 많은 장치와 통신할 수 있도록 함으로써 상호 운용성을 강화해야 합니다.

00:01:01.000 --> 00:01:08.000
인코더 파이프라인은 통화에 두 명 이상의 수신자가 있을 때 효율적이어야 한다.

00:01:08.000 --> 00:01:13.000
그 앱은 최고의 시각적 품질로 비디오를 제시해야 한다.

00:01:13.000 --> 00:01:20.000
우리는 네트워크 손실로 인한 오류로부터 통신을 복구하기 위한 신뢰할 수 있는 메커니즘이 필요하다.

00:01:20.000 --> 00:01:27.000
내가 오늘 이야기할 저지연 비디오 인코딩은 이 모든 측면에서 최적화될 것이다.

00:01:27.000 --> 00:01:33.000
이 모드를 사용하면 실시간 애플리케이션이 새로운 수준의 성능을 달성할 수 있습니다.

00:01:33.000 --> 00:01:39.000
이 강연에서, 먼저 나는 저지연 비디오 인코딩에 대한 개요를 제공할 것이다.

00:01:39.000 --> 00:01:45.000
우리는 파이프라인에서 낮은 대기 시간을 달성하는 방법에 대한 기본적인 아이디어를 가질 수 있다.

00:01:45.000 --> 00:01:54.000
그런 다음 VTCompressionSession API를 사용하여 파이프라인을 구축하고 저지연 모드로 인코딩하는 방법을 보여줄 것입니다.

00:01:54.000 --> 00:02:00.000
마지막으로, 나는 우리가 저지연 모드에서 도입하고 있는 여러 기능에 대해 이야기할 것이다.

00:02:00.000 --> 00:02:05.000
먼저 저지연 비디오 인코딩에 대한 개요를 드리겠습니다.

00:02:05.000 --> 00:02:10.000
다음은 Apple 플랫폼의 비디오 인코더 파이프라인에 대한 간략한 다이어그램입니다.

00:02:10.000 --> 00:02:15.000
비디오 툴박스는 CVImagebuffer를 입력 이미지로 사용합니다.

00:02:15.000 --> 00:02:24.000
그것은 비디오 인코더에게 원시 데이터의 크기를 줄이기 위해 H.264와 같은 압축 알고리즘을 수행하도록 요청합니다.

00:02:24.000 --> 00:02:33.000
출력 압축 데이터는 CMSampleBuffer로 래핑되며, 비디오 통신을 위해 네트워크를 통해 전송될 수 있습니다.

00:02:33.000 --> 00:02:44.000
이전 다이어그램에서 알 수 있듯이, 엔드 투 엔드 대기 시간은 처리 시간과 네트워크 전송 시간이라는 두 가지 요인에 의해 영향을 받을 수 있습니다.

00:02:44.000 --> 00:02:50.000
처리 시간을 최소화하기 위해, 저지연 모드는 프레임 재정렬을 제거합니다.

00:02:50.000 --> 00:02:54.000
원 인, 원 아웃 인코딩 패턴을 따른다.

00:02:54.000 --> 00:03:06.000
또한, 이 모드의 속도 컨트롤러는 네트워크 변화에 대응하여 더 빠르게 적응하므로 네트워크 혼잡으로 인한 지연도 최소화됩니다.

00:03:06.000 --> 00:03:14.000
이 두 가지 최적화를 통해, 우리는 이미 기본 모드에 비해 명백한 성능 개선을 볼 수 있다.

00:03:14.000 --> 00:03:21.000
저지연 인코딩은 720p 30fps 비디오의 경우 최대 100밀리초의 지연을 줄일 수 있습니다.

00:03:21.000 --> 00:03:26.000
그러한 절약은 화상 회의에 매우 중요할 수 있다.

00:03:26.000 --> 00:03:37.000
대기 시간을 줄임으로써, 우리는 화상 회의 및 라이브 방송과 같은 실시간 통신을 위한 보다 효율적인 인코딩 파이프라인을 달성할 수 있습니다.

00:03:37.000 --> 00:03:45.000
또한, 저지연 모드는 전력을 절약하기 위해 항상 하드웨어 가속 비디오 인코더를 사용합니다.

00:03:45.000 --> 00:03:56.000
참고로, 이 모드에서 지원되는 비디오 코덱 유형은 H.264이며, iOS와 macOS 모두에서 이 기능을 제공합니다.

00:03:56.000 --> 00:04:02.000
다음으로, 저는 비디오 툴박스와 함께 저지연 모드를 사용하는 방법에 대해 이야기하고 싶습니다.

00:04:02.000 --> 00:04:11.000
먼저 VTCompressionSession의 사용을 요약한 다음 저지연 인코딩을 활성화하는 데 필요한 단계를 보여드리겠습니다.

00:04:11.000 --> 00:04:21.000
VTCompressionSession을 사용할 때, 가장 먼저 VTCompressionSessionCreate API로 세션을 만드는 것입니다.

00:04:21.000 --> 00:04:28.000
VTSessionSetProperty API를 통해 목표 비트 전송률과 같은 세션을 선택적으로 구성할 수 있습니다.

00:04:28.000 --> 00:04:35.000
구성이 제공되지 않으면, 인코더는 기본 동작으로 작동할 것이다.

00:04:35.000 --> 00:04:46.000
세션이 생성되고 제대로 구성된 후, VTCompressionSessionEncodeFrame 호출을 통해 CVImageBuffer를 세션에 전달할 수 있습니다.

00:04:46.000 --> 00:04:53.000
인코딩된 결과는 세션 생성 중에 제공된 출력 핸들러에서 검색할 수 있습니다.

00:04:53.000 --> 00:04:58.000
압축 세션에서 저지연 인코딩을 활성화하는 것은 쉽다.

00:04:58.000 --> 00:05:02.000
우리가 필요한 유일한 변화는 세션 생성에 있다.

00:05:02.000 --> 00:05:06.000
여기 그것을 하는 방법을 보여주는 코드 스니펫이 있습니다.

00:05:06.000 --> 00:05:11.000
먼저 우리는 인코더 사양을 위한 CFMutableDictionary가 필요합니다.

00:05:11.000 --> 00:05:18.000
encoderSpecification은 세션이 사용해야 하는 특정 비디오 인코더를 지정하는 데 사용됩니다.

00:05:18.000 --> 00:05:25.000
그런 다음 encoderSpecification에서 EnableLowLatencyRateControl 플래그를 설정해야 합니다.

00:05:25.000 --> 00:05:36.000
마지막으로, 우리는 이 encoderSpecification을 VTCompressionSessionCreate에 제공해야 하며, 압축 세션은 저지연 모드에서 작동할 것입니다.

00:05:36.000 --> 00:05:39.000
구성 단계는 평소와 같다.

00:05:39.000 --> 00:05:45.000
예를 들어, AverageBitRate 속성으로 목표 비트 전송률을 설정할 수 있습니다.

00:05:45.000 --> 00:05:51.000
좋아요, 우리는 비디오 툴박스로 저지연 모드의 기본 사항을 다루었습니다.

00:05:51.000 --> 00:05:59.000
실시간 비디오 애플리케이션을 개발하는 데 도움이 될 수 있는 이 모드의 새로운 기능으로 넘어가고 싶습니다.

00:05:59.000 --> 00:06:04.000
지금까지, 우리는 저지연 모드를 사용하여 대기 시간의 이점에 대해 이야기했습니다.

00:06:04.000 --> 00:06:10.000
나머지 혜택은 제가 소개할 기능으로 얻을 수 있습니다.

00:06:10.000 --> 00:06:13.000
첫 번째 특징은 새로운 프로필이다.

00:06:13.000 --> 00:06:20.000
우리는 파이프라인에 두 개의 새로운 프로필을 추가하여 상호 운용성을 강화했다.

00:06:20.000 --> 00:06:24.000
그리고 우리는 또한 시간적 확장성에 대해 이야기하게 되어 기쁩니다.

00:06:24.000 --> 00:06:28.000
이 기능은 화상 회의에 매우 도움이 될 수 있다.

00:06:28.000 --> 00:06:35.000
이제 최대 프레임 양자화 매개 변수로 이미지 품질을 세밀하게 제어할 수 있습니다.

00:06:35.000 --> 00:06:42.000
마지막으로, 우리는 장기 참조에 대한 지원을 추가하여 오류 탄력성을 개선하고 싶습니다.

00:06:42.000 --> 00:06:45.000
새로운 프로필 지원에 대해 이야기해 봅시다.

00:06:45.000 --> 00:06:51.000
프로필은 디코더가 지원할 수 있는 코딩 알고리즘 그룹을 정의한다.

00:06:51.000 --> 00:07:00.000
수신기 측과 통신하기 위해, 인코딩된 비트스트림은 디코더가 지원하는 특정 프로필을 준수해야 합니다.

00:07:00.000 --> 00:07:09.000
여기 비디오 툴박스에서, 우리는 베이스라인 프로필, 메인 프로필 및 하이 프로필과 같은 많은 프로필을 지원합니다.

00:07:09.000 --> 00:07:19.000
오늘 우리는 가족에 두 개의 새로운 프로필을 추가했습니다: 제한된 기준 프로필, CBP, 그리고 제한된 높은 프로필, CHP.

00:07:19.000 --> 00:07:29.000
CBP는 주로 저비용 애플리케이션에 사용되며 CHP는 더 나은 압축 비율을 위한 고급 알고리즘을 가지고 있다.

00:07:29.000 --> 00:07:35.000
어떤 프로필을 사용해야 하는지 알기 위해 디코더 기능을 확인해야 합니다.

00:07:35.000 --> 00:07:43.000
CBP를 요청하려면, ProfileLevel 세션 속성을 ContrainedBaseLine_AutoLevel로 설정하기만 하면 됩니다.

00:07:43.000 --> 00:07:50.000
마찬가지로, 우리는 CHP를 사용하기 위해 프로필 레벨을 ContrainedHigh_AutoLevel로 설정할 수 있습니다.

00:07:50.000 --> 00:07:54.000
이제 시간적 확장성에 대해 이야기해 봅시다.

00:07:54.000 --> 00:08:01.000
우리는 다자간 화상 통화의 효율성을 향상시키기 위해 시간적 확장성을 사용할 수 있습니다.

00:08:01.000 --> 00:08:05.000
간단한 3자 화상 회의 시나리오를 생각해 봅시다.

00:08:05.000 --> 00:08:16.000
이 모델에서 수신기 "A"는 600kbps의 낮은 대역폭을 가지고 있으며, 수신기 B는 1,000kbps의 더 높은 대역폭을 가지고 있다.

00:08:16.000 --> 00:08:28.000
일반적으로, 발신자는 각 수신기 측의 다운링크 대역폭을 충족하기 위해 두 세트의 비트스트림을 인코딩해야 합니다. 이것은 최적이 아닐 수도 있다.

00:08:28.000 --> 00:08:40.000
이 모델은 발신자가 하나의 단일 비트스트림만 인코딩하면 되지만 나중에 두 개의 레이어로 나눌 수 있는 시간적 확장성으로 더 효율적일 수 있다.

00:08:40.000 --> 00:08:44.000
이 과정이 어떻게 작동하는지 보여드릴게요.

00:08:44.000 --> 00:08:54.000
다음은 각 프레임이 이전 프레임을 예측 참조로 사용하는 인코딩된 비디오 프레임 시퀀스입니다.

00:08:54.000 --> 00:09:05.000
우리는 프레임의 절반을 다른 레이어로 가져올 수 있으며, 원래 레이어의 프레임만 예측에 사용되도록 참조를 변경할 수 있습니다.

00:09:05.000 --> 00:09:13.000
원래 레이어는 기본 레이어라고 불리며, 새로 구성된 레이어는 향상 레이어라고 불린다.

00:09:13.000 --> 00:09:20.000
향상 레이어는 프레임 속도를 개선하기 위해 기본 레이어의 보충으로 사용될 수 있습니다.

00:09:20.000 --> 00:09:27.000
수신기 "A"의 경우, 베이스 레이어 자체가 이미 디코딩 가능하기 때문에 베이스 레이어 프레임을 보낼 수 있습니다.

00:09:27.000 --> 00:09:37.000
그리고 더 중요한 것은, 기본 레이어가 프레임의 절반만 포함하기 때문에, 전송된 데이터 속도는 낮을 것이다.

00:09:37.000 --> 00:09:48.000
반면에, 수신기 B는 기본 레이어 프레임과 향상 레이어 프레임을 수신하기에 충분한 대역폭을 가지고 있기 때문에 더 부드러운 비디오를 즐길 수 있다.

00:09:48.000 --> 00:09:53.000
시간적 확장성을 사용하여 인코딩된 비디오를 보여드리겠습니다.

00:09:53.000 --> 00:10:02.000
나는 두 개의 비디오를 재생할 것이다, 하나는 베이스 레이어에서, 다른 하나는 향상 레이어와 함께 베이스 레이어에서.

00:10:02.000 --> 00:10:11.000
베이스 레이어 자체는 정상적으로 재생할 수 있지만, 동시에 비디오가 매끄럽지 않다는 것을 알 수 있습니다.

00:10:11.000 --> 00:10:16.000
두 번째 비디오를 재생하면 그 차이를 즉시 볼 수 있다.

00:10:16.000 --> 00:10:24.000
오른쪽 비디오는 기본 레이어와 향상 레이어를 모두 포함하기 때문에 왼쪽 비디오에 비해 프레임 속도가 더 높습니다.

00:10:24.000 --> 00:10:31.000
왼쪽 비디오는 입력 프레임 속도의 50%를 가지고 있으며, 목표 비트 전송률의 60%를 사용합니다.

00:10:31.000 --> 00:10:37.000
이 두 비디오는 인코더가 한 번에 하나의 비트스트림을 인코딩하기만 하면 됩니다.

00:10:37.000 --> 00:10:44.000
이것은 우리가 다자간 화상 회의를 할 때 훨씬 더 전력 효율적일 것이다.

00:10:44.000 --> 00:10:48.000
시간적 확장성의 또 다른 이점은 오류 탄력성이다.

00:10:48.000 --> 00:10:58.000
보시다시피, 향상 레이어의 프레임은 예측에 사용되지 않으므로 이러한 프레임에 의존하지 않습니다.

00:10:58.000 --> 00:11:07.000
이것은 네트워크 전송 중에 하나 이상의 향상 레이어 프레임이 삭제되면 다른 프레임은 영향을 받지 않는다는 것을 의미합니다.

00:11:07.000 --> 00:11:11.000
이것은 전체 세션을 더 강력하게 만든다.

00:11:11.000 --> 00:11:15.000
시간적 확장성을 활성화하는 방법은 꽤 간단하다.

00:11:15.000 --> 00:11:22.000
우리는 BaseLayerFrameRateFraction이라는 저지연 모드에서 새로운 세션 속성을 만들었습니다.

00:11:22.000 --> 00:11:34.000
이 속성을 0.5로 설정하기만 하면 됩니다. 즉, 입력 프레임의 절반은 기본 레이어에 할당되고 나머지는 향상 레이어에 할당됩니다.

00:11:34.000 --> 00:11:38.000
샘플 버퍼 첨부 파일에서 레이어 정보를 확인할 수 있습니다.

00:11:38.000 --> 00:11:49.000
기본 레이어 프레임의 경우, CMSampleAttachmentKey_ IsDependedOnByOthers는 참이며, 그렇지 않으면 거짓입니다.

00:11:49.000 --> 00:11:54.000
우리는 또한 각 레이어의 목표 비트 전송률을 설정할 수 있는 옵션이 있습니다.

00:11:54.000 --> 00:12:01.000
세션 속성 AverageBitRate를 사용하여 목표 비트 전송률을 구성한다는 것을 기억하십시오.

00:12:01.000 --> 00:12:12.000
목표 비트 전송률을 구성한 후, 기본 레이어에 필요한 목표 비트 전송률의 비율을 제어하기 위해 새로운 BaseLayerBitRateFraction 속성을 설정할 수 있습니다.

00:12:12.000 --> 00:12:18.000
이 속성이 설정되지 않으면, 기본값 0.6이 사용됩니다.

00:12:18.000 --> 00:12:26.000
그리고 우리는 기본 레이어 비트 전송률 비율이 0.6에서 0.8 사이여야 한다고 권장합니다.

00:12:26.000 --> 00:12:33.000
이제, 최대 프레임 양자화 매개 변수 또는 최대 프레임 QP로 넘어가겠습니다.

00:12:33.000 --> 00:12:39.000
프레임 QP는 이미지 품질과 데이터 속도를 조절하는 데 사용됩니다.

00:12:39.000 --> 00:12:43.000
우리는 낮은 프레임 QP를 사용하여 고품질 이미지를 생성할 수 있습니다.

00:12:43.000 --> 00:12:47.000
이 경우 이미지 크기는 클 것이다.

00:12:47.000 --> 00:12:56.000
반면에, 우리는 높은 프레임 QP를 사용하여 낮은 품질이지만 더 작은 크기로 이미지를 생성할 수 있습니다.

00:12:56.000 --> 00:13:10.000
저지연 모드에서 인코더는 현재 목표 비트 전송률 제약 하에서 최고의 시각적 품질을 생성하기 위해 이미지 복잡성, 입력 프레임 속도, 비디오 모션과 같은 요소를 사용하여 프레임 QP를 조정합니다.

00:13:10.000 --> 00:13:17.000
그래서 우리는 프레임 QP를 조정하기 위해 인코더의 기본 동작에 의존하는 것이 좋습니다.

00:13:17.000 --> 00:13:29.000
하지만 고객이 비디오 품질에 대한 특정 요구 사항이 있는 경우, 이제 인코더가 사용할 수 있는 최대 프레임 QP를 제어할 수 있습니다.

00:13:29.000 --> 00:13:42.000
최대 프레임 QP를 사용하면 인코더는 항상 이 제한보다 작은 프레임 QP를 선택하므로 고객은 이미지 품질을 세밀하게 제어할 수 있습니다.

00:13:42.000 --> 00:13:49.000
일반 요금 제어는 지정된 최대 프레임 QP에서도 여전히 작동한다는 것을 언급할 가치가 있다.

00:13:49.000 --> 00:14:01.000
인코더가 최대 프레임 QP 캡에 도달했지만 비트 전송률 예산이 부족한 경우, 목표 비트 전송률을 유지하기 위해 프레임을 삭제하기 시작합니다.

00:14:01.000 --> 00:14:08.000
이 기능을 사용하는 한 가지 예는 열악한 네트워크를 통해 화면 콘텐츠 비디오를 전송하는 것이다.

00:14:08.000 --> 00:14:15.000
선명한 화면 콘텐츠 이미지를 보내기 위해 프레임 속도를 희생하여 절충할 수 있습니다.

00:14:15.000 --> 00:14:20.000
최대 프레임 QP 설정은 이 요구 사항을 충족할 수 있습니다.

00:14:20.000 --> 00:14:22.000
인터페이스를 살펴봅시다.

00:14:22.000 --> 00:14:29.000
새로운 세션 속성 MaxAllowedFrameQP로 최대 프레임 QP를 전달할 수 있습니다.

00:14:29.000 --> 00:14:38.000
최대 프레임 QP의 값은 표준에 따라 1에서 51 사이여야 한다는 것을 명심하세요.

00:14:38.000 --> 00:14:45.000
우리가 저지연 모드, 장기 참조에서 개발한 마지막 기능에 대해 이야기해 봅시다.

00:14:45.000 --> 00:14:50.000
장기 참조 또는 LTR은 오류 복원력에 사용될 수 있다.

00:14:50.000 --> 00:14:58.000
파이프라인의 인코더, 발신자 클라이언트 및 수신 클라이언트를 보여주는 이 다이어그램을 살펴봅시다.

00:14:58.000 --> 00:15:03.000
비디오 통신이 연결 상태가 좋지 않은 네트워크를 통과한다고 가정해 봅시다.

00:15:03.000 --> 00:15:07.000
전송 오류로 인해 프레임 손실이 발생할 수 있습니다.

00:15:07.000 --> 00:15:16.000
수신기 클라이언트가 프레임 손실을 감지하면, 세션을 재설정하기 위해 새로 고침 프레임을 요청할 수 있습니다.

00:15:16.000 --> 00:15:23.000
인코더가 요청을 받으면, 일반적으로 새로 고침 목적으로 키 프레임을 인코딩합니다.

00:15:23.000 --> 00:15:26.000
하지만 키 프레임은 보통 꽤 크다.

00:15:26.000 --> 00:15:30.000
큰 키 프레임은 수신기에 도달하는 데 더 오랜 시간이 걸린다.

00:15:30.000 --> 00:15:38.000
네트워크 상태가 이미 좋지 않기 때문에, 큰 프레임은 네트워크 혼잡 문제를 악화시킬 수 있다.

00:15:38.000 --> 00:15:43.000
그래서, 새로 고침을 위해 키 프레임 대신 예측 프레임을 사용할 수 있나요?

00:15:43.000 --> 00:15:48.000
만약 우리가 프레임 승인이 있다면, 대답은 '예'입니다.

00:15:48.000 --> 00:15:51.000
그게 어떻게 작동하는지 보여줄게.

00:15:51.000 --> 00:15:55.000
먼저, 우리는 승인이 필요한 프레임을 결정해야 한다.

00:15:55.000 --> 00:16:00.000
우리는 이 프레임을 장기 참조 또는 LTR이라고 부른다.

00:16:00.000 --> 00:16:03.000
이것은 인코더의 결정이다.

00:16:03.000 --> 00:16:12.000
발신자 클라이언트가 LTR 프레임을 전송할 때, 수신자 클라이언트로부터 승인을 요청해야 합니다.

00:16:12.000 --> 00:16:19.000
LTR 프레임이 성공적으로 수신되면, 승인을 다시 보내야 합니다.

00:16:19.000 --> 00:16:30.000
발신자 클라이언트가 승인을 받고 그 정보를 인코더에 전달하면, 인코더는 상대방이 어떤 LTR 프레임을 수신했는지 알 수 있다.

00:16:30.000 --> 00:16:34.000
나쁜 네트워크 상황을 다시 살펴봅시다.

00:16:34.000 --> 00:16:47.000
인코더가 새로 고침 요청을 받으면, 이때부터 인코더는 많은 승인된 LTR을 가지고 있으며, 이러한 승인된 LTR 중 하나에서 예측된 프레임을 인코딩할 수 있습니다.

00:16:47.000 --> 00:16:53.000
이런 식으로 인코딩된 프레임은 LTR-P라고 불린다.

00:16:53.000 --> 00:17:02.000
일반적으로 LTR-P는 키 프레임에 비해 인코딩된 프레임 크기 측면에서 훨씬 작기 때문에 전송하기가 더 쉽다.

00:17:02.000 --> 00:17:07.000
이제, LTR용 API에 대해 이야기해 봅시다.

00:17:07.000 --> 00:17:12.000
프레임 승인은 애플리케이션 계층에 의해 처리되어야 한다는 점에 유의하십시오.

00:17:12.000 --> 00:17:20.000
RTP 제어 프로토콜의 RPSI 메시지와 같은 메커니즘으로 수행할 수 있습니다.

00:17:20.000 --> 00:17:28.000
여기서 우리는 이 과정에서 인코더와 발신자 클라이언트가 어떻게 소통하는지에만 초점을 맞출 것이다.

00:17:28.000 --> 00:17:37.000
저지연 인코딩을 활성화하면, EnableLTR 세션 속성을 설정하여 이 기능을 활성화할 수 있습니다.

00:17:37.000 --> 00:17:48.000
LTR 프레임이 인코딩되면, 인코더는 샘플 첨부 파일 RequireLTRAcknowledgementToken에 고유한 프레임 토큰을 신호합니다.

00:17:48.000 --> 00:17:57.000
발신자 클라이언트는 AcknowledgedLTRTokens 프레임 속성을 통해 승인된 LTR 프레임을 인코더에 보고할 책임이 있습니다.

00:17:57.000 --> 00:18:06.000
한 번에 하나 이상의 승인이 올 수 있기 때문에, 우리는 이러한 프레임 토큰을 저장하기 위해 배열을 사용해야 합니다.

00:18:06.000 --> 00:18:12.000
ForceLTRRefresh 프레임 속성을 통해 언제든지 새로 고침 프레임을 요청할 수 있습니다.

00:18:12.000 --> 00:18:18.000
인코더가 이 요청을 받으면, LTR-P가 인코딩될 것이다.

00:18:18.000 --> 00:18:26.000
승인된 LTR을 사용할 수 없다면, 인코더는 이 경우 키 프레임을 생성할 것이다.

00:18:26.000 --> 00:18:27.000
알았어.

00:18:27.000 --> 00:18:30.000
이제 우리는 저지연 모드에서 새로운 기능을 다루었습니다.

00:18:30.000 --> 00:18:34.000
우리는 이 기능들을 함께 사용하는 것에 대해 이야기할 수 있다.

00:18:34.000 --> 00:18:42.000
예를 들어, 그룹 화면 공유 애플리케이션에 시간 확장성과 최대 프레임 양자화 매개 변수를 사용할 수 있습니다.

00:18:42.000 --> 00:18:55.000
시간적 확장성은 각 수신자에 대한 출력 비디오를 효율적으로 생성할 수 있으며, 화면 콘텐츠의 더 선명한 UI와 텍스트를 위해 최대 프레임 QP를 낮출 수 있습니다.

00:18:55.000 --> 00:19:05.000
통신이 불량한 네트워크를 통과하고 오류에서 복구하기 위해 새로 고침 프레임이 필요한 경우, 장기 참조를 사용할 수 있습니다.

00:19:05.000 --> 00:19:15.000
그리고 수신기가 제한된 프로필만 디코딩할 수 있다면, 우리는 제한된 기준선 프로필 또는 제한된 높은 프로필로 인코딩할 수 있습니다.

00:19:15.000 --> 00:19:16.000
알았어.

00:19:16.000 --> 00:19:19.000
우리는 여기서 몇 가지 주제를 다루었다.

00:19:19.000 --> 00:19:24.000
우리는 비디오 툴박스에 저지연 인코딩 모드를 도입했습니다.

00:19:24.000 --> 00:19:31.000
우리는 VTCompressionSession API를 사용하여 저지연 모드에서 비디오를 인코딩하는 방법에 대해 이야기했습니다.

00:19:31.000 --> 00:19:40.000
대기 시간 이점 외에도, 우리는 또한 실시간 비디오 애플리케이션의 요구 사항을 해결하기 위해 많은 새로운 기능을 개발했습니다.

00:19:40.000 --> 00:19:46.000
이러한 모든 개선으로, 나는 저지연 모드가 당신의 비디오 앱을 더 놀랍게 만들 수 있기를 바랍니다.

00:19:46.000 --> 00:19:50.000
시청해 주셔서 감사드리며 멋진 WWDC 2021을 보내세요.

00:19:50.000 --> 23:59:59.000
[쾌활한 음악].

