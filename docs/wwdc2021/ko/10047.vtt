WEBVTT

00:00:00.000 --> 00:00:05.000
♪ 베이스 음악 연주 ♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:13.000
브래드 포드: 안녕하세요, "카메라 캡처의 새로운 기능"에 오신 것을 환영합니다.

00:00:13.000 --> 00:00:16.000
저는 카메라 소프트웨어 팀의 브래드 포드입니다.

00:00:16.000 --> 00:00:37.000
저는 최소 초점 거리 보고로 시작하는 많은 새로운 카메라 기능을 선보일 것입니다; 10비트 HDR 비디오를 캡처하는 방법; 메인 코스, 제어 센터의 비디오 효과; 그리고 나서 - 새로운 기능으로부터의 짧은 휴식 - 카메라 앱에서 최고의 성능을 얻기 위한 전략을 검토할 것입니다.

00:00:37.000 --> 00:00:44.000
그리고 마지막으로, 당신의 가방을 위한 새로운 성능 트릭인 IOSurface 압축을 소개하겠습니다.

00:00:44.000 --> 00:00:52.000
오늘 설명할 모든 기능은 AVFoundation 프레임워크에서 찾을 수 있습니다. 특히 AVCapture로 시작하는 클래스입니다.

00:00:52.000 --> 00:01:13.000
간단히 검토하기 위해, 주요 객체는 카메라나 마이크를 나타내는 AVCaptureDevices입니다. AVCaptureDeviceInputs는 장치를 래핑하여 AVCapture 그래프의 중앙 제어 객체인 AVCaptureSession에 연결할 수 있습니다.

00:01:13.000 --> 00:01:17.000
AVCaptureOutputs는 다양한 방법으로 입력에서 데이터를 렌더링합니다.

00:01:17.000 --> 00:01:21.000
MovieFileOutput은 퀵타임 영화를 기록한다.

00:01:21.000 --> 00:01:26.000
PhotoOutput은 고품질 스틸과 라이브 사진을 캡처합니다.

00:01:26.000 --> 00:01:35.000
VideoDataOutput 또는 AudioDataOutput과 같은 데이터 출력은 카메라나 마이크에서 앱으로 비디오 또는 오디오 버퍼를 전달합니다.

00:01:35.000 --> 00:01:43.000
메타데이터와 깊이와 같은 몇 가지 다른 종류의 데이터 출력이 있다.

00:01:43.000 --> 00:01:53.000
라이브 카메라 미리보기의 경우, CALayer의 하위 클래스인 AVCaptureVideoPreviewLayer라는 특별한 유형의 출력이 있습니다.

00:01:53.000 --> 00:02:04.000
데이터는 캡처 입력에서 AVCaptureConnections를 통해 호환 가능한 캡처 출력으로 흐르며, 여기에 이 화살표로 표시됩니다.

00:02:04.000 --> 00:02:13.000
AVFoundation 카메라 캡처를 처음 접한다면, developer.apple.com의 카메라 및 미디어 캡처 시작 페이지에서 자세히 알아보시기 바랍니다.

00:02:13.000 --> 00:02:17.000
좋아, 우리의 새로운 기능 중 첫 번째에 바로 뛰어들자.

00:02:17.000 --> 00:02:24.000
최소 초점 거리는 렌즈에서 날카로운 초점을 얻을 수 있는 가장 가까운 지점까지의 거리입니다.

00:02:24.000 --> 00:02:29.000
그것은 DSLR 카메라나 스마트폰에 있는 모든 렌즈의 속성이다.

00:02:29.000 --> 00:02:36.000
아이폰 카메라도 최소 초점 거리를 가지고 있으며, 우리는 전에 그것을 출판한 적이 없습니다...

00:02:36.000 --> 00:02:38.000
...지금까지, 그건.

00:02:38.000 --> 00:02:46.000
iOS 15부터 최소 초점 거리는 iPhone 자동 초점 카메라의 공개된 속성이다.

00:02:46.000 --> 00:02:48.000
여기 최근 아이폰의 샘플이 있습니다.

00:02:48.000 --> 00:02:56.000
이 차트는 와이드 및 망원 카메라의 최소 초점 거리가 모델마다 어떻게 다른지 보여줍니다.

00:02:56.000 --> 00:03:09.000
아이폰 12 프로와 12 프로 맥스 와이드 카메라 사이에는 주목할 만한 차이가 있으며, 프로 맥스는 프로의 12에 비해 최소 15센티미터의 거리에 초점을 맞추고 있다.

00:03:09.000 --> 00:03:16.000
이것은 iPhone 12 Pro Max의 센서 시프트 안정화 기술 때문입니다.

00:03:16.000 --> 00:03:23.000
마찬가지로, 텔레의 최소 초점 거리는 12 프로보다 12 프로 맥스에서 더 멀다.

00:03:23.000 --> 00:03:27.000
이것은 망원 렌즈의 도달 범위가 길기 때문이다.

00:03:27.000 --> 00:03:32.000
그것은 2.5배 대 2배 줌을 가지고 있다.

00:03:32.000 --> 00:03:42.000
최소 초점 거리 보고가 왜 중요한지에 대한 빠른 데모를 보여드리겠습니다.

00:03:42.000 --> 00:03:45.000
여기 AVCamBarcode라는 샘플 앱이 있습니다.

00:03:45.000 --> 00:03:48.000
그것은 우리의 AVFoundation 바코드 탐지 API를 선보인다.

00:03:48.000 --> 00:03:54.000
UI는 사용자가 스캔을 위해 직사각형 안에 물체를 배치하도록 안내합니다.

00:03:54.000 --> 00:03:59.000
이 예에서, 나는 종이 한 장에 꽤 작은 QR 코드를 선택했다.

00:03:59.000 --> 00:04:02.000
바코드의 너비는 20밀리미터에 불과하다.

00:04:02.000 --> 00:04:10.000
메타데이터 버튼을 탭하면 AVCaptureMetadataOutput에서 지원하는 모든 다양한 객체 유형의 목록을 볼 수 있습니다.

00:04:10.000 --> 00:04:12.000
그것들이 많이 있어.

00:04:12.000 --> 00:04:21.000
QR코드를 선택한 다음 iPhone 12 Pro Max 카메라를 배치하여 직사각형을 QR코드로 채울 것입니다.

00:04:21.000 --> 00:04:27.000
불행히도, 그것은 너무 작아서 미리보기를 채우기 위해 페이지에 매우 가까이 다가가야 한다.

00:04:27.000 --> 00:04:30.000
그것은 카메라의 최소 초점 거리보다 더 가깝다.

00:04:30.000 --> 00:04:33.000
코드가 흐릿해서 스캔하지 않습니다.

00:04:33.000 --> 00:04:42.000
사용자가 물러나도록 안내하기 위해, 카메라 미리보기에 줌 요소를 적용해야 합니다...

00:04:42.000 --> 00:04:44.000
...그처럼.

00:04:44.000 --> 00:04:49.000
화면에서 확대된 이미지를 보면 물리적으로 카메라를 종이에서 더 멀리 이동하라는 메시지가 표시됩니다.

00:04:49.000 --> 00:04:58.000
슬라이더 버튼으로 할 수 있지만, 앱이 자동으로 줌을 처리한다면 훨씬 더 좋을 것이다.

00:04:58.000 --> 00:05:03.000
그것이 AVCaptureDevice의 새로운 minimumFocusDistance 속성이 들어오는 곳이다.

00:05:03.000 --> 00:05:06.000
그것은 iOS 15의 새로운 기능이다.

00:05:06.000 --> 00:05:26.000
카메라의 수평 시야, 스캔하고 싶은 최소 바코드 크기 - 여기서 20밀리미터로 설정했습니다 - 그리고 카메라 미리보기 창의 너비를 백분율로 감안할 때, 우리는 미리보기 너비를 채우는 데 필요한 최소 주제 거리를 계산하기 위해 약간의 수학을 할 수 있습니다.

00:05:26.000 --> 00:05:39.000
그런 다음 카메라의 새로운 minimumFocusDistance 속성을 사용하여 카메라가 가까이 초점을 맞출 수 없을 때 감지하고 사용자가 뒤로 물러나도록 안내할 수 있을 만큼 큰 줌 계수를 계산할 수 있습니다.

00:05:39.000 --> 00:05:48.000
그리고 마지막으로, 우리는 구성을 위해 잠그고, 줌 요소를 설정한 다음, 잠금을 해제하여 카메라에 적용합니다.

00:05:48.000 --> 00:05:58.000
데모 앱을 다시 컴파일한 후, UI는 이제 자동으로 올바른 줌 양을 적용합니다.

00:05:58.000 --> 00:06:02.000
앱이 실행되면, 이미 올바른 공간으로 확대되었습니다.

00:06:02.000 --> 00:06:05.000
더 이상 흐릿한 바코드는 없어!

00:06:05.000 --> 00:06:10.000
그리고 내가 그것을 탭하면, 우리는 그것이 나를 어디로 데려가는지 볼 수 있다.

00:06:10.000 --> 00:06:14.000
아! "아이폰 사진의 깊이 포착" -- 오래되었지만 좋은 것.

00:06:14.000 --> 00:06:20.000
그 세션 정말 고마워.

00:06:20.000 --> 00:06:31.000
최소 초점 거리를 통합하는 방법에 대한 모범 사례와 바코드 스캔을 위한 다른 많은 모범 사례에 대한 새로운 AVCamBarcode 샘플을 확인하십시오.

00:06:31.000 --> 00:06:35.000
다음은 10비트 HDR 비디오입니다.

00:06:35.000 --> 00:06:43.000
HDR은 하이 다이내믹 레인지의 약자이며, iOS 4.1부터 스틸 이미지 기술로 사용되어 왔다.

00:06:43.000 --> 00:06:53.000
높은 다이내믹 레인지를 보존하는 것은 일반적으로 장면의 여러 노출을 취한 다음 하이라이트와 그림자를 모두 보존하기 위해 혼합함으로써 달성된다.

00:06:53.000 --> 00:06:56.000
하지만 비디오 HDR은 어때?

00:06:56.000 --> 00:07:02.000
초당 30개 또는 60개의 프레임을 전달해야 하기 때문에 그것은 도전입니다.

00:07:02.000 --> 00:07:13.000
정확히 비디오 HDR은 아니지만 2018년에 애플은 아이폰 XS 카메라 라인에 EDR 또는 확장 다이내믹 레인지를 도입했다.

00:07:13.000 --> 00:07:18.000
EDR은 비디오를 위한 HDR과 같은 솔루션이다.

00:07:18.000 --> 00:07:30.000
그것은 본질적으로 표준 노출과 짧은 노출을 번갈아 가며 캡처 프레임 속도를 두 배로 늘리지만, 시간이 정해 캡처 사이에 수직 블랭킹이 거의 없습니다.

00:07:30.000 --> 00:07:38.000
명목상 초당 30프레임을 캡처할 때, EDR 비디오는 실제로 초당 60프레임으로 카메라를 실행하고 있다.

00:07:38.000 --> 00:07:50.000
장면에서 요구할 때, EV-의 색조 지도는 클리핑된 하이라이트를 복구하기 위해 EV0 이미지에 동적으로 적용되지만, 그림자의 디테일을 희생하지 않습니다.

00:07:50.000 --> 00:08:00.000
저조도에서 효과가 감소하기 때문에 완전한 HDR 솔루션은 아니지만, 중간에서 좋은 조명에서 놀라운 결과를 제공합니다.

00:08:00.000 --> 00:08:02.000
이제 여기 혼란스러운 부분이 있습니다.

00:08:02.000 --> 00:08:10.000
EDR은 videoHDR이라는 이름으로 AVCaptureDevice 속성 제품군으로 제시되었다.

00:08:10.000 --> 00:08:19.000
AVCapture API에서 videoHDRSupported 또는 videoHDREnabled를 볼 때마다, 정신적으로 EDR을 대체해야 합니다.

00:08:19.000 --> 00:08:22.000
그게 바로 그거야.

00:08:22.000 --> 00:08:30.000
AVCaptureDevice에는 또한 기본값이 true인 "automaticallyAdjusts VideoHDREnabled"라는 속성이 있습니다.

00:08:30.000 --> 00:08:35.000
따라서 EDR은 사용 가능할 때마다 자동으로 활성화됩니다.

00:08:35.000 --> 00:08:48.000
어떤 이유로든 비활성화하려면, automaticallyAdjustsVideo HDREnabled를 false로 설정한 다음, videoHDREnabled도 false로 설정해야 합니다.

00:08:48.000 --> 00:08:50.000
이제 그 이야기는 훨씬 더 좋아졌다.

00:08:50.000 --> 00:08:58.000
10비트 HDR 비디오에 대해 말할 수 있도록 EDR에 대해 말해야 했습니다.

00:08:58.000 --> 00:09:04.000
10비트 HDR 비디오는 비트가 더 많기 때문에 정말 높은 다이내믹 레인지입니다!

00:09:04.000 --> 00:09:07.000
그것은 편집성이 높아졌다는 것을 의미한다.

00:09:07.000 --> 00:09:12.000
하이라이트 복구를 위한 EDR이 있으며, 항상 켜져 있습니다.

00:09:12.000 --> 00:09:23.000
그것은 하이브리드 로그 감마 곡선과 BT.2020 색상 공간을 사용하여 Rec 709보다 더 밝은 색상의 대비를 허용합니다.

00:09:23.000 --> 00:09:39.000
그리고 AVCaptureMovieFileOutput 또는 AVCaptureVideoDataOutput과 AVAssetWriter를 사용하든, 우리는 프레임당 Dolby Vision 메타데이터를 영화에 자동으로 삽입하여 Dolby Vision 디스플레이와 호환되도록 합니다.

00:09:39.000 --> 00:09:45.000
10비트 HDR 비디오는 iPhone 12에 처음 도입되었다.

00:09:45.000 --> 00:09:50.000
10비트 HDR 비디오 포맷은 고유한 픽셀 포맷 유형으로 식별할 수 있습니다.

00:09:50.000 --> 00:09:56.000
구형 iPhone 모델에서 카메라에는 항상 쌍으로 제공되는 AVCaptureDeviceFormats가 있습니다.

00:09:56.000 --> 00:10:03.000
각 해상도와 프레임 속도 범위에는 420v와 420f 형식이 있습니다.

00:10:03.000 --> 00:10:07.000
이것들은 8비트, 이중 평면, YUV 형식이다.

00:10:07.000 --> 00:10:21.000
420v의 V는 비디오 범위 또는 16에서 235를 의미하고 420f의 F는 전체 범위 또는 0에서 255를 의미합니다.

00:10:21.000 --> 00:10:26.000
iPhone 12 모델에서, 일부 형식은 세 개의 클러스터로 제공됩니다.

00:10:26.000 --> 00:10:34.000
420v와 420f 포맷 이후에는 동일한 해상도와 프레임 속도 범위의 x420 포맷이 제공됩니다.

00:10:34.000 --> 00:10:46.000
420v와 마찬가지로, x420은 비디오 범위의 이중 평면 420 형식이지만, x420의 x는 8이 아닌 10비트를 나타낸다.

00:10:46.000 --> 00:11:06.000
코드에서 10비트 HDR 비디오 형식을 찾고 선택하려면, 픽셀 형식이 x420 또는 -- 심호흡 -- 420YpCbCr10BiPlanarVideoRange와 일치하는 형식을 찾을 때까지 AVCaptureDevice 형식을 반복하기만 하면 됩니다.

00:11:06.000 --> 00:11:13.000
물론 너비, 높이 및 최대 프레임 속도와 같은 다른 검색 기준을 포함할 수 있습니다.

00:11:13.000 --> 00:11:18.000
우리는 가능한 경우 10비트 HDR 비디오를 지원하도록 AVCam 샘플 코드를 업데이트했습니다.

00:11:18.000 --> 00:11:29.000
현재 선택한 장치 활성 형식의 10비트 HDR 변형을 찾을 수 있는 "tenBitVariantOfFormat"이라는 편리한 유틸리티 기능이 있습니다.

00:11:29.000 --> 00:11:32.000
한 번 보세요.

00:11:32.000 --> 00:11:41.000
10비트 HDR 비디오는 720p, 1080p 및 4K를 포함한 모든 가장 인기 있는 비디오 포맷에서 지원됩니다.

00:11:41.000 --> 00:11:53.000
그리고 우리는 12메가픽셀의 고해상도 사진을 지원하는 1920 x 1440의 4 x 3 형식도 포함했습니다.

00:11:53.000 --> 00:12:00.000
10비트 HDR 비디오를 캡처하는 것은 간단하지만, 제대로 편집하고 재생하는 것은 까다롭다.

00:12:00.000 --> 00:12:10.000
2020년부터 "AVFoundation으로 HDR 비디오 편집 및 재생"이라는 제목의 동반자 세션을 시청하도록 초대합니다.

00:12:10.000 --> 00:12:14.000
좋아, 그게 HDR 비디오를 위한 거야.

00:12:14.000 --> 00:12:20.000
이제 메인 이벤트로 가다: 제어 센터의 비디오 효과.

00:12:20.000 --> 00:12:28.000
간단히 말해서, 이것들은 코드 변경 없이 앱에서 사용할 수 있는 시스템 수준의 카메라 기능입니다.

00:12:28.000 --> 00:12:32.000
그리고 사용자가 통제하고 있다.

00:12:32.000 --> 00:12:34.000
이것은 우리에게 약간의 출발이다.

00:12:34.000 --> 00:12:42.000
전통적으로, 우리가 iOS 또는 macOS에 새로운 카메라 기능을 도입할 때, 애플의 앱은 그것을 즉시 채택한다.

00:12:42.000 --> 00:12:51.000
우리는 새로운 AVCapture API를 노출하고, 당신은 지금 하고 있는 것처럼 그들에 대해 배우고, 그런 다음 자신의 속도로 기능을 채택합니다.

00:12:51.000 --> 00:13:01.000
이것은 안전하고 보수적인 접근 방식이지만, 종종 사용자가 좋아하는 카메라 앱의 훌륭한 기능을 놓치는 긴 리드 타임을 초래합니다.

00:13:01.000 --> 00:13:16.000
제어 센터의 비디오 효과를 통해, 우리는 코드 변경 없이 모든 사람이 즉시 사용할 수 있는 시스템 수준의 사전 패키지 카메라 기능을 도입하고 있으며, 사용자가 제어할 수 있습니다.

00:13:16.000 --> 00:13:26.000
우리는 이러한 기능에 대한 새로운 API를 계속 공개하므로, 출시 일정이 허용하는 즉시 앱에서 경험을 조정할 수 있습니다.

00:13:26.000 --> 00:13:28.000
이 효과들을 살펴봅시다.

00:13:28.000 --> 00:13:34.000
첫 번째는 5월 Spring Loaded Apple 행사에서 발표되었으며 "Center Stage"라고 불립니다.

00:13:34.000 --> 00:13:44.000
그것은 최근에 출시된 M1 iPad Pro 모델에서 사용할 수 있으며 놀라운 12메가픽셀 울트라 와이드 전면 카메라를 사용합니다.

00:13:44.000 --> 00:13:49.000
센터 스테이지는 FaceTime 영상 통화의 제작 가치를 정말 향상시킵니다.

00:13:49.000 --> 00:13:53.000
그것은 또한 다른 모든 화상 회의 앱에서 즉시 잘 작동합니다.

00:13:53.000 --> 00:13:55.000
여기, 내가 보여줄게.

00:13:55.000 --> 00:14:03.000
저는 방금 App Store에서 Skype를 다운로드했습니다; 이것은 앱의 스톡 버전입니다.

00:14:03.000 --> 00:14:08.000
내가 스카이프 통화를 시작하면, 당신은 즉시 센터 스테이지가 행동에 옮기는 것을 볼 수 있습니다.

00:14:08.000 --> 00:14:12.000
그건 마치 너만의 개인 카메라 오퍼레이터를 갖는 것과 같아.

00:14:12.000 --> 00:14:22.000
그것은 당신이 빡빡하게 들어오든 뒤로 움직이고 속도를 조절하는 것을 좋아하든, 당신이 완벽한 액자를 유지하기 위해 현장을 돌아다닐 때 당신을 짜맞춥니다.

00:14:22.000 --> 00:14:26.000
그것은 심지어 당신이 카메라에서 얼굴을 돌릴 때 당신을 추적할 수 있습니다.

00:14:26.000 --> 00:14:31.000
그것은 얼굴뿐만 아니라 몸을 추적하기 때문이다.

00:14:31.000 --> 00:14:43.000
사용자로서, 제어 센터를 아래로 스와이프하고, 새로운 비디오 효과 모듈을 탭하고, 선택하여 센터 스테이지를 제어할 수 있습니다.

00:14:43.000 --> 00:14:49.000
센터 스테이지를 끄고 앱으로 돌아가면, 더 이상 센터 스테이지 효과를 얻지 못합니다.

00:14:49.000 --> 00:14:52.000
앱에는 변경 사항이 없습니다.

00:14:52.000 --> 00:14:59.000
모든 화상 회의 앱도 얻을 수 있는 새로운 기능이 있으며, 그것은 "초상화"라고 불린다.

00:14:59.000 --> 00:15:03.000
초상화 모드는 아름답게 렌더링된 얕은 피사계 심도 효과를 제공한다.

00:15:03.000 --> 00:15:16.000
그것은 단순한 프라이버시 블러가 아니다; 그것은 애플의 신경 엔진과 훈련된 단안 깊이 네트워크를 사용하여 와이드 오픈 렌즈로 실제 카메라를 근사한다.

00:15:16.000 --> 00:15:33.000
이제 아래로 스와이프하고 마이크 모드 모듈을 선택하여 마이크 모드를 살펴봅시다. 표준, 음성 격리 또는 와이드 스펙트럼 중에서 선택할 수 있습니다.

00:15:33.000 --> 00:15:37.000
마이크 모드는 화상 채팅의 오디오 품질을 향상시킵니다.

00:15:37.000 --> 00:15:39.000
1분 안에 이것들에 대해 더 알아보세요.

00:15:39.000 --> 00:15:48.000
센터 스테이지, 초상화 및 마이크 모드는 제어 센터에서 화면 부동산을 공유하지만, API 처리는 다소 다릅니다.

00:15:48.000 --> 00:15:54.000
먼저 센터 스테이지 API를 소개한 다음 초상화 및 마이크 모드를 소개하겠습니다.

00:15:54.000 --> 00:15:59.000
센터 스테이지는 M1 iPad Pro의 모든 전면 카메라에서 사용할 수 있습니다.

00:15:59.000 --> 00:16:13.000
새로운 전면 울트라 와이드 카메라, 잘린 기존 시야를 보여주는 가상 와이드 카메라 또는 가상 TrueDepth 카메라를 사용하든, 센터 스테이지를 사용할 수 있습니다.

00:16:13.000 --> 00:16:19.000
TrueDepth 카메라에는 몇 가지 조건이 있으며, 잠시 다룰 것입니다.

00:16:19.000 --> 00:16:24.000
제어 센터 비디오 효과 모듈은 앱당 켜기/끄기 토글을 제공합니다.

00:16:24.000 --> 00:16:34.000
이를 통해 회의 앱에서 센터 스테이지를 기본으로 설정할 수 있으며, 수동으로 사진을 프레임하려는 프로 사진 앱에서는 기본적으로 끌 수 있습니다.

00:16:34.000 --> 00:16:40.000
카메라당 하나의 주가 아니라 앱당 하나의 주가 있다.

00:16:40.000 --> 00:16:50.000
센터 스테이지 켜기/끄기 토글은 카메라당이 아닌 앱당이기 때문에 API에 AVCaptureDevice의 클래스 속성 세트로 표시됩니다.

00:16:50.000 --> 00:16:55.000
이것들은 읽을 수 있고, 쓸 수 있으며, 키 값을 관찰할 수 있다.

00:16:55.000 --> 00:17:01.000
centerStageEnabled는 제어 센터의 센터 스테이지 UI의 온/오프 상태와 일치합니다.

00:17:01.000 --> 00:17:07.000
센터 스테이지 제어 모드는 누가 활성화된 상태를 전환할 수 있는지를 지시한다.

00:17:07.000 --> 00:17:10.000
1분 안에 그것에 대해 더 알아보세요.

00:17:10.000 --> 00:17:13.000
모든 카메라나 포맷이 센터 스테이지를 지원하는 것은 아니다.

00:17:13.000 --> 00:17:22.000
모든 카메라의 형식 배열을 반복하여 기능을 지원하는 형식을 찾고 activeFormat으로 설정할 수 있습니다.

00:17:22.000 --> 00:17:34.000
또한, 센터 스테이지 활성 속성을 쿼리하거나 관찰하여 센터 스테이지가 현재 특정 카메라에 대해 활성화되어 있는지 확인할 수 있습니다.

00:17:34.000 --> 00:17:37.000
당신은 센터 스테이지의 한계를 알고 있어야 합니다.

00:17:37.000 --> 00:17:48.000
센터 스테이지는 30fps 포맷인 울트라 와이드 카메라의 전체 12메가픽셀 형식을 사용하므로 최대 프레임 속도는 30으로 제한됩니다.

00:17:48.000 --> 00:17:59.000
센터 스테이지는 이미지 품질을 유지하기 위해 업스케일링을 피하므로 1920 x 1440의 최대 출력 해상도로 제한됩니다.

00:17:59.000 --> 00:18:07.000
팬과 줌은 센터 스테이지 컨트롤 아래에 있어야 하므로, 비디오 줌 팩터는 하나로 잠겨 있습니다.

00:18:07.000 --> 00:18:23.000
기하학적 왜곡 보정은 센터 스테이지의 피플 프레이밍에 필수적이며, 깊이 생성은 RGB 및 적외선 카메라의 전체 시야 이미지를 일치시켜야 하기 때문에 깊이 전달은 꺼져 있어야 합니다.

00:18:23.000 --> 00:18:27.000
이제 제어 모드의 개념으로 들어가 봅시다.

00:18:27.000 --> 00:18:36.000
센터 스테이지에는 세 가지 지원 모드가 있습니다: 사용자, 앱 및 협동.

00:18:36.000 --> 00:18:40.000
사용자 모드는 모든 앱의 기본 센터 스테이지 제어 모드입니다.

00:18:40.000 --> 00:18:44.000
이 모드에서는 사용자만 기능을 켜고 끌 수 있습니다.

00:18:44.000 --> 00:18:52.000
앱이 Center Stage가 활성화된 상태를 프로그래밍 방식으로 변경하려고 하면 예외가 발생합니다.

00:18:52.000 --> 00:18:57.000
다음은 앱 모드로, 앱만 기능을 제어할 수 있습니다.

00:18:57.000 --> 00:19:02.000
토글이 회색으로 되어 있기 때문에 사용자는 제어 센터를 사용할 수 없습니다.

00:19:02.000 --> 00:19:04.000
이 모드의 사용은 권장되지 않습니다.

00:19:04.000 --> 00:19:08.000
센터 스테이지가 앱과 호환되지 않는 경우에만 사용해야 합니다.

00:19:08.000 --> 00:19:18.000
옵트아웃해야 하는 경우, 제어 모드를 앱으로 설정한 다음 isCenterStageEnabled를 false로 설정할 수 있습니다.

00:19:18.000 --> 00:19:31.000
센터 스테이지를 위한 최상의 사용자 경험은 사용자가 제어 센터의 기능을 제어할 수 있는 협동 모드이며, 앱은 자신의 UI로 제어할 수 있습니다.

00:19:31.000 --> 00:19:33.000
하지만 넌 좀 더 일을 해야 해.

00:19:33.000 --> 00:19:44.000
AVCaptureDevice .isCenterStageEnabled 속성을 관찰하고 UI를 업데이트하여 사용자가 원할 때 Center Stage가 켜져 있는지 확인해야 합니다.

00:19:44.000 --> 00:19:54.000
제어 모드를 협력으로 설정한 후, 예를 들어 앱의 버튼을 기반으로 중앙 무대를 true 또는 false로 설정할 수 있습니다.

00:19:54.000 --> 00:19:58.000
협동 모드의 포스터 아이는 페이스타임이다.

00:19:58.000 --> 00:20:16.000
FaceTime 통화를 하는 동안, 앱 내에서 바로 버튼을 사용하여 센터 스테이지를 켜서 나를 추적하거나, 제어 센터에서 아래로 스와이프하고 센터 스테이지를 켜거나 끄는 기존 방법을 사용할 수 있습니다.

00:20:16.000 --> 00:20:23.000
페이스타임과 제어 센터는 센터 스테이지의 상태에 협력하여 항상 사용자 의도와 일치합니다.

00:20:23.000 --> 00:20:27.000
FaceTime은 또한 기능이 서로 호환되지 않을 때를 알 수 있을 만큼 충분히 똑똑하다.

00:20:27.000 --> 00:20:38.000
그래서, 예를 들어, 깊이가 필요한 애니모티콘을 켜려고 한다면...

00:20:38.000 --> 00:20:44.000
...그 두 가지 기능은 서로 호환되지 않기 때문에 센터 스테이지를 끄는 것을 알고 있다.

00:20:44.000 --> 00:20:52.000
센터 스테이지를 다시 켜기 위해 탭하면, 페이스타임은 애니모티콘을 비활성화할 수 있습니다.

00:20:52.000 --> 00:20:54.000
그것은 센터 스테이지 API를 마무리한다.

00:20:54.000 --> 00:21:00.000
컨트롤 센터, 초상화에 있는 센터 스테이지의 룸메이트로 넘어갑시다.

00:21:00.000 --> 00:21:08.000
간단히 말해서, 그것은 와이드 조리개 렌즈처럼 보이도록 설계된 아름답게 렌더링된 얕은 피사계 심도 효과입니다.

00:21:08.000 --> 00:21:17.000
iOS에서 초상화는 Apple Neural Engine이 있는 모든 장치에서 지원됩니다. 이는 2018년 및 최신 휴대폰과 패드입니다.

00:21:17.000 --> 00:21:20.000
전면 카메라만 지원됩니다.

00:21:20.000 --> 00:21:27.000
마찬가지로 애플의 신경 엔진이 포함된 모든 M1 Mac에서도 지원됩니다.

00:21:27.000 --> 00:21:30.000
초상화는 계산적으로 복잡한 알고리즘이다.

00:21:30.000 --> 00:21:46.000
따라서, 비디오 렌더링 성능을 반응형으로 유지하기 위해, 1920 x 1440의 최대 해상도와 초당 30프레임의 최대 해상도로 제한됩니다.

00:21:46.000 --> 00:21:52.000
센터 스테이지와 마찬가지로, 초상화 효과는 앱당 끈적끈적한 켜기/끄기 상태를 가지고 있다.

00:21:52.000 --> 00:22:04.000
API는 센터 스테이지보다 간단하며, 사용자는 항상 제어 센터를 통해 제어할 수 있으며, 특정 클래스의 앱에서만 기본적으로 사용할 수 있습니다.

00:22:04.000 --> 00:22:14.000
iOS에서 VoIP UIBackgroundMode를 사용하는 앱은 자동으로 선택됩니다. 사용자는 제어 센터에서 효과를 켜거나 끌 수 있습니다.

00:22:14.000 --> 00:22:26.000
다른 모든 iOS 앱은 앱의 Info.plist: NSCameraPortraitEffectEnabled에 새 키를 추가하여 초상화 효과를 받을 자격이 있음을 선언하도록 선택해야 합니다.

00:22:26.000 --> 00:22:33.000
macOS에서는 모든 앱이 자동으로 선택되며, 즉시 효과를 사용할 수 있습니다.

00:22:33.000 --> 00:22:38.000
초상화 효과는 항상 제어 센터를 통해서만 사용자가 제어할 수 있습니다.

00:22:38.000 --> 00:22:43.000
센터 스테이지와 마찬가지로, 모든 카메라나 포맷이 초상화를 지원하는 것은 아니다.

00:22:43.000 --> 00:22:52.000
모든 카메라의 형식 배열을 반복하여 기능을 지원하는 형식을 찾고 활성 형식으로 설정할 수 있습니다.

00:22:52.000 --> 00:23:03.000
또한 isPortraitEffectActive 속성을 쿼리하거나 관찰하여 초상화가 현재 특정 카메라에 대해 활성화되어 있는지 확인할 수 있습니다.

00:23:03.000 --> 00:23:08.000
마이크 모드 API는 초상화와 유사하다.

00:23:08.000 --> 00:23:11.000
사용자 선택은 앱당 끈적끈적하다.

00:23:11.000 --> 00:23:17.000
사용자는 항상 제어할 수 있습니다; 앱은 마이크 모드를 직접 설정할 수 없습니다.

00:23:17.000 --> 00:23:21.000
일부 앱은 이 기능을 사용하려면 선택해야 합니다.

00:23:21.000 --> 00:23:52.000
마이크 모드는 AVFoundation의 AVCaptureDevice 인터페이스에 제공되며, 세 가지 맛이 있습니다: 표준 오디오 DSP를 사용하는 표준; 장치 주변의 모든 소리를 캡처하기 위해 처리를 최소화하지만 여전히 에코 캔슬링을 포함하는 넓은 스펙트럼; 그리고 음성을 향상시키고 키보드, 마우스 클릭 또는 이웃 어딘가에서 실행되는 리프 블로어와 같은 원치 않는 배경 소음을 제거하는 음성 격리.

00:23:52.000 --> 00:24:17.000
이러한 맛은 제어 센터에서 사용자만 설정할 수 있지만, 사용자가 선택한 모드인 AVCaptureDevice의 선호하는 MicrophoneMode와 사용자가 선호하는 마이크 모드를 지원하지 않을 수 있는 현재 오디오 경로를 고려하여 현재 사용 중인 모드인 activeMicrophoneMode를 사용하여 상태를 읽고 관찰할 수 있습니다.

00:24:17.000 --> 00:24:24.000
마이크 모드를 사용하려면, 앱은 코어 오디오 AUVoiceIO 오디오 장치를 채택해야 합니다.

00:24:24.000 --> 00:24:30.000
이것은 에코 취소를 수행하기 때문에 화상 회의 앱에서 인기 있는 인터페이스이다.

00:24:30.000 --> 00:24:38.000
그리고 마이크 모드 처리는 2018년 이후 iOS 및 macOS 기기에서만 사용할 수 있습니다.

00:24:38.000 --> 00:24:51.000
초상화 및 마이크 모드를 사용하면 사용자가 항상 제어할 수 있지만, 새로운 AVCaptureDevice .showSystemUserInterface 메소드를 호출하여 기능을 끄거나 켜라는 메시지를 표시할 수 있습니다.

00:24:51.000 --> 00:24:57.000
그리고 당신은 비디오 효과나 마이크 모드를 전달할 수 있습니다.

00:24:57.000 --> 00:25:02.000
이 API를 호출하면 제어 센터가 열리고 적절한 하위 모듈로 딥링크됩니다.

00:25:02.000 --> 00:25:12.000
여기서, 우리는 사용자가 초상화를 끌 수 있는 비디오 효과 모듈로 드릴다운하고 있습니다.

00:25:12.000 --> 00:25:17.000
그것은 초상화를 마무리하고, 제어 센터의 비디오 효과를 마무리한다.

00:25:17.000 --> 00:25:26.000
코드 줄을 변경하지 않고 앱에 주입된 시스템 수준의 카메라 기능의 예를 보여드렸는데, 이는 꽤 강력한 개념입니다!

00:25:26.000 --> 00:25:38.000
"비디오 형식을 사용하여 고품질 사진 캡처"라는 동반자 세션이 있으며, 코드 한 줄을 변경하지 않고도 앱에서 이미지 품질을 개선하기 위해 개선한 사항에 대해 배울 수 있습니다.

00:25:38.000 --> 00:25:41.000
확인해 주세요.

00:25:41.000 --> 00:25:43.000
우리는 많은 새로운 기능을 다루었다.

00:25:43.000 --> 00:25:48.000
세션의 이 시점에서, 나는 숨을 쉬고 공연에 대해 이야기하고 싶다.

00:25:48.000 --> 00:25:56.000
센터 스테이지와 초상화는 훌륭한 새로운 사용자 기능이지만, 성능 비용이 추가된다.

00:25:56.000 --> 00:26:04.000
따라서 카메라 앱이 인물 사진 및 센터 스테이지와 같은 새로운 기능을 사용할 준비가 되었는지 확인하기 위해 성능 모범 사례를 검토해 봅시다.

00:26:04.000 --> 00:26:09.000
카메라 앱은 AVCapture 클래스를 사용하여 다양한 기능을 제공합니다.

00:26:09.000 --> 00:26:21.000
가장 인기 있는 인터페이스는 AVCaptureVideoDataOutput으로, 비디오 프레임을 조작, 표시, 인코딩, 녹화 프로세스로 직접 가져올 수 있습니다.

00:26:21.000 --> 00:26:23.000
네가 말해봐.

00:26:23.000 --> 00:26:31.000
VideoDataOutput을 사용할 때, 앱이 실시간 마감일을 준수하여 프레임 드롭이 없도록 하는 것이 중요합니다.

00:26:31.000 --> 00:26:40.000
기본적으로 VideoDataOutput은 alwaysDiscardsLateVideoFrames 속성을 true로 설정하여 뒤처지는 것을 방지합니다.

00:26:40.000 --> 00:26:55.000
이것은 비디오 데이터 출력의 처리 파이프라인 끝에 하나의 버퍼 큐 크기를 적용하고 항상 가장 신선한 프레임을 제공하고 처리할 준비가 되지 않은 프레임을 삭제하여 주기적이거나 만성적인 느린 처리로부터 당신을 절약합니다.

00:26:55.000 --> 00:27:00.000
AVAssetWriter와 같이 수신 중인 프레임을 기록해야 하는 경우 도움이 되지 않습니다.

00:27:00.000 --> 00:27:12.000
처리된 결과를 기록하려면, 항상 DisccardsLateVideoFrames를 끄고 처리 시간에 세심한 주의를 기울여야 합니다.

00:27:12.000 --> 00:27:21.000
VideoDataOutput은 제공된 captureOutput didDrop sampleBuffer 대리자 콜백을 호출하여 프레임 드롭이 언제 발생하는지 알려줍니다.

00:27:21.000 --> 00:27:29.000
didDrop 콜백을 받으면, 포함된 sampleBuffer의 첨부 파일에 대해 droppedFrameReason을 검사할 수 있습니다.

00:27:29.000 --> 00:27:33.000
이것은 추가적인 프레임 드롭을 완화하기 위해 무엇을 해야 하는지 알려줄 수 있다.

00:27:33.000 --> 00:27:53.000
세 가지 이유가 있습니다: FrameWasLate, 이는 처리가 너무 오래 걸린다는 것을 의미합니다; OutOfBuffers, 이는 당신이 너무 많은 버퍼를 붙잡고 있을 수 있다는 것을 의미합니다; 그리고 불연속성, 이는 시스템이 느려지거나 당신의 잘못이 아닌 하드웨어 고장이 있다는 것을 의미합니다.

00:27:53.000 --> 00:27:56.000
이제 프레임 드롭에 반응하는 방법에 대해 이야기해 봅시다.

00:27:56.000 --> 00:28:00.000
가장 좋은 방법 중 하나는 장치 프레임 속도를 동적으로 낮추는 것이다.

00:28:00.000 --> 00:28:04.000
그렇게 하면 미리보기나 출력에 결함이 발생하지 않습니다.

00:28:04.000 --> 00:28:10.000
런타임에 AVCaptureDevice에서 새로운 activeMinVideoFrameDuration을 설정하기만 하면 됩니다.

00:28:10.000 --> 00:28:18.000
두 번째 방법은 작업량을 단순화하여 많은 시간을 들이지 않도록 하는 것입니다.

00:28:18.000 --> 00:28:26.000
이제 카메라 앱의 좋은 사용자 경험에 매우 중요한 또 다른 성능 지표인 시스템 압력에 대해 이야기해 봅시다.

00:28:26.000 --> 00:28:32.000
시스템 압력은 시스템이 변형이나 압력을 받을 수 있다는 것을 의미한다.

00:28:32.000 --> 00:28:40.000
AVCaptureDevice에는 요인과 전체 수준으로 구성된 systemPressureState라는 속성이 있습니다.

00:28:40.000 --> 00:28:47.000
SystemPressureState 기여 요인은 세 가지 가능한 기여자의 약간의 가면이다.

00:28:47.000 --> 00:28:51.000
시스템 온도는 장치가 얼마나 뜨거워지고 있는지를 나타낸다.

00:28:51.000 --> 00:29:00.000
피크파워는 배터리 노화에 관한 것이며, 배터리가 피크 전력 수요를 충족시킬 수 있을 만큼 빠르게 전압을 증가시킬 수 있는지 여부에 관한 것입니다.

00:29:00.000 --> 00:29:08.000
그리고 depthModuleTemperature는 TrueDepth 카메라의 적외선 센서가 얼마나 뜨거워지고 있는지를 나타냅니다.

00:29:08.000 --> 00:29:16.000
SystemPressureState의 수준은 사용자 경험이 손상되기 전에 조치를 취하는 데 도움이 되는 지표입니다.

00:29:16.000 --> 00:29:19.000
그것이 명목상일 때, 모든 것이 완벽하다.

00:29:19.000 --> 00:29:23.000
공정은 시스템 압력이 약간 높다는 것을 나타낸다.

00:29:23.000 --> 00:29:29.000
이것은 당신이 처리를 거의 하지 않지만 주변 온도가 높더라도 일어날 수 있습니다.

00:29:29.000 --> 00:29:35.000
심각한 경우, 시스템 압력이 매우 높습니다; 캡처 성능이 영향을 받을 수 있습니다.

00:29:35.000 --> 00:29:38.000
프레임 속도 조절이 권장됩니다.

00:29:38.000 --> 00:29:47.000
일단 당신이 임계에 도달하면, 시스템 압력은 매우 높아집니다; 캡처 품질과 성능은 상당한 영향을 받습니다.

00:29:47.000 --> 00:29:50.000
프레임 속도 조절이 적극 권장됩니다.

00:29:50.000 --> 00:29:57.000
그리고 당신은 시스템 압력이 심각하지 않은 셧다운으로 상황이 악화되는 것을 절대 원하지 않습니다.

00:29:57.000 --> 00:30:05.000
이 수준에서, AVCaptureSession은 열 트랩에서 장치를 구하기 위해 자동으로 멈춘다.

00:30:05.000 --> 00:30:09.000
당신은 다양한 방법으로 높은 압력에 반응할 수 있습니다.

00:30:09.000 --> 00:30:14.000
캡처 프레임 속도를 낮추세요; 이것은 항상 시스템 압력에 도움이 될 것입니다.

00:30:14.000 --> 00:30:22.000
프레임 속도를 낮추는 것이 선택 사항이 아닌 경우, 특정 기능을 끄는 것과 같이 CPU 또는 GPU의 워크로드를 줄이는 것을 고려하십시오.

00:30:22.000 --> 00:30:31.000
당신은 또한 기능을 계속 유지할 수 있지만, 아마도 더 작은 해상도를 처리하거나 덜 자주 처리함으로써 품질을 저하시킬 수 있습니다.

00:30:31.000 --> 00:30:41.000
AVCaptureSession은 그것이 당신의 앱에 대한 허용 가능한 품질 저하 전략인지 모르기 때문에 당신을 대신하여 속도 스로틀을 프레임하지 않습니다.

00:30:41.000 --> 00:30:43.000
그것은 성능 모범 사례를 마무리한다.

00:30:43.000 --> 00:30:49.000
이제 디저트 코스로, IOSurface 압축.

00:30:49.000 --> 00:31:04.000
ISP를 통해 결국 사진, 영화, 미리보기 또는 버퍼로 흐르는 비디오의 전체 메모리 대역폭 요구 사항에 대해 할 수 있는 일이 많지 않기 때문에 성능 섹션에서 메모리 대역폭에 대해 이야기하는 것을 조심스럽게 피했습니다.

00:31:04.000 --> 00:31:12.000
하지만 여전히, 메모리 대역폭은 어떤 카메라 기능이 동시에 실행될 수 있는지 결정하는 데 중요한 제한자가 될 수 있다.

00:31:12.000 --> 00:31:18.000
iOS와 macOS에서 압축되지 않은 비디오로 작업할 때, 많은 레이어가 관련되어 있습니다.

00:31:18.000 --> 00:31:21.000
그건 약간 러시아 둥지 인형 같아.

00:31:21.000 --> 00:31:31.000
최상위 수준에는 타이밍 및 메타데이터뿐만 아니라 모든 종류의 미디어 데이터를 래핑할 수 있는 CMSampleBuffer가 있습니다.

00:31:31.000 --> 00:31:40.000
한 단계 아래에는 메타데이터 첨부 파일과 함께 픽셀 버퍼 데이터를 특별히 감싸는 CVPixelBuffer가 있습니다.

00:31:40.000 --> 00:31:52.000
마지막으로, 메모리를 커널에 연결할 수 있는 가장 낮은 수준인 IOSurface에 도달하고 프로세스 전반에 걸쳐 큰 비디오 버퍼를 공유할 수 있는 인터페이스를 제공합니다.

00:31:52.000 --> 00:31:54.000
IOSurfaces는 거대하다.

00:31:54.000 --> 00:31:59.000
그들은 압축되지 않은 비디오의 큰 메모리 대역폭 요구 사항을 설명한다.

00:31:59.000 --> 00:32:05.000
이제 고맙게도, IOSurface 압축은 메모리 대역폭 문제에 대한 해결책을 제공한다.

00:32:05.000 --> 00:32:12.000
iOS 15의 새로운 기능, 우리는 무손실 인메모리 비디오 압축 형식에 대한 지원을 도입하고 있습니다.

00:32:12.000 --> 00:32:17.000
라이브 비디오의 총 메모리 대역폭을 낮추기 위한 최적화입니다.

00:32:17.000 --> 00:32:23.000
iOS 기기와 Mac의 주요 하드웨어 블록이 이해하는 교환 형식입니다.

00:32:23.000 --> 00:32:36.000
모든 iPhone 12 변형, 2020년 가을 iPad Air 및 2021년 봄 M1 iPad Pro에서 사용할 수 있습니다.

00:32:36.000 --> 00:32:40.000
압축된 IOSurfaces에서 어떤 주요 하드웨어 블록이 거래되나요?

00:32:40.000 --> 00:32:43.000
음, 많이 있어.

00:32:43.000 --> 00:32:51.000
여기에 나열된 모든 서비스는 압축된 IOSurfaces를 읽거나 쓰는 방법을 이해합니다.

00:32:51.000 --> 00:32:56.000
이 시점에서 당신은 "좋아요, 어떻게 가입하나요?"라고 말할 수 있습니다.

00:32:56.000 --> 00:32:57.000
음, 좋은 소식이야.

00:32:57.000 --> 00:33:12.000
지원되는 하드웨어에서 비디오를 캡처하고 AVCaptureSession이 프로세스에 버퍼를 제공할 필요가 없다면, 축하합니다. 세션은 이미 메모리 대역폭을 줄일 수 있을 때마다 IOSurface 압축을 활용하고 있습니다.

00:33:12.000 --> 00:33:20.000
압축된 표면을 비디오 데이터 출력에 전달하려면, 몇 가지 규칙에 대해 알아야 합니다.

00:33:20.000 --> 00:33:35.000
물리적 메모리 레이아웃은 불투명하고 변경될 수 있으므로, 디스크에 쓰지 말고, 모든 플랫폼에서 동일한 레이아웃을 가정하지 말고, CPU를 사용하여 읽거나 쓰지 마세요.

00:33:35.000 --> 00:33:40.000
AVCaptureVideoDataOutput은 여러 가지 버전의 IOSurface 압축을 지원합니다.

00:33:40.000 --> 00:33:51.000
이야기 초반에, 당신은 iOS 카메라가 기본적으로 420v와 420f를 지원한다는 것을 배웠습니다 -- 8비트 YUV 형식; 하나의 비디오와 하나의 전체 범위.

00:33:51.000 --> 00:33:57.000
그리고 나중에, 당신은 10비트 HDR 비디오 포맷인 x420에 대해 배웠습니다.

00:33:57.000 --> 00:34:05.000
요청 시 비디오 데이터 출력은 내부적으로 픽셀당 16비트 BGRA로 확장될 수 있습니다.

00:34:05.000 --> 00:34:14.000
이들 각각에는 iOS 15부터 AVCaptureVideoDataOutput을 통해 요청할 수 있는 IOSurface 압축 등가물이 있습니다.

00:34:14.000 --> 00:34:20.000
만약 당신이 네 문자 코드의 앰퍼샌드의 팬이라면, 오늘은 당신의 행운의 날입니다.

00:34:20.000 --> 00:34:23.000
여기 다시 아이 차트 형식이 있습니다.

00:34:23.000 --> 00:34:28.000
이것들은 코드에서 사용해야 하는 실제 상수입니다.

00:34:28.000 --> 00:34:33.000
2년 전에 우리는 "AVMultiCamPiP"라는 샘플 코드를 출시했습니다.

00:34:33.000 --> 00:34:53.000
이 샘플에서 전면 및 후면 카메라는 멀티캠 세션을 사용하여 VideoDataOutputs로 동시에 스트리밍된 다음 Metal 셰이더를 사용하여 Picture in Picture로 합성된 다음 AVAssetWriter를 사용하여 미리 보기 위해 컴포지트를 렌더링하고 영화에 씁니다.

00:34:53.000 --> 00:35:01.000
이것은 이러한 모든 작업이 하드웨어에서 수행되기 때문에 IOSurface 압축을 위한 완벽한 후보이다.

00:35:01.000 --> 00:35:06.000
다음은 AVMultiCamPiP의 기존 VideoDataOutput 설정 코드입니다.

00:35:06.000 --> 00:35:16.000
BGRA와 함께 작업하는 것을 좋아하기 때문에, 픽셀 형식 유형을 생성하도록 VideoDataOutput의 videoSettings를 구성합니다.

00:35:16.000 --> 00:35:19.000
새로운 코드는 단지 몇 가지 수표를 포함한다.

00:35:19.000 --> 00:35:25.000
먼저 BGRA의 IOSurface 압축 버전을 사용할 수 있는지 확인합니다.

00:35:25.000 --> 00:35:31.000
그리고 만약 그렇다면, 그것은 그것을 선택한다; 다른 조항은 대안으로 거기에 있다.

00:35:31.000 --> 00:35:35.000
그리고 그렇게, 우리는 끝에 왔다.

00:35:35.000 --> 00:35:52.000
최소 초점 거리 보고, 10비트 HDR 비디오를 캡처하는 방법, 제어 센터의 비디오 효과 및 마이크 모드, 성능 모범 사례 및 IOSurface 압축에 대해 배웠습니다.

00:35:52.000 --> 00:35:54.000
네가 즐겼길 바라!

00:35:54.000 --> 00:35:55.000
봐줘서 고마워.

00:35:55.000 --> 23:59:59.000
♪

