WEBVTT

00:00:00.000 --> 00:00:05.000
♪ 베이스 음악 연주 ♪

00:00:05.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:11.000
타오 지아: 안녕하세요, 제 이름은 타오입니다.

00:00:11.000 --> 00:00:18.000
오늘, 제 동료 잭과 저는 Create ML 프레임워크로 동적 iOS 앱을 만드는 것에 대해 이야기할 것입니다.

00:00:18.000 --> 00:00:21.000
그래서 앱이 역동적이라는 게 무슨 뜻이야?

00:00:21.000 --> 00:00:28.000
동적 앱은 사용자에게 앱의 특정 요소를 사용자 정의할 수 있는 유연성을 제공하는 앱입니다.

00:00:28.000 --> 00:00:34.000
동적 앱은 또한 다양한 사용자의 요구에 가장 잘 맞게 콘텐츠를 조정합니다.

00:00:34.000 --> 00:00:42.000
이러한 적응 가능한 인앱 기능은 사용자에게 더 지능적이고 개인화된 경험을 제공합니다.

00:00:42.000 --> 00:00:48.000
간단한 휴리스틱과 미리 정의된 규칙으로 그러한 경험을 제공할 수 있습니다.

00:00:48.000 --> 00:00:58.000
그러나 종종 이러한 접근 방식은 배경과 선호도가 다를 수 있기 때문에 모든 앱 사용자에게 최상의 경험을 제공하지 못할 수 있습니다.

00:00:58.000 --> 00:01:05.000
반면에, 기계 학습 기술을 사용하면 사용자 데이터에서 직접 배우는 모델을 만들 수 있습니다.

00:01:05.000 --> 00:01:12.000
이것은 종종 더 일반화 가능하고 휴리스틱과 미리 정의된 규칙보다 더 많은 사용자에게 적합할 가능성이 높다.

00:01:12.000 --> 00:01:16.000
그래서 그러한 경험을 제공하기 위해 어떤 도구를 사용할 수 있나요?

00:01:16.000 --> 00:01:26.000
Mac에서 사용할 수 있는 Create ML 앱을 사용하면 훈련 데이터를 선택하고 기차 버튼을 눌러 모델을 쉽게 만들 수 있습니다.

00:01:26.000 --> 00:01:32.000
그것은 풍부한 템플릿 세트를 통해 모든 종류의 모델 유형을 지원합니다.

00:01:32.000 --> 00:01:40.000
이 앱은 기계 학습 모델의 가속화된 교육을 제공하는 Create ML 프레임워크 위에 구축되었습니다.

00:01:40.000 --> 00:01:51.000
Create ML 프레임워크는 원래 macOS Mojave에 도입되어 Swift 코드와 macOS 앱 내에서 모델을 훈련할 수 있습니다.

00:01:51.000 --> 00:01:58.000
그리고 이제 우리는 그 프레임워크를 iOS 15와 iPadOS 15로 가져오고 있습니다.

00:01:58.000 --> 00:02:04.000
장치에서 사용할 수 있으므로, 앱은 모든 종류의 새롭고 역동적인 일을 할 수 있습니다.

00:02:04.000 --> 00:02:12.000
즉, 온디바이스 모델 생성을 위해 애플리케이션에서 직접 프로그래밍 API에 액세스할 수 있습니다.

00:02:12.000 --> 00:02:18.000
그것은 당신의 앱에 사용자로부터 배우고 적응할 수 있는 기능을 제공합니다.

00:02:18.000 --> 00:02:25.000
마지막으로 가장 중요한 것은, 사용자 데이터가 장치를 떠날 필요가 없다는 것입니다. 따라서 사용자 개인 정보 보호가 보존됩니다.

00:02:25.000 --> 00:02:27.000
이제, 뛰어들자.

00:02:27.000 --> 00:02:30.000
Create ML에는 다양한 작업이 있습니다.

00:02:30.000 --> 00:02:38.000
다음은 macOS에서 사용할 수 있는 모든 것이며, 이제 iOS에서 사용할 수 있습니다.

00:02:38.000 --> 00:02:43.000
그 중에는 이미지, 사운드 및 텍스트 분류기와 같은 인기 있는 작업이 있다.

00:02:43.000 --> 00:02:52.000
최근에 추가된 것들은 스타일 전송뿐만 아니라 올해의 새로운 핸드 포즈와 핸드 액션 분류기를 포함한다.

00:02:52.000 --> 00:02:57.000
이러한 도구를 사용하면, 많은 흥미로운 아이디어와 사용 사례가 있습니다.

00:02:57.000 --> 00:02:59.000
여기 몇 가지 예가 있습니다.

00:02:59.000 --> 00:03:13.000
이미지 분류를 통해, 앱은 아이가 가장 좋아하는 박제 동물이 어떻게 생겼는지 배우고 그들의 모험에 대한 이야기를 함께 만드는 데 도움이 되도록 더 많은 사진을 찾을 수 있습니다.

00:03:13.000 --> 00:03:24.000
텍스트 분류기는 사용자가 과거 행동에서 배운 제안된 태그와 폴더로 방금 쓴 메모를 빠르게 정리하는 데 사용할 수 있습니다.

00:03:24.000 --> 00:03:34.000
올해 새로운 핸드 액션 분류기는 사용자에게 사용자 지정 핸드 액션으로 인앱 시각 효과를 트리거할 수 있는 힘을 줄 수 있습니다.

00:03:34.000 --> 00:03:42.000
iOS에서 Create ML로 할 수 있는 멋진 것들이 너무 많지만 데모로 무엇을 의미하는지 보여주는 것이 좋습니다.

00:03:42.000 --> 00:03:51.000
사진 부스 앱처럼 보이는 앱이 있지만, 맞춤형 사진 필터를 만들 수 있기 때문에 더 역동적입니다.

00:03:51.000 --> 00:03:55.000
그게 어떻게 작동하는지 보여줄게.

00:03:55.000 --> 00:04:04.000
여기 내 iPad에서는 Create ML 스타일 전송 작업을 사용하여 Mac에서 훈련한 기존 필터 목록이 맨 위에 표시됩니다.

00:04:04.000 --> 00:04:09.000
그들 각각은 필터를 만드는 데 사용되는 특정 스타일 이미지로 표현된다.

00:04:09.000 --> 00:04:17.000
하단에서, 앱은 사진을 찍거나 선택하여 그 필터를 시도하기 위해 사진을 기다리고 있다.

00:04:17.000 --> 00:04:20.000
지금 사진 찍을게.

00:04:20.000 --> 00:04:22.000
셀카는 어때?

00:04:22.000 --> 00:04:28.000
이 필터들이 어떻게 생겼는지 봅시다.

00:04:28.000 --> 00:04:32.000
먼저 파도 형태의 첫 번째 사진을 클릭하겠습니다.

00:04:32.000 --> 00:04:40.000
오, 내 얼굴과 머리카락에 이 모든 물방울이 있어; 오래 전 마이애미에서의 휴가를 떠올리게 해.

00:04:40.000 --> 00:04:42.000
이 버디 사진은 어때?

00:04:42.000 --> 00:04:45.000
내가 얼마나 다채로운지 봐.

00:04:45.000 --> 00:04:50.000
금이 간 얼음처럼 보이는 이 세 번째 사진은 어때?

00:04:50.000 --> 00:04:54.000
오, 나는 멋지고 얼어붙어 보여.

00:04:54.000 --> 00:04:59.000
이제 이것들은 정말 재미있어 보이지만, 나는 여전히 무언가를 놓치고 있다고 느낀다.

00:04:59.000 --> 00:05:04.000
내가 선택한 사진을 사용하여 필터를 만들 수 있다면 어떨까요?

00:05:04.000 --> 00:05:07.000
그것은 이 앱을 사용하는 것을 정말 재미있게 만들 것이다.

00:05:07.000 --> 00:05:14.000
내가 한 번 해볼게.

00:05:14.000 --> 00:05:17.000
나는 내 딸이 3살이었을 때 이 그림을 가지고 있다.

00:05:17.000 --> 00:05:20.000
나는 질감과 색을 정말 좋아해.

00:05:20.000 --> 00:05:28.000
나는 내 딸의 예술적 스타일에서 내가 어떻게 보일지 궁금하다.

00:05:28.000 --> 00:05:37.000
이 "+ 필터" 버튼을 클릭하고, 카메라를 선택하고, 사진을 찍을게요.

00:05:37.000 --> 00:05:43.000
"사진을 사용해."

00:05:43.000 --> 00:05:45.000
이제 필터가 생성되고 있다.

00:05:45.000 --> 00:05:49.000
후드 아래에서, 그것은 맞춤형 스타일 전송 모델을 훈련하고 있다.

00:05:49.000 --> 00:05:52.000
그게 어떻게 작동하는지 설명할게.

00:05:52.000 --> 00:05:55.000
먼저, 단일 스타일 이미지를 선택하세요.

00:05:55.000 --> 00:05:59.000
내가 사용한 스타일 이미지는 내 딸의 그림이다.

00:05:59.000 --> 00:06:10.000
다음으로, 이 이미지의 원본 내용을 보존하면서 스타일을 적용하는 방법을 배우기 위해 모델에 대한 콘텐츠 이미지 세트를 제공해야 합니다.

00:06:10.000 --> 00:06:18.000
이 데모에서, 나는 경치 좋은 사진과 셀카를 포함하여 내 앨범의 수십 장의 사진을 사용했다.

00:06:18.000 --> 00:06:29.000
다른 사진 유형(예: 애완동물 사진)에 스타일을 적용하고 싶다면 콘텐츠 세트에 몇 장의 사진을 포함할 수도 있습니다.

00:06:29.000 --> 00:06:36.000
그런 다음, 애플리케이션 시나리오에 따라 필터 유형을 이미지 또는 비디오로 선택하십시오.

00:06:36.000 --> 00:06:43.000
이 데모를 위해, 나는 정적 사진에 스타일을 적용하고 싶기 때문에 이미지를 선택했다.

00:06:43.000 --> 00:06:56.000
또한 스타일 강도와 스타일 밀도뿐만 아니라 반복 횟수를 실험하여 스타일화와 원본 콘텐츠의 가장 좋아하는 조합을 얻을 수 있습니다.

00:06:56.000 --> 00:07:04.000
이러한 매개 변수를 설정하는 방법에 대한 자세한 내용은 작년 WWDC 세션을 참조하십시오.

00:07:04.000 --> 00:07:09.000
이제 새로 만든 필터를 내 사진으로 시도해 보자.

00:07:09.000 --> 00:07:13.000
와, 그게 내가 내 딸의 그림을 보는 방식이야.

00:07:13.000 --> 00:07:17.000
그것은 실제로 이러한 질감과 색상을 포착했다.

00:07:17.000 --> 00:07:24.000
내가 다른 사진을 찍는 건 어때?

00:07:24.000 --> 00:07:27.000
나는 내 딸이 정말 가지고 노는 것을 정말 좋아하는 토끼를 가지고 있다.

00:07:27.000 --> 00:07:32.000
토끼와 셀카를 찍고 필터를 바르는 건 어때?

00:07:32.000 --> 00:07:40.000
토끼도 그녀의 그림으로 양식화되었다.

00:07:40.000 --> 00:07:44.000
빨리 이걸 그녀에게 보여주고 그녀의 다른 그림들을 입어보고 싶어.

00:07:44.000 --> 00:07:46.000
정말 재미있을 거야.

00:07:46.000 --> 00:07:55.000
이 데모에서는 iOS의 Create ML 프레임워크에서 사용할 수 있는 스타일 전송 모델을 활용하여 맞춤형 사진 필터를 만드는 방법을 보여주었습니다.

00:07:55.000 --> 00:07:58.000
그래서 그건 코드에서 어떻게 생겼어?

00:07:58.000 --> 00:08:05.000
먼저, 하나의 스타일 이미지와 콘텐츠 이미지 세트를 지정하는 훈련 데이터 소스를 정의하십시오.

00:08:05.000 --> 00:08:13.000
다음으로, 세션 매개 변수를 정의하여 체크포인트를 저장할 위치와 같은 것을 지정하십시오.

00:08:13.000 --> 00:08:18.000
다음으로, 이 매개 변수를 사용하여 훈련 작업을 정의하세요.

00:08:18.000 --> 00:08:33.000
마지막으로, 교육 작업을 파견하고, 성공적으로 완료되면, 훈련된 모델을 저장하여 이미지를 양식화하고, 코어 ML 모델을 컴파일 및 인스턴스화하고, 예측을 시작하세요.

00:08:33.000 --> 00:08:34.000
그리고 그게 다야.

00:08:34.000 --> 00:08:41.000
그것이 내가 Create ML 프레임워크의 스타일 전송 API를 사용하여 맞춤형 사진 필터를 만드는 데 사용한 것이다.

00:08:41.000 --> 00:08:45.000
다른 작업은 비슷한 API 패턴을 따른다.

00:08:45.000 --> 00:08:54.000
지금까지 저는 이미지, 텍스트, 오디오 및 비디오와 같은 리치 미디어 데이터 유형에서 모델을 만들 수 있는 작업에 대해 이야기했습니다.

00:08:54.000 --> 00:08:58.000
하지만 당신의 앱이 그러한 데이터 유형과 상호 작용하지 않는다면 어떨까요?

00:08:58.000 --> 00:09:05.000
제 동료 잭을 초대하여 이러한 경우에 앱을 어떻게 역동적으로 만들 수 있는지에 대해 이야기하겠습니다.

00:09:05.000 --> 00:09:06.000
잭 캐클러: 고마워, 타오.

00:09:06.000 --> 00:09:15.000
지금까지 다룬 작업 외에도, iOS의 Create ML 프레임워크는 구조화된 표 데이터에 대한 분류기와 회귀자도 지원합니다.

00:09:15.000 --> 00:09:20.000
이것들이 어떻게 더 역동적인 앱 경험을 만들 수 있는지에 대한 예를 살펴봅시다.

00:09:20.000 --> 00:09:23.000
첫째, 분류기와 회귀자에 대한 배경.

00:09:23.000 --> 00:09:29.000
분류자는 훈련 데이터 세트의 데이터에서 특정 클래스를 예측하는 법을 배웁니다.

00:09:29.000 --> 00:09:35.000
회귀자는 비슷하지만, 이산 클래스 라벨 대신 숫자 값을 예측하는 법을 배운다.

00:09:35.000 --> 00:09:43.000
다음은 일반적인 표 데이터에서 분류자와 회귀자를 훈련시키기 위한 API이며, 다양한 시나리오에서 사용할 수 있습니다.

00:09:43.000 --> 00:09:49.000
특히, iOS에서 Create ML은 이들 각각에 대해 네 가지 다른 알고리즘을 제공한다.

00:09:49.000 --> 00:09:58.000
일반적인 표 모델로 작업하려면 모델에서 사용할 기능과 목표 값을 결정해야 하기 때문에 조금 더 많은 작업이 필요할 수 있습니다.

00:09:58.000 --> 00:10:00.000
그러나, 이것은 종종 간단할 수 있다.

00:10:00.000 --> 00:10:07.000
개인화된 경험을 추가하기 위해 표형 레그레시터를 사용하는 앱을 고려해 봅시다.

00:10:07.000 --> 00:10:10.000
여기 식당에서 식사를 주문할 수 있는 간단한 앱이 있습니다.

00:10:10.000 --> 00:10:12.000
그 앱에는 그 지역에 레스토랑이 있다.

00:10:12.000 --> 00:10:15.000
여기 어메이징 타이라고 불리는 현지 태국 레스토랑이 있습니다.

00:10:15.000 --> 00:10:21.000
내가 그것을 선택하면, 앱은 내가 식당에서 주문할 수 있는 요리와 각 요리에 대한 정보를 보여준다.

00:10:21.000 --> 00:10:24.000
간단한 앱이지만, 더 좋게 만들 수 있다면 어떨까요?

00:10:24.000 --> 00:10:32.000
정말 깔끔한 것은 시간이 지남에 따라 내 앱이 내 행동을 배우고 내가 좋아할 수 있는 지능형 레스토랑과 요리 제안을 표면화하는 데 도움이 되었다는 것이다.

00:10:32.000 --> 00:10:37.000
이것은 이것을 간단한 앱에서 정말 역동적인 경험으로 가져갈 것이다.

00:10:37.000 --> 00:10:41.000
나는 앱에서 바로 표 회귀자를 훈련시킴으로써 이것을 달성할 수 있다.

00:10:41.000 --> 00:10:50.000
나는 세 가지 종류의 정보를 가져와 구조화된 테이블에 결합하여 모델을 훈련시키고 새로운 역동적인 경험을 제공할 것이다.

00:10:50.000 --> 00:10:54.000
첫 번째는 내가 앱에 로드한 데이터인 콘텐츠이다.

00:10:54.000 --> 00:10:57.000
우리 레스토랑 앱의 경우, 그것은 요리에 대한 정보입니다.

00:10:57.000 --> 00:10:59.000
두 번째는 맥락이다.

00:10:59.000 --> 00:11:03.000
이 경우, 사용자가 주문하는 시간.

00:11:03.000 --> 00:11:10.000
마지막으로, 저는 사용자의 주문 내역을 추가하고 그들의 장치에서 바로 그들에게 딱 맞는 경험을 만듭니다.

00:11:10.000 --> 00:11:24.000
과거의 사용자 상호 작용뿐만 아니라 콘텐츠와 맥락을 결합함으로써, 나는 미래의 상호 작용을 예측할 수 있다; 개인화를 위한 좋은 기회이며, 이 경우 사용자가 미래에 좋아할 만한 요리를 예측하는 데 도움이 된다.

00:11:24.000 --> 00:11:27.000
모델이 추가된 앱으로 돌아가자.

00:11:27.000 --> 00:11:30.000
나는 오늘 점심을 주문하고 피자를 먹고 싶어.

00:11:30.000 --> 00:11:39.000
나는 식사를 점심으로 설정하고 피자 가게를 선택하고, 마르게리타 피자를 골라서 주문한다.

00:11:39.000 --> 00:11:44.000
이 창에는 실제로 우리의 표 회귀자를 훈련시키는 몇 가지 정보가 있습니다.

00:11:44.000 --> 00:11:55.000
그 내용은 이 요리의 키워드이다; 재료와 같은 것들 - 토마토, 모짜렐라 - 그리고 레스토랑 자체 - 피자 팔러 - 그리고 음식 장르 - 피자.

00:11:55.000 --> 00:11:58.000
이 모델의 맥락은 하루 중 시간이다.

00:11:58.000 --> 00:12:03.000
이건 점심에서 나온 거야, 그리고 이제 나는 내 모델에게 이것들이 내가 점심 때 좋아할 만한 것들이라고 가르쳤어.

00:12:03.000 --> 00:12:07.000
마지막으로, 내 상호 작용은 내가 다른 요리가 아니라 이 요리를 주문했다는 것이다.

00:12:07.000 --> 00:12:16.000
내가 훈련하고 있는 레그레이터는 내가 주문할 수 있는 각 요리에 대한 선호도 점수를 예측하고 있으며, 오늘 내가 다른 요리가 아니라 이 요리를 주문했다는 것을 알게 되었다.

00:12:16.000 --> 00:12:25.000
메인 화면으로 돌아가서, 모델은 이미 훈련을 받았고 나만을 위한 요리를 제안하는 새로운 창이 있다.

00:12:25.000 --> 00:12:33.000
내가 실제로 주문한 요리인 마르게리타 피자는 첫 번째 추천이지만, 다음 추천은 완전히 다른 레스토랑의 카프레제 샌드위치이다.

00:12:33.000 --> 00:12:36.000
몇몇 다른 피자들도 꼭대기 근처에 있다.

00:12:36.000 --> 00:12:38.000
다른 예를 들어 보자.

00:12:38.000 --> 00:12:42.000
내가 지금 저녁을 주문하고 있다고 말해줘.

00:12:42.000 --> 00:12:48.000
이번에는 어메이징 타이에서 노란 카레를 주문한다.

00:12:48.000 --> 00:12:50.000
이제 모델이 다시 업데이트되었습니다.

00:12:50.000 --> 00:12:53.000
그것은 내가 주문하는 시간에 맥락인 나의 새로운 선호도를 배웠다.

00:12:53.000 --> 00:12:59.000
내가 방금 주문한 노란 카레는 이제 최고의 추천이고 비슷한 카레가 두 번째 추천이다.

00:12:59.000 --> 00:13:02.000
다음 추천은 채식 피자입니다.

00:13:02.000 --> 00:13:10.000
내가 방금 주문한 카레처럼 버섯과 후추가 있고, 앱은 내가 저녁 식사의 첫 번째 선택이 아닐지라도 내가 피자를 좋아할 수도 있다는 것을 알고 있다.

00:13:10.000 --> 00:13:18.000
만약 내가 다음날 점심을 주문하러 간다면, 그 모델은 내가 점심으로 주문할 수 있는 것과 저녁으로 주문할 수 있는 것을 구별하는 법을 배웠다.

00:13:18.000 --> 00:13:26.000
이것은 내가 원하는 시간에 내가 원하는 것을 정확히 찾는 데 도움이 되는 정말 개인화된 경험을 제공하며, 그것은 단지 두 개의 주문으로 이루어진다.

00:13:26.000 --> 00:13:36.000
앱에 표 분류기 또는 회귀자를 추가하는 세 가지 실제 단계가 있습니다: 데이터 설정, 훈련 및 예측.

00:13:36.000 --> 00:13:42.000
여기서 첫 번째 기능은 식사와 키워드에서 이 회귀에서 활용되는 기능을 만듭니다.

00:13:42.000 --> 00:13:57.000
각 요리와 관련된 키워드를 현재 식사(컨텍스트)와 결합하여 모델이 콘텐츠(디시) 키워드와 컨텍스트(식사) 키워드 간의 상호 작용을 캡처할 수 있는 새로운 키워드를 만듭니다.

00:13:57.000 --> 00:14:07.000
우리는 단순히 특정 키워드가 데이터 입력에 존재한다는 것을 나타내기 위해 사전에 1.0의 값을 넣었다.

00:14:07.000 --> 00:14:14.000
먼저, 사용자가 주문한 각 요리에 대해, 이전에 생성된 기능과 긍정적인 목표 값이 있는 항목을 추가합니다.

00:14:14.000 --> 00:14:21.000
하지만, 내가 이것을 포함시킨다면, 그 모델은 내가 어떤 요리를 좋아하고 어떤 요리를 좋아하지 않는지 분별하는 법을 배우지 못할 것이다.

00:14:21.000 --> 00:14:29.000
이를 위해, 나는 또한 음의 목표 값이 -1인 접시에 없는 모든 키워드를 사용하여 항목을 추가합니다.

00:14:29.000 --> 00:14:35.000
이것은 모델이 어떤 키워드가 사용자 선호도에 가장 적합한지 배울 수 있게 해준다.

00:14:35.000 --> 00:14:42.000
나는 이 결합된 정보를 DataFrame으로 변환하여 키워드와 대상을 모두 지정한다.

00:14:42.000 --> 00:14:51.000
마지막으로, 나는 내가 예측하려고 하는 열이 내가 1 또는 -1로 설정한 대상 열이라고 명시하면서 모델을 훈련시킨다.

00:14:51.000 --> 00:14:58.000
이 경우, 모델은 앱에서 사용할 수 있는 의미 있는 결과를 생성하는 간단한 선형 회귀기입니다.

00:14:58.000 --> 00:15:06.000
예측 시간에, 나는 단순히 추론을 실행하고 싶은 데이터를 가지고 내가 훈련한 모델에서 예측을 호출한다.

00:15:06.000 --> 00:15:14.000
지금까지 우리는 iPadOS와 iOS 앱에서 스타일 전송 모델과 표형 레그레시터를 훈련시키는 방법을 보여주었습니다.

00:15:14.000 --> 00:15:19.000
기계 학습 교육을 앱에 통합하는 몇 가지 모범 사례에 대해 이야기해 봅시다.

00:15:19.000 --> 00:15:22.000
일반적으로 기계 학습을 위한 모범 사례를 따르는 것을 잊지 마세요.

00:15:22.000 --> 00:15:28.000
예를 들어, 훈련 데이터 세트가 아닌 데이터에서 모델이 어떻게 작동하는지 항상 테스트하세요.

00:15:28.000 --> 00:15:36.000
장기간의 훈련 작업의 경우, 비동기 훈련 제어 및 체크포인트 메커니즘을 활용하여 모델 생성 워크플로우를 사용자 정의하십시오.

00:15:36.000 --> 00:15:45.000
모델 생성의 일부 측면은 계산 집약적이거나, 추가 메모리를 소비하거나, 추가 자산을 다운로드해야 할 수 있습니다.

00:15:45.000 --> 00:15:49.000
앱에 통합할 때 이것들을 고려하세요.

00:15:49.000 --> 00:15:53.000
자세한 정보는 API와 문서를 참조하십시오.

00:15:53.000 --> 00:16:07.000
모범 사례에 대해 더 알고 싶다면, "훌륭한 ML 경험 설계"와 "Swift로 ML 만들기의 제어 교육"에 대한 지난 몇 년 동안의 다른 WWDC 세션을 확인하는 것이 좋습니다.

00:16:07.000 --> 00:16:12.000
이 세션에서, 우리는 iOS에서 Create ML 프레임워크를 사용하는 방법에 대해 이야기했습니다.

00:16:12.000 --> 00:16:21.000
우리는 스타일 전송과 표 회귀기를 사용하여 예를 제시했으며, 대부분의 Create ML 템플릿은 이제 iPhone 또는 iPad에서 직접 훈련할 수 있습니다.

00:16:21.000 --> 00:16:30.000
iOS 교육을 통해 사용자 개인 정보를 유지하면서 사용자에게 맞춤화되고 개인화된 경험을 제공하는 동적 앱을 만들 수 있습니다.

00:16:30.000 --> 00:16:36.000
교육과 추론은 전적으로 인앱이기 때문에, 걱정할 모델 배포도 없다.

00:16:36.000 --> 00:16:39.000
우리는 네가 생각해낸 것을 정말 기대하고 있어.

00:16:39.000 --> 00:16:42.000
들어주셔서 감사드리며 나머지 WWDC를 즐기세요.

00:16:42.000 --> 23:59:59.000
♪

