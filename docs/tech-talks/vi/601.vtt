WEBVTT

00:00:00.000 --> 00:00:08.000
iOS 11 giới thiệu ARKit: một khuôn khổ mới để tạo các ứng dụng thực tế tăng cường cho iPhone và iPad.

00:00:08.000 --> 00:00:20.000
ARKit đưa các ứng dụng vượt ra ngoài màn hình bằng cách đặt các đối tượng kỹ thuật số vào môi trường xung quanh bạn, cho phép bạn tương tác với thế giới thực theo những cách hoàn toàn mới.

00:00:20.000 --> 00:00:24.000
Tại WWDC, chúng tôi đã giới thiệu ba khả năng chính cho ARKit.

00:00:24.000 --> 00:00:33.000
Theo dõi vị trí phát hiện tư thế của thiết bị của bạn, cho phép bạn sử dụng iPhone hoặc iPad như một cửa sổ vào thế giới kỹ thuật số xung quanh bạn.

00:00:33.000 --> 00:00:53.000
Hiểu cảnh phát hiện các bề mặt nằm ngang như mặt bàn, tìm các điểm neo ổn định và cung cấp ước tính về điều kiện ánh sáng xung quanh và tích hợp với các công nghệ kết xuất như SpriteKit, SceneKit và Metal, cũng như với các công cụ trò chơi phổ biến như Unity và Unreal.

00:00:53.000 --> 00:01:00.000
Giờ đây với iPhone X, ARKit chuyển trọng tâm sang bạn, cung cấp tính năng theo dõi khuôn mặt bằng cách sử dụng camera mặt trước.

00:01:00.000 --> 00:01:07.000
Khả năng mới này cho phép phát hiện khuôn mặt mạnh mẽ và theo dõi vị trí trong sáu bậc tự do.

00:01:07.000 --> 00:01:20.000
Biểu cảm khuôn mặt cũng được theo dõi trong thời gian thực và các ứng dụng của bạn được cung cấp lưới tam giác vừa vặn và các thông số có trọng số đại diện cho hơn 50 chuyển động cơ cụ thể của khuôn mặt được phát hiện.

00:01:20.000 --> 00:01:27.000
Đối với AR, chúng tôi cung cấp hình ảnh màu mặt trước từ máy ảnh, cũng như hình ảnh có độ sâu phía trước.

00:01:27.000 --> 00:01:36.000
Và ARKit sử dụng khuôn mặt của bạn như một đầu dò ánh sáng để ước tính điều kiện ánh sáng và tạo ra các hệ số hài hòa hình cầu mà bạn có thể áp dụng cho kết xuất của mình.

00:01:36.000 --> 00:01:42.000
Và như tôi đã đề cập, tất cả những điều này được hỗ trợ độc quyền trên iPhone X.

00:01:42.000 --> 00:01:45.000
Có một số điều thực sự thú vị mà bạn có thể làm với Face Tracking.

00:01:45.000 --> 00:02:04.000
Đầu tiên là hiệu ứng selfie, nơi bạn đang hiển thị một kết cấu bán trong suốt lên lưới mặt cho các hiệu ứng như hình xăm ảo, hoặc sơn mặt, hoặc để trang điểm, mọc râu hoặc ria mép, hoặc phủ lên lưới bằng đồ trang sức, mặt nạ, mũ và kính.

00:02:04.000 --> 00:02:16.000
Thứ hai là chụp khuôn mặt, nơi bạn đang chụp biểu cảm khuôn mặt trong thời gian thực và sử dụng nó làm gian lận để chiếu biểu cảm lên hình đại diện hoặc cho một nhân vật trong trò chơi.

00:02:16.000 --> 00:02:20.000
Vì vậy, hãy đi sâu vào chi tiết và xem cách bắt đầu với theo dõi khuôn mặt.

00:02:20.000 --> 00:02:24.000
Điều đầu tiên bạn cần làm là tạo một ARSession.

00:02:24.000 --> 00:02:33.000
ARSession là đối tượng xử lý tất cả quá trình xử lý được thực hiện cho ARKit, mọi thứ từ cấu hình thiết bị đến chạy các kỹ thuật AR khác nhau.

00:02:33.000 --> 00:02:38.000
Để chạy một phiên, trước tiên chúng ta cần mô tả loại theo dõi mà chúng ta muốn cho ứng dụng này.

00:02:38.000 --> 00:02:44.000
Vì vậy, để làm điều này, bạn sẽ tạo một Cấu hình AR cụ thể để theo dõi khuôn mặt và thiết lập nó.

00:02:44.000 --> 00:02:51.000
Bây giờ để bắt đầu xử lý, bạn chỉ cần gọi phương thức "chạy" trong phiên và cung cấp cấu hình bạn muốn chạy.

00:02:51.000 --> 00:02:59.000
Trong nội bộ, ARKit sẽ định cấu hình AVCaptureSession và CMMotionManager để bắt đầu nhận hình ảnh máy ảnh và dữ liệu cảm biến.

00:02:59.000 --> 00:03:03.000
Và sau khi xử lý, kết quả sẽ được xuất ra dưới dạng ARFrames.

00:03:03.000 --> 00:03:12.000
Mỗi ARFrame là một ảnh chụp nhanh theo thời gian, cung cấp hình ảnh máy ảnh, dữ liệu theo dõi và điểm neo - về cơ bản là mọi thứ cần thiết để hiển thị cảnh của bạn.

00:03:12.000 --> 00:03:16.000
Bây giờ chúng ta hãy xem xét kỹ hơn ARConfiguration để theo dõi khuôn mặt.

00:03:16.000 --> 00:03:21.000
Chúng tôi đã thêm một lớp con mới gọi là ARFaceTrackingConfiguration.

00:03:21.000 --> 00:03:28.000
Đây là một lớp con cấu hình đơn giản yêu cầu ARSession cho phép theo dõi khuôn mặt thông qua camera mặt trước.

00:03:28.000 --> 00:03:36.000
Có một vài thuộc tính cơ bản để kiểm tra tính khả dụng của tính khả dụng của theo dõi khuôn mặt trên thiết bị của bạn và có bật ước tính ánh sáng hay không.

00:03:36.000 --> 00:03:41.000
Sau đó, một khi bạn gọi "chạy", bạn sẽ bắt đầu theo dõi và bắt đầu nhận ARFrames.

00:03:41.000 --> 00:03:45.000
Khi một khuôn mặt được phát hiện, phiên sẽ tạo ra một ARFaceAnchor.

00:03:45.000 --> 00:03:52.000
Điều này đại diện cho khuôn mặt chính - khuôn mặt lớn nhất, gần nhất trong tầm nhìn của máy ảnh.

00:03:52.000 --> 00:03:59.000
ARFaceAnchor cung cấp cho bạn tư thế khuôn mặt trong tọa độ thế giới, thông qua thuộc tính biến đổi của siêu lớp của nó.

00:03:59.000 --> 00:04:05.000
Nó cũng cung cấp cấu trúc liên kết 3D và các thông số của biểu cảm khuôn mặt hiện tại.

00:04:05.000 --> 00:04:12.000
Và như bạn có thể thấy, tất cả đều được theo dõi, và lưới và các thông số được cập nhật, trong thời gian thực, 60 lần mỗi giây.

00:04:12.000 --> 00:04:26.000
Giờ đây, tập trung vào cấu trúc liên kết, ARKit cung cấp cho bạn một lưới 3D chi tiết của khuôn mặt được trang bị trong thời gian thực với kích thước, hình dạng và phù hợp với biểu cảm khuôn mặt của người dùng.

00:04:26.000 --> 00:04:32.000
Dữ liệu này có sẵn ở một vài dạng khác nhau; đầu tiên là lớp ARFaceGeometry.

00:04:32.000 --> 00:04:41.000
Về cơ bản, đây là một lưới tam giác, vì vậy một mảng các đỉnh, chỉ số tam giác và tọa độ kết cấu, mà bạn có thể thực hiện để hình dung trong trình kết xuất của mình.

00:04:41.000 --> 00:04:53.000
ARKit cũng cung cấp một cách dễ dàng để hình dung lưới trong SceneKit thông qua lớp ARSCNFaceGeometry, lớp này xác định một đối tượng hình học có thể được gắn vào bất kỳ nút SceneKit nào.

00:04:53.000 --> 00:04:57.000
Bây giờ ngoài lưới hình học, chúng tôi cũng có một cái gì đó mà chúng tôi gọi là hình dạng pha trộn.

00:04:57.000 --> 00:05:02.000
Các hình dạng pha trộn cung cấp một mô hình cấp cao về biểu cảm khuôn mặt hiện tại.

00:05:02.000 --> 00:05:13.000
Chúng là một từ điển gồm các hệ số được đặt tên đại diện cho tư thế của các đặc điểm cụ thể - mí mắt, lông mày, hàm, mũi, v.v. của bạn - tất cả đều liên quan đến vị trí trung tính của chúng.

00:05:13.000 --> 00:05:18.000
Chúng được biểu thị dưới dạng các giá trị dấu phẩy động từ 0 đến 1 và tất cả chúng đều được cập nhật trực tiếp.

00:05:18.000 --> 00:05:28.000
Vì vậy, bạn có thể sử dụng các hệ số hình dạng pha trộn này để tạo hiệu ứng động hoặc giàn khoan, một nhân vật 2D hoặc 3D theo cách phản ánh trực tiếp chuyển động khuôn mặt của người dùng.

00:05:28.000 --> 00:05:32.000
Chỉ để cung cấp cho bạn ý tưởng về những gì có sẵn, đây là danh sách các hệ số hình dạng pha trộn.

00:05:32.000 --> 00:05:43.000
Vì vậy, mỗi thứ này đều được theo dõi và cập nhật độc lập - lông mày phải và trái, vị trí mắt, hàm, hình dạng nụ cười của bạn, vân vân.

00:05:43.000 --> 00:05:50.000
Một cái gì đó đi đôi với việc kết xuất hình học khuôn mặt hoặc tạo hoạt hình cho một nhân vật 3D là ánh sáng thực tế.

00:05:50.000 --> 00:06:02.000
Và bằng cách sử dụng khuôn mặt của bạn như một đầu dò ánh sáng, một ARSession đang chạy phát hiện khuôn mặt có thể cung cấp cho bạn ước tính ánh sáng định hướng, đại diện cho cường độ ánh sáng và hướng của nó trong không gian thế giới.

00:06:02.000 --> 00:06:06.000
Đối với hầu hết các ứng dụng, vectơ ánh sáng và cường độ này là quá đủ.

00:06:06.000 --> 00:06:14.000
Nhưng ARKit cũng cung cấp các hệ số hài hòa hình cầu độ hai, đại diện cho cường độ ánh sáng được phát hiện trong cảnh.

00:06:14.000 --> 00:06:19.000
Vì vậy, đối với các ứng dụng có yêu cầu nâng cao hơn, bạn cũng có thể tận dụng điều này.

00:06:19.000 --> 00:06:21.000
Và một vài tính năng nữa để đề cập đến.

00:06:21.000 --> 00:06:29.000
Ngoài hình ảnh máy ảnh mặt trước với dữ liệu màu, ARKit cũng có thể cung cấp cho ứng dụng của bạn hình ảnh chiều sâu mặt trước.

00:06:29.000 --> 00:06:31.000
Và tôi đang hiển thị điều này ở đây dưới dạng hình ảnh thang độ xám.

00:06:31.000 --> 00:06:37.000
Bản thân dữ liệu được cung cấp dưới dạng đối tượng AVDepthData, cùng với dấu thời gian.

00:06:37.000 --> 00:06:47.000
Nhưng điều quan trọng cần lưu ý, điều này đang được chụp ở 15Hz, đây là tần số thấp hơn so với hình ảnh màu mà ARKit chụp ở 60Hz.

00:06:47.000 --> 00:06:55.000
Và cuối cùng, một tính năng có thể được sử dụng với bất kỳ phiên ARKit nào, nhưng đặc biệt thú vị với tính năng theo dõi khuôn mặt là: Ghi lại âm thanh.

00:06:55.000 --> 00:07:06.000
Bây giờ nó bị tắt theo mặc định, nhưng nếu được bật, thì trong khi ARSession của bạn đang chạy, nó sẽ thu các mẫu âm thanh từ micrô và gửi một chuỗi CMSampleBuffers đến ứng dụng của bạn.

00:07:06.000 --> 00:07:12.000
Vì vậy, điều này rất hữu ích nếu bạn muốn ghi lại khuôn mặt và giọng nói của người dùng cùng một lúc.

00:07:12.000 --> 00:07:20.000
Để biết thêm thông tin về theo dõi khuôn mặt và liên kết đến mã mẫu, vui lòng truy cập trang web Nhà phát triển của chúng tôi tại developer.apple.com/arkit.

00:07:20.000 --> 23:59:59.000
Cảm ơn bạn đã xem!

