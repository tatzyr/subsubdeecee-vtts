WEBVTT

00:00:02.000 --> 00:00:08.000
피에르 모르프: 애플 실리콘 게임의 CPU 작업 스케줄링을 조정하는 방법에 대한 세션에 오신 것을 환영합니다.

00:00:08.000 --> 00:00:12.000
저는 금속 생태계 팀에서 일하는 피에르 모르프입니다.

00:00:12.000 --> 00:00:21.000
저는 여러 타사 개발자들이 Apple 플랫폼에서 GPU와 CPU 워크로드를 최적화하도록 돕고 있습니다.

00:00:21.000 --> 00:00:31.000
CoreOS 팀의 도움으로, 저는 게임에서 더 나은 CPU 성능과 효율성을 달성하기 위해 여기에 정보와 지침을 수집했습니다.

00:00:31.000 --> 00:00:39.000
우리는 게임에 집중하고 있습니다. 왜냐하면 그들은 보통 하드웨어 자원 측면에서 매우 까다롭기 때문입니다.

00:00:39.000 --> 00:00:47.000
또한, 그들의 일반적인 워크로드는 모든 프레임에서 수천 개는 아니더라도 수백 개의 CPU 작업을 처리해야 한다.

00:00:47.000 --> 00:00:58.000
16밀리초 이내에 완료하려면, 작업은 최대 CPU 처리량에 맞게 조정되어야 하며, 제출 오버헤드를 최소화해야 합니다.

00:00:58.000 --> 00:01:05.000
먼저, 애플 실리콘 CPU와 그 독특한 아키텍처에 대한 개요를 살펴보겠습니다.

00:01:05.000 --> 00:01:13.000
그런 다음, CPU 효율성을 극대화하기 위해 작업을 구성하는 방법에 대한 기본적인 지침을 제공하겠습니다.

00:01:13.000 --> 00:01:21.000
마지막으로, 우리는 그 지침이 구현되면 활용할 수 있는 유용한 API에 대해 논의할 것이다.

00:01:21.000 --> 00:01:25.000
애플 CPU 아키텍처를 시작합시다.

00:01:25.000 --> 00:01:29.000
애플은 10년 넘게 자체 칩을 설계해 왔다.

00:01:29.000 --> 00:01:32.000
그들은 애플 장치의 핵심에 있다.

00:01:32.000 --> 00:01:37.000
애플 실리콘은 고성능과 타의 추종을 불허하는 효율성을 제공한다.

00:01:37.000 --> 00:01:40.000
작년에, 애플은 M1 칩을 선보였다.

00:01:40.000 --> 00:01:44.000
그것은 Mac 컴퓨터에서 사용할 수 있게 된 최초의 애플 실리콘 칩이었다.

00:01:44.000 --> 00:01:47.000
그리고 올해는...

00:01:47.000 --> 00:01:50.000
...우리는 M1 Pro와 M1 Max를 소개했습니다.

00:01:50.000 --> 00:01:59.000
그들의 새로운 디자인은 애플 실리콘의 큰 도약이며 매우 까다로운 작업량을 효율적으로 처리할 수 있게 해준다.

00:01:59.000 --> 00:02:06.000
M1 칩은 단일 패키지에 많은 구성 요소를 모은다.

00:02:06.000 --> 00:02:12.000
그것은 CPU, GPU, 신경 엔진 등을 포함한다.

00:02:12.000 --> 00:02:21.000
그것은 또한 고대역폭, 저지연 통합 메모리를 가지고 있다; 그것은 애플 패브릭을 통해 모든 칩의 구성 요소에 접근할 수 있다.

00:02:21.000 --> 00:02:27.000
그것은 CPU와 GPU가 복사하지 않고 동일한 데이터에서 작동할 수 있다는 것을 의미합니다.

00:02:27.000 --> 00:02:31.000
CPU를 확대해 봅시다.

00:02:31.000 --> 00:02:40.000
M1에서, CPU는 두 가지 유형의 코어를 포함한다: 성능 코어와 효율 코어.

00:02:40.000 --> 00:02:45.000
그것들은 물리적으로 다르며, E 코어는 더 작다.

00:02:45.000 --> 00:02:52.000
효율 코어는 매우 낮은 에너지 소비로 작업을 처리하기 위한 것이다.

00:02:52.000 --> 00:03:02.000
매우 중요한 요점이 있다: P와 E 코어는 비슷한 마이크로아키텍처를 사용하며, 이는 실제로 그들의 내부 작업이다.

00:03:02.000 --> 00:03:09.000
그것들은 개발자들이 스레드가 P 또는 E 코어에서 실행되는지 신경 쓸 필요가 없도록 설계되었습니다.

00:03:09.000 --> 00:03:18.000
프로그램이 일종의 코어에서 잘 수행되도록 최적화되어 있다면, 다른 쪽에서는 잘 수행될 것으로 예상된다.

00:03:18.000 --> 00:03:25.000
그 코어들은 적어도 그들의 유형에 따라 물리적으로 클러스터로 그룹화된다.

00:03:25.000 --> 00:03:32.000
M1에서, 각 클러스터는 모든 코어에서 공유하는 마지막 수준의 캐시인 L2를 가지고 있다.

00:03:32.000 --> 00:03:36.000
크로스 클러스터 통신은 애플 패브릭을 통해 진행된다.

00:03:36.000 --> 00:03:42.000
여기에 표시된 CPU 토폴로지는 M1 칩에만 해당됩니다.

00:03:42.000 --> 00:03:44.000
다른 장치는 다른 CPU 레이아웃을 가질 수 있다.

00:03:44.000 --> 00:03:54.000
예를 들어, iPhone XS에는 두 개의 P 코어로 구성된 하나의 클러스터와 네 개의 E 코어로 구성된 하나의 클러스터가 있다.

00:03:54.000 --> 00:04:06.000
이 아키텍처를 통해 시스템은 필요할 때 성능을 최적화하거나 대신 효율성을 최적화하여 성능이 우선 순위가 아닐 때 배터리 수명을 향상시킬 수 있습니다.

00:04:06.000 --> 00:04:20.000
각 클러스터는 현재 작업량, 해당 클러스터의 현재 열압 및 기타 요인에 따라 커널의 스케줄러에 의해 독립적으로 활성화되거나 주파수를 조정할 수 있습니다.

00:04:20.000 --> 00:04:25.000
마지막으로, P 코어의 가용성은 보장되지 않는다는 점에 유의하십시오.

00:04:25.000 --> 00:04:32.000
그 시스템은 중요한 열 시나리오에서 그것들을 사용할 수 없게 만들 권리가 있다.

00:04:32.000 --> 00:04:38.000
다음은 CPU와 상호 작용하는 다양한 API 계층에 대한 개요입니다.

00:04:38.000 --> 00:04:44.000
먼저 우리는 macOS와 iOS를 실행하는 커널인 XNU가 있습니다.

00:04:44.000 --> 00:04:50.000
그곳은 스케줄러가 사는 곳이며, CPU에서 무엇이 언제 실행되는지 결정한다.

00:04:50.000 --> 00:04:57.000
그 위에, 우리는 두 개의 라이브러리가 있다: pthreads와 Mach 객체가 있는 POSIX.

00:04:57.000 --> 00:05:03.000
그들은 둘 다 애플리케이션에 기본적인 스레딩과 동기화 프리미티브를 제공한다.

00:05:03.000 --> 00:05:07.000
게다가 우리는 더 높은 수준의 도서관을 가지고 있다.

00:05:07.000 --> 00:05:11.000
스레드 관련 NSObjects는 POSIX 핸들을 캡슐화한다.

00:05:11.000 --> 00:05:21.000
예를 들어, NSLock은 pthread_mutex_lock을 캡슐화하고, NSThread는 무엇보다도 pthread를 캡슐화한다.

00:05:21.000 --> 00:05:24.000
그곳은 또한 GCD가 앉아 있는 곳이다.

00:05:24.000 --> 00:05:26.000
GCD는 고급 직업 관리자이다.

00:05:26.000 --> 00:05:28.000
우리는 나중에 그것을 다룰 것이다.

00:05:28.000 --> 00:05:36.000
이 세션에서, 우리는 낮은 수준에서 시작하여 API 기능으로 마무리할 것입니다.

00:05:36.000 --> 00:05:44.000
CPU에 가장 적합한 것과 스케줄러의 작업량을 덜어놓는 방법에 초점을 맞추는 것으로 시작합시다.

00:05:44.000 --> 00:05:48.000
이것은 우리의 근본적인 효율성 지침이 될 것이다.

00:05:48.000 --> 00:06:01.000
그들은 모든 직무 관리자 구현에 적용되고, API에 구애받지 않으며, 애플 실리콘과 인텔 기반 맥을 포함한 많은 플랫폼에 적용된다.

00:06:01.000 --> 00:06:06.000
우리가 이상적인 세상에 있고 이 직업을 가지고 있다고 상상해 봅시다.

00:06:06.000 --> 00:06:14.000
우리가 그것을 네 개의 코어에 퍼뜨린다면, 정확히 네 배 더 빨리 처리되어야 합니다, 그렇죠?

00:06:14.000 --> 00:06:18.000
불행히도, 그것은 실제 CPU에서 그렇게 간단하지 않다.

00:06:18.000 --> 00:06:24.000
많은 부기 작업이 진행되고 있으며, 각각 실행 시간이 소요된다.

00:06:24.000 --> 00:06:29.000
효율성을 위해 명심해야 할 세 가지 비용이 있어야 한다.

00:06:29.000 --> 00:06:32.000
코어 1, 2, 3을 보세요.

00:06:32.000 --> 00:06:35.000
그들은 우리 일을 처리하기 전에 아무것도 하지 않았다.

00:06:35.000 --> 00:06:43.000
음, CPU 코어가 꽤 오랫동안 할 일이 없을 때, 그것은 에너지를 절약하기 위해 유휴 상태가 된다.

00:06:43.000 --> 00:06:48.000
그리고 유휴 코어를 다시 활성화하는 데는 약간의 시간이 걸린다.

00:06:48.000 --> 00:06:53.000
그것이 우리의 첫 번째 비용, 핵심 기상 비용이다.

00:06:53.000 --> 00:06:55.000
여기 또 하나 있어.

00:06:55.000 --> 00:06:59.000
CPU 작업은 먼저 OS 스케줄러에 의해 시작됩니다.

00:06:59.000 --> 00:07:03.000
그것은 어떤 프로세스와 스레드가 다음에 실행되어야 하는지, 그리고 어떤 코어에서 실행되어야 하는지를 결정한다.

00:07:03.000 --> 00:07:08.000
그런 다음 CPU 코어는 실행 컨텍스트로 전환됩니다.

00:07:08.000 --> 00:07:11.000
우리는 그것을 일정 비용이라고 부를 것이다.

00:07:11.000 --> 00:07:15.000
이제, 세 번째이자 마지막 유형의 비용.

00:07:15.000 --> 00:07:22.000
코어 0에서 실행되는 스레드가 코어 1, 2, 3의 신호를 나타내는 것을 고려해 봅시다.

00:07:22.000 --> 00:07:26.000
예를 들어, 세마포로.

00:07:26.000 --> 00:07:28.000
그 신호는 즉각적이지 않다.

00:07:28.000 --> 00:07:40.000
이 간격 동안, 커널은 어떤 스레드가 프리미티브에서 기다리고 있는지 식별해야 하며, 스레드가 활성화되지 않은 경우, 그것을 예약해야 합니다.

00:07:40.000 --> 00:07:44.000
이 지연은 동기화 지연이라고 불린다.

00:07:44.000 --> 00:07:50.000
이러한 비용은 대부분의 CPU 아키텍처에서 어떤 형태로든 나타난다.

00:07:50.000 --> 00:07:54.000
그것들은 매우, 매우 짧기 때문에, 그 자체로 문제가 되지 않는다.

00:07:54.000 --> 00:08:01.000
하지만 그들이 누적되면 공연 히트가 될 수 있으며, 반복적이고 자주 나타날 수 있다.

00:08:01.000 --> 00:08:06.000
그 비용은 실생활에서 어떻게 생겼나요?

00:08:06.000 --> 00:08:10.000
이것은 M1에서 실행되는 게임의 악기 흔적이다.

00:08:10.000 --> 00:08:15.000
그 게임은 대부분의 프레임을 반복하는 문제가 있는 패턴을 보여준다.

00:08:15.000 --> 00:08:20.000
그것은 매우 미세한 세분화로 작업을 병렬화하려고 한다.

00:08:20.000 --> 00:08:24.000
우리는 이미 타임라인을 많이 확대했다.

00:08:24.000 --> 00:08:30.000
당신에게 아이디어를 주기 위해, 그 섹션은 18마이크로초밖에 걸리지 않습니다.

00:08:30.000 --> 00:08:34.000
그 CPU 코어와 그 두 스레드에 집중합시다.

00:08:34.000 --> 00:08:41.000
그 두 스레드는 병렬로 실행될 수 있었지만, 결국 같은 코어에서 연속적으로 실행되었다.

00:08:41.000 --> 00:08:43.000
왜 그런지 보자.

00:08:43.000 --> 00:08:47.000
그들은 서로 매우 자주 동기화한다.

00:08:47.000 --> 00:08:56.000
첫 번째는 두 번째가 시작하도록 신호를 보내고 동료가 끝날 때까지 매우 빠르게 기다린다.

00:08:56.000 --> 00:09:03.000
두 번째는 작동하기 시작하고, 첫 번째 것에 빠르게 신호를 보내고, 곧 기다린다.

00:09:03.000 --> 00:09:07.000
이 패턴은 계속해서 반복된다.

00:09:07.000 --> 00:09:15.000
우리는 여기서 두 가지 문제를 볼 수 있습니다: 첫째, 동기화 프리미티브는 매우 높은 주파수에서 사용됩니다.

00:09:15.000 --> 00:09:19.000
그것은 일을 방해하고 오버헤드를 도입한다.

00:09:19.000 --> 00:09:22.000
우리는 빨간색 섹션으로 오버헤드를 볼 수 있다.

00:09:22.000 --> 00:09:27.000
둘째, 활발한 작업인 파란색 섹션은 매우 짧다.

00:09:27.000 --> 00:09:32.000
그것은 4초에서 20마이크로초 사이에만 지속된다.

00:09:32.000 --> 00:09:40.000
이 지속 시간은 너무 작아서 CPU 코어를 깨우는 데 걸리는 시간보다 거의 짧다.

00:09:40.000 --> 00:09:47.000
그 빨간색 섹션 동안, OS 스케줄러는 대부분 CPU 코어가 깨어나기를 기다리고 있었다.

00:09:47.000 --> 00:09:52.000
하지만 그 일이 일어나기 직전에, 스레드는 코어를 차단하고 해방시킨다.

00:09:52.000 --> 00:10:00.000
두 번째 스레드는 다른 스레드가 깨어나기를 조금 더 기다리는 대신 같은 코어에서 실행됩니다.

00:10:00.000 --> 00:10:05.000
그것이 그 두 스레드가 병렬로 실행할 수 있는 작은 기회를 잃어버린 방법이다.

00:10:05.000 --> 00:10:10.000
이 관찰에서, 우리는 이미 두 가지 지침을 정의할 수 있다.

00:10:10.000 --> 00:10:13.000
먼저, 올바른 작업 세분성을 선택하세요.

00:10:13.000 --> 00:10:19.000
우리는 작은 일자리를 더 큰 일자리로 병합함으로써 그것을 달성할 수 있다.

00:10:19.000 --> 00:10:24.000
스레드를 예약하는 것은 무슨 일이 있어도 약간의 시간이 걸린다.

00:10:24.000 --> 00:10:30.000
작업이 작아지면, 일정 비용은 스레드 타임라인의 상대적으로 더 큰 부분을 차지할 것이다.

00:10:30.000 --> 00:10:34.000
CPU는 충분히 활용되지 않을 것이다.

00:10:34.000 --> 00:10:39.000
반대로, 더 큰 일자리는 더 오래 운영함으로써 스케줄링 비용을 상각한다.

00:10:39.000 --> 00:10:51.000
우리는 30마이크로초의 작업 항목을 많이 제출하는 전문 지원서를 보았습니다. 그들이 병합했을 때 성능이 크게 향상되었습니다.

00:10:51.000 --> 00:10:56.000
둘째, 스레드를 활용하기 전에 충분한 작업을 정렬하세요.

00:10:56.000 --> 00:11:02.000
이것은 대부분의 작업을 한 번에 준비함으로써 모든 프레임에서 수행될 수 있다.

00:11:02.000 --> 00:11:12.000
신호를 보내고 스레드를 기다릴 때, 그것은 일반적으로 일부는 CPU 코어에 예약되고 일부는 차단되고 코어에서 이동된다는 것을 의미합니다.

00:11:12.000 --> 00:11:16.000
그것을 여러 번 하는 것은 성과의 함정이다.

00:11:16.000 --> 00:11:21.000
실을 깨우고 멈추는 것은 우리가 방금 이야기한 더 많은 비용을 반복적으로 증가시킨다.

00:11:21.000 --> 00:11:30.000
반대로, 스레드가 중단 없이 더 많은 작업을 처리하도록 하면 동기화 지점이 제거됩니다.

00:11:30.000 --> 00:11:40.000
예를 들어, 중첩된 for-loops를 다룰 때, 더 거친 입도에서 외부를 병렬화하는 것이 훨씬 더 좋은 생각이다.

00:11:40.000 --> 00:11:43.000
그것은 내부 루프를 방해받지 않게 한다.

00:11:43.000 --> 00:11:53.000
그것은 그들에게 더 나은 일관성, 더 나은 캐시 활용, 그리고 전반적으로 더 적은 동기화 지점을 제공한다.

00:11:53.000 --> 00:11:58.000
더 많은 스레드를 활용하기 전에, 그것이 비용의 가치가 있는지 결정하세요.

00:11:58.000 --> 00:12:02.000
이제 다른 게임 흔적을 살펴봅시다.

00:12:02.000 --> 00:12:05.000
그것은 아이폰 XS에서 실행되고 있었다.

00:12:05.000 --> 00:12:09.000
우리는 그 도우미 스레드에 집중할 것이다.

00:12:09.000 --> 00:12:13.000
우리는 여기서 동기화 대기 시간을 볼 수 있다.

00:12:13.000 --> 00:12:19.000
이것은 커널이 다른 도우미들에게 신호를 보내는 데 걸린 시간이다.

00:12:19.000 --> 00:12:32.000
여기에는 두 가지 문제가 있습니다: 첫째, 실제 작업은 다시 매우 작습니다 - 약 11마이크로초 - 특히 전체 오버헤드와 비교할 때.

00:12:32.000 --> 00:12:37.000
그 일들을 함께 병합하는 것이 더 에너지 효율적이었을 것이다.

00:12:37.000 --> 00:12:45.000
두 번째 문제: 그 기간 동안, 80개의 다른 스레드가 세 개의 코어에 예정되어 있었다.

00:12:45.000 --> 00:12:50.000
우리는 여기서 진행 중인 작업 사이의 작은 격차인 컨텍스트 스위치를 볼 수 있다.

00:12:50.000 --> 00:13:01.000
이 예에서는 아직 문제가 되지 않지만, 스레드가 더 많으면 컨텍스트 전환 시간이 축적되어 CPU 성능을 방해할 수 있습니다.

00:13:01.000 --> 00:13:10.000
일반적인 게임이 프레임마다 적어도 수백 개의 작업을 가지고 있을 때 어떻게 모든 종류의 오버헤드를 최소화할 수 있을까요?

00:13:10.000 --> 00:13:14.000
그렇게 하는 가장 좋은 방법은 작업 풀을 사용하는 것이다.

00:13:14.000 --> 00:13:19.000
노동자 실은 직업 도둑질을 통해 그것들을 소비한다.

00:13:19.000 --> 00:13:24.000
스레드 예약은 커널에 의해 수행된다; 우리는 시간이 좀 걸리는 것을 보았다.

00:13:24.000 --> 00:13:28.000
그리고 CPU는 또한 컨텍스트 전환과 같은 몇 가지 작업을 해야 한다.

00:13:28.000 --> 00:13:33.000
반면에, 사용자 공간에서 새로운 일을 시작하는 것은 훨씬 저렴하다.

00:13:33.000 --> 00:13:40.000
일반적으로, 노동자는 원자 카운터를 줄이고, 직업에 대한 포인터를 잡아야 한다.

00:13:40.000 --> 00:13:49.000
두 번째 요점: 작업자를 사용하면 컨텍스트 스위치의 양을 줄일 수 있기 때문에 미리 정해진 스레드와의 상호 작용을 피하십시오.

00:13:49.000 --> 00:13:57.000
그리고 그들이 더 많은 일자리를 잡음에 따라, 당신은 이미 활성화된 코어에서 이미 활성화된 스레드를 활용합니다.

00:13:57.000 --> 00:14:00.000
마지막으로, 수영장을 현명하게 사용하세요.

00:14:00.000 --> 00:14:04.000
줄을 서 있는 일을 위해 충분한 노동자들을 깨워.

00:14:04.000 --> 00:14:16.000
그리고 이전 규칙은 여기에도 적용됩니다: 작업자 스레드를 깨우고 바쁘게 유지하는 것을 정당화하기 위해 충분한 작업이 정렬되어 있는지 확인하십시오.

00:14:16.000 --> 00:14:22.000
우리는 오버헤드를 줄였다; 이제, 우리는 CPU 사이클을 최대한 활용해야 한다.

00:14:22.000 --> 00:14:26.000
여기 피해야 할 몇 가지 패턴이 있습니다.

00:14:26.000 --> 00:14:27.000
바쁜 기다림을 피하세요.

00:14:27.000 --> 00:14:32.000
그들은 잠재적으로 유용한 일을 하는 대신 P 코어를 잠글 수 있다.

00:14:32.000 --> 00:14:39.000
그들은 또한 스케줄러가 스레드를 E에서 P 코어로 홍보하는 것을 방지한다.

00:14:39.000 --> 00:14:48.000
당신은 또한 에너지를 낭비하고 불필요한 열을 생산하여 열 헤드룸을 갉아먹고 있습니다.

00:14:48.000 --> 00:14:54.000
둘째, 수율 기능의 정의는 플랫폼과 심지어 OS에서도 느슨하다.

00:14:54.000 --> 00:15:04.000
애플 플랫폼에서, 그것은 "내가 실행하고 있는 핵심을 시스템의 다른 스레드, 다른 모든 것, 그들의 우선순위가 무엇이든 간에 양도하려고 시도하라"는 것을 의미한다.

00:15:04.000 --> 00:15:08.000
그것은 효과적으로 현재 스레드 우선 순위를 0으로 둔다.

00:15:08.000 --> 00:15:11.000
수율은 또한 시스템 정의 기간을 가지고 있다.

00:15:11.000 --> 00:15:16.000
그것은 매우 길 수 있다 - 최대 10밀리초까지.

00:15:16.000 --> 00:15:20.000
셋째, 수면 요청도 낙담한다.

00:15:20.000 --> 00:15:24.000
특정 이벤트를 기다리는 것이 훨씬 더 효율적이다.

00:15:24.000 --> 00:15:31.000
또한, 애플 플랫폼에서, 수면(0)은 의미가 없으며 그 전화는 심지어 폐기됩니다.

00:15:31.000 --> 00:15:38.000
이러한 패턴은 일반적으로 근본적인 스케줄링 오류가 처음에 발생했다는 신호이다.

00:15:38.000 --> 00:15:45.000
대신, 세마포어나 조건부 변수로 명시적인 신호를 기다리세요.

00:15:45.000 --> 00:15:51.000
최종 지침: CPU 코어 수와 일치하도록 스레드 수를 조정하십시오.

00:15:51.000 --> 00:15:57.000
사용 중인 각 프레임워크나 미들웨어에서 새로운 스레드 풀을 다시 만들지 마세요.

00:15:57.000 --> 00:16:01.000
작업량에 따라 스레드 수를 확장하지 마세요.

00:16:01.000 --> 00:16:06.000
당신의 작업량이 극적으로 증가한다면, 당신의 스레드도 계산될 것입니다.

00:16:06.000 --> 00:16:16.000
대신, CPU 정보를 쿼리하여 스레드 풀의 크기를 적절하게 조정하고 현재 시스템의 병렬화 기회를 극대화하십시오.

00:16:16.000 --> 00:16:20.000
이 정보를 조회하는 방법을 봅시다.

00:16:20.000 --> 00:16:29.000
macOS Monterey와 iOS 15부터 sysctl 인터페이스로 CPU 레이아웃에 대한 고급 세부 사항을 쿼리할 수 있습니다.

00:16:29.000 --> 00:16:40.000
모든 CPU 코어의 전체 수를 얻는 것 외에도, 이제 nperflevels로 기계가 얼마나 많은 유형의 코어를 가지고 있는지 쿼리할 수 있습니다.

00:16:40.000 --> 00:16:44.000
M1에는 두 가지 유형의 코어가 있습니다: P와 E.

00:16:44.000 --> 00:16:51.000
이 범위를 사용하여 코어 유형별 데이터를 쿼리하세요, 0이 가장 성능이 큽니다.

00:16:51.000 --> 00:17:00.000
예를 들어, perflevel{N}.logicalcpu는 현재 CPU가 얼마나 많은 P 코어를 가지고 있는지 알려줍니다.

00:17:00.000 --> 00:17:02.000
이건 그냥 개요일 뿐이야.

00:17:02.000 --> 00:17:08.000
또한 얼마나 많은 코어가 동일한 L2를 공유하는지와 같은 다른 많은 세부 사항을 쿼리할 수 있습니다.

00:17:08.000 --> 00:17:16.000
자세한 내용은 sysctl 매뉴얼 페이지 또는 문서 웹 페이지를 참조하십시오.

00:17:16.000 --> 00:17:21.000
CPU 사용량을 프로파일링할 때, 두 개의 악기 트랙은 매우 유용합니다.

00:17:21.000 --> 00:17:25.000
그것들은 게임 성능 템플릿에서 사용할 수 있습니다.

00:17:25.000 --> 00:17:32.000
첫 번째, 시스템 로드는 CPU 코어당 활성 스레드 수를 제공합니다.

00:17:32.000 --> 00:17:36.000
두 번째는 스레드 상태 추적이다.

00:17:36.000 --> 00:17:44.000
기본적으로 세부 정보 창은 스레드 상태 변경의 양과 프로세스당 기간을 보여줍니다.

00:17:44.000 --> 00:17:49.000
컨텍스트 스위치 보기로 변경할 수 있습니다.

00:17:49.000 --> 00:17:55.000
이것은 선택한 시간 범위에서 프로세스당 컨텍스트 스위치의 수를 제공합니다.

00:17:55.000 --> 00:18:03.000
컨텍스트 스위치 수는 앱의 스케줄링 효율성을 측정하는 데 유용한 지표이다.

00:18:03.000 --> 00:18:06.000
이 섹션을 마무리합시다.

00:18:06.000 --> 00:18:14.000
이러한 지침을 따르면, CPU를 최대한 활용하고 스케줄러가 해야 할 일을 간소화할 수 있습니다.

00:18:14.000 --> 00:18:25.000
작고 작은 작업을 더 오래 실행되는 작업으로 압축하면 캐시, 프리페처 및 예측 변수와 같은 마이크로 아키텍처 기능의 이점이 증가합니다.

00:18:25.000 --> 00:18:31.000
한 번에 더 많은 작업을 처리하는 것은 인터럽트 지연과 컨텍스트 스위치를 줄이는 것을 의미합니다.

00:18:31.000 --> 00:18:39.000
적절하게 확장된 스레드 풀은 스케줄러가 E와 P 코어 간의 작업을 쉽게 재조정할 수 있게 해준다.

00:18:39.000 --> 00:18:49.000
효율성과 성능의 핵심 테이크아웃은 작업량이 넓고 좁아지는 빈도를 최소화하는 것입니다.

00:18:49.000 --> 00:18:55.000
이제 그 지침을 적용하는 동안 활용할 수 있는 API 블록에 대해 알아봅시다.

00:18:55.000 --> 00:19:08.000
이 섹션에서는 멀티스레딩 시 우선 순위 지정 및 스케줄링 정책, 동기화 프리미티브 및 메모리 고려 사항을 다룰 것입니다.

00:19:08.000 --> 00:19:13.000
하지만 먼저, GCD를 살짝 엿보는 것으로 시작합시다.

00:19:13.000 --> 00:19:23.000
직업 관리자가 없거나, 당신이 목표로 하는 높은 성과에 도달하지 못한다면, GCD는 환상적인 선택입니다.

00:19:23.000 --> 00:19:28.000
그것은 직업 도둑질을 사용하는 범용 직업 관리자이다.

00:19:28.000 --> 00:19:35.000
그것은 모든 애플 플랫폼과 리눅스에서 사용할 수 있으며, 오픈 소스이다.

00:19:35.000 --> 00:19:38.000
이 API는 고도로 최적화되어 있다.

00:19:38.000 --> 00:19:42.000
첫째, 그것은 이미 당신을 위한 모든 모범 사례를 따르고 있습니다.

00:19:42.000 --> 00:19:47.000
둘째, 그것은 XNU 커널에 통합되어 있다.

00:19:47.000 --> 00:20:01.000
즉, GCD는 현재 기계의 방열 용량, P/E 코어 비율, 전류 열 압력 등 내부 세부 사항을 추적할 수 있습니다.

00:20:01.000 --> 00:20:05.000
그것의 인터페이스는 직렬 및 동시 파견 대기열에 의존한다.

00:20:05.000 --> 00:20:11.000
당신은 다양한 우선순위로 일자리를 찾을 수 있습니다.

00:20:11.000 --> 00:20:18.000
내부적으로, 각 디스패치 대기열은 개인 스레드 풀에서 다양한 양의 스레드를 활용합니다.

00:20:18.000 --> 00:20:24.000
그 숫자는 대기열의 유형과 작업 속성에 따라 다르다.

00:20:24.000 --> 00:20:29.000
이 내부 스레드 풀은 전체 프로세스에 대해 공유됩니다.

00:20:29.000 --> 00:20:36.000
그것은 주어진 과정에서 여러 라이브러리가 새로운 풀을 다시 만들지 않고 GCD를 사용할 수 있다는 것을 의미한다.

00:20:36.000 --> 00:20:39.000
GCD는 많은 기능을 제공한다.

00:20:39.000 --> 00:20:47.000
여기서 우리는 그것이 어떻게 작동하는지 이해하기 위해 동시 디스패치 대기열에서 두 가지 기능만 빠르게 검토할 것입니다.

00:20:47.000 --> 00:20:55.000
첫 번째인 dispatch_async를 사용하면 함수 포인터와 데이터 포인터로 구성된 작업을 대기열에 묶을 수 있습니다.

00:20:55.000 --> 00:21:04.000
작업을 시작할 때, 다음 작업도 처리할 준비가 되면 동시 대기열이 추가 스레드를 활용할 수 있습니다.

00:21:04.000 --> 00:21:09.000
그것은 전형적인 비동기 독립 작업을 위한 훌륭한 옵션이다.

00:21:09.000 --> 00:21:13.000
하지만 대규모 병렬 문제에 대해서는 그렇게 많지 않다.

00:21:13.000 --> 00:21:18.000
그 경우, dispatch_apply가 있다.

00:21:18.000 --> 00:21:25.000
그것은 GCD의 스레드 관리자를 과부하하지 않고 처음부터 많은 스레드를 활용할 것이다.

00:21:25.000 --> 00:21:36.000
우리는 여러 프로 앱이 dispatch_apply를 사용하기 위해 병렬로 마이그레이션하여 성능을 향상시키는 것을 보았습니다.

00:21:36.000 --> 00:21:39.000
그것은 GCD에 대한 간략한 개요였다.

00:21:39.000 --> 00:21:49.000
그것에 대해 더 알아보고 어떤 패턴을 피해야 할지 알아보려면, 그 두 개의 WWDC 세션을 참조하십시오.

00:21:49.000 --> 00:21:53.000
이제 맞춤형 작업 관리자로 전환합시다.

00:21:53.000 --> 00:22:00.000
우리는 스레드를 직접 조작하고 동기화할 때 가장 중요한 점을 다룰 것입니다.

00:22:00.000 --> 00:22:03.000
우선순위 지정부터 시작합시다.

00:22:03.000 --> 00:22:10.000
이전 섹션에서, 우리는 작업을 제출할 때 CPU 효율성을 높이는 방법을 검토했습니다.

00:22:10.000 --> 00:22:16.000
하지만 지금까지, 우리는 모든 직업이 평등하지 않다는 것을 언급하지 않았다.

00:22:16.000 --> 00:22:21.000
몇몇은 시간이 중요하며, 그들의 결과는 가능한 한 빨리 필요하다.

00:22:21.000 --> 00:22:25.000
그리고 다른 것들은 다음 한두 프레임에서만 필요할 것이다.

00:22:25.000 --> 00:22:36.000
따라서 더 중요한 일에 더 많은 자원을 제공하기 위해 작업을 처리할 때 중요성을 전달할 필요가 있습니다.

00:22:36.000 --> 00:22:40.000
그것은 당신의 스레드의 우선순위를 정함으로써 이루어질 수 있습니다.

00:22:40.000 --> 00:22:48.000
올바른 스레드 우선 순위를 설정하면 시스템이 배경 활동보다 게임이 더 중요하다는 것을 알 수 있습니다.

00:22:48.000 --> 00:22:57.000
이것은 원시 CPU 우선 순위 값이나 QoS 클래스로 스레드를 설정하여 달성할 수 있습니다.

00:22:57.000 --> 00:23:02.000
두 개념 모두 관련이 있지만, 약간 다르다.

00:23:02.000 --> 00:23:09.000
원시 CPU 우선 순위는 계산 처리량이 얼마나 중요한지 알려주는 정수 값이다.

00:23:09.000 --> 00:23:17.000
애플 플랫폼에서, 리눅스와는 달리, 이것은 오름차순이다 - 높을수록 더 중요하다.

00:23:17.000 --> 00:23:27.000
이 CPU 우선 순위는 또한 스레드가 P 또는 E 코어에서 실행되어야 하는지 여부를 암시한다.

00:23:27.000 --> 00:23:37.000
이제, 이 CPU 우선 순위는 스레드가 무엇을 하고 있는지에 대한 의도를 주지 않기 때문에 나머지 시스템 리소스에 영향을 미치지 않습니다.

00:23:37.000 --> 00:23:45.000
대신 스레드는 서비스 품질로 우선 순위를 지정할 수 있습니다 - 줄여서 QoS.

00:23:45.000 --> 00:23:49.000
QoS는 스레드에 의미를 연결하도록 설계되었다.

00:23:49.000 --> 00:23:59.000
이 의도는 스케줄러가 언제 작업을 실행할지에 대한 지능적인 결정을 내리는 데 크게 도움이 되며, OS를 더 빠르게 만든다.

00:23:59.000 --> 00:24:06.000
예를 들어, 덜 중요한 작업은 에너지를 절약하기 위해 시간이 지남에 따라 약간 연기될 수 있다.

00:24:06.000 --> 00:24:13.000
또한 네트워크, 디스크 액세스와 같은 시스템 리소스 액세스의 우선 순위를 지정할 수 있습니다.

00:24:13.000 --> 00:24:19.000
그것은 또한 에너지 절약 기능인 타이머 통합을 위한 임계값을 제공한다.

00:24:19.000 --> 00:24:25.000
QoS 클래스는 또한 CPU 우선 순위를 포함한다.

00:24:25.000 --> 00:24:36.000
가장 중요하지 않은 QOS_CLASS_BACKGROUND에서 가장 중요한 QOS_CLASS_USER_INTERACTIVE까지 다섯 가지 QoS 클래스가 있습니다.

00:24:36.000 --> 00:24:40.000
각각은 기본 CPU 우선 순위를 포함한다.

00:24:40.000 --> 00:24:46.000
선택적으로, 제한된 범위 내에서 약간 다운그레이드할 수 있습니다.

00:24:46.000 --> 00:24:54.000
이것은 동일한 QoS 클래스를 선택하는 여러 스레드의 CPU 우선 순위를 미세하게 조정하려는 경우에 유용합니다.

00:24:54.000 --> 00:25:03.000
백그라운드 클래스에 매우 주의하세요 - 그것을 사용하는 스레드는 매우 오랫동안 전혀 실행되지 않을 수 있습니다.

00:25:03.000 --> 00:25:10.000
그래서 전반적으로, 게임은 5에서 47에 이르는 CPU 우선 순위를 사용한다.

00:25:10.000 --> 00:25:16.000
그게 실제로 어떻게 되는지 보자.

00:25:16.000 --> 00:25:23.000
먼저, 기본값으로 pthread 속성을 할당하고 초기화해야 합니다.

00:25:23.000 --> 00:25:32.000
그런 다음 필요한 QoS 클래스를 설정한 다음 해당 속성을 pthread_create 함수에 전달합니다.

00:25:32.000 --> 00:25:36.000
속성 구조를 파괴하여 끝내세요.

00:25:36.000 --> 00:25:40.000
QoS 클래스를 이미 존재하는 스레드로 설정할 수도 있습니다.

00:25:40.000 --> 00:25:45.000
예를 들어, 그 함수는 호출 스레드에 영향을 미친다.

00:25:45.000 --> 00:25:54.000
참고로, 우리는 -5의 오프셋을 사용하여 클래스 CPU 우선 순위를 47에서 42로 다운그레이드했습니다.

00:25:54.000 --> 00:25:57.000
함수 이름에서 np 접미사를 볼 수 있습니다.

00:25:57.000 --> 00:26:05.000
그것은 "비휴대용"의 약자이다; 그것은 애플 플랫폼 전용 기능에 사용되는 명명 규칙이다.

00:26:05.000 --> 00:26:17.000
마지막으로, 이러한 기능을 사용하는 대신 원시 CPU 우선 순위 값을 직접 설정하면 해당 스레드에 대한 QoS를 선택 해제할 수 있습니다.

00:26:17.000 --> 00:26:25.000
그것은 영구적이며, 나중에 그 스레드에 대한 QoS를 다시 선택할 수 없습니다.

00:26:25.000 --> 00:26:32.000
iOS와 macOS는 사용자 대면 또는 백그라운드에서 실행되는 많은 프로세스를 처리합니다.

00:26:32.000 --> 00:26:36.000
어떤 경우에는 시스템이 과부하가 걸릴 수 있다.

00:26:36.000 --> 00:26:44.000
그런 일이 발생하면, 커널은 모든 스레드가 어느 시점에서 실행될 수 있도록 하는 방법이 필요하다.

00:26:44.000 --> 00:26:47.000
그것은 우선적인 부패로 이루어진다.

00:26:47.000 --> 00:26:58.000
이 특별한 경우, 커널은 시간이 지남에 따라 스레드 우선 순위를 천천히 낮춘다; 모든 스레드는 실행할 기회가 있다.

00:26:58.000 --> 00:27:03.000
우선 순위 붕괴는 매우 특별한 경우에 문제가 될 수 있다.

00:27:03.000 --> 00:27:09.000
일반적으로, 게임은 메인 스레드와 렌더링 스레드와 같은 몇 가지 매우 중요한 스레드를 가지고 있다.

00:27:09.000 --> 00:27:16.000
렌더링 스레드가 선점되면, 프레젠테이션 창을 놓칠 수 있으며, 게임이 더듬거릴 것입니다.

00:27:16.000 --> 00:27:22.000
그러한 경우, 당신은 스케줄링 정책으로 우선 순위 감소를 거부할 수 있습니다.

00:27:22.000 --> 00:27:29.000
기본적으로, SCHED_OTHER 정책으로 생성된 스레드.

00:27:29.000 --> 00:27:31.000
이것은 시분할 정책이다.

00:27:31.000 --> 00:27:36.000
그것을 사용하는 스레드는 우선 순위가 저하될 수 있다.

00:27:36.000 --> 00:27:40.000
그것은 또한 우리가 이전에 제시한 QoS 클래스와 호환된다.

00:27:40.000 --> 00:27:46.000
반면에, 우리는 선택적인 SCHED_RR 정책을 가지고 있다.

00:27:46.000 --> 00:27:49.000
RR은 "라운드 로빈"의 약자이다.

00:27:49.000 --> 00:27:55.000
그것을 선택하는 스레드는 우선 순위 감소의 영향을 받지 않는 고정된 우선 순위를 가지고 있다.

00:27:55.000 --> 00:28:00.000
그것은 실행 지연 시간에 더 나은 일관성을 제공한다.

00:28:00.000 --> 00:28:14.000
예를 들어, 전용 렌더링 스레드 또는 프레임별 작업자 스레드와 같이 일관되고 주기적이며 우선 순위가 높은 작업을 위해 독점적으로 설계되었습니다.

00:28:14.000 --> 00:28:24.000
그것을 선택하는 스레드는 매우 특정한 시간 창에서 작동해야 하며, CPU가 100% 지속적으로 바쁘지 않아야 합니다.

00:28:24.000 --> 00:28:29.000
이 정책을 사용하면 다른 스레드에서 굶주림으로 이어질 수 있습니다.

00:28:29.000 --> 00:28:38.000
마지막으로, 이 정책은 QoS 클래스와 호환되지 않습니다. 스레드는 원시 CPU 우선 순위를 사용해야 합니다.

00:28:38.000 --> 00:28:41.000
여기 게임 스레드에 권장되는 레이아웃이 있습니다.

00:28:41.000 --> 00:28:51.000
먼저, 게임 내에서 우선순위가 높은 것, 중간, 낮은 우선순위가 무엇인지, 그리고 사용자 경험에 중요한 것이 무엇인지 정의하세요.

00:28:51.000 --> 00:28:59.000
우선 순위로 작업을 나누면 시스템이 응용 프로그램의 어떤 부분이 가장 중요한지 알 수 있습니다.

00:28:59.000 --> 00:29:07.000
도구를 사용하여 게임을 프로파일링하고, 실제로 필요한 스레드에 대해서만 SCHED_RR을 선택하세요.

00:29:07.000 --> 00:29:13.000
또한, 여러 프레임을 확장하여 장기간 작업에 SCHED_RR을 사용하지 마세요.

00:29:13.000 --> 00:29:20.000
이러한 경우 QoS에 의존하여 시스템이 다른 프로세스와 성능의 균형을 맞출 수 있도록 도와주세요.

00:29:20.000 --> 00:29:29.000
QoS를 선택하는 또 다른 이유는 스레드가 GCD 또는 NSOperationQueues와 같은 Apple 프레임워크와 상호 작용할 때입니다.

00:29:29.000 --> 00:29:36.000
그 프레임워크들은 QoS 클래스를 작업 발행자에서 작업 자체로 전파하려고 한다.

00:29:36.000 --> 00:29:42.000
발행 스레드가 QoS를 포기했다면 그것은 분명히 무시된다.

00:29:42.000 --> 00:29:50.000
우선순위와 관련된 마지막 요점을 다루자: 우선순위 반전.

00:29:50.000 --> 00:29:59.000
우선 순위 반전은 우선 순위가 높은 스레드가 멈추고 우선 순위가 낮은 스레드에 의해 차단될 때 발생합니다.

00:29:59.000 --> 00:30:02.000
이것은 일반적으로 상호 배제와 함께 일어난다.

00:30:02.000 --> 00:30:07.000
두 개의 스레드가 같은 자원에 접근하려고 시도하며, 같은 자물쇠를 얻기 위해 싸운다.

00:30:07.000 --> 00:30:15.000
어떤 경우에는, 시스템은 우선 순위가 낮은 스레드를 증가시킴으로써 이 반전을 해결할 수 있다.

00:30:15.000 --> 00:30:17.000
그게 어떻게 작동하는지 보자.

00:30:17.000 --> 00:30:22.000
두 개의 스레드를 고려해 봅시다 - 여기 그들의 실행 타임라인이 있습니다.

00:30:22.000 --> 00:30:29.000
이 예에서, 파란색 스레드는 우선 순위가 낮고, 녹색 스레드는 우선 순위가 높다.

00:30:29.000 --> 00:30:37.000
중간에, 우리는 두 스레드 중 어느 것이 그 자물쇠를 소유할지 보여주는 잠금 타임라인을 가지고 있다.

00:30:37.000 --> 00:30:41.000
파란색 스레드가 실행되기 시작하고, 자물쇠를 획득한다.

00:30:41.000 --> 00:30:44.000
초록색 실도 시작된다.

00:30:44.000 --> 00:30:51.000
이 시점에서, 녹색 실은 현재 파란색 실이 소유하고 있는 자물쇠를 얻으려고 한다.

00:30:51.000 --> 00:30:57.000
녹색 스레드는 그 자물쇠를 다시 사용할 수 있을 때까지 막고 기다린다.

00:30:57.000 --> 00:31:04.000
이 경우, 런타임은 어떤 스레드가 그 자물쇠를 소유하고 있는지 알 수 있다.

00:31:04.000 --> 00:31:11.000
따라서, 파란색 스레드의 낮은 우선 순위를 높여 우선 순위 반전을 해결할 수 있습니다.

00:31:11.000 --> 00:31:19.000
어떤 프리미티브가 우선 순위 반전을 해결할 수 있고 어떤 프리미티브가 그렇지 않은가?

00:31:19.000 --> 00:31:30.000
알려진 단일 소유자가 있는 대칭 프리미티브는 pthread_mutex_t 또는 가장 효율적인 os_unfair_lock과 같이 그렇게 할 수 있습니다.

00:31:30.000 --> 00:31:43.000
Pthread 조건 변수나 dispatch_semaphore와 같은 비대칭 프리미티브는 런타임이 어떤 스레드가 신호를 보낼지 모르기 때문에 이 능력이 없습니다.

00:31:43.000 --> 00:31:53.000
동기화 프리미티브를 선택할 때 이 기능을 염두에 두고, 상호 배타적인 액세스를 위해 대칭 프리미티브를 선호하십시오.

00:31:53.000 --> 00:32:00.000
이 섹션을 마치기 위해, 기억에 대한 몇 가지 권장 사항에 대해 논의해 봅시다.

00:32:00.000 --> 00:32:07.000
Objective-C 프레임워크와 상호 작용할 때, 일부 객체는 자동 해제로 생성됩니다.

00:32:07.000 --> 00:32:16.000
그것은 그들이 목록에 추가된다는 것을 의미하며, 그래서 그들의 할당은 나중에만 일어난다.

00:32:16.000 --> 00:32:22.000
자동 해제 풀 블록은 그러한 물체가 얼마나 오래 보관될 수 있는지를 제한하는 범위이다.

00:32:22.000 --> 00:32:28.000
그것들은 당신의 앱의 최대 메모리 공간을 줄이는 데 효과적으로 도움을 줍니다.

00:32:28.000 --> 00:32:34.000
모든 스레드 진입점에 적어도 하나의 자동 해제 풀을 갖는 것이 중요하다.

00:32:34.000 --> 00:32:44.000
만약 어떤 스레드가 자동 해제된 물체를 조작한다면 - 예를 들어, 금속을 통해 - 하나 없이, 그것은 메모리 누출로 이어질 것이다.

00:32:44.000 --> 00:32:50.000
자동 해제 풀 블록은 메모리가 재활용될 때 더 잘 제어하기 위해 중첩될 수 있다.

00:32:50.000 --> 00:32:57.000
렌더링 스레드는 반복되는 프레임 렌더링 루틴 주위에 두 번째 스레드를 이상적으로 만들어야 합니다.

00:32:57.000 --> 00:33:08.000
작업자 스레드는 활성화에서 시작하여 작업자가 주차할 때 닫히고 더 많은 작업을 기다려야 합니다.

00:33:08.000 --> 00:33:10.000
예를 들어 보자.

00:33:10.000 --> 00:33:13.000
이것은 작업자 스레드 진입점이다.

00:33:13.000 --> 00:33:18.000
그것은 자동 해제 풀 블록으로 바로 시작됩니다.

00:33:18.000 --> 00:33:22.000
그런 다음 일자리가 가능할 때까지 기다린다.

00:33:22.000 --> 00:33:30.000
작업자가 활성화되면, 우리는 새로운 자동 해제 풀 블록을 추가하고, 작업을 처리할 때 그것을 유지합니다.

00:33:30.000 --> 00:33:36.000
스레드가 기다리고 주차하려고 할 때, 우리는 중첩된 수영장에서 나간다.

00:33:36.000 --> 00:33:40.000
결론적으로, 기억에 대한 한 가지 간단한 팁.

00:33:40.000 --> 00:33:49.000
성능을 향상시키기 위해, 여러 스레드가 동시에 같은 캐시 라인에 있는 데이터를 쓰는 것을 피하세요.

00:33:49.000 --> 00:33:52.000
그것은 "거짓 공유"로 알려져 있다.

00:33:52.000 --> 00:34:03.000
동일한 데이터 구조에서 여러 번 읽는 것은 괜찮지만, 그러한 경쟁적인 쓰기는 다른 하드웨어 캐시 사이의 캐시 라인으로 이어진다.

00:34:03.000 --> 00:34:08.000
애플 실리콘에서 캐시 라인은 128바이트 길이이다.

00:34:08.000 --> 00:34:16.000
이에 대한 한 가지 해결책은 메모리 충돌을 줄이기 위해 데이터 구조 내에 패딩을 삽입하는 것입니다.

00:34:16.000 --> 00:34:20.000
우리는 이 마지막 섹션을 끝냈다.

00:34:20.000 --> 00:34:21.000
마무리하자.

00:34:21.000 --> 00:34:31.000
우리는 먼저 애플 CPU 아키텍처에 대한 개요와 획기적인 디자인이 어떻게 그것을 훨씬 더 효율적으로 만드는지에 대한 개요를 얻었다.

00:34:31.000 --> 00:34:41.000
그런 다음, 우리는 CPU를 효율적으로 공급하고 OS 스케줄러의 부하를 줄이면서 원활하게 실행되도록 하는 방법을 알았습니다.

00:34:41.000 --> 00:34:53.000
우리는 마침내 스레드 우선 순위 지정, 스케줄링 정책, 우선 순위 반전, 메모리에 대한 팁과 같은 중요한 API 개념을 검토했습니다.

00:34:53.000 --> 00:35:03.000
작업량을 주시하기 위해 악기로 게임을 정기적으로 프로파일링하는 것을 잊지 마세요. 그래야 성능 문제를 일찍 발견할 수 있습니다.

00:35:03.000 --> 23:59:59.000
관심을 가져주셔서 감사합니다.

