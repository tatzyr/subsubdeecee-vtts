WEBVTT

00:00:00.000 --> 00:00:04.000
Jaap van Muijden: A13 Bionicのメタルエンハンスメントへようこそ。

00:00:04.000 --> 00:00:08.000
私の名前はAppleのGPUソフトウェアチームのJaap van Muijdenです。

00:00:08.000 --> 00:00:17.000
今日は、A13 BionicでAppleが設計した最新のGPUと、それを可能にする新しいMetal機能を紹介します。

00:00:17.000 --> 00:00:25.000
次に、これらの機能を使用してアプリのメモリ使用量を削減し、ランタイムのパフォーマンスを最適化する方法を紹介します。

00:00:25.000 --> 00:00:41.000
新しいA13 Bionicは、一般的なパフォーマンス、最新のアプリの進化するニーズをよりよく満たすアーキテクチャの改善、高度なMetal機能の3つの主要な分野に焦点を当てることで、Appleが設計したGPUの急速な進化を続けています。

00:00:41.000 --> 00:00:43.000
それぞれを見てみましょう。 

00:00:43.000 --> 00:00:55.000
A13 BionicのGPUは、一般的なパフォーマンスにおいてA10 Fusionのほぼ3倍高速で、A11およびA12 Bionic GPUの優れたパフォーマンス向上に基づいています。

00:00:55.000 --> 00:01:06.000
既存のアプリはA13でより速く実行され、より短い時間で各フレームを完了することができ、その結果、電力の節約とアプリの使用が延長されます。

00:01:06.000 --> 00:01:11.000
Appleが設計したGPUアーキテクチャは、最新のアプリの要求をよりよく満たすために急速に進化しました。

00:01:11.000 --> 00:01:26.000
A11以降、16ビットの浮動小数点とテクスチャリングレートが増加し、ゲームの一般的なボトルネックを緩和し、32ビットの浮動小数点演算の数値精度が向上し、高度なコンピューティングワークロードをより適切に処理しました。

00:01:26.000 --> 00:01:34.000
A12 GPUは、メモリとの間でテクスチャコンテンツをロスレス圧縮および解凍することで、メモリ帯域幅を大幅に向上させます。

00:01:34.000 --> 00:01:44.000
また、ユーザーインターフェイスをサポートするための専用ハードウェアを追加し、応答時間をさらに短縮するだけでなく、フォアグラウンドアプリへのUI要素の影響も軽減します。

00:01:44.000 --> 00:01:51.000
また、A12以降のGPUは、アプリ間でリソースをより効率的に共有することで、iPadのエクスペリエンスを向上させます。

00:01:51.000 --> 00:01:54.000
そして今、私たちはA13 GPUを持っています。

00:01:54.000 --> 00:02:08.000
A13 GPUアーキテクチャは、16ビット浮動小数点演算の速度を2倍にし、ブラックレベルをよりよく保持する小さな16ビット数のサポートを追加することで、GPU上の高ダイナミックレンジコンテンツの処理を大幅に改善します。

00:02:08.000 --> 00:02:17.000
A13 GPUはまた、レンダリングワークロードと同時に実行される独立したコンピューティング作業を大幅にサポートします。

00:02:17.000 --> 00:02:32.000
Appleが設計したGPUは、A9以降、この非同期コンピューティング機能をサポートしてきましたが、A13 GPUは、より多くのハードウェアチャネルを追加し、より締め切りに敏感なレンダリングタスクへの影響を最小限に抑えることで、次のレベルに引き上げます。

00:02:32.000 --> 00:02:43.000
A13の新しいメタル機能を説明する前に、A11とA12 GPUで導入された主要なメタル機能のいくつかを簡単に要約しましょう。

00:02:43.000 --> 00:02:45.000
A11から始めましょう。

00:02:45.000 --> 00:03:00.000
タイルシェーディング、イメージブロック、および永続的なスレッドグループメモリはすべて、Appleのタイルベースの遅延レンダリングアーキテクチャを明示的に活用し、多くの最新のレンダリング技術の帯域幅使用を最適化するために協力するように設計された機能です。

00:03:00.000 --> 00:03:12.000
ラスタライズ注文グループを使用すると、GPU上の複雑なピクセル単位のデータ構造を管理でき、カラーレート制御は、高度なレンダリングアルゴリズムでのマルチサンプルアンチエイリアスの使用を最適化します。

00:03:12.000 --> 00:03:14.000
そして今、A12に。

00:03:14.000 --> 00:03:26.000
レイヤードレンダリングにより、各レンダリングされたプリミティブターゲットは2Dテクスチャ配列のユニークなスライスをターゲットにし、マルチビューポートレンダリングでは、各プリミティブは最大16のビューポートとシザー長方形で同じことを行うことができます。

00:03:26.000 --> 00:03:40.000
ステンシルフィードバックにより、各フラグメントは高度なピクセルごとの効果に対して一意のステンシル参照値を設定できますが、ステンシルリゾル解決により、MSAAおよび非MSAAパス全体でステンシルバッファを再利用できます。

00:03:40.000 --> 00:03:52.000
また、可能な限りロスレス圧縮はデフォルトで有効になっていますが、Metalは、最適なリードバックが必要な場合に、共有ストレージモードテクスチャのインプレース圧縮と解凍を直接制御することもできます。

00:03:52.000 --> 00:03:58.000
それでは、A13 GPUをサポートする新しいApple GPUファミリー6を紹介しましょう。

00:03:58.000 --> 00:04:09.000
スパーステクスチャは、各テクスチャの最も重要な領域を追跡し、それらの領域のみをメモリにマッピングすることにより、固定メモリ予算でオープンワールドゲームのより高品質のテクスチャストリーミングを可能にします。

00:04:09.000 --> 00:04:19.000
ラスタライズレートマップは、最も重要な画像領域に高品質のラスタライズとシェーディングに焦点を当て、他の場所でレートを下げ、メモリとパフォーマンスの両方を節約します。

00:04:19.000 --> 00:04:27.000
頂点増幅は、ジオメトリを共有する階層化されたレンダリングで発生する冗長な頂点処理を排除します。

00:04:27.000 --> 00:04:38.000
GPU主導のパイプラインを使用すると、より大きく、より没入感のあるシーンを描くことができ、引数バッファティア2を使用すると、アプリはGPU主導のワークロードをこれまで以上に柔軟に実行できます。

00:04:38.000 --> 00:04:45.000
SIMDグループの指示は、シェーディング中にSIMDグループのスレッド間の共有と同期を最適化します。

00:04:45.000 --> 00:04:53.000
また、ASTC HDRは、高ダイナミックレンジのテクスチャに高品質の非可逆圧縮をもたらし、メモリと帯域幅を大幅に節約します。

00:04:53.000 --> 00:04:58.000
まばらなテクスチャから始めて、これらのそれぞれをより詳細に見てみましょう。

00:04:58.000 --> 00:05:08.000
スパーステクスチャは、A13 GPUに導入されたまったく新しい機能で、金属テクスチャのストレージとレジデンシーを細かい粒度で制御できます。

00:05:08.000 --> 00:05:11.000
まばらなテクスチャはメモリに完全には常駐していません。

00:05:11.000 --> 00:05:16.000
しかし、代わりに、スパースヒープと呼ばれる特別なメモリヒープにそれらのセクションを割り当てることができます。

00:05:16.000 --> 00:05:21.000
ここでは、データの一部がそのようなスパースヒープに割り当てられている2つのスパーステクスチャを見ることができます。

00:05:21.000 --> 00:05:27.000
1つのヒープは、多くのスパーステクスチャのストレージを提供でき、すべて事前に割り当てられた単一のメモリプールを共有します。

00:05:27.000 --> 00:05:36.000
すべてのスパーステクスチャは、テクスチャ解像度やピクセル形式に関係なく同じメモリフットプリントを持つスパースタイルと呼ばれる単位に分割されます。

00:05:36.000 --> 00:05:38.000
では、この機能の用途は何ですか?

00:05:38.000 --> 00:05:40.000
そのうちの1つはテクスチャストリーミングです。

00:05:40.000 --> 00:05:49.000
テクスチャストリーミングを使用すると、現在のビューに必要なテクスチャミップマップのみを読み込むことで、固定されたメモリフットプリントで信じられないほど大きなシーンをレンダリングできます。

00:05:49.000 --> 00:05:58.000
従来のテクスチャストリーミングでは、個々のミップマップは必要なときにロードされ、不要になったとき、またはより重要なテクスチャがメモリを必要とするときに追い出されます。

00:05:58.000 --> 00:06:04.000
テクスチャストリーミングは、伝統的にミップマップの粒度でテクスチャのレジデンシーを管理します。

00:06:04.000 --> 00:06:10.000
より高品質のミップマップが要求された場合、ミップマップピラミッドの最低レベルは常駐しますが、まだストリーミングされていません。

00:06:10.000 --> 00:06:17.000
読み込み操作が完了していないか、割り当てられたストリーミングメモリが不足しているため、まだ利用できない場合があります。

00:06:17.000 --> 00:06:24.000
利用可能な最低レベルのミップマップを持つことで、低解像度であっても、サンプリングする有効なデータが常にあることが保証されます。

00:06:24.000 --> 00:06:30.000
メタルのスパーステクスチャ機能は、このテクスチャストリーミングモデルを2つの方法で改善します。

00:06:30.000 --> 00:06:38.000
まず、スパーステクスチャは、スパーステクスチャの各領域がアクセスされる頻度を決定するために使用できるテクスチャアクセスカウンタを提供します。

00:06:38.000 --> 00:06:45.000
これにより、レンダラーがより頻繁にアクセスされる領域は、一般的に現在のビューでより表示されるため、テクスチャの読み込みに優先順位を付けることができます。

00:06:45.000 --> 00:06:51.000
第二に、居住は、ミップマップの粒度ではなく、まばらなタイルの粒度で管理できます。

00:06:51.000 --> 00:06:58.000
これにより、テクスチャメモリをさらに効率的にし、重要な場所でより目に見えるテクスチャの詳細が可能になります。

00:06:58.000 --> 00:07:05.000
スパーステクスチャを組み合わせることで、同じメモリバジェットでより目に見えるディテールをストリーミングでき、品質が向上します。

00:07:05.000 --> 00:07:09.000
では、Metalでスパーステクスチャを作成して使用する方法を見てみましょう。

00:07:09.000 --> 00:07:16.000
スパーステクスチャの使用を開始するには、まずスパースヒープを作成し、そこから1つ以上のテクスチャを割り当てます。

00:07:16.000 --> 00:07:20.000
新しいスパーステクスチャは、最初にマッピングされたスパースタイルなしで作成されます。

00:07:20.000 --> 00:07:25.000
GPUを使用してヒープからメモリマッピングを要求する必要があります。

00:07:25.000 --> 00:07:31.000
メモリは、仮想メモリページと同様に、スパースタイルと呼ばれるタイルサイズの単位でマッピングされます。

00:07:31.000 --> 00:07:36.000
同様に、不要になったときにGPUにタイルのマッピングを解除するように要求する必要があります。

00:07:36.000 --> 00:07:43.000
スパーステクスチャのサンプリングは、通常のテクスチャと同じように機能し、マッピングされていない領域のサンプリングはゼロを返します。

00:07:43.000 --> 00:07:55.000
最後に、テクスチャアクセスカウンタは、スパーステクスチャから読み戻して、各タイルがアクセスされる頻度の見積もりを取得できるため、テクスチャのタイルをマッピングするときに正確に制御し、優先順位を付けることができます。

00:07:55.000 --> 00:07:58.000
これらの各ステップをより詳細に見てみましょう。

00:07:58.000 --> 00:08:03.000
ここでは、指定されたメモリサイズでまばらなテクスチャヒープを作成するメタルコードがあります。

00:08:03.000 --> 00:08:08.000
まず、ヒープのサイズを計算し、それがまばらなタイルサイズの倍数であることを確認します。

00:08:08.000 --> 00:08:15.000
ここでは、ローカルヘルパー関数を使用して、データサイズをスパースタイルサイズの最も近い倍数に切り上げます。

00:08:15.000 --> 00:08:22.000
次に、スパースヒープ記述子を生成できます。ヒープタイプをスパースに設定し、ヒープのサイズをバイト単位で指定します。

00:08:22.000 --> 00:08:27.000
次に、MTLDeviceオブジェクトを使用してスパースヒープを作成します。

00:08:27.000 --> 00:08:30.000
まばらなテクスチャを作成するのはとても簡単です。

00:08:30.000 --> 00:08:37.000
まず、通常どおりテクスチャ記述子を作成し、次にスパースヒープオブジェクトを使用してテクスチャを作成します。

00:08:37.000 --> 00:08:44.000
スパーステクスチャを作成する方法を見たので、領域をメモリにマッピングする方法を見てみましょう。

00:08:44.000 --> 00:08:52.000
テクスチャの領域のマッピングとアンマッピングは、リソース状態コマンドエンコーダでマップコマンドとアンマップコマンドをエンコードすることによって行われます。

00:08:52.000 --> 00:09:00.000
このエンコーダは、Metalの他のレンダリングコマンドをエンコードするのと同様に、GPUタイムラインでマップ操作とマップ解除操作をスケジュールするために使用できます。

00:09:00.000 --> 00:09:03.000
これがコードでどのように見えるか見てみましょう。

00:09:03.000 --> 00:09:06.000
まず、エンコーダを作成します。

00:09:06.000 --> 00:09:14.000
そして、単にマップ操作をエンコードします。テクスチャと、マッピングするテクスチャの領域、スライス、およびミップレベルを指定します。

00:09:14.000 --> 00:09:20.000
領域がマッピングされ、マッピングされたメモリにテクスチャデータをブリットまたは作成できます。

00:09:20.000 --> 00:09:26.000
セクションのマッピングを解除するには、同じ手順に従います。唯一の違いは、エンコードする更新のモードです。

00:09:26.000 --> 00:09:32.000
テクスチャデータを作成してマッピングしたので、スパーステクスチャのサンプリングに移りましょう。

00:09:32.000 --> 00:09:36.000
まばらなテクスチャからのサンプリングは、通常のテクスチャからのサンプリングと変わりません。

00:09:36.000 --> 00:09:40.000
マッピングされていないセクションがアクセスされた場合には、明確に定義された動作があります。

00:09:40.000 --> 00:09:46.000
マップされていない領域をサンプリングすると、ゼロのベクトルが返され、書き込みは破棄されます。

00:09:46.000 --> 00:09:54.000
標準サンプリング機能に加えて、Metalは、マッピングされていない領域をテストするためにシェーダーで使用できるsparse_sample関数を提供します。

00:09:54.000 --> 00:10:01.000
スパーステクスチャを作成、マッピング、サンプリングする方法を見たので、簡単な実装を見てみましょう。

00:10:01.000 --> 00:10:06.000
スパーステクスチャを効率的にサンプリングする1つの方法は、フォールバックサンプリングを実行することです。

00:10:06.000 --> 00:10:15.000
シェーダーでは、まず sparse_sampleメソッドを使用してテクセルを取得しようとすることができ、それが失敗した場合は、下位レベルのミップマップにフォールバックできます。

00:10:15.000 --> 00:10:20.000
常に低いミップマップをロードしておくことで、有効なサンプルを見つけることが保証されます。

00:10:20.000 --> 00:10:29.000
また、フォールバックサンプリングをよりよくサポートするために、メタルシェーディング言語は、min LODクランプと呼ばれるテクスチャメソッドに関する新しい議論もサポートしています。

00:10:29.000 --> 00:10:34.000
最小LODクランプを使用すると、アクセスできるチェーンで最も高いミップマップを設定できます。

00:10:34.000 --> 00:10:40.000
これにより、データがあることを知っている最高のミップマップを指定することで、有効なサンプルを保証できます。

00:10:40.000 --> 00:10:43.000
それをコードで見てみましょう。

00:10:43.000 --> 00:10:47.000
ここには、まばらなテクスチャからサンプリングするフラグメントシェーダーがあります。

00:10:47.000 --> 00:10:53.000
Sparse_colorオブジェクトを返すsparse_sampleメソッドを使用して、スパーステクスチャのサンプリングを開始します。

00:10:53.000 --> 00:10:59.000
その後、返されたオブジェクトの常駐メソッドを呼び出して、GPUがマッピングデータをサンプリングしたかどうかを判断できます。

00:10:59.000 --> 00:11:03.000
もしそうなら、サンプリングされた値を取得して返します。

00:11:03.000 --> 00:11:10.000
それ以外の場合は、スパーステクスチャを再度サンプリングしますが、今回はLODクランプを使用して、サンプラーにより高いミップマップをバイパスさせます。

00:11:10.000 --> 00:11:18.000
このミップマップとそれ以下のミップマップにデータがあることを保証したため、2回目のサンプリングコールは通常のサンプルメソッドを使用して行われます。

00:11:18.000 --> 00:11:29.000
スパーステクスチャデータをマッピングしてサンプリングする機能を見たので、スパーステクスチャタイルをマッピングまたは解放するタイミングを決定する方法について少し話しましょう。

00:11:29.000 --> 00:11:36.000
従来のテクスチャストリーミングシステムは、アプリレベルの統計を手動で収集し、テクスチャレジデンシーの優先順位付けを支援します。

00:11:36.000 --> 00:11:41.000
これらの方法は、多くの場合、オーバーヘッドを管理するのに役立つミップマップまたはメッシュの粒度で粗いです。

00:11:41.000 --> 00:11:46.000
金属は代わりに、テクスチャアクセスカウンタと呼ばれるきめ細かいソリューションをサポートしています。

00:11:46.000 --> 00:11:53.000
これらのカウンターは、非常に低いオーバーヘッドでGPUがスパースタイルにアクセスする頻度を正確に追跡します。

00:11:53.000 --> 00:11:56.000
テクスチャアクセスカウンタはGPUから照会されます。

00:11:56.000 --> 00:11:59.000
これがどのように機能するかを見てみましょう。

00:11:59.000 --> 00:12:03.000
このメタルの例では、GPUからテクスチャアクセスカウンタを収集します。

00:12:03.000 --> 00:12:07.000
まず、サンプリングされたカウンタを含むバッファを作成します。

00:12:07.000 --> 00:12:16.000
そして、ブリットをエンコードして、スパーステクスチャからバッファにカウンターをコピーし、興味のあるミップレベル、スライス、領域を指定します。

00:12:16.000 --> 00:12:25.000
従来のテクスチャストリーミング技術は、長年にわたって非常に役立っており、固定されたメモリ予算を考えると、ユーザーが見るテクスチャのミップレベルでストリーミングすることができます。

00:12:25.000 --> 00:12:33.000
テクスチャ予算が使い果たされると、高解像度のミップレベルでストリーミングできなくなり、均一にぼやけたテクスチャが見え始めます。

00:12:33.000 --> 00:12:37.000
しかし、まばらなテクスチャで、あなたは今、あなたのメモリのより良い使用を得ることができます。

00:12:37.000 --> 00:12:47.000
メモリをマッピングして、特定のミップレベル内の各テクスチャタイルに最も適した品質レベルで、ユーザーが見る個々のテクスチャタイルのためのスペースを作ることができます。

00:12:47.000 --> 00:12:52.000
これにより、最も視覚的なインパクトを与えるタイルのテクスチャメモリを分散できます。

00:12:52.000 --> 00:13:06.000
さらに、この機能は、テクスチャをストリーミングするときに帯域幅を節約します。スパーステクスチャAPIを使用すると、ストリーミング中にメモリ内のミップマップチェーン全体をコピーして再配置する代わりに、個々のタイルをマッピングおよびマッピング解除できます。

00:13:06.000 --> 00:13:12.000
それはまばらなテクスチャのためであり、テクスチャのストリーミング品質も向上させる本当に重要なメモリ最適化です。

00:13:12.000 --> 00:13:17.000
それでは、ラスタライズレートマップと呼ばれるランタイム最適化手法に移りましょう。

00:13:17.000 --> 00:13:29.000
ラスタライズレートマップを使用すると、知覚されない場所で品質を低下させながら、最高の解像度で最も重要な画像領域をラスタライズしてシェーディングすることで、Retinaディスプレイをより適切に活用できます。

00:13:29.000 --> 00:13:42.000
ラスタライズレートマップを使用すると、画面スペースと物理レンダリングターゲットサイズ、および2つのスペース間の不均一なマッピングの両方を定義して、複数の解像度でラスタライズとシェーディングを行い、各領域の品質を制御できます。

00:13:42.000 --> 00:13:47.000
物理的な解像度は画面容量よりも小さく、帯域幅を節約し、メモリフットプリントを削減します。

00:13:47.000 --> 00:13:57.000
そして、不均一なマッピングは、ネイティブ解像度で画面全体をレンダリングするコストのほんの一部で、ゲームでよく使用される均一なアップスケールよりも高品質のビジュアルをもたらします。

00:13:57.000 --> 00:14:01.000
これがどのように機能するかを詳しく見てみましょう。

00:14:01.000 --> 00:14:05.000
これは、サンプルレンダラーのgバッファからの拡散レイヤーのスクリーンショットです。

00:14:05.000 --> 00:14:15.000
従来のレンダリングは、各頂点の画面空間座標を計算し、結果のプリミティブを画面空間でラスタライズしてフラグメントを生成することによってジオメトリを描画します。

00:14:15.000 --> 00:14:21.000
これらの画面空間座標は、ラスタ化中の物理レンダリングターゲットの座標への1対1のマッピングを持っています。

00:14:21.000 --> 00:14:35.000
ラスタライズレートマップを使用すると、フラグメントを作成するときに画面空間座標を不均一にマッピングするようにラスタライザを設定できるため、生成される総フラグメントの数を減らし、同時にレンダリングターゲットを小さくすることができます。

00:14:35.000 --> 00:14:40.000
どちらの画像でも、白いグリッドは仮想画面空間の均等な間隔のグリッドに対応します。

00:14:40.000 --> 00:14:44.000
しかし、ここで見ることができるように、それは物理的な空間に不均等に分布しています。

00:14:44.000 --> 00:14:53.000
この例では、ラスタライズレートマップを使用して、画面の解像度を画面の中央に保ちますが、画面の端に向かって減らしました。

00:14:53.000 --> 00:14:57.000
これをより明確に見るために、中央のタイルの1つを拡大しましょう。

00:14:57.000 --> 00:15:03.000
この物理タイルの解像度は、gバッファ内の同じ領域の解像度と一致します。

00:15:03.000 --> 00:15:11.000
しかし、画面の端に向かって移動すると、そのタイル専用の物理的なスペースを効果的に減らすことで品質が低下します。

00:15:11.000 --> 00:15:19.000
これにより、物理的な画像に歪んだ画像が表示されますが、このマッピングを逆にして、歪みのない最終画像を作成できることを示します。

00:15:19.000 --> 00:15:22.000
しかし、まず、マッピングがどのように定義されているかを見てみましょう。

00:15:22.000 --> 00:15:28.000
マッピングは、画面空間のX軸とY軸の2つの1D関数として定義されています。

00:15:28.000 --> 00:15:35.000
これらの機能をMetalで説明し、品質要件を定義する一連のコントロールポイントを使用します。

00:15:35.000 --> 00:15:41.000
この画像では、軸に沿った2つの1D機能を考えると、画面全体で効果的なラスタライズ率を見ることができます。

00:15:41.000 --> 00:15:48.000
1つの品質レベルは、軸に沿ったすべての画面空間ピクセルに対してフラグメントシェーダーが呼び出されることを意味します。

00:15:48.000 --> 00:15:55.000
そして、.5の品質レベルは、ピクセルの少なくとも50%に対して、与えられた軸に沿ってフラグメントシェーダーが呼び出されることを意味します。

00:15:55.000 --> 00:16:00.000
品質レベルがゼロであるということは、各フラグメントシェーダーがMetalがサポートする最小レートで呼び出されることを意味します。

00:16:00.000 --> 00:16:04.000
金属はこれらのコントロールポイントを再サンプリングして、最終的なレートマップを作成します。

00:16:04.000 --> 00:16:11.000
最終的なマッピングを直接制御しなくても、Metalは最低品質が維持されることを保証します。

00:16:11.000 --> 00:16:13.000
では、Metalでこのマッピングを作成しましょう。

00:16:13.000 --> 00:16:18.000
これは、先ほど見たラスタライズレートマップを構築するMetalコードです。

00:16:18.000 --> 00:16:21.000
まず、ラスタライズ関数を定義します。

00:16:21.000 --> 00:16:28.000
この例では、マップの水平軸と垂直軸の両方について、以前に示した5つの値を使用します。

00:16:28.000 --> 00:16:33.000
次に、レイヤー記述子を埋めて、ラスタライズレートマップ全体の品質を記述します。

00:16:33.000 --> 00:16:37.000
次に、水平方向と垂直方向の品質機能を提供することで作成します。

00:16:37.000 --> 00:16:46.000
品質を定義して、レイヤー記述子と最終的な画面空間解像度から金属ラスタライズレートマップ記述子を作成します。

00:16:46.000 --> 00:16:53.000
最後に、Metalデバイスを使用して、その記述子を使用してラスタライズレートマップオブジェクトをインスタンス化します。

00:16:53.000 --> 00:16:58.000
次に、このマップの物理的なレンダリングターゲットを作成する必要があります。

00:16:58.000 --> 00:17:06.000
実際のラスタライズレートマップレートは実装に依存するため、まずマップからリソースの物理的なサイズを照会する必要があります。

00:17:06.000 --> 00:17:15.000
次に、通常どおり物理レンダリングターゲットを作成します。正しい使用状況とストレージプロパティを指定し、Metalデバイスオブジェクトを使用してテクスチャをインスタンス化します。

00:17:15.000 --> 00:17:22.000
最後に、作成したテクスチャとラスタライズマップを組み合わせて、レンダリングパスを設定し、通常どおりレンダリングします。

00:17:22.000 --> 00:17:26.000
そして、それで、あなたはgバッファを不均一にラスタライズしました。

00:17:26.000 --> 00:17:29.000
しかし、後のパスでgバッファをシェーディングするのはどうですか?

00:17:29.000 --> 00:17:40.000
従来の遅延シェーディングパイプラインを使用すると、光のジオメトリがgバッファと同じ画面空間で正しくラスタライズされるため、同じラスタライズレートマップで照明を続けることができます。

00:17:40.000 --> 00:17:44.000
タイルの遅延レンダラーでは、もう少し作業を行う必要があります。

00:17:44.000 --> 00:17:52.000
タイルの遅延レンダリングにまだ慣れていない場合は、WWDC 2019でのModern Rendering with Metalトークをご覧ください。

00:17:52.000 --> 00:18:01.000
タイル繰延では、レンダリングターゲットの物理空間は等しいサイズのピクセルブロックに分割され、各ブロックは軽いタイルの淘汰とシェーディングを実行します。

00:18:01.000 --> 00:18:08.000
提示された画像では、サンプルコードは32×32ピクセルのブロックあたりのライト数のヒートマップを示しています。

00:18:08.000 --> 00:18:16.000
画面空間はもはや物理空間に対応しないため、ラスタライズレートマップをタイル付き遅延レンダラーと統合するには、1つの追加ステップが必要です。

00:18:16.000 --> 00:18:22.000
照明シェーダーは、物理空間のピクセル座標を仮想画面空間に変換する必要があります。

00:18:22.000 --> 00:18:25.000
これは、ラスタライズ中に使用されるリバースマッピングです。

00:18:25.000 --> 00:18:29.000
シェーダーでこのリバースマッピングを実行する方法を見てみましょう。

00:18:29.000 --> 00:18:34.000
まず、ラスタライズレートマップパラメータをシェーダーからアクセスできるようにする必要があります。

00:18:34.000 --> 00:18:39.000
これを行うには、まずパラメータを保持できるMTLBufferを作成します。

00:18:39.000 --> 00:18:42.000
次に、パラメータデータをMTLBufferにコピーします。

00:18:42.000 --> 00:18:45.000
そして最後に、MTLBufferをシェーダーにバインドします。

00:18:45.000 --> 00:18:48.000
地図がバインドされたので、それを使おう。

00:18:48.000 --> 00:18:55.000
シェーダーでは、対応するバッファバインドポイントでrasterization_rate_map_dataオブジェクトにアクセスできるようになりました。

00:18:55.000 --> 00:18:59.000
そのオブジェクトを使用して、rasterization_rate_map _decoderオブジェクトをインスタンス化できます。

00:18:59.000 --> 00:19:04.000
そして、デコーダを使用して、物理座標と画面座標の間で変換します。

00:19:04.000 --> 00:19:11.000
タイル付き遅延レンダラーに戻り、デコーダを使用して仮想画面空間でタイルカリングを実行します。

00:19:11.000 --> 00:19:19.000
光の淘汰を仮想画面空間に適応させることは、タイルがもはや正方形ではなく、画面空間の正しい領域に従うことを意味します。

00:19:19.000 --> 00:19:23.000
このヒートマップを完全で均一な解像度のレンダリングと比較しましょう。

00:19:23.000 --> 00:19:26.000
そして、ラスタライズレートマップバージョンに戻ります。

00:19:26.000 --> 00:19:34.000
ご覧のとおり、ラスタライズレートマップを使用すると、画面上のシェーディングされたタイルの量が大幅に減少しました。

00:19:34.000 --> 00:19:41.000
最後に、合成と最終プレゼンテーションのためにラスタライズレートマップがどのように準備されているかを考えてみましょう。

00:19:41.000 --> 00:19:51.000
最後の画像を画面に表示する前に、先ほど説明したシェーダーマッピングを使用して、物理的な空間テクスチャを高解像度サーフェスに変換するフルスクリーンパスを使用して、ラップを解除する必要があります。

00:19:51.000 --> 00:20:01.000
ご覧のとおり、このサンプルに選択された積極的なフォールオフにもかかわらず、品質のトレードオフに気づくことは非常に困難です。

00:20:01.000 --> 00:20:08.000
ラスタライズレートマップは、品質のトレードオフを隠すために、被写界深度などの他の技術と組み合わせることを期待しています。

00:20:08.000 --> 00:20:10.000
それはラスタライズレートマップ用です。

00:20:10.000 --> 00:20:14.000
頂点増幅に移りましょう。

00:20:14.000 --> 00:20:20.000
頂点増幅により、マルチビューレンダリングの場合のジオメトリ処理を削減できます。

00:20:20.000 --> 00:20:27.000
多層およびマルチビューポートレンダリングは、インスタンスを使用して各ビューをターゲットにするために必要な描画呼び出しの数を減らします。

00:20:27.000 --> 00:20:32.000
しかし、それはこれらの各インスタンスを処理するGPUコストを排除するものではありません。

00:20:32.000 --> 00:20:36.000
多くの多層およびマルチビューポートレンダリング技術は、ビュー間でジオメトリを共有します。

00:20:36.000 --> 00:20:41.000
たとえば、シャドウマップのカスケードや環境マップの側面の間。

00:20:41.000 --> 00:20:46.000
これらの各インスタンスは、通常、ほぼ同じ方法でそのジオメトリを変換します。

00:20:46.000 --> 00:20:54.000
したがって、位置はビューごとに一意ですが、法線、接線、テクスチャ座標などの属性は同じです。

00:20:54.000 --> 00:21:01.000
頂点増幅では、これらの共有属性を一度だけ処理できるため、頂点シェーディングの効率が向上します。

00:21:01.000 --> 00:21:06.000
カスケードシャドウマップのユースケースをより詳細に考えてみましょう。

00:21:06.000 --> 00:21:14.000
ビュー距離に応じて、レンダラーはシャドウマップを1つ、2つ、または3つ以上の重なり合うシャドウカスケードに分割することがあります。

00:21:14.000 --> 00:21:21.000
カスケードの数を増やすにつれて、各カスケードがカバーする仮想世界のサイズも大きくなります。

00:21:21.000 --> 00:21:28.000
これにより、より大きく、より遠いカスケードは、より近いカスケードと比較して、より多くのジオメトリを蓄積します。

00:21:28.000 --> 00:21:34.000
そして、より多くのカスケードで、複数のカスケードにレンダリングするオブジェクトの数が増えます。

00:21:34.000 --> 00:21:40.000
それでは、カスケードシャドウマップが伝統的にどのようにレンダリングされるか、そして関連するコストを考えてみましょう。

00:21:40.000 --> 00:21:44.000
マルチビューレンダリングの前に、各カスケードに別々に描画するだけです。

00:21:44.000 --> 00:21:48.000
これにより、GPUとCPUの両方のオーバーヘッドが増加しました。

00:21:48.000 --> 00:21:54.000
各頂点は複数回フェッチしてシェーディングする必要があり、各頂点も複数回出力されます。

00:21:54.000 --> 00:22:00.000
マルチビューインスタンスレンダリングは、インスタンスIDを使用して、各プリミティブを宛先ビューにマッピングします。

00:22:00.000 --> 00:22:06.000
複数のドローコールのCPUコストを排除しますが、GPUコストは同じままです。

00:22:06.000 --> 00:22:18.000
レイヤードレンダリングにインスタンスを使用すると、インスタンスIDが実際のインスタンスIDとターゲットレイヤーの両方をエンコードするようになったため、実際のインスタンスジオメトリのレンダリングも複雑になります。

00:22:18.000 --> 00:22:22.000
頂点増幅は、重複したフェッチ、シェーディング、および出力を排除します。

00:22:22.000 --> 00:22:25.000
また、別の増幅IDも提供します。

00:22:25.000 --> 00:22:29.000
動作中の頂点増幅を見てみましょう。

00:22:29.000 --> 00:22:33.000
既存の頂点関数は、頂点増幅に簡単に適応できます。

00:22:33.000 --> 00:22:42.000
この例では、増幅ごとに一意の位置を計算しますが、すべての増幅で色計算を共有します。

00:22:42.000 --> 00:22:46.000
2つの属性でVertexOutputを宣言することから始めます。

00:22:46.000 --> 00:22:55.000
コンパイラは通常、属性が一意であるか共有されているかを推測できますが、複雑なシェーダーの場合、どの属性が共有されているかを明示的にすることもできます。

00:22:55.000 --> 00:23:02.000
共有属性の計算が増幅IDに依存している場合、コンパイラはエラーを報告します。

00:23:02.000 --> 00:23:06.000
次に、増幅IDを保持する関数引数を宣言します。

00:23:06.000 --> 00:23:11.000
このIDに関連付けられた計算は、シェーダー呼び出しごとに増幅されます。

00:23:11.000 --> 00:23:16.000
color属性はそのIDに関連付けられていないため、一度だけ実行されます。

00:23:16.000 --> 00:23:23.000
しかし、位置は正しいビュー投影行列を検索するためのIDに依存するため、式全体が増幅されます。

00:23:23.000 --> 00:23:25.000
シェーダーコードはそれだけです。

00:23:25.000 --> 00:23:29.000
では、増幅されたドローコールをどのように設定するかを見てみましょう。

00:23:29.000 --> 00:23:33.000
増幅を可能にするパイプライン状態オブジェクトを作成することから始めましょう。

00:23:33.000 --> 00:23:38.000
金属でサポートされている最大増幅係数は、デバイスから照会できます。

00:23:38.000 --> 00:23:42.000
この場合、増幅係数が2つ欲しいとしましょう。

00:23:42.000 --> 00:23:46.000
サポートされている場合は、パイプラインの最大増幅係数に設定します。

00:23:46.000 --> 00:23:53.000
サポートされていない場合は、インスタンス化を通じて従来のマルチビューにフォールバックしたり、複数のドローコールを行うことに頼ることができます。

00:23:53.000 --> 00:23:56.000
最後に、パイプラインを作成します。

00:23:56.000 --> 00:24:02.000
パイプラインが作成され、増幅がサポートされていると仮定すると、ドロのエンコードを開始できます。

00:24:02.000 --> 00:24:07.000
増幅で描画するには、増幅数を設定し、viewMappingsをバインドする必要があります。

00:24:07.000 --> 00:24:13.000
viewMappingsは、増幅IDをターゲットレイヤーまたはビューポートにマッピングする方法について説明します。

00:24:13.000 --> 00:24:22.000
頂点シェーダーがレンダリングターゲットまたはビューポート配列インデックスもエクスポートする場合、そのインデックスはviewMappings配列のベースオフセットとして機能します。

00:24:22.000 --> 00:24:26.000
これで、目的の増幅を設定し、ドローをエンコードできます。

00:24:26.000 --> 00:24:29.000
メタルフレームデバッガを詳しく見てみましょう。

00:24:29.000 --> 00:24:37.000
このサンプルレンダリングでは、VertexAmplificationを使用して、カスケード2と3の両方にレンダリングされるすべての描画を増幅します。

00:24:37.000 --> 00:24:42.000
ここでは、この描画呼び出しは、2つのレンダリングターゲットを指定するビューマッピングでレンダリングされることがわかります。

00:24:42.000 --> 00:24:51.000
メッシュは、左側に示されている2番目のカスケードと、右側とジオメトリビューアの両方に表示される3番目のカスケードに同時にレンダリングされます。

00:24:51.000 --> 00:24:53.000
それは頂点増幅のためです。

00:24:53.000 --> 00:24:59.000
引数バッファと、それらがA13にどのように拡張されたかに移りましょう。

00:24:59.000 --> 00:25:02.000
メタル2で引数バッファを導入しました。

00:25:02.000 --> 00:25:08.000
引数バッファを使用すると、定数、テクスチャ、サンプラー、およびバッファ引数をMTLBuffersにエンコードできます。

00:25:08.000 --> 00:25:16.000
すべての描画引数を1つのMetal引数バッファにエンコードすることで、最小限のCPUオーバーヘッドで複雑なシーンをレンダリングできます。

00:25:16.000 --> 00:25:22.000
エンコードされると、引数バッファを再利用して、重複した冗長リソースバインディングを回避できます。

00:25:22.000 --> 00:25:31.000
引数バッファは、GPU上のシーン全体のドロー引数へのアクセスを提供することで、GPU主導のパイプラインを有効にするためにも必要です。

00:25:31.000 --> 00:25:38.000
その後、計算関数の引数バッファを変更して、シーンを動的に設定できます。

00:25:38.000 --> 00:25:42.000
ティア2引数バッファは、引数バッファの機能を劇的に強化します。

00:25:42.000 --> 00:25:48.000
A13を使用すると、Metal関数は引数バッファ内の任意のテクスチャをサンプリングまたは書き込むことができます。

00:25:48.000 --> 00:25:53.000
また、事実上無制限の数のテクスチャと多くのサンプラーにアクセスすることもできます。

00:25:53.000 --> 00:25:58.000
また、引数バッファは、複数のレベルの間接を持つ他の引数バッファも参照できるようになりました。

00:25:58.000 --> 00:26:10.000
これにより、GPUまたはCPUで事前に引数バッファを組み立てることなく、すべてのシーンデータに対して単一の引数バッファをエンコードし、ドローでアクセスする機能のロックを解除します。

00:26:10.000 --> 00:26:11.000
例を見てみましょう。 例を見てみましょう。

00:26:11.000 --> 00:26:15.000
シーンオブジェクトモデル階層の例を次に示します。

00:26:15.000 --> 00:26:21.000
WWDC 2019でのModern Rendering with Metalトークで同様の例を示しました。

00:26:21.000 --> 00:26:25.000
階層は、すべてのジオメトリデータ、材料、およびモデルデータを記述します。

00:26:25.000 --> 00:26:29.000
引数バッファを使用すると、このオブジェクトモデルを直接エンコードできます。

00:26:29.000 --> 00:26:33.000
しかし、Tier 2のサポートでは、レンダリング中に階層を直接使用することもできます。

00:26:33.000 --> 00:26:36.000
シェーダーの例を見てみましょう。 シェーダー

00:26:36.000 --> 00:26:45.000
まず、引数バッファがメタルシェーディング言語で定数、テクスチャ、サンプラー、バッファの構造として宣言されていることを思い出してください。

00:26:45.000 --> 00:26:50.000
これらの宣言は、先ほど説明したオブジェクト階層の例を直接反映します。

00:26:50.000 --> 00:26:58.000
1つ目は材料表現で、2つ目はメッシュ、材料、モデルのセットを参照するシーンです。

00:26:58.000 --> 00:27:03.000
さて、それでは、私たちのシーンを直接使用してシェードするフラグメント関数を見てみましょう。

00:27:03.000 --> 00:27:07.000
最初の関数パラメータは、シーン引数バッファです。

00:27:07.000 --> 00:27:11.000
2番目の関数パラメータは、描画ごとの定数です。

00:27:11.000 --> 00:27:19.000
この例では、このドローのモデルIDと、以前の計算パスで選択された詳細の離散レベルをエンコードします。

00:27:19.000 --> 00:27:25.000
次に、これらのIDを使用して、以前に計算されたIDを使用してシーンから素材を取得します。

00:27:25.000 --> 00:27:32.000
そして、ネストされた引数バッファからテクスチャ、定数、サンプラーを使用してフラグメントの色を計算します。

00:27:32.000 --> 00:27:33.000
そして、それだけです!

00:27:33.000 --> 00:27:39.000
マテリアルパラメータをドローごとの引数バッファに収集するための介入コンピューティングパスはもうありません。

00:27:39.000 --> 00:27:43.000
フラグメントシェーダーは、シーン引数バッファを直接使用するだけです。

00:27:43.000 --> 00:27:48.000
しかし、先に進む前に、引数バッファの堅牢なツールサポートを強調したいと思います。

00:27:48.000 --> 00:27:55.000
引数バッファとGPU駆動のパイプラインを使用すると、シーンのセットアップはGPUに移動し、デバッグも行います。

00:27:55.000 --> 00:28:03.000
メタルフレームデバッガを使用すると、引数バッファとそれらを使用するシェーダーの両方を簡単にデバッグおよび検査できます。

00:28:03.000 --> 00:28:12.000
バッファビューアを使用して、引数バッファ内のすべてのリソースを検査し、これらのリソースにすばやくジャンプしてさらに検査することができます。

00:28:12.000 --> 00:28:19.000
シェーダーデバッガを使用して、シェーダーが引数バッファにどのようにアクセスまたは構築しているかを理解することもできます。

00:28:19.000 --> 00:28:26.000
これは、引数バッファインデックスを計算したり、GPUの引数バッファを変更したりする場合に特に重要です。

00:28:26.000 --> 00:28:29.000
ティア2の引数バッファはそれだけです。

00:28:29.000 --> 00:28:34.000
それでは、新しいクラスのシェーダー最適化技術に移りましょう。

00:28:34.000 --> 00:28:39.000
SIMDグループ機能は、コンピューティング機能とグラフィックス機能を最適化するための強力なツールです。

00:28:39.000 --> 00:28:46.000
GPUワークロードは、GPUのアーキテクチャを活用することで、データと制御フロー情報を共有できます。

00:28:46.000 --> 00:28:52.000
MetalのSIMD実行モデルをすばやくレビューして、それを解き明かしましょう。

00:28:52.000 --> 00:29:00.000
Metalは、単一の命令、GPUの複数のデータの性質を利用するために、常にSIMDグループにスレッドを整理してきました。

00:29:00.000 --> 00:29:09.000
Metalコンピューティング関数のSIMDグループを活用して、代わりにSIMDグループバリアを使用してスレッドグループ全体を同期するコストを削減した可能性があります。

00:29:09.000 --> 00:29:14.000
SIMDグループのスレッドはロックステップで実行されるため、実行障壁は必要ありません。

00:29:14.000 --> 00:29:19.000
したがって、SIMDグループバリアはメモリ操作のみを同期します。

00:29:19.000 --> 00:29:32.000
SIMDグループ関数は、このロックステップ実行を利用して、スレッドグループメモリの代わりにレジスタを使用してスレッド間でデータを共有し、スレッドグループメモリバインド時のパフォーマンスを大幅に向上させることができます。

00:29:32.000 --> 00:29:36.000
また、計算機能とレンダリング機能の両方に使用できます。

00:29:36.000 --> 00:29:40.000
そして、少し見ればわかるように、これは非常に興味深いレンダリング最適化技術を可能にします。

00:29:40.000 --> 00:29:46.000
まず、例を挙げて、SIMD実行のためのより良い直感を構築することから始めましょう。

00:29:46.000 --> 00:29:52.000
左側は、SIMDグループをレーン0から始まる32レーンとして表しています。

00:29:52.000 --> 00:29:54.000
レーンはSIMDグループ内の単一スレッドです。

00:29:54.000 --> 00:29:57.000
では、このSIMDグループにいくつかの作業を実行させましょう。

00:29:57.000 --> 00:30:04.000
まず、すべてのレーンが配列AをレーンIDでインデックス化し、結果を変数Xに格納します。

00:30:04.000 --> 00:30:07.000
各車線がXの独自の値を持っていることに注意してください。

00:30:07.000 --> 00:30:17.000
この実行モデルでは、Aからデータをロードする命令は一度だけフェッチされ、独自のインデックスを持つ32のスレッドによって同時に実行されます。

00:30:17.000 --> 00:30:23.000
次に、laneIDで索引付けされた2番目の配列Bを読み取り、結果をYに格納します。

00:30:23.000 --> 00:30:28.000
最後に、XとYを乗算した結果を3番目の配列Cに格納します。

00:30:28.000 --> 00:30:35.000
実行された命令はグループ全体で1回しかフェッチされていないため、すべてのSIMDグループスレッドはロックステップで実行されます。

00:30:35.000 --> 00:30:43.000
SIMDグループ機能により、グループ内の各スレッドは、最小限のオーバーヘッドでSIMDグループ全体のレジスタ値を検査できます。

00:30:43.000 --> 00:30:47.000
この能力は、いくつかの興味深い機能を可能にします。

00:30:47.000 --> 00:30:52.000
まず、simd_maxを紹介し、変数Yに適用しましょう。

00:30:52.000 --> 00:30:58.000
各スレッドは、SIMDグループ内の任意のスレッドに見られるように、Yから最大の値を持つZ値を取得します。

00:30:58.000 --> 00:31:01.000
次に、放送してXに適用します。

00:31:01.000 --> 00:31:08.000
この例では、レーン0の値を1回の操作で他のすべてのレーンにブロードキャストします。

00:31:08.000 --> 00:31:17.000
Metal for A13は、シャッフル、パーミュート、すべてのレーンでの回転など、他の多くの同様に動作するSIMD機能をサポートしています。

00:31:17.000 --> 00:31:25.000
最後の例では、式がすべてのレーンで同じことを評価するかどうかを各レーンに伝えるsimd_allを見ていきます。

00:31:25.000 --> 00:31:32.000
この例では、Z変数は確かにすべてのレーンで9であるため、trueを返します。

00:31:32.000 --> 00:31:37.000
同様に、simd_anyは、式が任意のレーンに対して真と評価されるかどうかを指示します。

00:31:37.000 --> 00:31:45.000
Simd_allを使用すると、すべてのスレッドが同じニーズを持つ場合、より最適なパスを選択することで、シェーダーの発散を減らすことができます。

00:31:45.000 --> 00:31:47.000
例を見てみましょう。 例を見てみましょう。

00:31:47.000 --> 00:31:53.000
これは、SIMDグループ関数を使用したいくつかの最適化を含む、以前のフラグメントシェーダーです。

00:31:53.000 --> 00:32:00.000
要約すると、この関数は、引数バッファ、ユニフォーム、および頂点stage_inとしてエンコードされたシーンを入力として取ります。

00:32:00.000 --> 00:32:10.000
通常、照明機能は、透明なフラグメントに対して最終色のさまざまなコンポーネントを異なる方法で評価するため、さまざまなポイントで動的制御フローを必要とします。

00:32:10.000 --> 00:32:22.000
さて、すべてのフラグメントの不透明度を評価する代わりに、ここではsimd_allを使用して、SIMDグループ内のすべてのスレッドが不透明なフラグメントの照明を計算しているかどうかを動的にチェックします。

00:32:22.000 --> 00:32:27.000
もしそうなら、不透明なオブジェクトのみを想定した最適なパスを取ります。

00:32:27.000 --> 00:32:33.000
そして、そうでない場合は、不透明な断片と透明な断片の両方を照らすことができる以前のパスに戻ります。

00:32:33.000 --> 00:32:37.000
これは、A13のSIMDグループ機能の場合です。

00:32:37.000 --> 00:32:44.000
ギアを切り替えて、A13のASTCへのエキサイティングな追加のいくつかを見てみましょう。

00:32:44.000 --> 00:32:55.000
ビデオで先に述べたように、A13 GPUは16ビット浮動小数点演算の速度を2倍にし、HDR処理をより適切に処理するために小さな16ビット数のサポートを追加します。

00:32:55.000 --> 00:33:03.000
アプリは変更せずにこれらの改善を利用します。GPUでのHDR処理は、より速く、より正確になります。

00:33:03.000 --> 00:33:14.000
Apple Family 6では、ASTC HDRと呼ばれるHDRデータの効率的なストレージとサンプリングをサポートする新しいピクセルフォーマットのサポートも追加されています。

00:33:14.000 --> 00:33:24.000
ASTCは、多くのプラットフォームでサポートされているテクスチャ圧縮技術であり、帯域幅とメモリのほんの一部で高いテクスチャ画質を提供します。

00:33:24.000 --> 00:33:28.000
これは、複数のビットレートと入力フォーマットをサポートすることによって行います。

00:33:28.000 --> 00:33:37.000
ASTCローダイナミックレンジプロファイルは、Apple GPU Family 2からサポートされており、0から1の範囲で値を圧縮するのに適しています。

00:33:37.000 --> 00:33:44.000
アプリがメモリと帯域幅を節約するためにASTCをまだ使用していない場合は、そうすることを強くお勧めします。

00:33:44.000 --> 00:33:50.000
HDR画像に見られるより大きな輝度値をエンコードするには、ハイダイナミックレンジプロファイルが必要です。

00:33:50.000 --> 00:33:59.000
ASTC HDRがなければ、このような画像は通常、はるかに高いメモリコストで16ビットの浮動小数点ピクセル形式で保存されます。

00:33:59.000 --> 00:34:03.000
では、ASTC HDRはどのくらいのストレージを節約できますか?

00:34:03.000 --> 00:34:04.000
たくさん。

00:34:04.000 --> 00:34:05.000
例を考えてみましょう。

00:34:05.000 --> 00:34:16.000
HDRゲームは、多くの場合、低解像度のキューブマップテクスチャを使用して、シーンを照らすためにハイダイナミックレンジ環境マップを表し、通常、ゲームの世界やレベル全体に多くのそのようなプローブを配置します。

00:34:16.000 --> 00:34:26.000
ASTC HDRがなければ、各プローブは大量のメモリを消費することができ、そのようなプローブはすべてゲームのメモリ予算の大部分を簡単に消費する可能性があります。

00:34:26.000 --> 00:34:32.000
この例では、256×256のプローブキューブマップだけで3MBを消費します。

00:34:32.000 --> 00:34:37.000
ASTC HDRでは、同じプローブは何倍も少ないメモリを消費します。

00:34:37.000 --> 00:34:41.000
ビットレートを変更して、フットプリントを本当に減らすこともできます。

00:34:41.000 --> 00:34:46.000
HDRテクスチャの作成は、LDRに相当するものと同じくらい簡単です。

00:34:46.000 --> 00:34:51.000
この例では、4×4のASTC LDRテクスチャを作成しています。

00:34:51.000 --> 00:35:00.000
すべてのLDRフォーマットに一致するHDRフォーマットがあるため、これをHDRテクスチャに変換するには、ピクセルフォーマットを変更するだけです。

00:35:00.000 --> 00:35:04.000
さて、それはA13 GPUの新しいMetal機能をまとめます。

00:35:04.000 --> 00:35:07.000
私たちが学んだことをまとめましょう。

00:35:07.000 --> 00:35:11.000
まばらなテクスチャで高品質のテクスチャストリーミングを可能にします。

00:35:11.000 --> 00:35:20.000
これにより、ラスタライズレートマップで高価なシェーディングを必要な場所に焦点を合わせ、頂点増幅で冗長な頂点処理を排除することができます。

00:35:20.000 --> 00:35:29.000
また、引数バッファTier 2と、シャッフルと投票命令によるSIMDグループ共有を備えた、より柔軟なGPU駆動型パイプラインを可能にします。

00:35:29.000 --> 00:35:35.000
そして最後に、MetalはASTCでHDRパイプラインでメモリを節約できるようになりました。

00:35:35.000 --> 00:35:44.000
Metal、A13 GPUの詳細、および最新のサンプルコードについては、developer.apple.comをご覧ください。

00:35:44.000 --> 23:59:59.000
ありがとうございます。

