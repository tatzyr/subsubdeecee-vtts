WEBVTT

00:00:01.000 --> 00:00:02.000
アレハンドロ・イサザ:こんにちは。私はアレハンドロです。

00:00:02.000 --> 00:00:08.000
今日、Davidと私は、データ操作と探索のための新しいフレームワークであるTabularDataを紹介します。

00:00:08.000 --> 00:00:16.000
簡単な紹介から始めて、データ探索、データ変換、ベストプラクティスについて話し、要約で終わります。

00:00:16.000 --> 00:00:17.000
飛び込みましょう。

00:00:17.000 --> 00:00:20.000
まず、表形式データとは何ですか？

00:00:20.000 --> 00:00:26.000
簡単に言えば、表形式のデータは、スプレッドシートと同様に、行と列に整理されたデータです。

00:00:26.000 --> 00:00:29.000
しかし、あなたが何百もの列と数百万の行を持っていたと想像してみてください。

00:00:29.000 --> 00:00:32.000
ここで、TabularDataフレームワークの出番です。

00:00:32.000 --> 00:00:33.000
それで、それは何ですか?

00:00:33.000 --> 00:00:36.000
それは私たちが取り組んできたまったく新しいフレームワークです。

00:00:36.000 --> 00:00:40.000
macOS、iOS、tvOS、watchOSですでに利用可能です。

00:00:40.000 --> 00:00:44.000
非構造化データを探索して操作するのに役立ちます。

00:00:44.000 --> 00:00:49.000
「非構造化データ」とは、事前に定義された方法で配置されていないデータを意味します。

00:00:49.000 --> 00:00:56.000
たとえば、技術仕様のないデータセットをダウンロードする場合、たとえば、気象データや人口統計などです。

00:00:56.000 --> 00:00:59.000
そして、探検は、新しいデータセットに遭遇したときに最初に行うことです。

00:00:59.000 --> 00:01:01.000
どのような情報があるのか知りたいです。

00:01:01.000 --> 00:01:03.000
のようなもの、価値観は何ですか?

00:01:03.000 --> 00:01:05.000
タイプは何ですか?データはどのように表されますか?

00:01:05.000 --> 00:01:07.000
欠落している値はありますか?などなど。

00:01:07.000 --> 00:01:14.000
データセットを適切に理解し、操作という次のステップに進むには、これらの質問に答えることができる必要があります。

00:01:14.000 --> 00:01:19.000
操作は、データセットを解決しようとしている問題に最も適した形式に変換する場所です。

00:01:19.000 --> 00:01:26.000
たとえば、日付を文字列ではなく日付型として表現したり、x座標とy座標を点型に結合したりできます。

00:01:26.000 --> 00:01:30.000
TabularDataフレームワークは、大規模なデータセットを扱うのに最適です。

00:01:30.000 --> 00:01:32.000
一般的なユースケースをいくつか紹介します。

00:01:32.000 --> 00:01:36.000
いくつかの基準に従ってデータをグループ化する。例えば、年齢別に人々をグループ化する。

00:01:36.000 --> 00:01:38.000
共通の値に関するデータセットを結合する。

00:01:38.000 --> 00:01:43.000
たとえば、トランザクションのテーブルを購入者の情報で結合します。

00:01:43.000 --> 00:01:48.000
データを分割またはセグメント化して段階的に処理したり、データセット全体のサブセットにフィルタリングしたりします。

00:01:48.000 --> 00:01:53.000
そして、データパイプラインを構築する。例えば、機械学習のためのフィーチャーエンジニアリングを行うとき。

00:01:53.000 --> 00:01:57.000
フレームワークのコンテキストでは、テーブルはDataFrameとして知られています。

00:01:57.000 --> 00:02:00.000
DataFrameには、スプレッドシートに似た行と列が含まれています。

00:02:00.000 --> 00:02:04.000
しかし、スプレッドシートとは異なり、すべての列には特定の種類の値のみを含めることができます。

00:02:04.000 --> 00:02:08.000
しかし、これはまた、列が任意のタイプ、さらには独自のカスタムタイプを保持できることを意味します。

00:02:08.000 --> 00:02:12.000
例えば、辞書、GPS座標、または生のオーディオサンプル。

00:02:12.000 --> 00:02:18.000
DataFrameまたはDataFrameスライスを表すテーブルを表示するたびに、左側にインデックス列が含まれることを知ってください。

00:02:18.000 --> 00:02:21.000
これは、データインデックスで行にアクセスする必要がある場合に関連しています。

00:02:21.000 --> 00:02:29.000
フィルターなどの一部の操作では、データは変更されませんが、ソートなどの他の操作では、結果のデータフレームのインデックスが変更される場合があります。

00:02:29.000 --> 00:02:31.000
それを分解して、列にズームインしましょう。

00:02:31.000 --> 00:02:35.000
前述したように、列には特定の要素タイプがあります。この場合、Int。

00:02:35.000 --> 00:02:37.000
また、データフレーム内で一意でなければならない名前もあります。

00:02:37.000 --> 00:02:41.000
列は、配列と同じようにコレクションである列タイプで表されます。

00:02:41.000 --> 00:02:45.000
列を名前で参照できますが、ほとんどの場合、タイプも必要です。

00:02:45.000 --> 00:02:51.000
列の名前とタイプを保持するColumnIDと呼ばれる構造体があり、特定の列を参照するために使用できます。

00:02:51.000 --> 00:02:56.000
可能な限り、文字列リテラルよりも定義済みのColumnIDを使用して列を参照することをお勧めします。

00:02:56.000 --> 00:03:00.000
また、DataFrame内のすべての列が同じ数の要素を持つ必要があることに注意してください。

00:03:00.000 --> 00:03:04.000
しかし、nil値として表される欠落している要素が常にある可能性があります。

00:03:04.000 --> 00:03:06.000
列と同様に、行タイプがあります。

00:03:06.000 --> 00:03:10.000
行の各要素には、列名またはインデックスでアクセスできます。

00:03:10.000 --> 00:03:12.000
Rowはプロキシと考えることができます。

00:03:12.000 --> 00:03:17.000
実際には行の要素は含まれていません。代わりに、DataFrameの行を指す参照です。

00:03:17.000 --> 00:03:19.000
では、どのようにDataFrameを作成しますか?

00:03:19.000 --> 00:03:20.000
お見せしましょう。

00:03:20.000 --> 00:03:25.000
辞書リテラルから、または一度に1つの列を構築することで、DataFrameを作成できます。

00:03:25.000 --> 00:03:28.000
これは、辞書リテラルから構築する例です。

00:03:28.000 --> 00:03:35.000
辞書リテラルを使用する場合は、文字列、数値、ブール値、日付などの基本的なSwift型を使用することが制限されていることに注意してください。

00:03:35.000 --> 00:03:39.000
また、すべての列が同じ数の要素を持たなければならないことを覚えておいてください。

00:03:39.000 --> 00:03:45.000
DataFrameを構築するより一般的な方法は、一度に1つの列を作成し、その列をDataFrameに追加することです。

00:03:45.000 --> 00:03:46.000
ここに例があります。

00:03:46.000 --> 00:03:48.000
まず、空のデータフレームを作成します。

00:03:48.000 --> 00:03:50.000
次に、列を作成します。

00:03:50.000 --> 00:03:52.000
そして、DataFrameに列を追加します。

00:03:52.000 --> 00:04:00.000
すべての列でプロセスを繰り返すことができますが、繰り返しますが、すべての列が同じ数の要素を持ち、列名が一意であることを確認してください。

00:04:00.000 --> 00:04:03.000
DataFrameが何であるかがわかったので、データ探索をしましょう。

00:04:03.000 --> 00:04:05.000
最初にしたいことは、データセットをロードすることです。

00:04:05.000 --> 00:04:10.000
TabularDataは、カンマ区切りの値、CSV、およびJSONファイルの読み取りをサポートしています。

00:04:10.000 --> 00:04:16.000
そして、すべてのデフォルトオプションを使用して読み込まれるファイルURLで初期化子を呼び出すのと同じくらい簡単です。

00:04:16.000 --> 00:04:19.000
CSVを読み込むときに利用可能なオプションのいくつかを見てみましょう。

00:04:19.000 --> 00:04:23.000
以前にCSVを使用したことがある場合は、常にカンマがあるわけではないことを知っているかもしれません。

00:04:23.000 --> 00:04:26.000
区切り文字はタブまたはセミコロンです。

00:04:26.000 --> 00:04:29.000
または、列名のヘッダー行があるかもしれないし、ないかもしれない。

00:04:29.000 --> 00:04:34.000
また、特殊文字の文字列のエスケープ方法や、欠損値の表現方法のバリエーションもあります。

00:04:34.000 --> 00:04:37.000
TabularDataはすべてのバリエーションを処理できます。

00:04:37.000 --> 00:04:45.000
この例では、カスタムnilエンコーディングを使用し、空行を無視し、セミコロン区切り文字を使用して、ヘッダー行がないことを指定しています。

00:04:45.000 --> 00:04:49.000
オプションのフルセットとデフォルトを確認するには、ドキュメントを参照してください。

00:04:49.000 --> 00:04:54.000
ファイルが大きい場合は、一度に行のサブセットのみを読み込むことができます。

00:04:54.000 --> 00:04:55.000
行オプションでこれを行うことができます。

00:04:55.000 --> 00:04:59.000
たとえば、これは最初の100行のみをロードします。

00:04:59.000 --> 00:05:02.000
同様に、列のサブセットを選択できます。

00:05:02.000 --> 00:05:04.000
これを行うには、列引数を使用します。

00:05:04.000 --> 00:05:09.000
これにより、列を再編成できることに注意してください。

00:05:09.000 --> 00:05:13.000
CSVファイルを読み込むときに型推論がどのように機能するかについて簡単に説明しましょう。

00:05:13.000 --> 00:05:15.000
CSVファイルはすべてテキストベースです。

00:05:15.000 --> 00:05:18.000
しかし、すべての列を文字列型にすることはあまり便利ではありません。

00:05:18.000 --> 00:05:26.000
したがって、CSVファイルを読み込むとき、TabularDataは文字列にデフォルト設定する前に、値を数値、ブール値、および日付に変換しようとします。

00:05:26.000 --> 00:05:32.000
値を特定のタイプに強制したい場合、またはロードを少し高速化したい場合は、列のタイプを明示的に指定できます。

00:05:32.000 --> 00:05:34.000
型引数でこれを行います。

00:05:34.000 --> 00:05:39.000
この例では、id列に整数型を、name列に文字列型を指定しています。

00:05:39.000 --> 00:05:45.000
これにより、ロードプロセスが高速化されるだけでなく、指定されたタイプに変換できない値がある場合にもエラーがスローされます。

00:05:45.000 --> 00:05:56.000
これは、問題を早期に発見し、期待するものではないタイプの列で終わるのではなく、適切に処理できるため、良いことです。これにより、アプリの後半でクラッシュする可能性があります。

00:05:56.000 --> 00:05:58.000
最後に、日付解析について言及させてください。

00:05:58.000 --> 00:06:02.000
TabularDataは、デフォルトでは、ISO8601形式で日付を検出して解析します。

00:06:02.000 --> 00:06:08.000
CSVファイルに別の形式の日付が含まれている場合は、カスタム日付解析戦略を指定する必要があります。

00:06:08.000 --> 00:06:12.000
デイビッドにこれについて話してもらい、デモに入るときに例をお見せします。

00:06:12.000 --> 00:06:15.000
では、ギアを切り替えて、データを書き出すことについて話しましょう。

00:06:15.000 --> 00:06:18.000
最初で最も簡単な選択は、Swiftの印刷機能を使用することです。

00:06:18.000 --> 00:06:21.000
これにより、ターミナルできれいに印刷されたテーブルが生成されます。

00:06:21.000 --> 00:06:29.000
印刷された出力には、行インデックス、列名、列タイプ、データの最初の数行、行と列の数が含まれます。

00:06:29.000 --> 00:06:34.000
また、すべての行が画面に収まるとはなく、すべての列が画面に収まるわけではないことも示しています。

00:06:34.000 --> 00:06:38.000
この場合、表示されない列がさらに10個あります。

00:06:38.000 --> 00:06:42.000
印刷は探索やデバッグに最適ですが、明らかにデータの保存には最適ではありません。

00:06:42.000 --> 00:06:47.000
DataFrameをCSVファイルとして保存する場合は、writeCSVメソッドを使用します。

00:06:47.000 --> 00:06:51.000
注意すべき重要なことの1つは、writeCSVがすべての値のデフォルトの文字列変換を使用することです。

00:06:51.000 --> 00:06:58.000
生成されたCSVは読み戻せるものではない可能性があるため、列でカスタムタイプを使用するときは注意してください。

00:06:58.000 --> 00:07:05.000
原則として、CSVに書き込むときは、列の基本的なSwiftタイプのみを使用します。これにより、一部の列を変換する必要がある場合があります。

00:07:05.000 --> 00:07:08.000
writeCSVには、読み取りオプションに似たオプションがいくつかあります。

00:07:08.000 --> 00:07:11.000
CSVデータの書き方をカスタマイズできます。

00:07:11.000 --> 00:07:16.000
以下は、カスタムnilエンコーディングとカスタム区切り文字を使用してヘッダーを無効にしている例です。

00:07:16.000 --> 00:07:20.000
特定の行にアクセスするには、行の下付き文字を使用するだけです。

00:07:20.000 --> 00:07:23.000
その後、その行の特定の列にアクセスできます。

00:07:23.000 --> 00:07:26.000
しかし、可能な限り、代わりに最初に列にアクセスし、次に行にアクセスする必要があります。

00:07:26.000 --> 00:07:28.000
これが列にアクセスする方法です。

00:07:28.000 --> 00:07:33.000
列に名前でアクセスする場合は、添字から列:ラベルを省略できます。

00:07:33.000 --> 00:07:35.000
行のサブセットにアクセスすることもできます。

00:07:35.000 --> 00:07:37.000
この場合、DataFrameスライスを取得します。

00:07:37.000 --> 00:07:40.000
DataFrameスライスはDataFrameと非常によく似ています。

00:07:40.000 --> 00:07:47.000
基本的には元のDataFrameへの参照です。ほとんどの場合、それが完全なDataFrameなのかスライスなのかを知る必要さえありません。

00:07:47.000 --> 00:07:50.000
最後に、列のサブセットを選択することもできます。

00:07:50.000 --> 00:07:53.000
これにより、これらの列のみを含む新しいDataFrameが返されます。

00:07:53.000 --> 00:07:56.000
フィルタメソッドを使用して行のサブセットを選択することもできます。

00:07:56.000 --> 00:08:00.000
フィルタ操作の結果は、行の範囲を選択するのと同様に、DataFrameスライスです。

00:08:00.000 --> 00:08:05.000
しかし、行の範囲とは異なり、フィルターは不連続な行を返すことができます。

00:08:05.000 --> 00:08:08.000
DataFrameスライスインデックスを扱うときは注意が必要です。

00:08:08.000 --> 00:08:12.000
配列スライスと同様に、そのインデックスは元の行のインデックスを反映しています。

00:08:12.000 --> 00:08:18.000
具体的には、最初のインデックスはゼロではなく、次のインデックスは現在のインデックスプラス1ではないかもしれません。

00:08:18.000 --> 00:08:27.000
文字列インデックスと同様に、ゼロの代わりにstartIndex、カウントの代わりにendIndex、1つを追加する代わりにindex(after:)を使用します。

00:08:27.000 --> 00:08:31.000
基本をカバーしたので、アプリを構築して実践してみましょう。 

00:08:31.000 --> 00:08:34.000
サンフランシスコで駐車場を見つけるのは難しいです。

00:08:34.000 --> 00:08:38.000
デビッドと私は、路上の近くの駐車場を表示するiPhoneアプリを作りたいです。

00:08:38.000 --> 00:08:44.000
市が公開したデータを使用して、現在駐車が許可されている場所の近くにあるパーキングメーターを特定したいと考えています。

00:08:44.000 --> 00:08:47.000
データセットがあることは知っていますが、何が含まれているのか正確にはわかりません。

00:08:47.000 --> 00:08:51.000
したがって、最初のステップは、私たちが持っているものを理解するためにデータセットを探索することです。

00:08:51.000 --> 00:08:53.000
デイビッドに渡します。

00:08:53.000 --> 00:08:54.000
デビッド・フィンドレー:ありがとう、アレハンドロ。

00:08:54.000 --> 00:08:57.000
こんにちは。私はフレームワークエンジニアのデビッドです。

00:08:57.000 --> 00:09:01.000
このデモでは、TabularDataを使用してデータセットを探索する方法の例を見ていきます。

00:09:01.000 --> 00:09:05.000
まず、駐車ポリシーのCSVファイルを調べます。

00:09:05.000 --> 00:09:11.000
最初のステップは、データをロードすることです。これは、ファイルのURLをDataFrame初期化子に渡すことで簡単に行うことができます。

00:09:11.000 --> 00:09:16.000
イニシャライザはスロー可能であり、潜在的な解析エラーを処理する際に有用であることに注意してください。

00:09:16.000 --> 00:09:26.000
次に、簡単なプリントで、最初の数行と列を探索できます。

00:09:26.000 --> 00:09:32.000
読み込みには数秒かかりました。これは、DataFrameが100万行と15列以上をメモリにロードしたためです。

00:09:32.000 --> 00:09:43.000
初めてデータセットを探索するときは、通常、データセット全体を必要としないので、データを読み込むときに行範囲を指定して、探索を高速化します。

00:09:43.000 --> 00:09:46.000
次に、列を見ていきます。 

00:09:46.000 --> 00:09:50.000
画面に収まらないので、そのうちの2つが右側に隠されていることに注意してください。

00:09:50.000 --> 00:09:56.000
書式設定オプションでそれを修正する方法をお見せしましょう。

00:09:56.000 --> 00:09:59.000
書式設定オプションでは、データの表示方法を設定できます。

00:09:59.000 --> 00:10:09.000
この場合、最大ライン幅を250に増やし、列の幅を15に減らし、行を5に減らして、印刷結果をスクロールするのを防ぎます。

00:10:09.000 --> 00:10:21.000
その後、説明方法を使用して、印刷ステートメントにformattingOptionsを追加するだけです。

00:10:21.000 --> 00:10:26.000
すごい！すべてのコラムを探索できるようになったので、興味深いコラムをいくつか選びます。

00:10:26.000 --> 00:10:31.000
また、列を好きな順番にリストアップして再編成する良い機会です。

00:10:31.000 --> 00:10:37.000
HourlyRate、DayOfWeek、開始時刻と終了時刻、StartDate、PostIDがあります。

00:10:37.000 --> 00:10:45.000
次に行う必要があるのは、DataFrameを読み込むときにこれらの列をパラメータとして追加することだけです。

00:10:45.000 --> 00:10:48.000
さて、これはすでに探索するのがとても簡単です。

00:10:48.000 --> 00:10:51.000
文字列型を持つStartDate列を見てみましょう。

00:10:51.000 --> 00:10:55.000
これは、ISO8601の日付のみが自動的に検出されるためです。

00:10:55.000 --> 00:10:59.000
他の日付形式を明示的に指定する必要があります。

00:10:59.000 --> 00:11:03.000
アレハンドロが先に説明したCSVReadingOptionsを使用して修正できます。

00:11:03.000 --> 00:11:07.000
Foundation Date Parsing APIを使用して、日付解析戦略を追加します。

00:11:07.000 --> 00:11:15.000
フォーマットを年、月、日、ロケールを米国英語、タイムゾーンを太平洋標準時として指定します。

00:11:15.000 --> 00:11:23.000
次に、DataFrameを読み込むときにCSVReadingOptionsを渡します。

00:11:23.000 --> 00:11:30.000
StartDate列が正しいタイプになったので、DataFrameを簡単にフィルタリングして、アクティブな駐車ポリシーのみを設定できます。

00:11:30.000 --> 00:11:37.000
現在の日付を表す変数から始めて、フィルターメソッドを使用してDataFrameをフィルタリングします。

00:11:37.000 --> 00:11:43.000
フィルタメソッドは、列名（この場合はStartDate）とタイプ（日付）を取ります。

00:11:43.000 --> 00:11:51.000
クロージャでは、オプションの日付をアンラップし、日付値がnilのときにfalseを返して、フィルター結果に表示されないようにします。

00:11:51.000 --> 00:11:55.000
そして最後に、現在の日付以下の開始日を保持します。

00:11:55.000 --> 00:12:04.000
先に進んで、印刷を変更して、フィルタリングされた結果を表示します。

00:12:04.000 --> 00:12:07.000
これからは、StartDate列は必要ないので、先に進んで削除します。

00:12:07.000 --> 00:12:11.000
しかし、DataFrameスライスから列を削除できないので、注意する必要があります。

00:12:11.000 --> 00:12:18.000
列を削除することは変異方法であるため、まずDataFrameに変換し、varのfilteredPoliciesを作成する必要があります。

00:12:18.000 --> 00:12:27.000
これで、removeColumnメソッドを使用して列を削除し、削除する列としてStartDate列を指定できます。

00:12:27.000 --> 00:12:31.000
さて、それは私が駐車ポリシーデータセットで探求したかったすべてです。

00:12:31.000 --> 00:12:36.000
次のセクションでは、アレハンドロが表データを拡張する方法について説明します。

00:12:36.000 --> 00:12:38.000
あなたに戻って、アレハンドロ!

00:12:38.000 --> 00:12:39.000
アレハンドロ:ありがとう、デビッド。

00:12:39.000 --> 00:12:41.000
今、私は今、データセットについていくつかの素晴らしい洞察を持っています。

00:12:41.000 --> 00:12:46.000
次のステップは、私たちのニーズに合わせてそれを変革し、増強することです。

00:12:46.000 --> 00:12:50.000
最も単純な種類の変換は、列内の値を変更することです。

00:12:50.000 --> 00:12:55.000
これは、各値がおそらく異なるタイプの新しい値にマッピングされるマップ操作の形をとることができます。

00:12:55.000 --> 00:13:00.000
TabularDataは、利便性としてマップのインプレースバージョンを提供します: transformColumn。

00:13:00.000 --> 00:13:06.000
この例では、DayOfWeek列を文字列から平日を表す整数に変換しています。

00:13:06.000 --> 00:13:08.000
コードはこんな感じになります。

00:13:08.000 --> 00:13:14.000
各要素について、文字列をIntに変換します。

00:13:14.000 --> 00:13:18.000
transformColumnと同様に、デコードメソッドはデータのデコードを処理します。

00:13:18.000 --> 00:13:24.000
CSVファイルを扱う場合、JSON値としてCSVに埋め込まれた配列や辞書に遭遇する可能性があります。

00:13:24.000 --> 00:13:26.000
TabularDataは、これに対するデコード方法を提供します。

00:13:26.000 --> 00:13:30.000
以下は、左側のDataFrameにJSONデータブロブが埋め込まれている例です。

00:13:30.000 --> 00:13:37.000
Decodeを使用すると、JSONDecoderを使用して列を独自のタイプに変換できます。この例では、Preferencesです。

00:13:37.000 --> 00:13:39.000
そして、これがコードがどのように見えるかです。

00:13:39.000 --> 00:13:48.000
PreferencesタイプはDecodableプロトコルに準拠する必要があり、列にはJSONDecoderが入力として期待するDataタイプの要素を含める必要があることに注意してください。

00:13:48.000 --> 00:13:51.000
もう1つの有用な操作は、塗りつぶされた方法です。

00:13:51.000 --> 00:13:54.000
列のすべての欠落値をデフォルト値に置き換えることができます。

00:13:54.000 --> 00:13:58.000
そして、列操作のリストを完成させるために、要約について言及したいと思います。

00:13:58.000 --> 00:14:01.000
要約は、列の内容の簡単な概要を提供します。

00:14:01.000 --> 00:14:03.000
サマリーメソッドは、カテゴリサマリーを返します。

00:14:03.000 --> 00:14:14.000
これには、説明にsomeCountとして表示されている要素の数、noneCountとして表示される欠落している要素の数、一意の要素の数、およびモードと呼ばれる最も頻繁な値が含まれます。

00:14:14.000 --> 00:14:18.000
numericSummaryもあり、数値を含む列でのみ使用できます。

00:14:18.000 --> 00:14:23.000
これには、カウントに加えて、平均、標準偏差、その他の統計も含まれます。

00:14:23.000 --> 00:14:25.000
ここでは、要約の印刷結果を示しています。

00:14:25.000 --> 00:14:29.000
ただし、要約構造体を直接使用して統計にアクセスすることもできます。

00:14:29.000 --> 00:14:34.000
たとえば、スコアを75パーセンタイルのスコアにフィルタリングしたい場合。

00:14:34.000 --> 00:14:38.000
さて、それは多くの列変換でしたが、列変換は最も面白くありません。

00:14:38.000 --> 00:14:41.000
DataFrame変換は、本当に面白くなるところです。

00:14:41.000 --> 00:14:45.000
列変換とは異なり、DataFrame変換は一度に複数の列を操作します。

00:14:45.000 --> 00:14:47.000
簡単な例は並べ替えです。

00:14:47.000 --> 00:14:50.000
私たちは皆、ソートがどのように機能するかを知っていますが、明確にするために説明させてください。

00:14:50.000 --> 00:14:52.000
この表をスコアで並べ替えましょう。

00:14:52.000 --> 00:14:53.000
これはすべての列に影響します。

00:14:53.000 --> 00:14:59.000
また、ソート時に行のインデックスが変更されることに注意してください。

00:14:59.000 --> 00:15:02.000
もう1つの興味深いDataFrame変換は、combineColumnsです。

00:15:02.000 --> 00:15:06.000
combineColumnsメソッドを使用すると、複数の列を1つにまとめることができます。

00:15:06.000 --> 00:15:12.000
たとえば、緯度と経度に別々の列があるが、それらをCLLocationタイプに結合したいと想像してください。

00:15:12.000 --> 00:15:14.000
これを行う例を次に示します。

00:15:14.000 --> 00:15:17.000
まず、結合する列を指定します。

00:15:17.000 --> 00:15:18.000
次に、新しい列に名前を付けます。

00:15:18.000 --> 00:15:23.000
次に、入力列と新しい列のタイプを指定し、すべてがオプションでなければならないことに注意してください。

00:15:23.000 --> 00:15:28.000
不足している値のケースを処理し、新しい値を構築します。

00:15:28.000 --> 00:15:31.000
列と同様に、DataFrameの要約メソッドもあります。

00:15:31.000 --> 00:15:33.000
すべての列の要約統計を返します。

00:15:33.000 --> 00:15:39.000
大きなDataFrameがある場合、これはコストがかかる可能性があることに注意してください。興味のある列だけを要約した方が良いかもしれません。

00:15:39.000 --> 00:15:42.000
もう一つの興味深い方法は爆発です。

00:15:42.000 --> 00:15:47.000
要素の配列を含む列を取り、配列内のすべての要素に対して新しい行を作成します。

00:15:47.000 --> 00:15:49.000
この例を見てみましょう。 

00:15:49.000 --> 00:15:53.000
今回、スコア列には、各人のスコアの埋め込み配列が含まれています。

00:15:53.000 --> 00:15:57.000
DataFrameに爆発操作を適用すると、これらのそれぞれが新しい行になります。

00:15:57.000 --> 00:16:00.000
私たちは、複数のスコアを持つ人々のために名前を繰り返しました。

00:16:00.000 --> 00:16:05.000
これは、フィルタリングしたり、個々のスコアを見る必要がある他の操作を行う場合に便利です。

00:16:05.000 --> 00:16:11.000
私たちの武器庫にあるこれらのツールで、私はそれをデビッドに戻します。デビッドは、メーターデータを必要なフォームに入れるのに役立ちます。

00:16:11.000 --> 00:16:13.000
デビッド、私たちにいくつかのコードを見せてください。

00:16:13.000 --> 00:16:14.000
デビッド:ありがとう、アレハンドロ。

00:16:14.000 --> 00:16:18.000
あなたのことは知りませんが、私にとって、駐車場の最も重要な部分は場所です。

00:16:18.000 --> 00:16:21.000
幸いなことに、私は必要なものだけを持っている別のCSVファイルを持っています。

00:16:21.000 --> 00:16:23.000
そこに何が入っているかお見せしましょう。

00:16:23.000 --> 00:16:28.000
以前と同様に、データの読み込みから始めますが、今回は興味のある列をすでに知っています。

00:16:28.000 --> 00:16:37.000
POST_ID、STREET_NAME、STREET_NUM、LATITUDE、LONGITUDEがあり、前のデモと同じフォーマットオプションを使用して結果を印刷します。

00:16:37.000 --> 00:16:44.000
私が望む最初の拡張は、緯度と経度の列をコアロケーションタイプの新しい列に組み合わせることです。

00:16:44.000 --> 00:16:47.000
combineColumnsメソッドは、その仕事に最適です。

00:16:47.000 --> 00:16:52.000
ここでは、緯度と経度の列を場所という名前の新しい列にまとめています。

00:16:52.000 --> 00:16:58.000
クロージャでは、緯度と経度のパラメータタイプとコア位置の戻り値タイプを指定します。

00:16:58.000 --> 00:17:03.000
次に、オプションの緯度と経度の値をアンラップし、どちらかがnilの場合はnilを返します。

00:17:03.000 --> 00:17:08.000
そして最後に、緯度と経度の値をコアロケーションイニシャライザに渡します。

00:17:08.000 --> 00:17:15.000
DataFrameの場所を使用して、アプリの最初の機能を構築し始めることができます。場所が与えられたら、最も近いパーキングメーターを検索します。

00:17:15.000 --> 00:17:22.000
場所、DataFrame、および検索結果に含めるパーキングメーターの量を取る closestParkingという名前の関数を書きます。

00:17:22.000 --> 00:17:24.000
ローカルコピーから始めます。

00:17:24.000 --> 00:17:30.000
そして、アレハンドロが以前に導入したtransformColumnメソッドを使用して、場所を距離に変換します。

00:17:30.000 --> 00:17:34.000
そしてもちろん、場所の列の名前を距離に変更します。

00:17:34.000 --> 00:17:40.000
最後に、距離の列を昇順に並べ替え、戻るスポットの数を制限します。

00:17:40.000 --> 00:17:44.000
楽しみのために、サンフランシスコのApple Storeでこれを試してみましょう。

00:17:44.000 --> 00:17:51.000
Apple Mapsで見つけた座標、メーターDataFrameを接続し、検索結果を5つの駐車場に制限します。

00:17:51.000 --> 00:17:56.000
完璧！ポストストリートのアップルストアの近くにたくさんの駐車場があるようです。

00:17:56.000 --> 00:18:01.000
アプリの最初の機能はうまく機能していますが、最も近い駐車場がすべてすでに取得されている場合はどうなりますか?

00:18:01.000 --> 00:18:05.000
アプリの次の機能は、駐車場が最も多い通りを見つけることです。

00:18:05.000 --> 00:18:10.000
しかし、この機能を実装する前に、グループ化と呼ばれる新しい概念を紹介しましょう。

00:18:10.000 --> 00:18:13.000
グループ化は、グループ化列を指定して、データをグループに分割します。

00:18:13.000 --> 00:18:15.000
例えば、STREET_NAME列。

00:18:15.000 --> 00:18:25.000
グループメソッドは、最初に一意の通り名の値（ポストストリート、カリフォルニアストリート、ミッションストリート）を識別し、行を対応するグループに分割します。

00:18:25.000 --> 00:18:27.000
各グループはDataFrameスライスです。

00:18:27.000 --> 00:18:30.000
では、コードに戻りましょう。

00:18:30.000 --> 00:18:34.000
グループ化された方法で通りの名前でメーターをグループ化します。

00:18:34.000 --> 00:18:39.000
その後、各ストリートグループのパーキングメーターの数を数え、結果を降順で提供できます。

00:18:39.000 --> 00:18:44.000
駐車場が最も多い通りは結果の一番上にあり、それが私のアプリに必要なものです。

00:18:44.000 --> 00:18:45.000
これはとても素晴らしいです!

00:18:45.000 --> 00:18:47.000
私のアプリの2つの素晴らしい機能。

00:18:47.000 --> 00:18:50.000
しかし、ちょっと待ってください、私はちょうど最初の機能にバグがあることに気づきました。

00:18:50.000 --> 00:18:53.000
最も近いパーキングメーターは、メーターDataFrameのみを考慮します。

00:18:53.000 --> 00:18:58.000
私が本当に必要としているのは、アクティブな駐車ポリシーを持つ最も近いパーキングメーターです。

00:18:58.000 --> 00:19:02.000
その情報はデモ1のデータにあるので、これは面白くなっています。

00:19:02.000 --> 00:19:08.000
バグを修正できるように、2つの異なるソースからデータを結合する方法をお見せしましょう。

00:19:08.000 --> 00:19:12.000
以前にリレーショナルデータベースを使用したことがある場合は、参加に精通しているかもしれません。

00:19:12.000 --> 00:19:15.000
キーを使用して2つのDataFrameを結合できます。

00:19:15.000 --> 00:19:18.000
キーは、両方のデータフレームに表示される値です。

00:19:18.000 --> 00:19:23.000
メーターとポリシーDataFramesでは、キーはパーキングメーターを一意に識別するPOST_IDです。

00:19:23.000 --> 00:19:30.000
参加操作により、メーターからのPOST_IDがポリシーからのPOST_IDと一致する行を持つDataFrameが作成されます。

00:19:30.000 --> 00:19:35.000
行は、左のDataFrameと右のDataFrameから一致するデータで構成されています。

00:19:35.000 --> 00:19:38.000
列名には左または右の接頭辞があることに注意してください。

00:19:38.000 --> 00:19:41.000
これは、列の結合のどちら側から来たかを示します。

00:19:41.000 --> 00:19:45.000
プレフィックスは、結合結果の命名衝突を避けるのに役立ちます。

00:19:45.000 --> 00:19:48.000
この操作は内部結合であり、これがデフォルトです。

00:19:48.000 --> 00:19:52.000
他にも左アウター、右アウター、フルアウターの3種類があります。

00:19:52.000 --> 00:19:56.000
ここでは詳しく説明しませんが、詳細については、ドキュメントを参照してください。 を参照してください。

00:19:56.000 --> 00:20:00.000
さて、それは私が表形式のデータ拡張でカバーしたかったすべてです。

00:20:00.000 --> 00:20:03.000
次のセクションでは、アレハンドロがベストプラクティスについて話します。

00:20:03.000 --> 00:20:05.000
アレハンドロ:ありがとう、デビッド。

00:20:05.000 --> 00:20:08.000
今、私たちは必要な形ですべてのデータを持っているので、アプリを構築する時が来ました。

00:20:08.000 --> 00:20:13.000
生産準備をしながら、探査コードを再利用する方法について話しましょう。

00:20:13.000 --> 00:20:17.000
CSVファイルを読み込むために始めたコードに戻りましょう。

00:20:17.000 --> 00:20:19.000
これを行うと、列の型が不明になります。

00:20:19.000 --> 00:20:25.000
これは、タイプを事前に知る必要があるフィルターや参加などの操作には問題があります。

00:20:25.000 --> 00:20:29.000
ユーザーが提供したソースからデータをロードする場合、タイプについて仮定することは危険です。

00:20:29.000 --> 00:20:31.000
アプリがクラッシュする可能性があります。

00:20:31.000 --> 00:20:36.000
代わりに、この例のように、データをロードするときに期待するタイプを宣言する必要があります。

00:20:36.000 --> 00:20:39.000
ここでは、気になるすべての列の列IDを定義しています。

00:20:39.000 --> 00:20:44.000
そして、列名と列タイプの両方をCSV初期化子に提供します。

00:20:44.000 --> 00:20:49.000
列を参照する任意のメソッドでは、文字列の代わりに列IDを使用できることを忘れないでください。

00:20:49.000 --> 00:20:55.000
これで、無効な値がある場合は、ユーザーにエラーを提示するなど、処理できる例外が表示されます。

00:20:55.000 --> 00:20:58.000
このようにして、あなたが期待する列と列のタイプを持っていることを確認することができます。

00:20:58.000 --> 00:21:08.000
これは、カスタム日付形式を使用する場合に特に重要です。列が日付型であることを指定しないと、日付解析が静かに失敗し、代わりに文字列列が生成される可能性があるためです。

00:21:08.000 --> 00:21:15.000
日付を強制すると、失敗したセルの内容を含む例外がスローされ、問題をデバッグするのに役立ちます。

00:21:15.000 --> 00:21:19.000
エラーといえば、これらはCSVファイルを読み込むときに予想される種類のエラーです。

00:21:19.000 --> 00:21:24.000
カスタム日付パーサーを使用すると解析に失敗し、セルが解析に失敗すると生成されます。

00:21:24.000 --> 00:21:28.000
他のものは自明ですが、ドキュメントを参照してください。

00:21:28.000 --> 00:21:31.000
そして最後に、パフォーマンスについて簡単に言及させてください。

00:21:31.000 --> 00:21:37.000
ほとんどの場合、パフォーマンスを心配する必要はありませんが、大規模なデータセットで作業するときに大きな影響を与えるケースがいくつかあります。

00:21:37.000 --> 00:21:40.000
1つ目は、CSVを読み込むときの日付解析です。

00:21:40.000 --> 00:21:45.000
日付解析には多くの特別なケースと考慮事項があり、そのため、遅くなる傾向があります。

00:21:45.000 --> 00:21:50.000
CSVファイルの読み込みに数秒以上かかる場合、これはあなたが改善するために検討すべき最初の場所です。

00:21:50.000 --> 00:21:52.000
1つの選択肢は、解析を遅らせることです。

00:21:52.000 --> 00:21:56.000
これは、すぐに日付情報を必要としない場合に特にうまく機能します。

00:21:56.000 --> 00:21:58.000
たとえば、最初にフィルタリングまたはグループ化を実行したい。

00:21:58.000 --> 00:22:04.000
それがオプションでない場合は、日付文字列のパフォーマンスを最適化する日付パーサーを手作りすることを検討してください。

00:22:04.000 --> 00:22:10.000
グループ化するときは、文字列やIntなどの基本的なSwiftタイプを含む列をグループ列として常に使用してください。

00:22:10.000 --> 00:22:12.000
これにより、グループ化のパフォーマンスが高速化されます。

00:22:12.000 --> 00:22:19.000
複数の列でグループ化する場合は、まず列を単純なタイプの単一の列に結合してからグループ化することを検討してください。

00:22:19.000 --> 00:22:25.000
たとえば、曜日とメータータイプでグループ化する場合は、これら2つのプロパティを文字列にまとめることを検討してください。

00:22:25.000 --> 00:22:26.000
例えば、デイタイプ。

00:22:26.000 --> 00:22:32.000
同様に、参加するときは、基本的なSwiftタイプを含む列で参加することを検討してください。

00:22:32.000 --> 00:22:34.000
これで、私たちはアプリを完成させる準備が整いました。

00:22:34.000 --> 00:22:36.000
デビッド、それをまとめましょう。

00:22:36.000 --> 00:22:41.000
David: TabularDataのベストプラクティスを使用して、アプリの検索機能を書きます。

00:22:41.000 --> 00:22:44.000
駐車構造体は、結合されたメーターとポリシーDataFrameを保存します。

00:22:44.000 --> 00:22:48.000
そして、複数の方法がそれを必要とするので、私は場所ColumnIDを定義しました。

00:22:48.000 --> 00:22:51.000
loadMetersメソッドの詳細を掘り下げてみましょう。

00:22:51.000 --> 00:22:57.000
上部には、メーターをロードするために必要な列IDがあります。

00:22:57.000 --> 00:23:02.000
次に、メーターをロードし、各列の予想されるタイプを指定します。

00:23:02.000 --> 00:23:06.000
これは、提供されたCSVファイルに不一致がある場合にスローされます。

00:23:06.000 --> 00:23:12.000
次に、解決された列が私が期待していたとおりであることを確認し、それ以外の場合はカスタムParkingErrorをスローします。

00:23:12.000 --> 00:23:20.000
最後に、緯度、経度、および場所の列IDを使用するようにcombineColumns操作をリファクタリングしました。

00:23:20.000 --> 00:23:22.000
それにより、アプリの検索機能は本番対応です。

00:23:22.000 --> 00:23:27.000
TabularDataフレームワークの要約のためにアレハンドロに返します。

00:23:27.000 --> 00:23:29.000
アレハンドロ:ありがとう、デビッド。要約しましょう。

00:23:29.000 --> 00:23:35.000
今日は、TabularDataが未知のデータセットを探索し、操作し、アプリに持ち込む方法を紹介しました。

00:23:35.000 --> 00:23:43.000
データセットを調査し、いくつかの列とデータ変換を調べ、エラー処理とパフォーマンスに関するいくつかのベストプラクティスを終えました。

00:23:43.000 --> 00:23:46.000
TabularDataを使って素晴らしいアプリを作る方法を見るのが待ちきれません。

00:23:46.000 --> 23:59:59.000
ありがとう！

