WEBVTT

00:00:01.000 --> 00:00:07.000
ジェイソン・フィールダー：こんにちは、私の名前はジェイソン・フィールダーで、アップルのGPUソフトウェアエンジニアリングチームに所属しています。

00:00:07.000 --> 00:00:22.000
新しいM1 ProおよびM1 Maxノートブックの素晴らしいグラフィックス処理機能を活用する方法を学び、GPUでアプリケーションを優れたパフォーマンスにするために採用できるベストプラクティスを探ります。

00:00:22.000 --> 00:00:27.000
私たちの最新のMacBook Proは、私たちがこれまでに作った中で最も強力なチップを備えています。

00:00:27.000 --> 00:00:33.000
M1 Proには最大16のGPUコアがあり、M1 Maxはそれを32に倍増します。

00:00:33.000 --> 00:00:40.000
これは、はるかに高いDRAM帯域幅と相まって、MacBook Proのパフォーマンスが大幅に向上します。

00:00:40.000 --> 00:00:53.000
システムメモリは、ユニファイドメモリアーキテクチャのおかげでGPUで利用可能になり、最大64GBが利用可能で、GPUアプリケーションはこれまで以上に多くのメモリにアクセスできます。

00:00:53.000 --> 00:01:04.000
これらのMacBook Proは、開発者やクリエイティブなプロにとって全く新しい可能性の世界を開き、以前はデスクトップマシンのみをターゲットにしていたワークフローを可能にします。

00:01:04.000 --> 00:01:07.000
では、この新しいGPUポテンシャルの世界をどのように開くのでしょうか?

00:01:07.000 --> 00:01:12.000
GPUで作業をスケジュールできるようにするMetal Computeの要約から始めます。

00:01:12.000 --> 00:01:20.000
次に、APIとGPUアーキテクチャを理解して、アプリの各段階のベストプラクティスを見ていきます。

00:01:20.000 --> 00:01:25.000
次に、適用できる特定のカーネル最適化で締めくくります。

00:01:25.000 --> 00:01:29.000
メタルコンピュートの簡単なリフレッシュから始めましょう。

00:01:29.000 --> 00:01:34.000
Metalは、GPU作業を実行するためのAppleの最新の低オーバーヘッドAPIです。

00:01:34.000 --> 00:01:41.000
できるだけ薄くて効率的であるように設計されており、統一されたグラフィックスとコンピューティングインターフェースを提供します。

00:01:41.000 --> 00:01:53.000
Metalはマルチスレッドフレンドリーで、複数のCPUスレッドから作業を簡単にキューに入れることができ、開発者がオフラインまたはオンラインのシェーダーコンパイルパイプラインを使用する柔軟性を提供します。

00:01:53.000 --> 00:01:59.000
ハードウェア層のボンネットの下には、CPUとGPUの両方が同じ物理メモリに接続されています。

00:01:59.000 --> 00:02:09.000
CPUはユニファイドメモリブロック内にGPUリソースを作成し、GPUとCPUの両方がこれらのリソースを読み書きすることができます。

00:02:09.000 --> 00:02:14.000
GPUで実行されるカーネルを見るために、いくつかのAPIレイヤーがあります。

00:02:14.000 --> 00:02:16.000
最上層はコマンドキューです。

00:02:16.000 --> 00:02:23.000
その名前の通り、このオブジェクトは、アプリケーションがGPU上のいくつかのポイントで実行のために作業をキューに入れることを可能にします。

00:02:23.000 --> 00:02:28.000
コマンドは、コマンドバッファを介してCPUにバッチ処理されます。

00:02:28.000 --> 00:02:33.000
これらのオブジェクトは一時的なものであり、アプリにとって意味のある粒度でこれらの多くを作成します。

00:02:33.000 --> 00:02:44.000
これはCPUとGPUの同期に関する要件によって課せられているかもしれませんが、要するに、GPUを完全に忙しく保つのに十分な作業を確保したいと思うでしょう。

00:02:44.000 --> 00:02:48.000
コマンドバッファに命令を入れるには、コマンドエンコーダが必要です。

00:02:48.000 --> 00:02:52.000
さまざまな種類の作業をターゲットとするコマンドエンコーダにはさまざまな種類があります。

00:02:52.000 --> 00:03:01.000
3D描画用のグラフィックエンコーダ、リソースをコピーするためのブリットエンコーダがありますが、この講演では、カーネルディスパッチ用のコンピューティングエンコーダに焦点を当てます。

00:03:01.000 --> 00:03:06.000
コンピューティングエンコーダを導入することで、カーネルディスパッチをエンコードする準備が整いました。

00:03:06.000 --> 00:03:12.000
カーネル機能自体に加えて、エンコーダはカーネルが必要とするリソースがそれにバインドされている方法です。

00:03:12.000 --> 00:03:16.000
実際、複数のカーネルディスパッチを同じエンコーダにエンコードすることができます。

00:03:16.000 --> 00:03:30.000
各ディスパッチ間でカーネルまたはバインドされたリソースを変更し、ディスパッチを同時に実行できるかどうか、または以前のディスパッチが完了した後にシリアル化して実行する必要があるかどうかをMetalに通知することもできます。

00:03:30.000 --> 00:03:41.000
エンコーディングが完了したら、エンコーダを終了し、コマンドバッファを新しいエンコーダのエンコードを開始するか、実行のためにコマンドバッファをGPUにコミットできるようにします。

00:03:41.000 --> 00:03:46.000
ここでは、合計3つのコンピューティングエンコーダをGPUにエンコードしました。

00:03:46.000 --> 00:03:52.000
これは最初から最後までの作業の本体を表しており、GPUに実行を開始するように指示する準備ができています。

00:03:52.000 --> 00:04:02.000
コミットの呼び出しはすぐに戻り、Metalは、キュー内の他のすべての作業が完了する前に、GPUで作業がスケジュールされ、実行されることを保証します。

00:04:02.000 --> 00:04:10.000
CPUスレッドは、新しいコマンドバッファの構築を開始したり、GPUがビジーしている間に適切な他のアプリ作業を実行したりできるようになりました。

00:04:10.000 --> 00:04:18.000
しかし、CPUは、結果を読み戻すことができるように、一連の作業がいつ完了したかを知る必要があるでしょう。

00:04:18.000 --> 00:04:21.000
このため、コマンドバッファには2つのテクニックがあります。

00:04:21.000 --> 00:04:29.000
ここでは、作業をコミットする前に、アプリケーションは作業が完了するとMetalによって呼び出される完了ハンドラ関数を追加できます。

00:04:29.000 --> 00:04:38.000
単純なケースでは、呼び出し元のCPUスレッドをブロックするwaitUntilCompleteという同期メソッドがありますが、ここでは非同期メソッドを使用しています。

00:04:38.000 --> 00:04:41.000
これが私たちの基本的な実行モデルです。

00:04:41.000 --> 00:04:47.000
APIの最後の機能の1つは、複数のコマンドバッファを同時にエンコードできることです。

00:04:47.000 --> 00:04:54.000
複数のCPUスレッドは、一度に複数のコマンドバッファをエンコードし、エンコードが完了したら作業をコミットできます。

00:04:54.000 --> 00:05:05.000
順序付けが重要な場合は、enqueueを呼び出してコマンドキューで実行するためにコマンドバッファの場所を予約するか、単に目的の順序でコミットを呼び出します。

00:05:05.000 --> 00:05:08.000
アプリケーションに最も適したアプローチを使用してください。

00:05:08.000 --> 00:05:20.000
複数のコマンドキューを作成する可能性もあるため、Metalの柔軟性により、アプリはニーズに最も効率的なパターンでGPUに作業をエンコードすることができます。

00:05:20.000 --> 00:05:23.000
それが、Metalが公開する実行モデルの要約です。

00:05:23.000 --> 00:05:28.000
それに基づいて、それを最適化する方法を見てみましょう。 最適化する方法を見てみましょう。

00:05:28.000 --> 00:05:45.000
ユニファイドメモリアーキテクチャを活用するためにアプリがGPUメモリにアクセスする方法、先ほどのコンピューティングモデルに合わせてGPUに作業を提出する方法、UMAと最もよく合わせるために割り当てるリソースを選択する方法について、いくつかの推奨事項があります。

00:05:45.000 --> 00:05:50.000
最初に話すのは、間違いなくユニファイドメモリアーキテクチャです。

00:05:50.000 --> 00:05:55.000
この一連のベストプラクティスは、GPUに必要な作業量を最小限に抑えることです。

00:05:55.000 --> 00:06:02.000
ユニファイドメモリアーキテクチャを使用すると、システムRAMとビデオRAM間の従来のコピー管理が廃止されます。

00:06:02.000 --> 00:06:11.000
Metalは、GPUとCPUが同じメモリを読み書きできるようにする共有リソースを通じてUMAを公開します。

00:06:11.000 --> 00:06:22.000
リソース管理とは、システムメモリとビデオメモリの間でデータを複製したりシャドウイングしたりするのではなく、CPUとGPU間のアクセスを適切なタイミングで安全に同期させることです。

00:06:22.000 --> 00:06:33.000
メモリ内のリソースの単一のインスタンスから作業すると、アプリが持つ可能性のあるメモリ帯域幅の要件が大幅に削減され、大きなパフォーマンスの向上が可能になります。

00:06:33.000 --> 00:06:45.000
GPUがまだ最初のバッチを実行している間に、CPUが2番目のバッチの作業のバッファを更新する必要があるなど、競合の可能性がある場合は、明示的なマルチバッファモデルが必要です。

00:06:45.000 --> 00:06:53.000
CPUはバッファnでコンテンツを準備し、GPUはバッファn-1から読み取り、次のバッチのnをインクリメントします。

00:06:53.000 --> 00:07:04.000
これにより、アプリ開発者としてメモリのオーバーヘッドとアクセスパターンを調整し、不要なCPU/GPUのストールやコピーを回避できます。

00:07:04.000 --> 00:07:10.000
アプリが割り当てることができるGPUリソースの量の制限には、注意すべき2つの値があります。

00:07:10.000 --> 00:07:20.000
割り当てることができるGPUリソースの総量、そしてより重要なのは、単一のコマンドエンコーダが一度に参照できるメモリの量です。

00:07:20.000 --> 00:07:24.000
この制限は、作業セットの制限として知られています。

00:07:24.000 --> 00:07:30.000
recommendedMaxWorkingSetSizeを読むことで、実行時にMetalデバイスから取得できます。

00:07:30.000 --> 00:07:37.000
使用するメモリの量を制御し、利用可能であることに頼るために、アプリでこれを使用することをお勧めします。

00:07:37.000 --> 00:07:43.000
単一のコマンドエンコーダにはこの作業制限がありますが、Metalはこれを超えてさらにリソースを割り当てることができます。

00:07:43.000 --> 00:07:55.000
Metalはこれらのリソースのレジデンシーを管理し、システムメモリの割り当てと同様に、GPUの割り当ても事実上割り当てられ、実行前に常駐します。

00:07:55.000 --> 00:08:10.000
複数のコマンドエンコーダ間でリソース使用量を分割することで、アプリケーションは作業セットサイズを超える総リソースを使用し、ハードVRAM制限に関連する従来の制約を回避できます。

00:08:10.000 --> 00:08:16.000
新しいMacBook Proの場合、GPUの作業セットのサイズをこの表に示します。

00:08:16.000 --> 00:08:32.000
現在、32GBのシステムRAMを搭載したM1 ProまたはM1 Maxの場合、GPUは21GBのメモリにアクセスでき、64GBのRAMを搭載したM1 Maxの場合、GPUは48GBのメモリにアクセスできます。

00:08:32.000 --> 00:08:42.000
これは、MacのGPUでこれまでに利用可能にした最大のメモリ量であり、新しいMacBook Proのラインナップは、ユーザーに大幅に拡張された機能を提供します。

00:08:42.000 --> 00:08:51.000
私たちは、あなたがユーザーに力を与えることができる経験を見て、彼らがそれを使って作成するものを体験することに本当に興奮しています。

00:08:51.000 --> 00:08:58.000
それがUMAと協力するためのベストプラクティスであり、次のトピックの準備ができています。

00:08:58.000 --> 00:09:02.000
コマンドバッファレベルでは、送信に待ち時間があります。

00:09:02.000 --> 00:09:06.000
少量の仕事は、働くよりも待つ時間が増える可能性があります。

00:09:06.000 --> 00:09:13.000
コミットの呼び出しを行う前に、より多くのエンコーダを各コマンドバッファにバッチ処理してください。

00:09:13.000 --> 00:09:21.000
アプリが次に何をディスパッチすべきかを知らせるためにGPUの結果を待つのに時間を費やした場合、バブルはGPUのタイムラインに表示されます。

00:09:21.000 --> 00:09:26.000
これらのバブルでは、GPUはアイドル状態になり、次のディスパッチが到着するのを待っています。

00:09:26.000 --> 00:09:33.000
これを隠すには、複数の作業で作業する複数のCPUスレッドを使用し、GPUを忙しく保つことを検討してください。

00:09:33.000 --> 00:09:40.000
複数のコマンドバッファを作成するか、複数のコマンドキューを作成します。

00:09:40.000 --> 00:09:50.000
カーネルディスパッチ自体の場合、GPUは作業するのに十分なスレッドを持ち、各スレッド内で起動のオーバーヘッドを正当化するのに十分な作業によってビジー状態が保たれます。

00:09:50.000 --> 00:09:57.000
ここの画像処理の例では、各ピクセルは1つのスレッドで処理されます。

00:09:57.000 --> 00:10:06.000
できる場合は、カーネルディスパッチの合計スレッド数を増やして、GPUのすべての処理コアを利用できるようにします。

00:10:06.000 --> 00:10:17.000
ここでは、単一のカーネルディスパッチを使用してイメージ全体を処理し、MetalとGPUが利用可能なすべての処理コアに作業を最適に分散できるようにします。

00:10:17.000 --> 00:10:25.000
最後に、スレッド数が少なくて必要な場合は、デフォルトのシリアライズモデルの代わりに同時ディスパッチモデルを使用してください。

00:10:25.000 --> 00:10:32.000
M1ではうまく動作するが、M1 ProとM1 Maxではその可能性には及ばない多くのアプリケーションを観察しました。

00:10:32.000 --> 00:10:43.000
これらの技術を使用して大量の作業を提出することは、アプリケーションが拡張し、その可能性に到達するための簡単な方法です。

00:10:43.000 --> 00:10:47.000
私が話したい次の考慮事項は、L1キャッシュです。

00:10:47.000 --> 00:10:53.000
Apple Silicon GPUには、テクスチャ読み取りとバッファ読み取り用の個別のL1キャッシュが含まれています。

00:10:53.000 --> 00:11:02.000
Metalはグラフィックスとコンピューティング全体で統一されたAPIであるため、テクスチャオブジェクトとサンプラーの完全なスイートがアプリで利用できます。

00:11:02.000 --> 00:11:10.000
したがって、アプリケーションがデータソースにバッファのみを使用している場合、これらのリソースの一部をテクスチャに移動することでパフォーマンス上の利点があります。

00:11:10.000 --> 00:11:19.000
これにより、GPUの高性能キャッシュの利用が向上し、RAMからのトラフィックが削減され、パフォーマンスが向上します。

00:11:19.000 --> 00:11:21.000
それがどのように見えるか見てみましょう。

00:11:21.000 --> 00:11:31.000
GPUはすべてのリソースの読み取りのためにRAMにアクセスしますが、同じローカルメモリ領域への将来のバッファ読み取りのパフォーマンスを向上させるためのキャッシュがあります。

00:11:31.000 --> 00:11:41.000
しかし、キャッシュはサイズが限られており、すぐにいっぱいになるため、しばらく読み込まれていない古いデータは、新しい読み取りに道を譲るために破棄されます。

00:11:41.000 --> 00:11:54.000
仮説的には、カーネルが十分に小さなデータセットで動作した場合、キャッシュが入力されると、将来のすべての読み取りがキャッシュにヒットし、システムメモリのロードが完了するのを待つことによる失速や遅延なしで完了します。

00:11:54.000 --> 00:12:02.000
キャッシュへの帯域幅は大幅に高く、システムRAMよりもレイテンシが低くなります。

00:12:02.000 --> 00:12:09.000
読み取りがキャッシュを見逃すと、読み取りがRAMからフェッチされ、キャッシュに配置されている間、呼び出しスレッドは停止します。

00:12:09.000 --> 00:12:15.000
データの読み取りは、オンチップキャッシュ帯域幅ではなく、システムメモリ帯域幅によって制限されます。

00:12:15.000 --> 00:12:22.000
バッファから大量のデータにアクセスするカーネルは、このようにキャッシュをスラッシュし、パフォーマンスを低下させる可能性があります。

00:12:22.000 --> 00:12:30.000
AppleシリコンGPUには、テクスチャ読み取り専用のバッファキャッシュと並んで2番目のキャッシュが含まれています。

00:12:30.000 --> 00:12:41.000
アプリケーションは、ソースデータの一部をMetalバッファオブジェクトからMetalテクスチャオブジェクトに移動し、キャッシュスペースの量を効果的に増やし、パフォーマンスを向上させることができます。

00:12:41.000 --> 00:12:47.000
また、テクスチャデータはねじれる可能性があり、Metalはアップロード時に自動的にこれを行います。

00:12:47.000 --> 00:12:57.000
Twiddlingは、texelsがランダムアクセスパターンに対してより最適に順序付けられ、キャッシュ効率をさらに向上させ、通常のバッファよりも別のパフォーマンス向上を与えることを意味します。

00:12:57.000 --> 00:13:03.000
これは、読み取り時にカーネルに対して透過的であるため、カーネルソースに複雑さを加えません。

00:13:03.000 --> 00:13:06.000
実際、テクスチャは与え続ける贈り物です。

00:13:06.000 --> 00:13:18.000
Apple Siliconは、テクスチャが作成された後、可能であれば、テクスチャの可逆圧縮を実行して、そこからの読み取りのメモリ帯域幅をさらに削減し、パフォーマンスを向上させることもできます。

00:13:18.000 --> 00:13:25.000
これも、テクスチャの読み取りまたはサンプルで解凍が自動的に行われるため、シェーダーカーネルに対しても透明です。

00:13:25.000 --> 00:13:41.000
Metalテクスチャは、GPUにプライベートの場合、デフォルトで圧縮されますが、共有および管理されたテクスチャは、blitコマンドエンコーダのOptimizeContentsForGPUAccessの呼び出しを介してアップロードした後、明示的に圧縮することができます。

00:13:41.000 --> 00:13:48.000
可逆テクスチャ圧縮を利用できるようにするには、テクスチャの使用法をshaiderReadまたはrenderTargetのいずれかに設定する必要があります。

00:13:48.000 --> 00:13:53.000
テクスチャオブジェクトを作成するときに、これが記述子に設定されていることを確認してください。

00:13:53.000 --> 00:14:06.000
また、テクスチャデータが実際の画像データである場合、または非可逆圧縮が許容される方法で使用されている場合は、ASTCやBCなどのより高い比率の非可逆圧縮形式を検討してください。

00:14:06.000 --> 00:14:13.000
これにより、メモリフットプリントと帯域幅の使用率の両方がさらに削減され、カーネルのパフォーマンスが向上します。

00:14:13.000 --> 00:14:25.000
BCとASTCはどちらもオフラインツールを使用して生成でき、優れた画質を提供し、圧縮率は4:1から36:1の範囲です。

00:14:25.000 --> 00:14:37.000
私たちの作業が最適にバッチ処理され、データ入力にバッファとテクスチャを利用し、UMAが実行しているコピー作業の量を減らすことを認識しているため、カーネルの最適化を検討する準備が整いました。

00:14:37.000 --> 00:14:41.000
これらのベストプラクティスはすべて、カーネルのパフォーマンスを向上させることを目的としています。

00:14:41.000 --> 00:14:44.000
それらのいくつかを見てみましょう。 それらのいくつかを見てみましょう。

00:14:44.000 --> 00:14:51.000
カーネルの機会領域として、メモリインデックス、グローバルアトミック、占有に焦点を当てます。

00:14:51.000 --> 00:15:01.000
また、カーネルのボトルネックを理解するためにプロファイリングツールのどこを見るべきか、および最適化が持つ可能性のある改善を測定する方法も見ていきます。

00:15:01.000 --> 00:15:09.000
昨年のWWDCで、当社のGPUソフトウェアチームは、Appleシリコンの金属最適化技術に関するビデオを公開しました。

00:15:09.000 --> 00:15:18.000
ここでその講演の内容を簡単に要約しますが、完全な詳細と例については、そのプレゼンテーションをご覧ください。

00:15:18.000 --> 00:15:22.000
まず、メモリインデックスについて話したいと思います。

00:15:22.000 --> 00:15:27.000
配列にインデックスを作成するときは、符号なし型よりも符号付き整数型を使用します。

00:15:27.000 --> 00:15:32.000
ここにはforループがあり、count変数iは符号なしと宣言しました。

00:15:32.000 --> 00:15:38.000
シェーダー言語仕様のuintのラッピング特性により、これはベクトル化されたロードを無効にします。

00:15:38.000 --> 00:15:45.000
通常、これはあなたが望むものではなく、生成された余分なコードは、署名されたタイプを使用することで回避できます。

00:15:45.000 --> 00:15:54.000
そしてここでは、intのラッピング動作が未定義であるため、負荷はベクトル化され、パフォーマンスが向上する可能性があります。

00:15:54.000 --> 00:16:06.000
新しいMacBook ProのGPUコアとメモリ帯域幅の増加に伴い、一部のGPUワークロードの主なボトルネックがALUまたはメモリ帯域幅の使用から他の領域に移行するのを見てきました。

00:16:06.000 --> 00:16:08.000
それらの分野の1つはグローバル原子です。

00:16:08.000 --> 00:16:17.000
私たちの推奨事項は、カーネルでのアトミック操作の使用を最小限に抑えるか、代わりにスレッドグループアトミックを中心に構築された技術を使用することです。

00:16:17.000 --> 00:16:27.000
すべての優れた最適化ワークフローと同様に、アトミックの適度な使用は問題にならないので、これがあなたが経験している問題であるかどうかを理解するために、最初にシェーダーをプロファイリングしてください。

00:16:27.000 --> 00:16:30.000
では、この重要なプロファイリング情報をどのように入手するのですか?

00:16:30.000 --> 00:16:33.000
Xcode内でGPUフレームデバッガを使用することで。

00:16:33.000 --> 00:16:36.000
これは、この評価作業のための素晴らしいツールです。

00:16:36.000 --> 00:16:43.000
これは、GPUで起こっている作業に関する豊富な洞察を提供し、キャプチャを取得すると、それを閲覧することができます。

00:16:43.000 --> 00:16:52.000
タイムラインビューは、ワークロードの概要を説明し、GPUの主要なパフォーマンスカウンターを視覚化するグラフを示しています。

00:16:52.000 --> 00:16:56.000
これらのカウンタの多くは、使用率とリミッター値の両方を与えます。

00:16:56.000 --> 00:17:07.000
ここでALUを例にとると、使用率の数字は、カーネルが実行中にGPUのALU機能の約27%を使用したことを教えてくれます。

00:17:07.000 --> 00:17:14.000
他の時間は、データの読み取りと書き込み、制御ロジックの決定など、他のタスクに費やされました。

00:17:14.000 --> 00:17:23.000
リミッターの数字は、GPUがカーネルの実行時間の約31%の間、ALU使用率によってボトルネックされていることを意味します。

00:17:23.000 --> 00:17:32.000
では、GPUはどのようにしてGPUのALU機能の27%を活用し、ALUによって31%のボトルネックになるのでしょうか？

00:17:32.000 --> 00:17:37.000
リミッターは、行われたALU作業の効率と考えることができます。

00:17:37.000 --> 00:17:43.000
これは、実際の作業に費やされた時間と、内部のストールや非効率性に費やされた時間です。

00:17:43.000 --> 00:17:47.000
最良の場合、これらの時間は等しいですが、実際には違いがあります。

00:17:47.000 --> 00:17:53.000
大きな違いは、GPUにはやるべき仕事があるが、何らかの理由でそれを行うことができないことを示しています。

00:17:53.000 --> 00:18:07.000
たとえば、log（）や高価なテクスチャ形式を使用するなどの複雑なALU操作は、活用不足になる可能性があり、カーネルの数学を最適化するための範囲がある可能性があることを意味します。

00:18:07.000 --> 00:18:17.000
これらの2つの数字は、カーネルが実行している作業の一般的な構成と、各カテゴリの作業がどれほど効率的であるかを理解するのに役立ちます。

00:18:17.000 --> 00:18:22.000
この特定のカーネルでは、占有率が37%であることがわかります。

00:18:22.000 --> 00:18:27.000
この価値は低く見え、それが増加できるかどうかを理解するために確かに調査する価値があります。

00:18:27.000 --> 00:18:31.000
占有率を詳しく見てみましょう。

00:18:31.000 --> 00:18:37.000
これは、最大値と比較して、GPUで現在アクティブなスレッドの数の尺度です。

00:18:37.000 --> 00:18:45.000
この数字が低い場合は、その理由を理解し、これが予想されるのか、それとも問題を意味するのかを判断することが重要です。

00:18:45.000 --> 00:18:55.000
たとえば、実行する作業が単に小さいため、提出された作業のスレッド数が比較的少ない場合、低占有率は驚くべきことでも回避可能でもありません。

00:18:55.000 --> 00:19:00.000
GPUがALUなどの他のカウンターによって制限されている場合も問題ありません。

00:19:00.000 --> 00:19:10.000
しかし、低リミッターカウンタと組み合わせた低占有率は、GPUが同時により多くのスレッドを実行する能力を持っていることを意味します。

00:19:10.000 --> 00:19:14.000
では、何が問題のある低占有率を引き起こしている可能性がありますか?

00:19:14.000 --> 00:19:18.000
これの一般的な理由は、スレッドまたはスレッドグループメモリの枯渇です。

00:19:18.000 --> 00:19:24.000
これらのリソースは両方ともGPU上で有限であり、実行中のスレッド間で共有されています。

00:19:24.000 --> 00:19:32.000
スレッドメモリはレジスタによってバックアップされており、レジスタの圧力が高まるにつれて、収容するために占有率を減らすことができます。

00:19:32.000 --> 00:19:39.000
スレッドグループのメモリ使用量が多いため、占有率を増やす唯一の方法は、使用される共有メモリの量を減らすことです。

00:19:39.000 --> 00:19:45.000
スレラドグループメモリを減らすことは、スレッドレジスタ圧力の影響を減らすのにも役立ちます。

00:19:45.000 --> 00:19:54.000
パイプライン状態作成時にスレッドグループの最大スレッド数がわかっている場合、コンパイラがより効率的にレジスタをこぼす余地があります。

00:19:54.000 --> 00:20:09.000
これらの最適化は、コンピューティングパイプライン状態記述子にmaxThreadsPerThreadgroupを設定するか、カーネルソースでMetal Shader langauge max_total_threads_per threadgroup属性を直接使用することで有効にできます。

00:20:09.000 --> 00:20:12.000
この値を調整して、カーネルに最適なバランスを見つけてください。

00:20:12.000 --> 00:20:20.000
アルゴリズムで動作するスレッド実行幅の最小倍数である値を目指します。

00:20:20.000 --> 00:20:23.000
レジスタ圧力を深く掘り下げてみましょう。

00:20:23.000 --> 00:20:29.000
これが高いと、XcodeのGPUプロファイラにレジスタが流出します。

00:20:29.000 --> 00:20:36.000
このカーネルの例では、稼働率が16%であることがわかりますが、これは本当に低いです。

00:20:36.000 --> 00:20:45.000
このカーネルのコンパイラ統計を見ると、こぼれたバイトを含む相対的な命令コストが示されます。

00:20:45.000 --> 00:20:50.000
この流出は、一時的な登録簿とともに、私たちの貧弱な占有の原因である可能性が高い。

00:20:50.000 --> 00:20:58.000
スレッドメモリを使い果たしており、実行されるスレッドのより多くのレジスタを解放するために占有率が削減されます。

00:20:58.000 --> 00:21:08.000
レジスタはレジスタブロックのカーネルに割り当てられるため、占有率が増加する可能性があるためには、ブロックサイズまで使用量を減らす必要があります。

00:21:08.000 --> 00:21:18.000
最小限のレジスタ使用量を最適化することは、複雑なカーネルにインパクトのあるパフォーマンスを向上させる素晴らしい方法ですが、これを行うにはどうすればよいですか?

00:21:18.000 --> 00:21:25.000
32ビットタイプよりも16ビットタイプを好むと、カーネルの他の部分で利用可能なレジスタの数が増えます。

00:21:25.000 --> 00:21:29.000
これらのタイプから32ビットのカウンターパートへの変換は通常無料です。

00:21:29.000 --> 00:21:39.000
また、大きな配列や構造体など、スタックに保存されているデータを減らすことは、多数のレジスタを消費する可能性があり、それらを減らすことは効果的なツールです。

00:21:39.000 --> 00:21:44.000
一定のアドレス空間を最大限に活用するために、シェーダー入力を調整してください。

00:21:44.000 --> 00:21:51.000
これにより、不必要に使用される汎用レジスタの数を大幅に減らすことができます。

00:21:51.000 --> 00:21:58.000
そして最後のヒントは、スタックに保存されている配列や動的インデックスを持つ定数データへのインデックス作成を避けることです。

00:21:58.000 --> 00:22:02.000
この例をここに示します。ここでは、実行時に配列が初期化されます。

00:22:02.000 --> 00:22:08.000
コンパイル時にインデックスがコンパイラに知られていない場合、配列はメモリに流出する可能性があります。

00:22:08.000 --> 00:22:17.000
しかし、この2番目の例では、インデックスはコンパイル時に知られており、コンパイラはループを展開し、流出を最適化できる可能性があります。

00:22:17.000 --> 00:22:26.000
これらの各技術は、レジスタの割り当てを減らし、流出を減らし、より高性能なカーネルの占有率を高めるのに役立ちます。

00:22:26.000 --> 00:22:37.000
Apple SiliconのMetal最適化技術に関するより多くの洞察については、WWDC 2020のビデオ「Optimize Metal Performance for Apple Silicon Macs」をご覧ください。

00:22:37.000 --> 00:22:38.000
そして、あなたはそれを持っています。

00:22:38.000 --> 00:22:41.000
今日取り上げたことを復習しましょう。

00:22:41.000 --> 00:22:58.000
私たちは、コマンドキュー、コマンドバッファ、コマンドエンコーダの役割のレビューから始めて、提出モデルと、MetalのGPUに作業がどのようにキューに入れられるかを思い出させ、CPUエンコーディング時間とコストを削減するために複数のスレッドからMetalコマンドをエンコードする方法を模索しました。

00:22:58.000 --> 00:23:15.000
その知識で、アプリケーションを調整する方法に関する推奨事項を調べました。ユニファイドメモリアーキテクチャを利用するために不要なコピーを避ける。大量の作業を提出する。カーネルのリソースにメタルテクスチャとメタルバッファを使用します。

00:23:15.000 --> 00:23:20.000
そして最後に、パフォーマンスのボトルネックを特定するためにツールを使用する方法のウォークスルーを取りました。

00:23:20.000 --> 00:23:30.000
私たちは、GPUの使用率とリミッター値を解釈する方法と、それを発見した場合に問題のある低占有率にどのように対処できるかを理解しました。

00:23:30.000 --> 23:59:59.000
ありがとうございます。これまでで最もパワフルなMacBook Proのラインナップでできることに、あなたが私と同じくらい興奮していることを願っています。

