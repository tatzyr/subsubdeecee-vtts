WEBVTT

00:00:02.000 --> 00:00:08.000
ピエール・モーフ：AppleシリコンゲームのCPUジョブスケジューリングを調整する方法に関するセッションへようこそ。

00:00:08.000 --> 00:00:12.000
私はピエール・モーフで、メタルエコシステムチームで働いています。

00:00:12.000 --> 00:00:21.000
私は、いくつかのサードパーティの開発者がAppleプラットフォームでGPUとCPUのワークロードを最適化するのを支援してきました。

00:00:21.000 --> 00:00:31.000
CoreOSチームの助けを借りて、ゲームでより良いCPUパフォーマンスと効率を達成するための情報とガイドラインをここに集めました。

00:00:31.000 --> 00:00:39.000
私たちはゲームに焦点を当てています。なぜなら、彼らは通常、ハードウェアリソースの面で非常に要求が高いからです。

00:00:39.000 --> 00:00:47.000
また、彼らの典型的なワークロードでは、すべてのフレームで数千ではないにしても数百のCPUジョブを処理する必要があります。

00:00:47.000 --> 00:00:58.000
16ミリ秒以下でそれらを行うには、ジョブを最大CPUスループットに合わせて調整し、提出オーバーヘッドを最小限に抑える必要があります。

00:00:58.000 --> 00:01:05.000
まず、AppleシリコンCPUとそのユニークなアーキテクチャの概要を説明します。

00:01:05.000 --> 00:01:13.000
次に、CPU効率を最大化するために作業を整理する方法に関する基本的なガイダンスを提供します。

00:01:13.000 --> 00:01:21.000
最後に、これらのガイドラインが実装されたら、活用するための有用なAPIについて説明します。

00:01:21.000 --> 00:01:25.000
AppleのCPUアーキテクチャから始めましょう。

00:01:25.000 --> 00:01:29.000
アップルは10年以上にわたって独自のチップを設計してきた。

00:01:29.000 --> 00:01:32.000
それらはAppleデバイスの中核です。

00:01:32.000 --> 00:01:37.000
Appleシリコンは、高いパフォーマンスと比類のない効率を提供します。

00:01:37.000 --> 00:01:40.000
昨年、AppleはM1チップを導入した。

00:01:40.000 --> 00:01:44.000
これは、Macコンピュータで利用可能になった最初のAppleシリコンチップでした。

00:01:44.000 --> 00:01:47.000
そして今年は...

00:01:47.000 --> 00:01:50.000
...M1 ProとM1 Maxを導入しました。

00:01:50.000 --> 00:01:59.000
彼らの新しいデザインは、Appleシリコンにとって大きな飛躍であり、非常に要求の厳しいワークロードに効率的に取り組むことができます。

00:01:59.000 --> 00:02:06.000
M1チップは、多くのコンポーネントを1つのパッケージに集めます。

00:02:06.000 --> 00:02:12.000
CPU、GPU、ニューラルエンジンなどが含まれています。

00:02:12.000 --> 00:02:21.000
また、高帯域幅、低遅延のユニファイドメモリも備えており、Apple Fabricを通じてすべてのチップコンポーネントにアクセスできます。

00:02:21.000 --> 00:02:27.000
つまり、CPUとGPUはコピーせずに同じデータで動作する可能性があります。

00:02:27.000 --> 00:02:31.000
CPUにズームインしましょう。

00:02:31.000 --> 00:02:40.000
M1では、CPUにはパフォーマンスコアと効率コアの2つの異なるタイプのコアが含まれています。

00:02:40.000 --> 00:02:45.000
それらは物理的に異なり、Eコアは小さくなっています。

00:02:45.000 --> 00:02:52.000
効率コアは、非常に低いエネルギー消費で作業を処理することを目的としています。

00:02:52.000 --> 00:03:02.000
非常に重要なポイントがあります。PコアとEコアは同様のマイクロアーキテクチャを使用しており、これは本当に彼らの内部作業です。

00:03:02.000 --> 00:03:09.000
これらは、開発者がスレッドがPコアまたはEコアで動作するかどうかを気にする必要がないように設計されています。

00:03:09.000 --> 00:03:18.000
プログラムがコアの種類でうまく機能するように最適化されている場合、もう一方ではうまく機能することが期待されます。

00:03:18.000 --> 00:03:25.000
これらのコアは、少なくともそのタイプに応じて、物理的にクラスターにグループ化されます。

00:03:25.000 --> 00:03:32.000
M1では、各クラスターには最後のレベルのキャッシュ（L2）があり、すべてのコアで共有されています。

00:03:32.000 --> 00:03:36.000
クロスクラスター通信はApple Fabricを経由します。

00:03:36.000 --> 00:03:42.000
ここに示されているCPUトポロジは、M1チップに固有のものです。

00:03:42.000 --> 00:03:44.000
他のデバイスはCPUレイアウトが異なる場合があります。

00:03:44.000 --> 00:03:54.000
たとえば、iPhone XSには、2つのPコアの1つのクラスターと4つのEコアの1つのクラスターがあります。

00:03:54.000 --> 00:04:06.000
このアーキテクチャにより、システムは必要に応じてパフォーマンスを最適化したり、代わりに効率を最適化したりして、パフォーマンスが優先事項ではないときにバッテリー寿命を向上させることができます。

00:04:06.000 --> 00:04:20.000
各クラスターは、現在のワークロード、そのクラスターの現在の熱圧力、およびその他の要因に応じて、独立してアクティブ化されるか、カーネルのスケジューラによって周波数が調整される場合があります。

00:04:20.000 --> 00:04:25.000
最後に、Pコアの可用性は保証されていないことに注意してください。

00:04:25.000 --> 00:04:32.000
システムは、重要な熱シナリオでそれらを利用できないようにする権利を留保します。

00:04:32.000 --> 00:04:38.000
以下は、CPUと相互作用するさまざまなAPIレイヤーの概要です。

00:04:38.000 --> 00:04:44.000
まず、XNUがあります - macOSとiOSを実行しているカーネルです。

00:04:44.000 --> 00:04:50.000
それはスケジューラが住んでいる場所であり、CPUで何がいつ実行されるかを決定します。

00:04:50.000 --> 00:04:57.000
その上、pthreadsを持つPOSIXとMachオブジェクトの2つのライブラリがあります。

00:04:57.000 --> 00:05:03.000
どちらも、アプリケーションに基本的なスレッドと同期プリミティブを提供します。

00:05:03.000 --> 00:05:07.000
その上、私たちはより高いレベルのライブラリを持っています。

00:05:07.000 --> 00:05:11.000
スレッド関連のNSObjectsはPOSIXハンドルをカプセル化します。

00:05:11.000 --> 00:05:21.000
例えば、NSLockはpthread_mutex_lockをカプセル化し、NSThreadはとりわけpthreadをカプセル化します。

00:05:21.000 --> 00:05:24.000
そこはGCDが座っている場所でもあります。

00:05:24.000 --> 00:05:26.000
GCDは高度なジョブマネージャーです。

00:05:26.000 --> 00:05:28.000
後でカバーします。

00:05:28.000 --> 00:05:36.000
このセッションでは、低レベルから始めて、API機能で仕上げます。

00:05:36.000 --> 00:05:44.000
まず、CPUに最適なものと、スケジューラに置かれた作業負荷を軽くする方法に焦点を当てましょう。

00:05:44.000 --> 00:05:48.000
これが私たちの基本的な効率ガイドラインになります。

00:05:48.000 --> 00:06:01.000
それらは、ジョブマネージャーの実装に適用され、APIに依存しず、AppleシリコンとIntelベースのMacの両方を含む多くのプラットフォームに適用されます。

00:06:01.000 --> 00:06:06.000
私たちが理想的な世界にいて、この仕事を持っていると想像してみましょう。

00:06:06.000 --> 00:06:14.000
4つのコアに広げると、正確に4倍速く処理されるはずですよね?

00:06:14.000 --> 00:06:18.000
残念ながら、それは実際のCPUではそれほど簡単ではありません。

00:06:18.000 --> 00:06:24.000
多くの簿記作業が行われており、それぞれに実行時間がかかっています。

00:06:24.000 --> 00:06:29.000
効率性のために覚えておくべき3つのコストがあるはずです。

00:06:29.000 --> 00:06:32.000
コア1、2、3を見てください。

00:06:32.000 --> 00:06:35.000
彼らは私たちの仕事を処理する前に何もしていませんでした。

00:06:35.000 --> 00:06:43.000
まあ、CPUコアがかなり長い間何もすることがない場合、エネルギーを節約するためにアイドル状態になります。

00:06:43.000 --> 00:06:48.000
そして、アイドルコアの再活性化には少し時間がかかります。

00:06:48.000 --> 00:06:53.000
それが私たちの最初のコストであり、コアウェイクアップコストです。

00:06:53.000 --> 00:06:55.000
ここに別のものがあります。

00:06:55.000 --> 00:06:59.000
CPU作業は、最初にOSスケジューラによって開始されます。

00:06:59.000 --> 00:07:03.000
次にどのプロセスとスレッドを実行するか、どのコアで実行するかを決定します。

00:07:03.000 --> 00:07:08.000
その後、CPUコアはその実行コンテキストに切り替わります。

00:07:08.000 --> 00:07:11.000
それをスケジューリングコストと呼びます。

00:07:11.000 --> 00:07:15.000
さて、3番目と最後のタイプのコスト。

00:07:15.000 --> 00:07:22.000
コア0で実行されているスレッドは、コア1、2、3で実行されているスレッドを考えてみましょう。

00:07:22.000 --> 00:07:26.000
例えば、セマフォで。

00:07:26.000 --> 00:07:28.000
そのシグナリングは瞬間的ではありません。

00:07:28.000 --> 00:07:40.000
この間隔の間、カーネルはどのスレッドがプリミティブで待機しているかを特定する必要があります。スレッドがアクティブでなかった場合は、それをスケジュールする必要があります。

00:07:40.000 --> 00:07:44.000
この遅延は同期レイテンシと呼ばれます。

00:07:44.000 --> 00:07:50.000
これらのコストは、何らかの形で、ほとんどのCPUアーキテクチャに表示されます。

00:07:50.000 --> 00:07:54.000
彼らは非常に、非常に短いので、それら自体は問題ではありません。

00:07:54.000 --> 00:08:01.000
しかし、彼らが蓄積し、繰り返し頻繁に現れると、パフォーマンスヒットになる可能性があります。

00:08:01.000 --> 00:08:06.000
それらの費用は実生活でどのように見えますか?

00:08:06.000 --> 00:08:10.000
これは、M1で実行されているゲームの楽器の痕跡です。

00:08:10.000 --> 00:08:15.000
そのゲームは問題のあるパターンを示し、そのフレームのほとんどを繰り返します。

00:08:15.000 --> 00:08:20.000
非常に細かい粒度でジョブを並列化しようとします。

00:08:20.000 --> 00:08:24.000
私たちはすでにそのタイムラインにたくさんズームしました。

00:08:24.000 --> 00:08:30.000
あなたにアイデアを与えるために、そのセクションは18マイクロ秒しかかかりません。

00:08:30.000 --> 00:08:34.000
そのCPUコアと、その2つのスレッドに焦点を当てましょう。

00:08:34.000 --> 00:08:41.000
これらの2つのスレッドは並行して実行されていた可能性がありますが、同じコアで連続して実行されることになりました。

00:08:41.000 --> 00:08:43.000
理由を見てみましょう。

00:08:43.000 --> 00:08:47.000
彼らはお互いに非常に頻繁に同期します。

00:08:47.000 --> 00:08:56.000
最初のものは、2番目のものが開始するように合図し、非常に迅速にそのピアが完了するのを待ちます。

00:08:56.000 --> 00:09:03.000
2つ目は機能し始め、すぐに最初のものに信号を送り、その後すぐに待ちます。

00:09:03.000 --> 00:09:07.000
このパターンは何度も繰り返されます。

00:09:07.000 --> 00:09:15.000
ここでは2つの問題を見ることができます。第一に、同期プリミティブは非常に高い周波数で使用されます。

00:09:15.000 --> 00:09:19.000
それは仕事を中断し、オーバーヘッドを導入します。

00:09:19.000 --> 00:09:22.000
赤いセクションでオーバーヘッドが見えます。

00:09:22.000 --> 00:09:27.000
第二に、アクティブな作業 - 青いセクション - は非常に短いです。

00:09:27.000 --> 00:09:32.000
それは4マイクロ秒から20マイクロ秒の間しか持続しません。

00:09:32.000 --> 00:09:40.000
この持続時間は非常に小さく、CPUコアを目覚めさせるのにかかる時間よりもかろうじて短いです。

00:09:40.000 --> 00:09:47.000
これらの赤いセクションの間、OSスケジューラは主にCPUコアが起動するのを待っていました。

00:09:47.000 --> 00:09:52.000
しかし、それが起こる直前に、スレッドがコアをブロックして解放します。

00:09:52.000 --> 00:10:00.000
2番目のスレッドは、別のスレッドが目を覚ますのをもう少し待つのではなく、同じコアで実行されます。

00:10:00.000 --> 00:10:05.000
これら2つのスレッドが並行して実行する小さな機会を失ったのは、その方法です。

00:10:05.000 --> 00:10:10.000
この観察から、私たちはすでに2つのガイドラインを定義することができます。

00:10:10.000 --> 00:10:13.000
まず、適切なジョブの粒度を選択します。

00:10:13.000 --> 00:10:19.000
小さな仕事をより大きな仕事にマージすることで、それを達成することができます。

00:10:19.000 --> 00:10:24.000
スレッドのスケジューリングには、何があっても少し時間がかかります。

00:10:24.000 --> 00:10:30.000
ジョブが小さくなると、スケジューリングコストはスレッドのタイムラインの比較的大きな部分を占めます。

00:10:30.000 --> 00:10:34.000
CPUは十分に活用されないだろう。

00:10:34.000 --> 00:10:39.000
それどころか、より大きな仕事は、より長く実行することでスケジューリングコストを償却します。

00:10:39.000 --> 00:10:51.000
30マイクロ秒の作業項目をたくさん提出するプロのアプリケーションを見て、それらをマージしたときのパフォーマンスを大幅に向上させました。

00:10:51.000 --> 00:10:56.000
第二に、スレッドを活用する前に十分な作業を並べます。

00:10:56.000 --> 00:11:02.000
これは、ほとんどの仕事を一度に準備することで、すべてのフレームで行うことができます。

00:11:02.000 --> 00:11:12.000
シグナルを送信してスレッドを待つとき、それは通常、いくつかはCPUコアでスケジュールされ、いくつかはブロックされ、コアから移動されることを意味します。

00:11:12.000 --> 00:11:16.000
それを何度も行うことはパフォーマンスの落とし穴です。

00:11:16.000 --> 00:11:21.000
スレッドのスリープ解除と一時停止は、先ほど話したコストが増加します。

00:11:21.000 --> 00:11:30.000
逆に、スレッドが中断することなくより多くのジョブを処理できるようにすると、同期ポイントが削除されます。

00:11:30.000 --> 00:11:40.000
例として、ネストされたforループを扱う場合、より粗い粒度で外側を並列化する方がはるかに良い考えです。

00:11:40.000 --> 00:11:43.000
これにより、内側のループは途切れません。

00:11:43.000 --> 00:11:53.000
これにより、一貫性が向上し、キャッシュ使用率が向上し、全体的に同期ポイントが少なくなります。

00:11:53.000 --> 00:11:58.000
より多くのスレッドを活用する前に、コストに見合う価値があるかどうかを判断してください。

00:11:58.000 --> 00:12:02.000
それでは、別のゲームのトレースを見てみましょう。

00:12:02.000 --> 00:12:05.000
それはiPhone XSで動いていた。

00:12:05.000 --> 00:12:09.000
私たちはそれらのヘルパースレッドに焦点を当てます。

00:12:09.000 --> 00:12:13.000
ここで同期の待ち時間を見ることができます。

00:12:13.000 --> 00:12:19.000
これは、カーネルがそれらの異なるヘルパーに信号を送るのにかかった時間です。

00:12:19.000 --> 00:12:32.000
ここには2つの問題があります。第一に、実際の作業は再び非常に小さく、約11マイクロ秒、特にオーバーヘッド全体と比較して

00:12:32.000 --> 00:12:37.000
これらの仕事を統合すれば、よりエネルギー効率が高かったでしょう。

00:12:37.000 --> 00:12:45.000
2番目の問題：その期間に、80の異なるスレッドが3つのコアにスケジュールされました。

00:12:45.000 --> 00:12:50.000
ここでは、コンテキストスイッチ、アクティブな作業間の小さなギャップを見ることができます。

00:12:50.000 --> 00:13:01.000
この例では、まだ問題ではありませんが、スレッドが増えると、コンテキストの切り替え時間が蓄積され、CPUのパフォーマンスを妨げる可能性があります。

00:13:01.000 --> 00:13:10.000
典型的なゲームがフレームごとに少なくとも何百ものジョブを持っているとき、どのようにこれらの異なる種類のオーバーヘッドを最小限に抑えることができますか?

00:13:10.000 --> 00:13:14.000
これを行う最善の方法は、ジョブプールを使用することです。

00:13:14.000 --> 00:13:19.000
労働者の糸は、仕事の盗みを通してそれらを消費します。

00:13:19.000 --> 00:13:24.000
スレッドのスケジューリングはカーネルによって行われます。時間がかかることがわかりました。

00:13:24.000 --> 00:13:28.000
また、CPUはコンテキストの切り替えなどの作業も行う必要があります。

00:13:28.000 --> 00:13:33.000
一方、ユーザースペースで新しい仕事を始める方がはるかに安いです。

00:13:33.000 --> 00:13:40.000
一般的に、ワーカーはアトミックカウンターをデクリメントし、ジョブへのポインタをつかむだけです。

00:13:40.000 --> 00:13:49.000
2番目のポイント：ワーカーを使用するとコンテキストスイッチの量が減るため、所定のスレッドとのやり取りは避けてください。

00:13:49.000 --> 00:13:57.000
そして、彼らがより多くのジョブをつかむにつれて、あなたはすでにアクティブなコアですでにアクティブなスレッドを活用します。

00:13:57.000 --> 00:14:00.000
最後に、プールを賢く使ってください。

00:14:00.000 --> 00:14:04.000
列に並んでいる仕事にちょうど十分な労働者を起こしてください。

00:14:04.000 --> 00:14:16.000
そして、前のルールはここでも当てはまります。ワーカースレッドを目覚めさせ、それを忙しく保つことを正当化するために、十分な作業が並んでいることを確認してください。

00:14:16.000 --> 00:14:22.000
オーバーヘッドを削減しました。今、CPUサイクルを最大限に活用しなければなりません。

00:14:22.000 --> 00:14:26.000
避けるべきパターンをいくつか紹介します。

00:14:26.000 --> 00:14:27.000
忙しい待ち時間を避けてください。

00:14:27.000 --> 00:14:32.000
彼らは、Pコアで何か有用なことをするのではなく、潜在的にPコアをロックします。

00:14:32.000 --> 00:14:39.000
また、スケジューラがスレッドをEからPコアに昇格させるのを防ぎます。

00:14:39.000 --> 00:14:48.000
また、エネルギーを無駄にし、不要な熱を生み出し、熱ヘッドルームを食い尽くしています。

00:14:48.000 --> 00:14:54.000
第二に、イールド関数の定義は、プラットフォームやOS間で緩いです。

00:14:54.000 --> 00:15:04.000
Appleのプラットフォームでは、「私が実行しているコアをシステム上の他のスレッド、その他のもの、優先順位が何であれ、譲渡してみてください」という意味です。

00:15:04.000 --> 00:15:08.000
現在のスレッドの優先順位を効果的にゼロにします。

00:15:08.000 --> 00:15:11.000
利回りには、システム定義の期間もあります。

00:15:11.000 --> 00:15:16.000
それは非常に長いかもしれません - 最大10ミリ秒

00:15:16.000 --> 00:15:20.000
第三に、睡眠の呼び出しも推奨されません。

00:15:20.000 --> 00:15:24.000
特定のイベントを待つ方がはるかに効率的です。

00:15:24.000 --> 00:15:31.000
また、Appleプラットフォームでは、sleep(0)は意味がなく、その呼び出しは破棄されることに注意してください。

00:15:31.000 --> 00:15:38.000
これらのパターンは、一般的に、そもそも基本的なスケジューリングエラーが発生した兆候です。

00:15:38.000 --> 00:15:45.000
代わりに、セマフォまたは条件付き変数で明示的な信号を待ちます。

00:15:45.000 --> 00:15:51.000
最終ガイドライン：CPUコア数と一致するようにスレッド数をスケーリングします。

00:15:51.000 --> 00:15:57.000
使用している各フレームワークやミドルウェアで新しいスレッドプールを再作成することは避けてください。

00:15:57.000 --> 00:16:01.000
ワークロードに基づいてスレッド数をスケーリングしないでください。

00:16:01.000 --> 00:16:06.000
ワークロードが劇的に増加すると、スレッドもカウントされます。

00:16:06.000 --> 00:16:16.000
代わりに、CPU情報を照会してスレッドプールのサイズを適切に測定し、現在のシステムの並列化の機会を最大化します。

00:16:16.000 --> 00:16:20.000
この情報を照会する方法を見てみましょう。

00:16:20.000 --> 00:16:29.000
macOS MontereyとiOS 15以降、sysctlインターフェイスでCPUレイアウトに関する高度な詳細を照会できます。

00:16:29.000 --> 00:16:40.000
すべてのCPUコアの全体的な数を取得することに加えて、マシンがnperflevelsで持っているコアの種類を照会できるようになりました。

00:16:40.000 --> 00:16:44.000
M1には、PとEの2種類のコアがあります。

00:16:44.000 --> 00:16:51.000
この範囲を使用して、コアタイプごとにデータを照会し、ゼロが最もパフォーマンスを発揮します。

00:16:51.000 --> 00:17:00.000
たとえば、perflevel{N}.logicalcpuは、現在のCPUのPコアの数を示します。

00:17:00.000 --> 00:17:02.000
これは単なる概要です。

00:17:02.000 --> 00:17:08.000
また、同じL2を共有するコアの数など、他の多くの詳細を照会することもできます。

00:17:08.000 --> 00:17:16.000
詳細については、sysctlのマニュアルページ、またはドキュメントのウェブページを参照してください。

00:17:16.000 --> 00:17:21.000
CPU使用率をプロファイリングする場合、2つのインストゥルメントトラックが非常に便利です。

00:17:21.000 --> 00:17:25.000
それらはゲームパフォーマンステンプレートで利用できます。

00:17:25.000 --> 00:17:32.000
最初のシステム負荷は、CPUコアあたりのアクティブスレッド数を提供します。

00:17:32.000 --> 00:17:36.000
2つ目はスレッドステートトレースです。

00:17:36.000 --> 00:17:44.000
デフォルトでは、詳細ペインには、スレッド状態の変更の量とプロセスごとの期間が表示されます。

00:17:44.000 --> 00:17:49.000
コンテキストスイッチビューに変更できます。

00:17:49.000 --> 00:17:55.000
これにより、選択した時間範囲内のプロセスごとのコンテキストスイッチの数が表示されます。

00:17:55.000 --> 00:18:03.000
コンテキストスイッチカウントは、アプリのスケジューリング効率を測定するのに便利な指標です。

00:18:03.000 --> 00:18:06.000
このセクションを締めくくりましょう。

00:18:06.000 --> 00:18:14.000
これらのガイドラインに従うことで、CPUを最大限に活用し、スケジューラがしなければならないことを合理化することができます。

00:18:14.000 --> 00:18:25.000
小さくて小さなジョブを長時間実行するジョブに圧縮すると、キャッシュ、プリフェッチャー、予測などのマイクロアーキテクチャ機能の利点が高まります。

00:18:25.000 --> 00:18:31.000
一度により多くのジョブを処理することは、割り込みレイテンシとコンテキストスイッチが少ないことを意味します。

00:18:31.000 --> 00:18:39.000
適切にスケーリングされたスレッドプールにより、スケジューラはEコアとPコア間の作業の再調整が容易になります。

00:18:39.000 --> 00:18:49.000
効率性とパフォーマンスのための重要なポイントは、ワークロードが広く狭くなる頻度を最小限に抑えることです。

00:18:49.000 --> 00:18:55.000
それでは、これらのガイドラインを適用しながら活用できるAPIブロックについて調べてみましょう。

00:18:55.000 --> 00:19:08.000
このセクションでは、優先順位付けとスケジューリングポリシー、同期プリミティブ、およびマルチスレッド時のメモリの考慮事項について説明します。

00:19:08.000 --> 00:19:13.000
しかし、まずはGCDをのぞき見から始めましょう。

00:19:13.000 --> 00:19:23.000
ジョブマネージャーがいなければ、または目指している高いパフォーマンスに達していない場合、GCDは素晴らしい選択です。

00:19:23.000 --> 00:19:28.000
仕事を盗むことを使った汎用のジョブマネージャーです。

00:19:28.000 --> 00:19:35.000
それはすべてのAppleプラットフォームとLinuxで利用可能で、オープンソースです。

00:19:35.000 --> 00:19:38.000
このAPIは高度に最適化されています。

00:19:38.000 --> 00:19:42.000
まず、それはすでにあなたのためのすべてのベストプラクティスに従います。

00:19:42.000 --> 00:19:47.000
第二に、それはXNUカーネルに統合されています。

00:19:47.000 --> 00:20:01.000
つまり、GCDは、現在の機械の放熱容量、P / Eコア比、現在の熱圧力など、内部の詳細を追跡する可能性があります。

00:20:01.000 --> 00:20:05.000
そのインターフェースは、シリアルおよび同時ディスパッチキューに依存しています。

00:20:05.000 --> 00:20:11.000
さまざまな優先順位で仕事をキューに入れることができます。

00:20:11.000 --> 00:20:18.000
内部的には、各ディスパッチキューは、プライベートスレッドプールから可変量のスレッドを活用します。

00:20:18.000 --> 00:20:24.000
その数は、キューの種類とジョブプロパティによって異なります。

00:20:24.000 --> 00:20:29.000
この内部スレッドプールは、プロセス全体で共有されます。

00:20:29.000 --> 00:20:36.000
つまり、特定のプロセスでは、複数のライブラリが新しいプールを再作成せずにGCDを使用できることを意味します。

00:20:36.000 --> 00:20:39.000
GCDには多くの機能があります。

00:20:39.000 --> 00:20:47.000
ここでは、それがどのように機能するかを理解するために、同時ディスパッチキューから2つの機能をすばやく確認します。

00:20:47.000 --> 00:20:55.000
最初のpatch_asyncでは、関数ポインタとデータポインタで構成されたジョブをキューに入れることができます。

00:20:55.000 --> 00:21:04.000
ジョブを開始するとき、次のジョブも処理する準備ができている場合、同時キューは追加のスレッドを活用する場合があります。

00:21:04.000 --> 00:21:09.000
これは、典型的な非同期の独立したジョブに最適なオプションです。

00:21:09.000 --> 00:21:13.000
しかし、大規模に並行する問題についてはそれほど多くはありません。

00:21:13.000 --> 00:21:18.000
その場合、dispatch_applyがあります。

00:21:18.000 --> 00:21:25.000
それは、GCDのスレッドマネージャーに過負荷をかけることなく、最初から多くのスレッドを活用します。

00:21:25.000 --> 00:21:36.000
いくつかのプロアプリがdispatch_applyを使用するために並列に移行することでパフォーマンスを向上させるのを見てきました。

00:21:36.000 --> 00:21:39.000
それはGCDの簡単な概要でした。

00:21:39.000 --> 00:21:49.000
それと避けるべきパターンの詳細については、これら2つのWWDCセッションを参照してください。

00:21:49.000 --> 00:21:53.000
それでは、カスタムジョブマネージャーに切り替えましょう。

00:21:53.000 --> 00:22:00.000
スレッドを直接操作して同期する際に最も重要なポイントを取り上げます。

00:22:00.000 --> 00:22:03.000
優先順位付けから始めましょう。

00:22:03.000 --> 00:22:10.000
前のセクションでは、ジョブを提出する際のCPU効率を高める方法を確認しました。

00:22:10.000 --> 00:22:16.000
しかし、これまでのところ、すべての仕事が平等ではないとは言っていませんでした。

00:22:16.000 --> 00:22:21.000
いくつかは時間的に重要であり、その結果はできるだけ早く必要です。

00:22:21.000 --> 00:22:25.000
そして、他のものは、次の1つか2つのフレームでのみ必要になります。

00:22:25.000 --> 00:22:36.000
したがって、より重要なものにより多くのリソースを与えるために、仕事を処理するときに重要性の感覚を伝える必要があります。

00:22:36.000 --> 00:22:40.000
これは、スレッドに優先順位を付けることで行うことができます。

00:22:40.000 --> 00:22:48.000
正しいスレッドの優先順位を設定すると、ゲームがバックグラウンドアクティビティよりも重要であることをシステムに通知します。

00:22:48.000 --> 00:22:57.000
これは、生のCPU優先値またはQoSクラスのいずれかでスレッドを設定することで実現できます。

00:22:57.000 --> 00:23:02.000
どちらの概念も関連していますが、少し異なります。

00:23:02.000 --> 00:23:09.000
生のCPU優先度は、計算スループットがどれほど重要であるかを示す整数値です。

00:23:09.000 --> 00:23:17.000
Appleのプラットフォームでは、Linuxとは対照的に、これは上昇値であり、高ければ高いほど重要になります。

00:23:17.000 --> 00:23:27.000
このCPUの優先順位は、他の要因の中でも、スレッドがPコアまたはEコアで実行されるべきかどうかを示唆しています。

00:23:27.000 --> 00:23:37.000
さて、このCPUの優先順位は、スレッドが何をしているかについて意図を与えないため、残りのシステムリソースには影響しません。

00:23:37.000 --> 00:23:45.000
代わりに、Quality of Service（略してQoS）でスレッドに優先順位を付けることができます。

00:23:45.000 --> 00:23:49.000
QoSは、スレッドにセマンティクスをアタッチするように設計されています。

00:23:49.000 --> 00:23:59.000
この意図は、スケジューラがタスクを実行するタイミングについてインテリジェントな決定を下すのに大いに役立ち、OSの応答性を高めます。

00:23:59.000 --> 00:24:06.000
たとえば、エネルギーを節約するために、重要度の低いタスクが時間内にわずかに延期される可能性があります。

00:24:06.000 --> 00:24:13.000
また、ネットワーク、ディスクアクセスなどのシステムリソースアクセスに優先順位を付けることもできます。

00:24:13.000 --> 00:24:19.000
また、省エネ機能であるタイマー合体のためのしきい値も提供します。

00:24:19.000 --> 00:24:25.000
QoSクラスには、CPUの優先順位も含まれます。

00:24:25.000 --> 00:24:36.000
最も重要でないQOS_CLASS_BACKGROUNDから、最も高いQOS_CLASS_USER_INTERACTIVEまでの5つのQoSクラスがあります。

00:24:36.000 --> 00:24:40.000
それぞれにデフォルトのCPU優先度が含まれています。

00:24:40.000 --> 00:24:46.000
オプションで、限られた範囲内でわずかにダウングレードすることができます。

00:24:46.000 --> 00:24:54.000
これは、同じQoSクラスにオプトインする複数のスレッドのCPU優先度を細かく微調整したい場合に便利です。

00:24:54.000 --> 00:25:03.000
バックグラウンドクラスには細心の注意を払う必要があります。それを使用するスレッドは、非常に長い間まったく実行されない可能性があります。

00:25:03.000 --> 00:25:10.000
したがって、全体として、ゲームは5から47の範囲のCPUの優先順位を使用します。

00:25:10.000 --> 00:25:16.000
それが実際にどのように行われるか見てみましょう。

00:25:16.000 --> 00:25:23.000
まず、デフォルト値でpthread属性を割り当てて初期化する必要があります。

00:25:23.000 --> 00:25:32.000
次に、必要なQoSクラスを設定し、それらの属性をpthread_create関数に渡します。

00:25:32.000 --> 00:25:36.000
属性構造を破壊して終了します。

00:25:36.000 --> 00:25:40.000
QoSクラスを既存のスレッドに設定することもできます。

00:25:40.000 --> 00:25:45.000
例として、その関数は呼び出しスレッドに影響します。

00:25:45.000 --> 00:25:54.000
ここでは、-5のオフセットを使用し、クラスCPUの優先度を47から42にダウングレードしました。

00:25:54.000 --> 00:25:57.000
関数名にnpサフィックスが表示されることに注意してください。

00:25:57.000 --> 00:26:05.000
それは「nonportable」の略で、Appleプラットフォーム専用の機能に使用される命名規則です。

00:26:05.000 --> 00:26:17.000
最後に、これらの関数を使用する代わりに、生のCPU優先値を直接設定する場合は、そのスレッドのQoSをオプトアウトすることに注意してください。

00:26:17.000 --> 00:26:25.000
それは永続的であり、後でそのスレッドのQoSをオプトバックすることはできません。

00:26:25.000 --> 00:26:32.000
iOSとmacOSは、ユーザー向けまたはバックグラウンドで実行されている多くのプロセスを処理します。

00:26:32.000 --> 00:26:36.000
場合によっては、システムが過負荷になる可能性があります。

00:26:36.000 --> 00:26:44.000
その場合、カーネルはすべてのスレッドがある時点で実行する機会を確保する方法が必要です。

00:26:44.000 --> 00:26:47.000
それは優先減衰で行われます。

00:26:47.000 --> 00:26:58.000
この特別なケースでは、カーネルは時間の経過とともにスレッドの優先順位をゆっくりと下げます。その後、すべてのスレッドが実行する機会があります。

00:26:58.000 --> 00:27:03.000
優先減衰は、非常に特殊なケースでは問題になる可能性があります。

00:27:03.000 --> 00:27:09.000
通常、ゲームには、メインスレッドやレンダリングスレッドなど、非常に重要なスレッドがいくつかあります。

00:27:09.000 --> 00:27:16.000
レンダリングスレッドが先取りされると、プレゼンテーションウィンドウを見逃す可能性があり、ゲームが吃音になります。

00:27:16.000 --> 00:27:22.000
そのような場合、スケジューリングポリシーで優先度減衰をオプトアウトできます。

00:27:22.000 --> 00:27:29.000
デフォルトでは、SCHED_OTHERポリシーで作成されたaをスレッド化します。

00:27:29.000 --> 00:27:31.000
これはタイムシェアリングポリシーです。

00:27:31.000 --> 00:27:36.000
それを使用するスレッドは、優先順位の減衰の対象となる可能性があります。

00:27:36.000 --> 00:27:40.000
また、以前に提示したQoSクラスとも互換性があります。

00:27:40.000 --> 00:27:46.000
一方、オプションのSCHED_RRポリシーがあります。

00:27:46.000 --> 00:27:49.000
RRは「ラウンドロビン」の略です。

00:27:49.000 --> 00:27:55.000
それをオプトインするスレッドは、優先度の減衰の影響を受けない固定の優先度を持っています。

00:27:55.000 --> 00:28:00.000
実行レイテンシの一貫性が向上します。

00:28:00.000 --> 00:28:14.000
専用のレンダリングスレッドやフレームごとのワーカースレッドなど、一貫性のある周期的で優先度の高い作業専用に設計されています。

00:28:14.000 --> 00:28:24.000
それをオプトインするスレッドは、非常に特定の時間枠で動作しなければならず、CPUの100%の時間を継続的に使用しないでください。

00:28:24.000 --> 00:28:29.000
このポリシーを使用すると、他のスレッドの飢餓につながる可能性もあります。

00:28:29.000 --> 00:28:38.000
最後に、このポリシーはQoSクラスと互換性がありません。スレッドは生のCPU優先度を使用する必要があります。

00:28:38.000 --> 00:28:41.000
これはゲームスレッドの推奨レイアウトです。

00:28:41.000 --> 00:28:51.000
まず、ゲーム内で何が優先度、中、低優先で、何がユーザーエクスペリエンスにとって重要かを定義します。

00:28:51.000 --> 00:28:59.000
優先順位で作業を分割すると、アプリケーションのどの部分が最も重要かをシステムが知ることができます。

00:28:59.000 --> 00:29:07.000
楽器を使用してゲームをプロファイリングし、実際に必要なスレッドに対してのみSCHED_RRにオプトインします。

00:29:07.000 --> 00:29:13.000
また、複数のフレームを拡張して、長時間の作業にSCHED_RRを使用しないでください。

00:29:13.000 --> 00:29:20.000
このような場合はQoSに依存して、システムが他のプロセスとパフォーマンスのバランスをとるのに役立ちます。

00:29:20.000 --> 00:29:29.000
QoSを選択するもう1つの理由は、スレッドがGCDやNSOperationQueuesなどのAppleフレームワークと対話する場合です。

00:29:29.000 --> 00:29:36.000
これらのフレームワークは、QoSクラスをジョブ発行者からジョブ自体に伝播しようとします。

00:29:36.000 --> 00:29:42.000
発行スレッドがQoSを放棄した場合、それは明らかに無視されます。

00:29:42.000 --> 00:29:50.000
優先順位に関連する最後の1つのポイントを取り上げましょう:優先順位の反転。

00:29:50.000 --> 00:29:59.000
優先度反転は、優先度の高いスレッドが失速し、優先度の低いスレッドによってブロックされたときに発生します。

00:29:59.000 --> 00:30:02.000
これは通常、相互の除外で起こります。

00:30:02.000 --> 00:30:07.000
2つのスレッドが同じリソースにアクセスしようとし、同じロックを得るために戦います。

00:30:07.000 --> 00:30:15.000
場合によっては、システムは優先度の低いスレッドをブーストすることで、この反転を解決できる場合があります。

00:30:15.000 --> 00:30:17.000
それがどのように機能するか見てみましょう。

00:30:17.000 --> 00:30:22.000
2つのスレッドを考えてみましょう。これが実行タイムラインです。

00:30:22.000 --> 00:30:29.000
この例では、青いスレッドは優先度が低く、緑のスレッドは優先度が高いです。

00:30:29.000 --> 00:30:37.000
真ん中にはロックタイムラインがあり、2つのスレッドのどちらがそのロックを所有するかを示しています。

00:30:37.000 --> 00:30:41.000
青いスレッドが実行を開始し、ロックを取得します。

00:30:41.000 --> 00:30:44.000
緑色の糸も始まります。

00:30:44.000 --> 00:30:51.000
この時点で、緑色のスレッドは、現在青いスレッドが所有しているそのロックを取得しようとします。

00:30:51.000 --> 00:30:57.000
緑色のスレッドがブロックされ、そのロックが再び利用可能になるのを待ちます。

00:30:57.000 --> 00:31:04.000
この場合、ランタイムはどのスレッドがそのロックを所有しているかを知ることができます。

00:31:04.000 --> 00:31:11.000
したがって、青いスレッドの低い優先度を高めることで、優先度の反転を解決できます。

00:31:11.000 --> 00:31:19.000
どのプリミティブが優先度反転を解決する能力を持ち、どのプリミティブが解決できないか?

00:31:19.000 --> 00:31:30.000
単一の既知の所有者を持つ対称プリミティブは、pthread_mutex_tや最も効率的なos_unfair_lockのように、それを行うことができます。

00:31:30.000 --> 00:31:43.000
Pthread条件変数やdispatch_semaphoreのような非対称プリミティブは、ランタイムがどのスレッドがそれを通知するかを知らないため、この能力を持っていません。

00:31:43.000 --> 00:31:53.000
同期プリミティブを選択するときは、この機能を念頭に置いて、相互に排他的なアクセスのために対称プリミティブを優先してください。

00:31:53.000 --> 00:32:00.000
このセクションを終わらせるために、メモリに関するいくつかの推奨事項について話し合いましょう。

00:32:00.000 --> 00:32:07.000
Objective-Cフレームワークと対話すると、一部のオブジェクトは自動リリースとして作成されます。

00:32:07.000 --> 00:32:16.000
つまり、それらはリストに追加されるため、割り当て解除は後でのみ行われます。

00:32:16.000 --> 00:32:22.000
オートリリースプールブロックは、そのようなオブジェクトを保持できる期間を制限するスコープです。

00:32:22.000 --> 00:32:28.000
アプリのピークメモリフットプリントを効果的に削減するのに役立ちます。

00:32:28.000 --> 00:32:34.000
すべてのスレッドエントリポイントに少なくとも1つの自動リリースプールを持つことが重要です。

00:32:34.000 --> 00:32:44.000
スレッドが自動解放されたオブジェクト（たとえば、Metalを介して）を操作すると、メモリリークにつながります。

00:32:44.000 --> 00:32:50.000
オートリリースプールブロックは、メモリがリサイクルされたときにより適切に制御するために、ネストすることができます。

00:32:50.000 --> 00:32:57.000
レンダリングスレッドは、理想的には、繰り返されるフレームレンダリングルーチンの周りに2番目のスレッドを作成する必要があります。

00:32:57.000 --> 00:33:08.000
ワーカースレッドは、アクティベーション時に開始し、ワーカーが駐車し、より多くの作業を待つときに閉じられる2番目のスレッドを持つ必要があります。

00:33:08.000 --> 00:33:10.000
例を見てみましょう。

00:33:10.000 --> 00:33:13.000
これはワーカースレッドのエントリポイントです。

00:33:13.000 --> 00:33:18.000
それはすぐに自動リリースプールブロックから始まります。

00:33:18.000 --> 00:33:22.000
その後、仕事が利用可能になるのを待ちます。

00:33:22.000 --> 00:33:30.000
ワーカーがアクティブになると、新しい自動リリースプールブロックを追加し、ジョブを処理するときにそれを保持します。

00:33:30.000 --> 00:33:36.000
スレッドが待って駐車しようとしているとき、私たちはネストされたプールを出ます。

00:33:36.000 --> 00:33:40.000
結論として、記憶に関する1つの簡単なヒント。

00:33:40.000 --> 00:33:49.000
パフォーマンスを向上させるために、複数のスレッドが同じキャッシュ行にあるデータを同時に書き込むことは避けてください。

00:33:49.000 --> 00:33:52.000
それは「虚偽の共有」として知られています。

00:33:52.000 --> 00:34:03.000
同じデータ構造からの複数の読み取りは問題ありませんが、このような競合する書き込みは、異なるハードウェアキャッシュ間のキャッシュラインのpingポンにつながります。

00:34:03.000 --> 00:34:08.000
Appleシリコンでは、キャッシュ行の長さは128バイトです。

00:34:08.000 --> 00:34:16.000
これに対する解決策の1つは、メモリの競合を減らすために、データ構造内にパディングを挿入することです。

00:34:16.000 --> 00:34:20.000
この最後のセクションは終わりました。

00:34:20.000 --> 00:34:21.000
締めくくりましょう。

00:34:21.000 --> 00:34:31.000
私たちは最初にAppleのCPUアーキテクチャの概要と、その画期的なデザインがどのようにそれをはるかに効率的にするかについて説明しました。

00:34:31.000 --> 00:34:41.000
次に、OSスケジューラに負荷をかけながら、CPUを効率的に供給し、スムーズに実行する方法に入りました。

00:34:41.000 --> 00:34:53.000
最後に、スレッドの優先順位付け、スケジューリングポリシー、優先順位の反転、メモリに関するヒントなど、重要なAPIの概念をレビューしました。

00:34:53.000 --> 00:35:03.000
パフォーマンスの問題を早期に発見できるように、作業負荷を監視するために、楽器でゲームを定期的にプロファイリングすることを忘れないでください。

00:35:03.000 --> 23:59:59.000
ご清聴ありがとうございました。

