WEBVTT

00:00:00.000 -> 00:00:09.000
♪ ♪

00:00:09.000 -> 00:00:15.000
こんにちは、私の名前はブレット・キーティングです。ビジョンフレームワークの新機能をご紹介できることを嬉しく思います。

00:00:15.000 -> 00:00:17.000
あなたはビジョンに不慣れかもしれません。

00:00:17.000 -> 00:00:21.000
おそらく、これはあなたがビジョンフレームワークについて見た最初のセッションです。

00:00:21.000 -> 00:00:24.000
もしそうなら、ようこそ。

00:00:24.000 -> 00:00:28.000
あなたの利益のために、ビジョンフレームワークに関するいくつかのハイライトを簡単に要約しましょう。

00:00:28.000 -> 00:00:31.000
あなたのためのいくつかのビジョンフレームワークの事実。

00:00:31.000 -> 00:00:40.000
ビジョンは2017年に初めて導入され、それ以来、ビジョンが提供する技術で何千もの素晴らしいアプリが開発されてきました。

00:00:40.000 -> 00:00:52.000
ビジョンは、時間の経過とともに成長し続けるコンピュータビジョンアルゴリズムのコレクションであり、顔検出、画像分類、輪郭検出などが含まれます。

00:00:52.000 -> 00:00:56.000
これらの各アルゴリズムは、使いやすく一貫性のあるAPIを通じて利用可能になります。

00:00:56.000 -> 00:01:01.000
ビジョンフレームワークで1つのアルゴリズムを実行する方法を知っていれば、それらをすべて実行する方法を知っています。

00:01:01.000 -> 00:01:10.000
そして、Visionは、サポートするすべてのプラットフォームでApple Siliconを最大限に活用し、Visionの多くのアルゴリズムの中核となる機械学習を強化しています。

00:01:10.000 -> 00:01:20.000
ビジョンはtvOS、iOS、macOSで利用でき、MacでApple Siliconを十分に活用します。

00:01:20.000 -> 00:01:27.000
ビジョンフレームワークへの最近の追加には、ここに示されている人セグメンテーションが含まれます。

00:01:27.000 -> 00:01:34.000
また、このデモで示されている手のポーズの見積もり。

00:01:34.000 -> 00:01:42.000
そして、これはボディポーズの推定と軌道分析を使用するアクションとビジョンのサンプルアプリです。

00:01:42.000 -> 00:01:57.000
今日の議題は、機能の向上、パフォーマンスの向上、または精度の向上を提供する可能性のある既存のリクエストの更新であるいくつかの新しいリビジョンの概要から始まります。

00:01:57.000 -> 00:02:00.000
まず、テキスト認識の新しい改訂版があります。

00:02:00.000 -> 00:02:06.000
これは、VNRecognizeTextRequestRevision3によって与えられた3回目の改訂版です。

00:02:06.000 -> 00:02:10.000
これは、素晴らしいライブテキスト機能を強化するテキストリコグナイザです。

00:02:10.000 -> 00:02:19.000
テキストリコグナイザはいくつかの言語をサポートしており、supportedRecognitionLanguagesを呼び出すことで、どの言語がサポートされているかを発見できます。

00:02:19.000 -> 00:02:23.000
私たちは今、いくつかの新しい言語を追加しました、そして私はあなたにいくつかの例を紹介します。

00:02:23.000 -> 00:02:27.000
私たちは今、ビジョンで韓国語をサポートしています。

00:02:27.000 -> 00:02:31.000
これは、韓国語の領収書を転写する職場でのビジョンの例です。

00:02:31.000 -> 00:02:40.000
そして、これは日本語の対応する例であり、この現在サポートされている言語でのVisionのテキスト認識の結果も示しています。

00:02:40.000 -> 00:02:46.000
テキスト認識のために、新しい自動言語識別があります。

00:02:46.000 -> 00:02:53.000
recognitionLanguages プロパティを使用して、使用する認識言語を指定できます。

00:02:53.000 -> 00:02:59.000
しかし、アプリユーザーが認識しようとしている可能性のある言語を事前に知らないとします。

00:02:59.000 -> 00:03:12.000
さて、正確な認識モードのためだけに、automaticDetectsLanguageをtrueに設定することで、テキストリコグナイザに言語を自動的に検出するように依頼することができます。

00:03:12.000 -> 00:03:21.000
言語検出は時折これを間違える可能性があるため、どの言語を認識すべきかわからないような状況のためだけにこれを使用するのが最善です。

00:03:21.000 -> 00:03:34.000
どの言語を認識するかについて予備知識がある場合は、これらの言語をVisionに指定し、automaticDetectsLanguageをオフにしておくのが最善です。

00:03:34.000 -> 00:03:43.000
次に、VNDetectBarcodesRequestRevision3と呼ばれるバーコード検出の新しい3番目のリビジョンがあります。

00:03:43.000 -> 00:03:49.000
この改訂は、以前の改訂から逸脱した、ボンネットの下で現代の機械学習を活用します。

00:03:49.000 -> 00:03:59.000
バーコードには、店舗の製品によく見られるバーコードから、QRコード、ヘルスケアアプリケーションで使用される特殊コードまで、さまざまなシンボルがあります。

00:03:59.000 -> 00:04:06.000
ビジョンがどのシンボルをサポートしているかを知るには、supportedSymbologiesを呼び出すことができます。

00:04:06.000 -> 00:04:08.000
パフォーマンスについて話しましょう。

00:04:08.000 -> 00:04:20.000
MLを使用していることもあり、一度に1つではなく、1つのショットで複数のコードを検出しているため、複数のコードを含む画像のリクエストが高速になります。

00:04:20.000 -> 00:04:27.000
また、精度の向上により、多くのコードを含む特定の画像でより多くのコードが検出されます。

00:04:27.000 -> 00:04:31.000
さらに、重複した検出はほとんどありません。もしあれば、

00:04:31.000 -> 00:04:39.000
バウンディングボックスは、一部のコード、特に行が以前に返されたean13などの線形コードで改善されています。

00:04:39.000 -> 00:04:45.000
これで、バウンディングボックスが表示されているコード全体を囲んでいます。

00:04:45.000 -> 00:04:56.000
最後に、MLモデルは、過去に検出精度を妨げた曲面、反射、その他のアーティファクトなどを無視することができます。

00:04:56.000 -> 00:05:11.000
テキスト認識とバーコード検出のためのこれらの新しい改訂の両方は、バーコードとテキストをスキャンして返すためにカメラストリームを設定するドロップインUI要素であるVisionKit Data Scanner APIの技術的基盤を形成します。

00:05:11.000 -> 00:05:19.000
これは私たちのSDKへの本当に素晴らしい追加であり、詳細については、それについてのセッションをチェックすることを強くお勧めします。

00:05:19.000 -> 00:05:29.000
今日お話しする最後の新しいリビジョンは、VNGenerateOpticalFlowRequestRevision2と呼ばれるオプティカルフロー要求の新しいリビジョンです。

00:05:29.000 -> 00:05:37.000
バーコード検出器と同様に、この新しいリビジョンは、ボンネットの下で最新の機械学習も使用しています。

00:05:37.000 -> 00:05:48.000
光学フローは最も長く研究されたコンピュータビジョンの問題の1つですが、テキストやバーコードなど、私たちの日常生活の一部を形成するものの検出と比較して、それが何をするのか気づいていないかもしれません。

00:05:48.000 -> 00:05:54.000
オプティカルフローは、2つの連続した画像、通常はビデオからのフレームを分析します。

00:05:54.000 -> 00:06:04.000
ユースケースによっては、2つの隣接するフレーム間の動きを見たり、その間にいくつかのフレームをスキップしたりするかもしれませんが、いずれにせよ、2つの画像は時系列順にする必要があります。

00:06:04.000 -> 00:06:17.000
この分析は、動きの方向と大きさ、または第2の画像に正しく配置するために、いわば最初の画像のどれだけの部分を「移動」する必要があるかの推定値を提供します。

00:06:17.000 -> 00:06:23.000
VNPixelBufferObservationは、画像内のすべての場所でこの動きを表す結果です。

00:06:23.000 -> 00:06:25.000
それは2チャンネルの画像です。

00:06:25.000 -> 00:06:30.000
1つのチャネルにはX等級が含まれ、もう1つのチャネルにはY等級が含まれています。

00:06:30.000 -> 00:06:41.000
一緒に、これらはこの2D画像に配置された各ピクセルで2Dベクトルを形成し、その位置が入力として提供された画像の対応する場所にマップされるようにします。

00:06:41.000 -> 00:06:43.000
これを視覚的に見てみましょう。

00:06:43.000 -> 00:06:50.000
着信ビデオがあり、いくつかのフレームが入ってくるとしますが、特にこの2つの画像を見てみましょう。

00:06:50.000 -> 00:06:52.000
ここでは、ビーチで走っている犬がいます。

00:06:52.000 -> 00:06:57.000
左の画像から右の画像へ、犬が少し左に移動したようです。

00:06:57.000 -> 00:07:01.000
この動議をどのように推定し、表現しますか?

00:07:01.000 -> 00:07:05.000
さて、あなたはオプティカルフローを実行し、下の画像に似た何かに到達するでしょう。

00:07:05.000 -> 00:07:12.000
暗い領域は動きが見つかった場所であり、それが実際に犬の形にそそのように見えることに注目してください。

00:07:12.000 -> 00:07:16.000
それは、このシーンで犬だけが本当に動いているからです。

00:07:16.000 -> 00:07:23.000
ベクトルからx、yをカラーパレットにマップする「偽色」を使用して、この画像のモーションベクトルを示しています。

00:07:23.000 -> 00:07:30.000
この偽の色の表現では、「赤」の色合いは主に左への動きを示しています。

00:07:30.000 -> 00:07:36.000
1つのフレームから例を見たので、ビデオクリップ全体でどのように見えるかを見てみましょう。

00:07:36.000 -> 00:07:42.000
ここでは、ビーチで水筒を取ってくるこの犬の短いクリップの光学的流れを計算します。

00:07:42.000 -> 00:07:45.000
左側はリビジョン1の結果です。

00:07:45.000 -> 00:07:49.000
右側は、新しいMLベースのリビジョン2の結果です。

00:07:49.000 -> 00:07:52.000
うまくいけば、リビジョン2の改善のいくつかは明らかです。

00:07:52.000 -> 00:07:58.000
一つには、おそらく最も明らかに、水筒の動きははるかに正確にキャプチャされます。

00:07:58.000 -> 00:08:03.000
また、犬の推定運動の一部の改善に気づくかもしれません。

00:08:03.000 -> 00:08:10.000
私は尾の改善に最もはっきりと気づきますが、新しい改訂で彼の耳の動きが羽ばたきしているのも見ることができます。

00:08:10.000 -> 00:08:17.000
最初のリビジョンには少しのバックグラウンドノイズの動きも含まれていますが、2番目のリビジョンは背景が動いていないことをより一貫して表しています。

00:08:17.000 -> 00:08:21.000
うまくいけば、その例は、この技術が何をするかをあなたに良いアイデアを与えてくれました。

00:08:21.000 -> 00:08:25.000
では、アプリでどのように使用するかについて少し掘り下げてみましょう。

00:08:25.000 -> 00:08:29.000
明らかに、主なユースケースは、ビデオで局所的な動きを発見することです。

00:08:29.000 -> 00:08:44.000
これは、セキュリティビデオのユースケースに直接フィードされ、バックグラウンドから逸脱した動きを特定してローカライズすることが最も重要であり、オプティカルフローはほとんどのセキュリティカメラなどの固定カメラに最も適していることに言及する必要があります。

00:08:44.000 -> 00:08:51.000
Visionのオブジェクトトラッカーを使用して、ビデオ内で移動しているオブジェクトを追跡したい場合がありますが、トラッカーを初期化する場所を知る必要があります。

00:08:51.000 -> 00:08:54.000
オプティカルフローはそこでもあなたを助けることができます。

00:08:54.000 -> 00:09:03.000
独自のコンピュータビジョンや画像処理に精通している場合は、当社のオプティカルフロー結果を活用して、さらなるビデオ処理を可能にすることができます。

00:09:03.000 -> 00:09:10.000
ビデオ補間、またはビデオアクション分析は、オプティカルフローが提供する情報から大きな利益を得ることができます。

00:09:10.000 -> 00:09:16.000
それでは、リビジョン1とリビジョン2の重要な追加の違いを掘り下げてみましょう。

00:09:16.000 -> 00:09:22.000
リビジョン1は、常に入力と同じ解像度の光フローフィールドを返します。

00:09:22.000 -> 00:09:25.000
リビジョン2もデフォルトでこれを行います。

00:09:25.000 -> 00:09:36.000
しかし、小さなしわがあります。部分的には、リビジョン2がMLベースであるという事実のために、基礎となるモデルの出力は、ほとんどの入力画像解像度と比較して比較的低い解像度です。

00:09:36.000 -> 00:09:45.000
したがって、リビジョン1のデフォルトの動作に一致させるには、いくつかのアップサンプリングを行う必要があり、これを行うにはバイリニアアップサンプリングを使用しています。

00:09:45.000 -> 00:09:48.000
これは、アップサンプリングが何をするかを説明する視覚的な例です。

00:09:48.000 -> 00:09:55.000
左側には、ネットワーク出力のズームイン部分があり、これは低解像度であるため、ピクセル化されているように見えます。

00:09:55.000 -> 00:10:00.000
全体的なフローフィールドのアスペクト比は7:5である可能性があります。

00:10:00.000 -> 00:10:06.000
右側には、同じフィールドから取得した同様の領域があり、元の画像解像度にアップサンプリングされています。

00:10:06.000 -> 00:10:11.000
おそらく、その画像も異なるアスペクト比を持っています、16:9としましょう。

00:10:11.000 -> 00:10:18.000
フローフィールドのエッジがバイリニアアップサンプリングによって平滑化されていることに気付くでしょう。

00:10:18.000 -> 00:10:30.000
アスペクト比が異なる可能性があるため、アップサンプリングプロセスの一環として、フローフィールドを画像で何が起こっているかに適切に対応するために、フロー画像が引き伸ばされることに注意してください。

00:10:30.000 -> 00:10:41.000
ネットワーク出力を直接操作する場合は、フロー結果を元の画像にマッピングするときに、同様の方法で解像度とアスペクト比を考慮する必要があります。

00:10:41.000 -> 00:10:47.000
リクエスト時にKeepNetworkOutputをオンにすることで、アップサンプリングをスキップするオプションがあります。

00:10:47.000 -> 00:10:50.000
これにより、生のモデル出力が得られます。

00:10:50.000 -> 00:10:57.000
利用可能な出力解像度を選択するために、リクエストに適用できる4つのcomputationAccuracy設定があります。

00:10:57.000 -> 00:11:06.000
この表では、各精度設定の解像度を確認できますが、オブザベーションに含まれるピクセルバッファの幅と高さを常に確認してください。

00:11:06.000 -> 00:11:10.000
いつネットワーク出力を使用し、いつVisionをアップサンプリングできるようにする必要がありますか?

00:11:10.000 -> 00:11:17.000
デフォルトの動作は、すでにオプティカルフローを使用していて、その動作を下位互換性を維持したい場合に最適です。

00:11:17.000 -> 00:11:24.000
アップサンプリング出力が必要な場合は良い選択肢であり、バイリニアは許容され、追加のメモリとレイテンシの価値があります。

00:11:24.000 -> 00:11:33.000
ネットワーク出力は、完全な解像度を必要とせず、その場で対応を形成することができる場合、またはトラッカーを初期化したい場合に最適です。

00:11:33.000 -> 00:11:40.000
フル解像度のフローが必要な場合は、ネットワーク出力も正しい選択かもしれませんが、独自のアップサンプリング方法を使用することを好みます。

00:11:40.000 -> 00:11:44.000
これは、このセッションの新しいアルゴリズムの改訂をカバーしています。

00:11:44.000 -> 00:11:50.000
ビジョンフレームワークで行っている春の大掃除と、それがあなたにどのような影響を与えるかについて話し合いましょう。

00:11:50.000 -> 00:11:59.000
ビジョンが5年前に最初にリリースされたときに、各アルゴリズムの「リビジョン1」として、顔検出と顔のランドマークを最初に導入しました。

00:11:59.000 -> 00:12:06.000
それ以来、より効率的で正確な技術を使用する2つの新しいリビジョンをリリースしました。

00:12:06.000 -> 00:12:15.000
したがって、これらのアルゴリズムの最初のリビジョンをVisionフレームワークから削除し、2番目と3番目のリビジョンのみを維持します。

00:12:15.000 -> 00:12:18.000
ただし、リビジョン1を使用する場合は、恐れることはありません。

00:12:18.000 -> 00:12:26.000
リビジョン1を指定するコード、またはリビジョン1のみを含むSDKに対してコンパイルされたコードを引き続きサポートします。

00:12:26.000 -> 00:12:28.000
どうしてそんなことが可能なの、あなたは尋ねるかもしれません。

00:12:28.000 -> 00:12:36.000
リビジョン1は、この図で「リビジョン1検出器」と呼んだアルゴリズムをボンネットの下で実行します。

00:12:36.000 -> 00:12:40.000
同様に、リビジョン2はリビジョン2検出器を使用します。

00:12:40.000 -> 00:12:48.000
ビジョンのこのリリースのために行ったことは、リビジョン2検出器の出力でリビジョン1の要求を満たすことです。

00:12:48.000 -> 00:12:52.000
さらに、リビジョン1のリクエストは非推奨としてマークされます。

00:12:52.000 -> 00:12:59.000
これにより、古いリビジョン1検出器を完全に削除し、ビジョンフレームワークを合理化することができます。

00:12:59.000 -> 00:13:09.000
これにはいくつかの利点があり、少なくともディスクのスペースを節約することで、OSのリリースとSDKのダウンロードとインストールが安価になります。

00:13:09.000 -> 00:13:18.000
そこにいるすべてのビジョンの専門家は、「しかし、ちょっと待ってください」と自分自身に言っているかもしれません。リビジョン2は逆さまの顔を返しますが、リビジョン1はそうではありません。

00:13:18.000 -> 00:13:21.000
この行動の違いは、いくつかのアプリに影響を与えませんでしたか?

00:13:21.000 -> 00:13:27.000
リビジョン1の行動を維持するための予防措置を講じることを除いて、それは確かにそうするでしょう。

00:13:27.000 -> 00:13:32.000
リビジョン2検出器から逆さまの面を返すことはありません。

00:13:32.000 -> 00:13:40.000
同様に、リビジョン2のランドマーク検出器は、リビジョン1のランドマークコンステレーションと一致する結果を返します。

00:13:40.000 -> 00:13:45.000
実行時間は同等であり、精度の向上を経験するはずです。

00:13:45.000 -> 00:13:54.000
いずれにせよ、この変更は、アプリがコードに変更を加える必要はなく、物事は引き続き機能します。

00:13:54.000 -> 00:13:57.000
それでも、私たちはあなたのために行動を促す呼びかけがあります。

00:13:57.000 -> 00:14:02.000
はるかに優れたオプションが利用可能な場合、リビジョン1を使用することに満足すべきではありません。

00:14:02.000 -> 00:14:08.000
常に最新のリビジョンを使用することをお勧めします。これらのリクエストについては、リビジョン3になります。

00:14:08.000 -> 00:14:18.000
もちろん、この推奨事項の主な理由は、利用可能な最高レベルの精度とパフォーマンスを提供する最新の技術を使用することであり、誰がそれを望んでいませんか?

00:14:18.000 -> 00:14:31.000
さらに、私たちは何度か確立し、コミュニケーションをとっており、デフォルトの動作に頼るのではなく、常にリビジョンを明示的に指定するベストプラクティスをここで繰り返します。

00:14:31.000 -> 00:14:34.000
そして、それが私たちが春の大掃除のためにやったことです。

00:14:34.000 -> 00:14:38.000
それでは、Visionフレームワークを使用するアプリのデバッグを容易にした方法について話しましょう。

00:14:38.000 -> 00:14:41.000
ビジョンにクイックルックプレビューのサポートを追加しました。

00:14:41.000 -> 00:14:44.000
これは特にビジョンにとって何を意味しますか?

00:14:44.000 -> 00:14:52.000
さて、デバッガでVNObservationsにマウスポインタを合わせることができ、ワンクリックで入力画像で結果を視覚化できます。

00:14:52.000 -> 00:14:55.000
また、これをXcode Playgroundsでも利用できるようにしました。

00:14:55.000 -> 00:15:00.000
これがあなたのデバッグにどのように役立つかを本当に説明する唯一の方法は、あなたに示すことだと思います。

00:15:00.000 -> 00:15:04.000
Xcodeのデモに移りましょう。

00:15:04.000 -> 00:15:11.000
ここでは、顔のランドマークを検出し、顔の観察を返す簡単なルーチンがあります。

00:15:11.000 -> 00:15:15.000
まず、顔のランドマークのリクエストを設定します。

00:15:15.000 -> 00:15:20.000
その後、クラスで行く準備ができている画像があれば、それを表示します。

00:15:20.000 -> 00:15:26.000
次に、結果を保持する配列を宣言します。

00:15:26.000 -> 00:15:34.000
オートリリースプール内では、そのイメージでリクエストハンドラをインスタンス化し、リクエストを実行します。

00:15:34.000 -> 00:15:39.000
すべてがうまくいったと仮定すると、リクエストから結果を取得できます。

00:15:39.000 -> 00:15:44.000
結果を取得した後、それを実行してブレークポイントにたどり着きます。

00:15:44.000 -> 00:15:45.000
だから今、私はデバッガの中にいます。

00:15:45.000 -> 00:15:50.000
結果にマウスポインタを合わせると、オーバーレイは3つの顔を検出したことを示しています。

00:15:50.000 -> 00:15:53.000
それはすごい。入力画像には3つの顔があります。

00:15:53.000 -> 00:15:56.000
しかし、どの観察がどの顔であるかをどうやって知ることができますか?

00:15:56.000 -> 00:15:59.000
そこで、クイックルックプレビューのサポートが登場します。

00:15:59.000 -> 00:16:07.000
このリクエストに入ると、各「目」アイコンをクリックして結果を視覚化できます。

00:16:07.000 -> 00:16:15.000
画像は、ランドマークの星座と顔の境界ボックスのために描かれたオーバーレイで表示されます。

00:16:15.000 -> 00:16:19.000
これで、最初の観察が画像のどこにあるかがわかりました。

00:16:19.000 -> 00:16:27.000
次のものをクリックして、2回目の観察と3回目の観察のオーバーレイを描くことができます。

00:16:27.000 -> 00:16:34.000
次のブレークポイントに進み、フェイスオブザベーションをデバッグコンソールに出力するコードを実行します。

00:16:34.000 -> 00:16:48.000
ご想像のとおり、顔情報が印刷されているデバッグコンソールでは、どの顔がどの顔であるか、またはこれらの印刷された座標からの結果が正しいように見えるかどうかをすぐに視覚化することはかなり困難です。

00:16:48.000 -> 00:16:51.000
しかし、ここで指摘すべきことがもう1つあります。

00:16:51.000 -> 00:16:57.000
自動リリースプールを導入することで、リクエストハンドラーを人為的にスコープから追い出したことに注意してください。

00:16:57.000 -> 00:17:03.000
リクエストハンドラが範囲外になったので、結果にクイックルックプレビューのサポートをもう一度使用しましょう。

00:17:03.000 -> 00:17:09.000
さて、あなたは何を知っていますか、オーバーレイはまだ描かれていますが、画像は利用できません。

00:17:09.000 -> 00:17:21.000
これは覚えておくべきことです。オブザベーションを生成するために使用された画像要求ハンドラは、クイックルックプレビューが元の画像を表示に使用するために、まだどこかの範囲内にある必要があります。

00:17:21.000 -> 00:17:25.000
これは、画像要求ハンドラが入力画像が存在する場所であるためです。

00:17:25.000 -> 00:17:28.000
物事は引き続き機能しますが、画像は利用できません。

00:17:28.000 -> 00:17:37.000
このクイックルックプレビューのサポートは、物事がどのように機能するかを確認するための簡単な実験を行いながら、Xcode Playgroundsセッションで特に役立ちます。

00:17:37.000 -> 00:17:40.000
今、それを見てみましょう。 

00:17:40.000 -> 00:17:44.000
ここでは、バーコードの画像を分析するためのシンプルなプレイグラウンドが設定されています。

00:17:44.000 -> 00:17:50.000
このコードを通過するのではなく、いくつかの変更を加え、それが結果にどのように影響するかを確認しましょう。

00:17:50.000 -> 00:17:56.000
異なるシンボルの2つのバーコードを持つ画像にリビジョン2を使用することから始めます。

00:17:56.000 -> 00:18:04.000
すべての結果を要求すると、すべての結果が一度に表示され、最初の結果も最後に表示されます。

00:18:04.000 -> 00:18:07.000
リビジョン2にはいくつかの問題があることに注意してください。

00:18:07.000 -> 00:18:10.000
まず、最初のバーコードを見逃しました。

00:18:10.000 -> 00:18:13.000
また、2番目のバーコードを2回検出しました。

00:18:13.000 -> 00:18:19.000
そして、完全なバウンディングボックスではなく、バーコードを通る線を提供します。

00:18:19.000 -> 00:18:26.000
リビジョン2ではなく、リビジョン3に変更するとどうなりますか？

00:18:26.000 -> 00:18:28.000
まず、両方のバーコードを検出します。

00:18:28.000 -> 00:18:33.000
そして、線の代わりに、完全なバウンディングボックスが与えられます。

00:18:33.000 -> 00:18:41.000
このクイックルックプレビューサポートの素晴らしいところは、結果を視覚化するためにさまざまなユーティリティ関数を書く必要がなくなってきたことです。

00:18:41.000 -> 00:18:49.000
デバッガまたはXcode Playgroundで画像に直接オーバーレイできます。

00:18:49.000 -> 00:18:54.000
それがビジョンのクイックルックプレビューサポートです。

00:18:54.000 -> 00:18:58.000
これで、どの観察がどれであるかをより簡単に知ることができます。

00:18:58.000 -> 00:19:08.000
入力画像で使用するには、イメージリクエストハンドラをスコープ内に保つようにしてください。Xcode Playgroundのサポートにより、Visionフレームワークコードのライブチューニングがはるかに簡単になることを願っています。

00:19:08.000 -> 00:19:11.000
本日、ビジョンの重要なアップデートを取り上げました。

00:19:11.000 -> 00:19:21.000
すばやく確認するために、テキスト認識、バーコード検出、および光フローにいくつかの素晴らしい新しい改訂を追加しました。

00:19:21.000 -> 00:19:30.000
更新されたリビジョンを追加し続けるにつれて、古いリビジョンも削除しますので、リビジョンを最新の状態に保ち、最新かつ最高の技術を使用してください。

00:19:30.000 -> 00:19:36.000
また、今年はクイックルックプレビューのサポートにより、Visionアプリケーションのデバッグがはるかに簡単になりました。

00:19:36.000 -> 23:59:59.000
このセッションを楽しんで、素晴らしいWWDCをお過ごしください。♪ ♪

