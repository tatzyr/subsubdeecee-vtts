WEBVTT

00:00:00.000 -> 00:00:09.000
♪ ♪

00:00:09.000 -> 00:00:12.000
Dhruva: WWDC 2022へようこそ。

00:00:12.000 -> 00:00:16.000
私の名前はDhruvaで、GPUSWエンジニアです。

00:00:16.000 -> 00:00:25.000
今日、マッテオと私は、メタルで今年機械学習のために導入されたすべての新機能と機能強化を探ります。

00:00:25.000 -> 00:00:31.000
機械学習トレーニングは、MLパイプラインの最も計算集約的なプロセスです。

00:00:31.000 -> 00:00:37.000
並行性のため、GPUはMLワークロードに優れています。

00:00:37.000 -> 00:00:44.000
メタル機械学習APIは、メタルパフォーマンスシェーダー、またはMPSと呼ばれるフレームワークを通じて公開されます。

00:00:44.000 -> 00:00:56.000
MPSは、画像処理、線形代数、レイトレーシング、機械学習など、さまざまな分野の高性能GPUプリミティブのコレクションです。

00:00:56.000 -> 00:01:02.000
これらのメタルカーネルは、すべてのプラットフォームで最高のパフォーマンスを提供するために最適化されています。

00:01:02.000 -> 00:01:08.000
たとえば、MPSImageCannyフィルターは、入力画像のエッジマップを返します。

00:01:08.000 -> 00:01:12.000
これは、画像セグメンテーションアプリケーションで一般的な操作です。

00:01:12.000 -> 00:01:21.000
今年、Cannyフィルターは4Kの高解像度画像を最大8倍の速さで処理できます。

00:01:21.000 -> 00:01:32.000
MPSグラフは、MPSフレームワークの上にあり、多次元テンソルへのサポートを拡張するGPUの汎用計算グラフです。

00:01:32.000 -> 00:01:38.000
MPSグラフの使い方の詳細については、前のセッションを見ることをお勧めします。

00:01:38.000 -> 00:01:45.000
CoreMLやTensorflowのような高レベルのMLフレームワークは、MPSグラフの上にあります。

00:01:45.000 -> 00:01:51.000
TensorFlow Metalプラグインを使用して、GPU上でTensorFlowネットワークを高速化できます。

00:01:51.000 -> 00:01:57.000
TensorFlowを最大限に活用する方法の詳細については、昨年のセッションをご覧ください。

00:01:57.000 -> 00:02:01.000
Matteoと私はこのセッションで取り上げる3つのトピックがあります。

00:02:01.000 -> 00:02:07.000
まず、Apple GPUに搭載される最新のMLフレームワーク、PyTorchを紹介します。

00:02:07.000 -> 00:02:14.000
次に、今年のTensorFlowの機能強化について詳しく説明します。

00:02:14.000 -> 00:02:20.000
最後に、マッテオはMPSグラフフレームワークの新機能について話します。

00:02:20.000 -> 00:02:27.000
Mac GPUでPyTorchネットワークを高速化できることに本当に興奮しています。

00:02:27.000 -> 00:02:32.000
PyTorchは、人気のあるオープンソースの機械学習フレームワークです。

00:02:32.000 -> 00:02:41.000
PyTorchコミュニティで最も要求された機能の1番は、AppleシリコンでのGPUアクセラレーションのサポートでした。

00:02:41.000 -> 00:02:50.000
PyTorchエコシステムに新しいMPSバックエンドを導入することで、MetalのパワーをPyTorchにもたらしています。

00:02:50.000 -> 00:02:56.000
このバックエンドは、公式のPyTorch 1.12リリースの一部になります。

00:02:56.000 -> 00:03:02.000
MPSバックエンドは、PyTorch操作カーネルとランタイムフレームワークを実装しています。

00:03:02.000 -> 00:03:10.000
操作はMPSグラフとMPSを呼び出し、ランタイムコンポーネントはMetalを使用します。

00:03:10.000 -> 00:03:22.000
これにより、PyTorchは、Metalのコマンドキュー、コマンドバッファ、および同期プリミティブとともに、MPSの高効率カーネルを使用できます。

00:03:22.000 -> 00:03:32.000
オペレーションカーネルとPyTorch MPSランタイムコンポーネントは、オープンソースコードの一部であり、公式のPyTorch GitHubリポジトリにマージされています。

00:03:32.000 -> 00:03:37.000
MPS PyTorchバックエンドの使用は、簡単な3段階のプロセスです。

00:03:37.000 -> 00:03:44.000
まず、PyTorch 1.12から始めて、「pip install torch」を使用してベースパッケージをインストールできます。

00:03:44.000 -> 00:03:49.000
このパッケージは、公式のPythonパッケージリポジトリで入手できます。

00:03:49.000 -> 00:03:57.000
環境のセットアップとインストールの詳細については、Metal Developer ResourcesのWebページを参照してください。

00:03:57.000 -> 00:04:01.000
次に、PyTorchをインポートし、MPSデバイスを作成します。

00:04:01.000 -> 00:04:09.000
このコードスニペットは、利用可能な場合はMPSデバイスのバックエンドを使用し、そうでない場合はCPUにフォールバックします。

00:04:09.000 -> 00:04:14.000
最後のステップは、モデルと入力をMPSデバイスを使用するように変換することです。

00:04:14.000 -> 00:04:23.000
これを行う方法を実証するために、torchvisionから事前に訓練されたResNet50モデルで推論を実行する例を使用します。

00:04:23.000 -> 00:04:27.000
デフォルトでは、モデルはCPUで実行されます。

00:04:27.000 -> 00:04:32.000
「to」メソッドを使用して、モデルをMPSデバイスに変換することができます。

00:04:32.000 -> 00:04:39.000
これにより、モデル内の中間テンソルも加速されたMPSバックエンドを使用することが保証されます。

00:04:39.000 -> 00:04:42.000
最後に、モデルを実行できます。

00:04:42.000 -> 00:04:47.000
この例では、ランダムな入力テンソルをMPSモデルに渡します。

00:04:47.000 -> 00:04:51.000
デフォルトでは、すべてのテンソルはCPUに割り当てられます。

00:04:51.000 -> 00:04:58.000
MPSバックエンドを使用するには、ここでmpsDeviceも提供する必要があります。

00:04:58.000 -> 00:05:03.000
このテンソルのその後のすべての操作は、GPUで加速されます。

00:05:03.000 -> 00:05:09.000
最後に、サンプル入力をMPSモデルに渡して予測を取得します。

00:05:09.000 -> 00:05:15.000
MPSデバイスの使い方がわかったので、PyTorchの動作例を紹介します。

00:05:15.000 -> 00:05:17.000
私はいつも有名なアーティストになりたいと思っていました。

00:05:17.000 -> 00:05:25.000
そこで、機械学習とGPUを使用して、StyleTransferネットワークを使用してアートワークを作成することにしました。

00:05:25.000 -> 00:05:30.000
このネットワークでは、画像に異なる芸術的スタイルを適用することができます。

00:05:30.000 -> 00:05:37.000
この場合、目標は、この猫の写真に星空の夜のゴッホのスタイルを適用する方法を学ぶことです。

00:05:37.000 -> 00:05:45.000
新しいMPSデバイスを使用すると、GPUを使用してPyTorchネットワークを大幅に高速にトレーニングできます。

00:05:45.000 -> 00:05:53.000
これを実証するために、M1 MaxのCPUとGPUの両方で同時にこのネットワークのトレーニングを開始します。

00:05:53.000 -> 00:06:03.000
このスタイルを学ぶには何千もの反復が必要ですが、GPUははるかに短い時間で合理的なモデルに収束することができます。

00:06:03.000 -> 00:06:10.000
StyleTransferに加えて、これらすべてのPyTorchベンチマークで驚くべきスピードアップを見てきました。

00:06:10.000 -> 00:06:18.000
M1 Ultraでは、最大20倍のスピードアップが見られ、平均8.3倍速くなりました。

00:06:18.000 -> 00:06:27.000
PyTorchは機械学習モデルの開発を容易にし、Apple GPUを使用してそれらを訓練することで多くの時間を節約できます。

00:06:27.000 -> 00:06:33.000
次に、今年TensorFlowに対して行ったすべての機能強化について詳しく説明します。

00:06:33.000 -> 00:06:43.000
TensorFlow Metalアクセラレーションは、TensorFlow Metalプラグインを介してTensorFlowバージョン2.5から利用可能になりました。

00:06:43.000 -> 00:06:47.000
それ以来、いくつかの追加機能と改善が追加されました。

00:06:47.000 -> 00:06:58.000
これらには、より大きなバッチによるトレーニングの改善、新しい操作とカスタム操作のサポート、RNNの改善、および分散トレーニングが含まれます。

00:06:58.000 -> 00:07:10.000
TensorFlow Metalプラグインのリリースは、主要なTensorFlowのリリースと一致しているため、TensorFlowパッケージを更新して最新の機能と改善点を確認してください。

00:07:10.000 -> 00:07:13.000
より大きなバッチサイズから始めましょう。

00:07:13.000 -> 00:07:21.000
今年のTensorFlow Metalのソフトウェア改善により、Appleシリコンアーキテクチャのユニークな利点を活用することができます。

00:07:21.000 -> 00:07:28.000
このグラフは、さまざまなバッチサイズでResNet50モデルをトレーニングするスピードアップを示しています。

00:07:28.000 -> 00:07:38.000
データは、各グラデーションの更新が真のグラデーションにより密接に対応しているため、より大きなバッチサイズでパフォーマンスが向上することを示しています。

00:07:38.000 -> 00:07:46.000
Appleシリコンのユニファイドメモリアーキテクチャにより、より大きなネットワークやより大きなバッチサイズを実行できます。

00:07:46.000 -> 00:07:53.000
これで、クラウドクラスターに分割するのではなく、単一のMac Studioでワークロードを実行できます。これは素晴らしいことです!

00:07:53.000 -> 00:08:01.000
Apple Siliconアーキテクチャは、1ワットあたりのパフォーマンスも高いため、ネットワークはこれまで以上に効率的に実行されます。

00:08:01.000 -> 00:08:06.000
次に、新しい操作とカスタム操作について説明します。

00:08:06.000 -> 00:08:18.000
Tensorflow Metalプラグインは、argMin、all、pack、adaDeltaなど、さまざまな新しい操作のためのGPUアクセラレーションを備えています。

00:08:18.000 -> 00:08:26.000
しかし、現在TensorFlow APIでサポートされていない操作のGPUアクセラレーションが必要な場合はどうなりますか?

00:08:26.000 -> 00:08:30.000
これを行うには、カスタム操作を作成する必要があります。

00:08:30.000 -> 00:08:36.000
2回の反復で実行されている単純な畳み込みネットワークの例を次に示します。

00:08:36.000 -> 00:08:42.000
タイムラインは、それぞれ上下のGPUとCPUで行われた作業を表しています。

00:08:42.000 -> 00:08:50.000
ネットワークは畳み込みを行い、続いてmaxpool-ingを行い、次にソフトマックスクロスエントロピー損失を行います。

00:08:50.000 -> 00:09:00.000
これらの操作はすべて、MPSグラフを介してTensorFlow MetalプラグインでGPUアクセラレーションされますが、カスタム損失関数を使用することをお勧めします。

00:09:00.000 -> 00:09:13.000
このカスタム損失に対するMPS GPUアクセラレーションがなければ、その作業は同期オーバーヘッドを導入し、GPUを飢えさせるCPUタイムラインで実行する必要があります。

00:09:13.000 -> 00:09:18.000
GPUでこのカスタム損失を行うことで、はるかに優れたパフォーマンスを達成できます。

00:09:18.000 -> 00:09:26.000
カスタム操作を実装するには、TensorFlow Metal Streamプロトコルを理解する必要があります。

00:09:26.000 -> 00:09:31.000
これは、GPU操作をエンコードするために使用するプロトコルです。

00:09:31.000 -> 00:09:37.000
Metalストリームには、GPUカーネルをエンコードするために使用するMTLCommandBufferへの参照があります。

00:09:37.000 -> 00:09:45.000
また、複数のスレッドが作業を送信する可能性があるため、エンコード中にCPU側の同期に使用するdispatch_queueを公開します。

00:09:45.000 -> 00:09:51.000
commitまたはcommitAndWaitメソッドを使用して、GPUに作業を送信します。

00:09:51.000 -> 00:09:59.000
CommitAndWaitは、シリアル化された送信を観察できるように、現在のコマンドバッファが完了するまで待つデバッグツールです。

00:09:59.000 -> 00:10:04.000
では、これらの概念を使用してカスタム操作を実装する方法を見てみましょう。

00:10:04.000 -> 00:10:07.000
カスタム操作を書くには3つのステップがあります。

00:10:07.000 -> 00:10:09.000
まず、操作を登録します。

00:10:09.000 -> 00:10:13.000
次に、MetalStreamを使用して操作を実装します。

00:10:13.000 -> 00:10:19.000
そして最後に、操作をトレーニングスクリプトにインポートして使い始めます。

00:10:19.000 -> 00:10:22.000
操作の登録から始めます。

00:10:22.000 -> 00:10:32.000
TensorFlowコアによって公開されるREGISTER_OPマクロを使用して、opのセマンティクスと、TensorFlow Metalプラグインでどのように定義するかを指定します。

00:10:32.000 -> 00:10:36.000
次に、TensorFlow_MetalStreamを使用してopを実装します。

00:10:36.000 -> 00:10:40.000
「計算」関数を定義することから始めます。

00:10:40.000 -> 00:10:50.000
さて、この関数内で、入力のTensorFlow_Tensorオブジェクトを取得し、割り当てが必要な出力を定義します。

00:10:50.000 -> 00:10:55.000
次に、Metalストリームのコマンドバッファを使用してエンコーダを作成します。

00:10:55.000 -> 00:10:58.000
次に、カスタムGPUカーネルを定義します。

00:10:58.000 -> 00:11:02.000
あなたのopは、Metalストリームによって提供されるdispatch_queue内でエンコードされている必要があります。

00:11:02.000 -> 00:11:08.000
これにより、複数のスレッドからの提出物がシリアル化されることが保証されます。

00:11:08.000 -> 00:11:16.000
次に、TensorFlow_MetalStreamプロトコルで提供されるメソッドを使用してカーネルをコミットします。

00:11:16.000 -> 00:11:21.000
最後に、割り当てられたテンソルへの参照を削除します。

00:11:21.000 -> 00:11:27.000
最後に、操作をトレーニングスクリプトにインポートして使用を開始します。

00:11:27.000 -> 00:11:35.000
このステップでは、zero_out.soと呼ばれるカスタムopの共有動的ライブラリファイルをビルドします。

00:11:35.000 -> 00:11:41.000
.soファイルの構築とインポート方法については、Metal Developer Resourcesを参照してください。

00:11:41.000 -> 00:11:50.000
この例では、オプションのステップであるTensorFlow load_op_libraryを使用して、操作をトレーニングスクリプトにインポートします。

00:11:50.000 -> 00:11:56.000
これで、これはPythonラッパーのように機能し、カスタム操作をトレーニングスクリプトで呼び出すことができます。

00:11:56.000 -> 00:12:04.000
次に、Neural Radiance Fields、またはNeRFと呼ばれる興味深いアプリケーションの例を紹介したいと思います。

00:12:04.000 -> 00:12:13.000
より良いアルゴリズムのためにGPUアクセラレーションを有効にすることで、ネットワークのパフォーマンスを向上させるカスタム操作を書きました。

00:12:13.000 -> 00:12:18.000
NeRFは、モデルの3Dビューを合成するために使用されるネットワークです。

00:12:18.000 -> 00:12:23.000
トレーニングのために、NeRFは入力として、さまざまな角度からオブジェクトの画像を取ります。

00:12:23.000 -> 00:12:32.000
NeRFネットワークは2つの積み重ねられた多層パーセプトロンで構成され、出力はモデルの体積表現です。

00:12:32.000 -> 00:12:38.000
リアルタイムトレーニングのための重要なパフォーマンスの最適化は、ハッシュテーブルの実装を使用します。

00:12:38.000 -> 00:12:43.000
この更新されたネットワークは、はるかに小さな多層パーセプトロンを可能にします。

00:12:43.000 -> 00:12:52.000
TensorFlowはハッシュテーブルをネイティブにサポートしていないため、カスタムop機能を使用してMetalプラグインに実装します。

00:12:52.000 -> 00:12:58.000
ハッシュテーブルのGPUアクセラレーションにより、NeRFをはるかに高速にトレーニングできます。

00:12:58.000 -> 00:13:06.000
このMacBookから始めて、オリジナルの多層パーセプトロン実装を実行します。

00:13:06.000 -> 00:13:13.000
合理的なものをレンダリングするには、少なくとも20エポックが必要ですが、各エポックは約100秒かかります。

00:13:13.000 -> 00:13:17.000
つまり、何かが見られるまでに約30分かかるということです。

00:13:17.000 -> 00:13:26.000
だから今、私は事前に30分間トレーニングするために残された事前にトレーニングされたチェックポイントファイルからトレーニングを再開します。

00:13:26.000 -> 00:13:28.000
これはエポック20から始まります。

00:13:28.000 -> 00:13:33.000
3Dモデルは、30分間のトレーニングの後でもぼやけて不明瞭です。

00:13:33.000 -> 00:13:38.000
ネットワークがより明確なモデルを学ぶには、はるかに長いトレーニング時間が必要です。

00:13:38.000 -> 00:13:45.000
カスタムハッシュテーブルなしの元の2つの積み重ねられた多層パーセプトロンアプローチは遅すぎます。

00:13:45.000 -> 00:13:52.000
さて、このMacBookでは、カスタムハッシュテーブルを使用する最適化されたバージョンを開始します。

00:13:52.000 -> 00:14:00.000
この実装はすでにはるかに明確なモデルをレンダリングすることができ、各エポックは学習に10秒しかかかりません。

00:14:00.000 -> 00:14:09.000
このプロジェクトの詳細については、Metal Developer Resourcesにアップロードしたサンプルコードを確認してください。

00:14:09.000 -> 00:14:20.000
NeRFは、ネットワークを超高速に実行するために、独自のカスタム操作にGPUアクセラレーションを実装する方法を示す多くのネットワークの1つにすぎません。

00:14:20.000 -> 00:14:26.000
今後、あなたが作るすべての創造的なカスタマイズについて学ぶことを楽しみにしています。

00:14:26.000 -> 00:14:33.000
次に、Apple GPUを使用してMLワークロードのトレーニングを配布する方法をお見せしたいと思います。

00:14:33.000 -> 00:14:46.000
ワークロードのトレーニングを配布するために、トレーニングスクリプトの複数のインスタンスを別々のプロセスで実行し、各プロセスがモデルの単一の反復を評価できます。

00:14:46.000 -> 00:14:50.000
各プロセスは、中央データストアからデータを読み取ります。

00:14:50.000 -> 00:14:55.000
その後、モデルを駆け抜け、モデルの勾配を計算します。

00:14:55.000 -> 00:15:06.000
次に、プロセスはグラデーションを平均化し、これを相互に通信するので、各プロセスは次の反復の前に同じグラデーションを持ちます。

00:15:06.000 -> 00:15:13.000
最後に、モデルが更新され、すべての反復が使い果たされるまでこのプロセスを繰り返すことができます。

00:15:13.000 -> 00:15:23.000
TensorFlowでこれを実証するために、Horovodと呼ばれる一般的なオープンソースフレームワークを使用した分散トレーニングの例を使用します。

00:15:23.000 -> 00:15:27.000
Horovodは、リングオールリデュースアプローチを使用しています。

00:15:27.000 -> 00:15:34.000
このアルゴリズムでは、Nノードのそれぞれが2つのピアと複数回通信します。

00:15:34.000 -> 00:15:40.000
この通信を使用して、ワーカープロセスは各反復の前にグラデーションを同期させます。

00:15:40.000 -> 00:15:47.000
Thunderboltケーブルで互いに接続された4つのMac Studiosを使用して、これを実際にお見せします。

00:15:47.000 -> 00:15:53.000
この例では、画像の分類器であるResNetをトレーニングします。

00:15:53.000 -> 00:15:59.000
各Mac Studioの横にあるバーは、このネットワークのトレーニング中のGPU使用率を示しています。

00:15:59.000 -> 00:16:04.000
単一のMac Studioの場合、パフォーマンスは毎秒約200枚の画像です。

00:16:04.000 -> 00:16:16.000
Thunderbolt経由で接続された別のMac Studioを追加すると、両方のGPUが最大限に活用されるため、パフォーマンスは毎秒400画像にほぼ倍増します。

00:16:16.000 -> 00:16:24.000
最後に、さらに2つのMacスタジオを接続すると、パフォーマンスは毎秒800画像に向上します。

00:16:24.000 -> 00:16:30.000
これは、コンピューティングバウンドトレーニングワークロードのほぼ線形スケーリングです。

00:16:30.000 -> 00:16:35.000
それでは、TensorFlowの分散トレーニングパフォーマンスを見てみましょう。

00:16:35.000 -> 00:16:41.000
このチャートは、1つ、2つ、4つのMac Studiosの相対的なスピードアップを示しています。

00:16:41.000 -> 00:16:52.000
それらはリングトポロジで接続され、最新のTensorFlow MetalプラグインとHorovodを使用して、resNetやDistilBERTなどのコンピューティングバインドされたTensorFlowネットワークを実行します。

00:16:52.000 -> 00:16:57.000
ベースは、単一のMac Studioでのパフォーマンスです。

00:16:57.000 -> 00:17:12.000
グラフは、各GPUを追加してネットワークパフォーマンスが拡張されるため、複数のデバイスでGPUを活用してトレーニング時間を短縮し、すべてのAppleデバイスを最大限に活用できることを示しています。

00:17:12.000 -> 00:17:24.000
今年TensorFlowでロック解除されたすべての改善と機能は、CPU実装に対する相対的なパフォーマンスを示すこのチャートで最高潮に達し、将来的にはさらに改善される予定です。

00:17:24.000 -> 00:17:30.000
今、MatteoはMPSGraphフレームワークの新機能を共有します。

00:17:30.000 -> 00:17:31.000
Matteo: ありがとう、Dhruva。

00:17:31.000 -> 00:17:35.000
こんにちは、私の名前はマッテオで、GPUソフトウェアエンジニアです。

00:17:35.000 -> 00:17:41.000
PyTorchとTensorFlowは、MPSGraphフレームワークの上にあります。

00:17:41.000 -> 00:17:50.000
次に、MPSGraphは、MPSフレームワークによって公開された並列プリミティブを使用して、GPUでの作業を加速します。

00:17:50.000 -> 00:17:59.000
今日は、MPSGraphでコンピューティングワークロードをさらに高速化するために使用できる2つの機能について説明します。

00:17:59.000 -> 00:18:05.000
まず、2つのグラフ間で作業を同期できる新しい共有イベントAPIを紹介します。

00:18:05.000 -> 00:18:13.000
次に、MPSGraphでさらに多くのことを行うために使用できる新しい操作について確認します。

00:18:13.000 -> 00:18:16.000
共有イベントAPIから始めます。

00:18:16.000 -> 00:18:22.000
同じコマンドキューでアプリケーションを実行すると、ワークロード間の同期が保証されます。

00:18:22.000 -> 00:18:33.000
この例では、後処理や表示などの他のワークロードがディスパッチされる前に、コンピューティングワークロードが常に終了することが保証されています。

00:18:33.000 -> 00:18:39.000
このような場合は、各ディスパッチ内でGPUの並列処理を活用します。

00:18:39.000 -> 00:18:52.000
ただし、一部のアプリケーションは、GPUの最初の部分がコンピューティングに使用され、2番目の部分が後処理と表示に使用される、より多くの並列性の恩恵を受ける可能性があります。

00:18:52.000 -> 00:18:58.000
これは、複数のコマンドキューでGPUに作業を提出することで達成できます。

00:18:58.000 -> 00:19:09.000
残念ながら、この場合、計算が結果を出す前に後処理パイプラインが派遣され、データレースが導入される可能性があります。

00:19:09.000 -> 00:19:21.000
共有イベントAPIを使用して、この問題を解決し、コマンドキュー間で同期を導入して、ワークフローの依存関係を確実に満たすことができます。

00:19:21.000 -> 00:19:25.000
コード内で共有イベントを使用するのはとても簡単です。

00:19:25.000 -> 00:19:29.000
2つのグラフで作業していると仮定しましょう。

00:19:29.000 -> 00:19:32.000
1つ目は、コンピューティングワークロードを担当します。

00:19:32.000 -> 00:19:37.000
2つ目は、後処理の作業負荷を担当します。

00:19:37.000 -> 00:19:47.000
また、計算グラフの結果が後処理グラフの入力として使用され、異なるコマンドキューで実行されると仮定しましょう。

00:19:47.000 -> 00:19:55.000
Metal System Traceの新しいMPSGraphトラックは、コマンドキューが互いに重なっていることを示しています。

00:19:55.000 -> 00:19:58.000
これにより、データレースが発生します。

00:19:58.000 -> 00:20:01.000
共有イベントを使用してこの問題を解決できます。

00:20:01.000 -> 00:20:05.000
まず、Metalデバイスを使用してイベントを作成します。

00:20:05.000 -> 00:20:14.000
次に、実行記述子でシグナルメソッドを呼び出し、イベント、アクション、および値を提供します。

00:20:14.000 -> 00:20:24.000
次に、イベント変数と値を提供する2番目の記述子でwaitメソッドを呼び出すだけです。

00:20:24.000 -> 00:20:37.000
これで、Metalシステムトレースは、2つのコマンドキューが順番に実行され、計算グラフと後処理グラフの間の依存関係が解決されたことを示します。

00:20:37.000 -> 00:20:43.000
それが、共有イベントを使用して、アプリケーションの同期の問題を解決する方法です。

00:20:43.000 -> 00:20:48.000
次に、MPSGraphでサポートされている新しい操作について説明します。

00:20:48.000 -> 00:20:52.000
これらの操作により、フレームワークでさらに多くのことを行うことができます。

00:20:52.000 -> 00:20:59.000
RNNから始めて、これらの新しい操作の詳細をいくつか見ます。

00:20:59.000 -> 00:21:07.000
MPSGraphは現在、リカレントニューラルネットワークアプリケーション内で一般的に使用される3つの操作を公開しています。

00:21:07.000 -> 00:21:12.000
これらはRNN、LSTM、およびGRUレイヤーです。

00:21:12.000 -> 00:21:19.000
これらの操作はすべて同じように機能するので、今日はLSTMに焦点を当てます。

00:21:19.000 -> 00:21:25.000
LSTM操作は、自然言語処理やその他のアプリケーションに一般的に使用されます。

00:21:25.000 -> 00:21:29.000
この図は、LSTM操作がどのように機能するかを示しています。

00:21:29.000 -> 00:21:35.000
詳細については、以前のWWDCセッションをご覧ください。

00:21:35.000 -> 00:21:43.000
LSTMユニットは自分で実装できますが、これを行うには、このかなり複雑なカスタムサブグラフを作成する必要があります。

00:21:43.000 -> 00:21:53.000
代わりに、リカレントユニットが必要とするすべてのGPU作業を効率的にエンコードする新しいLSTM操作を使用できます。

00:21:53.000 -> 00:22:01.000
この新しい操作により、LSTMベースのCoreML推論モデルが大幅に高速になります。

00:22:01.000 -> 00:22:08.000
新しいLSTM操作を使用するには、まずMPSGraphLSTMDescriptorを作成します。

00:22:08.000 -> 00:22:15.000
アクティベーション機能を選択するなど、必要に応じて記述子のプロパティを変更できます。

00:22:15.000 -> 00:22:21.000
次に、LSTMユニットをグラフに追加し、入力テンソルを提供します。

00:22:21.000 -> 00:22:27.000
また、バイアスベクトル、および操作の初期状態とセルを指定することもできます。

00:22:27.000 -> 00:22:30.000
最後に、記述子を提供します。

00:22:30.000 -> 00:22:34.000
LSTMを設定するために必要なのはそれだけです。

00:22:34.000 -> 00:22:38.000
他のRNN業務も同様に機能します。

00:22:38.000 -> 00:22:44.000
これらの操作を試して、アプリケーションでどのようなスピードアップが得られるかを確認することをお勧めします。

00:22:44.000 -> 00:22:48.000
次に、Max Poolingの改善されたサポートを紹介します。

00:22:48.000 -> 00:23:00.000
最大プーリング操作は、入力テンソルとウィンドウサイズを取り、ウィンドウの各アプリケーションに対して、ウィンドウ内の入力の最大値を計算します。

00:23:00.000 -> 00:23:05.000
画像の次元を減らすために、コンピュータビジョンで一般的に使用されています。

00:23:05.000 -> 00:23:13.000
APIは、プーリング演算子によって抽出された最大値の場所のインデックスを返すように拡張されました。

00:23:13.000 -> 00:23:23.000
グラデーションパスでインデックスを使用できます。グラデーションは、最大値が抽出された場所に伝播する必要があります。

00:23:23.000 -> 00:23:26.000
新しいAPIはトレーニングにも機能します。

00:23:26.000 -> 00:23:34.000
トレーニング中にインデックスを再利用すると、PyTorchとTensorFlowでは最大6倍高速になります。

00:23:34.000 -> 00:23:40.000
これをコードで設定するには、まずGraphPooling記述子を作成します。

00:23:40.000 -> 00:23:46.000
returnIndicesMode、例えばglobalFlatten4Dを指定できます。

00:23:46.000 -> 00:23:53.000
次に、Return Indices APIを使用してグラフのプーリング操作を呼び出すことができます。

00:23:53.000 -> 00:23:56.000
操作の結果は2倍です。

00:23:56.000 -> 00:24:01.000
まず、プーリングTensor、そして2番目に、インデックスTensor。

00:24:01.000 -> 00:24:09.000
トレーニングパイプラインなど、後で使用するためにindicesTensorをキャッシュできます。

00:24:09.000 -> 00:24:19.000
MPSグラフは、トレーニンググラフの重みを初期化するために使用できる新しい並列乱数ジェネレータを公開するようになりました。

00:24:19.000 -> 00:24:28.000
新しいランダム操作はPhiloxアルゴリズムを使用し、特定のシードに対してTensorFlowと同じ結果を返します。

00:24:28.000 -> 00:24:41.000
新しい操作は、入力として状態テンソルを取ります。出力としてランダムテンソルと、2番目のランダム操作の入力として使用できる新しい状態テンソルを返します。

00:24:41.000 -> 00:24:46.000
新しいランダム操作を使用するには、randomPhiloxStateTensorメソッドを呼び出します。

00:24:46.000 -> 00:24:52.000
このメソッドは、指定されたシードで入力状態Tensorを初期化します。

00:24:52.000 -> 00:24:59.000
次に、分布とデータ型を入力として取るRandomOp記述子を宣言します。

00:24:59.000 -> 00:25:07.000
この例では、記述子は32ビット浮動小数点値の切り捨てられた正規分布を指定します。

00:25:07.000 -> 00:25:12.000
正規分布と統一分布を使用することもできます。

00:25:12.000 -> 00:25:21.000
平均、標準偏差、最小値、最大値を指定することで、分布特性をさらに定義できます。

00:25:21.000 -> 00:25:32.000
最後に、shapeTensor、記述子、および作成したばかりのstateTensorを提供するランダムな操作を作成できます。

00:25:32.000 -> 00:25:42.000
ランダムに加えて、MPSGraphは2つのビットベクトル間のハミング距離を計算するための新しいGPUアクセラレーション操作をサポートするようになりました。

00:25:42.000 -> 00:25:58.000
同じ長さの2つの入力間で異なるビット数として定義されるハミング距離は、2つのシーケンス間の編集距離の尺度であり、バイオインフォマティクスから暗号学まで、いくつかのアプリケーションで使用されます。

00:25:58.000 -> 00:26:06.000
HammingDistanceを使用するには、グラフ上のAPIを呼び出すと、primaryTensor、secondaryTensor、およびresultDataTypeを提供します。

00:26:06.000 -> 00:26:13.000
新しいカーネルは、GPU上のバッチディメンションでのブロードキャストをサポートしていることに注意してください。

00:26:13.000 -> 00:26:20.000
さて、非常に使いやすい新しいテンソル操作についてすべてお見せします。

00:26:20.000 -> 00:26:26.000
たとえば、テンソルの次元を2次元から3次元に拡張できるようになりました。

00:26:26.000 -> 00:26:30.000
そして、寸法を絞り戻すことができます。

00:26:30.000 -> 00:26:36.000
また、いくつかのスライスと軸を提供してテンソルを均等に分割することもできます。

00:26:36.000 -> 00:26:40.000
または、与えられた軸に沿ってテンソルを積み重ねます。

00:26:40.000 -> 00:26:46.000
また、特定の入力形状のテンソル寸法に沿って座標値を生成することもできます。

00:26:46.000 -> 00:26:54.000
たとえば、形状のテンソルを0軸に沿った座標で2×4で埋めることができます。

00:26:54.000 -> 00:26:59.000
これは、range1D操作を実装するためにも使用できます。

00:26:59.000 -> 00:27:07.000
たとえば、3から27までの数値の範囲を4単位で生成したいと仮定します。

00:27:07.000 -> 00:27:15.000
最初に形状6のテンソルの次元0に沿って座標を作成することで、これを行うことができます。

00:27:15.000 -> 00:27:21.000
次に、増分に掛けてオフセットを追加するだけです。

00:27:21.000 -> 00:27:25.000
これらはすべて今年追加された新しい操作です。

00:27:25.000 -> 00:27:34.000
これらすべての新しい操作により、MPSGraphを使用して、Appleのエコシステム全体でさらに多くのことを行い、より高いパフォーマンスを得ることができます。

00:27:34.000 -> 00:27:41.000
さて、MPSGraphからAppleシリコンで得られるパフォーマンスの向上をお見せします。

00:27:41.000 -> 00:27:50.000
Blackmagicは、MPS Graphを使用して機械学習ワークロードを高速化するDaVinci Resolveバージョン18をリリースしました。

00:27:50.000 -> 00:28:00.000
マジックマスクは、機械学習を使用して画面上の動く物体を識別し、その上に選択的にフィルターを適用するResolveの機能です。

00:28:00.000 -> 00:28:08.000
まず、以前のバージョンのResolveでこれがどのように機能するかを実演し、その後、現在のバージョンと比較します。

00:28:08.000 -> 00:28:13.000
マスクを作成するには、ターゲットオブジェクトを選択するだけです。

00:28:13.000 -> 00:28:16.000
オーバーレイを切り替えることでマスクを見ることができます。

00:28:16.000 -> 00:28:22.000
マスクは、被写体の形状を正しくマークする赤い領域によって識別されます。

00:28:22.000 -> 00:28:28.000
さて、ビデオを再生すると、マスクは画面上を移動するオブジェクトを追跡します。

00:28:28.000 -> 00:28:35.000
これは素晴らしく見えますが、機械学習パイプラインがボンネットの下で実行されるため、かなり低いフレームレートで実行されています。

00:28:35.000 -> 00:28:44.000
次に、MPSGraphを使用してMagic Maskネットワークを加速するResolveの最新バージョンに切り替えます。

00:28:44.000 -> 00:28:49.000
同じタイムラインを再度実行すると、フレームレートは以前よりもずっと速くなります。

00:28:49.000 -> 00:28:55.000
これにより、Appleシリコンでの編集体験がはるかに向上します。

00:28:55.000 -> 00:29:00.000
これらは、MPSグラフを採用するだけで得られる種類のスピードアップです。

00:29:00.000 -> 00:29:04.000
アプリにどのようなパフォーマンスをもたらすことができるかを探ることをお勧めします。

00:29:04.000 -> 00:29:13.000
最後に、PyTorchのGPUアクセラレーションを活用できるようになり、プロジェクトはオープンソースになりました。

00:29:13.000 -> 00:29:23.000
カスタム操作や分散トレーニングなど、TensorFlow Metalプラグインを使用してトレーニングワークロードを加速する新しい方法を見つけることができます。

00:29:23.000 -> 00:29:34.000
最後に、MPSGraphフレームワークを使用して最も要求の厳しい機械学習タスクを最適化し、共有イベントと新しい操作を使用して、Appleシリコンを最大限に活用することができます。

00:29:34.000 -> 00:29:39.000
Dhruvaと私は、アプリケーションでこれらの新機能をどのように使用するかを見るのが待ちきれません。

00:29:39.000 -> 23:59:59.000
セッションをご覧いただきありがとうございます。素晴らしいWWDCをお過ごしください。

