WEBVTT

00:00:00.000 -> 00:00:09.000
♪ ♪

00:00:09.000 -> 00:00:12.000
こんにちは、私の名前はニックで、ビデオチームのエンジニアです。

00:00:12.000 -> 00:00:17.000
今日は、メディアメタデータの公開と再生のインタラクションについてお話しできることを嬉しく思います。

00:00:17.000 -> 00:00:19.000
それで、それは正確にはどういう意味ですか?

00:00:19.000 -> 00:00:25.000
Appleデバイスには、再生情報が表示され、再生を制御できる場所がいくつかあります。

00:00:25.000 -> 00:00:32.000
たとえば、コントロールセンターの「再生中」セクションには、デバイスで現在再生中のメディアのアートワーク、タイトル、進行状況が表示されます。

00:00:32.000 -> 00:00:36.000
また、再生したり、一時停止したり、前方または後方にスキップすることもできます。

00:00:36.000 -> 00:00:40.000
再生中タイルを展開すると、アートワークや進捗状況など、詳細が表示されます。

00:00:40.000 -> 00:00:45.000
また、スクラブしたり、ボリュームを増減したりすることもできます。

00:00:45.000 -> 00:00:57.000
ロック画面には同じ情報とコントロールも表示され、ロックを解除することなく、進捗状況、一時停止、または別のデバイスへのAirPlayをチェックするのに便利な場所をユーザーに提供します。

00:00:57.000 -> 00:01:01.000
どのデバイスが再生していても、Apple Watchの「Now Playing」アプリは同じ体験を提供します。

00:01:01.000 -> 00:01:05.000
Apple TVのリモコンも内蔵されています。

00:01:05.000 -> 00:01:11.000
AVKitを使用する場合のtvOSでは、コントロールが提示されたときの情報オーバーレイには、タイトルとチャプター情報が表示されます。

00:01:11.000 -> 00:01:17.000
情報ペインまで下にスワイプすると、アートワークや説明などの詳細が表示されます。

00:01:17.000 -> 00:01:25.000
Apple TVのリモコンのテレビボタンを長押しすると、コントロールセンターが表示されます。iOSのように、再生中タイルも拡張できます。

00:01:25.000 -> 00:01:38.000
オーディオコンテンツがtvOSのバックグラウンドから再生を開始すると、リモコンの再生ボタンを押すか、別のデバイスからミュージックアプリでトラックを選択するかにかかわらず、再生中の情報を含む通知が表示されます。

00:01:38.000 -> 00:01:48.000
さらに、オーディオを再生するときにtvOSで短時間非アクティブになった後、現在再生されているものを示すフルスクリーンオーバーレイが表示されます。

00:01:48.000 -> 00:01:58.000
最後に、iOSでは、[他のスピーカーとテレビを制御する]ボタンを使用すると、すべてのデバイスで再生中の情報を表示したり、再生を制御したりできます。

00:01:58.000 -> 00:02:08.000
再生中情報が提示され、再生を制御できるデバイスやUIの数が増えるにつれて、再生中の情報を適切に公開し、リモートコマンドに応答することがこれまで以上に重要になっています。

00:02:08.000 -> 00:02:18.000
このセッションの残りの部分では、リモートコマンド、自動メタデータ公開、AVKitによる公開、手動公開の形での再生インタラクションへの応答について説明します。

00:02:18.000 -> 00:02:28.000
メディア再生にAVFoundationを使用する場合、再生中のメタデータを公開し、再生インタラクションに応答する最善の方法は、MPNowPlayingSessionクラスを使用することです。

00:02:28.000 -> 00:02:36.000
歴史的に、このクラスはtvOSでのみ利用可能でしたが、現在はiOS 16で利用可能です。

00:02:36.000 -> 00:02:44.000
これは、明確な再生セッションを表すために使用され、アプリに複数のアクティブなセッションが含まれている場合は、再生中のステータスを制御できます。

00:02:44.000 -> 00:02:52.000
手動メタデータパブリッシングと、iOSとtvOS 16で利用可能な新しい自動パブリッシングの両方をサポートしています。

00:02:52.000 -> 00:03:00.000
MPNowPlayingSessionは、セッションの後半で取り上げる独自の自動公開メカニズムを持つAVKitを使用する場合、tvOSで使用するべきではありません。

00:03:00.000 -> 00:03:10.000
「再生中」アプリであることは、アプリがコントロールセンター、ロック画面などに入力され、ユーザーがこれらのインターフェイスの1つから一時停止を押すと再生コントロールを受け取ることを意味します。

00:03:10.000 -> 00:03:15.000
MPNowPlayingSessionを使用すると、1つのアプリ内で複数の同時再生セッションを表現できます。

00:03:15.000 -> 00:03:22.000
ただし、複数のセッションを使用する場合、アプリはアプリをリモートコントロールするときにシステム全体に表示されるアクティブなセッションとして1つを宣伝する必要があります。

00:03:22.000 -> 00:03:30.000
たとえば、ピクチャー・イン・ピクチャーでは、2つの同時再生セッションがあり、フルスクリーン再生はアクティブな再生セッションと見なされるべきです。

00:03:30.000 -> 00:03:34.000
このシステムには、アプリを「Now Playing」として適格と認定するためのいくつかのヒューリスティックもあります。

00:03:34.000 -> 00:03:38.000
まず、少なくとも1つのリモートコマンドのハンドラを登録する必要があります。

00:03:38.000 -> 00:03:45.000
ご想像のとおり、再生インタラクションに応答しないアプリは、再生中のアプリとして表示するのに理想的な候補ではない可能性が最も高いです。

00:03:45.000 -> 00:03:52.000
第二に、アプリのAVAudioSessionは、混在できないカテゴリとカテゴリオプションで設定する必要があります。

00:03:52.000 -> 00:04:01.000
ミックス可能な再生カテゴリとオプションは、通知を再生するときに一般的に使用されるため、これは再生されているものがNow Playingの良い候補ではないというシステムにとって良い兆候です。

00:04:01.000 -> 00:04:04.000
再生セッションを理解するのに役立つ例をいくつか紹介します。

00:04:04.000 -> 00:04:10.000
この例では、単一のコンテンツが再生されているため、これは単一のMPNowPlayingSessionを使用して表現されます。

00:04:10.000 -> 00:04:17.000
アプリがPiPをサポートしている場合は、2つのMPNowPlayingSessionsがあります。1つはメインプレーヤー用、もう1つはPiP再生用です。

00:04:17.000 -> 00:04:22.000
より複雑なシナリオは、複数のプレーヤーを持つ単一のMPNowPlayingSessionです。

00:04:22.000 -> 00:04:27.000
この例では、各象限に1人ずつ4人の選手がいて、同じレースで異なる視点を示しています。

00:04:27.000 -> 00:04:33.000
同じMPNowPlayingSessionに追加されたプレイヤーは、常に同じコンテンツの一部である必要があります。

00:04:33.000 -> 00:04:36.000
そして、これらの各サンプルセッションがどのようにインスタンス化されるかを次に示します。

00:04:36.000 -> 00:04:41.000
1つ目は、単一のコンテンツを再生しているだけなので、シングルプレイヤーとのシングルセッションがあります。

00:04:41.000 -> 00:04:46.000
2番目の例はピクチャー・イン・ピクチャーを使用しているため、2つのセッションがあり、それぞれが1つのプレーヤーです。

00:04:46.000 -> 00:04:50.000
1つ目はフルスクリーンコンテンツで、2つ目はPiPのコンテンツです。

00:04:50.000 -> 00:04:57.000
最後の例であるマルチビューレースは、4人のプレーヤーとの1回のセッションで表されます。

00:04:57.000 -> 00:05:02.000
アプリに複数のセッションがある場合、該当する場合、特定のセッションをアクティブとして宣伝するのはアプリの責任です。

00:05:02.000 -> 00:05:13.000
たとえば、メディアがピクチャー・イン・ピクチャーで再生されている場合、ユーザーがフルスクリーンに展開すると、以前のフルスクリーンセッションはアクティブではなくなり、再生中になり、フルスクリーンになったPiPセッションがアクティブになります。

00:05:13.000 -> 00:05:20.000
この移行は、MPNowPlayingSessionでbecomeActiveIfPossibleを呼び出すことで実行できます。

00:05:20.000 -> 00:05:31.000
MPNowPlayingSessionのインスタンスの設定と「再生中」セッションの制御の基本について説明したので、ロック画面からでも、別の部屋のHomePodからでも、リモートコマンドの受信と応答について話しましょう。

00:05:31.000 -> 00:05:35.000
再生と一時停止コマンドに登録する基本的な例から始めましょう。

00:05:35.000 -> 00:05:43.000
そうすることで、ユーザーが別のデバイスから再生または一時停止を押したり、Siriを使用してコマンドを発行したりすると、アプリがコールバックを受信できるようになります。

00:05:43.000 -> 00:05:46.000
まず、MPNowPlayingSessionをインスタンス化します。

00:05:46.000 -> 00:05:50.000
セッションは1つしかないので、「becomeActiveIfPossible」メソッドを呼び出す必要はありません。

00:05:50.000 -> 00:05:56.000
セッションが1つしかない場合、アプリが再生中アプリの場合、デフォルトのセッションになります。

00:05:56.000 -> 00:06:04.000
各MPNowPlayingSessionインスタンスには、再生セッションが応答できるリモートコマンドを宣言するために使用される独自のMPRemoteCommandCenterインスタンスがあります。

00:06:04.000 -> 00:06:11.000
次に、プレイヤーのplayメソッドを呼び出すplayCommandのハンドラーを追加し、成功を返します。

00:06:11.000 -> 00:06:14.000
次に、pauseCommandに対しても同じことをします。

00:06:14.000 -> 00:06:20.000
アプリがサポートし、現在再生中のコンテンツに適用されるすべてのコマンドにハンドラーを追加する必要があります。

00:06:20.000 -> 00:06:23.000
もう1つの例は、スキップフォワードとスキップバックコマンドです。

00:06:23.000 -> 00:06:30.000
このコマンドはほとんどのコンテンツに使用する必要があり、たとえば、前方にジャンプできないライブストリームには適用されません。

00:06:30.000 -> 00:06:36.000
まず、好みの間隔、またはどちらかの方向にジャンプしたい秒数を示す必要があります。

00:06:36.000 -> 00:06:38.000
この場合、15秒を使用します。

00:06:38.000 -> 00:06:47.000
次に、再生と一時停止のコマンドで行ったのと同様に、ユーザーがスキップフォワードボタンを押すか、Siriにスキップを依頼したときに呼び出されるハンドラを追加します。

00:06:47.000 -> 00:06:54.000
ハンドラでは、MPSkipIntervalCommandEventを受け取るので、まずイベントをそのタイプにキャストします。

00:06:54.000 -> 00:07:05.000
次に、現在の時間とMPSkipIntervalCommandEventで提供された間隔を取って新しい経過時間を計算し、それを求め、成功を返して、新しい位置にジャンプしたことを示しています。

00:07:05.000 -> 00:07:11.000
また、広告中にスキップするなど、アプリにコマンドが一時的に許可されていない状況がある可能性もあります。

00:07:11.000 -> 00:07:14.000
その場合、skipForwardCommandを無効にすることができます。

00:07:14.000 -> 00:07:19.000
リモートコマンドに応答する今、自動メタデータの公開について説明します。

00:07:19.000 -> 00:07:31.000
自動パブリッシングは、持続時間、現在の経過時間、再生状態、再生進行状況など、プレーヤーから直接観察できるメタデータプロパティを自動的に維持することで、メタデータを正確に保つ作業を取り除きます。

00:07:31.000 -> 00:07:39.000
コンテンツに広告が組み込まれていて、総期間と経過時間に寄与すべきではない場合は、ネットタイムを計算し、代わりにそれを報告することもできます。

00:07:39.000 -> 00:07:47.000
タイトル、説明、アートワークなどの他のメタデータは、nowPlayingInfoプロパティを使用してAVPlayerItemsに直接追加できます。

00:07:47.000 -> 00:07:52.000
この例では、自動公開を使用して作業の大部分を行い、タイトルとアートワークを自分で設定します。

00:07:52.000 -> 00:07:57.000
まず、新しいMPMediaItemArtworkインスタンスを作成し、アートワーク画像を渡します。

00:07:57.000 -> 00:08:00.000
ほとんどのアプリは、これを取得するためにネットワーク要求を実行します。

00:08:00.000 -> 00:08:03.000
次に、コンテンツの文字列タイトルを設定します。

00:08:03.000 -> 00:08:12.000
次に、アートワークとタイトルを取り、MPMediaItemPropertyTitleとMPMediaItemPropertyArtworkを使用して、現在のプレーヤーアイテムのnowPlayingInfo辞書として設定します。

00:08:12.000 -> 00:08:19.000
Now Playingメタデータは、MPMediaItemPropertyとMPNowPlayingInfoPropertyの両方から構成できます。

00:08:19.000 -> 00:08:26.000
最後に、プレーヤーに渡すMPNowPlayingSessionインスタンスを作成し、自動的にPublishNowPlayingInfoをtrueに設定します。

00:08:26.000 -> 00:08:37.000
automaticallyPublishNowPlayingInfoがtrueに設定されると、MPNowPlayingSessionインスタンスは、スクラブ、再生/一時停止イベント、または現在のプレーヤーアイテムの変更などの状態変更についてプレーヤーを観察し始めます。

00:08:37.000 -> 00:08:47.000
広告がアセットに焼き込まれ、合計期間や現在の経過時間に広告時間を含めたくない場合に、自動公開を使用する方法を示す別の例を次に示します。

00:08:47.000 -> 00:08:52.000
これを行うには、私たちが焼き上げたすべての広告に対してMPAdTimeRangeのインスタンスを作成します。

00:08:52.000 -> 00:08:56.000
この例では、冒頭から始まる30秒の広告が1つあります。

00:08:56.000 -> 00:09:01.000
そこで、ゼロの開始点と30秒の持続時間で作成します。

00:09:01.000 -> 00:09:14.000
先ほどのタイトルとアートワークと同様に、MPNowPlayingInfoPropertyAdTimeRangesを使用して、プレーヤーアイテムのnowPlayingInfo辞書にMPAdTimeRangeの配列を追加するだけです。

00:09:14.000 -> 00:09:20.000
その後、以前と同じように、MPNowPlayingSessionを作成し、自動公開を有効にします。

00:09:20.000 -> 00:09:22.000
次はAVKitによるメタデータの公開です。

00:09:22.000 -> 00:09:34.000
tvOSのAVKitを使用した再生メタデータの公開は、MPNowPlayingSessionと非常によく似ています。メタデータはAVPlayerItemに直接追加され、経過時間、期間、再生状態などの値が公開され、最新の状態に保たれます。

00:09:34.000 -> 00:09:43.000
プレーヤーとアセットから直接収集されたメタデータは、AVPlayerItem上のアプリが提供するメタデータと組み合わせて、プレーヤーUIの情報ペインに入力するためにも使用されます。

00:09:43.000 -> 00:09:47.000
AVKitは、リモートコマンドの登録と応答も処理します。

00:09:47.000 -> 00:09:55.000
AVKitを使用することは、これまでに議論したプラットフォーム機能や、AirPlayやピクチャー・イン・ピクチャーなどの他の機能と統合するための最善かつ最も簡単な方法です。

00:09:55.000 -> 00:10:05.000
AVKitを使用する際のメタデータの設定は、コンテンツを記述するためのAVMetadataItemインスタンスで構成されるAVPlayerItemのexternalMetadata配列を使用して行われます。

00:10:05.000 -> 00:10:08.000
通常、各AVMetadataItemに3つの値を設定します。

00:10:08.000 -> 00:10:14.000
まず、識別子は、AVMetadataItemが表すメタデータを示す鍵です。

00:10:14.000 -> 00:10:23.000
たとえば、コンテンツタイトルのAVMetadataCommonIdentifierTitle、またはアートワークのAVMetadataCommonIdentifierArtwork。

00:10:23.000 -> 00:10:25.000
2つ目は値です。

00:10:25.000 -> 00:10:27.000
タイトルの場合、これはタイトルを含む文字列になります。

00:10:27.000 -> 00:10:31.000
アートワークの場合、これは画像データを含むNSDataインスタンスになります。

00:10:31.000 -> 00:10:34.000
dataTypeは、提供されたアートワークの形式を示すために使用されます。

00:10:34.000 -> 00:10:40.000
JPEGデータが含まれている場合は、kCMMetadatabaseDataType_JPEGが使用されます。

00:10:40.000 -> 00:10:47.000
最後に、extendedLanguageTagは、タイトルや説明などの文字列に使用される言語を示すために使用されます。

00:10:47.000 -> 00:10:52.000
ほとんどの場合、すべての視聴者が同じ値を見るようにするために、ここでは値「und」を使用する必要があります。

00:10:52.000 -> 00:11:02.000
値が英語の場合、「en-us」を使用したくなるかもしれませんが、そうすると、言語がスペイン語などの他の言語に設定されているデバイスにメタデータが表示されなくなる可能性があります。

00:11:02.000 -> 00:11:05.000
ここでは、アートワークとタイトルを設定する例があります。

00:11:05.000 -> 00:11:08.000
まず、バンドルからアートワークの画像データを取得します。

00:11:08.000 -> 00:11:11.000
ほとんどのアプリは、ネットワークリソースからこれを取得します。

00:11:11.000 -> 00:11:15.000
次に、新しい可変AVMetadataItemをインスタンス化します。

00:11:15.000 -> 00:11:18.000
識別子を.commonIdentifierArtworkに設定しました。

00:11:18.000 -> 00:11:23.000
次に、値を生のアートワーク画像データとしてNSDataとして設定します。

00:11:23.000 -> 00:11:28.000
画像データはJPEGなので、dataTypeをkCMMetadataBaseDataType_JPEGに設定します。

00:11:28.000 -> 00:11:33.000
アートワークが代わりにPNGの場合は、kCMMetadataBaseDataType_PNGを使用します。

00:11:33.000 -> 00:11:40.000
このメタデータを任意の言語に設定したデバイスを持つユーザーに表示させたいため、extendedLanguageTagを「und」または「undefined」に設定します。

00:11:40.000 -> 00:11:49.000
次に、.commonIdentifierTitleと値の文字列タイトル、extendedLanguageTagの「und」を使用して、タイトルに対して同じ手順を繰り返します。

00:11:49.000 -> 00:11:57.000
すべてのメタデータ項目を設定したら、それらを配列に追加し、AVPlayerItemのexternalMetadataプロパティに設定します。

00:11:57.000 -> 00:12:05.000
プレイヤーアイテムにアートワークとタイトルが追加されたので、これがiOSのコントロールセンターとロック画面に表示されるものにどのようにマッピングされるかを確認できます。

00:12:05.000 -> 00:12:11.000
アートワークと同様に、説明、字幕情報、コンテンツ評価など、設定できる他のメタデータタイプがあります。

00:12:11.000 -> 00:12:17.000
アプリは、できるだけ豊富な体験をユーザーに提供するために、これらをできるだけ多く設定する必要があります。

00:12:17.000 -> 00:12:22.000
これまでのところ、MPNowPlayingSessionでの自動公開とAVKitでの公開を取り上げました。

00:12:22.000 -> 00:12:27.000
しかし、MPNowPlayingSessionとその自動公開機能は、AVPlayerインスタンスを渡す必要があります。

00:12:27.000 -> 00:12:31.000
それはすべてのアプリのオプションではないかもしれませんし、手動公開はまだ可能です。

00:12:31.000 -> 00:12:35.000
手動で公開するには、すべてのメタデータの値を提供する必要があります。

00:12:35.000 -> 00:12:40.000
自動公開とは異なり、経過時間や再生速度などの情報はシステムで決定することはできません。

00:12:40.000 -> 00:12:48.000
これは、低レベルの再生状態を手動で細かく制御できることを意味し、アプリは再生が変化するにつれて時間の経過とともに正確に保つ責任があります。

00:12:48.000 -> 00:12:58.000
リモートコマンドの登録と応答も引き続き必要であり、MPNowPlayingSessionを使用していないため、MPRemoteCommandCenterの共有インスタンスを使用する必要があることに注意してください。

00:12:58.000 -> 00:13:02.000
以下は、Now Playing Info辞書を更新する方法を示す基本的な例です。

00:13:02.000 -> 00:13:08.000
まず、自動公開のために行ったのと同様に、画像を含むMPMediaItemArtworkインスタンスを作成します。

00:13:08.000 -> 00:13:12.000
次に、利用可能なメタデータを含む辞書を作成します。

00:13:12.000 -> 00:13:19.000
この場合、タイトル、アートワーク、プレイヤー値の持続時間、経過時間、再生速度を設定します。

00:13:19.000 -> 00:13:23.000
次に、MPNowPlayingInfoCenterのデフォルトインスタンスに設定します。

00:13:23.000 -> 00:13:32.000
このメタデータの更新は、再生や一時停止、ユーザーが前方または後方にスクラブしたり、新しいコンテンツの再生を開始するなど、再生中に重要な変更が行われるときはいつでも行う必要があります。

00:13:32.000 -> 00:13:34.000
経過時間を定期的に更新する必要はありません。

00:13:34.000 -> 00:13:41.000
システムは、前回の更新から経過した時間に基づいて、常に正しい経過時間を推測します。

00:13:41.000 -> 00:13:50.000
再生中のメタデータを公開し、他のデバイスやインターフェイスからのリモートコマンドに応答するさまざまな方法に精通したので、ユーザーエクスペリエンスを最大化するために統合する必要があります。

00:13:50.000 -> 00:13:51.000
これまで以上に簡単です。

00:13:51.000 -> 00:13:59.000
既存の統合も恩恵を受けることができます。自動公開への切り替えは、将来の回帰を防ぎ、維持する必要があるコードの量を最小限に抑える簡単な方法です。

00:13:59.000 -> 00:14:03.000
詳細については、developer.apple.comのMediaPlayerを参照してください。

00:14:03.000 -> 23:59:59.000
見てくれてありがとう。

