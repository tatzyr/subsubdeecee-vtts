WEBVTT

00:00:00.000 -> 00:00:03.000
♪インストゥルメンタルヒップホップ音楽♪

00:00:03.000 -> 00:00:09.000
♪

00:00:09.000 -> 00:00:15.000
こんにちは、私はジョン・シェーンバーグで、アップルのロケーションテクノロジーチームのエンジニアです。

00:00:15.000 -> 00:00:25.000
このセッションでは、近くのインタラクションにもたらした新機能について説明します。これにより、空間認識でより豊かで多様な体験を構築することができます。

00:00:25.000 -> 00:00:47.000
近くのインタラクションフレームワークは、超広帯域技術のためのAppleのチップであるU1の機能を簡単に活用し、超広帯域用のAppleのU1チップと互換性のある近くのAppleデバイスまたはアクセサリ間で正確で空間的に認識された相互作用を作成することができます。

00:00:47.000 -> 00:00:52.000
過去2年間に利用可能なものの簡単なレビューから始めましょう。

00:00:52.000 -> 00:01:02.000
WWDC 2020でNearby Interactionが導入されたとき、その機能はU1を搭載した2台のiPhone間のセッションの作成と実行に焦点を当てました。

00:01:02.000 -> 00:01:13.000
WWDC 2021では、Apple Watchとサードパーティの超広帯域対応アクセサリとのランニングセッションをサポートするように機能が拡張されました。

00:01:13.000 -> 00:01:27.000
近くのインタラクションフレームワークのAPIを深く掘り下げることに興味がある場合は、2020年のWWDCトーク「近くのインタラクションに会う」と2021年の「サードパーティのアクセサリーで近くのインタラクションを探索する」を確認してください。

00:01:27.000 -> 00:01:36.000
私たちは、近くのインタラクションに対するコミュニティの反応に圧倒され、このセッションでは、あなたのために新しい機能と改善を発表することに興奮しています。

00:01:36.000 -> 00:01:44.000
私は2つの主要なトピックに焦点を当てます:ARKitとの近くの相互作用の強化とバックグラウンドセッション。

00:01:44.000 -> 00:01:56.000
その過程で、近くのインタラクションフレームワークをより簡単に使用するいくつかの改善点を共有し、昨年発表されたサードパーティのハードウェアサポートのアップデートで締めくくります。

00:01:56.000 -> 00:02:02.000
私たちは、あなたが新しい機能で何をするかに興奮しているので、詳細を掘り下げてみましょう。

00:02:02.000 -> 00:02:09.000
ARKitと近くのインタラクションを緊密に統合するエキサイティングな新機能から始めます。

00:02:09.000 -> 00:02:17.000
この新しい機能は、ARKitから計算されたデバイスの軌道を活用することで、近くのインタラクションを強化します。

00:02:17.000 -> 00:02:29.000
ARKitで強化された近くのインタラクションは、AirTagでPrecision Findingを強化するのと同じ基盤技術を活用し、近くのインタラクションを介して利用できるようにしています。

00:02:29.000 -> 00:02:41.000
最良のユースケースは、置き忘れたアイテム、関心のあるオブジェクト、またはユーザーが対話したいオブジェクトなど、特定の近くのオブジェクトにユーザーを誘導するエクスペリエンスです。

00:02:41.000 -> 00:02:55.000
ARKitとNearby Interactionを統合することで、Nearby Interactionを単独で使用するよりも距離と方向情報がより一貫して利用でき、超広帯域の視野を効果的に広げます。

00:02:55.000 -> 00:03:02.000
最後に、この新しい機能は、固定デバイスとの相互作用に最もよく使用されます。

00:03:02.000 -> 00:03:11.000
ARKitと近くのインタラクションのこの新しい統合がアプリケーションで可能になる可能性のデモンストレーションに飛び込みましょう。

00:03:11.000 -> 00:03:18.000
私はここに展示にユーザーを案内するのに役立つウルトラワイドバンドアクセサリーを持っている私のジェットパック博物館のためのアプリケーションを持っています。

00:03:18.000 -> 00:03:21.000
次のジェットパックを探しに行きましょう。

00:03:21.000 -> 00:03:31.000
ユーザーが次の展示に行くことを選択すると、アプリケーションは超広帯域アクセサリを発見し、近くのインタラクションの使用を開始するために必要な交換を実行します。

00:03:31.000 -> 00:03:45.000
その後、アプリケーションは、ARKitを使用した強化された近くのインタラクションモードを使用して、次の展示の物理的な場所を決定し始める間、電話を左右に移動するようにユーザーに指示します。

00:03:45.000 -> 00:03:55.000
アプリケーションが次の展示に対応する方向を理解したので、それをチェックアウトするために向かう方向をユーザーに指示する単純な矢印アイコンが表示されます。

00:03:55.000 -> 00:04:10.000
ARKitと近くのインタラクションの組み合わせを利用したこの豊富で空間的に認識された情報は、展示がユーザーの後ろにあり、ユーザーが展示から離れた方向に向かっていることを示すことさえできます。

00:04:10.000 -> 00:04:23.000
最後に、アプリケーションは、ARの世界で、次の展示の場所のオーバーレイを表示することができ、アプリケーションは、展示がARの世界でどこにあるかを解決するために、iPhoneを少し上下に動かすようにユーザーに促します。

00:04:23.000 -> 00:04:38.000
ARコンテンツがシーンに配置されると、近くのインタラクションと超広帯域測定とARKitの強力な組み合わせにより、ユーザーは簡単に次のジェットパックをチェックアウトできます。

00:04:38.000 -> 00:04:42.000
ジェットパックは見つからなかったかもしれませんが、女王を見つけました。

00:04:42.000 -> 00:04:47.000
それでは、この強化された近くのインタラクションモードを有効にする方法を見てみましょう。

00:04:47.000 -> 00:04:57.000
iOS 15では、おそらくアプリケーションに、近くのピアからNIDiscoveryTokenを受け入れ、セッション設定を作成し、NISessionを実行する方法があります。

00:04:57.000 -> 00:05:11.000
ARKitで拡張モードを有効にすることは、NIConfigurationのサブクラスの新しいisCameraAssistanceEnabledプロパティを使用した近くのインタラクションの新規および既存の使用で簡単にできます。

00:05:11.000 -> 00:05:18.000
ARKitで拡張モードを活用するために必要なのは、isCameraAssistanceEnabledプロパティの設定だけです。

00:05:18.000 -> 00:05:27.000
2つのAppleデバイスとAppleデバイスからサードパーティの超広帯域アクセサリを操作する場合、カメラアシスタンスが利用できます。

00:05:27.000 -> 00:05:34.000
カメラアシスタンスを有効にしてNISessionが実行されたときに何が起こるかの詳細を見てみましょう。

00:05:34.000 -> 00:05:41.000
カメラ支援を有効にすると、近くのインタラクションフレームワーク内にARSessionが自動的に作成されます。

00:05:41.000 -> 00:05:46.000
あなたはこのARSessionを作成する責任を負いません。

00:05:46.000 -> 00:05:56.000
カメラアシスタンスを有効にしてNISessionを実行すると、Nearby Interactionフレームワーク内で自動的に作成されたARSessionも実行されます。

00:05:56.000 -> 00:06:00.000
ARSessionは申請プロセス内で実行されています。

00:06:00.000 -> 00:06:09.000
その結果、アプリケーションはアプリケーションのInfo.plist内でカメラの使用状況説明キーを提供する必要があります。

00:06:09.000 -> 00:06:19.000
良い体験を提供するためにカメラが必要な理由をユーザーに知らせるために、これを便利な文字列にしてください。

00:06:19.000 -> 00:06:23.000
特定のアプリケーションに対して実行できるARSessionは1つだけです。

00:06:23.000 -> 00:06:34.000
つまり、アプリにすでにARKitエクスペリエンスがある場合は、作成したARSessionをNISessionと共有する必要があります。

00:06:34.000 -> 00:06:41.000
ARSession を NISession と共有するには、NISession クラスで新しい setARSession メソッドを使用できます。

00:06:41.000 -> 00:06:54.000
実行前にNISessionでsetARSessionが呼び出されると、セッションの実行時にARSessionは近くのインタラクションフレームワーク内で自動的に作成されません。

00:06:54.000 -> 00:07:02.000
これにより、アプリケーションARKitエクスペリエンスは、近くのインタラクションのカメラアシスタンスと同時に実行されます。

00:07:02.000 -> 00:07:16.000
このSwiftUIの例では、makeUIView関数の一部として、ARView内の基礎となるARSessionは、新しいsetARSessionメソッドを介してNISessionと共有されます。

00:07:16.000 -> 00:07:26.000
ARSessionを直接使用する場合は、ARWorldTrackingConfigurationを使用してARSessionでrunを呼び出す必要があります。

00:07:26.000 -> 00:07:37.000
さらに、カメラアシスタンスから高品質のパフォーマンスを確保するために、このARConfiguration内で特定の方法でいくつかのプロパティを設定する必要があります。

00:07:37.000 -> 00:07:52.000
worldAlignmentは、重力、コラボレーション、userFaceTracking無効、nil initialWorldMap、およびsessionShouldAttempt Relocalizationメソッドがfalseを返すデリゲートに設定する必要があります。

00:07:52.000 -> 00:07:57.000
作成したARSessionを共有する際のベストプラクティスに目を向けてみましょう。

00:07:57.000 -> 00:08:04.000
NISessionDelegate didInvalidateWithエラーメソッドでは、常にエラーコードを検査します。

00:08:04.000 -> 00:08:14.000
共有ARSessionの実行に使用されたARConfigurationが概説されたプロパティに準拠していない場合、NISessionは無効になります。

00:08:14.000 -> 00:08:21.000
新しいNIErrorコードinvalidARConfigurationが返されます。

00:08:21.000 -> 00:08:30.000
アプリで近くのオブジェクトの更新を受信するには、NISessionDelegateでdidUpdateNearbyObjectsメソッドを引き続き使用してください。

00:08:30.000 -> 00:08:47.000
didUpdateNearbyObjectsメソッドでは、おそらく目的のピアの近くのオブジェクトをチェックし、利用可能な場合はNINearbyObjectの距離と方向のプロパティに基づいてUIを更新し、常にこれらを思い出すように注意してnilになる可能性があります。

00:08:47.000 -> 00:08:54.000
カメラアシスタンスを有効にすると、NINearbyObject内で2つの新しいプロパティが利用可能になります。

00:08:54.000 -> 00:08:57.000
1つ目は水平角度です。

00:08:57.000 -> 00:09:03.000
これは、近くの物体への方位角方向を示すラジアンの1次元角度です。

00:09:03.000 -> 00:09:07.000
利用できない場合、この値はnilになります。

00:09:07.000 -> 00:09:14.000
第二に、verticalDirectionEstimateは、垂直次元の近くの物体との位置関係です。

00:09:14.000 -> 00:09:19.000
これは新しいVerticalDirectionEstimateタイプです。

00:09:19.000 -> 00:09:27.000
距離と方向は、ユーザーのデバイスと近くのオブジェクトとの間の重要な空間関係を表します。

00:09:27.000 -> 00:09:34.000
距離はメートル単位で測定され、方向はデバイスから近くの物体までの3Dベクトルです。

00:09:34.000 -> 00:09:44.000
水平角度は、NISessionを実行しているデバイスと、ローカル水平面内の近くのオブジェクトとの間の角度として定義されます。

00:09:44.000 -> 00:09:52.000
これは、2つのデバイス間の垂直変位オフセットとデバイス自体の水平回転を考慮します。

00:09:52.000 -> 00:10:02.000
方向は3Dですが、水平角度は2つのデバイス間の見出しの1D表現です。

00:10:02.000 -> 00:10:16.000
この水平角度プロパティは、方向プロパティと補完され、方向を解決できない場合は、水平角度を使用して、ユーザーを近くのオブジェクトに誘導するのに役立ちます。

00:10:16.000 -> 00:10:22.000
垂直方向の推定は、垂直位置情報の定性的評価です。

00:10:22.000 -> 00:10:27.000
フロアレベル間でユーザーを導くためにそれを使用する必要があります。

00:10:27.000 -> 00:10:32.000
それでは、新しいVerticalDirectionEstimateタイプを見てみましょう。

00:10:32.000 -> 00:10:44.000
VerticalDirectionEstimateは、NINearbyObject内のネストされた列挙型であり、近くのオブジェクトとの垂直関係の定性的評価を表します。

00:10:44.000 -> 00:10:50.000
プロパティを使用する前に、VerticalDirectionEstimateが不明かどうかを必ず確認してください。

00:10:50.000 -> 00:11:07.000
垂直関係は、同じ、上、下、または近くのオブジェクトを表す特別なaboveOrBelow値が同じレベルではなく、デバイスの上または下に明確ではありません。

00:11:07.000 -> 00:11:12.000
超広帯域測定は、視野と障害物の影響を受けます。

00:11:12.000 -> 00:11:19.000
方向情報の視野は、デバイスの背面から投影する円錐に対応します。

00:11:19.000 -> 00:11:39.000
カメラ支援が有効になっているときにARKitから計算されたデバイスの軌道により、距離、方向、水平角度、垂直方向の見積もりをより多くのシナリオで利用でき、超広帯域センサーの視野を効果的に拡大します。

00:11:39.000 -> 00:11:48.000
それでは、ARKitと近くのインタラクションの統合を活用して、ARオブジェクトをシーンに配置しましょう。

00:11:48.000 -> 00:12:02.000
近くのオブジェクトを表す3D仮想コンテンツをカメラフィードの視覚化に簡単にオーバーレイできるように、ヘルパーメソッドを追加しました。worldTransform on NISession。

00:12:02.000 -> 00:12:13.000
このメソッドは、利用可能な場合、物理環境内の指定された近くのオブジェクトの位置を表すARKitの座標空間にworldTransformを返します。

00:12:13.000 -> 00:12:18.000
利用できない場合、このメソッドはnilを返します。

00:12:18.000 -> 00:12:23.000
デモンストレーションでこの方法を使用して、次の展示の上に浮遊球を配置しました。

00:12:23.000 -> 00:12:34.000
近くのインタラクションの位置出力をできるだけ簡単に活用して、アプリのAR世界のコンテンツを操作できるようにしたいと考えています。

00:12:34.000 -> 00:12:38.000
iOSの2つの強力なシステムの組み合わせ。

00:12:38.000 -> 00:12:49.000
ユーザーは、カメラ支援が世界変換を適切に計算できるように、デバイスを垂直方向と水平方向で十分にスイープする必要があります。

00:12:49.000 -> 00:12:59.000
この方法は、カメラの支援がARKitの世界変換に完全に収束するために、ユーザーの動きが不十分である場合、nilを返すことができます。

00:12:59.000 -> 00:13:11.000
この変換がアプリ体験にとって重要な場合、この変換を生成するために行動を起こすようにユーザーを指導することが重要です。

00:13:11.000 -> 00:13:22.000
デモンストレーションで見たものと同じようにユーザーを導くことを可能にするために、NISessionDelegateに加えたいくつかの追加を見てみましょう。

00:13:22.000 -> 00:13:36.000
ユーザーをオブジェクトに導くのを助けるために、NISessionDelegateコールバックは、新しいdidUpdateAlgorithmConvergenceデリゲートメソッドを介して、近くのインタラクションアルゴリズムの収束に関する情報を提供します。

00:13:36.000 -> 00:13:50.000
アルゴリズム収束は、水平角度、垂直方向推定、およびworldTransformが利用できない理由と、ユーザーがこれらのプロパティを解決するために実行できるアクションを理解するのに役立ちます。

00:13:50.000 -> 00:13:58.000
デリゲートは、新しいNIAAlgorithmConvergenceオブジェクトとオプションのNINearbyObjectを提供します。

00:13:58.000 -> 00:14:07.000
このデリゲートメソッドは、NIConfigurationでカメラアシスタンスを有効にした場合にのみ呼び出されます。

00:14:07.000 -> 00:14:11.000
新しいNIAlgorithmConvergenceタイプを見てみましょう。

00:14:11.000 -> 00:14:18.000
NIAlgorithmConvergenceには、NIAlgorithm ConvergenceStatusタイプであるシングルステータスプロパティがあります。

00:14:18.000 -> 00:14:26.000
NIAlgorithmConvergenceStatus型は、アルゴリズムが収束しているかどうかを表す列挙型です。

00:14:26.000 -> 00:14:36.000
アルゴリズムが収束しない場合、関連する値の配列 NIAlgorithmConvergenceStatus 。理由が提供されています。

00:14:36.000 -> 00:14:49.000
新しいデリゲートメソッドに戻り、カメラアシスタンスのステータスをユーザーに更新したいとしましょう。コンバージェンスステータスをオンにして、不明または収束している場合は、その情報をユーザーに表示できます。

00:14:49.000 -> 00:14:53.000
必ずNINearbyObjectを検査してください。

00:14:53.000 -> 00:15:04.000
オブジェクトがnilの場合、特定のNINearbyObjectではなく、NIAAlgorithmConvergence状態がセッション自体に適用されます。

00:15:04.000 -> 00:15:13.000
ステータスがコンバージされていない場合、アルゴリズムがコンバージされていない理由を説明する関連する値も含まれます。

00:15:13.000 -> 00:15:19.000
このため、ローカライズされた説明は、ユーザーとのより良いコミュニケーションに役立ちます。

00:15:19.000 -> 00:15:23.000
次に、これらの値の使い方を見てみましょう。

00:15:23.000 -> 00:15:36.000
notConvergedのケースと関連する理由の値をより詳細に検査することで、近くのオブジェクトに関する必要な情報を生成するのに役立つアクションを実行するようにユーザーを導くことができます。

00:15:36.000 -> 00:15:41.000
関連する値は、NIAlgorithmConvergence StatusReasonsの配列です。

00:15:41.000 -> 00:15:51.000
その理由は、総動きが不十分、水平または垂直のスイープの動きが不十分、照明が不十分であることを示している可能性があります。

00:15:51.000 -> 00:16:03.000
複数の理由が同時に存在する可能性があることに注意し、アプリケーションにとって最も重要なことに基づいて、各アクションを順番にユーザーを導きます。

00:16:03.000 -> 00:16:13.000
デモンストレーションで電話を動かし、世界の変革を解決するために水平方向と垂直方向の両方をスイープする必要があったことを思い出してください。

00:16:13.000 -> 00:16:18.000
これは、カメラアシスタンスによる強化された近くのインタラクションモードに関する最も重要な部分です。

00:16:18.000 -> 00:16:23.000
このモードをよりよく活用できるように、いくつかの追加の変更を加えました。

00:16:23.000 -> 00:16:33.000
以前は、特定のデバイスで近くのインタラクションがサポートされているかどうかを確認するために必要なのは、NISessionの単一のisSupportedクラス変数だけでした。

00:16:33.000 -> 00:16:36.000
これは現在非推奨です。

00:16:36.000 -> 00:16:52.000
カメラアシスタンスの追加により、新しいNIDeviceCapabilityオブジェクトを返すNISessionの新しいdeviceCapabilitiesクラスメンバーを使用して、Nearby Interactionでサポートされているデバイス機能をよりわかりやすくしました。

00:16:52.000 -> 00:17:03.000
少なくとも、supportsPreciseDistance Measurementプロパティをチェックすることは、現在非推奨のisSupportedクラス変数と同等です。

00:17:03.000 -> 00:17:18.000
デバイスが正確な距離測定をサポートしていることを確立したら、NIDeviceCapabilityを使用して、アプリケーションを実行しているデバイス上の近くのインタラクションから利用可能な機能を完全に理解する必要があります。

00:17:18.000 -> 00:17:33.000
NIDeviceCapabilityオブジェクトの追加supportsDirectionMeasurementとsupportsCameraAssistanceプロパティをチェックして、アプリのエクスペリエンスをデバイスの機能に合わせて調整することをお勧めします。

00:17:33.000 -> 00:17:45.000
すべてのデバイスが方向測定やカメラ支援をサポートするわけではないので、このデバイスの機能に合わせた体験を必ず含めてください。

00:17:45.000 -> 00:17:53.000
特に、Apple Watchを最大限にサポートするために、距離のみの体験を含めることに留意してください。

00:17:53.000 -> 00:18:03.000
ARKitとの近くのインタラクションを強化する方法として、カメラ支援のためのすべてです。では、アクセサリーのバックグラウンドセッションに注意を向けましょう。

00:18:03.000 -> 00:18:16.000
今日では、アプリで近くのインタラクションを使用して、ユーザーが他のデバイスをポイントしたり、友達を見つけたり、アクセサリまでの距離や方向に基づいてコントロールやその他のUIを表示したりできます。

00:18:16.000 -> 00:18:30.000
ただし、アプリがバックグラウンドに移行したり、ユーザーがiOSとwatchOSで画面をロックしたりすると、アプリケーションがフォアグラウンドに戻るまで、実行中のNISessionsは一時停止されます。

00:18:30.000 -> 00:18:38.000
これは、アクセサリと対話する際に、実践的なユーザーエクスペリエンスに焦点を当てる必要があることを意味します。

00:18:38.000 -> 00:18:43.000
iOS 16以降、近くのインタラクションはハンズフリーになりました。

00:18:43.000 -> 00:18:56.000
近くのインタラクションを使用して、スマートスピーカーで部屋に入ったときに音楽の再生を開始したり、eBikeに乗ったときにeBikeをオンにしたり、アクセサリーで他のハンズフリーアクションをトリガーしたりできるようになりました。

00:18:56.000 -> 00:19:03.000
ユーザーがアクセサリのバックグラウンドセッションでアプリを積極的に使用していない場合でも、これを行うことができます。

00:19:03.000 -> 00:19:09.000
このエキサイティングな新しい機能を達成する方法を見てみましょう。

00:19:09.000 -> 00:19:15.000
アクセサリでNISessionを設定して実行する方法について、シーケンスを確認しましょう。

00:19:15.000 -> 00:19:20.000
昨年のWWDCプレゼンテーションからこのシーケンスを認識しているかもしれません。

00:19:20.000 -> 00:19:33.000
アクセサリは、超広帯域アクセサリ構成データをデータチャネルを介してアプリケーションに送信し、このデータからNINearbyAccessoryConfigurationを作成します。

00:19:33.000 -> 00:19:40.000
NISessionを作成し、NISessionDelegateを設定して、アクセサリから超広帯域測定を取得します。

00:19:40.000 -> 00:19:51.000
設定でNISessionを実行すると、セッションは共有可能な設定データを返し、アプリケーションと相互運用するようにアクセサリをセットアップします。

00:19:51.000 -> 00:20:01.000
この共有可能な構成データをアクセサリに送り返した後、アプリケーションとアクセサリで超広帯域測定を受信できるようになりました。

00:20:01.000 -> 00:20:10.000
サードパーティ製アクセサリとの近くのインタラクションの設定と実行に関するすべての詳細については、昨年のWWDCセッションを確認してください。

00:20:10.000 -> 00:20:14.000
それでは、新しいバックグラウンドセッションの設定方法を見てみましょう。

00:20:14.000 -> 00:20:21.000
前のシーケンス図は、アプリケーションとアクセサリの間を流れるデータを示しました。

00:20:21.000 -> 00:20:29.000
アクセサリとアプリケーション間の通信チャネルがBluetooth LEを使用することは非常に一般的です。

00:20:29.000 -> 00:20:37.000
Bluetooth LEを使用してアクセサリとペアリングすると、近くのインタラクションを有効にして、バックグラウンドでセッションを開始および継続できます。

00:20:37.000 -> 00:20:40.000
これがどのように可能かをよく見てみましょう。

00:20:40.000 -> 00:20:51.000
今日では、アプリがバックグラウンドにある間に、Core Bluetoothを使用してBluetooth LEアクセサリでデータを検出、接続、交換するようにアプリを設定できます。

00:20:51.000 -> 00:20:59.000
詳細については、既存のコアBluetoothプログラミングガイドまたは2017年のWWDCセッションをご覧ください。

00:20:59.000 -> 00:21:18.000
Core Bluetoothの強力なバックグラウンド操作を利用して、アクセサリを効率的に検出し、バックグラウンドでアプリケーションを実行すると、アプリケーションはバックグラウンドで超広帯域をサポートするBluetooth LEアクセサリでNISessionを開始できます。

00:21:18.000 -> 00:21:24.000
それでは、この新しいモードを反映するためにシーケンス図がどのように更新されるかを見てみましょう。

00:21:24.000 -> 00:21:29.000
このアクセサリと対話するには、まずBluetooth LE-pairedであることを確認してください。

00:21:29.000 -> 00:21:32.000
次に、アクセサリに接続します。

00:21:32.000 -> 00:21:46.000
アクセサリがアクセサリの超広帯域構成データを生成すると、アプリケーションに送信し、近くのインタラクションGATTサービスに入力する必要があります。これについては次の詳細です。

00:21:46.000 -> 00:22:02.000
最後に、アプリケーションがアクセサリの構成データを受信したら、アクセサリのUWB構成データとそのBluetoothピア識別子の両方を提供する新しい初期化子を使用して、NINearbyAccessoryConfigurationオブジェクトを構築します。

00:22:02.000 -> 00:22:15.000
この構成でNISessionを実行し、NISessionDelegateで共有可能な構成を受信してセットアップを完了し、共有可能な構成をアクセサリに送信します。

00:22:15.000 -> 00:22:27.000
アクセサリがBluetooth識別子と超広帯域構成の間に関係を作成するには、新しい近くのインタラクションGATTサービスを実装する必要があります。

00:22:27.000 -> 00:22:35.000
近くのインタラクションサービスには、アクセサリ構成データと呼ばれる単一の暗号化された特性が含まれています。

00:22:35.000 -> 00:22:43.000
NINearbyAccessoryConfigurationオブジェクトの初期化に使用されたのと同じUWB設定データが含まれています。

00:22:43.000 -> 00:22:53.000
iOSはこの特性を使用して、Bluetoothピア識別子とNISessionの関連性を検証します。

00:22:53.000 -> 00:22:57.000
あなたのアプリはこの特性から直接読み取ることはできません。

00:22:57.000 -> 00:23:07.000
この新しいNearby Interaction GATTサービスの詳細については、developer.apple.com/ nearby-interactionをご覧ください。

00:23:07.000 -> 00:23:20.000
アクセサリが複数のNISessionsを並行してサポートしている場合は、それぞれが異なるNISessionのUWB構成を持つアクセサリ構成データの複数のインスタンスを作成します。

00:23:20.000 -> 00:23:23.000
それがアクセサリーに必要なものです。

00:23:23.000 -> 00:23:30.000
いくつかのコードに飛び込んで、アプリケーションに実装する必要があるものに目を向けましょう!

00:23:30.000 -> 00:23:37.000
アクセサリのバックグラウンドセッションでは、アクセサリがユーザーのiPhoneにLEペアリングされている必要があります。

00:23:37.000 -> 00:23:40.000
あなたのアプリは、このプロセスをトリガーする責任があります。

00:23:40.000 -> 00:23:50.000
これを行うには、アクセサリをスキャンし、接続し、そのサービスと特性を発見する方法を実装します。

00:23:50.000 -> 00:23:56.000
次に、アクセサリの暗号化された特性の1つを読み取る方法を実装します。

00:23:56.000 -> 00:23:59.000
あなたはこれを一度だけ行う必要があります。

00:23:59.000 -> 00:24:03.000
ペアリングを受け入れるプロンプトがユーザーに表示されます。

00:24:03.000 -> 00:24:09.000
アクセサリのバックグラウンドセッションには、アクセサリへのBluetooth接続も必要です。

00:24:09.000 -> 00:24:15.000
アプリは、バックグラウンドでバックグラウンドされている場合でも、この接続を形成できる必要があります。

00:24:15.000 -> 00:24:20.000
これを行うには、アクセサリへの接続試行を開始する方法を実装します。

00:24:20.000 -> 00:24:26.000
アクセサリがBluetoothの範囲内にない場合でも、これを行う必要があります。

00:24:26.000 -> 00:24:38.000
次に、CBManagerDelegateメソッドを実装して、Core Bluetoothによってアプリが再起動された後に状態を復元し、接続が確立されたときに処理します。

00:24:38.000 -> 00:24:42.000
これで、アクセサリのバックグラウンドセッションを実行する準備が整いました。

00:24:42.000 -> 00:24:55.000
アクセサリのUWB構成データとCBPeripheral識別子からのBluetoothピア識別子の両方を提供することで、NINearbyAccessoryConfigurationオブジェクトを作成します。

00:24:55.000 -> 00:25:02.000
その設定でNISessionを実行すると、アプリがバックグラウンドになっている間に実行されます。

00:25:02.000 -> 00:25:03.000
それでおそれ！

00:25:03.000 -> 00:25:09.000
さて、Xcodeでアプリを更新する必要がある設定がもう1つあります。

00:25:09.000 -> 00:25:17.000
このバックグラウンドモードでは、アプリのInfo.plistのUIBackgroundModes配列の近くのインタラクション文字列が必要です。

00:25:17.000 -> 00:25:23.000
Xcodeの機能エディタを使用して、このバックグラウンドモードを追加することもできます。

00:25:23.000 -> 00:25:33.000
また、アプリがバックグラウンドでアクセサリに接続できるように、「Bluetooth LEアクセサリを使用」が有効になっていることを確認する必要があります。

00:25:33.000 -> 00:25:38.000
この新しいアクセサリーのバックグラウンドセッションに関する1つの重要な注意事項。

00:25:38.000 -> 00:25:49.000
アプリケーションがバックグラウンドにある場合、NISessionは引き続き実行され、中断されないため、超広帯域測定はアクセサリで利用できます。

00:25:49.000 -> 00:25:54.000
アクセサリの超広帯域測定値を消費し、行動する必要があります。

00:25:54.000 -> 00:26:06.000
アプリケーションはランタイムを受信せず、アプリケーションがフォアグラウンドに戻るまでdidUpdateNearbyObjectデリゲートコールバックを受信しません。

00:26:06.000 -> 00:26:11.000
この新しいバックグラウンドモードを使用する場合は、次のベストプラクティスを確認しましょう。

00:26:11.000 -> 00:26:17.000
アクセサリとのLEペアリングをトリガーすると、ペアリングを受け入れるプロンプトがユーザーに表示されます。

00:26:17.000 -> 00:26:23.000
アクセサリをペアリングしたい理由をユーザーにとって直感的な時間にこれを行います。

00:26:23.000 -> 00:26:32.000
これは、セットアップフローで、アクセサリとの関係を作成するか、ユーザーがアクセサリと対話したいという欲求を明確に示している可能性があります。

00:26:32.000 -> 00:26:42.000
アプリがバックグラウンドになっている間、NISessionは中断されませんが、didUpdateNearbyObjectデリゲートコールバックは受信されません。

00:26:42.000 -> 00:26:47.000
しかし、あなたのアクセサリーは超広帯域測定を受けます。

00:26:47.000 -> 00:26:54.000
これらの測定値をアクセサリで直接処理して、ユーザーにどのようなアクションが起こるべきかを判断します。

00:26:54.000 -> 00:27:06.000
最後に、重要なユーザーインタラクション中にアクセサリからアプリにデータを送信するだけで、バッテリー使用量を管理します。たとえば、ユーザーに通知を表示します。

00:27:06.000 -> 00:27:14.000
バックグラウンドセッションで知っておくべきことはそれだけであり、サードパーティのハードウェアサポートに関する最後のトピックに私を導きます。

00:27:14.000 -> 00:27:26.000
本日、以前に利用可能なベータU1互換開発キットがベータ版から外れ、より広く使用できることを発表できることを嬉しく思います。

00:27:26.000 -> 00:27:35.000
互換性のある超広帯域開発キットの詳細については、developer.apple.com /nearby-interactionをご覧ください。

00:27:35.000 -> 00:27:47.000
また、近くのインタラクションGATTサービスを含む新しいアクセサリーバックグラウンドセッションをサポートするために、アクセサリーメーカーの仕様を更新し、同じウェブサイトで入手できます。

00:27:47.000 -> 00:27:52.000
では、このセッションで話し合ったことをまとめましょう。

00:27:52.000 -> 00:28:09.000
近くのインタラクションには、ARKitと近くのインタラクションを緊密に統合する新しいカメラ支援モードが含まれており、ユーザーを近くのオブジェクトに導く空間認識体験を作成するためのシームレスな体験を提供します。

00:28:09.000 -> 00:28:21.000
アクセサリのバックグラウンドセッションを使用すると、セッションをバックグラウンドに開始および拡張して、ユーザーにとってよりハンズオフなエクスペリエンスを構築できます。

00:28:21.000 -> 00:28:28.000
サードパーティ互換のウルトラワイドバンドハードウェアサポートのエキサイティングなアップデートを発表しました。

00:28:28.000 -> 00:28:31.000
今年の近くのインタラクションのアップデートはこれで終わりです。

00:28:31.000 -> 00:28:43.000
デモをダウンロードし、更新された機能に関するフィードバックを提供し、更新されたサードパーティの仕様を確認し、空間体験を備えた素晴らしいアプリを構築してください。

00:28:43.000 -> 00:28:44.000
ありがとうございます。

00:28:44.000 -> 23:59:59.000
♪

