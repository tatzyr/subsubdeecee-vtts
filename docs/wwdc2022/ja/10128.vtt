WEBVTT

00:00:00.000 -> 00:00:03.000
♪まろやかなインストゥルメンタルヒップホップ音楽♪

00:00:03.000 -> 00:00:09.000
♪

00:00:09.000 -> 00:00:11.000
ハオ・タン:こんにちは、私の名前はハオです。

00:00:11.000 -> 00:00:15.000
私はオブジェクトキャプチャチームのエンジニアです。

00:00:15.000 -> 00:00:27.000
今日、同僚のRisaと私は、Object Capture APIとRealityKitを使用して、現実世界のオブジェクトの3Dモデルを作成し、それらをARに取り込む方法を紹介します。

00:00:27.000 -> 00:00:29.000
始めましょう。

00:00:29.000 -> 00:00:38.000
まず、昨年macOSでRealityKit APIとして立ち上げたObject Captureの要約をお伝えします。

00:00:38.000 -> 00:00:52.000
次に、ARKitのカメラ機能強化をいくつか紹介します。これにより、オブジェクトの高解像度写真をキャプチャでき、オブジェクトキャプチャをARアプリケーションによりよく統合するのに役立ちます。

00:00:52.000 -> 00:01:02.000
その後、オブジェクトキャプチャのベストプラクティスガイドラインに目を通し、この技術を最大限に活用し続けることができます。

00:01:02.000 -> 00:01:15.000
最後のセクションでは、RisaがRealityKitのオブジェクトキャプチャを使用したエンドツーエンドのワークフローを案内し、現実世界のオブジェクトをAR体験に持ち込む方法を実演します。

00:01:15.000 -> 00:01:19.000
オブジェクトキャプチャの簡単な要約から始めましょう。

00:01:19.000 -> 00:01:29.000
オブジェクトキャプチャは、現実世界のオブジェクトの画像を詳細な3Dモデルに簡単に回転させることができるコンピュータビジョン技術です。

00:01:29.000 -> 00:01:37.000
iPhone、iPad、またはデジタル一眼レフでさまざまな角度からオブジェクトの写真を撮ることから始めます。

00:01:37.000 -> 00:01:42.000
次に、それらの写真をオブジェクトキャプチャをサポートするMacにコピーします。

00:01:42.000 -> 00:01:51.000
Photogrammetry APIを使用すると、RealityKitはわずか数分で写真を3Dモデルに変換できます。

00:01:51.000 -> 00:02:02.000
出力モデルには、幾何学的なメッシュと、モデルに自動的に適用されるテクスチャを含むさまざまなマテリアルマップの両方が含まれています。

00:02:02.000 -> 00:02:12.000
オブジェクトキャプチャAPIの詳細については、オブジェクトキャプチャに関する昨年のWWDCセッションを見ることを強くお勧めします。

00:02:12.000 -> 00:02:25.000
多くの開発者は、Unity、Cinema4D、Qlone、PolyCam、PhotoCatchなど、オブジェクトキャプチャを使用して素晴らしい3Dキャプチャアプリを作成しました。

00:02:25.000 -> 00:02:31.000
これに加えて、このAPIを使用して作成された美しい外観のモデルがあります。

00:02:31.000 -> 00:02:39.000
これは、PhotoCatchアプリ内のオブジェクトキャプチャのパワーを使用してEthan Saadiaによって作成されたいくつかのモデルです。

00:02:39.000 -> 00:02:48.000
そして、Shopifyの友人Mikko Haapojaも、このAPIを使用して見栄えの良い3Dモデルの束を生成しました。

00:02:48.000 -> 00:02:56.000
オブジェクトキャプチャで得られる出力3Dモデルの詳細な品質は、電子商取引において非常に有益です。

00:02:56.000 -> 00:03:02.000
たとえば、足にさまざまな靴を試着できるGOATアプリがあります。

00:03:02.000 -> 00:03:12.000
これらの靴のモデルはすべて、最高級の詳細をキャプチャするように設計されたオブジェクトキャプチャAPIで作成されています。

00:03:12.000 -> 00:03:22.000
これは、製品の購入決定を支援したり、スペース内のオブジェクトに正確にフィットするように試してみたりするのに大いに役立ちます。

00:03:22.000 -> 00:03:34.000
たとえば、Plant Storyアプリを使用すると、スペース内のさまざまな植物の実際の3Dモデルをプレビューできます。これらはすべてオブジェクトキャプチャで作成されています。

00:03:34.000 -> 00:03:43.000
これは、植物に必要なスペースの感覚を得たり、単に現実的に詳細にあなたのスペースでそれらを見るのに役立ちます。

00:03:43.000 -> 00:03:49.000
リアリズムについて言えば、このビデオで本物の植物を見つけることができましたか?

00:03:49.000 -> 00:03:55.000
はい、それはテーブルの一番左隅にある白いプランターにあるものです。

00:03:55.000 -> 00:04:04.000
2021年の発売以来、Object Capture APIがこのような驚くほど広く使用されているのを見て、私たちは非常に興奮しています。

00:04:04.000 -> 00:04:14.000
さて、オブジェクトキャプチャによる再構築の品質に大きく役立つARKitのカメラ機能強化について話しましょう。

00:04:14.000 -> 00:04:21.000
優れたオブジェクトキャプチャ体験は、あらゆる側面からオブジェクトの良い写真を撮ることから始まります。

00:04:21.000 -> 00:04:31.000
この目的のために、iPhoneやiPadなどの高解像度カメラ、さらにはデジタル一眼レフカメラやミラーレスカメラを使用できます。

00:04:31.000 -> 00:04:47.000
iPhoneまたはiPadでカメラアプリを使用すると、深度と重力情報を含む高品質の写真を撮ることができ、Object Capture APIはオブジェクトの実際のスケールと向きを自動的に回復できます。

00:04:47.000 -> 00:05:03.000
それに加えて、iPhoneまたはiPadを使用している場合は、ARKitの追跡機能を利用して、モデルの上に3DガイダンスUIをオーバーレイして、あらゆる側面からオブジェクトをうまくカバーすることができます。

00:05:03.000 -> 00:05:14.000
注意すべきもう1つの重要な点は、キャプチャからの画像解像度が高いほど、オブジェクトキャプチャが生成できる3Dモデルの品質が向上するということです。

00:05:14.000 -> 00:05:23.000
そのために、今年のARKitのリリースでは、まったく新しい高解像度の背景写真APIを導入します。

00:05:23.000 -> 00:05:31.000
このAPIを使用すると、ARSessionを実行している間に、ネイティブカメラの解像度で写真をキャプチャできます。

00:05:31.000 -> 00:05:40.000
デバイス上のカメラセンサーを最大限に活用しながら、オブジェクトの上に3D UIオーバーレイを使用できます。

00:05:40.000 -> 00:05:47.000
iPhone 13では、それはワイドカメラの完全な12メガピクセルのネイティブ解像度を意味します。

00:05:47.000 -> 00:05:50.000
このAPIは非侵入的です。

00:05:50.000 -> 00:06:01.000
現在のARSessionの継続的なビデオストリームを中断しないため、アプリはユーザーにスムーズなAR体験を提供し続けます。

00:06:01.000 -> 00:06:16.000
さらに、ARKitはEXIFメタデータを写真で使用できるようにします。これにより、アプリはホワイトバランス、露出、および後処理に価値のあるその他の設定に関する有用な情報を読むことができます。

00:06:16.000 -> 00:06:22.000
ARKitを使用すると、この新しいAPIをアプリで非常に簡単に使用できます。

00:06:22.000 -> 00:06:37.000
ARWorldTrackingConfgurationで高解像度フレームキャプチャをサポートするビデオフォーマットを照会するだけで、成功したら、新しいビデオフォーマットを設定してARSessionを実行できます。

00:06:37.000 -> 00:06:53.000
高解像度写真のキャプチャに関しては、ARSessionの新しいcaptureHighResolutionFrame API関数を呼び出すだけで、非同期に完了ハンドラを介して高解像度の写真が返されます。

00:06:53.000 -> 00:06:56.000
それはとても簡単です。

00:06:56.000 -> 00:07:07.000
また、フォーカス、露出、ホワイトバランスなどのカメラ設定を手動で制御することを好むユースケースもあることも認識しています。

00:07:07.000 -> 00:07:19.000
そのため、基礎となるAVCaptureDeviceに直接アクセスし、きめ細かなカメラ制御のためにそのプロパティを変更する便利な方法を提供しています。

00:07:19.000 -> 00:07:33.000
このコード例に示すように、ARWorldTrackingConfigurationでconfigurableCaptureDevice ForPrimaryCameraを呼び出すだけで、基盤となるAVCaptureDeviceにアクセスできます。

00:07:33.000 -> 00:07:44.000
これらの機能強化の詳細については、今年のWWDCの「Discover ARKit 6セッション」をチェックすることを強くお勧めします。

00:07:44.000 -> 00:07:49.000
では、オブジェクトキャプチャに関するベストプラクティスのガイドラインをいくつか確認しましょう。

00:07:49.000 -> 00:07:56.000
まず最初に、オブジェクトキャプチャに適切な特性を持つオブジェクトを選択する必要があります。

00:07:56.000 -> 00:08:01.000
良い物体は、その表面に十分な質感を持っています。

00:08:01.000 -> 00:08:09.000
オブジェクトの一部の領域がテクスチャレスまたは透明である場合、それらの領域の詳細はうまく再構築されない可能性があります。

00:08:09.000 -> 00:08:14.000
良い物体はまた、まぶしさや反射がないはずです。

00:08:14.000 -> 00:08:21.000
オブジェクトにマットな表面がない場合は、拡散照明を使用して鏡面を減らすことができます。

00:08:21.000 -> 00:08:29.000
オブジェクトを裏返して底をキャプチャしたい場合は、オブジェクトが硬いままであることを確認してください。

00:08:29.000 -> 00:08:33.000
言い換えれば、ひっくり返したときに形を変えるべきではありません。

00:08:33.000 -> 00:08:48.000
そして最後に、良いオブジェクトはある程度細かい構造を含むことができますが、オブジェクトの細かい詳細を回復するには、高解像度カメラを使用してクローズアップ写真を撮る必要があります。

00:08:48.000 -> 00:08:52.000
次に重要なことは、理想的なキャプチャ環境を設定することです。

00:08:52.000 -> 00:09:00.000
キャプチャ環境に良好で均一で拡散した照明があることを確認する必要があります。

00:09:00.000 -> 00:09:06.000
安定した背景を確保し、オブジェクトの周りに十分なスペースを確保することが重要です。

00:09:06.000 -> 00:09:11.000
部屋が暗い場合は、明るいターンテーブルを利用できます。

00:09:11.000 -> 00:09:24.000
次に、オブジェクトの良い写真をキャプチャするためのいくつかのガイドラインを見ていきます。これにより、オブジェクトキャプチャから良質の3Dモデルが確実に取得されます。

00:09:24.000 -> 00:09:37.000
例として、同僚のマウネシュがiPhoneを使って、私たちの最愛のARKitエンジニア、クリスチャン・リプスキーによって作成された美しい海賊船の画像をキャプチャする方法を紹介します。

00:09:37.000 -> 00:09:43.000
マウネシュは、海賊船を清潔なテーブルの真ん中に置くことから始めます。

00:09:43.000 -> 00:09:47.000
これにより、船は写真ではっきりと目立ちます。

00:09:47.000 -> 00:09:51.000
彼は両手でiPhoneを着実に握っている。

00:09:51.000 -> 00:09:57.000
ゆっくりと船の周りを回っていると、さまざまな高さで写真を撮ります。

00:09:57.000 -> 00:10:07.000
彼は、最大限の詳細をキャプチャできるように、船がカメラの視野の中央に十分な大きさであることを確認します。

00:10:07.000 -> 00:10:15.000
彼はまた、隣接する2枚の写真の間に常に高い重なりを維持していることを確認しています。

00:10:15.000 -> 00:10:27.000
彼がかなりの数の写真を撮った後(この場合は約80枚)、彼は船を横にひっくり返して、底を再構築することもできます。

00:10:27.000 -> 00:10:34.000
彼は反転した向きで船のさらに約20枚の写真を撮り続けています。

00:10:34.000 -> 00:10:39.000
注意すべきことの1つは、彼がiPhoneを横向きモードで保持していることです。

00:10:39.000 -> 00:10:49.000
これは、彼が長いオブジェクトをキャプチャしているためであり、この場合、ランドスケープモードはオブジェクトの最大量の詳細をキャプチャするのに役立ちます。

00:10:49.000 -> 00:10:59.000
しかし、代わりに背の高い物体をキャプチャする場合は、ポートレートモードでiPhoneを使用する必要があるかもしれません。

00:10:59.000 -> 00:11:00.000
それでおそれ！

00:11:00.000 -> 00:11:09.000
プロセスの最後のステップは、これらの写真をMacにコピーし、Object Capture APIを使用して処理することです。

00:11:09.000 -> 00:11:15.000
さまざまなユースケースに最適化された4つの異なる詳細レベルから選択できます。

00:11:15.000 -> 00:11:25.000
縮小および中程度の詳細レベルは、AR QuickLookで3Dコンテンツを表示するなど、Webベースおよびモバイルエクスペリエンスでの使用に最適化されています。

00:11:25.000 -> 00:11:34.000
これらの詳細レベルの再構築されたモデルは、三角形や材料チャネルが少ないため、メモリの消費が少なくなります。

00:11:34.000 -> 00:11:44.000
完全および生の詳細レベルは、コンピュータゲームやポストプロダクションワークフローなど、ハイエンドのインタラクティブなユースケースを対象としています。

00:11:44.000 -> 00:11:55.000
これらのモデルには最高の幾何学的ディテールが含まれており、焼きたての材料と未焼いた材料のどちらかを選択する柔軟性を提供しますが、再構築するにはより多くのメモリが必要です。

00:11:55.000 -> 00:12:00.000
ユースケースに応じて、適切な出力レベルを選択することが重要です。

00:12:00.000 -> 00:12:09.000
海賊船では、M1 Macで処理するのに数分しかかからなかった中程度の詳細レベルを選択しました。

00:12:09.000 -> 00:12:18.000
出力3Dモデルはとても見事に見えたので、実際に公海を航行する海賊船のアニメーションクリップをまとめました。

00:12:18.000 -> 00:12:22.000
そして、それがあなたのためのオブジェクトキャプチャの力です!

00:12:22.000 -> 00:12:24.000
アホイ！

00:12:24.000 -> 00:12:31.000
今、私はそれをRisaに引き渡します。Risaは、RealityKitのObject Captureを使用してエンドツーエンドのワークフローを案内します。

00:12:31.000 -> 00:12:33.000
米山理沙:ありがとう、ハオ。

00:12:33.000 -> 00:12:46.000
オブジェクトキャプチャAPIを確認したので、RealityKitを使用して実際のオブジェクトをARに取り込むために、エンドツーエンドの開発者ワークフローを確認できることを嬉しく思います。

00:12:46.000 -> 00:12:54.000
ワークフローの例で各ステップを詳細に説明しますので、デモに飛び込みましょう。

00:12:54.000 -> 00:13:02.000
私の同僚のザックは時折木工職人であり、最近6つの特大の木製のチェスの駒を建てました - それぞれのユニークな駒に1つずつ。

00:13:02.000 -> 00:13:08.000
これらのチェスの駒を見て、私はインタラクティブなARチェスゲームを作成することに触発されています。

00:13:08.000 -> 00:13:15.000
以前は、現実世界のオブジェクトの高品質の3Dモデルを作成するには、3Dモデラーと材料の専門家が必要でした。

00:13:15.000 -> 00:13:24.000
これで、Object Capture APIを使用すると、これらのチェスの駒を直接キャプチャし、拡張現実に持ち込むことができます。

00:13:24.000 -> 00:13:27.000
ルークを捕獲することから始めましょう。

00:13:27.000 -> 00:13:35.000
私の同僚のブライアンは、前のセクションで説明したベストプラクティスを念頭に置いて、このプロのセットアップを使用します。

00:13:35.000 -> 00:13:44.000
この場合、ブライアンは、最終的な出力で厳しい影を避けるために、いくつかのプロの照明でこのターンテーブルにルークを置いています。

00:13:44.000 -> 00:13:54.000
また、出力USDZで自動スケール推定と重力ベクトル情報を提供するターンテーブルでiPhoneカメラを使用することもできます。

00:13:54.000 -> 00:14:00.000
詳細については、2021年からのオブジェクトキャプチャセッションを参照してください。

00:14:00.000 -> 00:14:12.000
もちろん、ブライアンがここで行うような精巧なセットアップがない場合は、iOSデバイスを持ち、オブジェクトの周りを歩き回って画像をキャプチャすることもできます。

00:14:12.000 -> 00:14:17.000
ルークピースのすべての写真がわかったので、これらをMacに転送します。

00:14:17.000 -> 00:14:24.000
2021年に導入されたPhotogrammetrySession APIを使用して、これらの写真を処理します。

00:14:24.000 -> 00:14:33.000
ベストプラクティスのガイドラインに従って、ARアプリがうまく機能することを確認したいので、縮小された詳細レベルを使用して再構築します。

00:14:33.000 -> 00:14:38.000
APIの最終出力は、USDZファイルタイプモデルになります。

00:14:38.000 -> 00:14:43.000
これが私が再構築したばかりのルークチェスの駒の最終出力です。

00:14:43.000 -> 00:14:50.000
時間を節約するために、私は先に進み、他の5つの作品を事前にキャプチャしました。

00:14:50.000 -> 00:14:56.000
チェスの駒の配色が1つしかないチェスゲームをどうやって作るのか疑問に思うかもしれません。

00:14:56.000 -> 00:15:01.000
6つのユニークなピースを複製して、Reality Converterにドラッグしましょう。

00:15:01.000 -> 00:15:08.000
元のテクスチャの色を反転し、重複したセットをこの新しい反転テクスチャに置き換えました。

00:15:08.000 -> 00:15:15.000
このようにして、各プレイヤーに1つずつ、より軽いバージョンと暗いバージョンのチェスの駒を持つことができます。

00:15:15.000 -> 00:15:20.000
エクスポートメニューで圧縮テクスチャオプションをオンにしてモデルをエクスポートします。

00:15:20.000 -> 00:15:26.000
これは、テクスチャのメモリフットプリントを減らすのに役立ちます。

00:15:26.000 -> 00:15:33.000
チェスの駒のフルセットができたので、モデルをXcodeプロジェクトに持ち込む準備が整いました。

00:15:33.000 -> 00:15:42.000
Y軸のプリミティブキューブを縮小し、黒と白の色を交互にすることで、RealityKitを使用してチェス盤を作成しました。

00:15:42.000 -> 00:15:47.000
ここに私が再建したすべてのチェスの駒がチェス盤にレイアウトされています。

00:15:47.000 -> 00:15:56.000
これは、私たちのアプリケーションで実際のオブジェクトを見るのはすでにエキサイティングですが、実際のインタラクティブなゲームにするためにいくつかの機能を追加し始めましょう。

00:15:56.000 -> 00:16:08.000
デモのこの部分を通して、いくつかの異なる既存の技術を紹介したいと思いますので、目的の出力を達成するために技術を組み合わせる方法の例を提供できます。

00:16:08.000 -> 00:16:20.000
RealityKitの高度なトピックの実用的なユースケースをいくつか見上げるので、まだAPIに精通していない場合は、2021年からのRealityKitセッションをチェックすることをお勧めします。

00:16:20.000 -> 00:16:26.000
最初にアプリケーションを起動するときに、スタートアップアニメーションを追加することから始めたいと思います。

00:16:26.000 -> 00:16:36.000
チェスの駒も一緒に翻訳されている間、チェッカータイルが最終的な位置の少し上からゆっくりと所定の位置に落ちるアニメーションを想像しています。

00:16:36.000 -> 00:16:41.000
この効果をコードに再現するには、2つのステップが必要です。

00:16:41.000 -> 00:16:50.000
最初のステップは、両方のエンティティをy軸に沿って翻訳し、チェスの駒を均一に縮小することです。

00:16:50.000 -> 00:16:56.000
2番目のステップと最後のステップは、両方のエンティティを元の変換に戻すことです。

00:16:56.000 -> 00:16:59.000
これのコードは非常に簡単です。

00:16:59.000 -> 00:17:03.000
チェッカータイルエンティティを反復することから始めます。

00:17:03.000 -> 00:17:10.000
各エンティティについて、これが着地する最終的な位置になるため、チェッカータイルの現在の変換を保存します。

00:17:10.000 -> 00:17:16.000
次に、各正方形をy軸で10cm上に移動します。

00:17:16.000 -> 00:17:22.000
これで、移動機能を利用して、これを元の変換に戻すことができます。

00:17:22.000 -> 00:17:29.000
また、チェッカーボードを概説するこのボーダーUSDZには、アニメーションが組み込まれていることも知っています。

00:17:29.000 -> 00:17:35.000
playAnimation APIを使用して、アニメーションを同時に開始できます。

00:17:35.000 -> 00:17:42.000
チェスの駒にまったく同じアニメーションを追加しましたが、翻訳されるにつれてスケールも変更しました。

00:17:42.000 -> 00:17:47.000
そして、ここにそれがあります:ほんの数行のコードでシンプルなスタートアップアニメーション。

00:17:47.000 -> 00:17:53.000
しかし、チェスの駒を動かす能力がなければ、実際にはチェスをすることはできません。

00:17:53.000 -> 00:17:55.000
次はそれに取り組みましょう。

00:17:55.000 -> 00:18:00.000
チェスの駒を動かし始める前に、1つを選択できるようにする必要があります。

00:18:00.000 -> 00:18:05.000
私はすでにARViewにUITapGestureRecognizerを追加しました。

00:18:05.000 -> 00:18:14.000
ユーザーが特定の場所をタップすると、カメラの原点から始まり、その2Dポイントを通過する光線を定義します。

00:18:14.000 -> 00:18:21.000
その後、そのレイで3Dシーンにレイキャストを実行して、エンティティにヒットしたかどうかを確認できます。

00:18:21.000 -> 00:18:29.000
私は自分のシーンでチェスの駒を選択できるようにしたいだけなので、チェスの駒の衝突グループをマスクとして指定しました。

00:18:29.000 -> 00:18:35.000
レイキャスト関数は、CollisionComponentを持っていないすべてのエンティティを無視することに注意してください。

00:18:35.000 -> 00:18:39.000
チェスの駒を見つけたら、最終的にそれを選ぶことができます。

00:18:39.000 -> 00:18:47.000
どの作品が選択されているかがわかったので、作品が光っているように見せる効果を追加したい。

00:18:47.000 -> 00:18:52.000
これを達成するためにカスタム材料を活用することができます。より具体的には、表面シェーダーです。

00:18:52.000 -> 00:19:03.000
サーフェスシェーダーを使用すると、Metalを介して材料パラメータを計算または指定することができ、その後、各ピクセルごとに1回、RealityKitのフラグメントシェーダーによって呼び出されます。

00:19:03.000 -> 00:19:08.000
メタルでこの火災効果のように見える表面シェーダーを書くことができます。

00:19:08.000 -> 00:19:15.000
次に、カスタム素材を適用し、このサーフェスシェーダーを長方形のプリズムに適用し、シェーダーがエンティティの外観に影響を与えます。

00:19:15.000 -> 00:19:19.000
望ましい効果を達成するために、いくつかのコードを書きましょう。

00:19:19.000 -> 00:19:24.000
このサーフェスシェーダーで使用するノイズテクスチャをプロジェクトに追加しました。

00:19:24.000 -> 00:19:30.000
テクスチャを2回サンプリングします。1回は効果の全体的な形状で、もう1回は詳細です。

00:19:30.000 -> 00:19:35.000
次に、RGB値を取り、私たちが望むように見えるように再マップします。

00:19:35.000 -> 00:19:45.000
次に、抽出したばかりの処理値を使用して、y位置と画像値を比較して、サンプルポイントの不透明度を計算します。

00:19:45.000 -> 00:19:52.000
効果にいくらかの動きを与えるために、私たちは時間の関数としてテクスチャのy軸を通って移動します。

00:19:52.000 -> 00:20:02.000
さらに、各サンプルポイントの面角をカメラの表示方向と組み合わせて使用して、側面の効果をフェードします。

00:20:02.000 -> 00:20:07.000
これにより、エッジが柔らかくなり、基礎となるモデルの規則的な性質が隠されます。

00:20:07.000 -> 00:20:15.000
最後に、サーフェスパラメータ関数を使用して計算した色と不透明度を設定します。

00:20:15.000 -> 00:20:19.000
そして、ここに選択シェーダーが適用されたチェスの駒があります。

00:20:19.000 -> 00:20:22.000
彼らは本当に内側から輝いているように見えます。

00:20:22.000 -> 00:20:30.000
さて、それを3つの別々の翻訳アニメーションと組み合わせると、このようなものになります。

00:20:30.000 -> 00:20:38.000
チェスの駒を動かす機能が実装されているため、相手の駒をキャプチャすることもできます。

00:20:38.000 -> 00:20:45.000
サーフェスシェーダーと同様に、ジオメトリ修飾子はカスタムマテリアルを使用して実装できます。

00:20:45.000 -> 00:20:54.000
位置、法線、テクスチャ座標などの頂点データを変更できるため、非常に強力なツールです。

00:20:54.000 -> 00:21:00.000
これらのメタル関数のそれぞれは、RealityKitの頂点シェーダーによって頂点ごとに1回呼び出されます。

00:21:00.000 -> 00:21:08.000
これらの変更は純粋に一時的なものであり、実際のエンティティの頂点情報には影響しません。

00:21:08.000 -> 00:21:14.000
キャプチャされたときにピースをつぶすために、楽しいジオメトリ修飾子を追加できると思います。

00:21:14.000 -> 00:21:24.000
私は0から1までのキャプチャアニメーションの進行状況を表すために、 capturedProgressと呼ばれる私のチェスの駒にこのプロパティを持っています。

00:21:24.000 -> 00:21:32.000
キャプチャはユーザーが開始したアクションであるため、どういうわけかジオメトリ修飾子にアニメーションを開始するタイミングを伝える必要があります。

00:21:32.000 -> 00:21:38.000
良いことは、customMaterialにカスタムプロパティを設定することでこれを行うことができることです。

00:21:38.000 -> 00:21:42.000
これにより、CPUとGPUの間でデータを共有できます。

00:21:42.000 -> 00:21:50.000
ここでは特にカスタム値プロパティを使用し、アニメーションの進行状況をジオメトリ修飾子に渡します。

00:21:50.000 -> 00:21:57.000
メタル側からアニメーションの進行状況を抽出するには、ユニフォームのカスタムパラメータを使用できます。

00:21:57.000 -> 00:22:06.000
別のピースに押しつぶされているかのように、オブジェクトを垂直にスケーリングしたいので、スケール軸をy方向として設定します。

00:22:06.000 -> 00:22:13.000
アニメーションに複雑さを加えるために、x軸のジオメトリを変更して波効果を作成します。

00:22:13.000 -> 00:22:19.000
頂点のオフセットは、set_model_position_ offset関数を使用して設定できます。

00:22:19.000 -> 00:22:23.000
これが私たちのジオメトリ修飾子の最終製品です。

00:22:23.000 -> 00:22:30.000
X軸に沿って垂直に引き伸ばされながら、崩壊する前に少しスケールアップすることがわかります。

00:22:30.000 -> 00:22:40.000
チェスの初心者として、私がゲームを学ぶのを助けるために、選択したピースがどこに移動できるかを示す機能を追加すると役立つかもしれないと思いました。

00:22:40.000 -> 00:22:52.000
チェッカーピースは、独自のモデルコンポーネントを持つ個々のエンティティであるため、サーフェスシェーダーを使用して潜在的な動きにパルス効果を適用して、他の要素と区別することができます。

00:22:52.000 -> 00:22:58.000
次に、「ブルーム」と呼ばれる後処理効果を追加して、効果をさらに強調します。

00:22:58.000 -> 00:23:04.000
繰り返しになりますが、グロー効果のためにサーフェスシェーダーで使用したカスタムパラメータを使用しています。

00:23:04.000 -> 00:23:11.000
この場合、CPU側からメタルサーフェスシェーダーにブール値を渡しています。

00:23:11.000 -> 00:23:16.000
このチェッカーが可能な動きであれば、色を変更して脈動効果を加えたいです。

00:23:16.000 -> 00:23:21.000
ここでは、特に発光色にパルスを追加します。

00:23:21.000 -> 00:23:25.000
最後に、ビュー全体にブルーム効果を追加します。

00:23:25.000 -> 00:23:32.000
ブルームは、明るい領域の境界から光の羽を生成する後処理効果です。

00:23:32.000 -> 00:23:39.000
ARViewのrender callbacksプロパティを活用することで、この効果を実現できます。

00:23:39.000 -> 00:23:45.000
すでに内蔵されているメタルパフォーマンスシェーダー機能を使用して、ブルーム効果を書きます。

00:23:45.000 -> 00:23:52.000
次に、先ほど定義したブルーム関数としてrenderCallbacks.postProcessクロージャを設定するだけです。

00:23:52.000 -> 00:24:00.000
チェッカーを脈打つと、白い色に脈動し、ブルーム効果でさらに強調されます。

00:24:00.000 -> 00:24:08.000
表面シェーダーとブルーム効果を合わせると、ピースをどこに移動できるかを正確に見ることができます。

00:24:08.000 -> 00:24:16.000
最後に、私たちが持っているすべてのものを組み合わせて、ARアプリで現実のチェスの駒が生き生きとしているのを見てみましょう。

00:24:16.000 -> 00:24:21.000
私たちは、私たちが追加したすべての機能が私たちの環境でどのように見えるかを見ることができます。

00:24:21.000 -> 00:24:26.000
あなたの便宜のために、キャプチャチェスのサンプルプロジェクトをセッションリソースにリンクしました。

00:24:26.000 -> 00:24:31.000
ダウンロードして、自分の環境で見るために自分で試してみてください。

00:24:31.000 -> 00:24:32.000
そして、それは簡単です。

00:24:32.000 -> 00:24:40.000
キャプチャから特大のチェスの駒の再構築まで、そして私たちの拡張現実アプリに。

00:24:40.000 -> 00:24:46.000
今日のこのセッションでは多くのことを取り上げたので、いくつかの重要なポイントをまとめましょう。

00:24:46.000 -> 00:24:53.000
私たちはまず、2021年に発表したオブジェクトキャプチャAPIを要約することから始めました。

00:24:53.000 -> 00:25:03.000
その後、アクティブなARSession中にネイティブカメラ解像度でオンデマンドで写真をキャプチャできるARKitの新しいAPIを調べました。

00:25:03.000 -> 00:25:19.000
オブジェクトキャプチャ技術を最大限に活用するために、再構築に適したオブジェクトの種類、高品質の画像を取得するための理想的な環境、およびオブジェクトのキャプチャ中に従うべき推奨フローをリストアップしました。

00:25:19.000 -> 00:25:25.000
このセッションの後半では、エンドツーエンドの開発者ワークフローの例を見てきました。

00:25:25.000 -> 00:25:35.000
特大のチェスの駒の写真をキャプチャし、PhotogrammetrySession APIへの入力として画像を使用して3Dモデルを作成しました。

00:25:35.000 -> 00:25:40.000
次に、いくつかのテクスチャを置き換えるために、モデルをReality Converterにインポートしました。

00:25:40.000 -> 00:25:47.000
そして最後に、私たちはゆっくりとチェスゲームを構築し、ARでチェスの駒が動作しているのを見ました。

00:25:47.000 -> 00:25:50.000
そして、今日のセッションはそれだけです。

00:25:50.000 -> 00:25:51.000
ご覧いただき、誠にありがとうございます。

00:25:51.000 -> 00:25:53.000
アホイ！

00:25:53.000 -> 23:59:59.000
♪

