WEBVTT

00:00:00.000 -> 00:00:03.000
♪まろやかなインストゥルメンタルヒップホップ音楽♪

00:00:03.000 -> 00:00:09.000
♪

00:00:09.000 -> 00:00:13.000
ナマスカル！こんにちは、WWDC22へようこそ。

00:00:13.000 -> 00:00:22.000
私の名前はCreate MLチームのエンジニアであるVrushali Mundheです。Create MLの新機能について皆さんと共有できることを嬉しく思います。

00:00:22.000 -> 00:00:32.000
Create MLを使用すると、収集したデータを使用して強力な機械学習モデルを簡単にトレーニングして、ユニークなエクスペリエンスを提供し、アプリを強化できます。

00:00:32.000 -> 00:00:41.000
Create MLはXcodeにバンドルされたアプリとして出荷され、コードなしでMac上でCore MLモデルをすばやく構築してトレーニングできます。

00:00:41.000 -> 00:00:47.000
Create MLは、SDKで出荷されるSwiftフレームワークとしても利用できます。

00:00:47.000 -> 00:00:57.000
APIを使用すると、モデルの作成を簡単に自動化したり、独自のアプリ内から直接トレーニングによるダイナミックな体験を作成したりできます。

00:00:57.000 -> 00:01:04.000
Create MLのコア機能の詳細については、これらの以前のセッションをご覧ください。

00:01:04.000 -> 00:01:08.000
このセッションでは、Create MLの新機能について説明します。

00:01:08.000 -> 00:01:14.000
モデルの精度と有用性を評価するのに役立つCreate MLアプリの新機能から始めます。

00:01:14.000 -> 00:01:26.000
その後、Create MLフレームワーク、その拡張機能、および独自のアプリのモデルを高度にカスタマイズする機能に注意を向けます。

00:01:26.000 -> 00:01:30.000
モデル作成のための典型的なワークフローを見直すことから始めましょう。

00:01:30.000 -> 00:01:35.000
特定されたタスクが与えられた場合、データを収集して注釈を付けることから始めます。

00:01:35.000 -> 00:01:40.000
例えば、食料品を視覚的に識別したいとします。

00:01:40.000 -> 00:01:50.000
この画像分類タスクでは、出発点は画像の収集とラベル付けです。ここでは、いくつかの果物と野菜。

00:01:50.000 -> 00:01:56.000
Create MLは、アプリで使用できるこのデータからモデルをトレーニングするのに役立ちます。

00:01:56.000 -> 00:02:09.000
しかし、このモデルを使用する前に、重要なステップは、それがどれほどうまく機能するかを評価することです。ここでは、トレーニングセットの一部ではなかった画像でモデルがどれほど正確であるかを確認しています。

00:02:09.000 -> 00:02:26.000
評価によっては、追加のデータと変更されたトレーニング設定でモデルを反復するか、モデルが十分に機能したら、アプリに統合する準備が整いました。この評価にさらに焦点を当てたいと思います。

00:02:26.000 -> 00:02:35.000
評価を実行するとき、私たちはしばしば、トレーニングから持ち出された新しいデータでモデルをテストすることによって測定された一連の指標に目を向けます。

00:02:35.000 -> 00:02:48.000
トップレベルの精度メトリックを見ることから始めるか、クラスごとの統計に飛び込んで、モデルの行動の一般的な感覚と、訓練されたものを超えて一般化する能力を得ることができます。

00:02:48.000 -> 00:03:07.000
最終的に、モデルはアプリでデータ駆動型のエクスペリエンスを強化する責任があり、評価中は、入力やシナリオのカテゴリの観点からモデルの主な長所と短所を特定したいと考えています。それはうまくいくか、期待を下回る可能性があります。

00:03:07.000 -> 00:03:13.000
Create MLアプリには、モデル作成の旅のこの部分に役立つ新機能があります。

00:03:13.000 -> 00:03:16.000
私が取り組んでいるプロジェクトをお見せしましょう。

00:03:16.000 -> 00:03:20.000
ここでは、食料品を識別するためのモデルを作成するためのプロジェクトを設定しています。

00:03:20.000 -> 00:03:30.000
私はトレーニングデータとしてさまざまな果物や野菜の画像を収集し、適切にラベル付けすることから始めました。

00:03:30.000 -> 00:03:38.000
これは私の異なるクラスと各クラスの画像の数です。

00:03:38.000 -> 00:03:43.000
私はすでに25回の反復のために画像分類器を訓練しました。

00:03:43.000 -> 00:03:58.000
次に、[評価]タブをクリックすると、新しいテストデータを追加できます。これは、テスト用に取っておいたトレーニングデータとは別に、一連の画像です。

00:03:58.000 -> 00:04:03.000
次に、[評価]をクリックしてテストを開始します。

00:04:03.000 -> 00:04:08.000
評価が完了すると、UIは結果の詳細を提供します。

00:04:08.000 -> 00:04:14.000
上部には、テストの精度をすばやく把握できる高レベルの要約セクションがあります。

00:04:14.000 -> 00:04:19.000
ここでは、このテストデータの精度は89%です。

00:04:19.000 -> 00:04:24.000
このメトリクスタブの下にある表は、各クラスの豊富なメトリクスを提供します。

00:04:24.000 -> 00:04:32.000
これらのドロップダウンメニューを使用してここに表示されているものを調整し、偽陽性や偽陰性などの指標を追加できます。

00:04:32.000 -> 00:04:34.000
これらのクラスの1つを復習しましょう。

00:04:34.000 -> 00:04:36.000
トマトはどうですか？

00:04:36.000 -> 00:04:40.000
このモデルは、32枚のトマト画像のうち29枚を正しく分類しました。

00:04:40.000 -> 00:04:50.000
また、このクラスの精度が91%であることを示しています。これは、モデルが何かがトマトであると言う時間の9%を意味し、それは間違っています。

00:04:50.000 -> 00:04:58.000
これらの数字と統計は非常に便利ですが、データ自体のコンテキストでそれらを見ることがさらに重要な場合があります。

00:04:58.000 -> 00:05:05.000
精度をクリックすると、トマトとして誤って分類された画像が表示されます。

00:05:05.000 -> 00:05:08.000
テストデータには、これらのケースの3つを次に示します。

00:05:08.000 -> 00:05:16.000
各画像について、アプリはサムネイル、モデルが予測したクラス、およびその下にある真のラベルを表示します。

00:05:16.000 -> 00:05:22.000
この最初の例では、モデルはこれをトマトに分類しましたが、ジャガイモとラベル付けされていました。

00:05:22.000 -> 00:05:25.000
しかし、これは確かに私にはトマトのように見えます。

00:05:25.000 -> 00:05:27.000
これは、テストデータが誤ってラベル付けされたケースのようです。

00:05:27.000 -> 00:05:31.000
実際、これらの3つの例はすべて誤ってラベル付けされているようです。

00:05:31.000 -> 00:05:33.000
これは簡単に対処できるはずです。

00:05:33.000 -> 00:05:37.000
テストセットのラベル付けを再確認して再検討するようにメモします。

00:05:37.000 -> 00:05:42.000
これは明らかに私の側のエラーでしたが、それが唯一のエラーの原因ですか?

00:05:42.000 -> 00:05:47.000
私は私が選んだランダムなクラスのメトリクスを探索してここに来ました。

00:05:47.000 -> 00:05:50.000
「どこから始めればいいの？」と疑問に思うかもしれません。

00:05:50.000 -> 00:05:53.000
または、「次は何を探索すればよいですか?」

00:05:53.000 -> 00:05:58.000
トップレベルの要約セクションは、あなたを助けるためにここにあります。

00:05:58.000 -> 00:06:05.000
アプリは、あなたの探検を始めるのに最適な場所として役立つことができる最も重要な評価の詳細のいくつかを選択しました。

00:06:05.000 -> 00:06:10.000
上からやり直して、成功したケースを確認させてください。

00:06:10.000 -> 00:06:15.000
ここをクリックすると、この正しいカウント...

00:06:15.000 -> 00:06:23.000
ここでは、モデルが正しく分類されたすべての162枚の画像をすばやく見ることができます。

00:06:23.000 -> 00:06:31.000
次に、間違ったものをクリックして、すべての失敗のレビューと対比させてください。

00:06:31.000 -> 00:06:35.000
合計で21の失敗があります。

00:06:35.000 -> 00:06:38.000
これはまた誤ったラベルのトマトです。

00:06:38.000 -> 00:06:43.000
目立つ他の種類のエラーがあるかどうか確認させてください。

00:06:43.000 -> 00:06:46.000
いかがですか...これ？

00:06:46.000 -> 00:06:53.000
この画像はニンジンとラベル付けされていますが、モデルはジャガイモと予測しています。

00:06:53.000 -> 00:07:01.000
この小さなサムネイルではわかりにくいですが、この画像をクリックして確認して、より良いビューを取得しましょう。

00:07:01.000 -> 00:07:03.000
まあ、これは私には足のように見えます。

00:07:03.000 -> 00:07:09.000
これは明らかに私が慣れている長くて細いニンジンの形ではありませんが、ジャガイモとして簡単に混同する可能性があります。

00:07:09.000 -> 00:07:14.000
おそらく、ニンジンのトレーニングデータにより多くの形状のバリエーションを追加することを検討する必要があります。

00:07:14.000 -> 00:07:16.000
これもメモしておきます。

00:07:16.000 -> 00:07:25.000
今回は、ファイル名の横にある矢印をクリックして、Finderのこの画像に移動します。

00:07:25.000 -> 00:07:36.000
次のデータ収集で再検討したいことを思い出させるために、右クリックしてこれを赤のラベルを付けます。

00:07:36.000 -> 00:07:40.000
この拡張されたビューの中から私の探検を続けさせてください。

00:07:40.000 -> 00:07:46.000
このビューには、完全な予測結果も表示され、すべてのクラスにおけるモデルの信頼度がリストされていることに注意してください。

00:07:46.000 -> 00:07:53.000
また、これらの左右の矢印を使用して例をナビゲートすることもできます。

00:07:53.000 -> 00:07:57.000
ここから別の例に移ります。

00:07:57.000 -> 00:07:58.000
これは興味深いケースです。

00:07:58.000 -> 00:08:02.000
1つの画像に複数の野菜があります。

00:08:02.000 -> 00:08:11.000
それはナスだと書いてあり、ここにナスがあるのは事実ですが、他のものもあります。

00:08:11.000 -> 00:08:16.000
これが私のアプリで考慮すべき重要なユースケースであるかどうかを考える必要があります。

00:08:16.000 -> 00:08:32.000
おそらく、UIは、一度に1種類の食料品のみを指すようにユーザーを導くことができるか、複数のタイプをサポートしたい場合は、画像分類器全体ではなく、オブジェクト検出器（アプリ内の別のテンプレート）の使用を検討することをお勧めします。

00:08:32.000 -> 00:08:37.000
要約セクションに戻ると、トップの混乱についてこの行を確認させてください。

00:08:37.000 -> 00:08:40.000
ここでは「ペッパー」と「ビーン」と書かれています。

00:08:40.000 -> 00:08:44.000
クリックしてこのケースを調査しましょう。

00:08:44.000 -> 00:08:49.000
ピーマンとラベル付けされた4つの画像は、誤って豆に分類されています。

00:08:49.000 -> 00:08:55.000
これらは私にはスパイシーなピーマンのように見えますが、豆のように緑色だと思います。

00:08:55.000 -> 00:08:58.000
モデルは一般的にピーマンに問題があるのだろうか。 

00:08:58.000 -> 00:09:05.000
このクエリオプションをIncorrectからCort Correctに切り替えさせてください...

00:09:05.000 -> 00:09:09.000
...これらの失敗を正しく分類されたピーマンと対比する。

00:09:09.000 -> 00:09:17.000
32枚の画像を正しく分類しました。しかし、これらのほとんどがピーマンであることに気づきました。

00:09:17.000 -> 00:09:24.000
トレーニングデータをチェックして、複数のピーマンをうまく表現していることを確認する必要があります。

00:09:24.000 -> 00:09:34.000
この迅速な調査は、トレーニングとテストデータの量、質、多様性が機械学習にとってどれほど重要であるかを思い出させてくれました。

00:09:34.000 -> 00:09:40.000
ほんの数分で、このアプリはラベル付けと表現に関するいくつかの問題を視覚的に特定するのに役立ちました。

00:09:40.000 -> 00:09:46.000
トレーニングデータを微調整して、見た問題が解決するかどうかを確認する必要があります。

00:09:46.000 -> 00:09:54.000
また、私が以前に考慮していなかったことを明らかにしました:ユーザーが1枚の写真で複数の野菜をキャプチャするとどうなりますか?

00:09:54.000 -> 00:09:58.000
アプリのデザインについてもう少し考える必要があります。

00:09:58.000 -> 00:10:04.000
評価するラベル付きデータのコレクションがあったため、この調査はすべて可能でした。

00:10:04.000 -> 00:10:15.000
しかし、すぐにテストしたい、またはより多くのカメラアングルや照明条件を探求すべきかどうかを検討したいラベルのない例がある場合はどうなりますか?

00:10:15.000 -> 00:10:18.000
プレビュータブが役立つのはここです。

00:10:18.000 -> 00:10:36.000
同僚がここに送ってくれたいくつかの例をドラッグして、それがどれほどうまくいくかを見ることができます。

00:10:36.000 -> 00:10:43.000
または、iPhoneをContinuityカメラとして使用して、これをライブでテストすることもできます。

00:10:43.000 -> 00:10:49.000
私がこれらの実際の野菜を指摘すると、モデルはそれらをライブで正しく分類することができます。

00:10:49.000 -> 00:10:54.000
これはコショウとトマトです。

00:10:54.000 -> 00:11:01.000
要約すると、ラベル付けされたデータセットで訓練されたモデルの動作をより深く掘り下げることができます。

00:11:01.000 -> 00:11:06.000
評価ペインには、拡張オプション付きの詳細なメトリックサマリーが提供されます。

00:11:06.000 -> 00:11:24.000
新しいExploreタブは、現在画像分類器、ハンドポーズ分類器、およびオブジェクト検出テンプレートで利用可能な新しいインタラクティブUIで、関連するデータとともにテスト評価結果をフィルタリングして視覚化できるオプションを提供します。

00:11:24.000 -> 00:11:26.000
ライブプレビューは、即時のフィードバックを可能にします。

00:11:26.000 -> 00:11:34.000
画像分類器、ハンドアクション分類器、ボディアクション分類器テンプレートに拡張されています。

00:11:34.000 -> 00:11:45.000
また、この機能を拡張して、接続されたウェブカメラから選択できるようにし、macOS VenturaのContinuityカメラもサポートしています。

00:11:45.000 -> 00:11:48.000
これは、Create MLアプリの新機能の簡単な要約です。

00:11:48.000 -> 00:11:54.000
Create MLフレームワークの新機能について話し合うためにシフトしましょう。

00:11:54.000 -> 00:11:59.000
Create MLフレームワークは、macOS、iOS、iPadOSで利用できます。

00:11:59.000 -> 00:12:04.000
今年は、tvOS 16へのサポートの一部を拡大します。

00:12:04.000 -> 00:12:24.000
プログラマティックインターフェイスは、開発時にモデル作成を自動化できるだけでなく、ユーザーの入力やデバイス上の動作から直接学習する動的な機能を構築する多くの機会を開き、ユーザーのプライバシーを維持しながらパーソナライズされた適応性のある体験を提供します。

00:12:24.000 -> 00:12:27.000
タスクのサポートはプラットフォームによって異なることに注意してください。

00:12:27.000 -> 00:12:41.000
たとえば、表形式の分類器と回帰器はどこでも利用できますが、ビデオを含むものなど、より大きなデータと計算要件を持つタスクの中にはmacOSが必要です。

00:12:41.000 -> 00:12:48.000
あなたが持つかもしれない一般的な質問の1つは、「私のアイデアをこれらのCreate MLの事前定義されたタスクの1つにマッピングできない場合はどうなりますか?」です。

00:12:48.000 -> 00:12:56.000
この質問に答えるために、Create MLファミリーに新しいメンバーを導入します。Create ML Componentsです。

00:12:56.000 -> 00:13:02.000
Create ML Componentsは、Create MLの基礎となる構成要素を公開します。

00:13:02.000 -> 00:13:09.000
それらを組み合わせて、ユースケースに合わせてカスタマイズされたパイプラインとモデルを作成できます。

00:13:09.000 -> 00:13:12.000
詳細については、これらのセッションをチェックすることを強くお勧めします。

00:13:12.000 -> 00:13:19.000
「Create ML Componentsを知る」では、ビルディングブロックとそれらをどのように構成できるかについて学びます。

00:13:19.000 -> 00:13:28.000
「Create ML Componentsを使用して高度なモデルを作成する」では、非同期時間的コンポーネントの使用とトレーニングのカスタマイズについて詳しく説明します。

00:13:28.000 -> 00:13:35.000
無限の能力があります。私が個人的に興奮しているものを紹介しましょう：アクションの繰り返しカウント。

00:13:35.000 -> 00:13:40.000
私が働いていないとき、おそらくあなたは私が踊っているのを見つけるでしょう。

00:13:40.000 -> 00:13:44.000
私は専門的に訓練されたインドのクラシックダンスのカタックアーティストです。

00:13:44.000 -> 00:13:49.000
私のフォームを改善するために、私はしばしば自分のルーチンを繰り返し練習することに頼っています。

00:13:49.000 -> 00:13:56.000
振付師/教師として、パフォーマーに特定のカウントのステップを練習し、私に提出してもらいたいと思います。

00:13:56.000 -> 00:14:01.000
Create MLの新しい繰り返しカウント機能は、実際にそれを行うのに役立ちます!

00:14:01.000 -> 00:14:09.000
ここでは、これはチャッカー - 回転 - カタックダンスの不可欠な部分です。

00:14:09.000 -> 00:14:14.000
私は自分のフォームとスタミナを構築するために、毎日特定のカウントのためにこれを練習したいと思います。

00:14:14.000 -> 00:14:18.000
私は自分の動きを数えるCreate MLを使用して構築されたiOSアプリを持っています。

00:14:18.000 -> 00:14:27.000
実際にやってみましょう。

00:14:27.000 -> 00:14:31.000
私がチャッカーを取ると、カウントはそれに対応するように増加します。

00:14:31.000 -> 00:14:36.000
ここで、私は5つのチャッカーをしました、そしてカウントはまさにそれを反映しています。

00:14:36.000 -> 00:14:41.000
次に、右側と左側の動きで構成される別の小さなルーチンを試してみましょう。

00:14:41.000 -> 00:14:57.000
カウンターはそれらを1つとしてカウントします。

00:14:57.000 -> 00:14:59.000
ここでは、カウントは3を示しています。

00:14:59.000 -> 00:15:17.000
別の簡単な片側腕の動きを試してみましょう。

00:15:17.000 -> 00:15:18.000
それは4です。

00:15:18.000 -> 00:15:26.000
アクション分類と組み合わせると、繰り返しアクションを同時にカウントして分類できます。

00:15:26.000 -> 00:15:30.000
繰り返しカウントはランタイムAPIとして利用できます。

00:15:30.000 -> 00:15:37.000
トレーニングデータを必要とせず、この機能をアプリに追加するのはほんの数行のコードです。

00:15:37.000 -> 00:15:42.000
その実装は、クラスに依存しないように設計された事前訓練されたモデルに基づいています。

00:15:42.000 -> 00:15:56.000
つまり、ジャンピングジャック、スクワット、トワール、チャッカーなどのフィットネスやダンスアクションに機能しますが、さまざまな全身反復アクションにも適用できます。

00:15:56.000 -> 00:16:04.000
サンプルコードとこのセッションにリンクされている記事をチェックすることで、このモデルと潜在的なユースケースについて詳しく知ることができます。

00:16:04.000 -> 00:16:08.000
つまり、Create MLの新機能の簡単な概要です。

00:16:08.000 -> 00:16:16.000
Create MLアプリのインタラクティブな評価とライブプレビューでは、トレーニングするモデルの理解を深めることができます。

00:16:16.000 -> 00:16:32.000
Create MLフレームワークは、tvOSサポート、繰り返しカウントを追加し、アプリケーションのニーズに合わせて高度にカスタマイズされたモデルを構築するのに役立つ、基礎となるコンポーネントの豊富なセットにアクセスできるように拡張されています。

00:16:32.000 -> 00:16:38.000
ありがとう、そして私はあなたがこれらすべてのエキサイティングな新機能を楽しんだことを願っています、そして私たちはあなたがそれらで何をするかを見るのが待ちきれません!

00:16:38.000 -> 23:59:59.000
♪

