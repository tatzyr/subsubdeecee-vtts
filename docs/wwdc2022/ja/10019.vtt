WEBVTT

00:00:00.000 --> 00:00:03.000
♪インストゥルメンタルヒップホップ音楽♪

00:00:03.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:11.000
こんにちは、私はアレハンドロです。

00:00:11.000 --> 00:00:13.000
私はCreateMLチームのエンジニアです。

00:00:13.000 --> 00:00:19.000
今日は、コンポーネントを使用して機械学習モデルを構築するためのまったく新しいAPIについて話します。

00:00:19.000 --> 00:00:23.000
Create MLは、機械学習モデルをトレーニングするためのシンプルなAPIを提供します。

00:00:23.000 --> 00:00:31.000
これは、画像分類、音声分類など、サポートされている一連のタスクに基づいています。

00:00:31.000 --> 00:00:36.000
WWDC 2021では、Create MLフレームワークに関する2つの素晴らしい講演を行いました。

00:00:36.000 --> 00:00:39.000
まだチェックしていない場合は、必ずチェックしてください。

00:00:39.000 --> 00:00:42.000
しかし、私は事前に定義されたタスクを超えることについて話したいと思います。

00:00:42.000 --> 00:00:48.000
Create MLが提供するものを超えて、特定の問題に合わせてタスクをカスタマイズしたい場合はどうなりますか?

00:00:48.000 --> 00:00:51.000
または、別のタイプのタスクを構築したい場合はどうなりますか?

00:00:51.000 --> 00:00:56.000
コンポーネントを使用して、新しい創造的な方法でタスクを作成できるようになりました。

00:00:56.000 --> 00:00:58.000
掘り下げましょう。

00:00:58.000 --> 00:01:03.000
MLタスクを分割し、各コンポーネントが何をするかを説明することから始めます。

00:01:03.000 --> 00:01:07.000
次に、コンポーネントをつなぎ合わせる方法について話します。

00:01:07.000 --> 00:01:10.000
カスタム画像タスクの例が続きます。

00:01:10.000 --> 00:01:13.000
次に、表形式のタスクについて話します。

00:01:13.000 --> 00:01:16.000
そして、私は展開戦略で終わります。

00:01:16.000 --> 00:01:23.000
機械学習タスクの内部を探求することから始めて、何が入り、どのように機能するかを理解しましょう。

00:01:23.000 --> 00:01:27.000
このようにして、カスタムタスクを構築し始めるとき、あなたは私が何を言っているのか知っています。

00:01:27.000 --> 00:01:31.000
例として画像分類器を使います。

00:01:31.000 --> 00:01:36.000
画像分類器は、ラベル付き画像のリストを使用してモデルをトレーニングします。

00:01:36.000 --> 00:01:41.000
この例では、それぞれのラベルが付いた猫と犬の画像があります。

00:01:41.000 --> 00:01:45.000
しかし、各ステップで画像がどのように変換されるかを探りましょう。

00:01:45.000 --> 00:01:50.000
これを行うには、画像分類タスクを展開して、中身を確認します。

00:01:50.000 --> 00:01:53.000
概念的には、画像分類器は非常に簡単です。

00:01:53.000 --> 00:01:56.000
これは、特徴抽出器と分類器で構成されています。

00:01:56.000 --> 00:02:02.000
しかし、重要な部分は、Create MLコンポーネントがこれらのコンポーネントに独立してアクセスできるということです。

00:02:02.000 --> 00:02:07.000
コンポーネントを追加、削除、または切り替えて、新しいタスクを作成できます。

00:02:07.000 --> 00:02:10.000
コンポーネントをボックスとして表現します。

00:02:10.000 --> 00:02:12.000
矢印はデータの流れを表しています。

00:02:12.000 --> 00:02:18.000
画像分類器の最初のステップである特徴抽出にズームインしましょう。

00:02:18.000 --> 00:02:25.000
一般的に、特徴抽出器は、興味深い部分、つまり特徴のみを保持することで、入力の次元を減らします。

00:02:25.000 --> 00:02:31.000
画像の場合、特徴抽出器は画像内のパターンを探します。

00:02:31.000 --> 00:02:39.000
Create MLは、Vision Frameworkが提供する優れた画像機能抽出器であるVision Feature Printを使用しています。

00:02:39.000 --> 00:02:42.000
さて、2番目の作品、分類器について話しましょう。

00:02:42.000 --> 00:02:47.000
分類器は、一連の例を使用して分類を学習します。

00:02:47.000 --> 00:02:54.000
いくつかの一般的な実装は、ロジスティック回帰、ブーストツリー、およびニューラルネットワークです。

00:02:54.000 --> 00:03:02.000
したがって、画像分類器のトレーニングは、注釈付き画像から始まり、注釈付き機能に行き、分類器で終わります。

00:03:02.000 --> 00:03:05.000
しかし、なぜ私たちはそれを粉々にしたいのですか?

00:03:05.000 --> 00:03:08.000
その理由は、可能性を広げたいからです。

00:03:08.000 --> 00:03:12.000
コントラストを増やして前処理をしたいのかもしれません。

00:03:12.000 --> 00:03:19.000
または、機能を抽出する前に、すべての画像を均一な明るさになるように正規化したいかもしれません。

00:03:19.000 --> 00:03:22.000
あるいは、別のフィーチャー抽出器を試してみたいかもしれません。

00:03:22.000 --> 00:03:25.000
あるいは、別の分類器を試してみたいかもしれません。

00:03:25.000 --> 00:03:27.000
可能性は無限大です。

00:03:27.000 --> 00:03:30.000
これらはオプションのほんの一部です。

00:03:30.000 --> 00:03:37.000
そのため、macOS、iOS、iPadOS、tvOSでMLコンポーネントのサポートを追加しました。

00:03:37.000 --> 00:03:46.000
私たちの希望は、私たちが独自のコンポーネントと一緒に提供するコンポーネントの一部、またはコミュニティの他の人によって構築されたコンポーネントを使用して、新しいモデルを作成できることです。

00:03:46.000 --> 00:03:49.000
そして、あなたは私たちのすべてのプラットフォームでそれを活用することができます。

00:03:49.000 --> 00:03:54.000
以下は、Create ML Componentsに組み込まれているコンポーネントの一部です。

00:03:54.000 --> 00:03:58.000
しかし、一歩下がって、いくつかの概念を紹介しましょう。

00:03:58.000 --> 00:04:02.000
コンポーネントには、変圧器と見積もりの2種類があります。

00:04:02.000 --> 00:04:07.000
トランスフォーマーは、単に何らかの変換を実行できるタイプです。

00:04:07.000 --> 00:04:10.000
入力タイプと出力タイプを定義します。

00:04:10.000 --> 00:04:17.000
たとえば、画像機能抽出器は、入力画像を取り、形状形状の特徴の配列を生成します。

00:04:17.000 --> 00:04:21.000
一方、見積もりはデータから学ぶ必要があります。

00:04:21.000 --> 00:04:27.000
入力例を取り、いくつかの処理を行い、変圧器を生成します。

00:04:27.000 --> 00:04:30.000
私たちはこのプロセスを「フィッティング」と呼んでいます。

00:04:30.000 --> 00:04:41.000
すごい。これらの概念を邪魔にならないように、Create ML Componentsを使用すると、コンポジションを使用して個々のコンポーネントから画像分類器を構築する方法について説明しましょう。

00:04:41.000 --> 00:04:44.000
これは、コンポーネントを使用した画像分類器です。

00:04:44.000 --> 00:04:50.000
特徴抽出器としてImageFeaturePrint、分類器としてLogisticRegressionClassifierがあります。

00:04:50.000 --> 00:04:58.000
コンポーネントがトランスフォーマーか見積もりかにかかわらず、追加方法を使用してそれらを組み合わせます。

00:04:58.000 --> 00:05:02.000
そして、これはコンポーネントが無限の可能性を提供する場所です。

00:05:02.000 --> 00:05:09.000
簡単な変更でロジスティック回帰ではなく、完全に接続されたニューラルネットワークを分類器として使用できます。

00:05:09.000 --> 00:05:13.000
または、CoreMLモデルでカスタム機能抽出器を使用することもできます。

00:05:13.000 --> 00:05:19.000
たとえば、ヘッドレスResNet-50モデルは、モデルギャラリーで見つけることができます。

00:05:19.000 --> 00:05:25.000
2つのコンポーネントを構成する場合、最初のコンポーネントの出力は2番目のコンポーネントの入力と一致する必要があります。

00:05:25.000 --> 00:05:32.000
画像分類器の場合、フィーチャーエクストラクタの出力は、CoreMLフレームワークからの形状の配列です。

00:05:32.000 --> 00:05:36.000
これは、ロジスティック回帰分類器の入力でもあります。

00:05:36.000 --> 00:05:41.000
追加メソッドを使用するときにコンパイラエラーが発生した場合、これは最初に確認するものです。

00:05:41.000 --> 00:05:44.000
タイプが一致していることを確認してください。

00:05:44.000 --> 00:05:48.000
しかし、フィッティングに関する重要な点を明確にさせてください。

00:05:48.000 --> 00:05:53.000
私は前に、フィッティングは見積もりから変圧器に行くプロセスだと言いました。

00:05:53.000 --> 00:05:57.000
これを構成された推定者の観点から見てみましょう。

00:05:57.000 --> 00:06:05.000
画像分類器の場合のように、構成された推定器がトランスと推定器の両方を持っている場合、推定器のピースのみが取り付けられます。

00:06:05.000 --> 00:06:14.000
しかし、変圧器は、推定器の適合方法に正しい特徴を供給するために使用されるため、プロセスの重要な部分です。

00:06:14.000 --> 00:06:15.000
これがコードです。

00:06:15.000 --> 00:06:24.000
画像分類器には、特徴が画像であり、注釈が文字列である注釈付き機能のコレクションが必要です。

00:06:24.000 --> 00:06:28.000
デモに入るときに、機能の読み込みについて話します。

00:06:28.000 --> 00:06:32.000
データを取得したら、フィットメソッドを呼び出すことができます。

00:06:32.000 --> 00:06:37.000
これは、訓練されたモデルである変圧器を返します。

00:06:37.000 --> 00:06:44.000
また、フィッティング時に使用されるタイプは関連しているが、結果の変圧器のタイプとは異なることに注意することが重要です。

00:06:44.000 --> 00:06:49.000
特に、適合メソッドで使用されるタイプは常にコレクションです。

00:06:49.000 --> 00:06:55.000
また、監督された見積もりの場合、機能には注釈を含める必要があります。

00:06:55.000 --> 00:07:03.000
Create ML Componentsは、AnnotatedFeatureタイプを使用して、その注釈とともに機能を表します。

00:07:03.000 --> 00:07:06.000
モデルを手に入れたら、予測をすることができます。

00:07:06.000 --> 00:07:11.000
装着したばかりのモデルなのか、それともディスクからパラメータをロードしているのかは関係ありません。

00:07:11.000 --> 00:07:15.000
APIはどちらの場合でも同じです。

00:07:15.000 --> 00:07:20.000
私は分類器を訓練しているので、結果は分類分布です。

00:07:20.000 --> 00:07:25.000
分布には、各ラベルの確率が含まれています。

00:07:25.000 --> 00:07:30.000
この場合、画像の最も可能性の高いラベルを印刷しているだけです。

00:07:30.000 --> 00:07:37.000
適合メソッドは、検証メトリックを含むトレーニングイベントを観察するメカニズムも提供します。

00:07:37.000 --> 00:07:43.000
この例では、検証データを渡し、検証精度を印刷しています。

00:07:43.000 --> 00:07:48.000
監視対象の見積もりのみが検証メトリックを提供することに注意してください。

00:07:48.000 --> 00:07:56.000
モデルをトレーニングしたら、学習したパラメータを保存して、後で再利用するか、アプリにデプロイすることができます。

00:07:56.000 --> 00:07:58.000
書き込みメソッドを使用してこれを行います。

00:07:58.000 --> 00:08:02.000
後で、readメソッドを使用して読むことができます。

00:08:02.000 --> 00:08:04.000
そして、それは構図です。

00:08:04.000 --> 00:08:06.000
ここが面白くなるところです。

00:08:06.000 --> 00:08:13.000
Create MLが今までサポートしていなかった新しいタスクを書くことについて話しましょう。

00:08:13.000 --> 00:08:17.000
画像を採点するためにモデルを訓練したい場合はどうなりますか?

00:08:17.000 --> 00:08:23.000
あなたが果物の写真を持っているとしましょうが、果物を分類する代わりに、あなたはそれを評価したいと思いました。

00:08:23.000 --> 00:08:26.000
熟度に基づいてスコアをつけてください。

00:08:26.000 --> 00:08:30.000
これを行うには、分類の代わりに回帰を行う必要があります。

00:08:30.000 --> 00:08:37.000
だから、熟度に基づいてバナナの画像にスコアを与える画像回帰を書いてみましょう。

00:08:37.000 --> 00:08:43.000
各画像に1から10の間の熟度値を与えます。

00:08:43.000 --> 00:08:47.000
画像回帰器は画像分類器と非常によく似ています。

00:08:47.000 --> 00:08:54.000
唯一の違いは、推定値が分類器ではなく回帰者になることです。

00:08:54.000 --> 00:08:58.000
すでに推測しているかもしれませんが、これは簡単でしょう。

00:08:58.000 --> 00:09:01.000
あなたの記憶をリフレッシュするために、ここに私たちの画像分類器があります。

00:09:01.000 --> 00:09:04.000
そして、これは画像回帰です。

00:09:04.000 --> 00:09:09.000
ロジスティック回帰分類器を線形回帰器に置き換えました。

00:09:09.000 --> 00:09:15.000
この単純な変更により、予想される入力が適合メソッドにも変更されます。

00:09:15.000 --> 00:09:17.000
以前は、画像とラベルを期待していました。

00:09:17.000 --> 00:09:20.000
今、それは画像とスコアを期待しています。

00:09:20.000 --> 00:09:22.000
しかし、概念については十分です。

00:09:22.000 --> 00:09:28.000
実際のコードでこれをデモさせてください。

00:09:28.000 --> 00:09:31.000
カスタム画像回帰の書き方をお見せしましょう。

00:09:31.000 --> 00:09:38.000
コードをカプセル化するためにImageRegressor構造体を定義することから始めます。

00:09:38.000 --> 00:09:42.000
私はさまざまなレベルの熟度にあるバナナの画像が入ったフォルダを持っています。

00:09:42.000 --> 00:09:48.000
そのURLを定義することから始めます。

00:09:48.000 --> 00:09:51.000
次のステップは、列車の方法を追加することです。

00:09:51.000 --> 00:09:56.000
これは、トレーニングデータを使用してモデルを作成する場所です。

00:09:56.000 --> 00:10:05.000
構成された見積もりでステップを追加または変更しても戻り値が変更されないように、戻り値の型に「some」キーワードを使用します。

00:10:05.000 --> 00:10:07.000
さて、見積もりを定義します。 見積もりを定義します

00:10:07.000 --> 00:10:14.000
これは単に線形回帰器が追加された特徴抽出器です。

00:10:14.000 --> 00:10:17.000
そして今、私は彼らのスコアでトレーニング画像をロードする必要があります。

00:10:17.000 --> 00:10:24.000
URLと文字列ラベルを含むAnnotatedFeaturesのコレクションであるAnnotatedFilesを使用できます。

00:10:24.000 --> 00:10:29.000
それは私のニーズに合った便利な初期化子を提供します。

00:10:29.000 --> 00:10:34.000
私のファイルは、名前の後にダッシュ、そして熟度値が続きます。

00:10:34.000 --> 00:10:41.000
したがって、セパレータはダッシュで、注釈はファイル名コンポーネントのインデックス1にあることを指定します。

00:10:41.000 --> 00:10:46.000
また、type引数を使用して画像ファイルのみをリクエストします。

00:10:46.000 --> 00:10:49.000
URLがわかったので、画像をロードする必要があります。

00:10:49.000 --> 00:10:56.000
これを行うには、mapFeaturesメソッドとImageReaderを使用できます。

00:10:56.000 --> 00:11:01.000
また、スコアを文字列から浮動小数点値に変換する必要があります。

00:11:01.000 --> 00:11:08.000
mapAnnotationsメソッドを使用してこれを行うことができます。

00:11:08.000 --> 00:11:12.000
そして、それで、私はトレーニングデータを持っています。

00:11:12.000 --> 00:11:15.000
しかし、私は検証のためにその一部を脇に置きたいです。

00:11:15.000 --> 00:11:17.000
これを行うには、randomSplitメソッドを使用できます。

00:11:17.000 --> 00:11:25.000
トレーニングのために80%を維持し、残りは検証に使用します。

00:11:25.000 --> 00:11:29.000
今、私はフィットする準備ができています。

00:11:29.000 --> 00:11:33.000
そして、自分のアプリにデプロイできるように、トレーニングされたパラメータを保存します。

00:11:33.000 --> 00:11:40.000
保存する場所を選択します。

00:11:40.000 --> 00:11:44.000
そして、私は書き込みメソッドを呼び出します。

00:11:44.000 --> 00:11:50.000
最後に、変圧器を返します。

00:11:50.000 --> 00:11:55.000
これは、コンポーネントを使用してモデルを定義し、トレーニングすることの本質です。

00:11:55.000 --> 00:12:03.000
構成された見積もりを定義し、トレーニングデータをロードし、フィットメソッドを呼び出し、書き込みを使用してパラメータを保存しました。

00:12:03.000 --> 00:12:05.000
しかし、私が改善できることがいくつかあります。

00:12:05.000 --> 00:12:12.000
まず第一に、私は検証データセットを渡していますが、検証エラーを観察していないので、そうします。

00:12:12.000 --> 00:12:21.000
適合されたメソッドは、メトリクスを収集するために使用できるイベントハンドラを取ります。

00:12:21.000 --> 00:12:26.000
とりあえず、トレーニングと検証の最大エラー値の両方を印刷します。

00:12:26.000 --> 00:12:33.000
また、最終モデルの平均絶対誤差も欲しいです。

00:12:33.000 --> 00:12:44.000
取り付けられたトランスフォーマーを検証機能に適用し、それを実際のスコアと一緒にmeanAbsoluteError関数に渡すことで計算します。

00:12:44.000 --> 00:12:49.000
私はこれを実行しましたが、私は素晴らしいモデルを手に入れませんでした - エラーは高かったです。

00:12:49.000 --> 00:12:52.000
これは、バナナの画像がそれほど多くありません。

00:12:52.000 --> 00:12:57.000
より多くの画像を取得する必要がありますが、その前に、データセットを拡張してみることができます。

00:12:57.000 --> 00:13:00.000
画像を回転させて拡大縮小して、より多くの例を得ることができます。

00:13:00.000 --> 00:13:05.000
これを行うには、注釈付きの画像を取り、それを拡張する新しい方法を書くつもりです。

00:13:05.000 --> 00:13:13.000
注釈付きの画像の配列を返します。

00:13:13.000 --> 00:13:20.000
私が行う最初の増強はローテーションです。

00:13:20.000 --> 00:13:26.000
-Piとpiの間の角度をランダムに選択し、それを使って画像を回転させます。

00:13:26.000 --> 00:13:31.000
ランダムスケールもやります。

00:13:31.000 --> 00:13:39.000
そして、オリジナル、回転した画像、スケーリングされた画像の3つの画像を返します。

00:13:39.000 --> 00:13:49.000
拡張機能があるので、flatMapを使用してトレーニング画像を拡張します。

00:13:49.000 --> 00:13:53.000
私のデータセットの各要素は配列に変換されます。

00:13:53.000 --> 00:13:59.000
FlatMapは、その配列の配列を単一の配列に平坦化します。これは、適合メソッドに必要なものです。

00:13:59.000 --> 00:14:04.000
拡張は、予測を行うときではなく、フィッティング時にのみ適用されることに注意してください。

00:14:04.000 --> 00:14:07.000
さて、これは私の精度を高めました。

00:14:07.000 --> 00:14:12.000
しかし、私のモデルをさらに良くするもう1つの改善について話しましょう。

00:14:12.000 --> 00:14:16.000
ビジョンフレームワークを使用して、画像を顕著なオブジェクトにトリミングしたいです。

00:14:16.000 --> 00:14:19.000
これは私のトレーニングデータの画像の1つです。

00:14:19.000 --> 00:14:23.000
誰かが背景に他の果物と一緒にバナナを持っている。

00:14:23.000 --> 00:14:27.000
モデルは写真の他のオブジェクトによって混乱する可能性があります。

00:14:27.000 --> 00:14:33.000
ビジョンフレームワークAPIを使用すると、画像を最も顕著なオブジェクトに自動的にトリミングできます。

00:14:33.000 --> 00:14:38.000
これを行うには、WWDC 2019のビジョントークをチェックしてください。

00:14:38.000 --> 00:14:46.000
カスタムトランスフォーマーを書くと、フィッティング時と予測を取得するときの両方で、この変換をすべての画像に簡単に適用できます。

00:14:46.000 --> 00:14:47.000
やり方をお見せしましょう。

00:14:47.000 --> 00:14:53.000
トランスフォーマープロトコルに準拠するために必要なのは、適用された方法を実装することだけです。

00:14:53.000 --> 00:14:57.000
そしてこの場合、画像を撮って画像を返してほしい。

00:14:57.000 --> 00:15:06.000
顕著なオブジェクトを取得しない場合は、元の画像を返すと言うことを除いて、このコードに入るつもりはありません。

00:15:06.000 --> 00:15:16.000
カスタムトランスを持っているので、イメージリグレッサーに追加します。

00:15:16.000 --> 00:15:28.000
特徴を抽出する前に、カスタムトランスを使用する必要があります。

00:15:28.000 --> 00:15:37.000
顕著性が私のタスク定義の一部になった今、それはすべてのトレーニング画像をトリミングするために使用され、推論を行うときにも使用されます。

00:15:37.000 --> 00:15:42.000
これは、トレーニングと推論の間でタスク定義を共有する利点の1つです。

00:15:42.000 --> 00:15:46.000
次のタスクに進む前に、いくつかの重要なポイントを強調させてください。

00:15:46.000 --> 00:15:50.000
コンポーネントを使用して、カスタムタスクを作成できるようになりました。

00:15:50.000 --> 00:15:53.000
私は追加方法を使ってこれをしました。

00:15:53.000 --> 00:16:01.000
AnnotatedFilesを使用して、注釈付きのファイル名でファイルをロードしましたが、ディレクトリによって注釈されたファイルを読み込むこともできます。

00:16:01.000 --> 00:16:08.000
ImageReaderを使用してURLを画像にマッピングし、注釈を文字列から値にマッピングしました。

00:16:08.000 --> 00:16:15.000
randomSplitを使用して検証データセットを脇に置き、後で使用するために訓練されたパラメータを保存しました。

00:16:15.000 --> 00:16:20.000
その後、拡張を追加し、モデルを改善するためにカスタムトランスを定義しました。

00:16:20.000 --> 00:16:23.000
しかし、これは単なる画像以上のもののために働きます。

00:16:23.000 --> 00:16:28.000
ギアを切り替えて、別のタイプのタスクについて話します。表形式のタスクです。

00:16:28.000 --> 00:16:30.000
これらは表形式のデータを使用するタスクです。

00:16:30.000 --> 00:16:35.000
表形式データは、異なるタイプの複数の機能を持つことによって特徴付けられる。

00:16:35.000 --> 00:16:39.000
数値データとカテゴリデータの両方を含めることができます。

00:16:39.000 --> 00:16:42.000
人気のある例は、住宅価格データです。

00:16:42.000 --> 00:16:48.000
地域や年齢などもありますが、近所や建物の種類などもあります。

00:16:48.000 --> 00:16:53.000
そして、あなたは値を予測することを学びたいです。例えば、販売価格。

00:16:53.000 --> 00:16:58.000
2021年、私たちはTaboularDataフレームワークを導入しました。

00:16:58.000 --> 00:17:06.000
これで、Create ML Componentsと一緒にTabularDataフレームワークを使用して、表形式の分類器と回帰器を構築およびトレーニングできます。

00:17:06.000 --> 00:17:09.000
TabularDataに関する技術講演もお勧めします。

00:17:09.000 --> 00:17:15.000
これは、表形式のタスクを構築する際に必要となるデータ探索の素晴らしい紹介です。

00:17:15.000 --> 00:17:17.000
飛び込みましょう。

00:17:17.000 --> 00:17:23.000
表形式のデータを扱う場合、テーブルの各列には異なるタイプの機能があります。

00:17:23.000 --> 00:17:32.000
また、含まれている情報の種類、分布、値の範囲、その他の要因に基づいて、各列を異なる方法で処理することもできます。

00:17:32.000 --> 00:17:36.000
MLコンポーネントを作成すると、ColumnSelectorを使用してこれを行うことができます。

00:17:36.000 --> 00:17:38.000
ここに例があります。

00:17:38.000 --> 00:17:42.000
私は住宅価格について言及しましたが、それらはばかげています。

00:17:42.000 --> 00:17:44.000
代わりにアボカドの価格を使うつもりです。

00:17:44.000 --> 00:17:47.000
私はこのアボカドの価格表を持っています。

00:17:47.000 --> 00:17:52.000
これに基づいてアボカドの価格を予測するための表形式の回帰を構築したい。

00:17:52.000 --> 00:18:01.000
バッグ、年、ボリュームなどの数値データを含む列と、タイプや地域などのカテゴリデータを含む列が含まれています。

00:18:01.000 --> 00:18:06.000
一部の回帰者は、これらの値をよりよく表現することで利益を得ます。

00:18:06.000 --> 00:18:11.000
たとえば、これはデータセット内のボリューム値の分布です。

00:18:11.000 --> 00:18:17.000
それは正規分布に近いですが、15,000を中心に大きな値を持っています。

00:18:17.000 --> 00:18:23.000
これは、正規化の恩恵を受けることができるデータセットの素晴らしい例だと思います。

00:18:23.000 --> 00:18:27.000
だから、私が最初にやりたいことは、これらの値を正規化することです。

00:18:27.000 --> 00:18:35.000
これを行うには、正規化したい列名をColumnSelectorに渡し、標準のスケーラーを使用できます。

00:18:35.000 --> 00:18:37.000
これがコードです。

00:18:37.000 --> 00:18:39.000
まず、列セレクタを作成します。

00:18:39.000 --> 00:18:42.000
次に、拡大縮小したい列名を渡します。

00:18:42.000 --> 00:18:47.000
すべての列に同じタイプの要素が含まれている必要があります。この場合、Doubleです。

00:18:47.000 --> 00:18:50.000
次に、オプションのラップを解除します。

00:18:50.000 --> 00:18:53.000
欠けている値がないことを知っているので、これを行うことができます。

00:18:53.000 --> 00:18:56.000
しかし、不足している値を置き換えるインペーターを使用することもできます。

00:18:56.000 --> 00:19:01.000
そして、アンラッパーにStandardScalerを追加します。

00:19:01.000 --> 00:19:08.000
そこで、バッグの番号が数万で、ボリュームが数十万だったこのテーブルから始めました。

00:19:08.000 --> 00:19:16.000
そして、これらの列をスケーリングした後、私は1に近い大きさを持つ値になり、モデルのパフォーマンスを向上させることができます。

00:19:16.000 --> 00:19:24.000
より具体的に、私の値は平均がゼロで、標準偏差が1になりました。

00:19:24.000 --> 00:19:34.000
これは同様の例ですが、この例では、文字列型の型と領域の列を選択し、ワンホットエンコーディングを実行しています。

00:19:34.000 --> 00:19:42.000
ワンホットエンコーディングとは、各カテゴリの存在を示す配列を使用してカテゴリデータをエンコードすることを指します。

00:19:42.000 --> 00:19:47.000
この例では、ブロンズ、シルバー、ゴールドの3つのカテゴリーがあります。

00:19:47.000 --> 00:19:54.000
それぞれが配列内の一意の位置を取得し、その位置の1で示されます。

00:19:54.000 --> 00:20:01.000
代替案は、各カテゴリに連続した番号を与える序数エンコーダを使用することです。

00:20:01.000 --> 00:20:07.000
カテゴリがいくつかしかない場合はワンホットエンコーダを使用し、それ以外の場合はオーディナルエンコーダを使用してください。

00:20:07.000 --> 00:20:17.000
さて、これらすべてをまとめて、表形式の回帰を構築しましょう。

00:20:17.000 --> 00:20:25.000
以前と同様に、構造体を作成し、データURLとパラメータURLの定義を開始します。

00:20:25.000 --> 00:20:32.000
また、予測したい列の列IDを定義したい：価格。

00:20:32.000 --> 00:20:41.000
列車法と予測法の両方から使用できるように、タスクを別々に定義します。

00:20:41.000 --> 00:20:46.000
前述したように、ボリュームを正規化します。

00:20:46.000 --> 00:20:53.000
次に、ブーストされたツリーリグレクターを使用して価格を予測します。

00:20:53.000 --> 00:21:01.000
これは、結果の予測の列でもある注釈列の名前を取り、3つの特徴列すべての名前を取ります。

00:21:01.000 --> 00:21:03.000
この3つのコラムから始めます。

00:21:03.000 --> 00:21:13.000
次に、追加メソッドを使用してピースを結合し、タスクを返します。

00:21:13.000 --> 00:21:20.000
タスクの定義がわかったので、以前と同じように列車の方法を追加します。

00:21:20.000 --> 00:21:26.000
そして、以前と同様に、リターンタイプがモデルの詳細に依存しないようにしたい。

00:21:26.000 --> 00:21:32.000
最初のステップは、CSVファイルをデータフレームにロードすることです。

00:21:32.000 --> 00:21:35.000
私はこれを行うためにTabularDataフレームワークを使用しています。

00:21:35.000 --> 00:21:43.000
そして、以前と同じように、検証のためにデータの一部を分割したいと思います。

00:21:43.000 --> 00:21:50.000
トレーニングと検証データセットをフィットメソッドに渡します。

00:21:50.000 --> 00:21:59.000
また、以前と同じように検証エラーを報告し、後で使用するために訓練されたパラメータを保存します。

00:21:59.000 --> 00:22:04.000
最後に、変圧器を返します。

00:22:04.000 --> 00:22:09.000
訓練された変圧器を手に入れたら、それを使ってデータフレームの価格予測を行うことができます。

00:22:09.000 --> 00:22:17.000
私はこれを行うための予測方法を書くつもりです。

00:22:17.000 --> 00:22:24.000
タスク定義とパラメータURLからモデルをロードすることから始めます。

00:22:24.000 --> 00:22:35.000
予測に使用するデータフレームに、タイプ、地域、ボリュームなどの機能として使用した列があることを確認する必要があります。

00:22:35.000 --> 00:22:38.000
予測値は価格列になります。

00:22:38.000 --> 00:22:44.000
上部で定義した列IDを使用します。

00:22:44.000 --> 00:22:46.000
そして、私の表形式の回帰はこれで終わりです。

00:22:46.000 --> 00:22:56.000
訓練されたパラメータを生成するために一度だけ呼び出す必要がある列車方法と、アボカドの価格、アボカドの種類、地域、量に基づく予測を返す予測方法があります。

00:22:56.000 --> 00:22:59.000
私のアプリでこれを使用するために必要なのはそれだけです。

00:22:59.000 --> 00:23:03.000
表形式のタスクに取り組む際に留意すべきことがいくつかあります。

00:23:03.000 --> 00:23:07.000
ColumnSelector操作を使用して、特定の列を処理できます。

00:23:07.000 --> 00:23:19.000
ツリー分類器と回帰器はすべて表形式であることは注目に値しますが、AnnotatedFeatureProviderを使用した表形式のタスクでは、線形回帰器などの非表形式の推定器を使用することもできます。

00:23:19.000 --> 00:23:22.000
ドキュメントを参照してください。

00:23:22.000 --> 00:23:29.000
予測を行うときは、必要な列でデータフレームを構築し、正しいタイプを使用するようにしてください。

00:23:29.000 --> 00:23:34.000
カスタムタスクを構築する方法がわかったので、展開について話しましょう。

00:23:34.000 --> 00:23:38.000
これまでのところ、私はトレーニングと推論に同じAPIを使用してきました。

00:23:38.000 --> 00:23:43.000
Create ML Componentsを使用する場合、あなたのモデルはあなたのコードであることを指摘したいと思います。

00:23:43.000 --> 00:23:48.000
ファイルからトレーニングされたパラメータをロードする場合でも、タスク定義が必要です。

00:23:48.000 --> 00:23:55.000
これは状況によっては便利ですが、展開にCore MLを使用したい場合があります。

00:23:55.000 --> 00:23:58.000
Core MLを使用する場合は、コードを残します。

00:23:58.000 --> 00:24:01.000
モデルはモデルファイルで完全に表されます。

00:24:01.000 --> 00:24:05.000
Core MLを使用する準備ができているなら、これは良いワークフローかもしれません。

00:24:05.000 --> 00:24:08.000
そして、それは最適化されたテンソル演算の利点を持っています。

00:24:08.000 --> 00:24:12.000
しかし、心に留めておくべき考慮事項がいくつかあります。

00:24:12.000 --> 00:24:15.000
すべての操作がCore MLでサポートされているわけではありません。

00:24:15.000 --> 00:24:19.000
具体的には、カスタムトランスと見積もりはサポートされていません。

00:24:19.000 --> 00:24:24.000
また、Core MLは、画像や形状配列などのいくつかのタイプしかサポートしていません。

00:24:24.000 --> 00:24:30.000
カスタムタイプを使用している場合は、Core MLモデルを使用するときにアプリでそれらを変換する必要があるかもしれません。

00:24:30.000 --> 00:24:33.000
これは、変圧器をCore MLモデルとしてエクスポートする方法です。

00:24:33.000 --> 00:24:39.000
トランスフォーマーにサポートされていない操作が含まれている場合、エラーがスローされます。

00:24:39.000 --> 00:24:46.000
トレーニングされたパラメータと一緒にタスク定義をデプロイしたい場合は、それらをSwiftパッケージにバンドルすることを検討する必要があります。

00:24:46.000 --> 00:24:51.000
このようにして、パラメータをロードして予測を実行する簡単な方法を提供できます。

00:24:51.000 --> 00:24:58.000
Swiftパッケージリソースの詳細については、WWDC 2020のSwiftパッケージトークをご覧ください。

00:24:58.000 --> 00:24:59.000
私が持っているのはそれだけです。

00:24:59.000 --> 00:25:04.000
覚えておくべき主なことは、コンポジションでカスタムタスクを作成できるようになったことです。

00:25:04.000 --> 00:25:06.000
可能性は無限大です。

00:25:06.000 --> 00:25:08.000
あなたが何を作るかを見るのを楽しみにしています。

00:25:08.000 --> 00:25:20.000
オーディオやビデオのタスクを含むより高度なテクニックについては、同僚のDavidがより高度なカスタムタスクを提示する「Create ML Componentsで高度なモデルを作成する」をチェックしてください。

00:25:20.000 --> 00:25:24.000
ありがとう、WWDC 2022の残りを楽しんでください!

00:25:24.000 --> 23:59:59.000
♪

