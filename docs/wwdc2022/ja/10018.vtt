WEBVTT

00:00:00.000 -> 00:00:03.000
♪インストゥルメンタルヒップホップ音楽♪

00:00:03.000 -> 00:00:09.000
♪

00:00:09.000 -> 00:00:11.000
こんにちは、私の名前はカレン・シンです。

00:00:11.000 -> 00:00:14.000
私はカメラソフトウェアチームのエンジニアです。

00:00:14.000 -> 00:00:24.000
「macOSアプリにContinuityカメラのサポートをブリングする」へようこそ。このセッションを開始するには、Continuity Cameraとは何ですか？

00:00:24.000 -> 00:00:32.000
次に、アプリケーションがContinuity Cameraで自動カメラ選択体験を構築する方法について説明します。

00:00:32.000 -> 00:00:40.000
そして最後に、Continuity Camera用のmacOS 13の新しいAPIについて説明しておきます。

00:00:40.000 -> 00:00:45.000
連係カメラを使えば、iPhoneをウェブカメラとして使えるようになりました。

00:00:45.000 -> 00:00:49.000
セットアップはシームレスです。iPhoneをMacに近づけるだけです。

00:00:49.000 -> 00:00:54.000
また、ワイヤレスで機能するので、すぐに通話に参加できます。

00:00:54.000 -> 00:01:01.000
あなたのiPhoneは、いくつかの条件下で外付けカメラとマイクとしてMacに表示されます。

00:01:01.000 -> 00:01:07.000
まず、macOS 13とiOS 16を実行している必要があります。

00:01:07.000 -> 00:01:13.000
MacとiPhoneの両方は、2要素認証を使用して同じApple IDにサインインする必要があります。

00:01:13.000 -> 00:01:20.000
有線接続の場合、電話をUSB経由でMacに接続する必要があります。

00:01:20.000 -> 00:01:28.000
または、ワイヤレス接続の場合、2つのデバイスが近接しており、BluetoothとWi-Fiの両方がオンになっている必要があります。

00:01:28.000 -> 00:01:35.000
それを通して話すのではなく、魔法の連続性カメラがデバイスでどのように見えるかをすぐにお見せしましょう。

00:01:35.000 -> 00:01:38.000
ここにMacBook ProとiPhone 13 Proがあります。

00:01:38.000 -> 00:01:47.000
両方のデバイスが同じApple IDでサインインしています。

00:01:47.000 -> 00:01:50.000
電話は私のMacBookに取り付けられたスタンドの上に置かれています。

00:01:50.000 -> 00:02:04.000
今日は同僚のエリックとビデオ会議に参加し、ZoomでContinuity Cameraを使用する方法を紹介します。

00:02:04.000 -> 00:02:12.000
アプリは最初に内蔵カメラを使用して起動され、その後、新しいカメラで何ができるかを説明するオンボーディングダイアログが表示されます。

00:02:12.000 -> 00:02:27.000
ダイアログは、MacがmacOS 13にアップグレードされた後、カメラアプリケーションを初めて開くと、Continuity Cameraの対象となるiPhoneが1回表示されます。

00:02:27.000 -> 00:02:30.000
こんにちは、エリック！

00:02:30.000 -> 00:02:35.000
エリック：ああ、カレン！こんにちは！

00:02:35.000 -> 00:02:51.000
カレン：オンボーディングダイアログがシステムに表示されると、Continuity Cameraとマイクデバイスがすべてのアプリケーションで利用可能になります。

00:02:51.000 -> 00:03:01.000
このカメラを使うように切り替えて、それがどのように見えるか見てみましょう。

00:03:01.000 -> 00:03:09.000
連係カメラはiPhoneのリアカメラシステムを使用しているため、iPhoneに期待するのと同じ素晴らしいビデオ品質が得られます。

00:03:09.000 -> 00:03:16.000
そして、それは電話の4つの向きすべてで動作します。

00:03:16.000 -> 00:03:27.000
縦向きは、横向きに比べて視野が拡大されます。

00:03:27.000 -> 00:03:37.000
連続カメラでは、いくつかの新しいビデオエフェクトなど、ウェブカメラでこれまでに不可能だったことを行うこともできます。

00:03:37.000 -> 00:03:45.000
おそらく、iOS 14.5とmacOS 12.3で導入されたセンターステージとポートレートのビデオエフェクトにすでに精通しているでしょう。

00:03:45.000 -> 00:04:00.000
そうでない場合は、WWDC 2021の「カメラキャプチャの新機能」セッションを見て、システムのビデオエフェクトとアプリケーションでそれらと対話する方法について詳しく学ぶことを強くお勧めします。

00:04:00.000 -> 00:04:09.000
コントロールセンターに行って、連係カメラでシステムビデオエフェクトを有効にしましょう。

00:04:09.000 -> 00:04:17.000
センターステージは、シーン内を動き回るときにあなたをフレームに保ちます。

00:04:17.000 -> 00:04:22.000
ポートレートは背景をぼかし、自然にあなたに焦点を合わせます。

00:04:22.000 -> 00:04:35.000
ポートレートはAppleシリコンMacでのみサポートされていますが、Continuity Cameraを使用すると、すべてのIntelおよびAppleシリコンMacで利用可能になりました。

00:04:35.000 -> 00:04:40.000
Studio Lightは、macOS 13で利用可能な新しいシステムビデオエフェクトです。

00:04:40.000 -> 00:04:45.000
iPhone 12以降を使用する場合は、Continuity Cameraでサポートされています。

00:04:45.000 -> 00:04:48.000
画面上で最高に見せたいときは、これを有効にしてください。

00:04:48.000 -> 00:04:54.000
それは背景を暗くし、あなたの顔を照らす見事な照明効果を提供します。

00:04:54.000 -> 00:05:00.000
スタジオライトは、窓の前にいるときなど、厳しい照明状況に最適です。

00:05:00.000 -> 00:05:13.000
明確な比較のために各ビデオエフェクトを別々に見せていますが、それらはすべてうまく機能します。

00:05:13.000 -> 00:05:25.000
そして、効果の任意の組み合わせを同時に適用することができます。

00:05:25.000 -> 00:05:30.000
連続カメラのために本当にお見せしたいもう1つのエキサイティングな機能があります。

00:05:30.000 -> 00:05:36.000
一緒に仕事をして机の上にあるものを共有したいときは、デスクビューを使用できるようになりました。

00:05:36.000 -> 00:05:48.000
デスクビューアプリにはmacOS 13が付属しており、コントロールセンターですぐに起動できます。

00:05:48.000 -> 00:05:54.000
それは、すべての複雑な機器を必要とせずに、オーバーヘッドカメラのセットアップのように動作します。

00:05:54.000 -> 00:06:05.000
iPhoneは超広角カメラフィードを2つに分割し、机と顔の両方を同時に見せるので、学校のプロジェクトでコラボレーションしたり、友人に編みステッチを教えたりできます。

00:06:05.000 -> 00:06:18.000
超広角カメラの拡張垂直視野を活用し、トリミングされたフレームに遠近法歪み補正を適用し、フレームを回転させてこのデスクビューを作成します。

00:06:18.000 -> 00:06:52.000
ほとんどのビデオ会議アプリで利用可能な共有ウィンドウ機能を使用して、メインのビデオカメラフィードと並行して実行されるこのデスクビューフィードを共有できます。

00:06:52.000 -> 00:06:57.000
デスクビューは、メインカメラから同時にストリーミングすることなく、単独で使用することもできます。

00:06:57.000 -> 00:07:07.000
しかし、デスクビューとメインカメラの両方からストリーミングする場合は、メインカメラでセンターステージを有効にして、顔と体をキャプチャするためのより良いフレーミングを行うことをお勧めします。

00:07:07.000 -> 00:07:12.000
この機能は、電話が横向きまたは縦向きのいずれかに配置されている場合にサポートされます。

00:07:12.000 -> 00:07:19.000
縦向きは、垂直視野が大きいため、最も汎用性を提供します。

00:07:19.000 -> 00:07:26.000
アプリケーションに適したカスタマイズされた統合を提供するデスクビューカメラAPIもあります。

00:07:26.000 -> 00:07:29.000
すぐにAPIについて話します。

00:07:29.000 -> 00:07:38.000
Macでのビデオ会議通話中に、セッションに集中してほしいのですが、重要なことを見逃さないようにしたいと考えています。

00:07:38.000 -> 00:07:49.000
コンティニュイティカメラが使用されている場合、携帯電話上のすべての通知が消音され、重要な通話通知がMacに転送されます。

00:07:49.000 -> 00:07:50.000
さようなら、エリック！

00:07:50.000 -> 00:07:58.000
エリック：さようなら、カレン！

00:07:58.000 -> 00:08:07.000
カレン：アプリケーションに新しいコードを1行も書き込むことなく、ユーザーが利用できるすべての素晴らしい体験について話しました。

00:08:07.000 -> 00:08:16.000
しかし、新しいAPIの採用により、Continuity Cameraの体験をアプリでさらに魔法のように洗練されたものにすることができます。

00:08:16.000 -> 00:08:24.000
ほとんどのユーザーがMacで少なくとも2つのカメラデバイスを手に入れるようになったので、カメラをどのように管理すべきかについてもっと考えました。

00:08:24.000 -> 00:08:36.000
macOS 13より前は、デバイスのプラグを抜いた場合、またはより良いカメラがシステムで利用可能になった場合、通常、アプリケーションでは手動選択ステップが必要です。

00:08:36.000 -> 00:08:43.000
アプリケーションでカメラを自動的に切り替えることで、お客様に魔法のような体験を提供したいと考えています。

00:08:43.000 -> 00:08:56.000
アプリでこの機能を構築するのに役立つ2つの新しいAPIをAVFoundationフレームワークに追加しました。クラスプロパティuserPreferredCameraとAVCaptureDeviceのsystemPreferredCameraです。

00:08:56.000 -> 00:09:00.000
userPreferredCameraは読み取り/書き込みプロパティです。

00:09:00.000 -> 00:09:05.000
ユーザーがアプリケーションでカメラを選択するたびに、このプロパティを設定する必要があります。

00:09:05.000 -> 00:09:18.000
これにより、AVCaptureDeviceクラスはユーザーの好みを学習し、アプリの起動と再起動で各アプリケーションのカメラのリストを保存し、その情報を使用してカメラを提案することができます。

00:09:18.000 -> 00:09:25.000
また、カメラが接続されるか切断されるかも考慮されます。

00:09:25.000 -> 00:09:33.000
このプロパティはキー値で観察可能で、ユーザーの好みに基づいて最適な選択をインテリジェントに返します。

00:09:33.000 -> 00:09:41.000
最新の優先デバイスが切断されると、リスト内の次の利用可能なカメラに自発的に変更されます。

00:09:41.000 -> 00:09:56.000
ユーザー選択履歴がない場合や、優先デバイスが接続されていない場合でも、プロパティは常にすぐに使用できるカメラデバイスを返し、以前にストリーミングされたカメラを優先しようとします。

00:09:56.000 -> 00:10:03.000
システムにカメラがない場合にのみnilを返します。

00:10:03.000 -> 00:10:06.000
systemPreferredCameraは読み取り専用プロパティです。

00:10:06.000 -> 00:10:15.000
これは、userPreferredCameraだけでなく、システムに存在するカメラの最良の選択を提案するために、他のいくつかの要因を組み込んでいます。

00:10:15.000 -> 00:10:26.000
たとえば、このプロパティは、Continuity Cameraが自動的に選択する必要があるというシグナルを表示すると、userPreferredCameraとは異なる値を返します。

00:10:26.000 -> 00:10:34.000
このプロパティはまた、デバイスのサスペンションを内部的に追跡するので、中断されたデバイスよりもサスペンドされていないデバイスを優先します。

00:10:34.000 -> 00:10:44.000
これは、内蔵カメラがMacBookの蓋を閉じることから中断された場合に、別のカメラに変更する自動切り替え動作を構築するのに役立ちます。

00:10:44.000 -> 00:11:00.000
連続性カメラは、電話が横向きの固定スタンドに置かれ、画面がオフになり、USB経由でMacに接続されているか、Macの近い範囲内に接続されているときに、自動的に選択されるように通知します。

00:11:00.000 -> 00:11:10.000
このシナリオでは、デバイスが継続カメラとして使用されるべきであるというユーザーの意図は明らかです。

00:11:10.000 -> 00:11:25.000
systemPreferredCamera APIを採用する場合は、常にキー値でこのプロパティを観察し、それに応じてAVCaptureSessionのビデオ入力デバイスを更新して、魔法のカメラの選択体験を提供する必要があります。

00:11:25.000 -> 00:11:31.000
userPreferredCameraとsystemPreferredCameraはすでにファーストパーティアプリケーションで採用されています。

00:11:31.000 -> 00:11:43.000
これらのAPIを採用するアプリケーションが増えているため、Appleデバイスでユニバーサルで一貫したカメラ選択方法をお客様に提供できるようになります。

00:11:43.000 -> 00:11:56.000
連続カメラによる自動切り替えがFaceTimeでどのように見えるかを説明するデモをお見せしましょう。

00:11:56.000 -> 00:12:00.000
ここFaceTimeでは、自動カメラ選択モードになっています。

00:12:00.000 -> 00:12:13.000
手動と自動の両方の動作を提供したいアプリケーションには、自動モードを有効または無効にするための新しいUIを追加することをお勧めします。

00:12:13.000 -> 00:12:16.000
FaceTimeは現在、内蔵カメラからストリーミング中です。

00:12:16.000 -> 00:12:26.000
机から電話を取り、MacBookの後ろのスタンドに置くと...

00:12:26.000 -> 00:12:32.000
...FaceTimeは、Continuity Cameraからシームレスにストリーミングに切り替わります。

00:12:32.000 -> 00:12:43.000
そこで、新しいクラスプロパティsystemPreferredCameraが登場します。電話がストリーミングする準備ができている位置にあるとき、プロパティ値はContinuity Cameraに変わります。

00:12:43.000 -> 00:12:47.000
同様の方法でアプリケーションを構築したいと思うかもしれません。

00:12:47.000 -> 00:12:55.000
これは、自動カメラ選択と手動選択モードを実装する方法に関する私のレシピです。

00:12:55.000 -> 00:13:02.000
自動カメラ選択がオンのときは、systemPreferredCameraプロパティを観察するキー値を開始します。

00:13:02.000 -> 00:13:09.000
セッションの入力デバイスを更新して、変更されるたびにsystemPreferredCameraに従ってください。

00:13:09.000 -> 00:13:15.000
オートモードでは、ユーザーが自分でカメラを選択できるようにするオプションを提供することを強くお勧めします。

00:13:15.000 -> 00:13:26.000
別のカメラが選択されたら、userPreferredCameraをそのデバイスに設定すると、systemPreferredCameraのプロパティ値に反映されます。

00:13:26.000 -> 00:13:33.000
自動カメラ選択がオフの場合、systemPreferredCameraプロパティのキー値の観察を停止します。

00:13:33.000 -> 00:13:42.000
systemPreferredCameraに従う代わりに、手動モードでユーザーが選んだカメラでセッションの入力デバイスを更新する必要があります。

00:13:42.000 -> 00:13:59.000
しかし、自動モードと同様に、ユーザーが別のカメラを選択するたびにuserPreferredCameraプロパティを設定する必要があるため、優先カメラのユーザーの履歴を維持し、自動カメラ選択モードに戻るときに適切なカメラを提案します。

00:13:59.000 -> 00:14:10.000
userPreferredCameraとsystemPreferredCamera APIを組み込む方法に関するベストプラクティスについては、新しいサンプルアプリ「Continuity Camera Sample」をご覧ください。

00:14:10.000 -> 00:14:23.000
Continuity Cameraは、Macに魔法のウェブカメラ体験をもたらすだけでなく、MacアプリでiPhone固有のカメラ機能のパワーを活用する新しい機会を提供します。

00:14:23.000 -> 00:14:33.000
アプリケーションがContinuity Cameraデバイスをよりよく活用できるように、macOS 13にいくつかのAVCapture APIを追加しました。

00:14:33.000 -> 00:14:39.000
Continuity Cameraのおかげで、iPhoneの写真撮影の驚くべき品質をmacOSにもたらしています。

00:14:39.000 -> 00:14:44.000
まず、高解像度の写真のキャプチャをサポートします。

00:14:44.000 -> 00:14:49.000
以前は、macOSはビデオ解像度での写真撮影のみをサポートしていました。

00:14:49.000 -> 00:14:56.000
macOS 13以降では、Continuity Cameraで最大12メガピクセルの写真を撮影できます。

00:14:56.000 -> 00:15:16.000
これは、キャプチャセッションを開始する前に、まずAVCapturePhotoOutputオブジェクトでhighResolutionCaptureEnabledをtrueに設定し、各キャプチャのphotoSettingsオブジェクトでhighResolutionPhotoEnabledプロパティをtrueに設定することで有効にできます。

00:15:16.000 -> 00:15:44.000
高解像度の写真をキャプチャすることに加えて、Continuity Cameraは、最初にphotoOutputオブジェクトで最大写真品質の優先順位を設定し、AVCapturePhotoSettingsオブジェクトにphotoQualityPrioritizationプロパティを設定して各キャプチャの優先順位を選択することで、写真の品質を速度に対して優先順位を付ける方法を制御することをサポートしています。

00:15:44.000 -> 00:15:58.000
アプリケーションの適切な優先順位の選択の詳細については、WWDC2021の「ビデオフォーマットを使用して高品質の写真をキャプチャする」をご覧ください。

00:15:58.000 -> 00:16:01.000
もう1つの写真関連の機能はフラッシュキャプチャです。

00:16:01.000 -> 00:16:14.000
photoSettingsオブジェクトにflashModeを設定して、シーンと照明条件に基づいてフラッシュをオン、オフ、または自動的に選択するかどうかを制御できるようになりました。

00:16:14.000 -> 00:16:25.000
また、キャプチャセッションによって生成された時付けされたメタデータを処理できるように、macOSでAVCaptureMetadataOutputを利用できるようにしています。

00:16:25.000 -> 00:16:32.000
iPhoneから顔のメタデータオブジェクトと人体のメタデータオブジェクトをストリーミングできるようになりました。

00:16:32.000 -> 00:16:37.000
顔のメタデータオブジェクトを受信するためのセッションを設定する方法を見てみましょう。

00:16:37.000 -> 00:16:48.000
適切なビデオ入出力でセッションを設定した後、AVCaptureMetadataOutputを作成し、addOutputを呼び出してセッションに追加する必要があります。

00:16:48.000 -> 00:16:57.000
特にフェイスメタデータを受信するには、フェイスオブジェクトタイプを含めるように出力にオブジェクトタイプ配列を設定します。

00:16:57.000 -> 00:17:06.000
availableMetadataObjectTypesプロパティをチェックして、要求されたメタデータ型がサポートされていることを確認してください。

00:17:06.000 -> 00:17:10.000
次に、メタデータコールバックを受信するようにデリゲートを設定します。

00:17:10.000 -> 00:17:18.000
セッションの実行が開始されると、リアルタイムで生成されたフェイスメタデータオブジェクトでコールバックを取得します。

00:17:18.000 -> 00:17:33.000
先ほど話したAVCapturePhotoOutputとAVCaptureMetadataOutputに加えて、Continuity Cameraはビデオデータ出力、ムービーファイル出力、AVCaptureVideoPreviewLayerもサポートしています。

00:17:33.000 -> 00:17:42.000
これは、このカメラをアプリケーションに統合する際に注意すべきContinuity Cameraでサポートされているビデオフォーマットのリストです。

00:17:42.000 -> 00:17:53.000
640×480から1080pまでの3つの16×9フォーマットと、1920×1440の1つの4×3フォーマットをサポートしています。

00:17:53.000 -> 00:18:01.000
必要に応じて、最大30フレーム/秒または60フレーム/秒をサポートするフォーマットを選択できます。

00:18:01.000 -> 00:18:05.000
もう1つの大きな追加は、デスクビューデバイスAPIです。

00:18:05.000 -> 00:18:10.000
デスクビューカメラは、別のAVCaptureDeviceとして公開されます。

00:18:10.000 -> 00:18:12.000
このデバイスを見つけるには2つの方法があります。

00:18:12.000 -> 00:18:20.000
1つ目は、デバイス検出セッションでAVCaptureDeviceType DeskViewCameraを調べることです。

00:18:20.000 -> 00:18:33.000
または、メインビデオカメラのAVCaptureDeviceオブジェクトをすでに知っている場合は、そのデバイスのcompanionDeskViewCameraプロパティを使用してデスクビューデバイスにアクセスできます。

00:18:33.000 -> 00:18:42.000
このAPIは、複数のContinuity Cameraデバイスがある場合に、メインカメラとデスクビューデバイスをペアリングするのに役立ちます。

00:18:42.000 -> 00:19:00.000
目的のデスクビューカメラのAVCaptureDeviceオブジェクトを取得したら、他のカメラデバイスと同様に、キャプチャセッションでAVCaptureビデオデータ出力、ムービーファイル出力、またはビデオプレビューレイヤーで使用できます。

00:19:00.000 -> 00:19:06.000
デスクビューデバイスは現在、420Vピクセルフォーマットの1つのストリーミングフォーマットをサポートしています。

00:19:06.000 -> 00:19:14.000
フォーマットの解像度は1920×1440で、サポートされている最大フレームレートは30fpsです。

00:19:14.000 -> 00:19:16.000
これでセッションは終わりです。

00:19:16.000 -> 00:19:27.000
コンティニュイティカメラ、macOSで魔法のカメラの選択を構築する方法、およびMacアプリケーションにコンティニュイティカメラを統合するためのいくつかの新しいAPIについて学びました。

00:19:27.000 -> 00:19:34.000
私はあなたがこれらすべてのAPIを採用し、WWDCの素晴らしい残りを持っているのを見て興奮しています。

00:19:34.000 -> 23:59:59.000
♪

