WEBVTT

00:00:00.000 --> 00:00:03.000
♪ (부드러워 기악 힙합 음악) ♪

00:00:03.000 --> 00:00:09.000
♪

00:00:09.000 --> 00:00:14.000
프라빈 샤르마: 안녕하세요. 제 이름은 프라빈이고, 저는 여기 애플의 프로토타이핑 팀에서 왔습니다.

00:00:14.000 --> 00:00:18.000
카이 강: 안녕. 제 이름은 카이이고 비디오 엔지니어링 팀에서 왔어요.

00:00:18.000 --> 00:00:24.000
프라빈: 지난 몇 년 동안 애플은 사람들이 세상을 앱으로 가져올 수 있는 강력한 새로운 방법을 가능하게 했다.

00:00:24.000 --> 00:00:39.000
작년에, 우리는 실제 물체의 사진을 찍는 Object Capture를 도입했고, RealityKit의 Photogrammetry API를 사용하여 앱에서 사용할 수 있는 3D 모델로 바꿉니다.

00:00:39.000 --> 00:00:54.000
개체 캡처에 앞서, 우리는 공간의 기하학적 구조를 거칠게 이해하고 앱에서 새로운 증강 현실 사용 사례를 가능하게 하는 장면 재구성 API를 출시했습니다.

00:00:54.000 --> 00:01:01.000
올해, 우리는 RoomPlan이라는 새로운 프레임워크를 발표하게 되어 매우 기쁩니다.

00:01:01.000 --> 00:01:07.000
RoomPlan을 사용하면 LiDAR 지원 iPhone 또는 iPad를 사용하여 방을 스캔할 수 있습니다.

00:01:07.000 --> 00:01:15.000
앱에서 사용할 수 있는 방과 방 정의 객체의 파라메트릭 3D 모델을 생성합니다.

00:01:15.000 --> 00:01:21.000
RoomPlan 스캐닝 경험이 어떻게 생겼는지 살펴봅시다.

00:01:21.000 --> 00:01:40.000
RoomPlan은 ARKit으로 구동되는 정교한 기계 학습 알고리즘을 사용하여 벽, 창문, 개구부 및 문뿐만 아니라 벽난로, 소파, 테이블 및 캐비닛과 같은 방을 정의하는 물체를 감지합니다.

00:01:40.000 --> 00:01:52.000
RealityKit을 사용하여 스캔 진행 상황을 실시간으로 렌더링하는 RoomCaptureView API를 사용하면 스캔 경험을 앱에 쉽게 통합할 수 있습니다.

00:01:52.000 --> 00:02:04.000
그리고 스캔을 마치면, RoomCaptureView는 사용 사례에 가장 잘 맞는 최종 후처리 결과를 제공합니다.

00:02:04.000 --> 00:02:14.000
처음으로, 기계 학습과 컴퓨터 비전 알고리즘을 구현하는 복잡성 없이, 사람들은 이제 새로운 방식으로 그들의 방과 상호 작용할 수 있다.

00:02:14.000 --> 00:02:24.000
예를 들어, 인테리어 디자인 앱은 벽 색상 변화를 미리 보고 방을 다시 칠하는 데 필요한 페인트의 양을 정확하게 계산할 수 있습니다.

00:02:24.000 --> 00:02:31.000
건축 앱은 이제 누군가가 방 레이아웃의 변경 사항을 실시간으로 미리 보고 편집할 수 있도록 쉽게 할 수 있습니다.

00:02:31.000 --> 00:02:39.000
부동산 앱은 이제 에이전트가 목록의 평면도와 3D 모델을 캡처할 수 있도록 원활하게 할 수 있습니다.

00:02:39.000 --> 00:02:46.000
그리고 전자상거래 앱은 물리적 공간에서 제품 시각화를 통해 고객을 참여시킬 수 있다.

00:02:46.000 --> 00:02:56.000
이것들은 RoomPlan이 활성화하는 응용 프로그램의 몇 가지 예일 뿐이며, RoomPlan을 앱에 통합하는 것이 얼마나 간단한지 보고 놀랄 것입니다.

00:02:56.000 --> 00:02:57.000
한 번 보자.

00:02:57.000 --> 00:03:01.000
RoomPlan을 사용할 수 있는 두 가지 주요 방법이 있습니다.

00:03:01.000 --> 00:03:08.000
첫 번째는 RoomPlan을 앱에 원활하게 통합할 수 있는 즉시 사용 가능한 스캔 경험입니다.

00:03:08.000 --> 00:03:18.000
두 번째는 앱이 스캔의 실시간 파라메트릭 데이터를 사용할 수 있도록 하는 데이터 API이지만 사용 사례에 가장 적합합니다.

00:03:18.000 --> 00:03:30.000
이 두 API를 모두 사용하면 최상의 스캔 결과를 얻을 수 있도록 몇 가지 모범 사례를 권장하며, 이 프레젠테이션의 마지막 섹션에서 검토할 것입니다.

00:03:30.000 --> 00:03:38.000
먼저, 새로운 RoomCaptureView API를 사용하여 앱에 가져올 수 있는 스캔 경험에 대해 이야기해 봅시다.

00:03:38.000 --> 00:03:43.000
RoomCaptureView는 앱에 쉽게 배치할 수 있는 UIView 하위 클래스입니다.

00:03:43.000 --> 00:03:54.000
그것은 세계 공간 스캐닝 피드백, 실시간 룸 모델 생성, 코칭 및 사용자 지침의 프레젠테이션을 처리합니다.

00:03:54.000 --> 00:04:01.000
RoomCaptureView 기반 스캔 중에 제시된 디자인 요소를 자세히 살펴봅시다.

00:04:01.000 --> 00:04:13.000
활성 RoomCaptureView 세션 동안, 애니메이션 라인은 벽, 창문, 개구부, 문 및 방을 정의하는 물체를 실시간으로 감지합니다.

00:04:13.000 --> 00:04:23.000
RoomCaptureView 하단에서 실시간으로 생성된 대화형 3D 모델은 스캔 진행 상황에 대한 개요를 한 눈에 제공합니다.

00:04:23.000 --> 00:04:29.000
마지막으로, 텍스트 코칭은 최상의 스캔 결과를 안내합니다.

00:04:29.000 --> 00:04:35.000
간단한 네 단계로 RoomCaptureView를 어떻게 사용할 수 있는지 살펴봅시다.

00:04:35.000 --> 00:04:40.000
먼저, 우리는 ViewController에서 RoomCaptureView 참조를 만듭니다.

00:04:40.000 --> 00:04:46.000
둘째, 우리는 RoomCaptureSession 구성 객체에 대한 참조를 만듭니다.

00:04:46.000 --> 00:04:54.000
셋째, 우리는 스캔 세션을 시작하고, 구성을 캡처 세션의 실행 기능으로 전달합니다.

00:04:54.000 --> 00:05:00.000
그리고 마지막으로, 우리의 응용 프로그램은 캡처 세션에 스캔을 중지하라고 말한다.

00:05:00.000 --> 00:05:14.000
선택적으로, 앱은 RoomCaptureViewDelegate 프로토콜을 준수하고 사후 처리된 결과와 프레젠테이션을 거부하거나 사후 처리된 스캔 결과를 처리할 수 있습니다.

00:05:14.000 --> 00:05:25.000
예를 들어, 제공된 CapturedRoom 데이터 구조체에서 사용할 수 있는 내보내기 기능을 호출하여 결과의 USDZ를 내보낼 수 있습니다.

00:05:25.000 --> 00:05:29.000
그리고 그것이 RoomPlan을 앱에 통합하는 것이 얼마나 간단한지입니다.

00:05:29.000 --> 00:05:32.000
우리는 당신이 이 API로 무엇을 만드는지 보게 되어 매우 기쁩니다.

00:05:32.000 --> 00:05:39.000
이제 내 동료 Kai는 RoomCaptureSession과 RoomPlan의 데이터 API에 대해 이야기할 것이다.

00:05:39.000 --> 00:05:40.000
카이: 고마워, 프라빈.

00:05:40.000 --> 00:05:55.000
이 섹션에서는 스캔하는 동안 기본 데이터 구조에 대한 액세스를 제공하고 처음부터 스캐닝 경험의 사용자 지정 시각화를 구축하는 데 도움이 되는 데이터 API를 안내할 것입니다.

00:05:55.000 --> 00:06:03.000
기본 워크플로우는 스캔, 프로세스 및 내보내기의 세 부분으로 구성되어 있습니다.

00:06:03.000 --> 00:06:13.000
스캔을 위해, 우리는 캡처 세션을 설정하고 시작하는 방법과 캡처 프로세스를 표시하고 모니터링하는 방법에 대한 기본 사항을 다룰 것입니다.

00:06:13.000 --> 00:06:21.000
그런 다음 스캔한 데이터가 어떻게 처리되고 최종 모델이 프레젠테이션을 위해 수신되는지 살펴볼 것입니다.

00:06:21.000 --> 00:06:32.000
마지막으로, USD 워크플로우에서도 사용할 수 있는 출력 USD 파일을 생성하고 내보내는 방법에 대해 논의할 것입니다.

00:06:32.000 --> 00:06:36.000
이제, 스캔 단계를 자세히 살펴봅시다.

00:06:36.000 --> 00:06:43.000
우리는 RoomCaptureSession API를 사용하여 세션을 설정하고 스캔을 계속할 때 진행 상황을 표시할 것입니다.

00:06:43.000 --> 00:06:47.000
코드로 보여줄게.

00:06:47.000 --> 00:06:50.000
다음은 간단한 RealityKit 앱의 예입니다.

00:06:50.000 --> 00:06:56.000
시작하려면, RoomPlan을 Swift 프로젝트로 가져오기만 하면 됩니다.

00:06:56.000 --> 00:07:05.000
앱의 ViewController에서 결과를 시각화하고 RoomCaptureSession 인스턴스를 시작하는 사용자 지정 유형을 가질 수 있습니다.

00:07:05.000 --> 00:07:17.000
또한, RoomCaptureSession은 앱이 AR 보기에서 평면과 개체 경계 상자를 그릴 수 있도록 기본 AR 세션에 핸들을 제공합니다.

00:07:17.000 --> 00:07:20.000
RoomCaptureSession은 위임 패턴을 채택한다.

00:07:20.000 --> 00:07:26.000
ViewController 클래스에서 ViewController 자체를 captureSession의 대리인으로 할당할 수 있습니다.

00:07:26.000 --> 00:07:33.000
이를 통해 ViewController는 RoomCaptureSession에서 실시간 업데이트를 받을 수 있습니다.

00:07:33.000 --> 00:07:39.000
이러한 업데이트에는 캡처하는 동안 사람들을 안내하기 위한 3D 모델과 지침이 포함됩니다.

00:07:39.000 --> 00:07:48.000
이러한 업데이트를 받으려면, ViewController는 RoomCaptureSessionDelegate 프로토콜을 준수하고 두 가지 방법을 구현해야 합니다.

00:07:48.000 --> 00:07:57.000
첫 번째는 실시간 CapturedRoom 데이터 구조를 얻기 위한 captureSession(_ session: didUpdate room:) 방법입니다.

00:07:57.000 --> 00:08:05.000
비주얼라이저를 사용하여 3D 모델의 AR 뷰를 업데이트할 수 있으며, 이는 사람들에게 진행 상황에 대한 실시간 피드백을 제공합니다.

00:08:05.000 --> 00:08:11.000
우리는 대화의 후반부에서 CapturedRoom 구조에 더 깊이 빠져들 것이다.

00:08:11.000 --> 00:08:16.000
이 방법은 캡처된 방에 대한 업데이트를 감지할 때 호출될 것이다.

00:08:16.000 --> 00:08:21.000
두 번째 방법은 captureSession(_ session: didProvide instruction:)이다.

00:08:21.000 --> 00:08:27.000
이 방법은 실시간 피드백이 포함된 명령 구조를 제공합니다.

00:08:27.000 --> 00:08:33.000
당신의 시각 자료는 스캔하는 동안 사람들을 안내하기 위해 지침을 사용할 수 있습니다.

00:08:33.000 --> 00:08:37.000
이 API가 제공하는 지침을 살펴봅시다.

00:08:37.000 --> 00:08:53.000
이러한 지침에는 물체와의 거리, 스캔 속도, 방에 대한 조명 조정뿐만 아니라 더 많은 질감을 가진 방의 특정 영역에 초점을 맞추는 것이 포함됩니다.

00:08:53.000 --> 00:09:01.000
이러한 지침은 실시간 피드백으로 사람들을 안내하기 위해 스캔 중에 제공될 것입니다.

00:09:01.000 --> 00:09:04.000
다음으로, 우리는 프로세스 부분으로 넘어갈 것이다.

00:09:04.000 --> 00:09:13.000
이 섹션에서는 RoomBuilder 클래스를 사용하여 스캔한 데이터를 처리하고 최종 3D 모델을 생성할 것입니다.

00:09:13.000 --> 00:09:21.000
캡처된 데이터를 처리하려면, 첫 번째 단계는 ViewController 클래스에서 RoomBuilder 인스턴스를 시작하는 것입니다.

00:09:21.000 --> 00:09:32.000
다음으로, 캡처 프로세스 후 센서 데이터를 받으려면, 앱은 captureSession(_ session: didEndWith data: error:) 메소드를 구현해야 합니다.

00:09:32.000 --> 00:09:45.000
RoomCaptureSession이 중지되면, 앱에서 stop() 함수를 호출하거나 오류로 인해, 이 함수는 CaptureRoomData 객체와 선택적 오류를 반환하기 위해 호출됩니다.

00:09:45.000 --> 00:09:55.000
마지막으로, 캡처된 데이터를 처리하기 위해, 우리는 await 키워드를 사용하여 roomBuilder의 비동기 roomModel(from:) 메소드를 호출합니다.

00:09:55.000 --> 00:10:01.000
이 방법은 스캔된 데이터를 처리하고 최종 3D 모델을 구축하기 위해 비동기적으로 실행됩니다.

00:10:01.000 --> 00:10:09.000
그것은 우리가 작년 WWDC에서 도입한 Swift async/await 기능을 활용한다.

00:10:09.000 --> 00:10:17.000
단 몇 초 안에, 그 모델은 당신의 앱에서 최종 프레젠테이션에 사용할 수 있을 것입니다.

00:10:17.000 --> 00:10:26.000
이제 CapturedRoom 데이터 구조의 세부 사항과 앱에서 사용하기 위해 내보낼 수 있는 방법에 대해 자세히 알아보겠습니다.

00:10:26.000 --> 00:10:32.000
최상위 수준에는 표면과 물체로 구성된 CapturedRoom이 있다.

00:10:32.000 --> 00:10:49.000
표면에는 반경, 시작 및 종료 각도, 표면의 네 개의 다른 가장자리, 벽, 개구부, 창문, 문과 같은 곡선을 나타내는 독특한 속성이 포함되어 있습니다.

00:10:49.000 --> 00:10:56.000
물건에는 테이블, 침대, 소파 등과 같은 가구 카테고리가 포함되어 있습니다.

00:10:56.000 --> 00:11:13.000
표면과 물체는 치수, 스캔된 표면이나 물체에 대한 세 가지 수준의 자신감을 제공하는 자신감, 3D 변환 매트릭스 및 고유 식별자와 같은 몇 가지 공통 속성을 공유합니다.

00:11:13.000 --> 00:11:17.000
그들이 코드에서 어떻게 표현되는지 봅시다.

00:11:17.000 --> 00:11:23.000
CapturedRoom 구조는 방 안의 요소에 대한 완전한 파라메트릭 표현이다.

00:11:23.000 --> 00:11:31.000
그것은 벽, 개구부, 문, 창문, 그리고 방 안의 물건을 포함한 다섯 가지 속성을 포함한다.

00:11:31.000 --> 00:11:41.000
처음 네 요소의 경우, 그들은 2D 평면 건축 구조를 나타내는 표면 구조로 표현된다.

00:11:41.000 --> 00:11:47.000
오른쪽에서, 당신은 우리가 이전에 다루었던 표면의 다양한 특성을 볼 수 있습니다.

00:11:47.000 --> 00:11:54.000
마지막 속성은 방에 있는 3D 물체의 배열이며, 그것들은 입체체로 표현된다.

00:11:54.000 --> 00:11:59.000
오른쪽에서, 당신은 객체의 다양한 속성을 볼 수 있습니다.

00:11:59.000 --> 00:12:04.000
다음은 RoomPlan에서 지원하는 객체 유형 목록입니다.

00:12:04.000 --> 00:12:12.000
여기에는 소파, 테이블, 의자, 침대 등과 같은 다양한 일반적인 가구 유형이 포함됩니다.

00:12:12.000 --> 00:12:24.000
마지막으로, 내보내기 기능을 사용하면 이 CapturedRoom을 기존 워크플로우의 USD 또는 USDZ 데이터로 내보낼 수 있습니다.

00:12:24.000 --> 00:12:40.000
다음은 Cinema 4D에서 USD 출력을 직접 열어 방의 계층적 데이터 구조와 각 방 요소 또는 개체의 크기와 위치를 탐색하고 편집하는 방법을 보여주는 예입니다.

00:12:40.000 --> 00:12:57.000
또한 기존 USD 및 USDZ 워크플로우를 활용하여 캡처된 방의 렌더링을 부동산, 전자 상거래, 유틸리티 및 인테리어 디자인과 같은 다양한 애플리케이션에 추가할 수 있습니다.

00:12:57.000 --> 00:13:02.000
지금까지, 우리는 스캐닝 경험과 기본 RoomPlan API를 다루었습니다.

00:13:02.000 --> 00:13:09.000
우리는 이제 RoomPlan으로 좋은 결과를 얻을 수 있도록 몇 가지 모범 사례를 살펴볼 것입니다.

00:13:09.000 --> 00:13:22.000
우리는 좋은 스캔을 허용하는 권장 조건, 방을 선택하는 동안 살펴봐야 할 방 기능, 그리고 명심해야 할 몇 가지 스캔 및 열 고려 사항을 다룰 것입니다.

00:13:22.000 --> 00:13:29.000
RoomPlan API는 전형적인 가정에서 가장 일반적인 건축 구조와 물체를 지원합니다.

00:13:29.000 --> 00:13:38.000
최대 방 크기가 30피트 x 30피트 또는 약 9 x 9미터인 싱글 주거용 방에 가장 적합합니다.

00:13:38.000 --> 00:13:45.000
조명은 또한 API가 선명한 비디오 스트림과 좋은 AR 추적 성능을 얻는 데 중요하다.

00:13:45.000 --> 00:13:54.000
밤에 가족 거실에서 전형적인 API를 사용하려면 최소 50럭스 이상을 사용하는 것이 좋습니다.

00:13:54.000 --> 00:14:02.000
하드웨어의 경우, RoomPlan API는 모든 LiDAR 지원 iPhone 및 iPad Pro 모델에서 지원됩니다.

00:14:02.000 --> 00:14:07.000
API에 도전할 수 있는 몇 가지 특별한 조건이 있다.

00:14:07.000 --> 00:14:15.000
예를 들어, 전체 높이 거울과 유리는 LiDAR 센서가 예상 출력을 생성하는 데 어려움을 제기한다.

00:14:15.000 --> 00:14:20.000
높은 천장조차도 LiDAR 센서의 스캐닝 범위 한계를 초과할 수 있다.

00:14:20.000 --> 00:14:27.000
또한, 매우 어두운 표면은 장치가 스캔하기 어려울 수 있다.

00:14:27.000 --> 00:14:31.000
더 나은 스캔 결과를 얻기 위한 몇 가지 고려 사항이 있습니다.

00:14:31.000 --> 00:14:41.000
첫째, 정확도 요구 사항이 높은 응용 프로그램의 경우, 스캔하기 전에 방을 준비하면 스캔의 품질을 향상시킬 수 있습니다.

00:14:41.000 --> 00:14:50.000
예를 들어, 커튼을 열면 더 많은 자연광이 들어오고 창문 폐색을 줄일 수 있으며, 이는 주간 스캔에 가장 적합합니다.

00:14:50.000 --> 00:14:57.000
문을 닫으면 방 밖의 불필요한 영역을 스캔할 가능성을 줄일 수 있다.

00:14:57.000 --> 00:15:03.000
좋은 스캐닝 동작을 따르는 것은 API로 좋은 스캐닝 결과를 달성하는 데 매우 중요합니다.

00:15:03.000 --> 00:15:16.000
그리고 그것이 우리가 스캔하는 동안 사람들에게 텍스처, 거리, 속도 및 조명 조건에 대한 피드백을 제공하기 위해 사용자 지시 위임 방법을 제공하는 이유입니다.

00:15:16.000 --> 00:15:21.000
명심해야 할 또 다른 것은 장치의 배터리와 열전이다.

00:15:21.000 --> 00:15:27.000
우리는 좋은 스캐닝 경험을 보장하기 위해 RoomPlan API에서 많은 최적화를 수행했습니다.

00:15:27.000 --> 00:15:34.000
그럼에도 불구하고, 5분 동안 반복적인 스캔이나 한 번의 긴 스캔을 피하는 것이 가장 좋습니다.

00:15:34.000 --> 00:15:45.000
이것들은 피로를 유발할 뿐만 아니라 배터리를 소모하고 앱의 사용자 경험에 영향을 미칠 수 있는 열 문제를 일으킬 수 있습니다.

00:15:45.000 --> 00:15:47.000
오늘 우리가 다룬 많은 것들이 있다.

00:15:47.000 --> 00:15:50.000
우리는 새로운 API인 RoomPlan을 도입했다.

00:15:50.000 --> 00:16:05.000
방을 캡처할 수 있는 직관적인 스캔 경험, 환경을 이해하기 위한 강력한 기계 학습 모델, 앱에 쉽게 통합할 수 있는 완전한 파라메트릭 USD 출력 형식을 제공합니다.

00:16:05.000 --> 00:16:13.000
새로운 RoomPlan 경험을 더 잘 설계하고 구현하는 방법에 대한 지침은 아래의 관련 회담을 확인하세요.

00:16:13.000 --> 00:16:16.000
Praveen: 앱에서 RoomPlan을 시도해 볼 시간입니다.

00:16:16.000 --> 00:16:19.000
우리는 당신이 이 새로운 API로 무엇을 만들 수 있는지 빨리 보고 싶습니다.

00:16:19.000 --> 00:16:21.000
카이: 봐줘서 고마워!

00:16:21.000 --> 23:59:59.000
♪

