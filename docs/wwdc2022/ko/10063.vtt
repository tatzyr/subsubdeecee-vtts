WEBVTT

00:00:00.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:12.000
드루바: WWDC 2022에 오신 것을 환영합니다.

00:00:12.000 --> 00:00:16.000
제 이름은 드루바이고, 저는 GPUSW 엔지니어입니다.

00:00:16.000 --> 00:00:25.000
오늘, 마테오와 나는 올해 메탈에서 기계 학습을 위해 도입된 모든 새로운 기능과 개선 사항을 탐구할 것이다.

00:00:25.000 --> 00:00:31.000
기계 학습 교육은 ML 파이프라인에서 가장 계산 집약적인 과정이다.

00:00:31.000 --> 00:00:37.000
병렬 특성으로 인해, GPU는 ML 워크로드에서 탁월하다.

00:00:37.000 --> 00:00:44.000
금속 기계 학습 API는 금속 성능 셰이더 또는 MPS라는 프레임워크를 통해 노출됩니다.

00:00:44.000 --> 00:00:56.000
MPS는 이미지 처리, 선형 대수학, 레이 트레이싱 및 기계 학습과 같은 다양한 분야를 위한 고성능 GPU 프리미티브 모음입니다.

00:00:56.000 --> 00:01:02.000
이 금속 커널은 모든 플랫폼에서 최고의 성능을 제공하도록 최적화되어 있습니다.

00:01:02.000 --> 00:01:08.000
예를 들어 MPSImageCanny 필터는 입력 이미지의 가장자리 맵을 반환합니다.

00:01:08.000 --> 00:01:12.000
이것은 이미지 세분화 애플리케이션에서 일반적인 작업이다.

00:01:12.000 --> 00:01:21.000
올해, 캐니 필터는 4K, 고해상도 이미지를 최대 8배 더 빠르게 처리할 수 있다.

00:01:21.000 --> 00:01:32.000
MPS 그래프는 MPS 프레임워크 위에 있고 다차원 텐서에 대한 지원을 확장하는 GPU의 범용 컴퓨팅 그래프입니다.

00:01:32.000 --> 00:01:38.000
MPS 그래프를 사용하는 방법에 대한 자세한 내용을 보려면 이전 세션을 보는 것이 좋습니다.

00:01:38.000 --> 00:01:45.000
CoreML과 Tensorflow와 같은 높은 수준의 ML 프레임워크는 MPS 그래프 위에 있다.

00:01:45.000 --> 00:01:51.000
TensorFlow Metal 플러그인으로 GPU에서 TensorFlow 네트워크를 가속화할 수 있습니다.

00:01:51.000 --> 00:01:57.000
TensorFlow를 최대한 활용하는 방법에 대한 자세한 내용은 작년 세션을 확인하세요.

00:01:57.000 --> 00:02:01.000
마테오와 나는 이 세션에서 다룰 세 가지 주제가 있다.

00:02:01.000 --> 00:02:07.000
먼저, Apple GPU인 PyTorch에 제공되는 최신 ML 프레임워크를 소개하겠습니다.

00:02:07.000 --> 00:02:14.000
다음으로, 나는 올해 TensorFlow의 개선 사항에 대해 자세히 알아볼 것이다.

00:02:14.000 --> 00:02:20.000
마지막으로, 마테오는 MPS 그래프 프레임워크의 새로운 기능에 대해 이야기할 것이다.

00:02:20.000 --> 00:02:27.000
우리는 당신이 이제 Mac GPU에서 PyTorch 네트워크를 가속화할 수 있게 되어 정말 기쁩니다.

00:02:27.000 --> 00:02:32.000
PyTorch는 인기 있는 오픈 소스 기계 학습 프레임워크이다.

00:02:32.000 --> 00:02:41.000
PyTorch 커뮤니티에서 가장 많이 요청된 기능은 애플 실리콘의 GPU 가속 지원이었다.

00:02:41.000 --> 00:02:50.000
우리는 PyTorch 생태계에 새로운 MPS 백엔드를 도입하여 PyTorch에 금속의 힘을 가져오고 있습니다.

00:02:50.000 --> 00:02:56.000
이 백엔드는 공식 PyTorch 1.12 릴리스의 일부가 될 것이다.

00:02:56.000 --> 00:03:02.000
MPS 백엔드는 PyTorch 작업 커널과 런타임 프레임워크를 구현합니다.

00:03:02.000 --> 00:03:10.000
작업은 MPS 그래프와 MPS를 호출하고 런타임 구성 요소는 메탈을 사용합니다.

00:03:10.000 --> 00:03:22.000
이를 통해 PyTorch는 Metal의 명령 대기열, 명령 버퍼 및 동기화 프리미티브와 함께 MPS의 고효율 커널을 사용할 수 있습니다.

00:03:22.000 --> 00:03:32.000
운영 커널과 PyTorch MPS 런타임 구성 요소는 오픈 소스 코드의 일부이며 공식 PyTorch GitHub 저장소에 병합되었습니다.

00:03:32.000 --> 00:03:37.000
MPS PyTorch 백엔드를 사용하는 것은 간단한 3단계 과정이다.

00:03:37.000 --> 00:03:44.000
먼저, PyTorch 1.12부터 'pip install torch'를 사용하여 기본 패키지를 설치할 수 있습니다.

00:03:44.000 --> 00:03:49.000
이 패키지는 공식 파이썬 패키지 저장소에서 사용할 수 있습니다.

00:03:49.000 --> 00:03:57.000
환경 설정 및 설치에 대한 자세한 내용은 Metal Developer Resources 웹 페이지를 참조하십시오.

00:03:57.000 --> 00:04:01.000
둘째, PyTorch를 가져오고 MPS 장치를 만드세요.

00:04:01.000 --> 00:04:09.000
이 코드 스니펫은 사용 가능한 경우 MPS 장치 백엔드를 사용하며, 그렇지 않으면 CPU로 돌아갑니다.

00:04:09.000 --> 00:04:14.000
마지막 단계는 MPS 장치를 사용하기 위해 모델과 입력을 변환하는 것입니다.

00:04:14.000 --> 00:04:23.000
이것을 하는 방법을 보여주기 위해, 나는 torchvision에서 사전 훈련된 ResNet50 모델에 대한 추론을 실행하는 예를 사용할 것이다.

00:04:23.000 --> 00:04:27.000
기본적으로, 모델은 CPU에서 실행될 것이다.

00:04:27.000 --> 00:04:32.000
"To" 방법을 사용하여 MPS 장치를 사용하기 위해 모델을 변환할 수 있습니다.

00:04:32.000 --> 00:04:39.000
이것은 모델 내부의 중간 텐서가 가속화된 MPS 백엔드를 사용할 수 있도록 한다.

00:04:39.000 --> 00:04:42.000
마지막으로, 당신은 모델을 실행할 수 있습니다.

00:04:42.000 --> 00:04:47.000
이 예제는 무작위 입력 텐서를 MPS 모델로 전달한다.

00:04:47.000 --> 00:04:51.000
기본적으로, 모든 텐서는 CPU에 할당됩니다.

00:04:51.000 --> 00:04:58.000
MPS 백엔드를 사용하려면, 여기에 mpsDevice도 제공해야 합니다.

00:04:58.000 --> 00:05:03.000
이 텐서의 모든 후속 작업은 GPU에서 가속화될 것이다.

00:05:03.000 --> 00:05:09.000
마지막으로, 예측을 얻기 위해 샘플 입력을 MPS 모델에 전달하세요.

00:05:09.000 --> 00:05:15.000
이제 MPS 장치를 사용하는 방법을 알았으니, 작동하는 PyTorch의 예를 보여드리겠습니다.

00:05:15.000 --> 00:05:17.000
나는 항상 유명한 예술가가 되고 싶었어.

00:05:17.000 --> 00:05:25.000
그래서 저는 StyleTransfer 네트워크를 사용하여 작품을 만드는 데 도움을 주기 위해 기계 학습과 GPU를 사용하기로 결정했습니다.

00:05:25.000 --> 00:05:30.000
이 네트워크를 사용하면 이미지에 다른 예술적 스타일을 적용할 수 있습니다.

00:05:30.000 --> 00:05:37.000
이 경우, 목표는 별이 빛나는 밤의 반 고흐의 스타일을 이 고양이 사진에 적용하는 방법을 배우는 것이다.

00:05:37.000 --> 00:05:45.000
새로운 MPS 장치를 사용하면 GPU를 사용하여 PyTorch 네트워크를 훨씬 빠르게 훈련시킬 수 있습니다.

00:05:45.000 --> 00:05:53.000
이것을 증명하기 위해, 나는 M1 Max에서 동시에 CPU와 GPU 모두에서 이 네트워크를 훈련시키기 시작할 것이다.

00:05:53.000 --> 00:06:03.000
이 스타일을 배우려면 수천 번의 반복이 필요하지만, GPU는 훨씬 짧은 시간에 합리적인 모델로 수렴할 수 있다.

00:06:03.000 --> 00:06:10.000
StyleTransfer 외에도, 우리는 이 모든 PyTorch 벤치마크에서 놀라운 속도를 보았습니다.

00:06:10.000 --> 00:06:18.000
M1 Ultra에서, 우리는 평균 8.3배 더 빠른 속도로 최대 20배 더 빠른 속도를 보았다.

00:06:18.000 --> 00:06:27.000
PyTorch를 사용하면 기계 학습 모델을 쉽게 개발할 수 있으며, Apple GPU를 사용하여 많은 시간을 절약할 수 있습니다.

00:06:27.000 --> 00:06:33.000
다음으로, 나는 우리가 올해 TensorFlow에 대해 만든 모든 개선 사항을 살펴볼 것이다.

00:06:33.000 --> 00:06:43.000
텐서플로우 메탈 가속은 텐서플로우 버전 2.5부터 텐서플로우 메탈 플러그인을 통해 사용할 수 있습니다.

00:06:43.000 --> 00:06:47.000
그 이후로, 몇 가지 추가 기능과 개선 사항이 추가되었습니다.

00:06:47.000 --> 00:06:58.000
여기에는 더 큰 배치로 개선된 교육, 새로운 운영 및 사용자 지정 운영 지원, RNN 개선 및 분산 교육이 포함됩니다.

00:06:58.000 --> 00:07:10.000
TensorFlow Metal 플러그인 릴리스는 주요 TensorFlow 릴리스와 일치하므로 TensorFlow 패키지를 업데이트하여 최신 기능과 개선 사항을 확인하십시오.

00:07:10.000 --> 00:07:13.000
더 큰 배치 크기로 시작합시다.

00:07:13.000 --> 00:07:21.000
올해 TensorFlow Metal의 소프트웨어 개선을 통해 Apple 실리콘 아키텍처의 고유한 이점을 활용할 수 있습니다.

00:07:21.000 --> 00:07:28.000
이 그래프는 다양한 배치 크기로 ResNet50 모델을 훈련하는 속도를 보여줍니다.

00:07:28.000 --> 00:07:38.000
데이터는 각 그라디언트 업데이트가 실제 그라디언트와 더 밀접하게 대응하기 때문에 더 큰 배치 크기로 성능이 향상된다는 것을 보여준다.

00:07:38.000 --> 00:07:46.000
애플 실리콘의 통합 메모리 아키텍처를 사용하면 더 큰 네트워크나 더 큰 배치 크기를 실행할 수 있습니다.

00:07:46.000 --> 00:07:53.000
이제 클라우드 클러스터에서 분할하는 대신 단일 Mac Studio에서 워크로드를 실행할 수 있습니다. 정말 멋집니다!

00:07:53.000 --> 00:08:01.000
애플 실리콘 아키텍처는 또한 와트당 고성능을 가지고 있으며, 이는 네트워크가 그 어느 때보다 효율적으로 실행된다는 것을 의미합니다.

00:08:01.000 --> 00:08:06.000
다음으로 나는 새로운 운영과 맞춤 운영에 대해 이야기할 것이다.

00:08:06.000 --> 00:08:18.000
Tensorflow Metal 플러그인은 이제 argMin, all, pack, adaDelta 등을 포함한 다양한 새로운 작업을 위한 GPU 가속을 제공합니다.

00:08:18.000 --> 00:08:26.000
하지만 현재 TensorFlow API에서 지원되지 않는 작업에 대한 GPU 가속을 원한다면 어떨까요?

00:08:26.000 --> 00:08:30.000
이렇게 하려면, 사용자 지정 작업을 만들어야 합니다.

00:08:30.000 --> 00:08:36.000
다음은 두 번의 반복으로 실행되는 간단한 컨볼루션 네트워크의 예입니다.

00:08:36.000 --> 00:08:42.000
타임라인은 각각 위와 아래의 GPU와 CPU에서 수행된 작업을 나타낸다.

00:08:42.000 --> 00:08:50.000
네트워크는 컨벌루션과 맥스풀링과 소프트맥스 크로스 엔트로피 손실을 수행한다.

00:08:50.000 --> 00:09:00.000
이러한 모든 작업은 MPS 그래프를 통해 TensorFlow Metal 플러그인에서 GPU로 가속되지만 사용자 지정 손실 기능을 사용할 수 있습니다.

00:09:00.000 --> 00:09:13.000
이 사용자 지정 손실에 대한 MPS GPU 가속이 없다면, 그 작업은 동기화 오버헤드를 도입하고 GPU를 굶주리는 CPU 타임라인에서 수행되어야 할 것이다.

00:09:13.000 --> 00:09:18.000
GPU에서 이 사용자 지정 손실을 수행함으로써 훨씬 더 나은 성능을 얻을 수 있습니다.

00:09:18.000 --> 00:09:26.000
사용자 지정 작업을 구현하려면 TensorFlow Metal Stream 프로토콜을 이해해야 합니다.

00:09:26.000 --> 00:09:31.000
이것은 GPU 작업을 인코딩하는 데 사용하는 프로토콜입니다.

00:09:31.000 --> 00:09:37.000
메탈 스트림은 GPU 커널을 인코딩하는 데 사용하는 MTLCommandBuffer에 대한 참조를 보유하고 있습니다.

00:09:37.000 --> 00:09:45.000
또한 작업을 제출하는 여러 스레드가 있을 수 있으므로 인코딩하는 동안 CPU 측 동기화에 사용할 dispatch_queue를 노출합니다.

00:09:45.000 --> 00:09:51.000
Commit 또는 commitAndWait 방법을 사용하여 GPU에 작업을 제출하십시오.

00:09:51.000 --> 00:09:59.000
CommitAndWait은 현재 명령 버퍼가 완료될 때까지 기다리는 디버깅 도구이므로 직렬화된 제출을 관찰할 수 있습니다.

00:09:59.000 --> 00:10:04.000
이제 이러한 개념들이 사용자 지정 작업을 구현하는 데 어떻게 사용될 수 있는지 봅시다.

00:10:04.000 --> 00:10:07.000
사용자 지정 작업을 작성하는 데는 세 단계가 있습니다.

00:10:07.000 --> 00:10:09.000
먼저, 작업을 등록하세요.

00:10:09.000 --> 00:10:13.000
다음으로, MetalStream을 사용하여 작업을 실행하세요.

00:10:13.000 --> 00:10:19.000
그리고 마지막으로, 작업을 교육 스크립트로 가져와서 사용하기 시작하세요.

00:10:19.000 --> 00:10:22.000
나는 그 작업을 등록하는 것부터 시작할 것이다.

00:10:22.000 --> 00:10:32.000
TensorFlow 코어에 의해 노출된 REGISTER_OP 매크로를 사용하여 op의 의미와 TensorFlow Metal 플러그인에서 정의하는 방법을 지정하십시오.

00:10:32.000 --> 00:10:36.000
다음으로, TensorFlow_MetalStream을 사용하여 op를 구현하세요.

00:10:36.000 --> 00:10:40.000
"계산" 기능을 정의하는 것으로 시작하세요.

00:10:40.000 --> 00:10:50.000
이제, 이 함수 내에서, 입력에 대한 TensorFlow_Tensor 객체를 가져오고 할당이 필요할 수 있는 출력을 정의하십시오.

00:10:50.000 --> 00:10:55.000
그런 다음 메탈 스트림의 명령 버퍼를 사용하여 인코더를 만드세요.

00:10:55.000 --> 00:10:58.000
다음으로, 사용자 지정 GPU 커널을 정의하세요.

00:10:58.000 --> 00:11:02.000
당신의 작전은 메탈 스트림에서 제공하는 dispatch_queue 내에서 인코딩되어야 합니다.

00:11:02.000 --> 00:11:08.000
이것은 여러 스레드의 제출물이 직렬화되도록 한다.

00:11:08.000 --> 00:11:16.000
그런 다음 TensorFlow_MetalStream 프로토콜에 제공된 방법을 사용하여 커널을 커밋하십시오.

00:11:16.000 --> 00:11:21.000
마지막으로, 할당된 텐서에 대한 참조를 삭제하세요.

00:11:21.000 --> 00:11:27.000
마지막으로, 작업을 훈련 스크립트로 가져와서 사용을 시작하세요.

00:11:27.000 --> 00:11:35.000
이 단계에서, zero_out.so라는 사용자 지정 op의 공유 동적 라이브러리 파일을 구축하세요.

00:11:35.000 --> 00:11:41.000
.So 파일을 만들고 가져오는 방법에 대한 정보는 Metal Developer Resources를 참조하십시오.

00:11:41.000 --> 00:11:50.000
이 예제는 선택 단계인 TensorFlow load_op_library를 사용하여 작업을 훈련 스크립트로 가져옵니다.

00:11:50.000 --> 00:11:56.000
이제, 이것은 파이썬 래퍼처럼 작동하며 우리의 사용자 지정 op는 교육 스크립트에서 호출될 수 있습니다.

00:11:56.000 --> 00:12:04.000
다음으로, Neural Radiance Fields 또는 NeRF라는 흥미로운 응용 프로그램의 예를 보여드리고자 합니다.

00:12:04.000 --> 00:12:13.000
우리는 더 나은 알고리즘을 위해 GPU 가속을 활성화하여 네트워크의 성능을 높이는 사용자 지정 작업을 작성했습니다.

00:12:13.000 --> 00:12:18.000
NeRF는 모델의 3D 뷰를 합성하는 데 사용되는 네트워크이다.

00:12:18.000 --> 00:12:23.000
훈련을 위해, NeRF는 다른 각도에서 물체의 이미지를 입력으로 받아들인다.

00:12:23.000 --> 00:12:32.000
NeRF 네트워크는 두 개의 누적 다층 퍼셉트론으로 구성되어 있으며, 출력은 모델의 체적 표현이다.

00:12:32.000 --> 00:12:38.000
실시간 교육을 위한 주요 성능 최적화는 해시 테이블 구현을 사용합니다.

00:12:38.000 --> 00:12:43.000
이 업데이트된 네트워크는 훨씬 더 작은 다층 퍼셉트론을 허용한다.

00:12:43.000 --> 00:12:52.000
TensorFlow는 기본적으로 해시 테이블을 지원하지 않으므로 사용자 지정 op 기능을 사용하여 Metal 플러그인에 구현합니다.

00:12:52.000 --> 00:12:58.000
해시 테이블의 GPU 가속은 NeRF를 훨씬 더 빠르게 훈련시킬 수 있게 해준다.

00:12:58.000 --> 00:13:06.000
나는 이 맥북에서 시작하여 원래의 다층 퍼셉트론 구현을 실행할 것이다.

00:13:06.000 --> 00:13:13.000
합리적인 것을 만들기 위해, 우리는 적어도 20개의 시대가 필요하지만 각 시대는 약 100초가 걸린다.

00:13:13.000 --> 00:13:17.000
그것은 무엇이든 보이기까지 약 30분이 걸릴 것이라는 것을 의미한다.

00:13:17.000 --> 00:13:26.000
그래서 이제 나는 30분 전에 훈련하도록 남겨진 사전 훈련된 체크포인트 파일에서 훈련을 다시 시작할 것이다.

00:13:26.000 --> 00:13:28.000
이것은 20년 에포크에서 시작한다.

00:13:28.000 --> 00:13:33.000
3D 모델은 30분의 훈련 후에도 흐릿하고 불분명하다.

00:13:33.000 --> 00:13:38.000
네트워크가 더 명확한 모델을 배우기 위해서는 훨씬 더 긴 훈련 시간이 필요할 것이다.

00:13:38.000 --> 00:13:45.000
사용자 지정 해시 테이블이 없는 원래의 두 개의 누적 다층 퍼셉트론 접근 방식은 너무 느립니다.

00:13:45.000 --> 00:13:52.000
이제 이 맥북에서 사용자 지정 해시 테이블을 사용하는 최적화된 버전을 시작할 것입니다.

00:13:52.000 --> 00:14:00.000
이 구현은 이미 훨씬 더 명확한 모델을 렌더링할 수 있으며 각 시대는 배우는 데 10초밖에 걸리지 않는다.

00:14:00.000 --> 00:14:09.000
이 프로젝트에 대한 자세한 내용은 Metal Developer Resources에 업로드한 샘플 코드를 확인하세요.

00:14:09.000 --> 00:14:20.000
NeRF는 네트워크를 빠르게 실행하기 위해 사용자 지정 작업을 위해 GPU 가속을 구현하는 방법을 보여주는 많은 네트워크 중 하나일 뿐입니다.

00:14:20.000 --> 00:14:26.000
저는 당신이 만드는 모든 창의적인 커스터마이징에 대해 배우기를 기대합니다.

00:14:26.000 --> 00:14:33.000
이제 Apple GPU를 사용하여 ML 워크로드 교육을 배포하는 방법을 보여드리고 싶습니다.

00:14:33.000 --> 00:14:46.000
워크로드 교육을 배포하기 위해, 각 프로세스가 모델의 단일 반복을 평가하는 별도의 프로세스에서 교육 스크립트의 여러 인스턴스를 실행할 수 있습니다.

00:14:46.000 --> 00:14:50.000
각 프로세스는 중앙 데이터 저장소에서 데이터를 읽을 것이다.

00:14:50.000 --> 00:14:55.000
그 후, 그것은 모델을 실행하고 모델 그라디언트를 계산할 것이다.

00:14:55.000 --> 00:15:06.000
다음으로, 프로세스는 그라디언트를 평균하고 이를 서로 전달하므로 각 프로세스는 다음 반복 전에 동일한 그라디언트를 갖습니다.

00:15:06.000 --> 00:15:13.000
마지막으로, 모델이 업데이트되고 모든 반복이 소진될 때까지 이 과정을 반복할 수 있습니다.

00:15:13.000 --> 00:15:23.000
이것을 TensorFlow에서 시연하기 위해, 나는 Horovod라는 인기 있는 오픈 소스 프레임워크를 사용하는 분산 교육의 예를 사용할 것이다.

00:15:23.000 --> 00:15:27.000
호로보드는 링 올 리듀스 접근 방식을 사용한다.

00:15:27.000 --> 00:15:34.000
이 알고리즘에서, 각 N 노드는 두 개의 피어와 여러 번 통신한다.

00:15:34.000 --> 00:15:40.000
이 통신을 사용하여, 작업자는 각 반복 전에 그라디언트를 동기화한다.

00:15:40.000 --> 00:15:47.000
나는 썬더볼트 케이블로 서로 연결된 네 개의 맥 스튜디오를 사용하여 이것을 실제로 보여줄 것이다.

00:15:47.000 --> 00:15:53.000
이 예를 들어, 나는 이미지 분류기인 ResNet을 훈련시킬 것이다.

00:15:53.000 --> 00:15:59.000
각 Mac Studio 측면의 막대는 이 네트워크를 훈련하는 동안 GPU 활용도를 보여줍니다.

00:15:59.000 --> 00:16:04.000
단일 Mac Studio의 경우, 성능은 초당 약 200개의 이미지입니다.

00:16:04.000 --> 00:16:16.000
썬더볼트를 통해 연결된 다른 Mac Studio를 추가하면, 두 GPU가 최대한 활용되기 때문에 성능은 초당 400개의 이미지로 거의 두 배가 됩니다.

00:16:16.000 --> 00:16:24.000
마지막으로, 두 개의 Mac 스튜디오를 더 연결하면, 성능은 초당 800개의 이미지로 향상됩니다.

00:16:24.000 --> 00:16:30.000
이것은 컴퓨팅 바운드 트레이닝 워크로드에 대한 거의 선형 스케일링입니다.

00:16:30.000 --> 00:16:35.000
이제 TensorFlow의 분산 교육 성능을 살펴보겠습니다.

00:16:35.000 --> 00:16:41.000
이 차트는 하나, 둘, 네 개의 맥 스튜디오의 상대적인 속도를 보여준다.

00:16:41.000 --> 00:16:52.000
그들은 링 토폴로지에 연결되어 있으며 최신 TensorFlow Metal 플러그인과 Horovod와 함께 resNet 및 DistilBERT와 같은 컴퓨팅 바운드 TensorFlow 네트워크를 실행합니다.

00:16:52.000 --> 00:16:57.000
기본은 단일 Mac Studio에서의 성능이다.

00:16:57.000 --> 00:17:12.000
그래프는 각 GPU를 추가하여 네트워크 성능이 확장되므로 이제 여러 장치에서 GPU를 활용하여 교육 시간을 단축하고 모든 Apple 장치를 최대한 활용할 수 있음을 보여줍니다.

00:17:12.000 --> 00:17:24.000
올해 TensorFlow에 대해 잠금 해제된 모든 개선 사항과 기능은 향후 더 많은 개선 사항과 함께 CPU 구현에 대한 상대적인 성능을 보여주는 이 차트로 절정에 달합니다.

00:17:24.000 --> 00:17:30.000
이제 Matteo는 MPSGraph 프레임워크의 새로운 기능을 공유할 것이다.

00:17:30.000 --> 00:17:31.000
마테오: 고마워, 드루바.

00:17:31.000 --> 00:17:35.000
안녕하세요, 제 이름은 마테오이고, GPU 소프트웨어 엔지니어입니다.

00:17:35.000 --> 00:17:41.000
PyTorch와 TensorFlow는 MPSGraph 프레임워크 위에 있다.

00:17:41.000 --> 00:17:50.000
차례로, MPSGraph는 MPS 프레임워크에 의해 노출된 병렬 프리미티브를 사용하여 GPU 작업을 가속화합니다.

00:17:50.000 --> 00:17:59.000
오늘 저는 MPSGraph로 컴퓨팅 워크로드를 더욱 가속화하는 데 사용할 수 있는 두 가지 기능에 대해 이야기할 것입니다.

00:17:59.000 --> 00:18:05.000
먼저, 두 그래프 간의 작업을 동기화할 수 있는 새로운 공유 이벤트 API를 보여드리겠습니다.

00:18:05.000 --> 00:18:13.000
둘째, MPSGraph로 더 많은 것을 할 수 있는 새로운 작업을 검토하겠습니다.

00:18:13.000 --> 00:18:16.000
공유 이벤트 API로 시작하겠습니다.

00:18:16.000 --> 00:18:22.000
동일한 명령 대기열에서 애플리케이션을 실행하면 워크로드 간의 동기화를 보장합니다.

00:18:22.000 --> 00:18:33.000
이 예에서, 컴퓨팅 워크로드는 사후 처리 및 디스플레이와 같은 다른 워크로드가 파견되기 전에 항상 종료되도록 보장됩니다.

00:18:33.000 --> 00:18:39.000
이와 같은 경우, 각 단일 디스패치 내에서 GPU 병렬성을 활용할 수 있습니다.

00:18:39.000 --> 00:18:52.000
그러나, 일부 응용 프로그램은 GPU의 첫 번째 부분이 컴퓨팅에 사용되고 두 번째 부분이 후처리 및 디스플레이에 사용되는 더 많은 병렬 처리의 이점을 누릴 수 있다.

00:18:52.000 --> 00:18:58.000
이것은 여러 명령 대기열에서 GPU에 작업을 제출함으로써 달성될 수 있다.

00:18:58.000 --> 00:19:09.000
안타깝게도, 이 경우, 컴퓨팅이 결과를 산출하기 전에 사후 처리 파이프라인이 파견되어 데이터 경쟁을 도입할 수 있습니다.

00:19:09.000 --> 00:19:21.000
공유 이벤트 API를 사용하여 이 문제를 해결하고 명령 대기열 간에 동기화를 도입하여 워크플로우 종속성을 만족시킬 수 있습니다.

00:19:21.000 --> 00:19:25.000
코드 내에서 공유 이벤트를 사용하는 것은 매우 간단합니다.

00:19:25.000 --> 00:19:29.000
당신이 두 개의 그래프로 작업하고 있다고 가정해 봅시다.

00:19:29.000 --> 00:19:32.000
첫 번째는 컴퓨팅 워크로드를 담당한다.

00:19:32.000 --> 00:19:37.000
두 번째는 사후 처리 작업량을 책임진다.

00:19:37.000 --> 00:19:47.000
또한 계산 그래프의 결과가 후처리 그래프의 입력으로 사용되며, 다른 명령 대기열에서 실행된다고 가정해 봅시다.

00:19:47.000 --> 00:19:55.000
Metal System Trace의 새로운 MPSGraph 트랙은 명령 대기열이 서로 겹친다는 것을 나타냅니다.

00:19:55.000 --> 00:19:58.000
이것은 데이터 경쟁을 일으킨다.

00:19:58.000 --> 00:20:01.000
공유 이벤트를 사용하여 이 문제를 해결할 수 있습니다.

00:20:01.000 --> 00:20:05.000
먼저, 금속 장치를 사용하여 이벤트를 만드세요.

00:20:05.000 --> 00:20:14.000
다음으로, 실행 설명자에서 신호 메서드를 호출하여 이벤트, 작업 및 값을 제공합니다.

00:20:14.000 --> 00:20:24.000
그런 다음 이벤트 변수와 값을 제공하는 두 번째 설명자에서 wait 메소드를 호출하기만 하면 됩니다.

00:20:24.000 --> 00:20:37.000
이제, 메탈 시스템 추적은 두 개의 명령 대기열이 순차적으로 실행되고, 계산과 후처리 그래프 사이의 종속성이 해결되었음을 나타냅니다.

00:20:37.000 --> 00:20:43.000
그것이 공유 이벤트를 사용하여 애플리케이션의 동기화 문제를 해결할 수 있는 방법입니다.

00:20:43.000 --> 00:20:48.000
둘째, MPSGraph가 지원하는 새로운 운영에 대해 이야기하겠습니다.

00:20:48.000 --> 00:20:52.000
이러한 작업을 통해 프레임워크로 더 많은 일을 할 수 있습니다.

00:20:52.000 --> 00:20:59.000
나는 RNN을 시작으로 이 새로운 작전들 각각에 대한 몇 가지 세부 사항을 살펴볼 것이다.

00:20:59.000 --> 00:21:07.000
MPSGraph는 이제 반복 신경망 애플리케이션 내에서 일반적으로 사용되는 세 가지 작업을 노출한다.

00:21:07.000 --> 00:21:12.000
이것들은 RNN, LSTM 및 GRU 층이다.

00:21:12.000 --> 00:21:19.000
이 작업들은 모두 비슷하게 작동하기 때문에, 나는 오늘 LSTM에 집중할 것이다.

00:21:19.000 --> 00:21:25.000
LSTM 작업은 일반적으로 자연어 처리 및 기타 응용 프로그램에 사용됩니다.

00:21:25.000 --> 00:21:29.000
이 다이어그램은 LSTM 작업이 어떻게 작동하는지 보여줍니다.

00:21:29.000 --> 00:21:35.000
그것에 대해 더 알아보려면, 이전 WWDC 세션을 확인하세요.

00:21:35.000 --> 00:21:43.000
LSTM 장치를 직접 구현할 수 있지만, 그렇게 하려면 다소 복잡한 사용자 지정 하위 그래프를 만들어야 합니다.

00:21:43.000 --> 00:21:53.000
대신, 반복 장치에 필요한 모든 GPU 작업을 효율적으로 인코딩하는 새로운 LSTM 작업을 사용할 수 있습니다.

00:21:53.000 --> 00:22:01.000
이 새로운 작업은 LSTM 기반 CoreML 추론 모델을 훨씬 빠르게 만든다.

00:22:01.000 --> 00:22:08.000
새로운 LSTM 작업을 사용하려면, 먼저 MPSGraphLSTMDescriptor를 만드세요.

00:22:08.000 --> 00:22:15.000
예를 들어 활성화 기능을 선택하는 등 필요에 따라 설명자 속성을 수정할 수 있습니다.

00:22:15.000 --> 00:22:21.000
다음으로, LSTM 단위를 그래프에 추가하여 입력 텐서를 제공합니다.

00:22:21.000 --> 00:22:27.000
당신은 또한 작업을 위한 초기 상태와 셀뿐만 아니라 바이어스 벡터를 제공할 수 있습니다.

00:22:27.000 --> 00:22:30.000
마지막으로, 설명자를 제공하세요.

00:22:30.000 --> 00:22:34.000
그것이 당신이 LSTM을 설정하기 위해 해야 할 전부입니다.

00:22:34.000 --> 00:22:38.000
다른 RNN 운영도 비슷하게 작동한다.

00:22:38.000 --> 00:22:44.000
이러한 작업을 시도하고 응용 프로그램에서 어떤 종류의 속도를 얻을 수 있는지 보는 것이 좋습니다.

00:22:44.000 --> 00:22:48.000
다음으로, 맥스 풀링에 대한 개선된 지원을 보여드리겠습니다.

00:22:48.000 --> 00:23:00.000
최대 풀링 작업은 입력 텐서와 창 크기를 취하고 창의 각 응용 프로그램에 대해 창 내의 입력의 최대 값을 계산합니다.

00:23:00.000 --> 00:23:05.000
그것은 일반적으로 이미지의 차원을 줄이기 위해 컴퓨터 비전에서 사용된다.

00:23:05.000 --> 00:23:13.000
API는 풀링 운영자가 추출한 최대 값 위치의 인덱스를 반환하도록 확장되었습니다.

00:23:13.000 --> 00:23:23.000
그라디언트 패스에서 인덱스를 사용할 수 있으며, 여기서 그라디언트는 최대 값이 추출된 위치를 통해 전파되어야 합니다.

00:23:23.000 --> 00:23:26.000
새로운 API는 훈련을 위해서도 작동한다.

00:23:26.000 --> 00:23:34.000
PyTorch와 TensorFlow는 훈련 중에 인덱스를 재사용하는 것이 최대 6배 더 빠를 수 있습니다.

00:23:34.000 --> 00:23:40.000
이것을 코드로 설정하려면, 먼저 GraphPooling 설명자를 만드세요.

00:23:40.000 --> 00:23:46.000
returnIndicesMode, 예를 들어 globalFlatten4D를 지정할 수 있습니다.

00:23:46.000 --> 00:23:53.000
그런 다음 Return Indices API를 사용하여 그래프에서 풀링 작업을 호출할 수 있습니다.

00:23:53.000 --> 00:23:56.000
그 수술의 결과는 두 가지이다.

00:23:56.000 --> 00:24:01.000
첫째, 풀링텐서, 그리고 둘째, 인덱스텐서.

00:24:01.000 --> 00:24:09.000
예를 들어, 훈련 파이프라인에서 나중에 사용하기 위해 인덱스텐서를 캐시할 수 있습니다.

00:24:09.000 --> 00:24:19.000
MPS 그래프는 이제 훈련 그래프의 가중치를 초기화하는 데 사용할 수 있는 새로운 병렬 난수 생성기를 노출한다.

00:24:19.000 --> 00:24:28.000
새로운 무작위 연산은 Philox 알고리즘을 사용하고 주어진 시드에 대해 TensorFlow와 동일한 결과를 반환합니다.

00:24:28.000 --> 00:24:41.000
새로운 작업은 입력으로 상태 텐서를 취합니다. 예를 들어 두 번째 무작위 작업의 입력으로 사용할 수 있는 무작위 텐서와 새로운 상태 텐서를 출력으로 반환합니다.

00:24:41.000 --> 00:24:46.000
새로운 랜덤 연산을 사용하려면, randomPhiloxStateTensor 메소드를 호출하세요.

00:24:46.000 --> 00:24:52.000
이 방법은 주어진 시드로 입력 stateTensor를 초기화합니다.

00:24:52.000 --> 00:24:59.000
그런 다음 분포와 데이터 유형을 입력으로 사용하는 RandomOp 설명자를 선언하십시오.

00:24:59.000 --> 00:25:07.000
이 예에서, 설명자는 32비트 부동 소수점 값의 잘린 정규 분포를 지정합니다.

00:25:07.000 --> 00:25:12.000
일반 및 균일 분포를 사용할 수도 있습니다.

00:25:12.000 --> 00:25:21.000
평균, 표준 편차, 최소 및 최대 값을 지정하여 분포 특성을 더 정의할 수 있습니다.

00:25:21.000 --> 00:25:32.000
마지막으로, 방금 만든 shapeTensor, 설명자 및 stateTensor를 제공하는 임의의 작업을 만들 수 있습니다.

00:25:32.000 --> 00:25:42.000
랜덤 외에도, MPSGraph는 이제 두 비트 벡터 사이의 해밍 거리를 계산하기 위해 새로운 GPU 가속 작업을 지원합니다.

00:25:42.000 --> 00:25:58.000
같은 길이의 두 입력 간에 다른 비트 수로 정의되는 해밍 거리는 두 시퀀스 사이의 편집 거리의 척도이며, 생물 정보학에서 암호화에 이르기까지 여러 응용 프로그램에서 사용됩니다.

00:25:58.000 --> 00:26:06.000
HammingDistance를 사용하려면, 그래프에서 API를 호출하여 primaryTensor, secondaryTensor 및 resultDataType을 제공합니다.

00:26:06.000 --> 00:26:13.000
새로운 커널은 GPU의 배치 차원을 통한 방송을 지원합니다.

00:26:13.000 --> 00:26:20.000
이제, 사용하기 매우 쉬운 새로운 텐서 조작 작업에 대한 모든 것을 보여드리겠습니다.

00:26:20.000 --> 00:26:26.000
예를 들어, 이제 텐서의 차원을 2차원에서 3차원으로 확장할 수 있습니다.

00:26:26.000 --> 00:26:30.000
그리고 당신은 치수를 다시 짜낼 수 있습니다.

00:26:30.000 --> 00:26:36.000
또한 여러 조각과 축을 제공하는 텐서를 고르게 나눌 수 있습니다.

00:26:36.000 --> 00:26:40.000
또는 주어진 축을 따라 텐서를 쌓으세요.

00:26:40.000 --> 00:26:46.000
주어진 입력 형상의 텐서 치수를 따라 좌표 값을 생성할 수도 있습니다.

00:26:46.000 --> 00:26:54.000
예를 들어, 0축을 따라 좌표로 모양 2 x 4의 텐서를 채울 수 있습니다.

00:26:54.000 --> 00:26:59.000
이것은 또한 range1D 작업을 구현하는 데 사용될 수 있다.

00:26:59.000 --> 00:27:07.000
예를 들어, 4의 증가로 3에서 27 사이의 숫자 범위를 생성하고 싶다고 가정해 봅시다.

00:27:07.000 --> 00:27:15.000
먼저 모양 6의 텐서의 차원 0을 따라 좌표를 만들어 그렇게 할 수 있습니다.

00:27:15.000 --> 00:27:21.000
그런 다음, 당신이 해야 할 일은 증분으로 곱하고 오프셋을 추가하는 것입니다.

00:27:21.000 --> 00:27:25.000
그것들은 모두 올해 추가된 새로운 작업이다.

00:27:25.000 --> 00:27:34.000
이러한 모든 새로운 운영을 통해 MPSGraph를 사용하여 Apple 생태계에서 더 많은 일을 하고 더 높은 성능을 얻을 수 있습니다.

00:27:34.000 --> 00:27:41.000
이제 MPSGraph에서 Apple Silicon에서 얻을 수 있는 성능 개선을 보여드리겠습니다.

00:27:41.000 --> 00:27:50.000
블랙매직은 MPS 그래프를 사용하여 기계 학습 워크로드를 가속화하는 다빈치 리졸브 버전 18을 출시했습니다.

00:27:50.000 --> 00:28:00.000
매직 마스크는 기계 학습을 사용하여 화면에서 움직이는 물체를 식별하고 그 위에 필터를 선택적으로 적용하는 Resolve의 기능입니다.

00:28:00.000 --> 00:28:08.000
먼저 이전 버전의 Resolve에서 이것이 어떻게 작동하는지 시연한 다음, 현재 버전과 비교할 것입니다.

00:28:08.000 --> 00:28:13.000
마스크를 만들려면, 대상 개체를 선택하기만 하면 됩니다.

00:28:13.000 --> 00:28:16.000
오버레이를 전환하여 마스크를 볼 수 있습니다.

00:28:16.000 --> 00:28:22.000
마스크는 피사체의 모양을 정확하게 표시하는 빨간색 영역으로 식별됩니다.

00:28:22.000 --> 00:28:28.000
이제, 내가 비디오를 재생하면, 마스크는 화면에서 움직일 때 물체를 추적할 것이다.

00:28:28.000 --> 00:28:35.000
이것은 멋져 보이지만, 기계 학습 파이프라인이 후드 아래에서 실행되기 때문에 꽤 낮은 프레임 속도로 실행되고 있다.

00:28:35.000 --> 00:28:44.000
이제 MPSGraph를 사용하여 매직 마스크 네트워크를 가속화하는 최신 버전의 Resolve로 전환하겠습니다.

00:28:44.000 --> 00:28:49.000
같은 타임라인을 다시 실행하면, 프레임 속도가 이전보다 훨씬 빠릅니다.

00:28:49.000 --> 00:28:55.000
이것은 애플 실리콘에서 훨씬 더 나은 편집 경험을 가져온다.

00:28:55.000 --> 00:29:00.000
이것들은 MPS 그래프를 채택함으로써 얻을 수 있는 종류의 속도 향상이다.

00:29:00.000 --> 00:29:04.000
앱에 어떤 종류의 성능을 가져올 수 있는지 살펴보는 것이 좋습니다.

00:29:04.000 --> 00:29:13.000
마무리하기 위해, 이제 PyTorch를 위한 GPU 가속을 활용할 수 있으며, 이 프로젝트는 이제 오픈 소스입니다.

00:29:13.000 --> 00:29:23.000
예를 들어, 사용자 지정 작업 및 분산 교육을 사용하여 TensorFlow Metal 플러그인을 사용하여 교육 워크로드를 가속화하는 새로운 방법을 찾을 수 있습니다.

00:29:23.000 --> 00:29:34.000
마지막으로, 공유 이벤트와 새로운 작업을 사용하여 Apple 실리콘을 최대한 활용하기 위해 MPSGraph 프레임워크로 가장 까다로운 기계 학습 작업을 최적화할 수 있습니다.

00:29:34.000 --> 00:29:39.000
Dhruva와 나는 당신이 당신의 애플리케이션에서 이러한 새로운 기능을 어떻게 사용할지 빨리 보고 싶습니다.

00:29:39.000 --> 23:59:59.000
세션을 시청해 주셔서 감사드리며, 멋진 WWDC를 보내십시오.

