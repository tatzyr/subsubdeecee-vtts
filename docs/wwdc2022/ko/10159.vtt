WEBVTT

00:00:00.000 --> 00:00:11.000
- 안녕 그리고 환영해.

00:00:11.000 --> 00:00:17.000
제 이름은 마르코 지오다노이고, 저는 여기 애플의 GPU 소프트웨어 엔지니어링 팀과 함께 있습니다.

00:00:17.000 --> 00:00:23.000
이 세션에서는 Apple M1 GPU에서 워크로드를 확장하는 방법에 대해 이야기하겠습니다.

00:00:23.000 --> 00:00:33.000
복잡한 컴퓨팅 워크로드에서 작업하고 Apple 실리콘 하드웨어를 최대한 활용하고 훌륭한 스케일링을 달성하는 방법을 알고 싶다면, 이 이야기는 당신을 위한 것입니다.

00:00:33.000 --> 00:00:42.000
컴퓨팅 확장성 개념과 애플리케이션이 M1 GPU 제품군에서 어떻게 자연스럽게 성능을 확장할 수 있는지에 대해 논의하는 것으로 시작하겠습니다.

00:00:42.000 --> 00:00:52.000
그리고 나서, 저는 단계별 "방법"을 공유하고 워크로드에 대한 컴퓨팅 스케일링을 극대화하기 위해 사용할 수 있는 도구에 대해 이야기할 것입니다.

00:00:52.000 --> 00:00:59.000
확장성이 무엇이고 왜 그것이 당신의 작업량에 중요한지 이해하는 것부터 시작합시다.

00:00:59.000 --> 00:01:08.000
Apple M1 GPU는 처음부터 확장하여 전체 SOC 제품군에서 워크로드가 우수한 성능을 달성할 수 있도록 설계되었습니다.

00:01:08.000 --> 00:01:17.000
모든 Metal 3 기능을 지원하는 동일한 GPU는 8코어 iPad에서 64코어 Mac Studio까지 확장됩니다.

00:01:17.000 --> 00:01:24.000
높은 수준의 스케일링을 활용하기 위해, M1에 최적화된 앱을 갖는 것은 훌륭한 출발점이다.

00:01:24.000 --> 00:01:34.000
많은 저명한 프로 앱은 이미 Apple M1에 최적화되어 있으며 모든 장치에서 우수한 스케일링을 경험하고 있습니다.

00:01:34.000 --> 00:01:44.000
예를 들어, 여기에 포스트 프로덕션 업계의 사진 및 비디오 편집자인 Affinity Photo와 DaVinci Resolve가 있습니다.

00:01:44.000 --> 00:01:47.000
이 앱들은 훌륭한 스케일링을 달성하고 있다.

00:01:47.000 --> 00:01:53.000
확장성이 실제로 무엇을 의미하는지, 그리고 어떻게 "이상적인" 확장을 달성할 수 있는지 정의해 봅시다.

00:01:53.000 --> 00:02:01.000
GPU 워크로드 확장성은 GPU 코어의 수가 증가하여 성능을 향상시킬 수 있는 능력이다.

00:02:01.000 --> 00:02:07.000
오른쪽 차트는 GPU 코어 수가 증가함에 따라 애플리케이션 속도를 보여줍니다.

00:02:07.000 --> 00:02:12.000
선형 비율 개선은 이상적인 것으로 여겨진다.

00:02:12.000 --> 00:02:25.000
그러나, 앱에서 작업하는 동안, 고원에 도달하고 수익이 감소하면서 확장되거나 GPU 타임라인의 격차로 인해 전혀 확장되지 않는 스케일링 유형을 알 수 있습니다.

00:02:25.000 --> 00:02:44.000
또는 성능이 향상되지만 워크로드가 여기와 같이 24 ~ 32 또는 48 ~ 64 코어 사이의 일부 GPU 리미터에 도달하는 스택에서 균일하지 않은 다른 유형의 스케일링을 볼 수 있습니다.

00:02:44.000 --> 00:02:56.000
당신의 목표는 가능한 한 선형 스케일링에 가까워지는 것이며, 병목 현상을 식별하고 원하는 결과를 얻을 수 있는 도구와 기술을 보여드리겠습니다.

00:02:56.000 --> 00:03:01.000
다음 섹션에서는 GPU 스케일링을 극대화하기 위한 접근 방식에 대해 논의할 것이다.

00:03:01.000 --> 00:03:06.000
모든 작업량에 대해, 당신은 먼저 병목 현상이 어디에 있는지 확인해야 합니다.

00:03:06.000 --> 00:03:11.000
워크로드는 계산이나 대역폭에 의해 제한될 수 있다.

00:03:11.000 --> 00:03:16.000
최적화 과정에서, 당신은 결국 하나와 다른 것 사이에서 튕겨질 수 있습니다.

00:03:16.000 --> 00:03:26.000
계산에 묶여 있다면, 계산을 줄이기 위해 메모리를 활용하기 위해 부하의 일부를 이동하려고 할 수도 있고, 그 반대의 경우도 마찬가지입니다.

00:03:26.000 --> 00:03:29.000
확장하면 병목 현상이 바뀔 수 있습니다.

00:03:29.000 --> 00:03:35.000
한 가지 좋은 해결책은 MPS나 MPSGraph와 같은 애플 프레임워크를 사용하는 것이다.

00:03:35.000 --> 00:03:41.000
만약 당신이 그들의 프리미티브를 활용할 수 있다면, 우리는 모든 컴퓨팅 커널이 모든 하드웨어에서 가장 잘 실행되도록 했습니다.

00:03:41.000 --> 00:03:50.000
그러나, 모든 것을 MPS로 대체할 수는 없으므로, 작업량을 프로파일링하고 이해하는 것이 중요합니다.

00:03:50.000 --> 00:04:02.000
먼저 GPU 격차를 최소화하는 데 도움이 될 수 있는 세 가지 항목을 다룰 것입니다: 작업 분배 개선, GPU 타임라인 격차 제거, 원자 운영 고려 사항.

00:04:02.000 --> 00:04:18.000
그런 다음 먼저 워크로드의 컴퓨팅 그리드 모양과 메모리 레이아웃의 효과를 조사하고 마지막으로 블렌더 사이클의 특정 예를 보고 GPU 리미터를 최적화하는 방법을 설명하겠습니다.

00:04:18.000 --> 00:04:22.000
GPU 격차를 최소화하는 데 집중하는 것으로 시작하세요.

00:04:22.000 --> 00:04:32.000
이러한 종류의 스케일링은 하드웨어가 유휴 상태인 GPU 타임라인의 간격과 함께 GPU가 완전히 활용되지 않은 결과일 수 있다.

00:04:32.000 --> 00:04:37.000
작업 분배를 조사하여 확장을 개선할 수 있는지 봅시다.

00:04:37.000 --> 00:04:47.000
작은 워크로드는 일반적으로 전체 GPU를 포화시키지 않으며, 커널 동기화에는 비용이 들기 때문에 둘 다 적절한 스케일링을 방지할 수 있다.

00:04:47.000 --> 00:04:55.000
워크로드가 하드웨어에 어떻게 매핑되는지 이해하는 것은 매우 중요하므로, 그것에 대해 이야기해 봅시다.

00:04:55.000 --> 00:05:00.000
워크로드는 스레드 그룹의 3D 그리드 형태로 파견된다.

00:05:00.000 --> 00:05:12.000
스레드 그룹은 GPU 코어에 균일하게 분산되어 있으며 크기가 제한되어 있지만 GPU 코어에 매우 빠른 스레드 그룹 메모리에 액세스할 수 있습니다.

00:05:12.000 --> 00:05:21.000
단일 스레드 그룹은 다른 컴퓨팅 방언에서 파도 또는 왜곡으로도 알려진 SIMD 그룹으로 더 세분화된다.

00:05:21.000 --> 00:05:33.000
컴퓨팅 파이프라인 상태 객체에서 "threadExecutionWidth"를 선택하면 SIMD 너비가 반환되며, 모든 Apple GPU에서는 32와 같습니다.

00:05:33.000 --> 00:05:42.000
스레드 그룹은 스레드 그룹당 최대 1024개의 스레드를 가질 수 있으며 스레드는 최대 32K의 스레드 그룹 메모리를 공유할 수 있습니다.

00:05:42.000 --> 00:05:48.000
GPU를 바쁘게 유지하려면, 모든 GPU 코어에서 할 수 있는 충분한 작업이 있어야 한다.

00:05:48.000 --> 00:05:51.000
여기 파견할 그리드의 예가 있습니다.

00:05:51.000 --> 00:05:59.000
스레드 그룹은 GPU 클러스터로 파견되고 GPU 코어에 분산된다.

00:05:59.000 --> 00:06:04.000
스레드 그룹이 너무 적으면, 작업량이 기계를 완전히 포화시키지 않을 것이다.

00:06:04.000 --> 00:06:08.000
이것을 고치는 방법은 다음과 같습니다.

00:06:08.000 --> 00:06:16.000
워크로드가 얼마나 많은 스레드를 생성하는지 계산하는 것으로 시작하고 디스패치가 전체 기계를 포화시킬지 대략적으로 확인하세요.

00:06:16.000 --> 00:06:30.000
상대적으로 복잡한 커널의 경우, 셰이더 코어당 1K에서 2K의 동시 스레드는 매우 좋은 점유율로 간주되므로, 경험의 규칙으로 GPU 코어당 1에서 2K 스레드를 취하십시오.

00:06:30.000 --> 00:06:35.000
이제 하드웨어를 완전히 포화시키기에 충분한 작업이 있는지 계산할 수 있습니다.

00:06:35.000 --> 00:06:43.000
여기 표는 다른 SOC를 포화시키기 위한 가장 낮은 권장 스레드 수를 보여줍니다.

00:06:43.000 --> 00:06:48.000
고려해야 할 또 다른 것은 불필요하게 큰 스레드 그룹 크기를 사용하는 것을 피하는 것이다.

00:06:48.000 --> 00:06:54.000
스레드 그룹을 더 작게 만들면 하드웨어에 부하를 더 균일하게 매핑할 것이다.

00:06:54.000 --> 00:07:02.000
더 큰 스레드 그룹을 사용하면 더 균일한 분포를 방지하여 GPU 코어의 불균형을 초래할 수 있습니다.

00:07:02.000 --> 00:07:08.000
작업량에 잘 매핑되는 SIMD 너비의 가장 작은 배수를 사용하는 것이 가장 좋습니다.

00:07:08.000 --> 00:07:16.000
더 작은 스레드 그룹을 사용함으로써, GPU는 워크로드의 균형을 더 잘 맞출 수 있는 더 많은 기회를 갖게 된다.

00:07:16.000 --> 00:07:23.000
항상 Xcode 또는 Instruments GPU Tools로 커널 런타임 성능을 확인하십시오.

00:07:23.000 --> 00:07:28.000
예를 들어, 이 GPU 캡처에는 일부 계산을 수행하는 커널이 있다.

00:07:28.000 --> 00:07:32.000
점유율은 꽤 낮고, 이는 예상치 못한 일이다.

00:07:32.000 --> 00:07:40.000
컴파일러 통계는 Xcode 14의 새로운 최대 이론적 점유율이 100%라는 것을 보여준다.

00:07:40.000 --> 00:07:51.000
이것은 스레드가 충분하지 않을 수 있음을 나타냅니다. 실제로, 우리는 알고리즘이 더 이상 기계를 포화시키지 않고 점점 더 적은 스레드를 발송하기 시작하는 것을 볼 수 있습니다.

00:07:51.000 --> 00:07:55.000
낮은 점유율에는 몇 가지 다른 원인이 있을 수 있다.

00:07:55.000 --> 00:08:01.000
모든 세부 사항을 얻으려면, MacBook Pro Tech 토크에서 Metal Compute를 확인하세요.

00:08:01.000 --> 00:08:09.000
좋아요, 이제 워크로드가 올바르게 분산되었으니, GPU가 항상 바쁜지 확인할 때입니다.

00:08:09.000 --> 00:08:18.000
GPU를 활용하지 않는 것은 결코 이상적인 스케일링으로 이어지지 않으며, 활용하지 않는 최악의 경우는 유휴 상태를 유지하는 것이다.

00:08:18.000 --> 00:08:23.000
GPU는 GPU 타임라인 격차 때문에 유휴 상태일 수 있다.

00:08:23.000 --> 00:08:26.000
이 예시를 생각해 보세요.

00:08:26.000 --> 00:08:34.000
다음은 CPU와 GPU 간의 작업 직렬화로 인해 GPU의 50%만 사용하는 워크로드입니다.

00:08:34.000 --> 00:08:42.000
이 경우, 전체 작업 기간은 중복 없이 CPU와 GPU 작업의 합이다.

00:08:42.000 --> 00:08:49.000
GPU 코어를 두 배로 늘리면 GPU 트랙이 더 빨리 완성되지만, CPU 트랙은 영향을 받지 않습니다.

00:08:49.000 --> 00:08:57.000
전반적인 성능은 이상적인 스케일링과는 거리가 먼 33%만 증가한다.

00:08:57.000 --> 00:09:08.000
GPU 코어가 다시 두 배가 되면, GPU의 워크로드는 훨씬 더 빠르지만, 전체 대기 시간은 원래 시간에 비해 60%만 줄어듭니다!

00:09:08.000 --> 00:09:13.000
따라서 GPU 코어 스케일링은 그러한 경우 수익 감소를 가져온다.

00:09:13.000 --> 00:09:17.000
이것은 이상과는 거리가 멀다. 고치자!

00:09:17.000 --> 00:09:28.000
M1 프로의 이 기기 추적은 큰 GPU 타임라인 격차를 보여주며, 이는 적절한 스케일링을 분명히 방지할 것이다.

00:09:28.000 --> 00:09:38.000
M1 Ultra에서는 동일한 워크로드가 실제로 조금 더 빠르지만, GPU 유휴 시간이 더 높아졌고 워크로드가 잘 확장되지 않습니다.

00:09:38.000 --> 00:09:45.000
큰 격차는 명령 버퍼에서 waitUntilCompleted를 사용하는 CPU 동기화로 인해 발생합니다.

00:09:45.000 --> 00:09:54.000
대기 논리를 변경하고 직렬화를 제거한 후, GPU는 완전히 활용되었고, 이는 훌륭하다.

00:09:54.000 --> 00:10:03.000
전후의 작업량 스케일링을 비교하면, 우리는 스케일링이 이상적인 스케일링에 훨씬 더 가까워졌다고 말할 수 있다.

00:10:03.000 --> 00:10:15.000
이전 예에서는 CPU/GPU 동기화를 완전히 제거할 수 있었지만, 애플리케이션 특성으로 인해 항상 그런 것은 아닙니다.

00:10:15.000 --> 00:10:20.000
유휴 시간을 줄이기 위해 취할 수 있는 다른 접근 방식이 있습니다.

00:10:20.000 --> 00:10:30.000
MTLSharedEvents를 사용하여 CPU에 신호를 보내고, 더 많은 작업을 파이프라인하고, GPU 기반 인코딩을 사용하고, 동시 디스패치를 사용하는 것을 고려하십시오.

00:10:30.000 --> 00:10:35.000
그래서 GPU 타임라인 격차를 최소화하기 위한 접근 방식에 대해 논의해 봅시다.

00:10:35.000 --> 00:10:39.000
그들 중 일부는 당신의 작업 흐름에 맞을 수도 있습니다.

00:10:39.000 --> 00:10:44.000
GPU 완성을 위해 CPU를 기다리는 것은 이상적인 스케일링으로 이어지지 않는다.

00:10:44.000 --> 00:10:51.000
애플리케이션이 WaitUntilCompleted를 사용하고 있다면, 대신 MTLSharedEvents를 사용해 볼 수 있습니다.

00:10:51.000 --> 00:10:57.000
MTLSharedEvents는 오버헤드가 낮고 타임라인 격차를 줄이는 데 도움이 될 수 있습니다.

00:10:57.000 --> 00:11:02.000
다음으로 고려해야 할 것은 작업량을 배관하는 것이다.

00:11:02.000 --> 00:11:13.000
알고리즘에 다음 배치가 작동하는 데 필요한 데이터가 있다면, MTLSharedEvents를 기다리기 전에 하나 이상의 배치를 미리 인코딩할 수 있습니다.

00:11:13.000 --> 00:11:19.000
그렇게 함으로써, GPU는 고갈되지 않을 것이며 항상 처리해야 할 것이다.

00:11:19.000 --> 00:11:26.000
작업을 같은 대기열에서 미리 인코딩할 수 없다면, 두 번째 대기열을 사용하여 작업을 겹치는 것을 고려해 보세요.

00:11:26.000 --> 00:11:35.000
여러 대기열을 사용하면 독립적인 작업을 제출할 수 있으며, 이벤트를 기다릴 때 다른 제출 스레드를 지연시키지 않습니다.

00:11:35.000 --> 00:11:41.000
이렇게 하면, GPU는 작업을 계속 받고 처리할 수 있다.

00:11:41.000 --> 00:11:47.000
경우에 따라, 알고리즘은 GPU에서 직접 작업을 인코딩할 수 있다.

00:11:47.000 --> 00:11:56.000
간접 명령 버퍼를 사용하면 다음 배치의 인코딩을 GPU에서 직접 이동할 수 있으므로 동기화가 필요하지 않습니다.

00:11:56.000 --> 00:12:02.000
간접 명령 버퍼에 대한 자세한 내용은 "Modern Rendering with Metal"을 확인하세요.

00:12:02.000 --> 00:12:09.000
워크로드는 이제 가능한 한 CPU와 GPU 간의 값비싼 동기화를 제거하거나 최소화합니다.

00:12:09.000 --> 00:12:15.000
하지만 바쁜 GPU 타임라인에도 불구하고, 스케일링 문제는 여전히 존재할 수 있다.

00:12:15.000 --> 00:12:17.000
조사해 보자.

00:12:17.000 --> 00:12:23.000
이 그래프는 이미지가 한 번에 1프레임씩 처리되는 이미지 처리 워크로드에서 가져온 것입니다.

00:12:23.000 --> 00:12:29.000
많은 백투백 컴퓨팅 직렬 디스패치도 확장을 제한할 수 있다.

00:12:29.000 --> 00:12:41.000
GPU는 바쁘지만, 커널 동기화에는 비용이 있으며, 또한 모든 디스패치에는 스레드 그룹이 분산되고 아직 코어를 포화시키지 않는 작은 램프가 있습니다.

00:12:41.000 --> 00:12:49.000
마찬가지로, 스레드 그룹이 끝나고 은퇴할 때, 더 이상 코어를 완전히 포화시키기에 충분한 작업이 없을 수도 있다.

00:12:49.000 --> 00:12:54.000
이 상황에서, 조언은 가능할 때 독립적인 작업을 겹치는 것이다.

00:12:54.000 --> 00:12:56.000
시각적인 예를 봅시다.

00:12:56.000 --> 00:13:00.000
여기서 우리는 두 개의 이미지를 차례로 처리하는 작업량이 있다.

00:13:00.000 --> 00:13:04.000
일반적으로, 커널은 서로 동기화되어야 한다.

00:13:04.000 --> 00:13:07.000
그러나, 이것이 작업 일정을 잡는 유일한 방법은 아니다.

00:13:07.000 --> 00:13:13.000
동시 디스패치를 사용하여 두 이미지의 독립적인 작업을 인터리브할 수 있습니다.

00:13:13.000 --> 00:13:19.000
여기서 운전자는 동시 파견 덕분에 다른 작업을 인터리프할 수 있다.

00:13:19.000 --> 00:13:27.000
우리는 이전에 연속이었던 두 개의 커널이 이제 독립적인 작업으로 분리되어 있다는 것을 알 수 있다.

00:13:27.000 --> 00:13:33.000
그러나, MTLDispatchTypeConcurrent를 사용할 때, 장벽을 수동으로 설치해야 합니다.

00:13:33.000 --> 00:13:47.000
동시 디스패치를 통해 운전자는 작업을 더 단단히 포장할 수 있으며, 종속 커널 간의 동기화 비용의 대부분을 숨기고 다양한 커널의 램프 업과 꼬리 끝을 채울 수 있습니다.

00:13:47.000 --> 00:13:55.000
이 최적화는 M1 Max에서 M1 Ultra로 이동할 때 워크로드 성능과 스케일링을 크게 향상시켰습니다.

00:13:55.000 --> 00:14:07.000
워크로드는 두 개의 이미지가 인터리브된 상태에서 30% 더 빠르며, 이전 스케일링에 비해 3개의 이미지가 병렬로 70% 더 빠릅니다.

00:14:07.000 --> 00:14:11.000
커널이 하고 있는 원자 작업을 신중하게 고려하는 것이 중요하다.

00:14:11.000 --> 00:14:15.000
그것이 가장 효율적인 방법으로 만들어졌는지 확인합시다.

00:14:15.000 --> 00:14:22.000
원자 연산을 통해 여러 스레드에서 데이터를 안전하게 읽고 쓸 수 있습니다.

00:14:22.000 --> 00:14:26.000
글로벌 원자는 GPU 전체에 걸쳐 일관성이 있다.

00:14:26.000 --> 00:14:32.000
많은 스레드가 동일한 글로벌 값을 읽고 쓰려고 할 때, 이것은 경합으로 이어진다.

00:14:32.000 --> 00:14:38.000
GPU 코어의 수를 늘리는 것은 도움이 되지 않으며 실제로 더 많은 경합으로 이어진다.

00:14:38.000 --> 00:14:45.000
예를 들어 알고리즘에서 원자 행동을 어떻게 개선할 수 있는지 조사해 봅시다.

00:14:45.000 --> 00:14:51.000
여기 버퍼의 모든 값이 함께 요약되는 환원 알고리즘이 있습니다.

00:14:51.000 --> 00:14:57.000
가장 간단한 방법은 메인 메모리에서 스레드당 원자 추가 작업을 수행하는 것이다.

00:14:57.000 --> 00:15:09.000
그러나, 이것은 메인 메모리의 단일 값에 큰 압력을 가하고 각 메모리 쓰기를 효과적으로 직렬화하기 때문에 이상적이지 않다.

00:15:09.000 --> 00:15:18.000
하드웨어가 원자 메모리 경합을 돕기 위해 제공하는 두 가지가 있다: 심드 그룹 명령과 스레드 그룹 원자.

00:15:18.000 --> 00:15:31.000
Prefix_exlusive sum 및 simd_min 등과 같은 SIMD 명령은 메모리로 왕복하지 않고 SIMD 그룹의 레지스터 간에 작업을 수행하고 메모리를 교환할 수 있습니다.

00:15:31.000 --> 00:15:35.000
스레드그룹 원자는 스레드그룹 메모리에 의해 충족된다.

00:15:35.000 --> 00:15:42.000
각 GPU 코어에는 GPU 코어 수에 따라 확장할 수 있는 자체 스레드 그룹 메모리가 있습니다.

00:15:42.000 --> 00:15:48.000
이 두 가지 기능이 작업량을 개선하는 데 어떻게 도움이 될 수 있는지 봅시다.

00:15:48.000 --> 00:15:56.000
여기서 우리는 같은 감소 문제가 있지만, 이번에는 SIMD 그룹 명령, 포괄적인 메모리 합계를 사용하기 시작합니다.

00:15:56.000 --> 00:16:03.000
이러한 작업은 마지막 스레드에서 SIMD 그룹의 모든 숫자의 합을 남길 것이다.

00:16:03.000 --> 00:16:14.000
그런 다음 각 SIMD 그룹의 마지막 스레드는 스레드 그룹 메모리에서 단일 원자 추가를 수행하여 모든 SIMD 그룹을 스레드 그룹 메모리의 단일 값으로 줄일 수 있습니다.

00:16:14.000 --> 00:16:24.000
이런 식으로, SIMD 그룹 명령과 스레드 그룹 메모리를 사용하여, 메인 메모리를 전혀 건드리지 않고 전체 스레드 그룹이 줄어들었다.

00:16:24.000 --> 00:16:29.000
각 그룹은 독립적으로 그리고 병렬로 줄일 수 있을 것이다.

00:16:29.000 --> 00:16:37.000
이제 각 스레드 그룹이 단일 값으로 축소되었으므로, 스레드 그룹당 하나의 스레드는 메인 메모리에서 단일 원자를 수행할 수 있습니다.

00:16:37.000 --> 00:16:50.000
이것은 스레드 그룹당 하나의 원자만 필요할 뿐만 아니라, 스레드 그룹이 다른 시간에 완료되기 때문에 시간이 지남에 따라 원자를 분산시켜 메모리 경합을 더욱 줄인다.

00:16:50.000 --> 00:17:02.000
요약하자면, 원자 효과를 극대화하기 위해, 메모리 지역을 활용하고, SIMD 그룹 작업을 사용하고, 스레드 그룹 메모리 원자를 활용하십시오.

00:17:02.000 --> 00:17:08.000
이 모든 것은 스케일링을 방지하는 원자 작동 압력을 줄이는 데 크게 도움이 될 것이다.

00:17:08.000 --> 00:17:15.000
이제 GPU 격차가 해결되었으므로, 스케일링이 이상에 더 가까운지 확인할 때입니다.

00:17:15.000 --> 00:17:25.000
Xcode 및 Metal System Trace의 GPU 리미터는 GPU 코어 실행 파이프라인의 병목 현상과 비효율성을 최적화하는 데 도움이 됩니다.

00:17:25.000 --> 00:17:36.000
예를 들어, 비효율적인 메모리 액세스 패턴은 항상 높은 마지막 레벨 캐시 또는 메모리 관리 장치 또는 MMU 제한기와 꽤 낮은 활용도를 유발합니다.

00:17:36.000 --> 00:17:43.000
가장 먼저 해결해야 할 것은 스레드 그룹과 메모리 레이아웃을 조정하는 방법이다.

00:17:43.000 --> 00:17:54.000
메모리 범위와 발산을 줄이는 핵심은 공간적으로나 시간적으로 워크로드 메모리 액세스 패턴을 명확하게 이해하는 것이다.

00:17:54.000 --> 00:18:09.000
그것이 이해되면, 두 가지 가능한 튜닝 방향이 있습니다: 데이터 액세스 위치를 개선하기 위해 데이터 레이아웃을 재구성하거나, 데이터 레이아웃과 더 잘 일치하고 메모리와 캐시 위치를 개선하기 위해 액세스 패턴을 조정하십시오.

00:18:09.000 --> 00:18:12.000
예를 들어 보자.

00:18:12.000 --> 00:18:18.000
여기에는 데이터가 한 줄씩 수평으로 배치되는 메모리 버퍼가 있습니다.

00:18:18.000 --> 00:18:29.000
그러나, 컴퓨팅 커널이 파견될 때, 정사각형 스레드 그룹이 분산되는 2D와 같은 패턴을 갖는 것이 일반적이며, 이는 상당히 공간적으로 국한되어 있다.

00:18:29.000 --> 00:18:36.000
이 접근 패턴과 데이터 레이아웃은 데이터 지역에 적합하지 않다.

00:18:36.000 --> 00:18:42.000
예를 들어, 첫 번째 SIMD 그룹이 데이터에 액세스할 때, 요청은 캐시 라인에 포장됩니다.

00:18:42.000 --> 00:18:50.000
대부분의 캐시 라인은 사용되지 않지만, 여전히 캐시의 공간을 차지한다.

00:18:50.000 --> 00:19:01.000
액세스 패턴에 더 잘 맞도록 데이터를 다시 정렬하세요. 예를 들어, 전체 행을 가로지르는 대신 줄무늬로 현지화됩니다.

00:19:01.000 --> 00:19:12.000
이 새로운 메모리 레이아웃을 통해 스레드 그룹은 캐시 라인에서 요청될 대부분의 데이터를 활용하여 발산을 줄이고 캐시 효율성을 향상시킬 수 있습니다.

00:19:12.000 --> 00:19:19.000
다른 옵션은 현재 데이터 레이아웃에 더 잘 맞도록 3D 그리드가 파견되는 방식을 변경하는 것입니다.

00:19:19.000 --> 00:19:29.000
예를 들어, 더 직사각형 모양과 같이 메모리 레이아웃에 더 잘 매핑되는 그룹을 만들기 위해 스레드 그룹 크기를 사용해 보세요.

00:19:29.000 --> 00:19:37.000
이 경우, 액세스 패턴은 메모리 레이아웃과 정렬되어 훨씬 더 높은 캐시 효율성을 제공합니다.

00:19:37.000 --> 00:19:41.000
작업량에 가장 적합한 것을 찾기 위해 실험해야 할 수도 있습니다.

00:19:41.000 --> 00:19:54.000
때때로 당신은 절충을 하거나, 메모리 지역에 대한 스레드 발산을 희생하거나, 그 반대의 경우도 마찬가지이며, 데이터 레이아웃, 디스패치 그리드 또는 이 모든 것의 조합을 변경해야 할 수도 있습니다.

00:19:54.000 --> 00:20:00.000
모든 작업량과 접근 패턴은 다르다.

00:20:00.000 --> 00:20:08.000
이제 메모리 지역성을 개선하는 방법을 알았으니, 블렌더 사이클에서 좀 더 구체적인 예를 봅시다.

00:20:08.000 --> 00:20:13.000
사이클은 생산 렌더링을 위한 블렌더의 물리적 기반 경로 추적기이다.

00:20:13.000 --> 00:20:24.000
그것은 생산 요구를 위한 예술적 제어와 유연한 셰이딩 노드와 함께 즉시 물리적으로 기반한 결과를 제공하도록 설계되었습니다.

00:20:24.000 --> 00:20:36.000
이 기기 추적은 낮은 읽기 대역폭, 높은 상위 GPU 제한기, 높은 캐시 제한기 및 낮은 마지막 수준 캐시 활용도를 명확하게 보여줍니다.

00:20:36.000 --> 00:20:42.000
대역폭과 MMU 제한기를 제어하는 것은 스케일링에 중요하다.

00:20:42.000 --> 00:20:50.000
상단 리미터가 마지막 레벨 캐시 또는 MMU인 경우, 메모리 범위를 줄이고 데이터 위치를 극대화해야 합니다.

00:20:50.000 --> 00:20:53.000
예를 들어 보자.

00:20:53.000 --> 00:20:57.000
주기는 발산을 줄이기 위해 데이터 정렬을 사용한다.

00:20:57.000 --> 00:21:01.000
그것은 재료 유형별로 레이 히트를 정렬함으로써 그것을 한다.

00:21:01.000 --> 00:21:11.000
이것은 스레드 발산을 줄이는 데 좋지만, 공간 기억 발산을 증가시켜 높은 MMU 리미터를 초래한다.

00:21:11.000 --> 00:21:17.000
이를 돕기 위해, 우리는 데이터 지역성을 높이기 위해 정렬하기 전에 메모리 범위를 분할하는 실험을 했다.

00:21:17.000 --> 00:21:18.000
그걸 시각화하자.

00:21:18.000 --> 00:21:28.000
광선이 빛 여행을 시뮬레이션하기 위해 장면으로 발사될 때, 그들은 물체에 부딪히고 데이터는 버퍼로 수집된다.

00:21:28.000 --> 00:21:39.000
교차로 지점에서 우리는 많은 것을 알고 있다 - 유리, 금속 등과 같은 부딪힌 재료 유형, 교차로 위치, 광선 등.

00:21:39.000 --> 00:21:43.000
단순함을 위해, 재료 유형에만 집중합시다.

00:21:43.000 --> 00:21:47.000
여기 메모리의 버퍼에 있는 재료가 있습니다.

00:21:47.000 --> 00:21:53.000
레이 히트당 많은 데이터가 수집되기 때문에, 메모리 버퍼는 꽤 커질 수 있다.

00:21:53.000 --> 00:22:00.000
많은 메모리를 옮기는 것을 피하려면, 인덱스 목록을 채우고 대신 정렬하세요.

00:22:00.000 --> 00:22:06.000
정렬 후, 동일한 재료 유형에 대한 인덱스는 이제 함께 포장됩니다.

00:22:06.000 --> 00:22:11.000
SIMD 그룹은 인덱스 로딩을 시작하고 재료를 처리할 수 있다.

00:22:11.000 --> 00:22:18.000
SIMD 그룹은 인덱스를 사용하여 원래 버퍼에 해당 데이터를 로드합니다.

00:22:18.000 --> 00:22:25.000
그러나, SIMD 그룹은 전체 메모리 범위에 걸쳐 읽을 것이며, MMU에 압력을 가할 것이다.

00:22:25.000 --> 00:22:28.000
새로운 접근 방식을 조사해 봅시다.

00:22:28.000 --> 00:22:36.000
메모리 범위는 단순히 다른 파티션의 인덱스를 혼합할 수 없는 이상적인 파티션으로 분할됩니다.

00:22:36.000 --> 00:22:46.000
정렬할 때, 액세스한 데이터의 범위가 이전과 같이 전체 메모리 범위에 걸쳐 있는 대신 파티션 내부에 포함되어 있는 것이 분명합니다.

00:22:46.000 --> 00:22:52.000
그것은 스레드 발산과 기억 발산 사이의 절충안과 균형이다.

00:22:52.000 --> 00:22:58.000
이상적인 파티션 수와 크기는 작업량에 크게 의존한다.

00:22:58.000 --> 00:23:02.000
어떤 것이 가장 잘 작동하는지 실험해야 할 수도 있습니다.

00:23:02.000 --> 00:23:07.000
또 다른 메탈 시스템 트레이스를 가져가서 작업량이 개선되었는지 봅시다.

00:23:07.000 --> 00:23:11.000
여기서 우리는 최적화된 버전의 제한기와 활용도를 볼 수 있습니다.

00:23:11.000 --> 00:23:17.000
최고 성능 리미터와 마지막 레벨 캐시 리미터가 다운되었다.

00:23:17.000 --> 00:23:22.000
결과적으로, 대역폭과 셰이더 런타임이 크게 개선되었다.

00:23:22.000 --> 00:23:24.000
얼마인지 보자.

00:23:24.000 --> 00:23:29.000
최고 제한자와 LLC 제한자는 약 20% 감소했다.

00:23:29.000 --> 00:23:32.000
그것은 데이터 흐름이 더 효율적이라는 것을 의미한다.

00:23:32.000 --> 00:23:39.000
GPU 읽기 대역폭이 크게 증가하여 GPU 코어에 더 많은 데이터를 푸시할 수 있습니다.

00:23:39.000 --> 00:23:48.000
전반적으로, 이 실험으로 메모리 지역성을 증가시키면 장면에 따라 성능이 10~30% 향상되었다.

00:23:48.000 --> 00:23:54.000
이것은 메모리 액세스 패턴을 개선하기 위해 시도할 수 있는 많은 방법의 예일 뿐입니다.

00:23:54.000 --> 00:23:58.000
최고 성능 제한기를 위해 계속 실험하고 최적화하세요.

00:23:58.000 --> 00:24:03.000
GPU 도구에는 조정할 수 있는 더 유용한 카운터가 있다.

00:24:03.000 --> 00:24:08.000
Xcode는 컴파일러 통계 창에 새로운 이론적 점유율을 가지고 있다.

00:24:08.000 --> 00:24:24.000
Xcode와 Instruments 모두 이제 여러 MMU 관련 리미터와 카운터, 특히 새로운 MMU 리미터, MMU 활용 카운터 및 MMU TLB 미스 요금 카운터가 있습니다.

00:24:24.000 --> 00:24:27.000
나는 오늘 많은 것을 다뤘다.

00:24:27.000 --> 00:24:36.000
저는 GPU 확장성과 확장 시 병목 현상이 어떻게 바뀔 수 있는지, 그리고 도구가 확장성 문제를 찾고 해결하는 데 어떻게 도움이 될 수 있는지에 대해 논의했습니다.

00:24:36.000 --> 00:24:43.000
나는 또한 당신의 지원서에 가장 적합한 결과를 얻기 위해 어떻게 실험하고 절충해야 하는지에 대해 논의했습니다.

00:24:43.000 --> 00:24:48.000
저는 당신의 모든 훌륭한 앱이 애플 실리콘에서 놀라울 정도로 잘 확장되는 것을 기대하고 있습니다.

00:24:48.000 --> 23:59:59.000
봐줘서 고마워.

