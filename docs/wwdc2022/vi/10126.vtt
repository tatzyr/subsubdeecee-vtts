WEBVTT

00:00:00.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:11.000
Christian: Xin chào, tên tôi là Christian.

00:00:11.000 --> 00:00:18.000
Tôi là một kỹ sư trong nhóm ARKit, và tôi muốn chào đón bạn đến với phiên của chúng tôi, Khám phá ARKit 6.

00:00:18.000 --> 00:00:24.000
Bạn sẽ học cách tận dụng những tiến bộ mới nhất trong khuôn khổ Thực tế tăng cường của chúng tôi.

00:00:24.000 --> 00:00:30.000
Chúng tôi rất vui khi thấy những gì bạn đã tạo ra trong vài năm qua với ARKit.

00:00:30.000 --> 00:00:38.000
Chúng ta đang thấy một số ứng dụng tuyệt vời trong thiết kế nội thất, du lịch, triển lãm ảo, trò chơi và rất nhiều ứng dụng khác.

00:00:38.000 --> 00:00:45.000
Nhóm của chúng tôi tại Apple đã rất chú ý đến phản hồi của bạn và chúng tôi đã kết hợp rất nhiều phản hồi đó vào ARKit 6.

00:00:45.000 --> 00:00:46.000
Hãy cùng xem nào.

00:00:46.000 --> 00:00:54.000
Chúng tôi đang giới thiệu chế độ video 4K mới cho phép bạn chạy luồng máy ảnh ở độ phân giải hình ảnh cao nhất từ trước đến nay.

00:00:54.000 --> 00:01:01.000
Sau đó, tôi sẽ nói về một số cải tiến máy ảnh bổ sung mà chúng tôi đã thực hiện giúp bạn kiểm soát nhiều hơn phông nền video.

00:01:01.000 --> 00:01:14.000
Chúng tôi cũng có các cập nhật về hành vi của neo máy bay, bổ sung vào API Chụp chuyển động và cuối cùng chia sẻ các thành phố mới nơi neo vị trí sẽ được hỗ trợ.

00:01:14.000 --> 00:01:17.000
Hãy bắt đầu với video 4K.

00:01:17.000 --> 00:01:32.000
Trong suốt vài năm qua, chúng tôi đã thấy rất nhiều nhu cầu về nội dung có độ phân giải cao, đặc biệt là những ứng dụng tận dụng sức mạnh của Thực tế tăng cường để làm phim, luôn khao khát nhiều điểm ảnh hơn.

00:01:32.000 --> 00:01:36.000
Hãy để tôi chỉ cho bạn cách chụp và xử lý hình ảnh cho ARKit.

00:01:36.000 --> 00:01:39.000
Đây là mô-đun máy ảnh của iPhone 13 Pro.

00:01:39.000 --> 00:01:43.000
Nếu chúng ta mở nó ra, chúng ta có thể thấy thiết lập của nó.

00:01:43.000 --> 00:01:46.000
Hãy để chúng tôi nói về máy ảnh Wide và Ultrawide.

00:01:46.000 --> 00:01:55.000
Cả hai máy ảnh này đều có thể được sử dụng cho các nhiệm vụ thị giác máy tính khác nhau, chẳng hạn như theo dõi thế giới, chụp chuyển động hoặc phân đoạn người.

00:01:55.000 --> 00:02:02.000
Máy ảnh rộng có một vị trí đặc biệt trong trái tim của chúng ta, vì nó cung cấp hình ảnh cho phông nền kết xuất.

00:02:02.000 --> 00:02:13.000
Điều quan trọng là phải hiểu cách hình ảnh được xử lý để kết xuất, vì vậy hãy để tôi phóng to đến mức cảm biến.

00:02:13.000 --> 00:02:17.000
Khi chụp ảnh cho ARKit, chúng tôi sử dụng một phần lớn cảm biến hình ảnh.

00:02:17.000 --> 00:02:25.000
Nói chính xác hơn, đó là diện tích 3840x2880 pixel trên mô hình cụ thể này.

00:02:25.000 --> 00:02:28.000
Sau khi chụp, chúng tôi sử dụng một quá trình gọi là binning.

00:02:28.000 --> 00:02:41.000
Nó hoạt động như sau: Binning lấy một vùng 2x2 pixel, tính trung bình các giá trị pixel và ghi lại một pixel duy nhất.

00:02:41.000 --> 00:02:44.000
Điều này có hai lợi thế đáng kể.

00:02:44.000 --> 00:02:53.000
Đầu tiên, kích thước hình ảnh được giảm đi gấp hai lần, trong trường hợp này, nó thu nhỏ xuống 1920x1440 pixel.

00:02:53.000 --> 00:02:58.000
Do đó, mỗi khung hình tiêu tốn ít bộ nhớ và sức mạnh xử lý hơn.

00:02:58.000 --> 00:03:05.000
Điều này cho phép thiết bị chạy máy ảnh với tốc độ lên đến 60 khung hình mỗi giây và giải phóng tài nguyên để kết xuất.

00:03:05.000 --> 00:03:15.000
Thứ hai, quá trình này mang lại lợi thế trong môi trường ánh sáng yếu, nơi việc tính trung bình các giá trị điểm ảnh làm giảm tác động của nhiễu cảm biến.

00:03:15.000 --> 00:03:25.000
Chúng tôi kết thúc với một luồng máy ảnh cung cấp hình ảnh ở độ phân giải HD khoảng 17 mili giây một lần.

00:03:25.000 --> 00:03:33.000
Sau khi sử dụng khung hiện tại cho các tác vụ thị giác máy tính khác nhau, ARKit hiển thị khung hiện tại để kết xuất.

00:03:33.000 --> 00:03:42.000
Trong trường hợp bạn đang viết trình kết xuất Kim loại của riêng mình, bạn có quyền truy cập vào nó thông qua CurrentFrame.capturedImage của ARSession.

00:03:42.000 --> 00:03:49.000
Nếu bạn đang sử dụng RealityKit, hình ảnh sẽ tự động được xử lý thêm để sử dụng làm phông nền.

00:03:49.000 --> 00:04:00.000
Nó được chia tỷ lệ trên thiết bị để phù hợp với chiều rộng màn hình 2532 pixel và được cắt để phù hợp với tỷ lệ khung hình hiển thị.

00:04:00.000 --> 00:04:10.000
RealityKit thực hiện nhiệm vụ kết xuất và tổng hợp nội dung ảo, giống như con tàu cướp biển này, trên khung hình và hiển thị kết quả cuối cùng trên màn hình.

00:04:10.000 --> 00:04:17.000
Giờ đây, với sức mạnh của phần cứng mới nhất của chúng tôi, chúng tôi bật chế độ video 4K đầy đủ trong ARKit.

00:04:17.000 --> 00:04:27.000
Ứng dụng của bạn giờ đây có thể tận dụng hình ảnh có độ phân giải cao hơn bằng cách bỏ qua bước phân loại và truy cập trực tiếp vào nó ở độ phân giải 4K đầy đủ.

00:04:27.000 --> 00:04:37.000
Ở chế độ 4K, diện tích hình ảnh 3840x2160 pixel được sử dụng và bạn có thể quay video với tốc độ 30 khung hình mỗi giây.

00:04:37.000 --> 00:04:41.000
Ngoài những thay đổi này, ứng dụng của bạn sẽ hoạt động giống như trước đây.

00:04:41.000 --> 00:04:49.000
Nếu bạn sử dụng RealityKit, nó sẽ thực hiện chia tỷ lệ, cắt xén và kết xuất cho bạn.

00:04:49.000 --> 00:04:54.000
Bạn có thể bật chế độ 4K bằng một vài bước đơn giản.

00:04:54.000 --> 00:04:58.000
Hãy xem nó trông như thế nào trong mã.

00:04:58.000 --> 00:05:11.000
'ARConfiguration' có chức năng tiện lợi mới 'recommendedVideoFormatFor4KResolution' trả về định dạng video 4K nếu chế độ đó được hỗ trợ trên thiết bị của bạn.

00:05:11.000 --> 00:05:17.000
Nếu thiết bị hoặc cấu hình không hỗ trợ 4K, chức năng này sẽ trả về số không.

00:05:17.000 --> 00:05:25.000
Sau đó, bạn có thể gán định dạng video này cho cấu hình của mình, sau đó bạn chạy phiên của mình với cấu hình đã điều chỉnh đó.

00:05:25.000 --> 00:05:34.000
Chế độ video 4K có sẵn trên iPhone 11 trở lên và trên bất kỳ iPad Pro nào có chip M1.

00:05:34.000 --> 00:05:40.000
Độ phân giải là 3840x2160 pixel với tốc độ 30 khung hình mỗi giây.

00:05:40.000 --> 00:05:53.000
Tỷ lệ khung hình là 16:9, đối với iPad có nghĩa là hình ảnh phải được cắt ở hai bên để hiển thị toàn màn hình và kết xuất cuối cùng có thể được phóng to.

00:05:53.000 --> 00:06:01.000
Khi sử dụng ARKit, đặc biệt là ở độ phân giải 4K mới, điều quan trọng là phải tuân theo một số phương pháp hay nhất để có kết quả tối ưu.

00:06:01.000 --> 00:06:04.000
Đừng giữ ARFrame quá lâu.

00:06:04.000 --> 00:06:12.000
Điều này có thể ngăn hệ thống giải phóng bộ nhớ, điều này có thể ngăn ARKit hiển thị các khung hình mới hơn cho bạn.

00:06:12.000 --> 00:06:15.000
Điều này sẽ hiển thị thông qua các giọt khung trong kết xuất của bạn.

00:06:15.000 --> 00:06:20.000
Cuối cùng, trạng thái theo dõi của ARCamera có thể giảm trở lại giới hạn.

00:06:20.000 --> 00:06:26.000
Kiểm tra các cảnh báo trên bảng điều khiển để đảm bảo bạn không giữ lại quá nhiều hình ảnh tại bất kỳ thời điểm nào.

00:06:26.000 --> 00:06:32.000
Cũng xem xét liệu định dạng video 4K mới có thực sự là lựa chọn phù hợp cho ứng dụng của bạn hay không.

00:06:32.000 --> 00:06:40.000
Các ứng dụng được hưởng lợi từ video độ phân giải cao là những ứng cử viên tốt, chẳng hạn như video, làm phim và các ứng dụng sản xuất ảo.

00:06:40.000 --> 00:06:55.000
Xử lý hình ảnh có độ phân giải cao hơn chiếm thêm tài nguyên hệ thống, vì vậy đối với các trò chơi và ứng dụng khác dựa vào tốc độ làm mới cao, chúng tôi vẫn khuyên bạn nên sử dụng video full HD với tốc độ 60 khung hình mỗi giây.

00:06:55.000 --> 00:07:03.000
Ngoài chế độ 4K mới, còn có một số cải tiến bổ sung cho phép bạn kiểm soát máy ảnh của mình nhiều hơn.

00:07:03.000 --> 00:07:12.000
Tôi sẽ bắt đầu bằng cách giới thiệu API ảnh nền độ phân giải cao và chỉ ra cách bật chế độ HDR mới.

00:07:12.000 --> 00:07:24.000
Hơn nữa, tôi sẽ trình bày cách truy cập vào AVCaptureDevice cơ bản để kiểm soát chi tiết hơn và chỉ cho bạn cách đọc các thẻ EXIF trong ARKit.

00:07:24.000 --> 00:07:30.000
Hãy nhảy vào API ảnh nền độ phân giải cao mới.

00:07:30.000 --> 00:07:35.000
Trong khi chạy ARSession, bạn vẫn có quyền truy cập vào luồng video như bình thường.

00:07:35.000 --> 00:07:46.000
Ngoài ra, ARKit cho phép bạn yêu cầu chụp những bức ảnh đơn lẻ theo yêu cầu trong nền, trong khi luồng video đang chạy không bị gián đoạn.

00:07:46.000 --> 00:07:50.000
Những khung ảnh đơn lẻ đó tận dụng tối đa cảm biến máy ảnh của bạn.

00:07:50.000 --> 00:07:55.000
Trên iPhone 13 của tôi, điều đó có nghĩa là toàn bộ 12 megapixel của camera rộng.

00:07:55.000 --> 00:08:06.000
Khi chuẩn bị cho WWDC, chúng tôi tại ARKit đã có một ý tưởng thú vị cho một ứng dụng Nhiếp ảnh làm nổi bật những gì API mới này có thể giúp bạn tạo ra.

00:08:06.000 --> 00:08:16.000
Trong ví dụ của chúng tôi, chúng tôi đưa bạn quay ngược thời gian về ngày 1 tháng 4 năm 2016, khi lá cờ cướp biển nổi tiếng đang bay qua Khuôn viên Apple Infinite Loop.

00:08:16.000 --> 00:08:25.000
Tôi đã hỏi Tommy, nhiếp ảnh gia gốc, chính xác anh ấy đã chụp bức ảnh đó ở đâu sáu năm trước.

00:08:25.000 --> 00:08:38.000
Dựa trên tọa độ này, chúng tôi có thể tạo một mỏ neo vị trí hướng dẫn bạn đến cùng một vị trí chính xác nơi Tommy đã đứng vào tháng 4 năm 2016, như được chỉ ra bởi chấm lớn màu xanh lam.

00:08:38.000 --> 00:08:45.000
Khi đến được vị trí đó, nó sẽ giúp bạn đóng khung bức tranh hoàn hảo đó bằng cách hiển thị một hình vuông lấy nét.

00:08:45.000 --> 00:08:51.000
Cuối cùng, ứng dụng cho phép bạn chụp ảnh bằng cách nhấn vào màn hình.

00:08:51.000 --> 00:09:00.000
Bức ảnh đó có thể được chụp ở độ phân giải máy ảnh gốc trong khi phiên ARKit hiện tại đang chạy, mà không cần phải quay một phiên AVCapture khác.

00:09:00.000 --> 00:09:06.000
Chúng tôi rất vui khi thấy bạn có ý tưởng nào kết hợp sức mạnh của AR và nhiếp ảnh.

00:09:06.000 --> 00:09:15.000
Một trường hợp sử dụng khác sẽ được hưởng lợi rất nhiều bởi API này là việc tạo ra các mô hình 3D bằng cách sử dụng Object Capture.

00:09:15.000 --> 00:09:30.000
Chụp đối tượng chụp ảnh một vật thể trong thế giới thực, như chiếc giày chạy bộ này và sử dụng các thuật toán trắc quang mới nhất của chúng tôi, nó biến chúng thành một mô hình 3D sẵn sàng để triển khai trong ứng dụng AR của bạn.

00:09:30.000 --> 00:09:37.000
Với ARKit, bạn có thể phủ lên giao diện người dùng 3D lên trên một đối tượng vật lý và cung cấp hướng dẫn chụp tốt hơn.

00:09:37.000 --> 00:09:47.000
Và bây giờ với API hình nền có độ phân giải cao mới, bạn có thể chụp ảnh có độ phân giải cao hơn của đối tượng và tạo ra các mô hình 3D chân thực hơn nữa.

00:09:47.000 --> 00:09:56.000
Tôi là một fan hâm mộ lớn của photogrammetry, vì vậy tôi thực sự khuyên bạn nên xem phiên "Đưa thế giới của bạn đến với thực tế tăng cường" năm nay.

00:09:56.000 --> 00:10:01.000
Hãy để tôi chỉ cho bạn cách bạn có thể bật tính năng chụp ảnh có độ phân giải cao trong mã.

00:10:01.000 --> 00:10:07.000
Đầu tiên, chúng tôi kiểm tra định dạng video hỗ trợ hiResCapture.

00:10:07.000 --> 00:10:15.000
Chúng ta có thể sử dụng chức năng tiện lợi 'recommendedVideoFormatForHighResolution FrameCapturing' cho điều đó.

00:10:15.000 --> 00:10:22.000
Sau khi chúng tôi đảm bảo rằng định dạng được hỗ trợ, chúng tôi có thể đặt định dạng video mới và chạy phiên.

00:10:22.000 --> 00:10:27.000
Chúng tôi cũng phải nói với ARKit khi nào nên chụp ảnh độ phân giải cao.

00:10:27.000 --> 00:10:32.000
Trong ví dụ trước của chúng tôi, việc chụp ảnh được kích hoạt bằng một cú chạm vào màn hình.

00:10:32.000 --> 00:10:39.000
Trong ứng dụng của riêng bạn, bạn có thể muốn phản ứng với các sự kiện khác nhau kích hoạt chụp khung hình có độ phân giải cao.

00:10:39.000 --> 00:10:42.000
Nó thực sự phụ thuộc vào trường hợp sử dụng của bạn.

00:10:42.000 --> 00:10:47.000
ARSession có một chức năng mới được gọi là captureHighResolutionFrame.

00:10:47.000 --> 00:10:54.000
Gọi chức năng này kích hoạt chụp ảnh có độ phân giải cao ngoài băng tần.

00:10:54.000 --> 00:11:03.000
Bạn có quyền truy cập vào ARFrame chứa hình ảnh có độ phân giải cao và tất cả các thuộc tính khung khác không đồng bộ trong trình xử lý hoàn thành.

00:11:03.000 --> 00:11:08.000
Bạn nên kiểm tra xem việc chụp khung hình có thành công hay không trước khi truy cập nội dung của nó.

00:11:08.000 --> 00:11:11.000
Trong ví dụ này, chúng tôi lưu trữ khung vào đĩa.

00:11:11.000 --> 00:11:22.000
Ngoài ra, hãy ghi nhớ các phương pháp hay nhất của chúng tôi về lưu giữ hình ảnh mà tôi đã đề cập trước đó, đặc biệt là vì những hình ảnh này sử dụng độ phân giải đầy đủ của cảm biến hình ảnh.

00:11:22.000 --> 00:11:26.000
Tiếp theo, hãy nói về HDR.

00:11:26.000 --> 00:11:31.000
Dải động cao chụp phạm vi màu sắc rộng hơn và ánh xạ chúng đến màn hình của bạn.

00:11:31.000 --> 00:11:35.000
Điều này dễ thấy nhất trong môi trường có độ tương phản cao.

00:11:35.000 --> 00:11:38.000
Đây là một ví dụ điển hình từ sân sau của tôi.

00:11:38.000 --> 00:11:47.000
Cảnh này có cả những khu vực rất tối - ví dụ, trên hàng rào gỗ - và một số khu vực rất sáng như những đám mây trên bầu trời.

00:11:47.000 --> 00:11:58.000
Khi bật chế độ HDR, như ở bên phải, bạn có thể thấy rằng các chi tiết ở những khu vực này, như độ mịn trên mây, được bảo toàn tốt hơn nhiều trong HDR.

00:11:58.000 --> 00:12:01.000
Hãy xem HDR được bật trong mã như thế nào.

00:12:01.000 --> 00:12:09.000
Bạn có thể truy vấn bất kỳ định dạng video nào nếu nó hỗ trợ HDR thông qua thuộc tính 'isVideoHDRSupported' của nó.

00:12:09.000 --> 00:12:13.000
Hiện tại, chỉ có các định dạng video không liên kết hỗ trợ HDR.

00:12:13.000 --> 00:12:22.000
Nếu HDR được hỗ trợ, hãy đặt videoHDRAllowed trong cấu hình thành true và chạy phiên của bạn với cấu hình đó.

00:12:22.000 --> 00:12:29.000
Bật HDR sẽ có tác động đến hiệu suất, vì vậy hãy đảm bảo chỉ sử dụng nó khi có nhu cầu.

00:12:29.000 --> 00:12:43.000
Trong trường hợp sử dụng mà bạn thích kiểm soát thủ công các cài đặt như phơi sáng hoặc cân bằng trắng, giờ đây có cách thuận tiện để truy cập trực tiếp vào AVCaptureDevice và thay đổi bất kỳ cài đặt nào của nó.

00:12:43.000 --> 00:12:54.000
Trong ví dụ mã của chúng tôi, hãy gọi 'configurableCaptureDevice ForPrimaryCamera' của cấu hình của bạn để có quyền truy cập vào 'AVCaptureDevice' bên dưới.

00:12:54.000 --> 00:13:07.000
Sử dụng khả năng này để tạo giao diện tùy chỉnh cho ứng dụng ARKit của bạn, nhưng hãy nhớ rằng hình ảnh không chỉ được sử dụng làm phông nền kết xuất mà còn được ARKit tích cực sử dụng để phân tích cảnh.

00:13:07.000 --> 00:13:14.000
Vì vậy, bất kỳ thay đổi nào như phơi sáng quá mức có thể có tác động tiêu cực đến chất lượng đầu ra của ARKit.

00:13:14.000 --> 00:13:19.000
Bạn cũng có thể thực hiện một số thao tác nâng cao, như kích hoạt các sự kiện tập trung.

00:13:19.000 --> 00:13:29.000
Để biết thêm thông tin về cách cấu hình AVCaptureSessions, vui lòng tham khảo tài liệu AVCapture trên developer.apple.com.

00:13:29.000 --> 00:13:33.000
Cuối cùng, ARKit hiển thị các thẻ EXIF cho ứng dụng của bạn.

00:13:33.000 --> 00:13:37.000
Chúng hiện có sẵn với mọi ARFrame.

00:13:37.000 --> 00:13:45.000
Các thẻ EXIF chứa thông tin hữu ích về cân bằng trắng, độ phơi sáng và các cài đặt khác có thể có giá trị để xử lý hậu kỳ.

00:13:45.000 --> 00:13:49.000
Điều đó kết thúc tất cả các cập nhật trên đường ống chụp ảnh.

00:13:49.000 --> 00:13:53.000
Hãy xem chúng ta có những thay đổi nào đối với Plane Anchors.

00:13:53.000 --> 00:13:58.000
Neo máy bay đã là một tính năng phổ biến kể từ phiên bản đầu tiên của ARKit.

00:13:58.000 --> 00:14:05.000
Nhiều người trong số các bạn đã bày tỏ sự cần thiết phải có sự tách biệt sạch hơn giữa neo mặt phẳng và hình học mặt phẳng bên dưới.

00:14:05.000 --> 00:14:12.000
Vì lý do đó, chúng tôi đang công bố các cập nhật về hành vi của neo phẳng và hình dạng của mặt phẳng.

00:14:12.000 --> 00:14:17.000
Đây là một ví dụ về một mỏ neo máy bay điển hình trong iOS 15.

00:14:17.000 --> 00:14:24.000
Vào đầu phiên AR, nó vừa vặn với mặt phẳng với cuốn sổ ghi chép có kết cấu tốt này trên bàn.

00:14:24.000 --> 00:14:31.000
Khi chạy phiên, mặt phẳng được cập nhật dần dần để tính đến các phần mới của bảng xuất hiện.

00:14:31.000 --> 00:14:39.000
Mỗi khi hình học mặt phẳng được cập nhật, vòng quay neo cũng được cập nhật để phản ánh hướng mới của mặt phẳng.

00:14:39.000 --> 00:14:47.000
Với iOS 16, chúng tôi giới thiệu sự tách biệt rõ ràng hơn giữa neo máy bay và hình học máy bay của chúng.

00:14:47.000 --> 00:14:52.000
Các bản cập nhật về neo phẳng và hình học hiện đã được tách rời hoàn toàn.

00:14:52.000 --> 00:15:06.000
Trong khi mặt phẳng đang mở rộng và cập nhật hình học của nó khi bảng đầy đủ xuất hiện, bản thân vòng quay neo vẫn không đổi.

00:15:06.000 --> 00:15:21.000
Khi tương phản với hành vi cũ ở phía bên tay trái, bạn có thể thấy rằng neo mặt phẳng trong iOS 16 vẫn ở cùng một hướng, được căn chỉnh với sổ ghi chép, trong toàn bộ Phiên AR.

00:15:21.000 --> 00:15:28.000
Tất cả thông tin về hình học mặt phẳng hiện được chứa trong một lớp gọi là ARPlaneExtent.

00:15:28.000 --> 00:15:33.000
Các bản cập nhật xoay không còn được thể hiện thông qua việc xoay chính neo mặt phẳng.

00:15:33.000 --> 00:15:42.000
Thay vào đó, ARPlaneExtent chứa một thuộc tính mới, rotationOnYAxis, đại diện cho góc quay.

00:15:42.000 --> 00:15:52.000
Ngoài thuộc tính mới này, các mặt phẳng được xác định đầy đủ bởi chiều rộng và chiều cao, cũng như tọa độ trung tâm của PlaneAnchor.

00:15:52.000 --> 00:15:58.000
Hãy để tôi chỉ cho bạn cách tạo hình ảnh trực quan hóa mặt phẳng này trong mã.

00:15:58.000 --> 00:16:06.000
Đầu tiên, chúng tôi tạo ra một thực thể dựa trên lưới phẳng theo chiều rộng và chiều cao được chỉ định.

00:16:06.000 --> 00:16:16.000
Sau đó, chúng tôi đặt các thực thể biến đổi theo vòng quay trên trục y và cũng bù nó bằng giá trị của thuộc tính trung tâm.

00:16:16.000 --> 00:16:26.000
Mỗi khi mặt phẳng được cập nhật, chúng ta phải tính đến thực tế là chiều rộng, chiều cao và tọa độ tâm và vòng quay mới OnYAxis có thể thay đổi.

00:16:26.000 --> 00:16:34.000
Để sử dụng hành vi mới này, hãy đặt mục tiêu triển khai của bạn thành iOS 16 trong cài đặt Xcode của bạn.

00:16:34.000 --> 00:16:42.000
Bản cập nhật tiếp theo là trên MotionCapture, những người chủ mưu học máy của chúng tôi đã làm việc chăm chỉ để cải thiện hơn nữa.

00:16:42.000 --> 00:16:49.000
Có cả một bộ cập nhật, cho cả bộ xương 2D, cũng như cho các khớp 3D.

00:16:49.000 --> 00:16:55.000
Đối với bộ xương 2D, chúng tôi đang theo dõi hai khớp mới: tai trái và tai phải.

00:16:55.000 --> 00:16:59.000
Chúng tôi cũng đã cải thiện khả năng phát hiện tư thế tổng thể.

00:16:59.000 --> 00:17:09.000
Trên iPhone 12 trở lên, cũng như trên các mẫu iPad Pro và iPad Air mới nhất với chip M1, bộ xương 3D, như được hiển thị bằng màu đỏ, đã được cải thiện.

00:17:09.000 --> 00:17:14.000
Bạn sẽ trải nghiệm ít bồn chồn hơn và tổng thể nhất quán hơn về thời gian.

00:17:14.000 --> 00:17:21.000
Theo dõi cũng ổn định hơn nếu các bộ phận của người bị che khuất hoặc khi đi đến gần máy ảnh.

00:17:21.000 --> 00:17:29.000
Để sử dụng MotionCapture được cải tiến, hãy đặt mục tiêu triển khai của bạn thành iOS 16 trong cài đặt Xcode của bạn.

00:17:29.000 --> 00:17:36.000
Tiếp theo, tôi cũng muốn thông báo các thành phố và quốc gia mới nơi LocationAnchors sẽ được hỗ trợ.

00:17:36.000 --> 00:17:42.000
Như một lời nhắc nhở nhỏ, Apple Maps sử dụng LocationAnchor API để cung cấp năng lượng cho hướng dẫn đi bộ cho người đi bộ.

00:17:42.000 --> 00:17:50.000
Trong ví dụ này, bạn có thể thấy rằng nó có thể dẫn bạn qua các đường phố của London, nhờ vào sức mạnh của LocationAnchors.

00:17:50.000 --> 00:17:57.000
LocationAnchors đã có sẵn ở ngày càng nhiều thành phố ở Hoa Kỳ và ở London, Vương quốc Anh.

00:17:57.000 --> 00:18:03.000
Bắt đầu từ hôm nay, chúng sẽ có mặt tại các thành phố Vancouver, Toronto và Montreal của Canada.

00:18:03.000 --> 00:18:10.000
Chúng tôi cũng đang cho phép họ ở Singapore, và ở bảy khu vực đô thị ở Nhật Bản, bao gồm cả Tokyo.

00:18:10.000 --> 00:18:14.000
Cũng như ở Melbourne và Sydney, Úc.

00:18:14.000 --> 00:18:33.000
Cuối năm nay, chúng tôi sẽ cung cấp chúng ở Auckland, New Zealand, Tel Aviv, Israel và Paris, Pháp Nếu bạn muốn biết liệu LocationAnchors có được hỗ trợ tại một tọa độ cụ thể hay không, chỉ cần sử dụng phương pháp checkAvailability của ARGeoTrackingConfiguration.

00:18:33.000 --> 00:18:37.000
Và đó là tất cả các bản cập nhật cho ARKit 6.

00:18:37.000 --> 00:18:43.000
Tóm lại, tôi đã trình bày cách chạy ARKit ở định dạng video 4K mới.

00:18:43.000 --> 00:18:51.000
Đối với các trường hợp sử dụng nâng cao, tôi đã trình bày cách bật HDR hoặc kiểm soát thủ công AVCaptureDevice.

00:18:51.000 --> 00:18:59.000
Đối với nhiều ứng dụng có nhiều điểm ảnh hơn, tôi đã trình bày cách lấy ảnh có độ phân giải cao từ phiên ARKit.

00:18:59.000 --> 00:19:07.000
Chúng tôi đã nói về hành vi mới của Plane Anchors, và tôi đã trình bày các khớp tai mới và những cải tiến khác trong MotionCapture.

00:19:07.000 --> 00:19:14.000
Bạn cũng phải biết LocationAnchors sẽ có mặt ở quốc gia nào vào cuối năm nay.

00:19:14.000 --> 00:19:15.000
Cảm ơn vì đã điều chỉnh.

00:19:15.000 --> 23:59:59.000
Chúc WWDC 2022 tuyệt vời!

