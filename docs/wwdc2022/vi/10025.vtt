WEBVTT

00:00:00.000 --> 00:00:13.000
Ron Santos: Này, hy vọng bạn khỏe. Tôi là Ron Santos, một kỹ sư đầu vào.

00:00:13.000 --> 00:00:21.000
Hôm nay tôi ở đây để nói chuyện với bạn về việc ghi lại mã và văn bản có thể đọc được bằng máy từ nguồn cấp dữ liệu video, hoặc, như chúng tôi muốn gọi nó, quét dữ liệu.

00:00:21.000 --> 00:00:24.000
Chính xác thì chúng ta có ý gì khi quét dữ liệu?

00:00:24.000 --> 00:00:29.000
Nó chỉ đơn giản là một cách sử dụng cảm biến, giống như máy ảnh, để đọc dữ liệu.

00:00:29.000 --> 00:00:32.000
Thông thường dữ liệu đó xuất hiện dưới dạng văn bản.

00:00:32.000 --> 00:00:39.000
Ví dụ, một biên lai với thông tin thú vị như số điện thoại, ngày tháng và giá cả.

00:00:39.000 --> 00:00:45.000
Hoặc có thể dữ liệu đến dưới dạng mã có thể đọc được bằng máy, giống như mã QR phổ biến.

00:00:45.000 --> 00:00:53.000
Bạn có thể đã sử dụng máy quét dữ liệu trước đây, có thể trong ứng dụng Máy ảnh hoặc bằng cách sử dụng các tính năng Văn bản Trực tiếp được giới thiệu trong iOS 15.

00:00:53.000 --> 00:00:59.000
Và tôi cá là bạn đã sử dụng các ứng dụng trong cuộc sống hàng ngày của mình với trải nghiệm quét tùy chỉnh của riêng chúng.

00:00:59.000 --> 00:01:02.000
Nhưng nếu bạn phải xây dựng máy quét dữ liệu của riêng mình thì sao?

00:01:02.000 --> 00:01:04.000
Bạn sẽ làm nó như thế nào?

00:01:04.000 --> 00:01:09.000
iOS SDK có nhiều hơn một giải pháp cho bạn, tùy thuộc vào nhu cầu của bạn.

00:01:09.000 --> 00:01:22.000
Một lựa chọn là bạn có thể sử dụng khung AVFoundation để thiết lập biểu đồ máy ảnh, kết nối đầu vào và đầu ra với một phiên và định cấu hình nó để tạo ra AVMetadataObjects như mã có thể đọc được bằng máy.

00:01:22.000 --> 00:01:30.000
Nếu bạn cũng muốn chụp văn bản, một lựa chọn khác sẽ là kết hợp cả khung AVFoundation và Vision với nhau.

00:01:30.000 --> 00:01:35.000
Trong sơ đồ này, thay vì đầu ra siêu dữ liệu, bạn tạo đầu ra dữ liệu video.

00:01:35.000 --> 00:01:47.000
Đầu ra dữ liệu video dẫn đến việc phân phối các bộ đệm mẫu có thể được đưa vào khung Vision để sử dụng với các yêu cầu nhận dạng văn bản và mã vạch, dẫn đến các đối tượng quan sát Vision.

00:01:47.000 --> 00:01:54.000
Để biết thêm về việc sử dụng Vision để quét dữ liệu, hãy xem "Trích xuất dữ liệu tài liệu bằng Vision" từ WWDC21.

00:01:54.000 --> 00:01:58.000
Được rồi, vậy đó là sử dụng AVFoundation và Vision để quét dữ liệu.

00:01:58.000 --> 00:02:03.000
Trong iOS 16, chúng tôi có một tùy chọn mới gói gọn tất cả những điều đó cho bạn.

00:02:03.000 --> 00:02:07.000
Giới thiệu DataScannerViewController trong khung VisionKit.

00:02:07.000 --> 00:02:13.000
Nó kết hợp các tính năng của AVFoundation và Vision đặc biệt cho mục đích quét dữ liệu.

00:02:13.000 --> 00:02:34.000
Người dùng DataScannerViewController được xử lý các tính năng như xem trước máy ảnh trực tiếp, nhãn hướng dẫn hữu ích, tô sáng mục, chạm để lấy nét cũng được sử dụng để lựa chọn và cuối cùng là chụm để phóng to để xem xét kỹ hơn.

00:02:34.000 --> 00:02:37.000
Và hãy nói về các tính năng cho các nhà phát triển như bạn.

00:02:37.000 --> 00:02:42.000
DataScannerViewController là một lớp con UIViewController mà bạn có thể trình bày theo cách bạn chọn.

00:02:42.000 --> 00:02:51.000
Tọa độ cho các mục được công nhận luôn nằm trong tọa độ xem, giúp bạn không chuyển đổi từ không gian hình ảnh sang tọa độ Tầm nhìn, sang tọa độ xem.

00:02:51.000 --> 00:02:59.000
Bạn cũng sẽ có thể giới hạn phần hoạt động của chế độ xem bằng cách chỉ định một khu vực quan tâm, cũng nằm trong tọa độ xem.

00:02:59.000 --> 00:03:04.000
Để nhận dạng văn bản, bạn có thể chỉ định các loại nội dung để giới hạn loại văn bản bạn tìm thấy.

00:03:04.000 --> 00:03:10.000
Và đối với các mã có thể đọc được bằng máy, bạn có thể chỉ định chính xác ký hiệu nào cần tìm kiếm.

00:03:10.000 --> 00:03:15.000
Tôi hiểu rồi; Tôi sử dụng các ứng dụng của bạn và tôi hiểu rằng quét dữ liệu chỉ là một phần nhỏ trong chức năng của chúng.

00:03:15.000 --> 00:03:18.000
Nhưng nó có thể yêu cầu rất nhiều mã.

00:03:18.000 --> 00:03:24.000
Với DataScannerViewController, mục tiêu của chúng tôi là thực hiện các nhiệm vụ phổ biến cho bạn, vì vậy bạn có thể tập trung thời gian của mình vào nơi khác.

00:03:24.000 --> 00:03:28.000
Tiếp theo, tôi sẽ hướng dẫn bạn thêm nó vào ứng dụng của bạn.

00:03:28.000 --> 00:03:31.000
Hãy bắt đầu với mô tả sử dụng quyền riêng tư.

00:03:31.000 --> 00:03:38.000
Khi các ứng dụng cố gắng quay video, iOS yêu cầu người dùng cấp quyền rõ ràng của họ để truy cập vào máy ảnh.

00:03:38.000 --> 00:03:42.000
Bạn sẽ muốn cung cấp một thông điệp mô tả biện minh cho nhu cầu của mình.

00:03:42.000 --> 00:03:48.000
Để làm điều đó, hãy thêm "quyền riêng tư - mô tả sử dụng máy ảnh" vào tệp Info.plist của ứng dụng của bạn.

00:03:48.000 --> 00:03:53.000
Hãy nhớ rằng, hãy mô tả càng nhiều càng tốt, để người dùng biết những gì họ đồng ý.

00:03:53.000 --> 00:03:55.000
Bây giờ vào mã.

00:03:55.000 --> 00:04:01.000
Bất cứ nơi nào bạn muốn trình bày máy quét dữ liệu, hãy bắt đầu bằng cách nhập VisionKit.

00:04:01.000 --> 00:04:14.000
Tiếp theo, vì tính năng quét dữ liệu không được hỗ trợ trên tất cả các thiết bị, hãy sử dụng thuộc tính lớp isSupported để ẩn bất kỳ nút hoặc menu nào hiển thị chức năng, vì vậy người dùng không được cung cấp thứ gì đó mà họ không thể sử dụng.

00:04:14.000 --> 00:04:22.000
Nếu bạn tò mò, bất kỳ thiết bị iPhone và iPad 2018 và mới hơn nào có Apple Neural Engine đều hỗ trợ quét dữ liệu.

00:04:22.000 --> 00:04:24.000
Bạn cũng sẽ muốn kiểm tra tình trạng sẵn có.

00:04:24.000 --> 00:04:27.000
Nhớ lại mô tả sử dụng quyền riêng tư?

00:04:27.000 --> 00:04:41.000
Quét có sẵn nếu người dùng chấp thuận ứng dụng để truy cập máy ảnh và nếu thiết bị không có bất kỳ hạn chế nào, như hạn chế truy cập máy ảnh được đặt ở đây, trong Hạn chế quyền riêng tư và nội dung của Screen Time.

00:04:41.000 --> 00:04:43.000
Bây giờ bạn đã sẵn sàng để cấu hình một phiên bản.

00:04:43.000 --> 00:04:47.000
Điều đó được thực hiện bằng cách trước tiên chỉ định các loại dữ liệu mà bạn quan tâm.

00:04:47.000 --> 00:04:52.000
Ví dụ, bạn có thể quét cả mã QR và văn bản.

00:04:52.000 --> 00:05:01.000
Bạn có thể tùy ý chuyển danh sách các ngôn ngữ để trình nhận dạng văn bản sử dụng làm gợi ý cho các khía cạnh xử lý khác nhau, như chỉnh sửa ngôn ngữ.

00:05:01.000 --> 00:05:04.000
Nếu bạn có ý tưởng về những ngôn ngữ mong đợi, hãy liệt kê chúng.

00:05:04.000 --> 00:05:08.000
Nó đặc biệt hữu ích khi hai ngôn ngữ có kịch bản trông giống nhau.

00:05:08.000 --> 00:05:13.000
Nếu bạn không cung cấp bất kỳ ngôn ngữ nào, ngôn ngữ ưa thích của người dùng sẽ được sử dụng theo mặc định.

00:05:13.000 --> 00:05:17.000
Bạn cũng có thể yêu cầu một loại nội dung văn bản cụ thể.

00:05:17.000 --> 00:05:20.000
Trong ví dụ này, tôi muốn máy quét của mình tìm kiếm URL.

00:05:20.000 --> 00:05:26.000
Bây giờ bạn đã nêu các loại dữ liệu cần nhận dạng, bạn có thể tạo phiên bản DataScanner của mình.

00:05:26.000 --> 00:05:33.000
Trong ví dụ trước, tôi đã chỉ định ký hiệu mã vạch, ngôn ngữ nhận dạng và loại nội dung văn bản.

00:05:33.000 --> 00:05:37.000
Hãy để tôi dành một chút thời gian để giải thích các lựa chọn khác cho từng lựa chọn đó.

00:05:37.000 --> 00:05:43.000
Đối với ký hiệu mã vạch, chúng tôi hỗ trợ tất cả các ký hiệu giống như máy dò mã vạch của Vision.

00:05:43.000 --> 00:05:50.000
Về mặt ngôn ngữ, như một phần của tính năng LiveText, DataScannerViewController hỗ trợ cùng một ngôn ngữ chính xác.

00:05:50.000 --> 00:05:55.000
Và trong iOS 16, tôi rất vui khi nói rằng chúng tôi đang thêm hỗ trợ cho tiếng Nhật và tiếng Hàn.

00:05:55.000 --> 00:05:58.000
Tất nhiên, điều này có thể thay đổi một lần nữa trong tương lai.

00:05:58.000 --> 00:06:04.000
Vì vậy, hãy sử dụng thuộc tính lớp supportedTextRecognitionLanguages để truy xuất danh sách cập nhật nhất.

00:06:04.000 --> 00:06:11.000
Cuối cùng, khi quét văn bản với ý nghĩa ngữ nghĩa cụ thể, DataScannerViewController có thể tìm thấy bảy loại này.

00:06:11.000 --> 00:06:14.000
Bây giờ chúng tôi đã sẵn sàng giới thiệu Máy quét dữ liệu cho người dùng.

00:06:14.000 --> 00:06:22.000
Trình bày nó giống như bất kỳ bộ điều khiển chế độ xem nào khác, sử dụng toàn màn hình, sử dụng một trang tính hoặc thêm nó vào một hệ thống phân cấp chế độ xem khác hoàn toàn.

00:06:22.000 --> 00:06:24.000
Tất cả tùy thuộc vào bạn.

00:06:24.000 --> 00:06:29.000
Sau đó, khi bản trình bày hoàn tất, hãy gọi startScanning() để bắt đầu tìm kiếm dữ liệu.

00:06:29.000 --> 00:06:35.000
Vì vậy, bây giờ tôi muốn lùi lại một bước và dành thời gian xem xét các thông số khởi tạo của Data Scanner.

00:06:35.000 --> 00:06:38.000
Tôi đã sử dụng một cái ở đây, recognizedDataTypes.

00:06:38.000 --> 00:06:43.000
Nhưng có những người khác có thể giúp bạn tùy chỉnh trải nghiệm của mình.

00:06:43.000 --> 00:06:44.000
Hãy xem qua từng cái một.

00:06:44.000 --> 00:06:49.000
recognizedDataTypes cho phép bạn chỉ định loại dữ liệu cần nhận dạng.

00:06:49.000 --> 00:06:52.000
Văn bản, mã có thể đọc được bằng máy và loại nào của mỗi loại.

00:06:52.000 --> 00:06:56.000
Mức chất lượng có thể cân bằng, nhanh chóng hoặc chính xác.

00:06:56.000 --> 00:07:04.000
Fast sẽ hy sinh độ phân giải để ủng hộ tốc độ trong các tình huống mà bạn mong đợi các mục lớn và dễ đọc, như văn bản trên bảng hiệu.

00:07:04.000 --> 00:07:11.000
Chính xác sẽ cung cấp cho bạn độ chính xác tốt nhất, ngay cả với các mặt hàng nhỏ như mã QR siêu nhỏ hoặc số sê-ri nhỏ.

00:07:11.000 --> 00:07:15.000
Tôi khuyên bạn nên bắt đầu với cân bằng, điều này sẽ hoạt động tốt cho hầu hết các trường hợp.

00:07:15.000 --> 00:07:23.000
recognizesMultipleItems cung cấp cho bạn tùy chọn tìm kiếm một hoặc nhiều mục trong khung, chẳng hạn như nếu bạn muốn quét nhiều mã vạch cùng một lúc.

00:07:23.000 --> 00:07:29.000
Khi nó sai, mục trung tâm nhiều nhất được nhận dạng theo mặc định cho đến khi người dùng nhấn vào nơi khác.

00:07:29.000 --> 00:07:33.000
Bật tính năng theo dõi tốc độ khung hình cao khi bạn vẽ các điểm nổi bật.

00:07:33.000 --> 00:07:39.000
Nó cho phép các điểm nổi bật theo dõi các mục càng gần càng tốt khi máy ảnh di chuyển hoặc cảnh thay đổi.

00:07:39.000 --> 00:07:43.000
Bật pinch-to-zoom hoặc vô hiệu hóa nó.

00:07:43.000 --> 00:07:47.000
Chúng tôi cũng có các phương pháp bạn có thể sử dụng để tự sửa đổi mức thu phóng.

00:07:47.000 --> 00:07:52.000
Khi bạn bật hướng dẫn, nhãn sẽ hiển thị ở đầu màn hình để giúp hướng dẫn người dùng.

00:07:52.000 --> 00:08:00.000
Và, cuối cùng, bạn có thể bật tính năng tô sáng hệ thống nếu bạn cần hoặc bạn có thể tắt nó để vẽ tô sáng tùy chỉnh của riêng bạn.

00:08:00.000 --> 00:08:08.000
Bây giờ bạn đã biết cách trình bày trình quét dữ liệu, hãy nói về cách bạn nhập các mục được nhận dạng và cả cách bạn vẽ các điểm nổi bật tùy chỉnh của riêng mình.

00:08:08.000 --> 00:08:12.000
Đầu tiên, cung cấp một đại diện cho máy quét dữ liệu.

00:08:12.000 --> 00:08:20.000
Bây giờ bạn đã có một đại diện, bạn có thể triển khai phương thức dataScanner didTapOn, được gọi khi người dùng nhấn vào một mục.

00:08:20.000 --> 00:08:24.000
Với nó, bạn sẽ nhận được một phiên bản của loại RecognizeItem mới này.

00:08:24.000 --> 00:08:29.000
RecognizedItem là một enum chứa văn bản hoặc mã vạch như một giá trị liên quan.

00:08:29.000 --> 00:08:33.000
Đối với văn bản, thuộc tính phiên âm giữ chuỗi được nhận dạng.

00:08:33.000 --> 00:08:39.000
Đối với mã vạch, nếu tải trọng của nó chứa một chuỗi, bạn có thể truy xuất nó bằng payloadStringValue.

00:08:39.000 --> 00:08:48.000
Hai điều khác bạn nên biết về RecognizedItem: Đầu tiên, mỗi mặt hàng được công nhận có một mã định danh duy nhất mà bạn có thể sử dụng để theo dõi một mặt hàng trong suốt vòng đời của nó.

00:08:48.000 --> 00:08:54.000
Vòng đời đó bắt đầu khi vật phẩm được nhìn thấy lần đầu tiên và kết thúc khi nó không còn trong tầm nhìn.

00:08:54.000 --> 00:08:57.000
Và thứ hai, mỗi RecognizedItem có một thuộc tính giới hạn.

00:08:57.000 --> 00:09:01.000
Giới hạn không phải là một rect, nhưng nó bao gồm bốn điểm, một cho mỗi góc.

00:09:01.000 --> 00:09:07.000
Tiếp theo, hãy nói về ba phương thức đại diện liên quan được gọi khi các mục được nhận dạng trong cảnh thay đổi.

00:09:07.000 --> 00:09:12.000
Đầu tiên là didAdd, được gọi khi các mục trong cảnh mới được nhận dạng.

00:09:12.000 --> 00:09:18.000
Nếu bạn muốn tạo điểm nổi bật tùy chỉnh của riêng mình, bạn sẽ tạo một điểm ở đây cho mỗi mục mới.

00:09:18.000 --> 00:09:23.000
Bạn có thể theo dõi các điểm nổi bật bằng cách sử dụng ID từ mục liên quan của nó.

00:09:23.000 --> 00:09:35.000
Và khi thêm chế độ xem mới của bạn vào hệ thống phân cấp chế độ xem, hãy thêm chúng vào lớp phủ của DataScannerContainerView, để chúng xuất hiện phía trên bản xem trước máy ảnh, nhưng bên dưới bất kỳ chrome bổ sung nào khác.

00:09:35.000 --> 00:09:40.000
Phương thức đại diện tiếp theo là didUpdate, được gọi khi các mục di chuyển hoặc máy ảnh di chuyển.

00:09:40.000 --> 00:09:44.000
Nó cũng có thể được gọi khi phiên âm để thay đổi văn bản được công nhận.

00:09:44.000 --> 00:09:50.000
Chúng thay đổi vì máy quét nhìn thấy văn bản càng lâu thì nó sẽ càng chính xác hơn với phiên âm của nó.

00:09:50.000 --> 00:10:00.000
Sử dụng ID từ các mục được cập nhật để truy xuất các điểm nổi bật của bạn từ từ từ điển bạn vừa tạo, và sau đó tạo hiệu ứng động cho các chế độ xem theo giới hạn mới được cập nhật của chúng.

00:10:00.000 --> 00:10:07.000
Và cuối cùng, phương thức ủy quyền didRemove, được gọi khi các mục không còn hiển thị trong cảnh.

00:10:07.000 --> 00:10:15.000
Trong phương pháp này, bạn có thể quên đi bất kỳ chế độ xem nổi bật nào mà bạn đã liên kết với các mục đã xóa và bạn có thể xóa chúng khỏi hệ thống phân cấp chế độ xem.

00:10:15.000 --> 00:10:26.000
Tóm lại, nếu bạn vẽ các điểm nổi bật của riêng mình trên các mục, ba phương pháp ủy quyền đó sẽ rất quan trọng để bạn kiểm soát các điểm nổi bật hoạt hình vào cảnh, tạo hoạt ảnh chuyển động của chúng và tạo hoạt ảnh cho chúng.

00:10:26.000 --> 00:10:33.000
Và đối với mỗi phương thức trong số ba phương thức đại diện trước đó, bạn cũng sẽ được cung cấp một mảng của tất cả các mục hiện được công nhận.

00:10:33.000 --> 00:10:45.000
Điều đó có thể hữu ích cho việc nhận dạng văn bản vì các mục được đặt theo thứ tự đọc tự nhiên của chúng, có nghĩa là người dùng sẽ đọc mục ở chỉ mục 0 trước mục ở chỉ mục 1, v.v.

00:10:45.000 --> 00:10:48.000
Đó là tổng quan về cách sử dụng DataScannerViewController.

00:10:48.000 --> 00:10:55.000
Trước khi kết thúc, tôi muốn nhanh chóng đề cập đến một vài tính năng khác, như chụp ảnh.

00:10:55.000 --> 00:11:02.000
Bạn có thể gọi phương thức capturePhoto, phương thức này sẽ trả về UIImage chất lượng cao một cách không đồng bộ.

00:11:02.000 --> 00:11:07.000
Và nếu bạn không tạo các điểm nổi bật tùy chỉnh, bạn có thể không cần ba phương thức ủy quyền này.

00:11:07.000 --> 00:11:10.000
Thay vào đó, bạn có thể sử dụng thuộc tính recognizedItem.

00:11:10.000 --> 00:11:17.000
Đó là một AsyncStream sẽ được cập nhật liên tục khi cảnh thay đổi.

00:11:17.000 --> 00:11:19.000
Cảm ơn vì đã đi chơi.

00:11:19.000 --> 00:11:26.000
Hãy nhớ rằng, iOS SDK cung cấp cho bạn các tùy chọn để tạo quy trình làm việc thị giác máy tính với các khung AVFoundation và Vision.

00:11:26.000 --> 00:11:36.000
Nhưng có thể bạn đang tạo một ứng dụng quét văn bản hoặc mã có thể đọc được bằng máy bằng nguồn cấp dữ liệu video trực tiếp, như ứng dụng Pick-and-pack, ứng dụng back-of-the-warehouse hoặc ứng dụng điểm bán hàng.

00:11:36.000 --> 00:11:40.000
Nếu vậy, hãy xem qua DataScannerViewController trong VisionKit.

00:11:40.000 --> 00:11:50.000
Như tôi đã xem qua hôm nay, nó có một số thông số khởi tạo và phương pháp ủy quyền mà bạn có thể sử dụng để cung cấp trải nghiệm tùy chỉnh phù hợp với phong cách và nhu cầu của ứng dụng của bạn.

00:11:50.000 --> 00:12:01.000
Và cuối cùng, tôi muốn hét lên với phiên "Thêm tương tác Văn bản Trực tiếp vào ứng dụng của bạn", nơi bạn có thể tìm hiểu về khả năng Văn bản Trực tiếp của VisionKit cho hình ảnh tĩnh.

00:12:01.000 --> 00:12:03.000
Cho đến lần sau, bình yên.

00:12:03.000 --> 23:59:59.000
.

