WEBVTT

00:00:00.000 --> 00:00:09.000
♪ nhạc cụ hip hop ♪

00:00:09.000 --> 00:00:14.000
Xin chào, và chào mừng đến với "Khám phá những tiến bộ trong việc chụp ảnh iOS".

00:00:14.000 --> 00:00:20.000
Tôi là Nikolas Gelo từ nhóm Phần mềm Máy ảnh, và tôi sẽ giới thiệu một số tính năng máy ảnh mới thú vị trong iOS và iPadOS.

00:00:20.000 --> 00:00:25.000
Tôi sẽ bắt đầu với cách truyền độ sâu từ Máy quét LiDAR bằng AVFoundation.

00:00:25.000 --> 00:00:31.000
Tiếp theo, hãy xem ứng dụng của bạn sẽ nhận được kết xuất khuôn mặt được cải thiện như thế nào với tính năng lấy nét tự động điều khiển bằng khuôn mặt và phơi sáng tự động.

00:00:31.000 --> 00:00:36.000
Sau đó, tôi sẽ đưa bạn qua các cấu hình phát trực tuyến AVCaptureSession nâng cao.

00:00:36.000 --> 00:00:41.000
Và cuối cùng, tôi sẽ chỉ cho bạn cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi đa nhiệm.

00:00:41.000 --> 00:00:45.000
Tôi sẽ bắt đầu với cách truyền độ sâu từ Máy quét LiDAR bằng AVFoundation.

00:00:45.000 --> 00:00:53.000
iPhone 12 Pro, iPhone 13 Pro và iPad Pro được trang bị Máy quét LiDAR có khả năng xuất bản đồ độ sâu dày đặc.

00:00:53.000 --> 00:01:00.000
Máy quét LiDAR hoạt động bằng cách chụp ánh sáng vào môi trường xung quanh, và sau đó thu thập ánh sáng phản xạ từ các bề mặt trong cảnh.

00:01:00.000 --> 00:01:07.000
Độ sâu được ước tính bằng cách đo thời gian cần thiết để ánh sáng đi từ LiDAR đến môi trường và phản xạ trở lại máy quét.

00:01:07.000 --> 00:01:11.000
Toàn bộ quá trình này chạy hàng triệu lần mỗi giây.

00:01:11.000 --> 00:01:14.000
Tôi sẽ chỉ cho bạn Máy quét LiDAR đang hoạt động bằng AVFoundation.

00:01:14.000 --> 00:01:20.000
Ở đây trên iPhone 13 Pro Max, tôi đang chạy một ứng dụng sử dụng LiDAR Depth Camera AVCaptureDevice mới.

00:01:20.000 --> 00:01:24.000
Ứng dụng hiển thị dữ liệu độ sâu phát trực tuyến trên nguồn cấp dữ liệu camera trực tiếp.

00:01:24.000 --> 00:01:29.000
Màu xanh lam được hiển thị cho các vật thể ở gần và màu đỏ cho các vật thể ở xa hơn.

00:01:29.000 --> 00:01:33.000
Và sử dụng thanh trượt, tôi có thể điều chỉnh độ mờ của độ sâu.

00:01:33.000 --> 00:01:36.000
Ứng dụng này cũng chụp ảnh với bản đồ độ sâu độ phân giải cao.

00:01:36.000 --> 00:01:42.000
Khi tôi chụp ảnh, lớp phủ độ sâu tương tự được áp dụng nhưng với độ phân giải thậm chí còn lớn hơn cho ảnh tĩnh.

00:01:42.000 --> 00:01:45.000
Ứng dụng này có thêm một mẹo nữa.

00:01:45.000 --> 00:01:52.000
Khi tôi nhấn nút ngọn đuốc, ứng dụng sử dụng bản đồ độ sâu độ phân giải cao với hình ảnh màu để hiển thị ánh sáng trên hiện trường bằng RealityKit.

00:01:52.000 --> 00:01:57.000
Tôi có thể chạm xung quanh và hướng ánh đèn sân khấu vào các vật thể khác nhau trong cảnh.

00:01:57.000 --> 00:01:59.000
Hãy nhìn cách ánh đèn sân khấu làm nổi bật cây đàn guitar.

00:01:59.000 --> 00:02:04.000
Hoặc nếu tôi chạm vào đúng vị trí ở góc tường, đèn chiếu sáng tạo thành hình trái tim.

00:02:04.000 --> 00:02:09.000
Hãy quay lại với cây đàn guitar đó. Nó trông thật ngầu.

00:02:09.000 --> 00:02:14.000
API cho Máy quét LiDAR lần đầu tiên được giới thiệu trong ARKit trong iPadOS 13.4.

00:02:14.000 --> 00:02:21.000
Nếu bạn chưa xem bài thuyết trình WWDC 2020 "Khám phá ARKit 4", tôi khuyến khích bạn xem nó.

00:02:21.000 --> 00:02:26.000
Mới trong iOS 15.4, ứng dụng của bạn có thể truy cập Máy quét LiDAR với AVFoundation.

00:02:26.000 --> 00:02:33.000
Chúng tôi đã giới thiệu một loại thiết bị AVCapture mới, Camera độ sâu LiDAR tích hợp, cung cấp video và chiều sâu.

00:02:33.000 --> 00:02:36.000
Nó tạo ra thông tin độ sâu chất lượng cao, độ chính xác cao.

00:02:36.000 --> 00:02:43.000
AVCaptureDevice mới này sử dụng camera góc rộng phía sau để cung cấp video với Máy quét LiDAR để ghi lại độ sâu.

00:02:43.000 --> 00:02:47.000
Cả video và độ sâu đều được ghi lại trong trường nhìn của máy ảnh góc rộng.

00:02:47.000 --> 00:02:53.000
Và giống như TrueDepth AVCaptureDevice, tất cả các định dạng của nó đều hỗ trợ phân phối dữ liệu độ sâu.

00:02:53.000 --> 00:03:02.000
AVCaptureDevice mới này tạo ra dữ liệu độ sâu chất lượng cao bằng cách kết hợp đầu ra thưa thớt từ Máy quét LiDAR với hình ảnh màu từ camera góc rộng quay mặt về phía sau.

00:03:02.000 --> 00:03:08.000
LiDAR và đầu vào màu sắc được xử lý bằng cách sử dụng mô hình học máy xuất ra bản đồ độ sâu dày đặc.

00:03:08.000 --> 00:03:17.000
Bởi vì Máy ảnh Độ sâu LiDAR sử dụng máy ảnh góc rộng quay mặt về phía sau, máy ảnh Telephoto và Ultra Wide có thể được sử dụng cùng với AVCaptureMultiCamSession.

00:03:17.000 --> 00:03:20.000
Điều này hữu ích cho các ứng dụng muốn sử dụng nhiều máy ảnh cùng một lúc.

00:03:20.000 --> 00:03:32.000
Máy ảnh độ sâu LiDAR hiển thị nhiều định dạng, từ độ phân giải video 640 x 480 đến hình ảnh 12 megapixel đầy đủ ở 4032 x 3024.

00:03:32.000 --> 00:03:36.000
Trong khi phát trực tuyến, nó có thể xuất bản đồ độ sâu lên đến 320 x 240.

00:03:36.000 --> 00:03:43.000
Và để chụp ảnh, bạn có thể nhận bản đồ độ sâu 768 x 576.

00:03:43.000 --> 00:03:47.000
Lưu ý, độ phân giải độ sâu hơi khác nhau đối với các định dạng 16 x 9 và 4 x 3.

00:03:47.000 --> 00:03:51.000
Điều này phù hợp với tỷ lệ khung hình của video.

00:03:51.000 --> 00:03:58.000
Máy ảnh độ sâu LiDAR AVCaptureDevice có sẵn trên iPhone 12 Pro, iPhone 13 Pro và iPad Pro thế hệ thứ 5.

00:03:58.000 --> 00:04:03.000
iPhone 13 Pro có thể cung cấp dữ liệu độ sâu bằng cách sử dụng kết hợp camera phía sau.

00:04:03.000 --> 00:04:09.000
AVFoundation Capture API gọi đây là "thiết bị ảo" bao gồm các thiết bị vật lý.

00:04:09.000 --> 00:04:20.000
Ở mặt sau của iPhone 13 Pro, có bốn AVCaptureDevice ảo có sẵn để sử dụng: Máy ảnh độ sâu LiDAR mới sử dụng Máy quét LiDAR với máy ảnh góc rộng.

00:04:20.000 --> 00:04:24.000
Máy ảnh kép sử dụng máy ảnh rộng và máy ảnh tele.

00:04:24.000 --> 00:04:28.000
Camera rộng kép, sử dụng camera rộng và siêu rộng.

00:04:28.000 --> 00:04:33.000
Và Triple Camera, sử dụng máy ảnh Wide, Ultra Wide, và Telephoto.

00:04:33.000 --> 00:04:37.000
Có sự khác biệt về loại độ sâu mà các thiết bị này tạo ra.

00:04:37.000 --> 00:04:45.000
Máy ảnh độ sâu LiDAR tạo ra "độ sâu tuyệt đối". Thời gian của kỹ thuật bay được sử dụng cho phép tính toán quy mô trong thế giới thực.

00:04:45.000 --> 00:04:49.000
Ví dụ, điều này rất tốt cho các tác vụ thị giác máy tính như đo lường.

00:04:49.000 --> 00:04:56.000
Máy ảnh TrueDepth, Dual, Dual Wide và Triple tạo ra độ sâu tương đối, dựa trên sự chênh lệch.

00:04:56.000 --> 00:05:00.000
Điều này sử dụng ít năng lượng hơn và rất tốt cho các ứng dụng hiển thị hiệu ứng ảnh.

00:05:00.000 --> 00:05:04.000
AVFoundation đại diện cho chiều sâu bằng cách sử dụng lớp AVDepthData.

00:05:04.000 --> 00:05:13.000
Lớp này có bộ đệm pixel chứa độ sâu với các thuộc tính khác mô tả nó, bao gồm kiểu dữ liệu độ sâu, độ chính xác và liệu nó có được lọc hay không.

00:05:13.000 --> 00:05:18.000
Nó được cung cấp bởi một AVCaptureDevice có khả năng sâu, giống như Máy ảnh Độ sâu LiDAR mới.

00:05:18.000 --> 00:05:25.000
Bạn có thể truyền độ sâu từ AVCaptureDepthDataOutput hoặc nhận độ sâu đính kèm với ảnh từ AVCapturePhotoOutput.

00:05:25.000 --> 00:05:27.000
Dữ liệu độ sâu được lọc theo mặc định.

00:05:27.000 --> 00:05:32.000
Lọc làm giảm nhiễu và lấp đầy các giá trị bị thiếu, hoặc các lỗ hổng, trong bản đồ độ sâu.

00:05:32.000 --> 00:05:39.000
Điều này rất tốt cho các ứng dụng video và nhiếp ảnh, vì vậy các hiện vật không xuất hiện khi sử dụng bản đồ độ sâu để áp dụng các hiệu ứng trên hình ảnh màu.

00:05:39.000 --> 00:05:46.000
Tuy nhiên, các ứng dụng thị giác máy tính nên ưu tiên dữ liệu độ sâu không được lọc để bảo toàn các giá trị ban đầu trong bản đồ độ sâu.

00:05:46.000 --> 00:05:51.000
Khi bộ lọc bị vô hiệu hóa, Máy ảnh Độ sâu LiDAR loại trừ các điểm tin cậy thấp.

00:05:51.000 --> 00:06:03.000
Để vô hiệu hóa tính năng lọc dữ liệu độ sâu, hãy đặt thuộc tính isFilteringEnabled trên AVCaptureDepthDataOutput của bạn thành sai và khi bạn nhận được đối tượng AVDepthData từ cuộc gọi lại đại diện của mình, nó sẽ không được lọc.

00:06:03.000 --> 00:06:14.000
Vì ARKit đã cung cấp quyền truy cập vào Máy quét LiDAR, bạn có thể hỏi, "AVFoundation so sánh như thế nào?" AVFoundation được thiết kế cho các ứng dụng video và nhiếp ảnh.

00:06:14.000 --> 00:06:20.000
Với AVFoundation, bạn có thể nhúng dữ liệu độ sâu được chụp bằng Máy quét LiDAR vào các bức ảnh có độ phân giải cao.

00:06:20.000 --> 00:06:24.000
ARKit phù hợp nhất cho các ứng dụng thực tế tăng cường, như tên cho thấy.

00:06:24.000 --> 00:06:31.000
Với Máy quét LiDAR, ARKit có khả năng cung cấp các tính năng như hình học cảnh và vị trí đối tượng.

00:06:31.000 --> 00:06:36.000
AVFoundation có thể cung cấp video có độ phân giải cao tuyệt vời để quay phim và chụp ảnh.

00:06:36.000 --> 00:06:42.000
Máy ảnh độ sâu LiDAR của AVFoundation có thể xuất độ sâu lên đến 768 x 576.

00:06:42.000 --> 00:06:47.000
Cái này lớn hơn gấp đôi độ phân giải độ sâu 256 x 192 của ARKit.

00:06:47.000 --> 00:06:55.000
ARKit sử dụng bản đồ độ sâu độ phân giải thấp hơn, vì vậy nó có thể áp dụng các thuật toán thực tế tăng cường cho các tính năng của nó.

00:06:55.000 --> 00:07:05.000
Để biết thêm thông tin "chuyên sâu" về cách sử dụng AVFoundation để thu thập dữ liệu độ sâu, hãy xem phiên trước của chúng tôi "Chụp chiều sâu trong chụp ảnh iPhone" từ WWDC 2017.

00:07:05.000 --> 00:07:10.000
Chúng tôi rất vui khi thấy những cách thú vị mà bạn có thể sử dụng Máy ảnh Độ sâu LiDAR trong ứng dụng của mình.

00:07:10.000 --> 00:07:18.000
Tiếp theo, tôi sẽ thảo luận về cách cải tiến hệ thống lấy nét tự động và phơi sáng tự động giúp cải thiện khả năng hiển thị của khuôn mặt trong cảnh cho ứng dụng của bạn.

00:07:18.000 --> 00:07:23.000
Hệ thống lấy nét tự động và phơi sáng tự động phân tích cảnh để chụp được hình ảnh đẹp nhất.

00:07:23.000 --> 00:07:33.000
Hệ thống lấy nét tự động điều chỉnh ống kính để giữ cho đối tượng lấy nét và hệ thống phơi sáng tự động cân bằng các vùng sáng nhất và tối nhất của cảnh để giữ cho đối tượng có thể nhìn thấy được.

00:07:33.000 --> 00:07:38.000
Tuy nhiên, đôi khi các điều chỉnh tự động được thực hiện không giữ cho khuôn mặt của đối tượng của bạn được lấy nét.

00:07:38.000 --> 00:07:44.000
Và những lần khác, khuôn mặt của đối tượng có thể khó nhìn thấy với những cảnh có đèn nền sáng.

00:07:44.000 --> 00:07:52.000
Một tính năng phổ biến của máy ảnh DSLR và các máy ảnh chuyên nghiệp khác là theo dõi khuôn mặt trong cảnh để tự động điều chỉnh tiêu cự và độ phơi sáng để giữ cho chúng có thể nhìn thấy được.

00:07:52.000 --> 00:07:58.000
Mới trong iOS 15.4, hệ thống lấy nét và phơi sáng sẽ ưu tiên các khuôn mặt.

00:07:58.000 --> 00:08:04.000
Chúng tôi thích những lợi ích của điều này đến nỗi chúng tôi đã bật nó theo mặc định cho tất cả các ứng dụng được liên kết trên iOS 15.4 trở lên.

00:08:04.000 --> 00:08:07.000
Tôi sẽ chỉ cho bạn một số ví dụ.

00:08:07.000 --> 00:08:13.000
Nếu không có tính năng lấy nét tự động điều khiển bằng khuôn mặt, máy ảnh vẫn lấy nét trên nền mà không lấy nét lại vào khuôn mặt.

00:08:13.000 --> 00:08:14.000
Xem lại lần nữa.

00:08:14.000 --> 00:08:19.000
Hãy nhìn xem khuôn mặt của anh ấy vẫn mất nét như thế nào khi anh ấy quay lại và những cái cây ở hậu cảnh vẫn sắc nét.

00:08:19.000 --> 00:08:23.000
Khi bật tính năng lấy nét tự động điều khiển bằng khuôn mặt, bạn có thể nhìn rõ khuôn mặt của anh ấy.

00:08:23.000 --> 00:08:28.000
Và khi anh ấy quay đi, máy ảnh sẽ chuyển tiêu điểm sang hậu cảnh.

00:08:28.000 --> 00:08:32.000
Khi chúng tôi so sánh các video cạnh nhau, sự khác biệt là rõ ràng.

00:08:32.000 --> 00:08:37.000
Ở bên phải với tính năng lấy nét tự động điều khiển bằng khuôn mặt, bạn có thể thấy các chi tiết nhỏ hơn trên bộ râu của anh ấy.

00:08:37.000 --> 00:08:42.000
Với những cảnh có đèn nền sáng, có thể là một thách thức để giữ cho khuôn mặt được phơi sáng tốt.

00:08:42.000 --> 00:08:48.000
Nhưng với hệ thống phơi sáng tự động ưu tiên khuôn mặt, chúng ta có thể dễ dàng nhìn thấy anh ấy.

00:08:48.000 --> 00:08:52.000
So sánh cạnh nhau, chúng ta có thể thấy sự khác biệt ở đây một lần nữa.

00:08:52.000 --> 00:08:57.000
Lưu ý rằng bằng cách giữ cho khuôn mặt của anh ấy được phơi sáng tốt trong bức ảnh bên phải, những cái cây ở hậu cảnh trông sáng hơn.

00:08:57.000 --> 00:08:59.000
Và bầu trời cũng vậy.

00:08:59.000 --> 00:09:04.000
Độ phơi sáng của toàn bộ cảnh được điều chỉnh khi ưu tiên khuôn mặt.

00:09:04.000 --> 00:09:11.000
Trong iOS 15.4, có các thuộc tính mới trên AVCaptureDevice để kiểm soát khi tính năng lấy nét tự động điều khiển bằng khuôn mặt và phơi sáng tự động được bật.

00:09:11.000 --> 00:09:17.000
Bạn có thể kiểm soát xem thiết bị có "tự động điều chỉnh" các cài đặt này hay không và quyết định khi nào nó sẽ được bật.

00:09:17.000 --> 00:09:23.000
Trước khi chuyển đổi các thuộc tính "isEnabled", trước tiên bạn phải tắt tính năng điều chỉnh tự động.

00:09:23.000 --> 00:09:26.000
Việc kích hoạt tự động hành vi này rất tốt cho các ứng dụng chụp ảnh.

00:09:26.000 --> 00:09:28.000
Nó được sử dụng bởi ứng dụng Máy ảnh của Apple.

00:09:28.000 --> 00:09:32.000
Nó cũng tuyệt vời cho các ứng dụng hội nghị truyền hình để giữ khuôn mặt hiển thị trong các cuộc gọi.

00:09:32.000 --> 00:09:40.000
FaceTime tận dụng điều này, nhưng đôi khi nó không phù hợp nhất cho một ứng dụng để có hệ thống lấy nét tự động và phơi sáng tự động được điều khiển bởi các khuôn mặt.

00:09:40.000 --> 00:09:48.000
Ví dụ: nếu bạn muốn ứng dụng của mình cung cấp cho hướng dẫn sử dụng quyền kiểm soát đối với hình ảnh đã chụp, bạn có thể cân nhắc tắt nó đi.

00:09:48.000 --> 00:09:53.000
Nếu bạn quyết định lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động không phù hợp với ứng dụng của mình, bạn có thể chọn không tham gia hành vi này.

00:09:53.000 --> 00:09:56.000
Đầu tiên, khóa AVCaptureDevice để cấu hình.

00:09:56.000 --> 00:10:02.000
Sau đó, tắt tính năng tự động điều chỉnh lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động.

00:10:02.000 --> 00:10:05.000
Tiếp theo, vô hiệu hóa tính năng lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động.

00:10:05.000 --> 00:10:10.000
Và cuối cùng, mở khóa thiết bị để cấu hình.

00:10:10.000 --> 00:10:18.000
Tôi sẽ nói về cách bạn có thể sử dụng các cấu hình phát trực tuyến nâng cao để nhận dữ liệu âm thanh và video phù hợp với nhu cầu ứng dụng của bạn.

00:10:18.000 --> 00:10:23.000
AVFoundation Capture API cho phép các nhà phát triển xây dựng các ứng dụng nhập vai bằng máy ảnh.

00:10:23.000 --> 00:10:33.000
AVCaptureSession quản lý luồng dữ liệu từ các đầu vào như máy ảnh và micrô được kết nối với AVCaptureOutputs, có thể cung cấp video, âm thanh, ảnh và hơn thế nữa.

00:10:33.000 --> 00:10:40.000
Hãy lấy một trường hợp sử dụng ứng dụng máy ảnh phổ biến làm ví dụ: Áp dụng các hiệu ứng tùy chỉnh như bộ lọc hoặc lớp phủ cho video đã quay.

00:10:40.000 --> 00:10:51.000
Một ứng dụng như thế này sẽ có: Một AVCaptureSession với hai đầu vào, một máy ảnh và một micrô, được kết nối với hai đầu ra, một cho dữ liệu video và một cho dữ liệu âm thanh.

00:10:51.000 --> 00:11:00.000
Dữ liệu video sau đó có các hiệu ứng được áp dụng và video được xử lý được gửi đến hai nơi, đến bản xem trước video và AVAssetWriter để ghi.

00:11:00.000 --> 00:11:03.000
Dữ liệu âm thanh cũng được gửi đến AVAssetWriter.

00:11:03.000 --> 00:11:10.000
Tính năng mới trong iOS 16 và iPadOS 16, các ứng dụng có thể sử dụng nhiều AVCaptureVideoDataOutputs cùng một lúc.

00:11:10.000 --> 00:11:19.000
Đối với mỗi đầu ra dữ liệu video, bạn có thể tùy chỉnh độ phân giải, ổn định, định hướng và định dạng pixel.

00:11:19.000 --> 00:11:21.000
Hãy quay lại ứng dụng máy ảnh ví dụ.

00:11:21.000 --> 00:11:25.000
Có những yêu cầu chụp ảnh cạnh tranh mà ứng dụng này đang cân bằng.

00:11:25.000 --> 00:11:31.000
Ứng dụng muốn hiển thị bản xem trước video trực tiếp của nội dung được quay và quay video chất lượng cao để phát lại sau này.

00:11:31.000 --> 00:11:36.000
Để xem trước, độ phân giải cần phải đủ lớn cho màn hình của thiết bị.

00:11:36.000 --> 00:11:39.000
Và quá trình xử lý cần phải đủ nhanh để xem trước độ trễ thấp.

00:11:39.000 --> 00:11:44.000
Nhưng khi ghi âm, tốt nhất là chụp ở độ phân giải cao với các hiệu ứng chất lượng được áp dụng.

00:11:44.000 --> 00:11:50.000
Với khả năng thêm AVCaptureVideoDataOutput thứ hai, biểu đồ chụp có thể được mở rộng.

00:11:50.000 --> 00:11:54.000
Bây giờ đầu ra dữ liệu video có thể được tối ưu hóa.

00:11:54.000 --> 00:12:01.000
Một đầu ra có thể cung cấp bộ đệm nhỏ hơn để xem trước và đầu kia có thể cung cấp bộ đệm 4K kích thước đầy đủ để ghi.

00:12:01.000 --> 00:12:11.000
Ngoài ra, ứng dụng có thể hiển thị một phiên bản hiệu ứng đơn giản hơn, hiệu quả hơn trên các bộ đệm xem trước nhỏ hơn và dự trữ các hiệu ứng chất lượng cao cho các bộ đệm kích thước đầy đủ khi ghi.

00:12:11.000 --> 00:12:17.000
Bây giờ ứng dụng không còn phải thỏa hiệp xem trước hoặc quay video của nó nữa.

00:12:17.000 --> 00:12:24.000
Một lý do khác để sử dụng đầu ra dữ liệu video riêng biệt để xem trước và ghi âm là áp dụng các chế độ ổn định khác nhau.

00:12:24.000 --> 00:12:28.000
Ổn định video giới thiệu độ trễ bổ sung cho đường ống quay video.

00:12:28.000 --> 00:12:34.000
Để xem trước, độ trễ là không mong muốn, vì độ trễ đáng chú ý khiến việc nắm bắt nội dung trở nên khó khăn.

00:12:34.000 --> 00:12:38.000
Để ghi âm, tính năng ổn định có thể được áp dụng để có trải nghiệm tốt hơn khi xem video sau này.

00:12:38.000 --> 00:12:48.000
Vì vậy, bạn không thể áp dụng tính năng ổn định trên một đầu ra dữ liệu video để xem trước độ trễ thấp và áp dụng tính năng ổn định cho đầu ra còn lại để phát lại sau.

00:12:48.000 --> 00:12:52.000
Có nhiều cách để định cấu hình độ phân giải đầu ra dữ liệu video của bạn.

00:12:52.000 --> 00:12:58.000
Đối với đầu ra kích thước đầy đủ, trước tiên, hãy tắt cấu hình tự động của kích thước bộ đệm đầu ra.

00:12:58.000 --> 00:13:02.000
Sau đó vô hiệu hóa việc phân phối bộ đệm đầu ra có kích thước xem trước.

00:13:02.000 --> 00:13:08.000
Tuy nhiên, trong hầu hết các trường hợp, đầu ra dữ liệu video đã được định cấu hình cho đầu ra kích thước đầy đủ.

00:13:08.000 --> 00:13:16.000
Đối với đầu ra có kích thước xem trước, một lần nữa, hãy tắt cấu hình tự động, nhưng thay vào đó, cho phép phân phối bộ đệm đầu ra có kích thước xem trước.

00:13:16.000 --> 00:13:21.000
Điều này được bật theo mặc định khi sử dụng ảnh AVCaptureSessionPreset.

00:13:21.000 --> 00:13:27.000
Để yêu cầu độ phân giải tùy chỉnh, hãy chỉ định chiều rộng và chiều cao trong từ điển cài đặt video của đầu ra.

00:13:27.000 --> 00:13:32.000
Tỷ lệ khung hình của chiều rộng và chiều cao phải khớp với tỷ lệ khung hình của Định dạng hoạt động của thiết bị nguồn.

00:13:32.000 --> 00:13:35.000
Có nhiều cách hơn để định cấu hình đầu ra dữ liệu video của bạn.

00:13:35.000 --> 00:13:43.000
Để áp dụng tính năng ổn định, hãy đặt tính năng ổn định ưa thích ở chế độ như điện ảnh mở rộng, tạo ra các video tuyệt vời để xem.

00:13:43.000 --> 00:13:47.000
Bạn có thể thay đổi hướng để nhận bộ đệm là chân dung.

00:13:47.000 --> 00:13:53.000
Và bạn có thể chỉ định định dạng pixel, để nhận bộ đệm YUV không mất dữ liệu 10-bit.

00:13:53.000 --> 00:14:01.000
Để biết thêm thông tin về việc chọn định dạng pixel cho AVCaptureVideoDataOutput, hãy xem Technote 3121.

00:14:01.000 --> 00:14:14.000
Ngoài việc sử dụng nhiều đầu ra dữ liệu video, bắt đầu từ iOS 16 và iPadOS 16, các ứng dụng có thể ghi lại bằng AVCaptureMovieFileOutput trong khi nhận dữ liệu từ AVCaptureVideoDataOutput và AVCaptureAudioDataOutput.

00:14:14.000 --> 00:14:25.000
Để xác định những gì có thể được thêm vào một phiên, bạn có thể kiểm tra xem đầu ra có thể được thêm vào nó hay không và truy vấn thuộc tính hardwareCost của phiên để xác định xem hệ thống có thể hỗ trợ cấu hình của bạn hay không.

00:14:25.000 --> 00:14:33.000
Bằng cách nhận dữ liệu video với đầu ra tệp phim, bạn có thể kiểm tra video trong khi quay và phân tích cảnh.

00:14:33.000 --> 00:14:40.000
Và nhận dữ liệu âm thanh với đầu ra tệp phim, bạn có thể lấy mẫu âm thanh trong khi ghi và nghe những gì đang được ghi.

00:14:40.000 --> 00:14:50.000
Với biểu đồ chụp như thế này, bạn có thể giảm tải cơ chế ghi vào AVCaptureMovieFileOutput trong khi vẫn nhận được các mẫu video và âm thanh không nén.

00:14:50.000 --> 00:14:55.000
Việc triển khai các cấu hình phát trực tuyến nâng cao này yêu cầu sử dụng API mới.

00:14:55.000 --> 00:15:01.000
Chúng tôi đã kích hoạt điều này bằng cách cho phép bạn làm nhiều hơn với API hiện có.

00:15:01.000 --> 00:15:06.000
Và cuối cùng, tôi sẽ thảo luận về cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi người dùng đang đa nhiệm.

00:15:06.000 --> 00:15:09.000
Trên iPad, người dùng có thể đa nhiệm theo nhiều cách.

00:15:09.000 --> 00:15:19.000
Ví dụ: ghi lại Bản ghi nhớ bằng giọng nói trong khi đọc Ghi chú ở Chế độ xem chia nhỏ hoặc bằng Slide Over, hãy ghi chú trong cửa sổ nổi phía trên Safari ở chế độ toàn màn hình.

00:15:19.000 --> 00:15:26.000
Với Picture in Picture, bạn có thể tiếp tục phát lại video trong khi thêm lời nhắc để xem thêm video WWDC.

00:15:26.000 --> 00:15:33.000
Và với Trình quản lý giai đoạn mới sử dụng iPadOS 16, người dùng có thể mở nhiều ứng dụng trong các cửa sổ nổi có thể thay đổi kích thước.

00:15:33.000 --> 00:15:38.000
Bắt đầu từ iOS 16, AVCaptureSessions sẽ có thể sử dụng máy ảnh trong khi đa nhiệm.

00:15:38.000 --> 00:15:46.000
Chúng tôi đã ngăn chặn truy cập máy ảnh trong khi đa nhiệm trước đây vì lo ngại về chất lượng dịch vụ mà hệ thống máy ảnh có thể cung cấp trong khi đa nhiệm.

00:15:46.000 --> 00:15:54.000
Các ứng dụng sử dụng nhiều tài nguyên như trò chơi chạy cùng với ứng dụng sử dụng máy ảnh có thể gây giảm khung hình và độ trễ khác, dẫn đến nguồn cấp dữ liệu máy ảnh kém.

00:15:54.000 --> 00:16:00.000
Người dùng xem video nhiều tháng hoặc nhiều năm sau đó có chất lượng kém có thể không nhớ rằng họ đã quay nó trong khi đa nhiệm.

00:16:00.000 --> 00:16:05.000
Cung cấp trải nghiệm máy ảnh tốt là ưu tiên hàng đầu của chúng tôi.

00:16:05.000 --> 00:16:13.000
Khi hệ thống phát hiện video từ máy ảnh được ghi lại trong khi đa nhiệm, một hộp thoại sẽ được hiển thị thông báo cho người dùng về khả năng cho các video chất lượng thấp hơn.

00:16:13.000 --> 00:16:20.000
Hộp thoại này sẽ được trình bày sau khi quá trình ghi kết thúc với AVCaptureMovieFileOutput hoặc AVAssetWriter.

00:16:20.000 --> 00:16:26.000
Nó sẽ chỉ được hiển thị một lần bởi hệ thống cho tất cả các ứng dụng và sẽ có một nút OK để loại bỏ.

00:16:26.000 --> 00:16:33.000
Có hai thuộc tính mới được thêm vào AVCaptureSession để cho biết khi nào truy cập máy ảnh đa nhiệm được hỗ trợ và bật.

00:16:33.000 --> 00:16:45.000
Các phiên ghi lại đã bật tính năng này sẽ không còn bị gián đoạn với lý do "thiết bị video không khả dụng với nhiều ứng dụng tiền cảnh." Một số ứng dụng có thể muốn yêu cầu trải nghiệm toàn màn hình để sử dụng máy ảnh.

00:16:45.000 --> 00:16:50.000
Điều này có thể hữu ích nếu bạn muốn ứng dụng của mình không cạnh tranh với các ứng dụng tiền cảnh khác về tài nguyên hệ thống.

00:16:50.000 --> 00:16:56.000
Ví dụ, ARKit không hỗ trợ sử dụng máy ảnh trong khi đa nhiệm.

00:16:56.000 --> 00:16:59.000
Bạn nên đảm bảo ứng dụng của mình hoạt động tốt khi chạy cùng với các ứng dụng khác.

00:16:59.000 --> 00:17:08.000
Làm cho ứng dụng của bạn có khả năng phục hồi để tăng áp lực hệ thống bằng cách theo dõi các thông báo của nó và thực hiện hành động để giảm tác động, như giảm tốc độ khung hình.

00:17:08.000 --> 00:17:15.000
Bạn có thể giảm dấu chân ứng dụng của mình trên hệ thống bằng cách yêu cầu các định dạng có độ phân giải thấp hơn, binned hoặc không phải HDR.

00:17:15.000 --> 00:17:23.000
Để biết thêm thông tin về các phương pháp hay nhất để duy trì hiệu suất, hãy đọc bài viết "Truy cập máy ảnh trong khi đa nhiệm".

00:17:23.000 --> 00:17:30.000
Ngoài ra, các ứng dụng gọi điện video và hội nghị truyền hình có thể hiển thị những người tham gia từ xa trong cửa sổ Ảnh trong Hình ảnh do hệ thống cung cấp.

00:17:30.000 --> 00:17:36.000
Giờ đây, người dùng ứng dụng của bạn có thể liên tục cuộc gọi video trong khi đa nhiệm trên iPad.

00:17:36.000 --> 00:17:43.000
AVKit đã giới thiệu API trong iOS 15 cho các ứng dụng để chỉ định bộ điều khiển chế độ xem để hiển thị những người tham gia cuộc gọi từ xa.

00:17:43.000 --> 00:17:48.000
Bộ điều khiển chế độ xem cuộc gọi video cho phép bạn tùy chỉnh nội dung của cửa sổ.

00:17:48.000 --> 00:17:55.000
Để tìm hiểu thêm về việc nhận con nuôi, vui lòng xem bài viết "Nhận hình ảnh trong hình ảnh cho các cuộc gọi video".

00:17:55.000 --> 00:17:58.000
Và điều này kết thúc những tiến bộ trong chụp ảnh iOS.

00:17:58.000 --> 00:18:12.000
Tôi đã chỉ ra cách bạn có thể phát trực tuyến độ sâu từ Máy quét LiDAR bằng AVFoundation, cách ứng dụng của bạn sẽ nhận được kết xuất khuôn mặt được cải thiện, cấu hình phát trực tuyến AVCaptureSession nâng cao được thiết kế riêng cho ứng dụng của bạn và cuối cùng, cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi đa

00:18:12.000 --> 00:18:14.000
Tôi hy vọng WWDC của bạn sẽ thành công.

00:18:14.000 --> 23:59:59.000
♪ ♪

