WEBVTT

00:00:00.000 --> 00:00:09.000
♪ ♪

00:00:09.000 --> 00:00:15.000
Ciao, tên tôi là Geppy Parziale, và tôi là một kỹ sư máy học ở đây tại Apple.

00:00:15.000 --> 00:00:27.000
Hôm nay, tôi muốn hướng dẫn bạn hành trình xây dựng một ứng dụng sử dụng máy học để giải quyết một vấn đề thường yêu cầu một chuyên gia thực hiện một số công việc rất chuyên biệt.

00:00:27.000 --> 00:00:37.000
Hành trình này cho tôi cơ hội chỉ cho bạn cách thêm các mô hình học máy mã nguồn mở vào ứng dụng của bạn và tạo ra những trải nghiệm mới tuyệt vời.

00:00:37.000 --> 00:00:49.000
Trong suốt hành trình, tôi cũng sẽ nêu bật một vài trong số rất nhiều công cụ, khuôn khổ và API có sẵn cho bạn trong hệ sinh thái phát triển của Apple để xây dựng các ứng dụng bằng cách sử dụng máy học.

00:00:49.000 --> 00:00:57.000
Khi xây dựng một ứng dụng, bạn, nhà phát triển, thực hiện một loạt các quyết định hy vọng sẽ mang lại trải nghiệm tốt nhất cho người dùng của bạn.

00:00:57.000 --> 00:01:04.000
Và điều này cũng đúng khi thêm chức năng học máy vào các ứng dụng.

00:01:04.000 --> 00:01:10.000
Trong quá trình phát triển, bạn có thể hỏi: tôi có nên sử dụng máy học để xây dựng tính năng này không?

00:01:10.000 --> 00:01:14.000
Làm thế nào tôi có thể có được một mô hình học máy?

00:01:14.000 --> 00:01:18.000
Làm cách nào để làm cho mô hình đó tương thích với các nền tảng của Apple?

00:01:18.000 --> 00:01:22.000
Mô hình đó có phù hợp với trường hợp sử dụng cụ thể của tôi không?

00:01:22.000 --> 00:01:26.000
Nó có chạy trên Apple Neural Engine không?

00:01:26.000 --> 00:01:29.000
Vậy chúng ta hãy cùng nhau thực hiện cuộc hành trình này.

00:01:29.000 --> 00:01:39.000
Tôi muốn xây dựng một ứng dụng cho phép tôi thêm màu sắc chân thực vào những bức ảnh đen trắng của gia đình mà tôi tìm thấy trong một chiếc hộp cũ ở tầng hầm của mình.

00:01:39.000 --> 00:01:47.000
Tất nhiên, một nhiếp ảnh gia chuyên nghiệp có thể làm điều này với một số công việc thủ công, dành thời gian trong công cụ chỉnh sửa ảnh.

00:01:47.000 --> 00:01:54.000
Thay vào đó, điều gì sẽ xảy ra nếu tôi muốn tự động hóa quy trình này và áp dụng màu sắc chỉ trong vài giây?

00:01:54.000 --> 00:01:58.000
Đây dường như là một nhiệm vụ hoàn hảo cho việc học máy.

00:01:58.000 --> 00:02:06.000
Apple cung cấp một lượng lớn các khuôn khổ và công cụ có thể giúp bạn xây dựng và tích hợp chức năng ML trong các ứng dụng của mình.

00:02:06.000 --> 00:02:12.000
Họ cung cấp mọi thứ từ xử lý dữ liệu đến đào tạo và suy luận mô hình.

00:02:12.000 --> 00:02:15.000
Đối với hành trình này, tôi sẽ sử dụng một vài trong số chúng.

00:02:15.000 --> 00:02:22.000
Nhưng hãy nhớ rằng, bạn có nhiều lựa chọn tùy thuộc vào nhiệm vụ học máy cụ thể mà bạn đang phát triển.

00:02:22.000 --> 00:02:29.000
Quá trình tôi sử dụng khi phát triển tính năng học máy trong các ứng dụng của mình trải qua một loạt các giai đoạn.

00:02:29.000 --> 00:02:38.000
Đầu tiên, tôi tìm kiếm mô hình học máy phù hợp trong ấn phẩm khoa học hoặc trang web chuyên ngành.

00:02:38.000 --> 00:02:46.000
Tôi đã tìm kiếm màu ảnh và tôi đã tìm thấy một mô hình có tên Colorizer có thể phù hợp với những gì tôi cần.

00:02:46.000 --> 00:02:53.000
Đây là một ví dụ về sự tô màu mà tôi có thể nhận được bằng cách sử dụng mô hình này.

00:02:53.000 --> 00:02:56.000
Đây là một cái khác.

00:02:56.000 --> 00:03:00.000
Và đây là một cái khác. Thực sự tuyệt vời.

00:03:00.000 --> 00:03:03.000
Để tôi chỉ cho bạn cách nó hoạt động.

00:03:03.000 --> 00:03:07.000
Mô hình Colorizer mong đợi một hình ảnh đen trắng làm đầu vào.

00:03:07.000 --> 00:03:15.000
Mã nguồn Python mà tôi tìm thấy chuyển đổi bất kỳ hình ảnh RGB nào thành hình ảnh không gian màu LAB.

00:03:15.000 --> 00:03:25.000
Không gian màu này có 3 kênh: một kênh đại diện cho độ sáng của hình ảnh hoặc kênh L, và hai kênh còn lại đại diện cho các thành phần màu.

00:03:25.000 --> 00:03:32.000
Các thành phần màu sắc bị loại bỏ trong khi độ nhẹ trở thành đầu vào của mô hình tạo màu.

00:03:32.000 --> 00:03:41.000
Mô hình sau đó ước tính hai thành phần màu mới, kết hợp với kênh L đầu vào, cung cấp màu sắc cho hình ảnh kết quả.

00:03:41.000 --> 00:03:45.000
Đã đến lúc làm cho mô hình này tương thích với ứng dụng của tôi.

00:03:45.000 --> 00:03:53.000
Để đạt được điều này, tôi có thể chuyển đổi mô hình PyTorch gốc sang định dạng Core ML bằng cách sử dụng coremltools.

00:03:53.000 --> 00:03:59.000
Đây là tập lệnh Python đơn giản mà tôi đã sử dụng để chuyển đổi mô hình PyTorch sang Core ML.

00:03:59.000 --> 00:04:04.000
Đầu tiên, tôi nhập kiến trúc và trọng lượng mô hình PyTorch.

00:04:04.000 --> 00:04:07.000
Sau đó tôi theo dõi mô hình đã nhập.

00:04:07.000 --> 00:04:12.000
Cuối cùng, tôi chuyển đổi mô hình PyTorch sang Core ML và lưu nó.

00:04:12.000 --> 00:04:19.000
Khi mô hình ở định dạng Core ML, tôi cần xác minh rằng quá trình chuyển đổi hoạt động chính xác.

00:04:19.000 --> 00:04:23.000
Tôi có thể làm điều đó trực tiếp trong Python một lần nữa bằng cách sử dụng coremltools.

00:04:23.000 --> 00:04:25.000
Và điều này thật dễ dàng.

00:04:25.000 --> 00:04:32.000
Tôi nhập hình ảnh vào không gian màu RGB và chuyển đổi nó thành không gian màu Lab.

00:04:32.000 --> 00:04:38.000
Sau đó, tôi tách độ nhẹ ra khỏi các kênh màu và loại bỏ chúng.

00:04:38.000 --> 00:04:42.000
Tôi chạy dự đoán bằng cách sử dụng mô hình Core ML.

00:04:42.000 --> 00:04:49.000
Và cuối cùng, sáng tác độ sáng đầu vào với các thành phần màu ước tính và chuyển đổi sang RGB.

00:04:49.000 --> 00:04:57.000
Điều này cho phép tôi xác minh rằng chức năng của mô hình được chuyển đổi phù hợp với chức năng của mô hình PyTorch ban đầu.

00:04:57.000 --> 00:05:01.000
Tôi gọi giai đoạn này là Xác minh Mô hình.

00:05:01.000 --> 00:05:05.000
Tuy nhiên, có một kiểm tra quan trọng khác cần được thực hiện.

00:05:05.000 --> 00:05:10.000
Tôi cần hiểu liệu mô hình này có thể chạy đủ nhanh trên thiết bị mục tiêu của tôi hay không.

00:05:10.000 --> 00:05:17.000
Vì vậy, tôi sẽ cần đánh giá mô hình trên thiết bị và đảm bảo rằng nó sẽ cung cấp trải nghiệm người dùng tốt nhất.

00:05:17.000 --> 00:05:26.000
Báo cáo Hiệu suất Core ML mới, hiện có sẵn trong Xcode 14, thực hiện phân tích dựa trên thời gian của mô hình Core ML.

00:05:26.000 --> 00:05:33.000
Tôi chỉ cần kéo và thả mô hình vào Xcode và tạo báo cáo hiệu suất trong vài giây.

00:05:33.000 --> 00:05:44.000
Sử dụng công cụ này, tôi có thể thấy rằng thời gian dự đoán ước tính là gần 90 mili giây trên iPad Pro với M1 và iPadOS 16.

00:05:44.000 --> 00:05:48.000
Và điều này là hoàn hảo cho ứng dụng tô màu ảnh của tôi.

00:05:48.000 --> 00:05:56.000
Nếu bạn muốn biết thêm về Báo cáo Hiệu suất trong Xcode, tôi khuyên bạn nên xem phiên năm nay "Tối ưu hóa việc sử dụng Core ML của bạn".

00:05:56.000 --> 00:06:05.000
Vì vậy, Báo cáo Hiệu suất có thể giúp bạn đánh giá mô hình và đảm bảo nó cung cấp trải nghiệm người dùng trên thiết bị tốt nhất.

00:06:05.000 --> 00:06:13.000
Bây giờ tôi chắc chắn về chức năng và hiệu suất của mô hình của mình, hãy để tôi tích hợp nó vào ứng dụng của mình.

00:06:13.000 --> 00:06:26.000
Quá trình tích hợp giống hệt với những gì tôi đã làm cho đến bây giờ trong Python, nhưng lần này tôi có thể làm điều đó liền mạch trong Swift bằng Xcode và tất cả các công cụ khác mà bạn quen thuộc.

00:06:26.000 --> 00:06:34.000
Hãy nhớ rằng mô hình, bây giờ ở định dạng Core ML, mong đợi một hình ảnh kênh duy nhất đại diện cho sự nhẹ nhàng của nó.

00:06:34.000 --> 00:06:45.000
Vì vậy, tương tự như những gì tôi đã làm trước đây trong Python, tôi cần chuyển đổi bất kỳ hình ảnh đầu vào RGB nào thành hình ảnh bằng cách sử dụng không gian màu Lab.

00:06:45.000 --> 00:06:53.000
Tôi có thể viết sự biến đổi này theo nhiều cách: trực tiếp bằng Swift với vImage hoặc sử dụng Metal.

00:06:53.000 --> 00:07:02.000
Khám phá sâu hơn trong tài liệu, tôi thấy rằng khung Core Image cung cấp thứ gì đó có thể giúp tôi điều này.

00:07:02.000 --> 00:07:10.000
Vì vậy, hãy để tôi chỉ cho bạn cách đạt được chuyển đổi RGB sang LAB và chạy dự đoán bằng cách sử dụng mô hình Core ML.

00:07:10.000 --> 00:07:17.000
Đây là mã Swift để trích xuất độ nhẹ từ hình ảnh RGB và chuyển nó đến mô hình Core ML.

00:07:17.000 --> 00:07:23.000
Đầu tiên, tôi chuyển đổi hình ảnh RGB thành LAB và trích xuất độ nhẹ.

00:07:23.000 --> 00:07:31.000
Sau đó, tôi chuyển đổi độ nhẹ thành CGImage và chuẩn bị đầu vào cho mô hình Core ML.

00:07:31.000 --> 00:07:33.000
Cuối cùng, tôi chạy dự đoán.

00:07:33.000 --> 00:07:45.000
Để trích xuất kênh L từ hình ảnh RGB đầu vào, trước tiên tôi chuyển đổi hình ảnh RGB thành hình ảnh LAB, sử dụng CIFilter convertRGBtoLab mới.

00:07:45.000 --> 00:07:51.000
Các giá trị của độ nhẹ được đặt trong khoảng từ 0 đến 100.

00:07:51.000 --> 00:07:59.000
Sau đó, tôi nhân hình ảnh Phòng thí nghiệm với ma trận màu và loại bỏ các kênh màu và trả lại độ sáng cho người gọi.

00:07:59.000 --> 00:08:04.000
Bây giờ chúng ta hãy phân tích những gì xảy ra ở đầu ra của mô hình.

00:08:04.000 --> 00:08:12.000
Mô hình Core ML trả về hai MLShapedArrays chứa các thành phần màu ước tính.

00:08:12.000 --> 00:08:19.000
Vì vậy, sau khi dự đoán, tôi chuyển đổi hai MLShapedArray thành hai CIImages.

00:08:19.000 --> 00:08:23.000
Cuối cùng, tôi kết hợp chúng với độ nhẹ đầu vào của mô hình.

00:08:23.000 --> 00:08:30.000
Điều này tạo ra một hình ảnh LAB mới mà tôi chuyển đổi sang RGB và trả lại nó.

00:08:30.000 --> 00:08:38.000
Để chuyển đổi hai MLShapedArrays thành hai CIImages, trước tiên tôi trích xuất các giá trị từ mỗi mảng có hình dạng.

00:08:38.000 --> 00:08:44.000
Sau đó, tôi tạo ra hai hình ảnh cốt lõi đại diện cho hai kênh màu và trả lại chúng.

00:08:44.000 --> 00:08:56.000
Để kết hợp độ nhẹ với các kênh màu ước tính, tôi sử dụng CIKernel tùy chỉnh lấy ba kênh làm đầu vào và trả về CIImage.

00:08:56.000 --> 00:09:05.000
Sau đó, tôi sử dụng CIFilter convertLabToRGB mới để chuyển đổi hình ảnh Lab sang RGB và trả lại cho người gọi.

00:09:05.000 --> 00:09:14.000
Đây là mã nguồn cho CIKernel tùy chỉnh mà tôi sử dụng để kết hợp độ nhẹ với hai kênh màu ước tính trong một CIImage duy nhất.

00:09:14.000 --> 00:09:29.000
Để biết thêm thông tin về các bộ lọc CI mới để chuyển đổi hình ảnh RGB sang hình ảnh LAB và ngược lại, vui lòng tham khảo phiên "Hiển thị nội dung EDR với Core Image, Metal và SwiftUI."

00:09:29.000 --> 00:09:34.000
Bây giờ tôi đã hoàn thành việc tích hợp tính năng ML này trong ứng dụng của mình, hãy xem nó hoạt động.

00:09:34.000 --> 00:09:36.000
Nhưng chờ đã.

00:09:36.000 --> 00:09:41.000
Tôi sẽ tô màu những bức ảnh gia đình cũ của mình trong thời gian thực như thế nào với ứng dụng của mình?

00:09:41.000 --> 00:09:46.000
Tôi có thể dành chút thời gian để số hóa từng cái và nhập chúng vào ứng dụng của mình.

00:09:46.000 --> 00:09:48.000
Tôi nghĩ tôi có một ý tưởng hay hơn.

00:09:48.000 --> 00:09:54.000
Điều gì sẽ xảy ra nếu tôi sử dụng máy ảnh iPad của mình để quét những bức ảnh này và tô màu trực tiếp chúng?

00:09:54.000 --> 00:09:58.000
Tôi nghĩ nó sẽ rất vui, và tôi có mọi thứ tôi cần để hoàn thành việc này.

00:09:58.000 --> 00:10:02.000
Nhưng trước tiên, tôi phải giải quyết một vấn đề.

00:10:02.000 --> 00:10:06.000
Mô hình của tôi cần 90 mili giây để xử lý một hình ảnh.

00:10:06.000 --> 00:10:11.000
Nếu tôi muốn xử lý một video, tôi sẽ cần thứ gì đó nhanh hơn.

00:10:11.000 --> 00:10:17.000
Để có trải nghiệm người dùng mượt mà, tôi muốn chạy camera của thiết bị ít nhất 30 khung hình / giây.

00:10:17.000 --> 00:10:24.000
Điều đó có nghĩa là máy ảnh sẽ tạo ra một khung hình khoảng 30 mili giây một lần.

00:10:24.000 --> 00:10:35.000
Nhưng vì mô hình cần khoảng 90 mili giây để tô màu khung hình video, tôi sẽ mất 2 hoặc 3 khung hình trong mỗi lần tô màu.

00:10:35.000 --> 00:10:44.000
Tổng thời gian dự đoán của một mô hình là một hàm của cả kiến trúc của nó cũng như các hoạt động của các đơn vị tính toán mà nó được ánh xạ đến.

00:10:44.000 --> 00:10:55.000
Nhìn vào báo cáo hiệu suất một lần nữa, tôi nhận thấy rằng mô hình của tôi có tổng cộng 61 thao tác chạy trên sự kết hợp giữa công cụ thần kinh và CPU.

00:10:55.000 --> 00:11:00.000
Nếu tôi muốn thời gian dự đoán nhanh hơn, tôi sẽ phải thay đổi mô hình.

00:11:00.000 --> 00:11:07.000
Tôi quyết định thử nghiệm kiến trúc của mô hình và khám phá một số lựa chọn thay thế có thể nhanh hơn.

00:11:07.000 --> 00:11:13.000
Tuy nhiên, một sự thay đổi trong kiến trúc có nghĩa là tôi cần phải đào tạo lại mạng.

00:11:13.000 --> 00:11:20.000
Apple cung cấp các giải pháp khác nhau cho phép tôi đào tạo các mô hình học máy trực tiếp trên máy Mac của mình.

00:11:20.000 --> 00:11:35.000
Trong trường hợp của tôi, vì mô hình ban đầu được phát triển trong PyTorch, tôi đã quyết định sử dụng PyTorch mới trên Metal, vì vậy tôi có thể tận dụng khả năng tăng tốc phần cứng to lớn do Apple Silicon cung cấp.

00:11:35.000 --> 00:11:50.000
Nếu bạn muốn biết thêm về PyTorch tăng tốc với Metal, vui lòng kiểm tra phiên, "Tăng tốc học máy với Metal" Do sự thay đổi này, hành trình của chúng ta cần lùi lại một bước.

00:11:50.000 --> 00:11:59.000
Sau khi đào tạo lại, tôi sẽ phải chuyển đổi kết quả sang định dạng Core ML và chạy lại xác minh.

00:11:59.000 --> 00:12:04.000
Lần này, tích hợp mô hình bao gồm việc hoán đổi mô hình cũ với mô hình mới.

00:12:04.000 --> 00:12:11.000
Sau khi đào tạo lại một vài mô hình thay thế ứng cử viên, tôi đã xác minh một mô hình sẽ đáp ứng yêu cầu của tôi.

00:12:11.000 --> 00:12:16.000
Đây là báo cáo hiệu suất tương ứng.

00:12:16.000 --> 00:12:27.000
Nó chạy hoàn toàn trên công cụ thần kinh và thời gian dự đoán hiện khoảng 16 mili giây, hoạt động cho video.

00:12:27.000 --> 00:12:33.000
Nhưng Báo cáo Hiệu suất chỉ cho tôi biết một khía cạnh trong hiệu suất của ứng dụng của tôi.

00:12:33.000 --> 00:12:40.000
Thật vậy, sau khi chạy ứng dụng của mình, tôi nhận thấy ngay rằng việc tô màu không mượt mà như tôi mong đợi.

00:12:40.000 --> 00:12:45.000
Vậy điều gì xảy ra trong ứng dụng của tôi trong thời gian chạy?

00:12:45.000 --> 00:12:52.000
Để hiểu điều đó, tôi có thể sử dụng mẫu Core ML mới trong Instruments.

00:12:52.000 --> 00:13:00.000
Phân tích phần ban đầu của dấu vết Core ML, sau khi tải mô hình, tôi nhận thấy rằng ứng dụng tích lũy các dự đoán.

00:13:00.000 --> 00:13:02.000
Và điều này thật bất ngờ.

00:13:02.000 --> 00:13:08.000
Thay vào đó, tôi mong đợi có một dự đoán duy nhất cho mỗi khung hình.

00:13:08.000 --> 00:13:19.000
Phóng to dấu vết và kiểm tra các dự đoán đầu tiên, tôi quan sát thấy rằng ứng dụng yêu cầu dự đoán Core ML thứ hai trước khi dự đoán đầu tiên kết thúc.

00:13:19.000 --> 00:13:27.000
Ở đây, Neural Engine vẫn đang làm việc trên yêu cầu đầu tiên khi yêu cầu thứ hai được trao cho Core ML.

00:13:27.000 --> 00:13:33.000
Tương tự, dự đoán thứ ba bắt đầu trong khi vẫn đang xử lý dự đoán thứ hai.

00:13:33.000 --> 00:13:42.000
Ngay cả sau bốn dự đoán, độ trễ giữa yêu cầu và thực thi đã là khoảng 20 mili giây.

00:13:42.000 --> 00:13:51.000
Thay vào đó, tôi cần đảm bảo rằng một dự đoán mới chỉ bắt đầu nếu dự đoán trước đó kết thúc để tránh xếp tầng những độ trễ này.

00:13:51.000 --> 00:14:03.000
Trong khi khắc phục sự cố này, tôi cũng phát hiện ra rằng tôi đã vô tình đặt tốc độ khung hình máy ảnh thành 60 khung hình / giây thay vì 30 khung hình / giây mong muốn.

00:14:03.000 --> 00:14:22.000
Sau khi đảm bảo rằng các ứng dụng xử lý khung hình mới sau khi dự đoán trước đó hoàn tất và đặt tốc độ khung hình máy ảnh thành 30 khung hình / giây, tôi có thể thấy rằng Core ML gửi chính xác một dự đoán duy nhất đến Apple Neural Engine và bây giờ ứng dụng chạy trơn tru.

00:14:22.000 --> 00:14:26.000
Vì vậy, chúng tôi đã kết thúc cuộc hành trình của mình.

00:14:26.000 --> 00:14:34.000
Hãy kiểm tra ứng dụng trên những bức ảnh gia đình cũ của tôi.

00:14:34.000 --> 00:14:38.000
Đây là những bức ảnh đen trắng của tôi mà tôi tìm thấy trong tầng hầm của mình.

00:14:38.000 --> 00:14:49.000
Họ chụp một số địa điểm ở Ý mà tôi đã đến thăm từ lâu.

00:14:49.000 --> 00:14:53.000
Đây là một bức ảnh tuyệt vời của Đấu trường La Mã ở Rome.

00:14:53.000 --> 00:14:59.000
Màu sắc của những bức tường và bầu trời thật chân thực.

00:14:59.000 --> 00:15:03.000
Hãy kiểm tra cái này.

00:15:03.000 --> 00:15:06.000
Đây là Castel del Monte ở miền Nam nước Ý.

00:15:06.000 --> 00:15:09.000
Thực sự tốt.

00:15:09.000 --> 00:15:12.000
Và đây là quê hương của tôi, Grottaglie.

00:15:12.000 --> 00:15:17.000
Thêm màu sắc vào những hình ảnh này đã tạo ra rất nhiều kỷ niệm.

00:15:17.000 --> 00:15:26.000
Lưu ý rằng tôi chỉ áp dụng màu sắc cho bức ảnh trong khi vẫn giữ phần còn lại của cảnh đen trắng.

00:15:26.000 --> 00:15:32.000
Ở đây, tôi đang tận dụng thuật toán phát hiện hình chữ nhật có sẵn trong khung Vision.

00:15:32.000 --> 00:15:41.000
Sử dụng VNDetectRectangleRequest, tôi có thể cô lập ảnh trong cảnh và sử dụng nó làm đầu vào cho mô hình Colorizer.

00:15:41.000 --> 00:15:44.000
Và bây giờ hãy để tôi tóm tắt lại.

00:15:44.000 --> 00:15:56.000
Trong suốt hành trình của chúng tôi, tôi đã khám phá số lượng lớn các khuôn khổ, API và công cụ mà Apple cung cấp để chuẩn bị, tích hợp và đánh giá chức năng học máy cho các ứng dụng của bạn.

00:15:56.000 --> 00:16:03.000
Tôi bắt đầu hành trình này để xác định một vấn đề đòi hỏi một mô hình học máy mã nguồn mở để giải quyết nó.

00:16:03.000 --> 00:16:10.000
Tôi đã tìm thấy một mô hình mã nguồn mở với chức năng mong muốn và làm cho nó tương thích với các nền tảng của Apple.

00:16:10.000 --> 00:16:16.000
Tôi đã đánh giá hiệu suất mô hình trực tiếp trên thiết bị bằng cách sử dụng Báo cáo Hiệu suất mới.

00:16:16.000 --> 00:16:22.000
Tôi đã tích hợp mô hình trong ứng dụng của mình bằng cách sử dụng các công cụ và khuôn khổ mà bạn quen thuộc.

00:16:22.000 --> 00:16:27.000
Tôi đã tối ưu hóa mô hình bằng cách sử dụng Mẫu Core ML mới trong Instruments.

00:16:27.000 --> 00:16:40.000
Với các công cụ và khuôn khổ của Apple, tôi có thể xử lý từng giai đoạn của quá trình phát triển trực tiếp trên các thiết bị và nền tảng của Apple từ việc chuẩn bị dữ liệu, đào tạo, tích hợp và tối ưu hóa.

00:16:40.000 --> 00:16:49.000
Hôm nay, chúng tôi vừa làm xước bề mặt của những gì bạn, nhà phát triển, có thể đạt được với các khuôn khổ và công cụ mà Apple cung cấp cho bạn.

00:16:49.000 --> 00:16:56.000
Vui lòng tham khảo các phiên trước, được liên kết với phiên này, để có thêm những ý tưởng truyền cảm hứng để đưa máy học vào ứng dụng của bạn.

00:16:56.000 --> 00:16:59.000
Khám phá và thử các khuôn khổ và công cụ.

00:16:59.000 --> 00:17:09.000
Tận dụng sức mạnh tổng hợp tuyệt vời giữa phần mềm và phần cứng để tăng tốc các tính năng học máy của bạn và làm phong phú thêm trải nghiệm người dùng của các ứng dụng của bạn.

00:17:09.000 --> 23:59:59.000
Chúc một WWDC tuyệt vời, và arrivederci. ♪ ♪

