[
  {
    "text": "iOS 11 introduced ARKit: ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=0"
  },
  {
    "text": "a new framework for creating augmented reality apps ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=3"
  },
  {
    "text": "for iPhone and iPad.",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=6"
  },
  {
    "text": "ARKit takes apps beyond the screen ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=8"
  },
  {
    "text": "by placing digital objects into the environment around you, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=10"
  },
  {
    "text": "enabling you to interact with the real world ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=14"
  },
  {
    "text": "in entirely new ways. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=16"
  },
  {
    "text": "At WWDC we introduced three primary capabilities ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=20"
  },
  {
    "text": "for ARKit. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=23"
  },
  {
    "text": "Positional tracking detects the pose of your device, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=24"
  },
  {
    "text": "letting you use your iPhone or iPad ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=27"
  },
  {
    "text": "as a window into a digital world all around you. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=29"
  },
  {
    "text": "Scene understanding detects horizontal surfaces ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=33"
  },
  {
    "text": "like tabletops, finds stable anchor points, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=35"
  },
  {
    "text": "and provides an estimate of ambient lighting conditions, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=38"
  },
  {
    "text": "and integration with rendering technologies like SpriteKit, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=42"
  },
  {
    "text": "SceneKit, and Metal, as well as with popular game engines ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=46"
  },
  {
    "text": "such as Unity and Unreal. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=49"
  },
  {
    "text": "Now with iPhone X, ARKit turns its focus to you, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=53"
  },
  {
    "text": "providing face tracking using the front-facing camera. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=56"
  },
  {
    "text": "This new ability enables robust face detection ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=60"
  },
  {
    "text": "and positional tracking in six degrees of freedom. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=63"
  },
  {
    "text": "Facial expressions are also tracked in real-time, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=67"
  },
  {
    "text": "and your apps provided with a fitted triangle mesh ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=70"
  },
  {
    "text": "and weighted parameters representing ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=73"
  },
  {
    "text": "over 50 specific muscle movements of the detected face. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=75"
  },
  {
    "text": "For AR, we provide ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=80"
  },
  {
    "text": "the front-facing color image from the camera, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=81"
  },
  {
    "text": "as well as a front-depth image. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=84"
  },
  {
    "text": "And ARKit uses your face as a light probe to estimate ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=87"
  },
  {
    "text": "lighting conditions, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=91"
  },
  {
    "text": "and generates spherical harmonics coefficients ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=92"
  },
  {
    "text": "that you can apply to your rendering. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=94"
  },
  {
    "text": "And as I mentioned, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=96"
  },
  {
    "text": "all of this is exclusively supported on iPhone X. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=98"
  },
  {
    "text": "There's some really fun things that you can do ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=102"
  },
  {
    "text": "with Face Tracking. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=104"
  },
  {
    "text": "The first is selfie effects, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=105"
  },
  {
    "text": "where you're rendering a semitransparent texture ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=107"
  },
  {
    "text": "onto the face mesh for effects like a virtual tattoo, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=110"
  },
  {
    "text": "or face paint, or to apply makeup, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=113"
  },
  {
    "text": "growing a beard or a mustache, or overlaying the mesh ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=116"
  },
  {
    "text": "with jewelry, masks, hats, and glasses. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=119"
  },
  {
    "text": "The second is face capture, where you are capturing ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=124"
  },
  {
    "text": "the facial expression in real time ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=126"
  },
  {
    "text": "and using that as rigging to project expressions ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=129"
  },
  {
    "text": "onto an avatar, or for a character in a game. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=131"
  },
  {
    "text": "So let's dive into the details ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=136"
  },
  {
    "text": "and see how to get started with face tracking. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=137"
  },
  {
    "text": "The first thing you'll need to do is to create an ARSession. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=140"
  },
  {
    "text": "ARSession is the object that handles ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=144"
  },
  {
    "text": "all the processing done for ARKit, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=146"
  },
  {
    "text": "everything from configuring the device ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=149"
  },
  {
    "text": "to running different AR techniques. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=151"
  },
  {
    "text": "To run a session, we first need to describe ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=153"
  },
  {
    "text": "what kind of tracking we want for this app. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=155"
  },
  {
    "text": "So to do this, you'll create a particular ARConfiguration ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=158"
  },
  {
    "text": "for face tracking and set it up. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=161"
  },
  {
    "text": "Now to begin processing, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=164"
  },
  {
    "text": "you simply call the \"run\" method on the session ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=166"
  },
  {
    "text": "and provide the configuration you want to run. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=168"
  },
  {
    "text": "Internally, ARKit will configure an AVCaptureSession ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=171"
  },
  {
    "text": "and CMMotionManager to begin receiving camera images ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=174"
  },
  {
    "text": "and the sensor data. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=177"
  },
  {
    "text": "And after processing, results will be outputted as ARFrames. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=179"
  },
  {
    "text": "Each ARFrame is a snapshot in time, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=183"
  },
  {
    "text": "providing camera images, tracking data, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=185"
  },
  {
    "text": "and anchor points -- basically everything that's needed ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=188"
  },
  {
    "text": "to render your scene. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=190"
  },
  {
    "text": "Now let's take a closer look at the ARConfiguration ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=192"
  },
  {
    "text": "for face tracking. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=194"
  },
  {
    "text": "We've added a new subclass ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=196"
  },
  {
    "text": "called ARFaceTrackingConfiguration. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=197"
  },
  {
    "text": "This is a simple configuration subclass ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=201"
  },
  {
    "text": "that tells the ARSession to enable face tracking ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=203"
  },
  {
    "text": "through the front-facing camera. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=206"
  },
  {
    "text": "There's a few basic properties to check for the availability ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=208"
  },
  {
    "text": "of face tracking on your device, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=211"
  },
  {
    "text": "and whether or not to enable lighting estimation. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=213"
  },
  {
    "text": "Then once you call \"run,\" ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=216"
  },
  {
    "text": "you'll start the tracking and begin receiving ARFrames. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=217"
  },
  {
    "text": "Once a face is detected, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=221"
  },
  {
    "text": "the session will generate an ARFaceAnchor. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=223"
  },
  {
    "text": "This represents the primary face -- ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=225"
  },
  {
    "text": "the single biggest, closest face in view of the camera. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=228"
  },
  {
    "text": "An ARFaceAnchor ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=232"
  },
  {
    "text": "provides you with the face pose in world coordinates, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=233"
  },
  {
    "text": "through the transform property of its superclass. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=236"
  },
  {
    "text": "It also provides the 3D topology and parameters ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=239"
  },
  {
    "text": "of the current facial expression. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=243"
  },
  {
    "text": "And as you can see, it's all tracked, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=245"
  },
  {
    "text": "and the mesh and parameters updated, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=247"
  },
  {
    "text": "in real time, 60 times per second. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=249"
  },
  {
    "text": "Now, focusing in on the topology, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=252"
  },
  {
    "text": "ARKit provides you with a detailed 3D mesh of the face ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=255"
  },
  {
    "text": "fitted in real time to the dimensions, the shape, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=260"
  },
  {
    "text": "and matching the facial expression of the user. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=262"
  },
  {
    "text": "This data is available in a couple different forms; ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=266"
  },
  {
    "text": "the first is the ARFaceGeometry class. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=268"
  },
  {
    "text": "This is essentially a triangle mesh, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=272"
  },
  {
    "text": "so an array of vertices, triangle indices, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=273"
  },
  {
    "text": "and texture coordinates, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=276"
  },
  {
    "text": "which you can take to visualize in your renderer. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=278"
  },
  {
    "text": "ARKit also provides an easy way to visualize ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=281"
  },
  {
    "text": "the mesh in SceneKit through the ARSCNFaceGeometry class, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=283"
  },
  {
    "text": "which defines a geometry object that can be attached ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=288"
  },
  {
    "text": "to any SceneKit node. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=291"
  },
  {
    "text": "Now aside from the geometry mesh, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=293"
  },
  {
    "text": "we also have something that we call blend shapes. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=294"
  },
  {
    "text": "Blend shapes provide a high-level model ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=297"
  },
  {
    "text": "of the current facial expression. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=300"
  },
  {
    "text": "They're a dictionary of named coefficients ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=302"
  },
  {
    "text": "representing the pose of specific features -- ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=304"
  },
  {
    "text": "your eyelids, eyebrows, jaw, nose, etcetera -- ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=307"
  },
  {
    "text": "all relative to their neutral position. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=310"
  },
  {
    "text": "They're expressed as floating point values ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=313"
  },
  {
    "text": "from zero to one, and they're all updated live. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=315"
  },
  {
    "text": "So you can use these blend shape coefficients ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=318"
  },
  {
    "text": "to animate or rig, a 2D or 3D character ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=320"
  },
  {
    "text": "in a way that directly mirrors the user's facial movements. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=324"
  },
  {
    "text": "Just to give you an idea of what's available, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=328"
  },
  {
    "text": "here's the list of blend shape coefficients. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=329"
  },
  {
    "text": "So each of these is tracked and updated independently -- ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=332"
  },
  {
    "text": "the right and left eyebrows, the position of your eyes, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=335"
  },
  {
    "text": "your jaw, the shape of your smile, etcetera.",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=338"
  },
  {
    "text": "Something that goes hand-in-hand ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=343"
  },
  {
    "text": "with rendering the face geometry or animating a 3D character ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=344"
  },
  {
    "text": "is realistic lighting. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=348"
  },
  {
    "text": "And by using your face as a light probe, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=350"
  },
  {
    "text": "an ARSession that's running face detection ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=353"
  },
  {
    "text": "can provide you with a directional light estimate, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=355"
  },
  {
    "text": "representing the light intensity ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=358"
  },
  {
    "text": "and its direction in world space. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=360"
  },
  {
    "text": "For most apps, this lighting vector ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=362"
  },
  {
    "text": "and intensity are more than enough. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=364"
  },
  {
    "text": "But ARKit also provides ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=366"
  },
  {
    "text": "second-degree spherical harmonics coefficients, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=368"
  },
  {
    "text": "representing the intensity of light detected in the scene. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=371"
  },
  {
    "text": "So for apps with more advanced requirements, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=374"
  },
  {
    "text": "you can take advantage of this as well. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=376"
  },
  {
    "text": "And a couple more features to mention. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=379"
  },
  {
    "text": "In addition to the front-facing camera image with color data, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=381"
  },
  {
    "text": "ARKit can also provide your app with ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=384"
  },
  {
    "text": "the front-facing depth image as well. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=386"
  },
  {
    "text": "And I'm showing this here as a greyscale image. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=389"
  },
  {
    "text": "The data itself is provided as an AVDepthData object, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=391"
  },
  {
    "text": "along with a timestamp. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=395"
  },
  {
    "text": "But it's important to note, this is being captured at 15Hz, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=397"
  },
  {
    "text": "which is a lower frequency than the color image ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=401"
  },
  {
    "text": "which ARKit captures at 60Hz.",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=403"
  },
  {
    "text": "And finally, a feature that can be used with any ARKit session, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=407"
  },
  {
    "text": "but is particularly interesting with face tracking is: ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=410"
  },
  {
    "text": "Audio Capture. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=414"
  },
  {
    "text": "Now it's disabled by default, but if enabled, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=415"
  },
  {
    "text": "then while your ARSession is running, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=418"
  },
  {
    "text": "it will capture audio samples from the microphone, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=420"
  },
  {
    "text": "and deliver a sequence of CMSampleBuffers to your app. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=423"
  },
  {
    "text": "So this is useful if you want to capture ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=426"
  },
  {
    "text": "the user's face and their voice at the same time.",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=428"
  },
  {
    "text": "For more information about face tracking, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=432"
  },
  {
    "text": "and links to the sample code, ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=434"
  },
  {
    "text": "please visit our Developer website ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=435"
  },
  {
    "text": "at developer.apple.com/arkit. ",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=437"
  },
  {
    "text": "Thank you for watching!",
    "link": "https://developer.apple.com/videos/play/tech-talks-601/?time=440"
  }
]