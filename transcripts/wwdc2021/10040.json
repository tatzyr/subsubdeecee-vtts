[
  {
    "text": " ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=0"
  },
  {
    "text": "♪ Bass music playing ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=2"
  },
  {
    "text": " ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=5"
  },
  {
    "text": "♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=7"
  },
  {
    "text": "Sergey Kamensky: Hello, everybody and welcome to WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=9"
  },
  {
    "text": "My name is Sergey Kamensky and I'm a software engineer ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=12"
  },
  {
    "text": "in Vision framework team. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=14"
  },
  {
    "text": "The topic of today's session is to show how Vision framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=15"
  },
  {
    "text": "can help with people analysis. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=18"
  },
  {
    "text": "Our agenda today consists of two main items. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=20"
  },
  {
    "text": "First we're going to have an overview ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=23"
  },
  {
    "text": "of people analysis technology in Vision framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=25"
  },
  {
    "text": "While doing that, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=27"
  },
  {
    "text": "we will be specifically focusing on the new additions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=28"
  },
  {
    "text": "And second, we're going to have the in-depth review ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=31"
  },
  {
    "text": "of the new person segmentation feature. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=34"
  },
  {
    "text": "Let's start with people analysis technology first. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=37"
  },
  {
    "text": "The cornerstone of people analysis in Vision ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=40"
  },
  {
    "text": "is person face analysis. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=42"
  },
  {
    "text": "Since the inception of Vision framework, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=44"
  },
  {
    "text": "we've been adding and enhancing ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=46"
  },
  {
    "text": "human face analysis capabilities. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=47"
  },
  {
    "text": "We currently offer face detection, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=49"
  },
  {
    "text": "face landmarks detection, and face capture quality detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=52"
  },
  {
    "text": "Face detection functionality in Vision framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=56"
  },
  {
    "text": "is exposed by the means of DetectFaceRectanglesRequest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=58"
  },
  {
    "text": "Our face detector offers high precision and recall metrics, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=62"
  },
  {
    "text": "it can find faces with arbitrary orientation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=65"
  },
  {
    "text": "different sizes, and also partially occluded. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=68"
  },
  {
    "text": "So far we have supported occlusions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=71"
  },
  {
    "text": "like glasses and hats. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=73"
  },
  {
    "text": "Now we are upgrading our face detector ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=75"
  },
  {
    "text": "to revision number three which, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=77"
  },
  {
    "text": "in addition to improving all existing great qualities, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=79"
  },
  {
    "text": "can now also detect faces covered by masks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=82"
  },
  {
    "text": "The main function of our face detector ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=86"
  },
  {
    "text": "is of course to find face bounding box, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=87"
  },
  {
    "text": "but it can also detect face pose metrics. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=90"
  },
  {
    "text": "Previously, we have provided roll and yaw metrics only. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=93"
  },
  {
    "text": "Most metrics are reported in radians ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=96"
  },
  {
    "text": "and their values are returned in discrete bins. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=98"
  },
  {
    "text": "With the new revision introduction, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=101"
  },
  {
    "text": "we're also adding a pitch metric ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=103"
  },
  {
    "text": "and thus completing the full picture. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=104"
  },
  {
    "text": "But we didn't stop there. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=107"
  },
  {
    "text": "We're also making all three metrics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=109"
  },
  {
    "text": "reported in continuous space. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=111"
  },
  {
    "text": "All face pose metrics are returned as property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=114"
  },
  {
    "text": "of our FaceObservation object, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=116"
  },
  {
    "text": "which is the result of executing the DetectFaceRectanglesRequest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=118"
  },
  {
    "text": "Let's look at the demo app that is designed to show ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=123"
  },
  {
    "text": "face pose detection functionality. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=125"
  },
  {
    "text": "The app processes camera feed ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=128"
  },
  {
    "text": "by running Vision face detector ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=129"
  },
  {
    "text": "and presents face pose metrics to the user ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=131"
  },
  {
    "text": "after converting the results from radians to degrees. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=133"
  },
  {
    "text": "For better tracking of the metric changes, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=136"
  },
  {
    "text": "the app uses red color gradient to show when face pose metrics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=138"
  },
  {
    "text": "increase in positive direction ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=142"
  },
  {
    "text": "and blue color gradient to show when the metrics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=143"
  },
  {
    "text": "increase in negative direction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=146"
  },
  {
    "text": "In both cases, the lighter the color is, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=148"
  },
  {
    "text": "the closer the metric is to the zero position. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=150"
  },
  {
    "text": "The zero position for each metric is what you would call ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=153"
  },
  {
    "text": "a neutral position of a human head, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=155"
  },
  {
    "text": "when the person is looking straight -- just like this. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=157"
  },
  {
    "text": "As we already discussed, we have three face pose metrics: ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=161"
  },
  {
    "text": "roll, yaw, and pitch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=164"
  },
  {
    "text": "These terms come from flight dynamics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=166"
  },
  {
    "text": "and they describe aircraft principle axes ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=168"
  },
  {
    "text": "with respect to the aircraft's center of gravity. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=170"
  },
  {
    "text": "The same terms have been adopted to describe ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=173"
  },
  {
    "text": "human head pose as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=175"
  },
  {
    "text": "When applied to head pose -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=177"
  },
  {
    "text": "or as we also call it, face pose -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=178"
  },
  {
    "text": "they track human head movement as following. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=180"
  },
  {
    "text": "Roll is tracking head movement in this direction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=183"
  },
  {
    "text": "When I'm going from the most negative ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=189"
  },
  {
    "text": "to the most positive values of roll, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=193"
  },
  {
    "text": "you can see that the background color changes ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=196"
  },
  {
    "text": "from dark blue to light blue, neutral, then light red, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=198"
  },
  {
    "text": "and finally dark red. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=202"
  },
  {
    "text": "Similar color changes are happening with the yaw metric, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=205"
  },
  {
    "text": "which is tracking the angle ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=208"
  },
  {
    "text": "when the head is turning right or left. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=209"
  },
  {
    "text": "And finally, the pitch metric is tracking my head movement ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=213"
  },
  {
    "text": "when my head is nodding up or down. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=216"
  },
  {
    "text": "Here you can see again similar color changes ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=220"
  },
  {
    "text": "when I'm going from the most negative ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=222"
  },
  {
    "text": "to the most positive end of the spectrum. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=226"
  },
  {
    "text": "Face landmarks detection is another important function ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=230"
  },
  {
    "text": "of our face analysis suite. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=232"
  },
  {
    "text": "Face landmarks detection is offered by means of ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=235"
  },
  {
    "text": "DetectFaceLandmarksRequest, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=237"
  },
  {
    "text": "and the latest revision is revision number three. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=239"
  },
  {
    "text": "This revision offers 76-point constellation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=242"
  },
  {
    "text": "to better represent major face regions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=244"
  },
  {
    "text": "and also provide accurate pupil detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=246"
  },
  {
    "text": "Face analysis suite ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=252"
  },
  {
    "text": "also includes face capture quality detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=253"
  },
  {
    "text": "This holistic measure takes into account ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=256"
  },
  {
    "text": "attributes like human face expressions, lighting, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=258"
  },
  {
    "text": "occlusions, blur, focusing, et cetera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=261"
  },
  {
    "text": "It is exposed via DetectFaceCaptureQualityRequest API ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=265"
  },
  {
    "text": "and the latest revision of this request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=268"
  },
  {
    "text": "is revision number two. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=270"
  },
  {
    "text": "It is important to remember that face capture quality ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=273"
  },
  {
    "text": "is a comparative measure of the same subject. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=275"
  },
  {
    "text": "This feature works great, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=278"
  },
  {
    "text": "to pick the best photo out of the photo burst series ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=280"
  },
  {
    "text": "or to pick the best photo to represent a person ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=282"
  },
  {
    "text": "in the photo library. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=285"
  },
  {
    "text": "This feature is not designed to compare faces ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=286"
  },
  {
    "text": "of different people. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=288"
  },
  {
    "text": "Human body analysis is another big section of ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=292"
  },
  {
    "text": "the people analysis technology offered by Vision framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=294"
  },
  {
    "text": "Vision provides several functions in this area, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=297"
  },
  {
    "text": "which include human body detection, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=299"
  },
  {
    "text": "human pose detection, and last but not least, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=302"
  },
  {
    "text": "human hand pose detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=305"
  },
  {
    "text": "First let's take a look at the human body detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=307"
  },
  {
    "text": "This function is offered via DetectHumanRectanglesRequest, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=310"
  },
  {
    "text": "and it currently detects human upper body only. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=314"
  },
  {
    "text": "We are adding new functionality to this request, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=317"
  },
  {
    "text": "and therefore upgrading this revision to revision number two. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=321"
  },
  {
    "text": "With the new revision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=325"
  },
  {
    "text": "in addition to the upper-body detection, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=326"
  },
  {
    "text": "we also offer a full-body detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=328"
  },
  {
    "text": "The choice between the upper-body ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=331"
  },
  {
    "text": "and the full-body detection is controlled via ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=333"
  },
  {
    "text": "the new upperBodyOnly property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=334"
  },
  {
    "text": "of the DetectHumanRectanglesRequest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=336"
  },
  {
    "text": "The default value for this property is set to true ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=339"
  },
  {
    "text": "to maintain backwards compatibility. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=342"
  },
  {
    "text": "Human body pose detection is offered in Vision framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=345"
  },
  {
    "text": "via DetectHumanBodyPoseRequest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=347"
  },
  {
    "text": "Processing this request provides ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=350"
  },
  {
    "text": "a collection of human body joint locations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=352"
  },
  {
    "text": "Revision number one is the latest ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=355"
  },
  {
    "text": "and the only available revision of this request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=357"
  },
  {
    "text": "Vision framework also offers human hand pose detection ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=362"
  },
  {
    "text": "as DetectHumanHandPoseRequest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=364"
  },
  {
    "text": "Similar to human body pose detection, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=367"
  },
  {
    "text": "processing of the hand pose request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=369"
  },
  {
    "text": "returns a collection of human hand joint locations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=371"
  },
  {
    "text": "We're upgrading functionality of this request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=376"
  },
  {
    "text": "by adding an important property to the resulting observation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=377"
  },
  {
    "text": "hand chirality. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=380"
  },
  {
    "text": "The new chirality property of the HumanHandPoseObservation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=383"
  },
  {
    "text": "will contain information ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=386"
  },
  {
    "text": "whether the detected hand was left or right. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=387"
  },
  {
    "text": "If you want to learn more details ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=390"
  },
  {
    "text": "about hand pose detection, I recommend watching ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=392"
  },
  {
    "text": "the \"Classify hand poses and actions with Create ML\" session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=394"
  },
  {
    "text": "This concludes our overview of the new upgrades ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=401"
  },
  {
    "text": "to the people analysis technology suite. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=404"
  },
  {
    "text": "It is time now to move to the second topic of our session, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=406"
  },
  {
    "text": "which is person segmentation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=409"
  },
  {
    "text": "What is person segmentation? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=413"
  },
  {
    "text": "In very simple terms, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=415"
  },
  {
    "text": "it's the ability to separate people from the scene. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=416"
  },
  {
    "text": "There are numerous applications ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=420"
  },
  {
    "text": "of the person segmentation technology nowadays. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=421"
  },
  {
    "text": "You are all familiar, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=424"
  },
  {
    "text": "with virtual background feature on video conferencing apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=425"
  },
  {
    "text": "It's also used in live sport analysis, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=429"
  },
  {
    "text": "autonomous driving, and many more places. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=431"
  },
  {
    "text": "Person segmentation also powers our famous Portrait mode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=433"
  },
  {
    "text": "Person segmentation in Vision framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=439"
  },
  {
    "text": "is a feature designed to work with a single frame. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=440"
  },
  {
    "text": "You can use it in streaming pipeline, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=443"
  },
  {
    "text": "and it's also suitable for the offline processing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=445"
  },
  {
    "text": "This feature is supported on multiple platforms ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=448"
  },
  {
    "text": "like macOS, iOS, iPadOS, and tvOS. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=450"
  },
  {
    "text": "Vision framework implements semantic person segmentation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=458"
  },
  {
    "text": "which means that it will return a single mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=460"
  },
  {
    "text": "for all people in the frame.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=463"
  },
  {
    "text": "Vision API for person segmentation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=468"
  },
  {
    "text": "is implemented by means of ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=470"
  },
  {
    "text": "GeneratePersonSegmentationRequest, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=472"
  },
  {
    "text": "This is a stateful request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=474"
  },
  {
    "text": "As opposed to traditional requests in Vision framework, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=476"
  },
  {
    "text": "the stateful request objects are reused throughout ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=478"
  },
  {
    "text": "the entire sequence of frames. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=481"
  },
  {
    "text": "In our particular case, using request object ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=483"
  },
  {
    "text": "helps with smoothing temporal changes between the frames ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=485"
  },
  {
    "text": "in fast-quality level model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=488"
  },
  {
    "text": "Let's take a look at the Person Segmentation API ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=490"
  },
  {
    "text": "offered by Vision framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=492"
  },
  {
    "text": "This API follows an already familiar ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=495"
  },
  {
    "text": "and established pattern. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=496"
  },
  {
    "text": "Create a request, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=498"
  },
  {
    "text": "create a request handler, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=500"
  },
  {
    "text": "process your request with the request handler, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=502"
  },
  {
    "text": "and finally, review the results. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=504"
  },
  {
    "text": "Default initialization of ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=507"
  },
  {
    "text": "GeneratePersonSegmentationRequest object ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=509"
  },
  {
    "text": "is equivalent to setting revision, qualityLevel, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=511"
  },
  {
    "text": "and outputPixelFormat properties to their default values. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=514"
  },
  {
    "text": "Let's review all properties one by one. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=517"
  },
  {
    "text": "First is the revision property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=521"
  },
  {
    "text": "Here we set the revision to revision number one. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=523"
  },
  {
    "text": "This is the default and the only available revision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=526"
  },
  {
    "text": "since we're dealing with the new request type. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=528"
  },
  {
    "text": "Even though there is technically no choice here today, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=531"
  },
  {
    "text": "we always recommend to set explicitly ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=533"
  },
  {
    "text": "to guarantee deterministic behavior in the future. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=535"
  },
  {
    "text": "This is because if new revisions are introduced, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=538"
  },
  {
    "text": "the default will also change to represent ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=540"
  },
  {
    "text": "the latest available revision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=542"
  },
  {
    "text": "Second is the qualityLevel property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=546"
  },
  {
    "text": "Vision API offers three different levels: ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=549"
  },
  {
    "text": "accurate, which is also the default one; ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=551"
  },
  {
    "text": "balanced; and fast. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=553"
  },
  {
    "text": "As far as the use cases go, we recommend using ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=556"
  },
  {
    "text": "accurate level for computational photography. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=558"
  },
  {
    "text": "This is the use case where you would like to achieve ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=562"
  },
  {
    "text": "the highest possible quality ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=564"
  },
  {
    "text": "and are typically not limited in time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=566"
  },
  {
    "text": "Using similar logic, balanced level is recommended ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=569"
  },
  {
    "text": "for video frame-by-frame segmentation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=571"
  },
  {
    "text": "and fast for streaming processing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=573"
  },
  {
    "text": "The third property is the output mask format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=577"
  },
  {
    "text": "We are going to review the resulting mask in details, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=580"
  },
  {
    "text": "but here I would like to mention that, as a client, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=583"
  },
  {
    "text": "you can specify which format ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=585"
  },
  {
    "text": "the resulting mask will be returned in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=587"
  },
  {
    "text": "There are three choices here: unsigned 8-bit integer mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=590"
  },
  {
    "text": "with a typical 0 to 255 quantization range, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=592"
  },
  {
    "text": "and two floating point mask formats -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=595"
  },
  {
    "text": "one with 32-bit full precision ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=597"
  },
  {
    "text": "and another with 16-bit half precision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=600"
  },
  {
    "text": "The 16-bit half precision is intended to provide you with ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=602"
  },
  {
    "text": "a reduced memory floating point format ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=605"
  },
  {
    "text": "that can be inserted directly ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=607"
  },
  {
    "text": "into further GPU-based processing with Metal. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=608"
  },
  {
    "text": "So far we have learned how to create, configure, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=614"
  },
  {
    "text": "and execute our person segmentation request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=616"
  },
  {
    "text": "It is time now to look at the results. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=619"
  },
  {
    "text": "The result of processing person segmentation request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=622"
  },
  {
    "text": "come in form of PixelBufferObservation object. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=625"
  },
  {
    "text": "PixelBufferObservation derives from observation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=628"
  },
  {
    "text": "and it adds an important pixelBuffer property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=630"
  },
  {
    "text": "The actual CVPixelBuffer object stored in this property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=635"
  },
  {
    "text": "has the same pixel format as our person segmentation request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=637"
  },
  {
    "text": "was configured with. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=641"
  },
  {
    "text": "Processing of person segmentation request ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=645"
  },
  {
    "text": "will produce a segmentation mask. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=647"
  },
  {
    "text": "Let's look at the original image ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=649"
  },
  {
    "text": "and three different quality level masks ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=652"
  },
  {
    "text": "generated by executing person segmentation request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=654"
  },
  {
    "text": "Fast, balanced, and accurate. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=657"
  },
  {
    "text": "Let's zoom in to look at the details of each mask. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=662"
  },
  {
    "text": "As expected, when we go from fast to balanced ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=665"
  },
  {
    "text": "and eventually to accurate, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=668"
  },
  {
    "text": "the quality of the mask increases ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=669"
  },
  {
    "text": "and we'll start seeing more and more details. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=671"
  },
  {
    "text": "Now let's examine the different mask levels ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=675"
  },
  {
    "text": "as a function of quality versus performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=677"
  },
  {
    "text": "When we move from fast to balanced, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=681"
  },
  {
    "text": "and eventually to accurate, the quality of the mask goes up ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=683"
  },
  {
    "text": "but so does the resource usage. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=687"
  },
  {
    "text": "The dynamic range, mask resolution, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=690"
  },
  {
    "text": "memory consumption, processing time all go up ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=692"
  },
  {
    "text": "when the mask quality increases. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=695"
  },
  {
    "text": "This represents a trade-off ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=696"
  },
  {
    "text": "between the quality of the segmentation mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=698"
  },
  {
    "text": "and the resource consumption needed to compute the mask. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=700"
  },
  {
    "text": "So you already know everything about mask generation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=706"
  },
  {
    "text": "and their properties. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=708"
  },
  {
    "text": "What can you actually do with the masks? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=710"
  },
  {
    "text": "Let's start with three images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=714"
  },
  {
    "text": "The input image, the segmentation mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=716"
  },
  {
    "text": "that was obtained by processing the input image, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=718"
  },
  {
    "text": "and the background image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=721"
  },
  {
    "text": "What we would like to do is to replace the background ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=723"
  },
  {
    "text": "in the original image in the area outside of the mask region ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=726"
  },
  {
    "text": "with the background from a different image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=729"
  },
  {
    "text": "When you execute such blending operation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=732"
  },
  {
    "text": "we end up with the young man in the original image ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=735"
  },
  {
    "text": "being transported from the beach promenade to the forest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=737"
  },
  {
    "text": "How does this blending sequence look like in the code? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=742"
  },
  {
    "text": "First let's assume we have done all relevant processing ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=746"
  },
  {
    "text": "and already have our three images: ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=748"
  },
  {
    "text": "the input image, the mask, and the background. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=751"
  },
  {
    "text": "Now we need to scale both the mask and the background ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=755"
  },
  {
    "text": "to the size of the original image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=757"
  },
  {
    "text": "Then we will create and initialize ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=760"
  },
  {
    "text": "the Core Image blending filter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=762"
  },
  {
    "text": "You probably noticed that I created my blending filter ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=765"
  },
  {
    "text": "with the red mask. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=767"
  },
  {
    "text": "This is because when CIImage is initialized ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=768"
  },
  {
    "text": "with one component PixelBuffer -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=771"
  },
  {
    "text": "as all our masks are -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=772"
  },
  {
    "text": "it creates an object with the red channel by default. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=774"
  },
  {
    "text": "Finally, we perform the blending operation to get our results. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=778"
  },
  {
    "text": "Let's take a look how we can use person segmentation feature ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=784"
  },
  {
    "text": "in Vision framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=786"
  },
  {
    "text": "Our second demo app, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=789"
  },
  {
    "text": "which is available for downloading, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=790"
  },
  {
    "text": "combines face pose metric detection ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=792"
  },
  {
    "text": "with the new person segmentation capability. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=794"
  },
  {
    "text": "The app processes camera feed by running face detection ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=796"
  },
  {
    "text": "and person segmentation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=798"
  },
  {
    "text": "Then that takes up the end segmentation mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=800"
  },
  {
    "text": "and uses it to replace the background in the area ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=802"
  },
  {
    "text": "outside of the mask pixels with a different color. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=805"
  },
  {
    "text": "The decision of what background color to use ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=808"
  },
  {
    "text": "comes from the combination of values ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=810"
  },
  {
    "text": "for roll, yaw, and pitch at any given point in time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=811"
  },
  {
    "text": "I'm currently located in a room with a table and chairs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=816"
  },
  {
    "text": "and the demo app shows my segmented silhouette ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=818"
  },
  {
    "text": "over the new background, which is the color mix ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=821"
  },
  {
    "text": "corresponding to my head position. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=823"
  },
  {
    "text": "Let's see if it tracks roll, yaw, and pitch changes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=826"
  },
  {
    "text": "When I turn my head like this, roll is a major contributor ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=829"
  },
  {
    "text": "to the background color mix decision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=836"
  },
  {
    "text": "When I turn my head left and right, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=838"
  },
  {
    "text": "yaw becomes the major contributor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=842"
  },
  {
    "text": "And finally, nodding my head up and down ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=844"
  },
  {
    "text": "makes pitch the major contributor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=848"
  },
  {
    "text": "Vision framework is not the only place ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=852"
  },
  {
    "text": "that offers person segmentation API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=853"
  },
  {
    "text": "There are several other frameworks that offer ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=855"
  },
  {
    "text": "similar functionality powered by the same technology. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=857"
  },
  {
    "text": "Let's take a brief look at each one of them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=860"
  },
  {
    "text": "First is the AVFoundation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=863"
  },
  {
    "text": "AVFoundation can return a person segmentation mask ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=866"
  },
  {
    "text": "in some of the newer-generation devices ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=869"
  },
  {
    "text": "during photo capture session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=870"
  },
  {
    "text": "The segmentation mask is returned ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=873"
  },
  {
    "text": "via PortraitEffectsMatte property of AVCapturePhoto. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=874"
  },
  {
    "text": "In order to get it, you will first need to check ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=879"
  },
  {
    "text": "if it's supported; ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=881"
  },
  {
    "text": "and if it is, enable the delivery of it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=882"
  },
  {
    "text": "The second framework that offers person segmentation API ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=885"
  },
  {
    "text": "is ARKit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=887"
  },
  {
    "text": "This functionality is supported on A12 Bionic and later devices, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=890"
  },
  {
    "text": "and is generated when processing camera feed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=893"
  },
  {
    "text": "The segmentation mask is returned ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=896"
  },
  {
    "text": "via segmentationBuffer property of ARFrame. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=897"
  },
  {
    "text": "Before attempting to retrieve it, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=901"
  },
  {
    "text": "you need to check if it's supported by examining ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=903"
  },
  {
    "text": "supportsFrameSemantics property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=905"
  },
  {
    "text": "of ARWorldTrackingConfiguration class. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=907"
  },
  {
    "text": "The third framework is Core Image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=912"
  },
  {
    "text": "Core Image offers a thin wrapper ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=914"
  },
  {
    "text": "on top of Vision person segmentation API, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=915"
  },
  {
    "text": "so you can perform the entire use case ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=918"
  },
  {
    "text": "within the Core Image domain. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=919"
  },
  {
    "text": "Let's take a look now at how person segmentation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=922"
  },
  {
    "text": "can be implemented using Core Image API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=925"
  },
  {
    "text": "We will start with logging an image ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=928"
  },
  {
    "text": "to perform segmentation on. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=930"
  },
  {
    "text": "Then we will create a person segmentation CIFilter, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=932"
  },
  {
    "text": "assign an inputImage to it, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=935"
  },
  {
    "text": "and execute the filter to get our segmentation mask. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=937"
  },
  {
    "text": "We have just reviewed multiple versions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=943"
  },
  {
    "text": "of person segmentation APIs and Apple SDKs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=944"
  },
  {
    "text": "Let's summarize to see where each one could be used. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=947"
  },
  {
    "text": "AVFoundation is available on some of iOS devices ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=951"
  },
  {
    "text": "with AVCaptureSession. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=954"
  },
  {
    "text": "If you have a capture session running, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=956"
  },
  {
    "text": "this will be your choice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=958"
  },
  {
    "text": "If you're developing an ARKit app, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=960"
  },
  {
    "text": "you should already have an AR session ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=961"
  },
  {
    "text": "where you can get your segmentation mask from. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=963"
  },
  {
    "text": "In this case, ARKit API is the recommended one to use. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=966"
  },
  {
    "text": "Vision API is available on multiple platforms ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=970"
  },
  {
    "text": "for online and offline single-frame processing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=972"
  },
  {
    "text": "And finally, Core Image offers a thin wrapper ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=976"
  },
  {
    "text": "around Vision API, which is a convenient option ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=978"
  },
  {
    "text": "if you want to stay within the Core Image domain. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=981"
  },
  {
    "text": "As any algorithm, person segmentation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=984"
  },
  {
    "text": "has its best practices -- or in other words, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=986"
  },
  {
    "text": "the set of conditions where it works best. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=988"
  },
  {
    "text": "If you're planning to use person segmentation feature, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=991"
  },
  {
    "text": "your app will perform better ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=993"
  },
  {
    "text": "if you try to follow these rules. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=995"
  },
  {
    "text": "First, you should try to segment up to four people in the scene ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=997"
  },
  {
    "text": "where all people are mostly visible, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1001"
  },
  {
    "text": "while maybe with natural occlusions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1003"
  },
  {
    "text": "Second, the height of each person ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1005"
  },
  {
    "text": "should be at least half of the image height, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1007"
  },
  {
    "text": "ideally with good contrast compared to the background. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1010"
  },
  {
    "text": "And third, we also recommend you to avoid ambiguities ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1013"
  },
  {
    "text": "like statues, pictures of people, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1016"
  },
  {
    "text": "people at far distance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1018"
  },
  {
    "text": "This concludes our session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1022"
  },
  {
    "text": "Let's take a brief look at what we have learned today. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1023"
  },
  {
    "text": "First, we had an overview ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1027"
  },
  {
    "text": "of the person analysis technology in Vision framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1028"
  },
  {
    "text": "while focusing on the upgrades like masked face detection, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1031"
  },
  {
    "text": "adding face pitch metric, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1034"
  },
  {
    "text": "and making all face pose metrics reported in continuous space. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1035"
  },
  {
    "text": "We also introduced new hand chirality metric ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1039"
  },
  {
    "text": "to the human hand pose detection. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1042"
  },
  {
    "text": "In the second part, we took a deep dive into ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1045"
  },
  {
    "text": "the new person segmentation API added to Vision framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1047"
  },
  {
    "text": "We also looked into other APIs offering similar functionality ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1050"
  },
  {
    "text": "and provided the guidance where each one could be used. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1053"
  },
  {
    "text": "I really hope that by watching this session, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1057"
  },
  {
    "text": "you have learned new tools for developing your apps ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1059"
  },
  {
    "text": "and are really eager to try them right away. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1061"
  },
  {
    "text": "Before we finish today, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1064"
  },
  {
    "text": "I would like to thank you for watching, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1065"
  },
  {
    "text": "wish you good luck, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1067"
  },
  {
    "text": "and have a great rest of the WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1068"
  },
  {
    "text": "♪",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10040/?time=1070"
  }
]