[
  {
    "text": " ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=2"
  },
  {
    "text": "Hello, and welcome to WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=9"
  },
  {
    "text": "My name’s John, and I work on Core ML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=11"
  },
  {
    "text": "Apple’s machine learning framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=14"
  },
  {
    "text": "Together with my colleague Brian, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=16"
  },
  {
    "text": "we're excited to show you how to tune up your models ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=18"
  },
  {
    "text": "as you bring the magic of machine learning ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=19"
  },
  {
    "text": "to your apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=21"
  },
  {
    "text": "To start things off, I’m going to show you ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=22"
  },
  {
    "text": "some enhancements to our machine learning APIs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=24"
  },
  {
    "text": "After that, we’ll dive into file format improvements ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=27"
  },
  {
    "text": "that open up a range of new possibilities. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=29"
  },
  {
    "text": "Later on, Brian will show us ML Programs ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=32"
  },
  {
    "text": "and take us under the hood and walk us ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=35"
  },
  {
    "text": "through typed execution and how you can use it ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=36"
  },
  {
    "text": "to fine-tune the accuracy and performance of your models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=39"
  },
  {
    "text": "You can use these improvements to streamline your workflow ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=42"
  },
  {
    "text": "and push your ML-powered experiences even further. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=45"
  },
  {
    "text": "Let’s start with the API improvements. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=48"
  },
  {
    "text": "Core ML provides you with a simple API ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=52"
  },
  {
    "text": "to work with models on your user’s device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=54"
  },
  {
    "text": "These models can be designed to work with a variety ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=56"
  },
  {
    "text": "of inputs and outputs, such as strings or primitive values ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=58"
  },
  {
    "text": "or more complex inputs like images and MultiArrays. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=61"
  },
  {
    "text": "Let’s talk more about this last type, MultiArray. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=65"
  },
  {
    "text": "Core ML makes it easy to work ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=69"
  },
  {
    "text": "with multidimensional data using MLMultiArray. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=71"
  },
  {
    "text": "While it’s a simple API, the code you have to write ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=74"
  },
  {
    "text": "to manipulate data with it doesn't always feel natural ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=77"
  },
  {
    "text": "in Swift. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=79"
  },
  {
    "text": "For example, to initialize a MultiArray with a bunch ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=80"
  },
  {
    "text": "of integers, you have to pass in the type at runtime. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=83"
  },
  {
    "text": "Plus you have to use NSNumber instead of regular integers, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=86"
  },
  {
    "text": "and that’s not type-safe ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=89"
  },
  {
    "text": "and doesn’t really look like elegant Swift. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=91"
  },
  {
    "text": "Core ML is introducing MLShapedArray to make it easier ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=94"
  },
  {
    "text": "for you to work with multidimensional data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=97"
  },
  {
    "text": "MLShapedArray is a pure Swift type that’s similar ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=99"
  },
  {
    "text": "to a normal array but supports multiple dimensions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=102"
  },
  {
    "text": "Like array, it’s a value type, with copy-on-write semantics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=105"
  },
  {
    "text": "and a rich slicing syntax that works easily ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=109"
  },
  {
    "text": "with your existing MLMultiArray code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=112"
  },
  {
    "text": "To initialize a two-dimensional MLMultiArray, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=115"
  },
  {
    "text": "you typically use two nested “for” loops. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=118"
  },
  {
    "text": "With an MLShapedArray, you can initialize ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=122"
  },
  {
    "text": "the same 2D array with a single line. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=125"
  },
  {
    "text": "MLShapedArray fits naturally in Swift and makes writing ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=128"
  },
  {
    "text": "and reviewing your code that much easier. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=131"
  },
  {
    "text": "Here’s another example. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=134"
  },
  {
    "text": "To access the second row as a slice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=135"
  },
  {
    "text": "you can just index into it like this. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=137"
  },
  {
    "text": "To access multiple rows and columns as a slice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=140"
  },
  {
    "text": "you can use a range for each dimension. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=143"
  },
  {
    "text": "MLShapedArray and MLMultiArray ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=147"
  },
  {
    "text": "are fully compatible with each other. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=149"
  },
  {
    "text": "You can easily convert one type into the other by using ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=151"
  },
  {
    "text": "the initializer that takes an instance of the other type. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=154"
  },
  {
    "text": "You can also convert data types ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=157"
  },
  {
    "text": "by using the converting initializer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=159"
  },
  {
    "text": "For example, this code converts a MultiArray ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=161"
  },
  {
    "text": "of doubles to a ShapedArray of Floats. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=164"
  },
  {
    "text": "Shaped arrays come in handy anytime you need to work ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=167"
  },
  {
    "text": "with multidimensional data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=169"
  },
  {
    "text": "For example, the YOLO object detection model finds objects ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=171"
  },
  {
    "text": "in an image, and then it outputs a 2-dimensional array. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=175"
  },
  {
    "text": "The table shows the data from one prediction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=178"
  },
  {
    "text": "Each row represents a bounding box, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=180"
  },
  {
    "text": "and the values in each column range between 0 and 1. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=183"
  },
  {
    "text": "Each value represents how confident the model is ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=185"
  },
  {
    "text": "that the bounding box contains a person, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=188"
  },
  {
    "text": "bicycle, or car, et cetera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=190"
  },
  {
    "text": "I want to write some code to pick the most likely label ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=192"
  },
  {
    "text": "for each bounding box. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=195"
  },
  {
    "text": "Here’s an example of how to do that. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=197"
  },
  {
    "text": "The code starts with the output’s confidence property, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=199"
  },
  {
    "text": "which is a 2-dimensional MultiArray. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=202"
  },
  {
    "text": "This function loops through each row to find ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=204"
  },
  {
    "text": "the highest confidence score in that row. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=206"
  },
  {
    "text": "Notice it has to frequently cast integers to NSNumber. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=209"
  },
  {
    "text": "This code uses MLShapedArray instead and does the same job ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=213"
  },
  {
    "text": "in fewer lines that are easier to read. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=217"
  },
  {
    "text": "Notice the model’s prediction result gives us ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=219"
  },
  {
    "text": "a ShapedArray property that contains the confidence values. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=221"
  },
  {
    "text": "This code is simpler because MLShapedArray and its scalars ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=224"
  },
  {
    "text": "conform to the standard Swift collection protocols. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=228"
  },
  {
    "text": "This provides a nice strongly typed experience ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=230"
  },
  {
    "text": "that’s more readable and a joy to work with in Swift. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=233"
  },
  {
    "text": "Next up, let’s talk about Core ML models ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=236"
  },
  {
    "text": "and how they’re represented in the file system. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=238"
  },
  {
    "text": "Core ML makes it easy to build rich ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=241"
  },
  {
    "text": "machine learning-powered experiences for your user. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=243"
  },
  {
    "text": "An ML model is the engine that brings these experiences ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=246"
  },
  {
    "text": "to life. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=248"
  },
  {
    "text": "The .mlmodel file format encodes ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=249"
  },
  {
    "text": "and abstracts the model’s functionality ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=251"
  },
  {
    "text": "so you don’t need to worry about it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=253"
  },
  {
    "text": "The format stores all the implementation details ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=255"
  },
  {
    "text": "and complexities of a model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=257"
  },
  {
    "text": "As a developer, you don’t need to care ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=259"
  },
  {
    "text": "about whether it’s a tree ensemble or a neural network ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=261"
  },
  {
    "text": "with millions of parameters. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=263"
  },
  {
    "text": "An ML Model is just a single file that you simply add ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=264"
  },
  {
    "text": "to an Xcode project and write code that works ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=267"
  },
  {
    "text": "with it, just like any other API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=269"
  },
  {
    "text": "Each Core ML model file consists of several components. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=272"
  },
  {
    "text": "The metadata stores information such as the author, license, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=276"
  },
  {
    "text": "version, and a short description. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=280"
  },
  {
    "text": "The interface defines the model’s inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=282"
  },
  {
    "text": "The architecture defines the model’s internal structure. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=286"
  },
  {
    "text": "For example, with a neural network, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=289"
  },
  {
    "text": "the architecture section describes the model's layers ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=292"
  },
  {
    "text": "and all the connections between them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=294"
  },
  {
    "text": "Finally, the last section stores the massive array ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=296"
  },
  {
    "text": "of values that the model learned during the training phase. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=299"
  },
  {
    "text": "An ML Model file encodes all these sections ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=303"
  },
  {
    "text": "into a protobuf binary format, which file systems ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=305"
  },
  {
    "text": "and source control software see as a single binary file. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=308"
  },
  {
    "text": "Source control software can’t tell that the binary model file ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=312"
  },
  {
    "text": "is actually a combination of several distinct components. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=315"
  },
  {
    "text": "To solve that, Core ML is adding a new model format ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=318"
  },
  {
    "text": "that breaks these components into separate files, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=321"
  },
  {
    "text": "using macOS’ built-in package functionality. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=323"
  },
  {
    "text": "Which brings us to the new Core ML Model Package. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=327"
  },
  {
    "text": "It’s a container that stores each of a model’s components ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=330"
  },
  {
    "text": "in its own file, separating out its architecture, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=332"
  },
  {
    "text": "weights, and metadata. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=335"
  },
  {
    "text": "By separating these components, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=337"
  },
  {
    "text": "model packages allow you to easily edit metadata ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=339"
  },
  {
    "text": "and track changes with source control. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=342"
  },
  {
    "text": "They also compile more efficiently ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=344"
  },
  {
    "text": "and provide more flexibility for tools ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=346"
  },
  {
    "text": "which read and write models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=348"
  },
  {
    "text": "Core ML and Xcode still fully support ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=350"
  },
  {
    "text": "the original ML model format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=352"
  },
  {
    "text": "But you can move to a more extensible format ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=355"
  },
  {
    "text": "and compile more efficiently by updating to a model package. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=357"
  },
  {
    "text": "Let’s try this out in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=360"
  },
  {
    "text": "Here’s a simple app that uses an object detection model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=362"
  },
  {
    "text": "to identify animals in an image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=365"
  },
  {
    "text": "Notice that some of the metadata fields are empty. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=367"
  },
  {
    "text": "It’s fairly common to come across models ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=370"
  },
  {
    "text": "where the metadata isn’t filled in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=372"
  },
  {
    "text": "In the past, you couldn’t edit these fields in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=374"
  },
  {
    "text": "But now that Xcode supports model packages, you can. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=377"
  },
  {
    "text": "Right now the model’s file type is ML Model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=381"
  },
  {
    "text": "but when I click on the Edit button, Xcode prompts me ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=383"
  },
  {
    "text": "to update the ML Model file to an ML Package. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=386"
  },
  {
    "text": "Xcode tells me that it’s about to update any ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=390"
  },
  {
    "text": "of my workspace’s references to the original model file ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=392"
  },
  {
    "text": "to point at the new.mlpackage. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=394"
  },
  {
    "text": "I’ll go ahead and click Update and Edit.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=397"
  },
  {
    "text": "Xcode’s UI now indicates the model is ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=402"
  },
  {
    "text": "in the ML Package format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=405"
  },
  {
    "text": "Now I can fill in the missing values directly in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=408"
  },
  {
    "text": "I’ll go ahead and update the description ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=411"
  },
  {
    "text": "with the word “animals.” ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=414"
  },
  {
    "text": "Since this model came from my coworker, Joseph, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=417"
  },
  {
    "text": "I’ll put his name in the Author field. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=419"
  },
  {
    "text": "I’ll say MIT License and version 2.0.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=421"
  },
  {
    "text": "I can also add, modify, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=427"
  },
  {
    "text": "and remove additional metadata fields as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=428"
  },
  {
    "text": "I’ll add a new metadata item that indicates ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=431"
  },
  {
    "text": "which year we used this model at WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=433"
  },
  {
    "text": "So we’ll say 2021. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=437"
  },
  {
    "text": "Now, in addition to the UI support, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=439"
  },
  {
    "text": "all of this information is also accessible using ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=441"
  },
  {
    "text": "Core ML’s MLModelDescription API at runtime. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=443"
  },
  {
    "text": "I can also modify the description ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=447"
  },
  {
    "text": "of the model's Inputs and Outputs in the Predictions tab. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=448"
  },
  {
    "text": "Here I’ll change the description of this Input. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=452"
  },
  {
    "text": "We'll add \"of an animal.\" ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=455"
  },
  {
    "text": "And down here, I’ll fix a typo by adding a missing hyphen. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=458"
  },
  {
    "text": "Now, a model with good metadata is a lot like code ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=463"
  },
  {
    "text": "with good comments. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=465"
  },
  {
    "text": "It helps you and your team understand the model's intent, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=466"
  },
  {
    "text": "and so it’s particularly important ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=469"
  },
  {
    "text": "to make sure you write good descriptions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=470"
  },
  {
    "text": "for your model’s inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=471"
  },
  {
    "text": "I’ll click Done to save the changes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=474"
  },
  {
    "text": "Now if I click on Source Control and then Commit, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=477"
  },
  {
    "text": "Xcode shows the changes in a diff view.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=481"
  },
  {
    "text": "The metadata is now in its own.json file, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=487"
  },
  {
    "text": "which makes it easy to verify my changes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=489"
  },
  {
    "text": "Similarly, the Feature Descriptions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=492"
  },
  {
    "text": "have their own separate.json file. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=494"
  },
  {
    "text": "If we had changed a few bytes ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=497"
  },
  {
    "text": "of a 62-megabyte binary ML Model file, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=499"
  },
  {
    "text": "we’d have a 62-megabyte binary diff. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=502"
  },
  {
    "text": "Model packages, however, are much more efficient and easy ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=504"
  },
  {
    "text": "to work with, especially for small text changes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=507"
  },
  {
    "text": "Xcode supports both model packages ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=510"
  },
  {
    "text": "and model files equally. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=512"
  },
  {
    "text": "For example, I can use the Preview tab ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=514"
  },
  {
    "text": "to test out my model package. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=516"
  },
  {
    "text": "If I bring in an image of two bears, we’ll see ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=519"
  },
  {
    "text": "that we get two bounding boxes, one for each bear. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=522"
  },
  {
    "text": "Similarly, I can go to the Utilities tab, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=526"
  },
  {
    "text": "where I can generate an encryption key ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=530"
  },
  {
    "text": "or an ML archive for a model package the same ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=532"
  },
  {
    "text": "as I would for an ML model file. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=534"
  },
  {
    "text": "So that’s model packages in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=537"
  },
  {
    "text": "Packages can do everything a model file can and more, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=539"
  },
  {
    "text": "such as editing model metadata. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=542"
  },
  {
    "text": "The last thing I want to show is the code ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=544"
  },
  {
    "text": "that Xcode automatically generates ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=546"
  },
  {
    "text": "for each model you add to a project. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=547"
  },
  {
    "text": "I’m going to click on this icon to see the generated code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=550"
  },
  {
    "text": "Earlier, we took a look at MLMultiArray ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=554"
  },
  {
    "text": "and its new Swift counterpart, MLShapedArray. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=556"
  },
  {
    "text": "Xcode now adds a new shaped array property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=559"
  },
  {
    "text": "for each MultiArray output in the wrapper class. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=561"
  },
  {
    "text": "For example, the generated class now has ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=565"
  },
  {
    "text": "a confidenceShapedArray property for the model’s output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=568"
  },
  {
    "text": "You can still use the original confidence MLMultiArray property ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=571"
  },
  {
    "text": "if you like. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=574"
  },
  {
    "text": "Note that your project’s deployment target must be one ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=577"
  },
  {
    "text": "of these OS versions, for example, macOS 12 or iOS 15, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=579"
  },
  {
    "text": "to take advantage of the new shaped array property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=583"
  },
  {
    "text": "Now that we’ve seen all this in action, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=586"
  },
  {
    "text": "let’s take a look at ML Model and ML Package side by side. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=587"
  },
  {
    "text": "ML Packages support all the same types that ML Model files ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=591"
  },
  {
    "text": "support, including trees, SVMs, neural networks, and so on. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=594"
  },
  {
    "text": "In addition to these types, ML Packages also support ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=599"
  },
  {
    "text": "a powerful new model type called ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=602"
  },
  {
    "text": "ML Program is a model type that represents neural networks ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=605"
  },
  {
    "text": "in a more code-oriented format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=608"
  },
  {
    "text": "To tell you more about ML Programs ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=610"
  },
  {
    "text": "and the new features they enable, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=612"
  },
  {
    "text": "I’ll hand it over to Brian. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=613"
  },
  {
    "text": "Thanks, John. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=615"
  },
  {
    "text": "My name is Brian Keene, and I’m excited to talk ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=616"
  },
  {
    "text": "about ML Programs and how typed execution gives you more control ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=618"
  },
  {
    "text": "over accuracy and better model performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=621"
  },
  {
    "text": "There are various ways a machine learning model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=624"
  },
  {
    "text": "may have been presented to you. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=626"
  },
  {
    "text": "If you’re taking a machine learning course ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=628"
  },
  {
    "text": "or reading a paper, you may encounter a model described ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=630"
  },
  {
    "text": "with respect to its mathematical or statistical formulation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=633"
  },
  {
    "text": "However, these mathematical expressions are often abstracted ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=636"
  },
  {
    "text": "and alternatively presented to you in the form ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=640"
  },
  {
    "text": "of a computation graph or network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=642"
  },
  {
    "text": "This graphical representation as depicted ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=645"
  },
  {
    "text": "in the middle two figures, describes how data flows ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=647"
  },
  {
    "text": "through a series of layers, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=650"
  },
  {
    "text": "each of which applies their own specific transform. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=651"
  },
  {
    "text": "In a machine learning software library, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=654"
  },
  {
    "text": "the model is instead expressed as operations in code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=656"
  },
  {
    "text": "Machine learning engineers are increasingly leveraging ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=659"
  },
  {
    "text": "this more generic program structure ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=662"
  },
  {
    "text": "composed of blocks, functions, and control flow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=664"
  },
  {
    "text": "The new ML Program model type in Core ML aligns itself ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=667"
  },
  {
    "text": "with this last representation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=671"
  },
  {
    "text": "This is a representative ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=673"
  },
  {
    "text": "It’s in a human readable text format, although ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=676"
  },
  {
    "text": "the intention is that you don’t have to write it yourself. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=678"
  },
  {
    "text": "The ML Program will be generated automatically ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=681"
  },
  {
    "text": "by Core ML’s converter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=683"
  },
  {
    "text": "An ML program consists of a main function. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=685"
  },
  {
    "text": "This main function consists of a sequence ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=688"
  },
  {
    "text": "of operations, or ops. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=690"
  },
  {
    "text": "Each op produces a variable, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=692"
  },
  {
    "text": "and this variable is strongly typed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=694"
  },
  {
    "text": "For operations that have weights, such as the linear ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=697"
  },
  {
    "text": "or convolution ops, the weights are typically ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=700"
  },
  {
    "text": "serialized into a separate binary file. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=702"
  },
  {
    "text": "This is a brief summary of how ML Programs ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=706"
  },
  {
    "text": "compare to Neural Networks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=709"
  },
  {
    "text": "Neural networks have layers, while ML Programs have ops. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=712"
  },
  {
    "text": "Weights in neural network models are embedded ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=717"
  },
  {
    "text": "in their layer descriptions, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=719"
  },
  {
    "text": "while ML Programs serialize the weights separately. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=721"
  },
  {
    "text": "And neural networks don’t specify ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=724"
  },
  {
    "text": "the intermediate tensor types. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=726"
  },
  {
    "text": "Instead, the compute unit determines ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=727"
  },
  {
    "text": "these types at runtime. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=729"
  },
  {
    "text": "ML Programs, on the other hand, have strongly typed tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=731"
  },
  {
    "text": "Today I’ll focus on ML Program’s strongly typed syntax ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=735"
  },
  {
    "text": "and the implications that typed intermediate tensors have ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=739"
  },
  {
    "text": "for on-device machine learning with ML Programs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=741"
  },
  {
    "text": "But first, how do you get an ML Program? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=744"
  },
  {
    "text": "Core ML previously introduced a unified converter API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=748"
  },
  {
    "text": "This unified converter API provides a convenient means ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=752"
  },
  {
    "text": "to get your model from Tensorflow ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=755"
  },
  {
    "text": "or PyTorch to the Core ML neural network model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=757"
  },
  {
    "text": "with a single function call. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=759"
  },
  {
    "text": "You can now use the same API to convert ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=762"
  },
  {
    "text": "to an ML Program by selecting iOS 15 ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=765"
  },
  {
    "text": "as the minimum deployment target. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=768"
  },
  {
    "text": "Under the hood, the Core ML converter ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=771"
  },
  {
    "text": "selects an on-disk representation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=773"
  },
  {
    "text": "for the model at conversion time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=775"
  },
  {
    "text": "For ML Programs, the on-disk intermediate representation is ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=777"
  },
  {
    "text": "provided by Model Intermediate Language, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=780"
  },
  {
    "text": "a feature introduced at WWDC 2020. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=782"
  },
  {
    "text": "The unified converter API is where you can opt-in ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=785"
  },
  {
    "text": "to deploy your model as an ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=788"
  },
  {
    "text": "Moving forward, ML Program will be ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=792"
  },
  {
    "text": "the favored format over neural network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=794"
  },
  {
    "text": "And ML Program is available beginning ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=796"
  },
  {
    "text": "with iOS15 and macOS Monterey. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=798"
  },
  {
    "text": "Core ML supports both ML Model and ML Package formats ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=801"
  },
  {
    "text": "for neural networks models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=805"
  },
  {
    "text": "but ML Program must be an ML Package to store ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=806"
  },
  {
    "text": "its weights separately from the architecture. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=809"
  },
  {
    "text": "Core ML is investing in ML Program ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=811"
  },
  {
    "text": "as a foundation for the future. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=813"
  },
  {
    "text": "There will be continued support for neural networks, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=815"
  },
  {
    "text": "but ML Program will be central to new features. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=817"
  },
  {
    "text": "So if ML Program is the future, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=820"
  },
  {
    "text": "what are the benefits of adopting ML Program today? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=822"
  },
  {
    "text": "This brings us to typed execution. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=825"
  },
  {
    "text": "To highlight the benefits of typed execution ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=827"
  },
  {
    "text": "with ML Programs, let’s first discuss what happens ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=829"
  },
  {
    "text": "with neural networks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=832"
  },
  {
    "text": "Shown here is an example input and output ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=834"
  },
  {
    "text": "to a Core ML Neural Network model that specifies Float32 ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=837"
  },
  {
    "text": "for the input and output tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=841"
  },
  {
    "text": "Inputs and outputs can also be double or 32-bit integer types. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=844"
  },
  {
    "text": "So the neural network model strongly types ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=849"
  },
  {
    "text": "these input and output tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=851"
  },
  {
    "text": "What about the types of the intermediate tensors? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=853"
  },
  {
    "text": "A neural network doesn’t strongly ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=857"
  },
  {
    "text": "type its intermediate tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=859"
  },
  {
    "text": "There is no information about the types ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=861"
  },
  {
    "text": "of these tensors in the on-disk model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=863"
  },
  {
    "text": "Instead, the compute unit that runs the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=865"
  },
  {
    "text": "infers the tensor’s types after Core ML loads the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=867"
  },
  {
    "text": "When the Core ML runtime loads a neural network, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=873"
  },
  {
    "text": "it automatically and dynamically ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=875"
  },
  {
    "text": "partitions the network graph into sections: ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=877"
  },
  {
    "text": "Apple Neural Engine friendly, GPU friendly, and CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=879"
  },
  {
    "text": "Each compute unit executes its section ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=883"
  },
  {
    "text": "of the network using its native type to maximize ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=885"
  },
  {
    "text": "its performance and the model’s overall performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=888"
  },
  {
    "text": "The GPU and the Neural Engine both use Float16, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=891"
  },
  {
    "text": "and CPU uses Float32. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=894"
  },
  {
    "text": "As the developer, you have some control ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=897"
  },
  {
    "text": "over this execution scheme by selecting .all, .cpuAndGPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=899"
  },
  {
    "text": "or .cpuOnly with the model’s computeUnits property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=903"
  },
  {
    "text": "This property defaults to .all, which instructs Core ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=907"
  },
  {
    "text": "to partition the model across the neural engine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=910"
  },
  {
    "text": "GPU, and CPU at runtime ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=912"
  },
  {
    "text": "to give your app the best performance possible. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=915"
  },
  {
    "text": "And if you set it to cpuOnly, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=918"
  },
  {
    "text": "Core ML will not use either the Neural Engine or the GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=920"
  },
  {
    "text": "which ensures your model is only executing the Float32 precision ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=923"
  },
  {
    "text": "on the CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=926"
  },
  {
    "text": "To summarize, neural networks have intermediate tensors, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=928"
  },
  {
    "text": "which are automatically typed at runtime ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=931"
  },
  {
    "text": "by the compute unit responsible for producing them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=933"
  },
  {
    "text": "You do have some control of their precision ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=936"
  },
  {
    "text": "by configuring the set of allowed compute units, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=938"
  },
  {
    "text": "but doing so is a global setting for the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=941"
  },
  {
    "text": "and may leave some performance on the table. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=943"
  },
  {
    "text": "What about ML Program? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=946"
  },
  {
    "text": "In the ML Program depicted here, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=949"
  },
  {
    "text": "the input and output tensors are strongly typed, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=950"
  },
  {
    "text": "and so is every intermediate tensor of the program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=953"
  },
  {
    "text": "You can even mix and match precision support ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=958"
  },
  {
    "text": "within a single compute unit, say, the CPU or GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=961"
  },
  {
    "text": "and these types are well defined at the time of model conversion. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=964"
  },
  {
    "text": "That’s long before you would use Core ML to load ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=967"
  },
  {
    "text": "and run the model in a deployment scenario. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=970"
  },
  {
    "text": "ML Programs use the same automatic partioning scheme ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=973"
  },
  {
    "text": "that distributes work to the Neural Engine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=976"
  },
  {
    "text": "GPU, and CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=978"
  },
  {
    "text": "However, it adds a type constraint. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=980"
  },
  {
    "text": "Core ML retains the ability to promote a tensor ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=982"
  },
  {
    "text": "to a higher precision, but the Core ML runtime ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=985"
  },
  {
    "text": "never casts intermediate tensors to a lower precision ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=987"
  },
  {
    "text": "than that specified in the ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=990"
  },
  {
    "text": "This new support for typed execution ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=992"
  },
  {
    "text": "has been made possible via expanded op support ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=995"
  },
  {
    "text": "on both GPU and CPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=997"
  },
  {
    "text": "particularly for Float32 ops on GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1000"
  },
  {
    "text": "and selected ops in Float16 on CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1003"
  },
  {
    "text": "With this expanded support, you can still ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1005"
  },
  {
    "text": "see the performance benefits of the GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1008"
  },
  {
    "text": "when your ML Program specifies Float32 precision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1010"
  },
  {
    "text": "Let’s try out the unified converter API ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1014"
  },
  {
    "text": "to produce ML Programs with different precisions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1016"
  },
  {
    "text": "OK, I’m now in a Jupyter notebook, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1020"
  },
  {
    "text": "which is a convenient tool for executing Python code ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1023"
  },
  {
    "text": "in an interactive way. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1025"
  },
  {
    "text": "I’ll go over the process of converting a model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1027"
  },
  {
    "text": "to the new ML Program format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1029"
  },
  {
    "text": "The model I’m going to use today is a style transfer model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1031"
  },
  {
    "text": "I’ve already downloaded a pretrained Tensorflow model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1034"
  },
  {
    "text": "from Open Source. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1037"
  },
  {
    "text": "This model takes in an image and produces a stylized image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1038"
  },
  {
    "text": "The first thing needed is a few import statements. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1042"
  },
  {
    "text": "I’ll import coremltools, the Python image library, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1044"
  },
  {
    "text": "as well as a couple helper libraries ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1047"
  },
  {
    "text": "and simple helper functions that I’ve written ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1049"
  },
  {
    "text": "to keep the code I use here succinct.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1051"
  },
  {
    "text": "Now I’ll specify the path of the style transfer model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1058"
  },
  {
    "text": "and the path to the image I’m going to stylize. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1061"
  },
  {
    "text": "I’m going to also set up the input types ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1063"
  },
  {
    "text": "for the conversion. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1065"
  },
  {
    "text": "In this case, it’ll be an image input type which specifies ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1066"
  },
  {
    "text": "the dimensions of the image on which the model was trained. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1069"
  },
  {
    "text": "Finally, there’s some additional setup ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1072"
  },
  {
    "text": "to prepare the input dictionary that I can use ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1073"
  },
  {
    "text": "to run the Core ML model post conversion. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1076"
  },
  {
    "text": "So the input has been loaded, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1080"
  },
  {
    "text": "and the source model is available. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1082"
  },
  {
    "text": "At this point, all of the external resources are ready ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1083"
  },
  {
    "text": "for conversion to an ML Program.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1086"
  },
  {
    "text": "For conversion, I’ll use the Unified Converter API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1091"
  },
  {
    "text": "The first argument is the source model path. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1094"
  },
  {
    "text": "Next, pass the array of input types. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1097"
  },
  {
    "text": "Here, there’s just the one. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1099"
  },
  {
    "text": "Finally, the minimum deployment target argument ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1101"
  },
  {
    "text": "will determine if Core ML Tools produces a neural network ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1103"
  },
  {
    "text": "or an ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1106"
  },
  {
    "text": "It defaults to iOS 13 and produces a neural network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1108"
  },
  {
    "text": "Right now I want to get an ML Program, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1112"
  },
  {
    "text": "so I’ll set the deployment target to iOS 15. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1114"
  },
  {
    "text": "I want to eventually deploy this model on an iOS app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1117"
  },
  {
    "text": "I could have alternatively specified a deployment target ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1120"
  },
  {
    "text": "of macOS 12, if my target device was a Mac. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1123"
  },
  {
    "text": "I’ll press Shift-Enter to convert the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1127"
  },
  {
    "text": "And conversion has completed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1130"
  },
  {
    "text": "There is a graph transform that happens automatically ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1133"
  },
  {
    "text": "for ML Programs during conversion. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1135"
  },
  {
    "text": "It’s called the FP16ComputePrecision pass. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1137"
  },
  {
    "text": "This graph pass casts every Float32 tensor ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1142"
  },
  {
    "text": "in the original Tensorflow graph ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1145"
  },
  {
    "text": "to a Float16 tensor in the ML program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1146"
  },
  {
    "text": "OK, now since the conversion is done, the next step is ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1149"
  },
  {
    "text": "to check the correctness of the ML program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1153"
  },
  {
    "text": "I can compare the output numerics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1155"
  },
  {
    "text": "with the original Tensorflow model by calling prediction ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1157"
  },
  {
    "text": "with the same image with both the models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1159"
  },
  {
    "text": "It’s worth noting for ML Programs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1163"
  },
  {
    "text": "I’m using exactly the same Core ML Tools APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1165"
  },
  {
    "text": "as in previous years for prediction, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1168"
  },
  {
    "text": "model saving, and other utilities. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1170"
  },
  {
    "text": "To do the comparison, I have already written ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1172"
  },
  {
    "text": "a utility method called _get_coreml_tensorflow_output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1174"
  },
  {
    "text": "It will print out multiple error metrics to evaluate ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1177"
  },
  {
    "text": "the output from Tensorflow and the output from Core ML.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1179"
  },
  {
    "text": "So since this is an image, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1185"
  },
  {
    "text": "the most appropriate error metric may be ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1187"
  },
  {
    "text": "the signal to noise ratio, or SNR. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1189"
  },
  {
    "text": "In practice, an SNR above 20 or 30 is ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1191"
  },
  {
    "text": "usually indicative of good results. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1194"
  },
  {
    "text": "Here I have an SNR of 71, and that’s pretty great. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1195"
  },
  {
    "text": "There’s a couple other metrics: max absolute error, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1199"
  },
  {
    "text": "average absolute error. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1203"
  },
  {
    "text": "I’m curious, though, what’s the accuracy cost ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1204"
  },
  {
    "text": "of using Float16? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1207"
  },
  {
    "text": "What have I lost? ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1208"
  },
  {
    "text": "To find out, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1210"
  },
  {
    "text": "I can disable the Float16 transform and convert again. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1211"
  },
  {
    "text": "I’ll use the same convert command, but this time ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1216"
  },
  {
    "text": "I’ll specify a compute_precision argument and set it to Float32. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1218"
  },
  {
    "text": "This will tell the converter to not inject ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1222"
  },
  {
    "text": "those Float16 casts, and so the Core ML Tools ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1224"
  },
  {
    "text": "converter will produce a Float32 ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1227"
  },
  {
    "text": "OK, now I’ll compare this Float32 ML Program ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1232"
  },
  {
    "text": "to the original Tensorflow one.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1235"
  },
  {
    "text": "And the SNR has increased to over 100, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1241"
  },
  {
    "text": "and the maximum absolute error has decreased ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1244"
  },
  {
    "text": "from about 1 down to 0.02. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1246"
  },
  {
    "text": "I still haven’t answered whether the error I got earlier ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1250"
  },
  {
    "text": "with the Float16 model had any discernible impact. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1252"
  },
  {
    "text": "This is a style transfer model, so the verdict could be made ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1255"
  },
  {
    "text": "based on a simple plot of the output image.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1258"
  },
  {
    "text": "I’ll plot the source image and the stylized versions ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1263"
  },
  {
    "text": "from all three models that I have: the Float16 ML Program, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1265"
  },
  {
    "text": "the Float32 ML program, and the Tensorflow model.",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1268"
  },
  {
    "text": "And I really don’t see any difference ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1274"
  },
  {
    "text": "between the three model outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1276"
  },
  {
    "text": "Of course, this evaluation of a single image, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1277"
  },
  {
    "text": "once with a couple of metrics and a visual inspection ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1280"
  },
  {
    "text": "is really just a smoke test. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1283"
  },
  {
    "text": "Things look OK. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1284"
  },
  {
    "text": "In practice, I’d evaluate with more error metrics ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1286"
  },
  {
    "text": "across a large dataset, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1289"
  },
  {
    "text": "evaluate failure cases within the pipeline used ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1290"
  },
  {
    "text": "by the machine learning model, and triage those. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1293"
  },
  {
    "text": "I have a small dataset handy, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1295"
  },
  {
    "text": "and to go one step further with this example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1297"
  },
  {
    "text": "I can compare the two ML Programs ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1299"
  },
  {
    "text": "with the Tensorflow model for each image within the dataset. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1300"
  },
  {
    "text": "The SNR of the Float32 ML program versus Tensorflow ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1304"
  },
  {
    "text": "is depicted as a red line with Xs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1307"
  },
  {
    "text": "and the Float16 ML Program is a blue line with circles. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1310"
  },
  {
    "text": "The Float32 ML Program seems to average an SNR around 100, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1313"
  },
  {
    "text": "and the Float16 ML Program stays around 70. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1316"
  },
  {
    "text": "The Float16 precision does ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1320"
  },
  {
    "text": "affect the numerics a little bit, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1321"
  },
  {
    "text": "but it doesn't seem significant for this use case. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1323"
  },
  {
    "text": "Although, even in this small dataset of 131 images, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1325"
  },
  {
    "text": "there are a few outliers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1328"
  },
  {
    "text": "Overall, the model is doing pretty well ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1329"
  },
  {
    "text": "what it’s expected to do. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1331"
  },
  {
    "text": "And this is the case for a majority ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1333"
  },
  {
    "text": "of deep learning models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1335"
  },
  {
    "text": "They typically tend to work just fine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1336"
  },
  {
    "text": "even with Float16 precision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1337"
  },
  {
    "text": "That’s why we have turned the Float16 transform on ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1339"
  },
  {
    "text": "by default in the Core ML converter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1342"
  },
  {
    "text": "A Float16 typed ML program will be available to execute ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1344"
  },
  {
    "text": "on the neural engine, which can present a substantial ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1347"
  },
  {
    "text": "performance boost and reduction in power consumption. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1350"
  },
  {
    "text": "Since the runtime treats the types of the tensors ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1353"
  },
  {
    "text": "as a minimum precision during execution, a Float32 ML Program ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1355"
  },
  {
    "text": "will execute on a combination of only the GPU and the CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1359"
  },
  {
    "text": "This demo demonstrated how easy it is now ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1363"
  },
  {
    "text": "to control the minimum precision in which the ML Program ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1366"
  },
  {
    "text": "will execute right at conversion time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1368"
  },
  {
    "text": "And unlike neural network Core ML models, if your model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1371"
  },
  {
    "text": "needs higher precision, you do not have to change the setting ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1374"
  },
  {
    "text": "of the compute unit to cpuOnly in the app code to achieve that. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1377"
  },
  {
    "text": "And as a final note, this demo notebook will be ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1381"
  },
  {
    "text": "available as an example ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1383"
  },
  {
    "text": "on the Core ML Tools documentation site. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1384"
  },
  {
    "text": "To recap, to get an ML program, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1387"
  },
  {
    "text": "use the convert function and pass an additional argument ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1390"
  },
  {
    "text": "to specify the deployment target, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1392"
  },
  {
    "text": "and set it to at least iOS 15 or macOS 12. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1394"
  },
  {
    "text": "By default, the Core ML converter ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1398"
  },
  {
    "text": "will produce an optimized Float16 model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1400"
  },
  {
    "text": "that is eligible for execution on the neural engine. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1402"
  },
  {
    "text": "If, as it might happen in some cases, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1405"
  },
  {
    "text": "the model is sensitive to Float16 precision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1408"
  },
  {
    "text": "it’s simple to set the precision to Float32 instead. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1410"
  },
  {
    "text": "There are, in fact, more advanced options available ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1414"
  },
  {
    "text": "in the Core ML Tools API, using which you can select ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1416"
  },
  {
    "text": "specific ops to execute in Float32 while keeping ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1419"
  },
  {
    "text": "the rest in Float16 to produce a mixed type ML Program. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1421"
  },
  {
    "text": "Please check out our documentation ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1425"
  },
  {
    "text": "for these examples. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1427"
  },
  {
    "text": "In summary, Core ML has several new enhancements ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1428"
  },
  {
    "text": "that make it easier to tune and work with your models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1431"
  },
  {
    "text": "The new MLShapedArray type makes it easy to work ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1434"
  },
  {
    "text": "with multidimensional data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1436"
  },
  {
    "text": "The ML Package format allows you ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1439"
  },
  {
    "text": "to edit metadata directly in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1441"
  },
  {
    "text": "An ML Package with the new ML Program model type ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1443"
  },
  {
    "text": "supports typed execution with Float32 support on GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1446"
  },
  {
    "text": "giving you more options to play with ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1449"
  },
  {
    "text": "as you tune your model’s performance and accuracy. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1451"
  },
  {
    "text": "We encourage you to upgrade your model ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1454"
  },
  {
    "text": "to ML Packages and use ML Programs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1455"
  },
  {
    "text": "Thanks for watching our session, and enjoy the rest of WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1458"
  },
  {
    "text": "[music]",
    "link": "https://developer.apple.com/videos/play/wwdc2021/10038/?time=1462"
  }
]