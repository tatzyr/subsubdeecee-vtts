[
  {
    "text": "♪ ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=0"
  },
  {
    "text": "Doug: Welcome, everyone. I’m Doug Davidson, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=10"
  },
  {
    "text": "and I’m here to talk to you about Natural Language Processing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=12"
  },
  {
    "text": "Now, there have been a number of sessions ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=15"
  },
  {
    "text": "on Natural Language Processing in past years. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=17"
  },
  {
    "text": "What we’re going to talk about today builds on all of that, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=19"
  },
  {
    "text": "with the addition of some exciting new functionality. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=22"
  },
  {
    "text": "First I’m going to give some background on NLP and NLP models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=25"
  },
  {
    "text": "Then I’ll summarize the existing functionality. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=31"
  },
  {
    "text": "Then I’ll talk about what’s new this year. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=34"
  },
  {
    "text": "I’ll discuss some advanced applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=37"
  },
  {
    "text": "And then I’ll wrap it up. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=40"
  },
  {
    "text": "Let’s start with some background. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=43"
  },
  {
    "text": "Schematically, NLP models generally have a similar flow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=45"
  },
  {
    "text": "They start off with text data, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=50"
  },
  {
    "text": "then have an input layer that converts it to a numerical feature representation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=52"
  },
  {
    "text": "upon which a machine learning model can act, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=58"
  },
  {
    "text": "and that produces some output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=60"
  },
  {
    "text": "The most obvious examples of this from previous years ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=63"
  },
  {
    "text": "are the Create ML models that are supported ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=65"
  },
  {
    "text": "for text classification and word tagging. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=68"
  },
  {
    "text": "The development of NLP as a field can be traced fairly closely ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=72"
  },
  {
    "text": "just by the development of increasingly sophisticated ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=76"
  },
  {
    "text": "versions of the input layers.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=79"
  },
  {
    "text": "Ten or twenty years ago, these were simple orthographic features. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=82"
  },
  {
    "text": "Then about a decade ago, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=86"
  },
  {
    "text": "things moved to the use of static word embeddings, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=88"
  },
  {
    "text": "such as Word2Vec and GloVe. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=91"
  },
  {
    "text": "Then to contextual word embeddings based on neural network models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=94"
  },
  {
    "text": "such as CNNs and LSTMs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=98"
  },
  {
    "text": "And more recently, transformer-based language models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=102"
  },
  {
    "text": "I should say a few words about what an embedding is. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=106"
  },
  {
    "text": "In the simplest form, it’s just a map from words in a language ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=109"
  },
  {
    "text": "to vectors in some abstract vector space, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=113"
  },
  {
    "text": "but trained as a machine learning model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=116"
  },
  {
    "text": "such that words with similar meaning are close together in vector space. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=118"
  },
  {
    "text": "This allows it to incorporate linguistic knowledge. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=123"
  },
  {
    "text": "Static embeddings are just a simple map from words to vectors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=127"
  },
  {
    "text": "Pass in a word, the model looks it up in a table and provides a vector. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=131"
  },
  {
    "text": "These are trained such that words with similar meaning ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=135"
  },
  {
    "text": "are close together in vector space. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=138"
  },
  {
    "text": "This is quite useful for understanding individual words. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=140"
  },
  {
    "text": "More sophisticated embeddings are dynamic and contextual ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=144"
  },
  {
    "text": "such that each word in a sentence is mapped to a different vector ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=147"
  },
  {
    "text": "depending on its use in the sentence. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=151"
  },
  {
    "text": "For example, “food” in “fast food joint” ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=153"
  },
  {
    "text": "has a different meaning than “food” in “food for thought,” ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=157"
  },
  {
    "text": "so they will get different embedding vectors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=160"
  },
  {
    "text": "Now, the point of having a powerful embedding as an input layer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=163"
  },
  {
    "text": "is to allow for transfer learning. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=167"
  },
  {
    "text": "The embedding is trained on large amounts of data ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=169"
  },
  {
    "text": "and encapsulates general knowledge of the language, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=172"
  },
  {
    "text": "which can be transferred to your specific task ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=174"
  },
  {
    "text": "without requiring huge amounts of task-specific training data.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=178"
  },
  {
    "text": "Currently, Create ML supports embeddings of this sort using ELMo models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=183"
  },
  {
    "text": "These models are based on LSTMs whose outputs are combined ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=188"
  },
  {
    "text": "to produce the embedding vector. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=192"
  },
  {
    "text": "These can be used via Create ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=194"
  },
  {
    "text": "for training classification and tagging models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=196"
  },
  {
    "text": "Now, let me discuss the models that have been supported so far. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=200"
  },
  {
    "text": "These were discussed in great detail in previous sessions in 2019 and 2020, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=204"
  },
  {
    "text": "so I’ll just describe them briefly here.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=209"
  },
  {
    "text": "Natural Language supports model training using Create ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=213"
  },
  {
    "text": "that generally follows the pattern we’ve seen for NLP models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=217"
  },
  {
    "text": "This involves models for two different tasks: ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=222"
  },
  {
    "text": "text classification and word tagging. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=224"
  },
  {
    "text": "In text classification, the output describes the input text ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=228"
  },
  {
    "text": "using one of a set of classes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=232"
  },
  {
    "text": "For example, it might be a topic or a sentiment. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=234"
  },
  {
    "text": "And in word tagging, the output puts a label on each word in the input text, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=237"
  },
  {
    "text": "for example, a part of speech or a role label.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=242"
  },
  {
    "text": "And the supported Create ML models have generally followed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=248"
  },
  {
    "text": "the evolution of the NLP field, starting with maxent and CRF-based models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=251"
  },
  {
    "text": "then adding support for static word embeddings, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=256"
  },
  {
    "text": "and then dynamic word embeddings for Create ML models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=259"
  },
  {
    "text": "using ELMo embeddings. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=262"
  },
  {
    "text": "And you can view the detail on this in previous sessions, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=265"
  },
  {
    "text": "“Advances in Natural Language Framework” from 2019 ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=268"
  },
  {
    "text": "and “Make Apps Smarter with Natural Language” from 2020. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=272"
  },
  {
    "text": "Now let me turn to what's new this year in Natural Language. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=275"
  },
  {
    "text": "I’m happy to say that we now provide transformer-based contextual embeddings. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=280"
  },
  {
    "text": "Specifically, these are BERT embeddings. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=285"
  },
  {
    "text": "That just stands for Bidirectional Encoder Representations from Transformers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=288"
  },
  {
    "text": "These are embedding models that are trained on large amounts of text ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=293"
  },
  {
    "text": "using a masked language model style of training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=296"
  },
  {
    "text": "This means that the model is given a sentence with one word masked out ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=300"
  },
  {
    "text": "and asked to suggest the word, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=303"
  },
  {
    "text": "for example, “food” in “food for thought,” ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=306"
  },
  {
    "text": "and trained to do better and better at this.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=308"
  },
  {
    "text": "Transformers at their heart are based on what’s called an attention mechanism, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=314"
  },
  {
    "text": "specifically, multi-headed self-attention, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=319"
  },
  {
    "text": "which allows the model to take into account ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=322"
  },
  {
    "text": "different portions of the text with different weights, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=324"
  },
  {
    "text": "in multiple different ways at once. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=327"
  },
  {
    "text": "The multi-headed self-attention mechanism is wrapped up with multiple other layers, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=331"
  },
  {
    "text": "then repeated several times, which altogether provides a powerful ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=335"
  },
  {
    "text": "and flexible model that can take advantage of large amounts of textual data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=339"
  },
  {
    "text": "So much so in fact that it can be trained on multiple languages at once, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=344"
  },
  {
    "text": "leading to a multilingual model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=349"
  },
  {
    "text": "This has several advantages. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=352"
  },
  {
    "text": "It makes it possible to support many languages immediately ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=354"
  },
  {
    "text": "and even multiple languages at once. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=357"
  },
  {
    "text": "But even more than that, because of similarities between languages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=360"
  },
  {
    "text": "there's some synergy such that data for one language helps with others.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=364"
  },
  {
    "text": "So we’ve gone immediately to supporting 27 different languages ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=370"
  },
  {
    "text": "across a wide variety of language families. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=374"
  },
  {
    "text": "This is done with three separate models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=377"
  },
  {
    "text": "one each for groups of languages that share related writing systems. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=380"
  },
  {
    "text": "So there's one model for Latin-script languages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=385"
  },
  {
    "text": "one for languages that use Cyrillic, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=388"
  },
  {
    "text": "and one for Chinese, Japanese, and Korean.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=391"
  },
  {
    "text": "These embedding models fit right in with the Create ML training ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=395"
  },
  {
    "text": "we discussed earlier, serving as an input encoding layer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=398"
  },
  {
    "text": "This is a powerful encoding for many different models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=402"
  },
  {
    "text": "In addition though, the data that you use for training ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=406"
  },
  {
    "text": "doesn’t have to all be in a single language. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=408"
  },
  {
    "text": "Let me show you how this works with an example. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=411"
  },
  {
    "text": "Suppose you're writing a messaging app and want to aid users ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=414"
  },
  {
    "text": "by automatically classifying the messages that they receive. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=418"
  },
  {
    "text": "Suppose you want to divide them into three categories: ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=422"
  },
  {
    "text": "personal messages, such as you might receive from your friends, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=425"
  },
  {
    "text": "business messages, such as you might receive from your colleagues, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=428"
  },
  {
    "text": "and commercial messages, such as you might receive from businesses you interact with. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=431"
  },
  {
    "text": "But users might receive messages in many different languages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=437"
  },
  {
    "text": "and you want to handle that. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=440"
  },
  {
    "text": "For this example, I’ve assembled some training data in multiple languages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=442"
  },
  {
    "text": "English, Italian, German, and Spanish. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=446"
  },
  {
    "text": "I used json format, but you could also use directories or CSV. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=449"
  },
  {
    "text": "To train our model, we go into the Create ML app and create a project. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=455"
  },
  {
    "text": "Then we need to select our training data.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=459"
  },
  {
    "text": "I’ve also prepared validation data and test data to go along with it.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=468"
  },
  {
    "text": "Then we need to choose our algorithm, and we have a new choice here: ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=480"
  },
  {
    "text": "the BERT embeddings.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=483"
  },
  {
    "text": "Once we’ve chosen those, we can choose the script. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=489"
  },
  {
    "text": "Since these are Latin-script languages, I’ll leave it on Latin. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=493"
  },
  {
    "text": "If we were using a single language, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=497"
  },
  {
    "text": "we would have the option of specifying it here, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=498"
  },
  {
    "text": "but this is multilingual, so we’ll just leave it on automatic.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=501"
  },
  {
    "text": "Then all we need to do is press Train, and model training will start.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=507"
  },
  {
    "text": "The most time-consuming part of the training ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=516"
  },
  {
    "text": "is applying these powerful embeddings to the text. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=518"
  },
  {
    "text": "Then the model trains fairly quickly to a high degree of accuracy.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=521"
  },
  {
    "text": "At that point, we can try it out on some example messages.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=529"
  },
  {
    "text": "In English… ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=536"
  },
  {
    "text": "Or Spanish.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=541"
  },
  {
    "text": "And the model is pretty confident that these are commercial messages. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=548"
  },
  {
    "text": "As an example of the synergies that are possible, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=552"
  },
  {
    "text": "this model hasn’t been trained on French, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=554"
  },
  {
    "text": "but it can still classify some French text as well.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=556"
  },
  {
    "text": "I do recommend though that you use training data ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=565"
  },
  {
    "text": "for each of the languages you are interested in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=568"
  },
  {
    "text": "Now, so far we’ve just been working with Create ML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=571"
  },
  {
    "text": "but it’s also possible to work with these embeddings ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=574"
  },
  {
    "text": "using the Natural Language framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=576"
  },
  {
    "text": "with a new class called NLContextualEmbedding. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=578"
  },
  {
    "text": "This allows you to identify the embedding model you want ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=582"
  },
  {
    "text": "and find out some of its properties.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=585"
  },
  {
    "text": "You can look for an embedding model in a number of different ways, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=588"
  },
  {
    "text": "for example, by language or by script. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=592"
  },
  {
    "text": "Once you have such a model, you can get properties ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=595"
  },
  {
    "text": "such as the dimensionality of the vectors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=598"
  },
  {
    "text": "Also, each model has an identifier, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=601"
  },
  {
    "text": "which is just a string that uniquely identifies the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=604"
  },
  {
    "text": "For example, when you start working with a model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=607"
  },
  {
    "text": "you might locate it by language, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=609"
  },
  {
    "text": "but later on you would want to make sure that you're using the exact same model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=611"
  },
  {
    "text": "and the identifier will allow you to do this. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=616"
  },
  {
    "text": "One thing to keep in mind is that, like many other Natural Language features, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=620"
  },
  {
    "text": "these embedding models rely on assets that are downloaded as needed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=624"
  },
  {
    "text": "NLContextualEmbedding provides some APIs to give you additional control over this, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=629"
  },
  {
    "text": "for example, to request download before use. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=634"
  },
  {
    "text": "You can ask whether a given embedding model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=640"
  },
  {
    "text": "currently has assets available on device, and if not put in a request, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=642"
  },
  {
    "text": "which will result in their being downloaded. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=646"
  },
  {
    "text": "Now, some of you may be saying, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=651"
  },
  {
    "text": "I have some models that I don’t train using Create ML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=654"
  },
  {
    "text": "but instead I train using PyTorch or TensorFlow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=657"
  },
  {
    "text": "Can I still use these new BERT embeddings? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=660"
  },
  {
    "text": "Yes, you can. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=663"
  },
  {
    "text": "We provide these pre-trained multilingual embedding models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=665"
  },
  {
    "text": "that are available to you, that you can use as an input layer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=668"
  },
  {
    "text": "to just about any model you want to train. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=671"
  },
  {
    "text": "Here’s how that would work. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=674"
  },
  {
    "text": "On your macOS device, you would use NLContextualEmbedding ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=677"
  },
  {
    "text": "to get the embedding vectors for your training data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=681"
  },
  {
    "text": "You would then feed these as input to your training ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=684"
  },
  {
    "text": "using PyTorch or TensorFlow ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=687"
  },
  {
    "text": "and convert the result to a Core ML model using Core ML tools.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=689"
  },
  {
    "text": "Then at inference time on device, you would use NLContextualEmbedding ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=696"
  },
  {
    "text": "to get the embedding vectors for your input data, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=700"
  },
  {
    "text": "pass them into your Core ML model to get the output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=703"
  },
  {
    "text": "To support this, there are additional NLContextualEmbedding APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=707"
  },
  {
    "text": "that allow you to load a model, apply it to a piece of text, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=711"
  },
  {
    "text": "and get the resulting embedding vectors.",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=715"
  },
  {
    "text": "If you remember the model identifier from earlier, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=718"
  },
  {
    "text": "you can use that to retrieve the same model that you used for training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=722"
  },
  {
    "text": "You can then apply the model to a piece of text, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=726"
  },
  {
    "text": "giving an NLContextualEmbeddingResult object. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=729"
  },
  {
    "text": "Once you have this object, you can then use it ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=734"
  },
  {
    "text": "to iterate over the embedding vectors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=736"
  },
  {
    "text": "Now, to give you just a taste of what's possible with this, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=740"
  },
  {
    "text": "we prepared a simple example model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=743"
  },
  {
    "text": "We started with an existing English-language Stable Diffusion model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=746"
  },
  {
    "text": "then used some multilingual data to fine-tune it ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=751"
  },
  {
    "text": "to use the new BERT embeddings as an input layer, taking those as fixed, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=755"
  },
  {
    "text": "and also training a simple linear projection layer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=760"
  },
  {
    "text": "to convert dimensionalities. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=764"
  },
  {
    "text": "The result then is a Stable Diffusion model that takes multilingual input. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=766"
  },
  {
    "text": "Here are some examples of output from the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=772"
  },
  {
    "text": "If I pass in some English text, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=775"
  },
  {
    "text": "“A path through a garden full of pink flowers,” ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=778"
  },
  {
    "text": "the model leads us down a path into a garden full of pink flowers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=781"
  },
  {
    "text": "But also, if I translate the same sentence into French, Spanish, Italian, and German, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=786"
  },
  {
    "text": "the model produces images of paths and gardens full of pink flowers for each one. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=791"
  },
  {
    "text": "Let me take a slightly more complicated example. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=797"
  },
  {
    "text": "“A road in front of trees and mountains under a cloudy sky.” ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=800"
  },
  {
    "text": "Here’s some output from the model, with road, trees, mountains, and clouds. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=805"
  },
  {
    "text": "But likewise, I can translate the same sentence ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=811"
  },
  {
    "text": "into French, Spanish, Italian, and German, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=814"
  },
  {
    "text": "or any of a number of other languages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=817"
  },
  {
    "text": "and for each one get an image of road, trees, mountains, and clouds. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=819"
  },
  {
    "text": "Now let me sum up the lessons from this session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=825"
  },
  {
    "text": "You can use Create ML to easily train models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=829"
  },
  {
    "text": "for text classification or word tagging tasks, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=832"
  },
  {
    "text": "and the new multilingual BERT embedding models provide ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=835"
  },
  {
    "text": "a powerful input encoding layer for this purpose. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=838"
  },
  {
    "text": "These models can be single-language or multilingual. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=841"
  },
  {
    "text": "You can also use the BERT embeddings as input layers ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=845"
  },
  {
    "text": "for whatever model you want to train with PyTorch or TensorFlow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=848"
  },
  {
    "text": "Thank you. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=853"
  },
  {
    "text": "Now go out and start training some models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=854"
  },
  {
    "text": "♪ ♪",
    "link": "https://developer.apple.com/videos/play/wwdc2023-10042/?time=857"
  }
]