[
  {
    "text": "♪ ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=0"
  },
  {
    "text": "Pulkit: Hi, I am Pulkit, and I am an engineer on the Core ML team. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=10"
  },
  {
    "text": "I am excited to share several updates that have been made to Core ML Tools. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=14"
  },
  {
    "text": "These updates help you optimize the size and performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=18"
  },
  {
    "text": "of your machine learning models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=21"
  },
  {
    "text": "With the capabilities of models improving significantly, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=23"
  },
  {
    "text": "more and more features are being driven by machine learning. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=26"
  },
  {
    "text": "As a result, the number of models deployed in a single app is increasing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=30"
  },
  {
    "text": "Along with that, each model in the app is also getting bigger, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=34"
  },
  {
    "text": "putting an upward pressure on the size of an app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=38"
  },
  {
    "text": "So, it's critical to keep model size in check. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=41"
  },
  {
    "text": "There are several benefits of reducing model size. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=45"
  },
  {
    "text": "You can ship more models in the same memory budget if each model is smaller. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=48"
  },
  {
    "text": "It can also enable you to ship bigger, more capable models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=53"
  },
  {
    "text": "It can also help make the model run faster. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=57"
  },
  {
    "text": "This is because a smaller model means less data ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=60"
  },
  {
    "text": "to move between the memory and the processor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=63"
  },
  {
    "text": "So, it seems like reducing a model's size is a great idea. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=66"
  },
  {
    "text": "What makes a model large? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=70"
  },
  {
    "text": "Let me walk through an example to help you understand. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=72"
  },
  {
    "text": "ResNet50 is a popular image classification model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=75"
  },
  {
    "text": "Its first layer is a convolution layer with about 9,000 parameters. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=79"
  },
  {
    "text": "And it has 53 convolution layers in total with varying sizes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=83"
  },
  {
    "text": "At the end, it has a linear layer with about 2.1 million parameters. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=88"
  },
  {
    "text": "This all adds up to 25 million parameters ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=93"
  },
  {
    "text": "If I save the model using Float16 precision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=97"
  },
  {
    "text": "it uses 2 bytes per weight, and I get a model of size 50 megabytes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=100"
  },
  {
    "text": "A 50-megabyte model is large, but when you get to some newer models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=105"
  },
  {
    "text": "like Stable Diffusion, you end up with even larger models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=109"
  },
  {
    "text": "Now, let's talk about some paths to getting a smaller model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=113"
  },
  {
    "text": "One way is to design a more efficient model architecture ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=117"
  },
  {
    "text": "that can achieve good performance with fewer and smaller weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=120"
  },
  {
    "text": "Another way is to compress the weights of your existing model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=125"
  },
  {
    "text": "This path of model compression is what I will focus on. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=128"
  },
  {
    "text": "I'll start by describing three useful techniques for model compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=131"
  },
  {
    "text": "Next, I'll demonstrate two workflows ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=135"
  },
  {
    "text": "that integrate these model compression techniques. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=137"
  },
  {
    "text": "I'll then illustrate how the latest Core ML Tools helps you ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=140"
  },
  {
    "text": "in applying these techniques and workflows to your models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=143"
  },
  {
    "text": "And lastly, Srijan will discuss the impact of model compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=147"
  },
  {
    "text": "on runtime performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=150"
  },
  {
    "text": "Let's start with the compression techniques. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=152"
  },
  {
    "text": "There are a couple of ways to compress model weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=155"
  },
  {
    "text": "The first way is to pack them more efficiently ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=158"
  },
  {
    "text": "using a sparse matrix representation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=160"
  },
  {
    "text": "This can be achieved by using a technique called pruning. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=164"
  },
  {
    "text": "Another way is to reduce the precision used to store the weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=168"
  },
  {
    "text": "This can be achieved either by quantization or by palettization. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=172"
  },
  {
    "text": "Both of these strategies are lossy, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=177"
  },
  {
    "text": "and the compressed models are typically slightly less accurate ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=179"
  },
  {
    "text": "compared to their uncompressed counterparts.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=182"
  },
  {
    "text": "Let's now take a deeper look at each of these techniques.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=186"
  },
  {
    "text": "Weight pruning helps you efficiently pack your model weights ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=190"
  },
  {
    "text": "with a sparse representation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=193"
  },
  {
    "text": "Sparsifying or pruning a weight matrix ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=195"
  },
  {
    "text": "means setting some of the weight values to 0. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=197"
  },
  {
    "text": "I start with a weight matrix. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=200"
  },
  {
    "text": "To prune it, I can set the smallest magnitude weights to 0.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=202"
  },
  {
    "text": "Now, I only need to store the non-zero values. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=207"
  },
  {
    "text": "I end up saving about 2 bytes of storage for every zero introduced. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=212"
  },
  {
    "text": "Of course, I will also need to store the locations of zeros, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=216"
  },
  {
    "text": "to reconstruct the dense matrix later. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=219"
  },
  {
    "text": "Model size goes down linearly with the level of sparsity introduced. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=223"
  },
  {
    "text": "A 50% sparse model means 50% of its weights are zero, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=227"
  },
  {
    "text": "and for a ResNet50 model, it has a size of about 28 megabytes, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=232"
  },
  {
    "text": "which is approximately half the Float16 size.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=236"
  },
  {
    "text": "The second weight compression technique is quantization, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=241"
  },
  {
    "text": "which uses 8-bit precision to store the weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=244"
  },
  {
    "text": "To perform quantization, you take the weight values ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=248"
  },
  {
    "text": "and scale, shift, and round them such that they lie in the INT8 range. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=252"
  },
  {
    "text": "In this example, the scale is 2.35, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=257"
  },
  {
    "text": "which maps the smallest value to -127, and the bias is 0. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=260"
  },
  {
    "text": "Depending on the model, a non-zero bias can also be used, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=266"
  },
  {
    "text": "which sometimes helps in reducing quantization error. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=270"
  },
  {
    "text": "The scale and bias can later be used to de-quantize the weights ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=273"
  },
  {
    "text": "to bring them back to their original range. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=277"
  },
  {
    "text": "To reduce the weight precision below 8 bits, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=280"
  },
  {
    "text": "you can use a technique called weight clustering or palettization. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=283"
  },
  {
    "text": "In this technique, weights with similar values ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=287"
  },
  {
    "text": "are grouped together and represented ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=289"
  },
  {
    "text": "using the value of the cluster centroid they belong to. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=291"
  },
  {
    "text": "These centroids are stored in a look up table. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=295"
  },
  {
    "text": "And the original weight matrix is converted to an index table, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=298"
  },
  {
    "text": "where each element points to the corresponding cluster center. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=301"
  },
  {
    "text": "In this example, since I have four clusters, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=305"
  },
  {
    "text": "I am able to represent each weight using 2 bits, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=308"
  },
  {
    "text": "achieving 8x compression over Float16. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=311"
  },
  {
    "text": "The number of unique cluster centers that can be used to represent the weights ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=314"
  },
  {
    "text": "is equal to 2 to the power of n, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=317"
  },
  {
    "text": "where n is the precision used for palettization. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=320"
  },
  {
    "text": "So 4-bit palettization means you can have 16 clusters. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=323"
  },
  {
    "text": "While quantization reduces your model size by half, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=327"
  },
  {
    "text": "palettization can help you make it up to 8 times smaller.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=330"
  },
  {
    "text": "To summarize, there are three different techniques for weight compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=335"
  },
  {
    "text": "Each of them uses a different way to represent the weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=340"
  },
  {
    "text": "They offer varying levels of compression, which can be controlled ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=344"
  },
  {
    "text": "by their respective parameters, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=347"
  },
  {
    "text": "like the amount of sparsity for pruning ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=349"
  },
  {
    "text": "and the number of bits for palettization. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=351"
  },
  {
    "text": "Now, I will illustrate how you can integrate these techniques ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=353"
  },
  {
    "text": "in your model development workflow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=356"
  },
  {
    "text": "Let's first start with the workflow for Core ML model conversion. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=358"
  },
  {
    "text": "You may start by training a model with your favorite python training framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=362"
  },
  {
    "text": "and then use Core ML Tools to convert that model to Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=367"
  },
  {
    "text": "This workflow can be extended one step further ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=371"
  },
  {
    "text": "to become a post-training compression workflow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=374"
  },
  {
    "text": "To do that, you add a compression step which operates on the already trained ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=377"
  },
  {
    "text": "and converted model weights in order to reduce the overall size. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=381"
  },
  {
    "text": "Note that this workflow can start at any point. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=385"
  },
  {
    "text": "For example, you may start with a pre-trained model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=388"
  },
  {
    "text": "with no need for training data or an already converted Core ML model.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=391"
  },
  {
    "text": "When applying this workflow, you will have an option ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=396"
  },
  {
    "text": "to choose the amount of compression applied. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=399"
  },
  {
    "text": "The more compression you apply, the smaller your resulting model will be, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=401"
  },
  {
    "text": "but as one may expect, there are some tradeoffs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=405"
  },
  {
    "text": "Specifically, you will be starting with an uncompressed model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=408"
  },
  {
    "text": "that achieves a certain accuracy. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=411"
  },
  {
    "text": "As you apply some compression, your model size will reduce, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=414"
  },
  {
    "text": "but it may also impact your accuracy. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=418"
  },
  {
    "text": "As you apply more compression, this impact may become more prominent ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=421"
  },
  {
    "text": "and the accuracy loss may become unacceptable.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=424"
  },
  {
    "text": "This trend and the acceptable tradeoff will be different for each use case ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=429"
  },
  {
    "text": "and it is model- and dataset-dependent. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=432"
  },
  {
    "text": "To see this tradeoff in practice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=435"
  },
  {
    "text": "let's look at a model that segments objects in an image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=437"
  },
  {
    "text": "For my image, the model returns probability ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=441"
  },
  {
    "text": "of each pixel belonging to the sofa. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=443"
  },
  {
    "text": "The baseline Float16 model segments the object very well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=446"
  },
  {
    "text": "For a 10% pruned model, the output is very similar to the base model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=449"
  },
  {
    "text": "Artifacts start appearing at 30% sparsity ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=453"
  },
  {
    "text": "and increase with higher levels. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=457"
  },
  {
    "text": "Once I get to 40% pruning, the model completely breaks down, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=460"
  },
  {
    "text": "and the probability map becomes unrecognizable. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=463"
  },
  {
    "text": "Similarly, 8-bit quantization and 6-bit palettization ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=467"
  },
  {
    "text": "preserve the base model's output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=471"
  },
  {
    "text": "At 4-bit palettization, you start seeing some artifacts, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=473"
  },
  {
    "text": "and at 2-bit palettization, the model fails to segment the object altogether. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=478"
  },
  {
    "text": "To overcome this degradation in model performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=483"
  },
  {
    "text": "at higher compression rates, you can use a different workflow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=485"
  },
  {
    "text": "This workflow is called training time compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=488"
  },
  {
    "text": "Here, you fine-tune your model on some data ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=491"
  },
  {
    "text": "while compressing the weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=494"
  },
  {
    "text": "Compression is introduced gradually and in a differentiable manner ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=496"
  },
  {
    "text": "to allow the weights to readjust to the new constraints imposed on them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=500"
  },
  {
    "text": "Once your model achieves a satisfactory accuracy, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=504"
  },
  {
    "text": "you can convert it and get a compressed Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=507"
  },
  {
    "text": "Note that you may either incorporate training time compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=511"
  },
  {
    "text": "in your existing model training workflow or start with a pre-trained model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=514"
  },
  {
    "text": "Training time compression improves the tradeoff between model accuracy ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=519"
  },
  {
    "text": "and the amount of compression, allowing you to maintain ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=524"
  },
  {
    "text": "the same model performance at higher compression rates. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=526"
  },
  {
    "text": "Let's look at the same image segmentation model again. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=530"
  },
  {
    "text": "For training time pruning, the model output is unaltered ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=533"
  },
  {
    "text": "up to 40% sparsity. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=536"
  },
  {
    "text": "This is where the post-training accuracy broke down. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=538"
  },
  {
    "text": "In fact, now even at 50% and 75% sparsity, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=542"
  },
  {
    "text": "the model achieves a similar probability map as the base model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=546"
  },
  {
    "text": "It's at 90% sparsity that you start observing ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=550"
  },
  {
    "text": "a significant degradation in model accuracy. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=553"
  },
  {
    "text": "Similarly, training time quantization and palettization ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=556"
  },
  {
    "text": "also preserve the baseline model's output, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=559"
  },
  {
    "text": "even up to 2 bits of compression in this case. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=561"
  },
  {
    "text": "To recap, you can apply weight compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=564"
  },
  {
    "text": "either during model conversion or during model training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=567"
  },
  {
    "text": "The latter provides better accuracy tradeoff ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=571"
  },
  {
    "text": "at the cost of longer training time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=573"
  },
  {
    "text": "Because the second workflow applies compression during training, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=576"
  },
  {
    "text": "we also need to use differentiable operations ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=579"
  },
  {
    "text": "to implement the compression algorithms. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=582"
  },
  {
    "text": "Let's now explore how these compression workflows can be executed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=584"
  },
  {
    "text": "with Core ML Tools. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=588"
  },
  {
    "text": "Post-training model compression APIs have been available in Core ML Tools 6 ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=589"
  },
  {
    "text": "for pruning, palettization, and quantization ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=593"
  },
  {
    "text": "under the compression utils submodule. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=597"
  },
  {
    "text": "However, there were no APIs for training time compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=599"
  },
  {
    "text": "With Core ML Tools 7, new APIs have been added ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=603"
  },
  {
    "text": "to provide capabilities for training time compression as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=606"
  },
  {
    "text": "And we have consolidated the older APIs and the new ones under a single module ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=610"
  },
  {
    "text": "called coremltools.optimize. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=614"
  },
  {
    "text": "The post-training compression APIs have been migrated ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=617"
  },
  {
    "text": "under coremltools.optimize.coreml, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=620"
  },
  {
    "text": "and the new training time APIs are available ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=623"
  },
  {
    "text": "under coremltools.optimize.torch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=625"
  },
  {
    "text": "The latter work with PyTorch models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=628"
  },
  {
    "text": "Let's first take a closer look at the post-training APIs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=631"
  },
  {
    "text": "In the post-training compression workflow, the input is a Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=635"
  },
  {
    "text": "It can be updated by the three methods available in the optimize.coreml module, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=640"
  },
  {
    "text": "which apply each of the three compression techniques that I have described. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=645"
  },
  {
    "text": "To use these methods, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=649"
  },
  {
    "text": "you start by creating an OptimizationConfig object, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=650"
  },
  {
    "text": "describing how you want to compress the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=654"
  },
  {
    "text": "Here, I am doing magnitude pruning with 75% target sparsity. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=657"
  },
  {
    "text": "Once the config is defined, you can use the prune_weights method ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=662"
  },
  {
    "text": "to prune the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=665"
  },
  {
    "text": "It's a simple, one-step process to get a compressed model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=667"
  },
  {
    "text": "You can use similar APIs for palettizing and quantizing the weights ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=670"
  },
  {
    "text": "using configs specific to those techniques. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=674"
  },
  {
    "text": "Let's consider the training time compression workflow now. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=677"
  },
  {
    "text": "In this case, as I described earlier, you need a trainable model and data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=680"
  },
  {
    "text": "More specifically, to compress the model with Core ML Tools, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=684"
  },
  {
    "text": "you start with a PyTorch model, likely with pre-trained weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=688"
  },
  {
    "text": "Then use one of the available APIs in the optimize.torch module to update it ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=692"
  },
  {
    "text": "and get a new PyTorch model with compression layers inserted in it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=697"
  },
  {
    "text": "And then fine-tune it, using the data and the original PyTorch training code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=701"
  },
  {
    "text": "This is the step where weights will get adjusted to allow for compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=706"
  },
  {
    "text": "And you can do this step on your MacBook locally, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=711"
  },
  {
    "text": "using the MPS PyTorch backend. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=713"
  },
  {
    "text": "Once the model gets trained to regain accuracy, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=716"
  },
  {
    "text": "convert it to get a Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=719"
  },
  {
    "text": "Let's explore this further through a code example. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=721"
  },
  {
    "text": "I am starting with the PyTorch code required ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=724"
  },
  {
    "text": "to fine-tune the model I want to compress. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=726"
  },
  {
    "text": "You can easily leverage Core ML Tools to add training time pruning ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=729"
  },
  {
    "text": "by adding just a few lines of code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=733"
  },
  {
    "text": "You first create a MagnitudePrunerConfig object ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=735"
  },
  {
    "text": "describing how you want to prune the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=738"
  },
  {
    "text": "Here, I am setting the target sparsity to 75%. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=740"
  },
  {
    "text": "You can also write the config in a yaml file ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=744"
  },
  {
    "text": "and load it using the from_yaml method. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=746"
  },
  {
    "text": "Then, you create a pruner object with the model you want to compress ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=749"
  },
  {
    "text": "and the config you just created. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=753"
  },
  {
    "text": "Next, you call prepare to insert pruning layers in the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=754"
  },
  {
    "text": "While fine-tuning the model, you call step API ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=758"
  },
  {
    "text": "to update the pruner's internal state. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=761"
  },
  {
    "text": "At the end of the training, you call finalize ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=763"
  },
  {
    "text": "to fold the pruning masks into the weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=765"
  },
  {
    "text": "This model can then be converted to Core ML using the conversion APIs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=768"
  },
  {
    "text": "The same workflow can be used for quantization and palettization as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=772"
  },
  {
    "text": "Now, Srijan will walk you through a demo showing how you can use ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=777"
  },
  {
    "text": "Core ML Tools APIs to palettize an object detection model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=781"
  },
  {
    "text": "Srijan: Thank you, Pulkit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=785"
  },
  {
    "text": "My name is Srijan, and I will be walking you through a demo ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=786"
  },
  {
    "text": "of the Core ML Tools optimize API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=790"
  },
  {
    "text": "I will be using an SSD model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=793"
  },
  {
    "text": "with a ResNet18 backbone to detect people in images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=796"
  },
  {
    "text": "Let's first import some basic model and training utilities. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=801"
  },
  {
    "text": "I am going to start with getting an instance ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=805"
  },
  {
    "text": "of the SSD ResNet18 model I just talked about. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=808"
  },
  {
    "text": "To simplify things, I will just call the pre-written ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=812"
  },
  {
    "text": "get_ssd_model utility for that. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=816"
  },
  {
    "text": "Now that the model is loaded, let's train it for a few epochs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=820"
  },
  {
    "text": "Since it's an object detection model, the goal of training would be ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=824"
  },
  {
    "text": "to reduce the SSD loss of the detection task. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=829"
  },
  {
    "text": "For conciseness, the train_epoch utility encapsulates the code ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=833"
  },
  {
    "text": "required to train the model for an epoch, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=838"
  },
  {
    "text": "like calling the forward through different batches, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=841"
  },
  {
    "text": "calculating the loss, and performing gradient descent. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=844"
  },
  {
    "text": "During training, the SSD loss seems to be coming down. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=848"
  },
  {
    "text": "I will now convert the model into a Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=852"
  },
  {
    "text": "To do that, I will first trace the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=856"
  },
  {
    "text": "and then call the coremltools.convert API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=859"
  },
  {
    "text": "Let's call an imported utility to check out the size of the model.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=864"
  },
  {
    "text": "The size of the model is 23.6 megabytes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=870"
  },
  {
    "text": "Now, I will run predictions on the Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=874"
  },
  {
    "text": "I have chosen an image of myself from my London trip ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=878"
  },
  {
    "text": "as well as another image to test the detections. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=881"
  },
  {
    "text": "The confidence threshold for the model to detect an object is set to 30% ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=885"
  },
  {
    "text": "so it would only plot boxes for which it is at least 30% confident ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=891"
  },
  {
    "text": "of the object being present.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=896"
  },
  {
    "text": "That detection seems spot on. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=905"
  },
  {
    "text": "I am now curious to see if I can reduce the size of this model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=907"
  },
  {
    "text": "I am going to try out post-training palettization first. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=912"
  },
  {
    "text": "For that, I'll import some config classes ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=916"
  },
  {
    "text": "and methods from coremltools.optimize.coreml.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=920"
  },
  {
    "text": "I am now going to palettize the weights of the model with 6 bits. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=926"
  },
  {
    "text": "For that, I'll create an OpPalettizerConfig object, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=930"
  },
  {
    "text": "specifying mode as kmeans and nbits as 6. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=934"
  },
  {
    "text": "This will specify parameters at an op level, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=938"
  },
  {
    "text": "and I can palettize each op differently. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=942"
  },
  {
    "text": "However, right now, I'm gonna apply the same 6-bit mode to all the ops. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=945"
  },
  {
    "text": "I'll do that by defining OptimizationConfig ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=951"
  },
  {
    "text": "and pass this op_config as a global parameter to it.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=955"
  },
  {
    "text": "The optimization config is then passed to the palettize_weights method ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=960"
  },
  {
    "text": "along with the converted model to get a palettized model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=965"
  },
  {
    "text": "Let's see what the size got reduced to now.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=970"
  },
  {
    "text": "The size of the model has gone down to around 9 megabytes, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=975"
  },
  {
    "text": "but did it affect the performance on test images? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=980"
  },
  {
    "text": "Let's find out. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=982"
  },
  {
    "text": "Wow, the detection still works well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=984"
  },
  {
    "text": "I am really excited to push my luck to trying out ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=987"
  },
  {
    "text": "2-bit post-training palettization now. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=991"
  },
  {
    "text": "Doing that is as simple as just changing nbits from 6 to 2 ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=995"
  },
  {
    "text": "in the OpPalettizerConfig ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1000"
  },
  {
    "text": "and running the palettize_weights API again.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1002"
  },
  {
    "text": "Let's use the utilities to see the size and performance of this Core ML model.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1008"
  },
  {
    "text": "As expected, the model's size has reduced and has come down to around 3 megabytes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1017"
  },
  {
    "text": "The performance, however, is suboptimal ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1023"
  },
  {
    "text": "as the model isn't able to detect people in both the images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1026"
  },
  {
    "text": "No boxes show up in the prediction, as none of the boxes ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1031"
  },
  {
    "text": "predicted by the model have confidence probability ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1035"
  },
  {
    "text": "above the 30% threshold. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1039"
  },
  {
    "text": "Let's try out 2-bit training time palettization ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1041"
  },
  {
    "text": "to see if that performs better.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1045"
  },
  {
    "text": "I will start by importing DKMPalettizerConfig ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1048"
  },
  {
    "text": "and DKMPalettizer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1052"
  },
  {
    "text": "from coremltools.optimize.torch to do that. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1054"
  },
  {
    "text": "DKM is an algorithm to learn weight clusters ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1058"
  },
  {
    "text": "by performing an attention-based differentiable kmeans operation on them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1062"
  },
  {
    "text": "Now it's time to define the palettization config. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1068"
  },
  {
    "text": "Just need to simply specify n_bits as 2 in the global_config, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1072"
  },
  {
    "text": "and all supported modules would be 2-bit palettized. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1077"
  },
  {
    "text": "And here, I'll create a palettizer object ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1081"
  },
  {
    "text": "from the model and the config. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1084"
  },
  {
    "text": "Calling the prepare API now would insert ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1087"
  },
  {
    "text": "palettization-friendly modules into the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1090"
  },
  {
    "text": "Time to fine-tune the model for a few epochs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1093"
  },
  {
    "text": "Now that the model has been fine-tuned, I will call the finalize API ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1097"
  },
  {
    "text": "which would restore the palettized weights as weights of the model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1102"
  },
  {
    "text": "thus completing the process. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1106"
  },
  {
    "text": "The next step is to check out the size of the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1109"
  },
  {
    "text": "For that, I will convert the torch model into a Core ML model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1112"
  },
  {
    "text": "Let's start by tracing the model using torch.jit.trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1118"
  },
  {
    "text": "I will now call the convert API, and this time, I will use ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1122"
  },
  {
    "text": "an additional flag called PassPipeline ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1127"
  },
  {
    "text": "and set its value to DEFAULT_PALETTIZATION. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1130"
  },
  {
    "text": "This will indicate to the converter to use a palettized representation ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1133"
  },
  {
    "text": "for the converted weights.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1139"
  },
  {
    "text": "Let's see the size of the model and its performance on test images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1143"
  },
  {
    "text": "I can see that the model I training-time palettized ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1148"
  },
  {
    "text": "is around 3 megabytes as well, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1151"
  },
  {
    "text": "which comes down to 8x compression, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1153"
  },
  {
    "text": "but unlike the post-training palettized model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1156"
  },
  {
    "text": "this model is performing the detection on test images correctly. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1158"
  },
  {
    "text": "Since this was a demo, I just tested model performance on two sample images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1163"
  },
  {
    "text": "In a real-world scenario, I would use a metric ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1169"
  },
  {
    "text": "like mean average precision and evaluate on a validation data set.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1173"
  },
  {
    "text": "Let's recap. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1178"
  },
  {
    "text": "I started with a trained model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1180"
  },
  {
    "text": "and converted it to get a 23.6-megabyte model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1182"
  },
  {
    "text": "with Float16 weights. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1186"
  },
  {
    "text": "Then, I used the palettize_weights API to quickly get a smaller model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1188"
  },
  {
    "text": "with 6-bit weights, which did perform well on my data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1193"
  },
  {
    "text": "However, when I pushed it further to 2 bits, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1197"
  },
  {
    "text": "it showed a clear drop in performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1201"
  },
  {
    "text": "Post this, I updated the torch model with the optimize.torch APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1204"
  },
  {
    "text": "and used the differentiable kmeans algorithm ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1209"
  },
  {
    "text": "to fine-tune for a few epochs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1212"
  },
  {
    "text": "With that, I was able to get good accuracy ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1215"
  },
  {
    "text": "with the 2-bit compression option. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1219"
  },
  {
    "text": "While the demo employed a specific model and optimization algorithm combination, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1222"
  },
  {
    "text": "this workflow will generalize to your use case ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1228"
  },
  {
    "text": "and will help you in figuring out the tradeoff ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1231"
  },
  {
    "text": "between the amount of compression you desire ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1233"
  },
  {
    "text": "and the time and data required to retrain the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1236"
  },
  {
    "text": "This brings us to our last topic, performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1240"
  },
  {
    "text": "I would like to briefly touch upon the improvements ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1244"
  },
  {
    "text": "that have been made to the Core ML runtime ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1247"
  },
  {
    "text": "to execute such models more efficiently when deployed in your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1250"
  },
  {
    "text": "Let's look at a few key differences ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1255"
  },
  {
    "text": "between the runtime in iOS 16 and iOS 17. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1258"
  },
  {
    "text": "While in iOS 16, there was support for weight-only compressed models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1262"
  },
  {
    "text": "in iOS 17, 8-bit activation quantized models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1267"
  },
  {
    "text": "can also be executed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1272"
  },
  {
    "text": "In iOS 16, a weight compressed model runs ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1274"
  },
  {
    "text": "at the same speed as the corresponding model with float weights, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1278"
  },
  {
    "text": "while in iOS 17, the Core ML runtime has been updated, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1282"
  },
  {
    "text": "and now compressed models run faster in certain scenarios. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1287"
  },
  {
    "text": "Similar runtime improvements are available in newer versions ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1291"
  },
  {
    "text": "of macOS, tvOS, and watchOS as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1296"
  },
  {
    "text": "But how are these improvements achieved? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1300"
  },
  {
    "text": "In models, where only the weights are compressed, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1303"
  },
  {
    "text": "since the activations are in floating point precision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1307"
  },
  {
    "text": "before an operation such as a convolution ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1311"
  },
  {
    "text": "or a matrix multiplication can happen, the weight values need to be decompressed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1314"
  },
  {
    "text": "to match the precision of the other input. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1320"
  },
  {
    "text": "This step of decompression takes place ahead of time ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1323"
  },
  {
    "text": "in the iOS 16 runtime. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1327"
  },
  {
    "text": "Hence, in this case, the model is converted ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1330"
  },
  {
    "text": "to a fully float precision model in memory prior to execution. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1334"
  },
  {
    "text": "Hence, no change is observed in inference latency. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1339"
  },
  {
    "text": "However, in iOS 17, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1343"
  },
  {
    "text": "in certain scenarios, the weights are decompressed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1346"
  },
  {
    "text": "just in time, just before the operation is executed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1349"
  },
  {
    "text": "This has the advantage of loading smaller bit weights from the memory ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1353"
  },
  {
    "text": "at the cost of doing decompression in every inference call. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1359"
  },
  {
    "text": "For certain compute units, such as the Neural Engine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1364"
  },
  {
    "text": "and certain types of models that are memory bound, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1368"
  },
  {
    "text": "this could lead to inference gains. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1372"
  },
  {
    "text": "To illustrate these runtime benefits, I selected and profiled a few models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1375"
  },
  {
    "text": "and plotted the relative amount by which their inference is sped up ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1380"
  },
  {
    "text": "compared to their Float16 variant.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1385"
  },
  {
    "text": "As expected, the amount of speedup is model- and hardware-dependent. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1388"
  },
  {
    "text": "These are the range of speedups for 4-bit palettized models ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1394"
  },
  {
    "text": "on iPhone 14 Pro Max. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1399"
  },
  {
    "text": "The improvements vary between 5% to 30%. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1401"
  },
  {
    "text": "For sparse models too, there are varying improvements based on model type, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1407"
  },
  {
    "text": "with some models running 75% faster ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1413"
  },
  {
    "text": "than their Float16 variants. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1416"
  },
  {
    "text": "The question now arises: what is the strategy ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1419"
  },
  {
    "text": "to get the best latency performance? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1423"
  },
  {
    "text": "That would be to start with a float model ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1426"
  },
  {
    "text": "and use the optimize.coreml APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1430"
  },
  {
    "text": "to explore various representations of the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1433"
  },
  {
    "text": "This would be quick, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1436"
  },
  {
    "text": "as it doesn't require retraining the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1438"
  },
  {
    "text": "Then, profile it on the device of your interest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1442"
  },
  {
    "text": "For this, Core ML performance reports in Xcode will give you ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1445"
  },
  {
    "text": "a lot of visibility into inference, including where operations run. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1450"
  },
  {
    "text": "Then, shortlist based on which configurations ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1456"
  },
  {
    "text": "give you the best gains. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1459"
  },
  {
    "text": "After this, you can focus on evaluating accuracy ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1461"
  },
  {
    "text": "and trying to improve, which may require applying some training time compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1465"
  },
  {
    "text": "with torch and Core ML Tools ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1471"
  },
  {
    "text": "before finalizing your model.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1473"
  },
  {
    "text": "To summarize, it is important to reduce the size of the models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1476"
  },
  {
    "text": "and now you can do that more easily than ever ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1481"
  },
  {
    "text": "with the new Core ML Tools APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1484"
  },
  {
    "text": "and achieve lower memory footprint and inference speedups. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1486"
  },
  {
    "text": "To check out more options and benchmarking data, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1490"
  },
  {
    "text": "do visit our documentation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1493"
  },
  {
    "text": "I would also highly recommend ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1496"
  },
  {
    "text": "tuning in to the \"Improve Core ML integration with async prediction\" video ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1498"
  },
  {
    "text": "which talks about improvements made to the Core ML framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1503"
  },
  {
    "text": "that I did not cover in the slides today. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1506"
  },
  {
    "text": "Thank you, and happy compressing.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10047/?time=1508"
  }
]