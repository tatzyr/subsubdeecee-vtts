[
  {
    "text": "♪ ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=0"
  },
  {
    "text": "Grant: Hi, my name is Grant. I’m an Engineer on the Accessibility Team. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=10"
  },
  {
    "text": "Many people use speech synthesis across Apple platforms ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=15"
  },
  {
    "text": "and some people rely on synthesizer voices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=19"
  },
  {
    "text": "These voices are a window into their devices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=23"
  },
  {
    "text": "Therefore, the voices they choose are often a very personal choice.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=26"
  },
  {
    "text": "People using speech synthesis on iOS can already choose from many different voices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=31"
  },
  {
    "text": "Let’s take a look at how you can provide even more. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=37"
  },
  {
    "text": "First, we’ll talk about what Speech Synthesis Markup Language is, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=41"
  },
  {
    "text": "how it can bring immersive speech output to your custom voices, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=46"
  },
  {
    "text": "and why your speech provider should adopt it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=51"
  },
  {
    "text": "Next, we’ll walk through how you can implement a speech synthesis provider ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=55"
  },
  {
    "text": "to bring your synthesizer and voice experiences across the device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=60"
  },
  {
    "text": "And finally, we’ll dive into Personal Voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=65"
  },
  {
    "text": "This is a new feature. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=69"
  },
  {
    "text": "Now, people can record their voice ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=71"
  },
  {
    "text": "and then generate a synthesized voice from those recordings. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=74"
  },
  {
    "text": "So now, you can synthesize speech with the user's own personal voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=78"
  },
  {
    "text": "Let’s start by taking a look at SSML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=84"
  },
  {
    "text": "SSML is a W3C standard for representing spoken text. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=89"
  },
  {
    "text": "SSML Speech is represented declaratively ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=95"
  },
  {
    "text": "using XML format with various tags and attributes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=99"
  },
  {
    "text": "You can use these tags to control speech properties like rate and pitch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=103"
  },
  {
    "text": "SSML is used in first-party synthesizers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=109"
  },
  {
    "text": "This includes WebSpeech in WebKit ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=113"
  },
  {
    "text": "and is the standard input for speech synthesizers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=116"
  },
  {
    "text": "Let’s take a look at how you can use SSML.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=120"
  },
  {
    "text": "Take this example phrase that has a pause in it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=124"
  },
  {
    "text": "We can represent this pause in SSML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=127"
  },
  {
    "text": "We’ll start with our \"hello\" string, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=131"
  },
  {
    "text": "add our one second pause using an SSML break tag, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=134"
  },
  {
    "text": "and finish by speeding up \"nice to meet you!\" ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=138"
  },
  {
    "text": "We do this by adding an SSML prosody tag ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=141"
  },
  {
    "text": "and setting the rate attribute to 200%. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=145"
  },
  {
    "text": "Now we can take this SSML and create an AVSpeechUtterance to speak with. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=149"
  },
  {
    "text": "Next, let’s take a look at how you can implement ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=156"
  },
  {
    "text": "your own speech synthesizer voices.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=159"
  },
  {
    "text": "So what is a speech synthesizer? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=163"
  },
  {
    "text": "A speech synthesizer receives some text and information ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=165"
  },
  {
    "text": "about desired speech properties in the form of SSML ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=169"
  },
  {
    "text": "and provides an audio representation of that text.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=173"
  },
  {
    "text": "Suppose you have a synthesizer with great new voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=178"
  },
  {
    "text": "and you want to bring it to iOS, macOS, and iPadOS. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=181"
  },
  {
    "text": "Speech synthesis providers allow you to implement ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=186"
  },
  {
    "text": "your own speech synthesizers and voices into our platforms ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=189"
  },
  {
    "text": "to give even more personalization to users beyond system voices.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=193"
  },
  {
    "text": "Let’s see how this works. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=199"
  },
  {
    "text": "Speech Synthesis provider audio unit extensions will be embedded in a host app ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=201"
  },
  {
    "text": "and will receive speech requests in the form of SSML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=206"
  },
  {
    "text": "The extension will be responsible for rendering audio for the SSML input ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=210"
  },
  {
    "text": "and optionally returning markers indicating where words occur ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=216"
  },
  {
    "text": "within those audio buffers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=220"
  },
  {
    "text": "The system will then manage all playback for that speech request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=222"
  },
  {
    "text": "You don't need to handle any audio session management; ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=226"
  },
  {
    "text": "it's managed internally by the Speech Synthesis Provider framework.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=229"
  },
  {
    "text": "Now that we understand what a synthesizer is, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=235"
  },
  {
    "text": "we can start to build a speech synthesizer extension.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=238"
  },
  {
    "text": "Let’s start by creating a new Audio Unit Extension app project in Xcode, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=242"
  },
  {
    "text": "then select the \"Speech Synthesizer\" Audio Unit Type ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=247"
  },
  {
    "text": "and provide a four character subtype identifier for your synthesizer, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=251"
  },
  {
    "text": "as well as a four character identifier for you as a manufacturer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=255"
  },
  {
    "text": "Audio unit extensions are the core architecture ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=260"
  },
  {
    "text": "upon which speech synthesizer extensions have been built. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=263"
  },
  {
    "text": "They allow your synthesizer to run in an extension process ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=267"
  },
  {
    "text": "instead of in your host app process.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=270"
  },
  {
    "text": "Our app is going to provide a simple interface ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=273"
  },
  {
    "text": "for buying and selecting a voice that our extension will synthesize speech for. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=276"
  },
  {
    "text": "We’ll start by creating a list view that shows our available voices for purchase. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=282"
  },
  {
    "text": "Each voice cell will show the voice name and a buy button.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=288"
  },
  {
    "text": "Next, I will populate my list with some voices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=292"
  },
  {
    "text": "Here, WWDCVoice is a simple struct holding the voice name and identifier.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=296"
  },
  {
    "text": "We also need a state variable for keeping track of purchased voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=304"
  },
  {
    "text": "and a new section to display them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=309"
  },
  {
    "text": "Next, let’s create a function for purchasing a voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=313"
  },
  {
    "text": "Here we can add the newly purchased voice to our list ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=317"
  },
  {
    "text": "and update our UI accordingly. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=321"
  },
  {
    "text": "Take note of the AVSpeechSynthesisProviderVoice method ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=323"
  },
  {
    "text": "updateSpeechVoices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=327"
  },
  {
    "text": "That is how your app can signal that the set of available voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=329"
  },
  {
    "text": "for your synthesizer has changed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=333"
  },
  {
    "text": "and the system voice list should be rebuilt. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=335"
  },
  {
    "text": "In our example, we can make this call ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=339"
  },
  {
    "text": "after completing an in-app purchase for a voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=341"
  },
  {
    "text": "We also need a way to keep tabs on which voices are available ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=346"
  },
  {
    "text": "in our speech synthesizer extension. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=350"
  },
  {
    "text": "This can be done by creating an instance of UserDefaults ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=353"
  },
  {
    "text": "that will be shared through an app group. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=356"
  },
  {
    "text": "An app group will allow us to share this voice list ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=359"
  },
  {
    "text": "between our host app and our extension. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=362"
  },
  {
    "text": "We are explicitly specifying a suite name ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=365"
  },
  {
    "text": "that we provided when creating the app group. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=367"
  },
  {
    "text": "This ensures the host app and extension read from the same domain.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=371"
  },
  {
    "text": "Taking a look back at the purchase function, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=376"
  },
  {
    "text": "I have implemented a method to update my user defaults ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=378"
  },
  {
    "text": "when a new voice is purchased. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=381"
  },
  {
    "text": "AVSpeechSynthesizer also has new API ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=385"
  },
  {
    "text": "to listen for a change in available system voices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=388"
  },
  {
    "text": "The set of system voices can change when a user deletes a voice ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=391"
  },
  {
    "text": "or downloads a new one. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=396"
  },
  {
    "text": "You can subscribe to the availableVoicesDidChangeNotification ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=398"
  },
  {
    "text": "to update your list of voices based on these changes.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=402"
  },
  {
    "text": "Now that our host app is done, let's fill in the audio unit, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=407"
  },
  {
    "text": "which consists of four key components.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=410"
  },
  {
    "text": "The first thing we’ll need to add is some way to inform the system of ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=414"
  },
  {
    "text": "what voices our synthesizer will provide. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=418"
  },
  {
    "text": "This is accomplished by overriding the speechVoices getter ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=421"
  },
  {
    "text": "to provide a list of voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=425"
  },
  {
    "text": "and reading from our app group UserDefaults domain we specified earlier. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=428"
  },
  {
    "text": "For each item in our voice list, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=433"
  },
  {
    "text": "we’ll construct a US English AVSpeechSynthesisProviderVoice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=435"
  },
  {
    "text": "Next, we need some way for the system to tell the synthesizer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=441"
  },
  {
    "text": "what text to synthesize. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=445"
  },
  {
    "text": "The synthesizeSpeechRequest method will be called ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=447"
  },
  {
    "text": "when the system wants to signal to an extension ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=450"
  },
  {
    "text": "that it should start synthesizing some text. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=453"
  },
  {
    "text": "The argument to this method will be an instance of ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=456"
  },
  {
    "text": "AVSpeechSynthesisProviderRequest ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=459"
  },
  {
    "text": "containing SSML and which voice to speak with. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=462"
  },
  {
    "text": "Next, I’ll call a helper method I’ve created ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=466"
  },
  {
    "text": "in my speech engine implementation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=469"
  },
  {
    "text": "In this example, my getAudioBuffer method will generate audio data ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=471"
  },
  {
    "text": "based on the voice specified in the request and the SSML input. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=476"
  },
  {
    "text": "We’ll also set an instance variable, called framePosition, to 0 ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=481"
  },
  {
    "text": "in order to keep track of how many frames we’ve rendered ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=485"
  },
  {
    "text": "as the render block is called and we copy frames out of the buffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=488"
  },
  {
    "text": "The system also needs a way to signal to a synthesizer to stop synthesizing audio ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=493"
  },
  {
    "text": "and discard the current speech request. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=499"
  },
  {
    "text": "This is accomplished with cancelSpeechRequest, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=501"
  },
  {
    "text": "where we will simply discard the current buffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=504"
  },
  {
    "text": "Finally, we need to implement the render block. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=507"
  },
  {
    "text": "The render block is called by the system with a desired frameCount. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=511"
  },
  {
    "text": "The audio unit is then responsible for filling the requested number of frames ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=515"
  },
  {
    "text": "into the outputAudioBuffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=519"
  },
  {
    "text": "Next, we will set ourselves up with a reference to the target buffer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=522"
  },
  {
    "text": "and the buffer we generated and stored earlier ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=526"
  },
  {
    "text": "during the synthesizeSpeechRequest call. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=529"
  },
  {
    "text": "Then, we’ll copy the frames into the target buffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=533"
  },
  {
    "text": "And then finally, once the audio unit has exhausted all the buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=537"
  },
  {
    "text": "for the current speech request, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=541"
  },
  {
    "text": "the actionFlags argument should be set to offlineUnitRenderAction_Complete ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=543"
  },
  {
    "text": "to signal to the system that rendering has completed ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=548"
  },
  {
    "text": "and there are no more audio buffers to be rendered. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=551"
  },
  {
    "text": "Let's see it in action! ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=554"
  },
  {
    "text": "This is my speech synthesizer app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=556"
  },
  {
    "text": "I will purchase a voice and navigate to a view where I can synthesize speech ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=559"
  },
  {
    "text": "using my new voice and speech engine. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=563"
  },
  {
    "text": "First, I will give the synthesizer an input of \"hello.\" ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=567"
  },
  {
    "text": "Synthesized voice: Hello. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=574"
  },
  {
    "text": "Grant: Then I’ll give the input \"goodbye.\" ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=576"
  },
  {
    "text": "Synthesized voice: Goodbye.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=581"
  },
  {
    "text": "Grant: We’ve now implemented a synthesis provider ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=583"
  },
  {
    "text": "and created a hosting app that provides voices you can use across the system, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=586"
  },
  {
    "text": "from VoiceOver to your own apps! ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=591"
  },
  {
    "text": "We can't wait to see what new voices and text-to-speech experiences you craft ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=594"
  },
  {
    "text": "using these APIs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=598"
  },
  {
    "text": "Let’s move on and talk about a new feature called Personal Voice.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=601"
  },
  {
    "text": "People can now record and recreate their voice on iOS and macOS ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=606"
  },
  {
    "text": "using the power of their device.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=611"
  },
  {
    "text": "Your Personal Voice is generated on the device and not on a server. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=614"
  },
  {
    "text": "This voice will appear amongst the rest of the System voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=619"
  },
  {
    "text": "and can be used with a new feature called Live Speech. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=622"
  },
  {
    "text": "Live Speech is a type-to-speak feature on iOS, iPadOS, macOS, and watchOS ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=626"
  },
  {
    "text": "that lets a person synthesize speech with their own voice on the fly.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=633"
  },
  {
    "text": "You can request access to synthesize speech with these voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=638"
  },
  {
    "text": "using a new request authorization API for Personal Voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=642"
  },
  {
    "text": "Keep in mind that usage of Personal Voice is sensitive ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=646"
  },
  {
    "text": "and should be primarily used for augmentative ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=650"
  },
  {
    "text": "or alternative communication apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=652"
  },
  {
    "text": "Let’s checkout an AAC app I’ve made to use Personal Voice.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=655"
  },
  {
    "text": "My app has two buttons ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=660"
  },
  {
    "text": "that will speak common phrases I find myself saying at WWDC ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=662"
  },
  {
    "text": "and a button for requesting access to use Personal Voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=667"
  },
  {
    "text": "Authorization can be requested with a new API ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=671"
  },
  {
    "text": "called requestPersonalVoiceAuthorization on AVSpeechSynthesizer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=674"
  },
  {
    "text": "Once authorized, Personal Voices will appear alongside System voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=680"
  },
  {
    "text": "in the AVSpeechSynthesisVoice API speechVoices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=685"
  },
  {
    "text": "and will be denoted with a new voiceTrait called isPersonalVoice.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=689"
  },
  {
    "text": "Now that I have access to Personal Voice, I can use it to speak with.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=694"
  },
  {
    "text": "Let’s check out a demo of Personal Voice in action. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=700"
  },
  {
    "text": "First, I’ll tap the “Use Personal Voice” button to request authorization, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=703"
  },
  {
    "text": "and once authorized, I can tap a symbol to hear my voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=709"
  },
  {
    "text": "Personal voice: Hi, my name is Grant. Welcome to WWDC23. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=714"
  },
  {
    "text": "Grant: Isn’t that amazing? ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=718"
  },
  {
    "text": "And now you can use these voices in your apps, too.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=720"
  },
  {
    "text": "Now that we discussed SSML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=724"
  },
  {
    "text": "you should use it to standardize speech input ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=726"
  },
  {
    "text": "and build a rich speech experience in your apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=729"
  },
  {
    "text": "We also walked through how to implement your Speech Synthesizer ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=733"
  },
  {
    "text": "into Apple platforms, so now you can provide great new speech voices ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=736"
  },
  {
    "text": "that people can use across the system. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=741"
  },
  {
    "text": "And finally, with Personal Voice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=744"
  },
  {
    "text": "you can bring even more of a personal touch to synthesis in your apps, ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=746"
  },
  {
    "text": "especially for people who may be at risk of losing their own voice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=751"
  },
  {
    "text": "We are super excited to see what experiences you create using these APIs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=755"
  },
  {
    "text": "Thanks for watching.",
    "link": "https://developer.apple.com/videos/play/wwdc2023/10033/?time=760"
  }
]