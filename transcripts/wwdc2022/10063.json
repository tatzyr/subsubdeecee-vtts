[
  {
    "text": "♪ ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=0"
  },
  {
    "text": "Dhruva: Welcome to WWDC 2022. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=9"
  },
  {
    "text": "My name is Dhruva, and I am a GPUSW Engineer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=12"
  },
  {
    "text": "Today, Matteo and I will explore all the new features and enhancements ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=16"
  },
  {
    "text": "introduced for machine learning this year in Metal. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=21"
  },
  {
    "text": "Machine learning training is the most computationally intensive process ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=25"
  },
  {
    "text": "of the ML pipeline. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=29"
  },
  {
    "text": "Due to their parallel nature, GPUs excel at ML workloads. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=31"
  },
  {
    "text": "The Metal machine learning APIs are exposed through a framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=37"
  },
  {
    "text": "called Metal Performance Shaders, or MPS. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=41"
  },
  {
    "text": "MPS is a collection of high performance GPU primitives ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=44"
  },
  {
    "text": "for various fields like Image Processing, Linear Algebra, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=49"
  },
  {
    "text": "Ray Tracing, and machine learning. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=53"
  },
  {
    "text": "These Metal kernels are optimized to provide the best performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=56"
  },
  {
    "text": "on all of our platforms. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=60"
  },
  {
    "text": "For example the MPSImageCanny filter ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=62"
  },
  {
    "text": "returns an edge-map for an input-image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=65"
  },
  {
    "text": "This is a common operation in image segmentation applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=68"
  },
  {
    "text": "This year, the Canny filter is able to process ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=72"
  },
  {
    "text": "4K, high-resolution images up to eight times faster. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=76"
  },
  {
    "text": "MPS Graph, is a general purpose compute graph ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=81"
  },
  {
    "text": "for the GPU which sits on top of the MPS framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=84"
  },
  {
    "text": "and extends support to multidimensional tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=88"
  },
  {
    "text": "I recommend watching the previous session to get more details ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=92"
  },
  {
    "text": "on how to use MPS Graph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=95"
  },
  {
    "text": "High level ML frameworks like CoreML and Tensorflow ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=98"
  },
  {
    "text": "sit on top of MPS Graph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=102"
  },
  {
    "text": "You can accelerate your TensorFlow networks on the GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=105"
  },
  {
    "text": "with the TensorFlow Metal plug-in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=108"
  },
  {
    "text": "For more on how to make the most of TensorFlow, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=111"
  },
  {
    "text": "check out last year's session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=114"
  },
  {
    "text": "Matteo and I have three topics to cover in this session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=117"
  },
  {
    "text": "First, I'll introduce the newest ML framework coming to Apple GPUs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=121"
  },
  {
    "text": "PyTorch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=126"
  },
  {
    "text": "Next, I'll dive into the enhancements made to TensorFlow over this year. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=127"
  },
  {
    "text": "Finally, Matteo will talk about what's new in the MPS Graph framework.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=134"
  },
  {
    "text": "We are really excited that you will now be able to accelerate your PyTorch networks ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=140"
  },
  {
    "text": "on your Mac GPUs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=145"
  },
  {
    "text": "PyTorch, is a popular open source machine learning framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=147"
  },
  {
    "text": "The number one most requested feature, in the PyTorch community ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=152"
  },
  {
    "text": "was support for GPU acceleration on Apple silicon. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=157"
  },
  {
    "text": "We are bringing the power of Metal to PyTorch ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=161"
  },
  {
    "text": "by introducing a new MPS backend to the PyTorch ecosystem. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=164"
  },
  {
    "text": "This backend will be part of the official PyTorch 1.12 release. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=170"
  },
  {
    "text": "The MPS backend implements the PyTorch operation kernels, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=176"
  },
  {
    "text": "as well as a Runtime framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=180"
  },
  {
    "text": "The operations call into MPS Graph and MPS ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=182"
  },
  {
    "text": "and the Runtime component uses Metal. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=187"
  },
  {
    "text": "This enables PyTorch to use the highly efficient kernels from MPS ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=190"
  },
  {
    "text": "along with Metal's Command queues, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=195"
  },
  {
    "text": "Command buffers, and synchronization primitives.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=197"
  },
  {
    "text": "The operation kernels and PyTorch MPS Runtime components ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=202"
  },
  {
    "text": "are part of the open source code ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=207"
  },
  {
    "text": "and merged into the official PyTorch GitHub repo. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=209"
  },
  {
    "text": "Using the MPS PyTorch backend is a simple three-step process. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=212"
  },
  {
    "text": "First, starting with PyTorch 1.12, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=217"
  },
  {
    "text": "you can install the base package using ‘pip install torch'. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=220"
  },
  {
    "text": "This package is available in the official python package repository. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=224"
  },
  {
    "text": "For more details on environment setup and installation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=229"
  },
  {
    "text": "please refer to the Metal Developer Resources web page. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=233"
  },
  {
    "text": "Second, import PyTorch and create the MPS device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=237"
  },
  {
    "text": "This code snippet uses the MPS device backend ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=241"
  },
  {
    "text": "if it is available, otherwise it'll fall back to the CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=244"
  },
  {
    "text": "The last step is to convert your models and inputs to use the MPS device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=249"
  },
  {
    "text": "To demonstrate how to do this, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=254"
  },
  {
    "text": "I will use an example which runs inference ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=256"
  },
  {
    "text": "on a pre-trained ResNet50 model from torchvision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=259"
  },
  {
    "text": "By default, the model will run on the CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=263"
  },
  {
    "text": "You can use the \"to\" method to convert the model to use the MPS device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=267"
  },
  {
    "text": "This ensures that intermediate tensors inside the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=272"
  },
  {
    "text": "will also use the accelerated MPS backend. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=276"
  },
  {
    "text": "Finally, you can run the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=279"
  },
  {
    "text": "This example passes a random input tensor to the MPS model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=282"
  },
  {
    "text": "By default, all tensors are allocated on the CPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=287"
  },
  {
    "text": "In order to use the MPS backend, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=291"
  },
  {
    "text": "you will also need to provide the mpsDevice here as well. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=293"
  },
  {
    "text": "All subsequent operations on this tensor will be accelerated on the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=298"
  },
  {
    "text": "Finally, pass the sample input to the MPS model to get a prediction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=303"
  },
  {
    "text": "Now that you know how to use the MPS device, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=309"
  },
  {
    "text": "I'll show you an example of PyTorch in action. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=312"
  },
  {
    "text": "I've always wanted to be a famous artist. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=315"
  },
  {
    "text": "So I decided to use machine learning and my GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=317"
  },
  {
    "text": "to help create my artwork using the StyleTransfer network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=321"
  },
  {
    "text": "This network allows you to apply a different artistic style to an image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=325"
  },
  {
    "text": "In this case, the goal is to learn how to apply Van Gogh's style ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=330"
  },
  {
    "text": "in Starry Night to this picture of a cat. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=334"
  },
  {
    "text": "With the new MPS device, you will be able to use the GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=337"
  },
  {
    "text": "to train your PyTorch networks significantly faster. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=341"
  },
  {
    "text": "To demonstrate this, I'll start training this network ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=345"
  },
  {
    "text": "on both the CPU and GPU simultaneously on an M1 Max. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=348"
  },
  {
    "text": "It takes thousands of iterations to learn this style, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=353"
  },
  {
    "text": "but the GPU is able to converge to a reasonable model in much less time.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=356"
  },
  {
    "text": "In addition to StyleTransfer, we have seen amazing speedups ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=363"
  },
  {
    "text": "on all these PyTorch benchmarks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=367"
  },
  {
    "text": "On the M1 Ultra, we saw speedups of up to 20 times faster ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=370"
  },
  {
    "text": "with an average of 8.3 times faster. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=375"
  },
  {
    "text": "PyTorch makes it easy to develop machine learning models, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=378"
  },
  {
    "text": "and you'll be able to save a lot of time by using Apple GPUs to train them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=382"
  },
  {
    "text": "Next, I'll dive into all the enhancements we've made this year to TensorFlow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=387"
  },
  {
    "text": "TensorFlow Metal acceleration has been available ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=393"
  },
  {
    "text": "since TensorFlow version 2.5 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=397"
  },
  {
    "text": "through the TensorFlow Metal plug-in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=400"
  },
  {
    "text": "Since then, several additional features and improvements have been added. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=403"
  },
  {
    "text": "These include improved training with bigger batches, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=407"
  },
  {
    "text": "new operations and custom op support, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=411"
  },
  {
    "text": "RNN improvements, and distributed training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=414"
  },
  {
    "text": "The TensorFlow Metal plug-in releases ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=418"
  },
  {
    "text": "are aligned with major TensorFlow releases, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=420"
  },
  {
    "text": "so make sure you update your TensorFlow packages ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=424"
  },
  {
    "text": "to get the latest features and improvements. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=426"
  },
  {
    "text": "Let's start with bigger batch sizes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=430"
  },
  {
    "text": "This year software improvements in TensorFlow Metal allow you ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=433"
  },
  {
    "text": "to leverage the unique benefits of the Apple silicon architecture. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=437"
  },
  {
    "text": "This graph shows speedups training a ResNet50 model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=441"
  },
  {
    "text": "with various batch sizes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=446"
  },
  {
    "text": "The data shows that performance improves with bigger batch sizes ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=448"
  },
  {
    "text": "because each gradient update corresponds more closely to the true gradient. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=453"
  },
  {
    "text": "Apple silicon's unified memory architecture ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=458"
  },
  {
    "text": "allows you to run larger networks or larger batch sizes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=461"
  },
  {
    "text": "Now you can run your workload on a single Mac Studio ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=466"
  },
  {
    "text": "instead of splitting it across a cloud cluster, which is awesome! ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=469"
  },
  {
    "text": "The Apple Silicon architecture also has high performance per watt, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=473"
  },
  {
    "text": "meaning your networks run more efficiently than ever. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=477"
  },
  {
    "text": "Next l'll talk about the new operations and custom operations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=481"
  },
  {
    "text": "The Tensorflow Metal plug-in now has GPU acceleration ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=486"
  },
  {
    "text": "for a variety of new operations, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=490"
  },
  {
    "text": "including argMin, all, pack, adaDelta, and many more. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=492"
  },
  {
    "text": "But what if you want GPU acceleration for an operation ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=498"
  },
  {
    "text": "that's currently not supported in the TensorFlow API? ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=502"
  },
  {
    "text": "To do this, you will need to create a custom operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=506"
  },
  {
    "text": "Here's an example of a simple convolutional network ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=510"
  },
  {
    "text": "running for two iterations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=513"
  },
  {
    "text": "The timeline represents the work done on the GPU and CPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=516"
  },
  {
    "text": "above and below respectively. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=520"
  },
  {
    "text": "The network does a convolution followed by maxpool-ing ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=522"
  },
  {
    "text": "and then a softmax cross entropy loss. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=526"
  },
  {
    "text": "All of these operations are GPU accelerated ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=530"
  },
  {
    "text": "in the TensorFlow Metal plug-in through MPS Graph ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=533"
  },
  {
    "text": "But you might want to use a custom loss function. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=536"
  },
  {
    "text": "Without MPS GPU acceleration for this custom loss, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=540"
  },
  {
    "text": "that work will need to be performed on the CPU timeline ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=544"
  },
  {
    "text": "which introduces synchronization overhead and starves the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=548"
  },
  {
    "text": "You can achieve far better performance by doing this custom loss on the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=553"
  },
  {
    "text": "In order to implement a custom operation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=558"
  },
  {
    "text": "you will need to understand the TensorFlow Metal Stream protocol. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=561"
  },
  {
    "text": "This is a protocol which you use to encode GPU operations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=566"
  },
  {
    "text": "The Metal stream holds a reference to the MTLCommandBuffer you use ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=571"
  },
  {
    "text": "to encode your GPU kernel. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=575"
  },
  {
    "text": "It also exposes the dispatch_queue to use for CPU side synchronization ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=577"
  },
  {
    "text": "while encoding as there may be multiple threads submitting work. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=581"
  },
  {
    "text": "Use the commit or commitAndWait methods to submit the work to the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=585"
  },
  {
    "text": "CommitAndWait is a debugging tool that will wait until the current command buffer ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=591"
  },
  {
    "text": "is done so you can observe serialized submissions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=595"
  },
  {
    "text": "Now let's see how these concepts can be used to implement a custom op. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=599"
  },
  {
    "text": "There are three steps to write a custom operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=604"
  },
  {
    "text": "First, register the operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=607"
  },
  {
    "text": "Next, implement the operation using a MetalStream. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=609"
  },
  {
    "text": "And finally, import the operation into your training scripts and begin using it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=613"
  },
  {
    "text": "I'll start with registering the operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=619"
  },
  {
    "text": "Use the REGISTER_OP macro exposed by TensorFlow core ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=622"
  },
  {
    "text": "to specify the semantics of the op ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=625"
  },
  {
    "text": "and how it should be defined in the TensorFlow Metal plug-in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=628"
  },
  {
    "text": "Next, implement the op using the TensorFlow_MetalStream. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=632"
  },
  {
    "text": "Start by defining the \"compute\" function. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=636"
  },
  {
    "text": "Now, inside this function, get the TensorFlow_Tensor objects ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=640"
  },
  {
    "text": "for the input and define the output, which might require an allocation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=645"
  },
  {
    "text": "Then create an encoder using the Metal stream's command buffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=650"
  },
  {
    "text": "Next, define the custom GPU kernel. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=655"
  },
  {
    "text": "Your op should be encoded inside the dispatch_queue ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=658"
  },
  {
    "text": "provided by the Metal stream. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=660"
  },
  {
    "text": "This ensures submissions from multiple threads are serialized.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=662"
  },
  {
    "text": "Then commit the kernel by using the method provided ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=668"
  },
  {
    "text": "in the TensorFlow_MetalStream protocol.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=672"
  },
  {
    "text": "Finally, delete the references to the allocated tensors.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=676"
  },
  {
    "text": "Last, import the operation into your training script to begin using it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=681"
  },
  {
    "text": "In this step, build the custom op's shared dynamic library file called zero_out.so. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=687"
  },
  {
    "text": "Refer to Metal Developer Resources ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=695"
  },
  {
    "text": "for info on how to build and import .so files. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=697"
  },
  {
    "text": "This example imports the operation into the training script ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=701"
  },
  {
    "text": "by using the TensorFlow load_op_library, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=705"
  },
  {
    "text": "which is an optional step. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=708"
  },
  {
    "text": "Now, this works like a python wrapper ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=710"
  },
  {
    "text": "and our custom op can be invoked in the training script. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=712"
  },
  {
    "text": "Next, I'd like to show you an example of an interesting application ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=716"
  },
  {
    "text": "called Neural Radiance Fields, or NeRF. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=720"
  },
  {
    "text": "We wrote a custom operation that elevated the network's performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=724"
  },
  {
    "text": "by enabling GPU acceleration for a better algorithm.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=728"
  },
  {
    "text": "NeRF is a network used to synthesize 3D views of a model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=733"
  },
  {
    "text": "For training, NeRF takes as input, images of an object from different angles. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=738"
  },
  {
    "text": "The NeRF network consists of two stacked Multi-layer perceptrons, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=743"
  },
  {
    "text": "and the output is a volumetric representation of the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=748"
  },
  {
    "text": "A key performance optimization for real time training ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=752"
  },
  {
    "text": "uses a hash table implementation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=755"
  },
  {
    "text": "This updated network allows a much smaller multi-layer perceptron. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=758"
  },
  {
    "text": "TensorFlow does not support hash tables natively ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=763"
  },
  {
    "text": "so we use the custom op feature ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=767"
  },
  {
    "text": "to implement them in the Metal plug-in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=769"
  },
  {
    "text": "The GPU acceleration for hash tables makes it possible to train NeRF much faster. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=772"
  },
  {
    "text": "I'll start on this MacBook ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=778"
  },
  {
    "text": "and run original multi-layer perceptron implementation.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=779"
  },
  {
    "text": "In order to render anything reasonable, we need at least 20 epochs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=786"
  },
  {
    "text": "but each epoch takes about 100 seconds. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=790"
  },
  {
    "text": "That means it will take about 30 minutes before anything is seen. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=793"
  },
  {
    "text": "So now I will restart training from a pre-trained checkpoint file, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=797"
  },
  {
    "text": "which was left to train for 30 minutes beforehand. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=802"
  },
  {
    "text": "This starts at epoch 20. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=806"
  },
  {
    "text": "The 3D model is blurred and unclear even after 30 minutes of training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=808"
  },
  {
    "text": "It would require a much longer training time for the network ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=813"
  },
  {
    "text": "to learn a clearer model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=817"
  },
  {
    "text": "The original two stacked multi-layer perceptron approach ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=818"
  },
  {
    "text": "without custom hash tables is too slow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=822"
  },
  {
    "text": "Now on this MacBook I'll kick off the optimized version ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=825"
  },
  {
    "text": "that uses custom hash tables. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=829"
  },
  {
    "text": "This implementation is already able to render a much clearer model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=832"
  },
  {
    "text": "and each epoch takes only 10 seconds to learn. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=837"
  },
  {
    "text": "For more information on this project, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=840"
  },
  {
    "text": "check out the sample code which we have uploaded to Metal Developer Resources.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=842"
  },
  {
    "text": "NeRF is just one of the many networks which demonstrates ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=849"
  },
  {
    "text": "how you can implement GPU acceleration for your own custom operations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=853"
  },
  {
    "text": "to make your networks run blazing fast. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=857"
  },
  {
    "text": "I look forward to learning about all the creative customizations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=860"
  },
  {
    "text": "you make, going forward. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=864"
  },
  {
    "text": "Now I want to show you how to use Apple GPUs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=866"
  },
  {
    "text": "to distribute training of ML workloads. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=870"
  },
  {
    "text": "In order to distribute training of workloads, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=873"
  },
  {
    "text": "you can run multiple instances of the training script in separate processes ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=876"
  },
  {
    "text": "where each process evaluates a single iteration of the model.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=880"
  },
  {
    "text": "Each process will read data from a central data store. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=886"
  },
  {
    "text": "After which, it will run through the model and calculate the model gradients. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=890"
  },
  {
    "text": "Next, the processes will average the gradients and communicate this ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=895"
  },
  {
    "text": "to each other so each process has the same gradients before the next iteration. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=900"
  },
  {
    "text": "Finally, the model is updated and you can repeat this process ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=906"
  },
  {
    "text": "until all the iterations are exhausted. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=910"
  },
  {
    "text": "To demonstrate this on TensorFlow, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=913"
  },
  {
    "text": "I will use an example of distributed training ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=915"
  },
  {
    "text": "using a popular open source framework called Horovod.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=918"
  },
  {
    "text": "Horovod uses a ring all-reduce approach. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=923"
  },
  {
    "text": "In this algorithm, each of N nodes communicates ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=927"
  },
  {
    "text": "with two of its peers multiple times. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=931"
  },
  {
    "text": "Using this communication, the worker processes synchronize ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=934"
  },
  {
    "text": "gradients before each iteration. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=937"
  },
  {
    "text": "I'll show this in action using four Mac Studios ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=940"
  },
  {
    "text": "connected to each other with Thunderbolt cables. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=944"
  },
  {
    "text": "For this example, I will train ResNet, a classifier for images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=947"
  },
  {
    "text": "The bar to the side of each Mac Studio shows the GPU utilization ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=953"
  },
  {
    "text": "while training this network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=958"
  },
  {
    "text": "For a single Mac Studio, the performance is about 200 images per second. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=959"
  },
  {
    "text": "When I add another Mac Studio connected via Thunderbolt, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=964"
  },
  {
    "text": "the performance almost doubles to 400 images per second ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=968"
  },
  {
    "text": "since both GPUs are utilized to the fullest. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=972"
  },
  {
    "text": "Finally, when I connect two more Mac Studios, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=976"
  },
  {
    "text": "the performance is elevated to 800 images per second. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=979"
  },
  {
    "text": "This is almost linear scaling on your compute bound training workloads.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=984"
  },
  {
    "text": "Now here's a look at the Distributed training performance of TensorFlow. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=990"
  },
  {
    "text": "This chart shows the relative speedup for one, two, and four Mac Studios. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=995"
  },
  {
    "text": "They are connected in a ring topology and run compute bound TensorFlow networks ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1001"
  },
  {
    "text": "such as resNet and DistilBERT ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1005"
  },
  {
    "text": "with the latest TensorFlow Metal plug-in and Horovod. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1008"
  },
  {
    "text": "The base is the performance on a single Mac Studio. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1012"
  },
  {
    "text": "The graph show that network performance scales with the addition of each GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1017"
  },
  {
    "text": "so you can now leverage GPUs on multiple devices, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1022"
  },
  {
    "text": "to speed up your training time ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1025"
  },
  {
    "text": "and make the most out of all your Apple devices.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1027"
  },
  {
    "text": "All the improvements and features unlocked for TensorFlow this year ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1032"
  },
  {
    "text": "culminate into this chart showing the relative performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1035"
  },
  {
    "text": "against the CPU implementation ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1039"
  },
  {
    "text": "with more improvements to come in the future. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1041"
  },
  {
    "text": "Now Matteo will share what's new in the MPSGraph framework.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1044"
  },
  {
    "text": "Matteo: Thanks, Dhruva. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1050"
  },
  {
    "text": "Hi, my name is Matteo, and I'm a GPU software engineer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1051"
  },
  {
    "text": "PyTorch and TensorFlow sit on top of the MPSGraph framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1055"
  },
  {
    "text": "In turn, MPSGraph uses the parallel primitives ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1061"
  },
  {
    "text": "exposed by the MPS framework to accelerate work on the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1065"
  },
  {
    "text": "Today I am going to talk about two features that you can use ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1070"
  },
  {
    "text": "to accelerate your compute workloads even further with MPSGraph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1074"
  },
  {
    "text": "First, I will show the new shared events API ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1079"
  },
  {
    "text": "which allows you to synchronize work between two graphs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1082"
  },
  {
    "text": "Second, I will go over new operations, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1085"
  },
  {
    "text": "which you can use to do even more with MPSGraph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1088"
  },
  {
    "text": "I'll begin with the Shared Events API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1093"
  },
  {
    "text": "Running applications on the same command queue ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1096"
  },
  {
    "text": "ensures synchronization between workloads. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1099"
  },
  {
    "text": "In this example, the compute workload is guaranteed ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1102"
  },
  {
    "text": "to always terminate before other workloads, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1106"
  },
  {
    "text": "such as post processing and display, are dispatched. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1109"
  },
  {
    "text": "In cases like this, you will leverage the GPU parallelism ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1113"
  },
  {
    "text": "within each single dispatch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1117"
  },
  {
    "text": "However, some applications could benefit from more parallelism, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1119"
  },
  {
    "text": "where a first portion of the GPU is used for the compute, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1124"
  },
  {
    "text": "and a second portion is used for the post processing and display. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1128"
  },
  {
    "text": "This could be achieved by submitting work to the GPU on multiple command queues. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1132"
  },
  {
    "text": "Unfortunately, in this case, the post processing pipeline ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1138"
  },
  {
    "text": "may be dispatched before the compute has produced the results, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1142"
  },
  {
    "text": "introducing a data race. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1146"
  },
  {
    "text": "The Shared Events API can be used to solve this problem ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1149"
  },
  {
    "text": "and introduce synchronization across command queues ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1153"
  },
  {
    "text": "to make sure that workflow dependencies can be satisfied. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1156"
  },
  {
    "text": "Using shared events within your code is very simple. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1161"
  },
  {
    "text": "Let's assume you are working with two graphs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1165"
  },
  {
    "text": "The first is responsible for the compute workload. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1169"
  },
  {
    "text": "The second, is responsible for the post processing workload. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1172"
  },
  {
    "text": "Let's also assume that the result of the compute graph is used as input ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1177"
  },
  {
    "text": "for the post processing graph, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1181"
  },
  {
    "text": "and that they run on different command queues. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1183"
  },
  {
    "text": "The new MPSGraph track in the Metal System Trace ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1187"
  },
  {
    "text": "indicates that the command queues are overlapping with each other. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1191"
  },
  {
    "text": "This produces a data race. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1195"
  },
  {
    "text": "You can solve this problem using a shared event. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1198"
  },
  {
    "text": "First, create the event using the Metal device. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1201"
  },
  {
    "text": "Next, invoke the signal method in the execution descriptor, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1205"
  },
  {
    "text": "providing the event, the action, and the value. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1210"
  },
  {
    "text": "Then all you have to do is to call the wait method ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1214"
  },
  {
    "text": "on the second descriptor, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1218"
  },
  {
    "text": "providing event variable and the value.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1220"
  },
  {
    "text": "Now, the Metal system trace indicates that the two command queues ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1224"
  },
  {
    "text": "are run sequentially, and the dependency between ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1229"
  },
  {
    "text": "compute and post processing graph has been resolved. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1232"
  },
  {
    "text": "That's how you can use shared events to solve synchronization problems ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1237"
  },
  {
    "text": "in your applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1241"
  },
  {
    "text": "Second, I'll talk about the new operations supported by MPSGraph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1243"
  },
  {
    "text": "These operations allow you to do even more with the framework. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1248"
  },
  {
    "text": "I'll go through some of the details of each of these new ops, starting with RNNs.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1252"
  },
  {
    "text": "MPSGraph now exposes three operations commonly used ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1259"
  },
  {
    "text": "within Recurrent Neural Network applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1263"
  },
  {
    "text": "These are the RNN, LSTM, and GRU layers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1267"
  },
  {
    "text": "These operations all work similarly, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1272"
  },
  {
    "text": "so I'll just focus on LSTMs today. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1274"
  },
  {
    "text": "The LSTM operation is commonly used for natural language processing ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1279"
  },
  {
    "text": "and other applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1283"
  },
  {
    "text": "This diagram shows how the LSTM operation works. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1285"
  },
  {
    "text": "To learn more about it, check out our previous WWDC session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1289"
  },
  {
    "text": "You could implement the LSTM unit yourself, but to do so, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1295"
  },
  {
    "text": "you would have to build this rather complicated custom subgraph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1299"
  },
  {
    "text": "Instead, you can use the new LSTM operation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1303"
  },
  {
    "text": "which efficiently encodes all the GPU work required by the recurrent unit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1307"
  },
  {
    "text": "This new operation makes LSTM-based CoreML inference models significantly faster.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1313"
  },
  {
    "text": "To use the new LSTM operation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1321"
  },
  {
    "text": "first create an MPSGraphLSTMDescriptor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1323"
  },
  {
    "text": "You can modify the descriptor properties as needed, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1328"
  },
  {
    "text": "for example selecting the activation functions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1331"
  },
  {
    "text": "Next, add the LSTM unit to the graph, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1335"
  },
  {
    "text": "providing the input tensors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1338"
  },
  {
    "text": "You can also provide a bias vector, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1341"
  },
  {
    "text": "as well as the initial state and cell for the operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1343"
  },
  {
    "text": "Finally, provide the descriptor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1347"
  },
  {
    "text": "That's all you need to do to set up an LSTM. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1350"
  },
  {
    "text": "The other RNN operations work similarly. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1354"
  },
  {
    "text": "I encourage you to try these operations out ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1358"
  },
  {
    "text": "and see what kind of speedups you can get in your application. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1360"
  },
  {
    "text": "Next, I'll show you the improved support for Max Pooling. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1364"
  },
  {
    "text": "The Max Pooling operation takes an input tensor and a window size ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1368"
  },
  {
    "text": "and computes, for each application of the window, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1373"
  },
  {
    "text": "the maximum value of the input within the window. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1376"
  },
  {
    "text": "It is commonly used in computer vision to reduce the dimensionality of an image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1380"
  },
  {
    "text": "The API has been extended to return the indices of the maximum value location ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1385"
  },
  {
    "text": "extracted by the pooling operator. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1390"
  },
  {
    "text": "You can use indices in the gradient pass, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1393"
  },
  {
    "text": "where the gradients must be propagated through the locations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1395"
  },
  {
    "text": "where the maximum values were extracted. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1399"
  },
  {
    "text": "The new API works for training too. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1403"
  },
  {
    "text": "Reusing the indices during training can be up to six times faster ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1406"
  },
  {
    "text": "for PyTorch and TensorFlow.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1410"
  },
  {
    "text": "To set this up in code, first, create the GraphPooling descriptor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1414"
  },
  {
    "text": "You can specify the returnIndicesMode, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1420"
  },
  {
    "text": "for example, globalFlatten4D. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1422"
  },
  {
    "text": "Then you can call the pooling operation on the graph with the Return Indices API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1426"
  },
  {
    "text": "The result of the operation is twofold. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1433"
  },
  {
    "text": "First, the poolingTensor, and second, the indicesTensor. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1436"
  },
  {
    "text": "You can cache the indicesTensor for later use, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1441"
  },
  {
    "text": "for example, on a training pipeline.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1444"
  },
  {
    "text": "MPS Graph now exposes a new parallel random number generator, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1449"
  },
  {
    "text": "which can be used, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1453"
  },
  {
    "text": "to initialize the weights of a training graph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1455"
  },
  {
    "text": "The new random operation uses the Philox algorithm ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1459"
  },
  {
    "text": "and returns the same results as TensorFlow for a given seed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1462"
  },
  {
    "text": "The new operation takes, as input, a state tensor; ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1468"
  },
  {
    "text": "it returns as output a random tensor ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1471"
  },
  {
    "text": "and a new state tensor that can be used, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1474"
  },
  {
    "text": "as input for a second random operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1478"
  },
  {
    "text": "To use the new random operation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1481"
  },
  {
    "text": "call the randomPhiloxStateTensor method. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1483"
  },
  {
    "text": "This method initializes an input stateTensor with the given seed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1486"
  },
  {
    "text": "Then declare the RandomOp descriptor, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1492"
  },
  {
    "text": "which takes as input the distribution and the data type. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1495"
  },
  {
    "text": "In the example, the descriptor specifies ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1499"
  },
  {
    "text": "a truncatedNormal distribution of 32bit floating point values. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1502"
  },
  {
    "text": "You can also use Normal and Uniform distributions.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1507"
  },
  {
    "text": "You can further define the distribution characteristics ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1512"
  },
  {
    "text": "by specifying the mean, standard deviation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1515"
  },
  {
    "text": "minimum, and maximum values. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1518"
  },
  {
    "text": "Finally, you can create the random operation, providing a shapeTensor, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1521"
  },
  {
    "text": "the descriptor, and the stateTensor just created.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1526"
  },
  {
    "text": "In addition to Random, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1532"
  },
  {
    "text": "MPSGraph now supports a new GPU accelerated operation ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1534"
  },
  {
    "text": "to compute the Hamming distance between two bit vectors. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1537"
  },
  {
    "text": "The hamming distance, defined as the number of bits ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1542"
  },
  {
    "text": "that differ between two inputs with same length, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1545"
  },
  {
    "text": "is a measure of the edit distance between two sequences, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1548"
  },
  {
    "text": "and it is used on several applications, from bioinformatics to cryptography. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1551"
  },
  {
    "text": "To use HammingDistance, call the API on the graph, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1558"
  },
  {
    "text": "providing primaryTensor, secondaryTensor, and the resultDataType. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1561"
  },
  {
    "text": "Note that the new kernel supports broadcasting over batch dimensions ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1566"
  },
  {
    "text": "on the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1571"
  },
  {
    "text": "Now, I'll show you all about the new tensor manipulation operations, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1573"
  },
  {
    "text": "which are very easy to use. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1578"
  },
  {
    "text": "You can now expand the dimensionality of the tensor, for example, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1580"
  },
  {
    "text": "from two to three dimensions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1584"
  },
  {
    "text": "And you can squeeze the dimensions back.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1586"
  },
  {
    "text": "You can also split a tensor evenly providing a number of slices and an axis. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1590"
  },
  {
    "text": "or stack tensors along a given axis.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1596"
  },
  {
    "text": "You can also generate coordinate values along tensor dimensions ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1600"
  },
  {
    "text": "for a given input shape. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1604"
  },
  {
    "text": "For example, you can populate a tensor of shape two by four ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1606"
  },
  {
    "text": "with coordinates along the 0 axis. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1611"
  },
  {
    "text": "This can be also used to implement a range1D operation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1614"
  },
  {
    "text": "For example, assume you want to generate the range of numbers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1619"
  },
  {
    "text": "between 3 and 27 with increments of 4. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1623"
  },
  {
    "text": "You can do so by first creating the coordinates ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1627"
  },
  {
    "text": "along the dimension 0 of a tensor of shape 6. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1630"
  },
  {
    "text": "Then, all you have to do is to multiply by the increment, and add the offset. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1635"
  },
  {
    "text": "Those are all of the new operations added this year. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1641"
  },
  {
    "text": "With all these new operations, you will be able to do even more ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1645"
  },
  {
    "text": "and get higher performance across the Apple ecosystem using MPSGraph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1649"
  },
  {
    "text": "Now, I am going to show you the performance improvements you can get ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1654"
  },
  {
    "text": "on Apple silicon out of MPSGraph.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1657"
  },
  {
    "text": "Blackmagic has just released DaVinci Resolve version 18, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1661"
  },
  {
    "text": "which uses MPS Graph to accelerate machine learning workloads. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1665"
  },
  {
    "text": "Magic Mask is a feature of Resolve that uses machine learning ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1670"
  },
  {
    "text": "to identify a moving object on screen and selectively apply filters on top of it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1674"
  },
  {
    "text": "First I'll demonstrate how this works in the previous version of Resolve, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1680"
  },
  {
    "text": "and then I'll compare it to the current version. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1685"
  },
  {
    "text": "To create the mask, you just need to select the target object. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1688"
  },
  {
    "text": "You can view the mask by toggling the overlay. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1693"
  },
  {
    "text": "The mask is identified by the red area, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1696"
  },
  {
    "text": "which correctly marks the shape of the subject. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1699"
  },
  {
    "text": "Now, if I play the video, the mask will track the object as it moves on screen. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1702"
  },
  {
    "text": "This looks great, but it's running at a pretty low frame rate, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1708"
  },
  {
    "text": "as the machine learning pipeline runs under the hood. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1712"
  },
  {
    "text": "Now I'll switch to the newest version of Resolve, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1715"
  },
  {
    "text": "which uses MPSGraph to accelerate the Magic Mask network. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1719"
  },
  {
    "text": "Running the same timeline again, the frame rate is way faster than before. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1724"
  },
  {
    "text": "This results in a much better editing experience on Apple silicon.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1729"
  },
  {
    "text": "These are the kind of speedups you can get just by adopting MPS Graph. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1735"
  },
  {
    "text": "I encourage you to explore what kind of performance it can bring to your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1740"
  },
  {
    "text": "To wrap up, you will now be able to leverage ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1744"
  },
  {
    "text": "GPU acceleration for PyTorch, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1748"
  },
  {
    "text": "and the project is now open source. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1750"
  },
  {
    "text": "You will find new ways to accelerate training workloads ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1753"
  },
  {
    "text": "using the TensorFlow Metal plug-in, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1756"
  },
  {
    "text": "for example, using custom operations and distributed training. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1759"
  },
  {
    "text": "Finally, you will be able to optimize the most demanding machine learning tasks ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1763"
  },
  {
    "text": "with the MPSGraph framework ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1768"
  },
  {
    "text": "to make the best out of Apple silicon, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1769"
  },
  {
    "text": "using shared events and new operations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1772"
  },
  {
    "text": "Dhruva and I can't wait to see how you will use these new features ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1774"
  },
  {
    "text": "in your applications. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1778"
  },
  {
    "text": "Thank you for watching the session, and have a great WWDC.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10063/?time=1779"
  }
]