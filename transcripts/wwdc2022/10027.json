[
  {
    "text": "♪ Mellow instrumental hip-hop music ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=0"
  },
  {
    "text": "♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=3"
  },
  {
    "text": "Hi, my name is Ben, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=9"
  },
  {
    "text": "and I'm an engineer on the Core ML team. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=11"
  },
  {
    "text": "Today I'm going to show some of the exciting new features ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=13"
  },
  {
    "text": "being added to Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=16"
  },
  {
    "text": "The focus of these features is to help you ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=18"
  },
  {
    "text": "optimize your Core ML usage. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=20"
  },
  {
    "text": "In this session, I'll go over performance tools ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=23"
  },
  {
    "text": "that are now available to give you the information you need ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=25"
  },
  {
    "text": "to understand and optimize your model's performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=28"
  },
  {
    "text": "when using Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=31"
  },
  {
    "text": "Then I'll go over some enhanced APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=34"
  },
  {
    "text": "which will enable you to make those optimizations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=36"
  },
  {
    "text": "And lastly, I'll give an overview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=40"
  },
  {
    "text": "of some additional Core ML capabilities ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=42"
  },
  {
    "text": "and integration options. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=44"
  },
  {
    "text": "Let me begin with the performance tools. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=47"
  },
  {
    "text": "To give some background, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=50"
  },
  {
    "text": "I'll start by summarizing the standard workflow ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=51"
  },
  {
    "text": "when using Core ML within your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=53"
  },
  {
    "text": "The first step is to choose your model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=56"
  },
  {
    "text": "This may be done in a variety of ways, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=59"
  },
  {
    "text": "such as using Core ML tools to convert a PyTorch ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=61"
  },
  {
    "text": "or TensorFlow model to Core ML format, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=64"
  },
  {
    "text": "using an already-existing Core ML model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=66"
  },
  {
    "text": "or using Create ML to train and export your model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=69"
  },
  {
    "text": "For more details on model conversion ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=73"
  },
  {
    "text": "or to learn about Create ML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=75"
  },
  {
    "text": "I recommend checking out these sessions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=76"
  },
  {
    "text": "The next step is to integrate that model into your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=80"
  },
  {
    "text": "This involves bundling the model with your application ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=83"
  },
  {
    "text": "and using the Core ML APIs to load and run inference ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=86"
  },
  {
    "text": "on that model during your app's execution. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=89"
  },
  {
    "text": "The last step is to optimize the way you use Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=93"
  },
  {
    "text": "First, I'll go over choosing a model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=99"
  },
  {
    "text": "There are many aspects of a model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=101"
  },
  {
    "text": "that you may want to consider ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=102"
  },
  {
    "text": "when deciding if you should use that model within your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=104"
  },
  {
    "text": "You also may have multiple candidates of models ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=107"
  },
  {
    "text": "you'd like to select from, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=109"
  },
  {
    "text": "but how do you decide which one to use? ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=110"
  },
  {
    "text": "You need to have a model whose functionality ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=113"
  },
  {
    "text": "will match the requirements of the feature you wish to enable. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=115"
  },
  {
    "text": "This includes understanding the model's accuracy ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=118"
  },
  {
    "text": "as well as its performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=121"
  },
  {
    "text": "A great way to learn about a Core ML model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=123"
  },
  {
    "text": "is by opening it in Xcode. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=125"
  },
  {
    "text": "Just double-click on any model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=127"
  },
  {
    "text": "and it will bring up the following. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=129"
  },
  {
    "text": "At the top, you'll find the model type, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=132"
  },
  {
    "text": "its size, and the operating system requirements. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=135"
  },
  {
    "text": "In the General tab, it shows additional details ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=139"
  },
  {
    "text": "captured in the model's metadata, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=142"
  },
  {
    "text": "its compute and storage precision, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=144"
  },
  {
    "text": "and info, such as class labels that it can predict. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=146"
  },
  {
    "text": "The Preview tab is for testing out your model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=150"
  },
  {
    "text": "by providing example inputs and seeing what it predicts. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=153"
  },
  {
    "text": "The Predictions tab displays the model's inputs and outputs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=157"
  },
  {
    "text": "as well as the types and sizes ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=160"
  },
  {
    "text": "that Core ML will expect at runtime. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=162"
  },
  {
    "text": "And finally, the Utilities tab can help with model encryption ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=165"
  },
  {
    "text": "and deployment tasks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=168"
  },
  {
    "text": "Overall, these views give you a quick overview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=172"
  },
  {
    "text": "of your model's functionality and preview of its accuracy. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=175"
  },
  {
    "text": "But what about your model's performance? ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=178"
  },
  {
    "text": "The cost of loading a model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=182"
  },
  {
    "text": "the amount of time a single prediction takes, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=184"
  },
  {
    "text": "or what hardware it utilizes, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=187"
  },
  {
    "text": "may be critical factors for your use case. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=189"
  },
  {
    "text": "You may have hard targets ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=192"
  },
  {
    "text": "related to real-time streaming data constraints ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=193"
  },
  {
    "text": "or need to make key design decisions around user interface ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=196"
  },
  {
    "text": "depending on perceived latency. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=199"
  },
  {
    "text": "One way to get insight into the model's performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=202"
  },
  {
    "text": "is to do an initial integration into your app ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=205"
  },
  {
    "text": "or by creating a small prototype ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=207"
  },
  {
    "text": "which you can instrument and measure. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=209"
  },
  {
    "text": "And since performance is hardware dependent, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=212"
  },
  {
    "text": "you would likely want to do these measurements ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=214"
  },
  {
    "text": "on a variety of supported hardware. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=215"
  },
  {
    "text": "Xcode and Core ML can now help you with this task ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=219"
  },
  {
    "text": "even before writing a single line of code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=221"
  },
  {
    "text": "Core ML now allows you to create performance reports. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=225"
  },
  {
    "text": "Let me show you.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=227"
  },
  {
    "text": " ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=232"
  },
  {
    "text": "I now have the Xcode model viewer open ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=233"
  },
  {
    "text": "for the YOLOv3 object detection model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=236"
  },
  {
    "text": "Between the Predictions and Utilities tabs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=239"
  },
  {
    "text": "there is now a Performance tab. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=241"
  },
  {
    "text": "To generate a performance report, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=244"
  },
  {
    "text": "I'll select the plus icon at the bottom left, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=246"
  },
  {
    "text": "select the device I'd like to run on -- ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=250"
  },
  {
    "text": "which is my iPhone -- click next, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=252"
  },
  {
    "text": "then select which compute units I'd like Core ML to use. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=256"
  },
  {
    "text": "I'm going to leave it on All, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=260"
  },
  {
    "text": "to allow Core ML to optimize for latency ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=261"
  },
  {
    "text": "with all available compute units. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=263"
  },
  {
    "text": "Now I'll finish by pressing Run Test. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=266"
  },
  {
    "text": "To ensure the test can run, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=271"
  },
  {
    "text": "make sure the selected device is unlocked. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=272"
  },
  {
    "text": "It shows a spinning icon while the performance report ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=276"
  },
  {
    "text": "is being generated. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=278"
  },
  {
    "text": "To create the report, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=280"
  },
  {
    "text": "the model is sent over to the device, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=282"
  },
  {
    "text": "then there are several iterations of compile, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=284"
  },
  {
    "text": "load, and predictions which are run with the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=286"
  },
  {
    "text": "Once those are complete, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=290"
  },
  {
    "text": "the metrics in the performance report are calculated. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=291"
  },
  {
    "text": "Now it's run the model on my iPhone, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=295"
  },
  {
    "text": "and it displays the performance report. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=297"
  },
  {
    "text": "At the top, it shows some details ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=300"
  },
  {
    "text": "about the device where the test was run ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=302"
  },
  {
    "text": "as well as which compute units were selected. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=304"
  },
  {
    "text": "Next it shows statistics about the run. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=309"
  },
  {
    "text": "The median prediction time was 22.19 milliseconds ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=312"
  },
  {
    "text": "and the median load time was about 400 ms. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=316"
  },
  {
    "text": "Also, if you plan to compile your model on-device, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=320"
  },
  {
    "text": "this shows the compilation time was about 940 ms. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=323"
  },
  {
    "text": "A prediction time of around 22 ms tells me that this model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=328"
  },
  {
    "text": "can support about 45 frames per second ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=332"
  },
  {
    "text": "if I want to run it in real time.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=334"
  },
  {
    "text": "Since this model contains a neural network, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=339"
  },
  {
    "text": "there's a layer view displayed towards the bottom ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=341"
  },
  {
    "text": "of the performance report. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=343"
  },
  {
    "text": "This shows the name and type of all of the layers, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=345"
  },
  {
    "text": "as well as which compute unit each layer ran on. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=349"
  },
  {
    "text": "A filled-in checkmark means that the layer was executed ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=353"
  },
  {
    "text": "on that compute unit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=356"
  },
  {
    "text": "An unfilled checkmark means that the layer is supported ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=359"
  },
  {
    "text": "on that compute unit, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=362"
  },
  {
    "text": "but Core ML did not choose to run it there. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=363"
  },
  {
    "text": "And an empty diamond means that the layer is not supported ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=366"
  },
  {
    "text": "on that compute unit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=369"
  },
  {
    "text": "In this case, 54 layers were run on the GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=372"
  },
  {
    "text": "and 32 layers were run on the Neural Engine. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=376"
  },
  {
    "text": "You can also filter the layers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=379"
  },
  {
    "text": "by a compute unit by clicking on it.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=380"
  },
  {
    "text": "That was how you can use Xcode 14 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=389"
  },
  {
    "text": "to generate performance reports for your Core ML models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=391"
  },
  {
    "text": "This was shown for running on an iPhone, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=395"
  },
  {
    "text": "but it will allow you to test on multiple operating system ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=397"
  },
  {
    "text": "and hardware combinations, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=400"
  },
  {
    "text": "without having to write a single line of code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=402"
  },
  {
    "text": "Now that you've chosen your model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=405"
  },
  {
    "text": "the next step is to integrate this model into your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=407"
  },
  {
    "text": "This involves bundling the model with your app ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=410"
  },
  {
    "text": "and making use of Core ML APIs to load the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=413"
  },
  {
    "text": "and make predictions with it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=416"
  },
  {
    "text": "In this case, I've built an app ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=419"
  },
  {
    "text": "that uses Core ML style transfer models to perform style transfer ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=421"
  },
  {
    "text": "on frames from a live camera session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=425"
  },
  {
    "text": "It's working properly; however, the frame rate ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=428"
  },
  {
    "text": "is slower than I'd expect, and I'd like to understand why. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=430"
  },
  {
    "text": "This is where you'd move on to step three, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=435"
  },
  {
    "text": "which is to optimize your Core ML usage. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=437"
  },
  {
    "text": "Generating a performance report can show the performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=440"
  },
  {
    "text": "a model is capable of achieving in a stand-alone environment; ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=443"
  },
  {
    "text": "however, you also need a way to profile the performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=446"
  },
  {
    "text": "of a model that's running live in your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=449"
  },
  {
    "text": "For this, you can now use the Core ML Instrument ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=452"
  },
  {
    "text": "found in the Instruments app in Xcode 14. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=455"
  },
  {
    "text": "This Instrument allows you to visualize the performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=458"
  },
  {
    "text": "of your model when it runs live in your app, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=461"
  },
  {
    "text": "and helps you identify potential performance issues. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=463"
  },
  {
    "text": "Let me show how it can be used. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=466"
  },
  {
    "text": "So I'm in Xcode ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=470"
  },
  {
    "text": "with my style transfer app workspace open, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=472"
  },
  {
    "text": "and I'm ready to profile the app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=474"
  },
  {
    "text": "I'll force-click on the Run button ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=476"
  },
  {
    "text": "and select Profile.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=477"
  },
  {
    "text": "This will install the latest version of the code ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=482"
  },
  {
    "text": "on my device and open Instruments for me ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=484"
  },
  {
    "text": "with my targeted device and app selected. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=486"
  },
  {
    "text": "Since I want to profile my Core ML usage, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=490"
  },
  {
    "text": "I'm going to select the Core ML template. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=492"
  },
  {
    "text": "This template includes the Core ML Instrument, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=497"
  },
  {
    "text": "as well as several other useful Instruments ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=499"
  },
  {
    "text": "which will help you profile your Core ML usage. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=501"
  },
  {
    "text": "To capture a trace, I'll simply press Record.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=504"
  },
  {
    "text": "The app is now running on my iPhone. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=512"
  },
  {
    "text": "I will let it run for a few seconds ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=515"
  },
  {
    "text": "and use a few different styles. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=516"
  },
  {
    "text": "And now I'll end the trace by pressing the Stop button. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=519"
  },
  {
    "text": "Now I have my Instruments trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=522"
  },
  {
    "text": "I'm going to focus on the Core ML Instrument. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=524"
  },
  {
    "text": "The Core ML Instrument shows all of the Core ML events ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=528"
  },
  {
    "text": "that were captured in the trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=530"
  },
  {
    "text": "The initial view groups all of the events into three lanes: ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=533"
  },
  {
    "text": "Activity, Data, and Compute. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=536"
  },
  {
    "text": "The Activity lane shows top-level Core ML events ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=541"
  },
  {
    "text": "which have a one-to-one relationship ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=544"
  },
  {
    "text": "with the actual Core ML APIs that you would call directly, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=546"
  },
  {
    "text": "such as loads and predictions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=549"
  },
  {
    "text": "The Data lane shows events in which Core ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=554"
  },
  {
    "text": "is performing data checks or data transformations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=556"
  },
  {
    "text": "to make sure that it can safely work ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=559"
  },
  {
    "text": "with the model's inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=560"
  },
  {
    "text": "The Compute lane shows when Core ML sends ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=565"
  },
  {
    "text": "compute requests to specific compute units, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=567"
  },
  {
    "text": "such as the Neural Engine, or the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=570"
  },
  {
    "text": "You can also select the Ungrouped view ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=573"
  },
  {
    "text": "where there is an individual lane for each event type. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=576"
  },
  {
    "text": "At the bottom, there's the Model Activity Aggregation view. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=582"
  },
  {
    "text": "This view provides aggregate statistics for all of the events ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=586"
  },
  {
    "text": "displayed in the trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=589"
  },
  {
    "text": "For example, in this trace, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=591"
  },
  {
    "text": "the average model load took 17.17 ms, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=593"
  },
  {
    "text": "and the average prediction took 7.2 ms. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=597"
  },
  {
    "text": "Another note is that it can sort the events by duration. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=602"
  },
  {
    "text": "Here, the list is telling me that more time is being spent ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=605"
  },
  {
    "text": "loading the model than actually making predictions with it, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=608"
  },
  {
    "text": "at a total of 6.41 seconds of loads, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=612"
  },
  {
    "text": "compared to only 2.69 seconds of predictions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=615"
  },
  {
    "text": "Perhaps this has something to with the low frame rate. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=619"
  },
  {
    "text": "Let me try to find where all of these loads are coming from.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=622"
  },
  {
    "text": "I am noticing that I am reloading my Core ML model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=628"
  },
  {
    "text": "prior to calling each prediction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=630"
  },
  {
    "text": "This is generally not good practice ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=633"
  },
  {
    "text": "as I can just load the model once and hold it in memory. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=635"
  },
  {
    "text": "I'm going to jump back into my code and try to fix this.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=638"
  },
  {
    "text": "I found the area of code where I load my model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=647"
  },
  {
    "text": "The issue here is that this is a computed properly, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=650"
  },
  {
    "text": "which means that each time I reference the ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=652"
  },
  {
    "text": "styleTransferModel variable, it will recompute the property, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=654"
  },
  {
    "text": "which means reloading the model, in this case. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=658"
  },
  {
    "text": "I can quickly fix this ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=661"
  },
  {
    "text": "by changing this to be a lazy variable.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=662"
  },
  {
    "text": "Now I'll reprofile the app to check if this has fixed ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=674"
  },
  {
    "text": "the repeated loads issue.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=677"
  },
  {
    "text": "I'll once again select the Core ML template ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=687"
  },
  {
    "text": "and capture a trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=690"
  },
  {
    "text": "This is much more in line with what I'd expect. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=694"
  },
  {
    "text": "The count column tells me ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=696"
  },
  {
    "text": "that there are five load events total, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=698"
  },
  {
    "text": "which matches the number of styles I used in the app, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=700"
  },
  {
    "text": "and the total duration of loads is much smaller ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=702"
  },
  {
    "text": "than the total duration of predictions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=705"
  },
  {
    "text": "Also, as I scroll through... ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=709"
  },
  {
    "text": "...it correctly shows repeated prediction events ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=714"
  },
  {
    "text": "without loads in between each one.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=717"
  },
  {
    "text": "Another note is that so far, I've only looked at the views ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=722"
  },
  {
    "text": "that show all Core ML model activity. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=724"
  },
  {
    "text": "In this app, there is one Core ML model per style, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=727"
  },
  {
    "text": "so I may want to breakdown the Core ML activity by model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=731"
  },
  {
    "text": "The Instrument makes this easy to do. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=734"
  },
  {
    "text": "In the main graph, you can click the arrow at the top left, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=737"
  },
  {
    "text": "and it will make one subtrack ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=743"
  },
  {
    "text": "for each model used in the trace. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=744"
  },
  {
    "text": "Here it displays all of the different style transfer models ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=747"
  },
  {
    "text": "that were used. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=749"
  },
  {
    "text": "The Aggregation view also offers similar functionality ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=752"
  },
  {
    "text": "by allowing you to break down the statistics by model.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=755"
  },
  {
    "text": "Next I'd like to dive into a prediction on one of my models ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=763"
  },
  {
    "text": "to get a better idea of how it's being run. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=767"
  },
  {
    "text": "I'll look deeper into the Watercolor model.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=770"
  },
  {
    "text": "In this prediction, the Compute lane is telling me ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=774"
  },
  {
    "text": "that my model was run on a combination ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=777"
  },
  {
    "text": "of the Neural Engine and the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=779"
  },
  {
    "text": "Core ML is sending these compute requests asynchronously, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=783"
  },
  {
    "text": "so if I'm interested to see when these compute units ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=786"
  },
  {
    "text": "are actively running the model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=788"
  },
  {
    "text": "I can combine the Core ML Instrument ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=790"
  },
  {
    "text": "with the GPU Instrument and the new Neural Engine Instrument. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=792"
  },
  {
    "text": "To do this, I have the three Instruments pinned here.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=796"
  },
  {
    "text": "The Core ML Instrument shows me the entire region ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=803"
  },
  {
    "text": "where the model ran.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=805"
  },
  {
    "text": "And within this region, the Neural Engine Instrument ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=813"
  },
  {
    "text": "shows the compute first running on the Neural Engine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=816"
  },
  {
    "text": "then the GPU Instrument shows the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=821"
  },
  {
    "text": "was handed off from the Neural Engine ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=823"
  },
  {
    "text": "to finish running on the GPU. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=825"
  },
  {
    "text": "This gives me a better idea of how my model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=827"
  },
  {
    "text": "is actually being executed on the hardware. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=830"
  },
  {
    "text": "To recap, I used the Core ML Instrument in Xcode 14 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=834"
  },
  {
    "text": "to learn about my model's performance ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=838"
  },
  {
    "text": "when running live in my app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=840"
  },
  {
    "text": "I then identified an issue ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=842"
  },
  {
    "text": "in which I was too frequently reloading my model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=844"
  },
  {
    "text": "I fixed the issue in my code, reprofiled the application, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=847"
  },
  {
    "text": "and verified that the issue had been fixed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=850"
  },
  {
    "text": "I was also able to combine the Core ML, GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=854"
  },
  {
    "text": "and new Neural Engine Instrument to get more details ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=857"
  },
  {
    "text": "on how my model was actually run on different compute units. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=860"
  },
  {
    "text": "That was an overview of the new tools ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=864"
  },
  {
    "text": "to help you understand performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=866"
  },
  {
    "text": "Next, I'll go over some enhanced APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=869"
  },
  {
    "text": "that can help optimize that performance. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=871"
  },
  {
    "text": "Let me start by going over how Core ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=874"
  },
  {
    "text": "handles model inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=876"
  },
  {
    "text": "When you create a Core ML model, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=879"
  },
  {
    "text": "that model has a set of input and output features, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=881"
  },
  {
    "text": "each with a type and size. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=884"
  },
  {
    "text": "At runtime, you use Core ML APIs to provide inputs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=887"
  },
  {
    "text": "that conform with the model's interface ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=890"
  },
  {
    "text": "and get outputs after running inference. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=892"
  },
  {
    "text": "Let me focus on images and MultiArrays ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=895"
  },
  {
    "text": "in a bit more detail. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=897"
  },
  {
    "text": "For images, Core ML supports 8-bit grayscale ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=900"
  },
  {
    "text": "and 32-bit color images with 8 bits per component. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=904"
  },
  {
    "text": "And for multidimensional arrays, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=908"
  },
  {
    "text": "Core ML supports Int32, Double, and Float32 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=910"
  },
  {
    "text": "as the scalar types. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=913"
  },
  {
    "text": "If your app is already working with these types, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=916"
  },
  {
    "text": "it's simply a matter of connecting them to the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=918"
  },
  {
    "text": "However, sometimes your types may differ. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=921"
  },
  {
    "text": "Let me show an example. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=924"
  },
  {
    "text": "I'd like to add a new filter to my image processing ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=926"
  },
  {
    "text": "and style app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=928"
  },
  {
    "text": "This filter works to sharpen images ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=930"
  },
  {
    "text": "by operating on a single-channel image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=931"
  },
  {
    "text": "My app has some pre- and post-processing operations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=935"
  },
  {
    "text": "on the GPU and represents this single channel ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=937"
  },
  {
    "text": "in Float16 precision. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=940"
  },
  {
    "text": "To do this, I used coremltools to convert ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=943"
  },
  {
    "text": "an image-sharpening torch model to Core ML format as shown here. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=946"
  },
  {
    "text": "The model was set up to use Float16 precision computation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=951"
  },
  {
    "text": "Also, it takes image inputs and produces image outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=954"
  },
  {
    "text": "I got a model that looks like this. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=959"
  },
  {
    "text": "Note that it takes grayscale images ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=962"
  },
  {
    "text": "which are 8-bit for Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=964"
  },
  {
    "text": "To make this work, I had to write some code ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=967"
  },
  {
    "text": "to downcast my input from OneComponent16Half ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=969"
  },
  {
    "text": "to OneComponent8 and then upcast the output ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=972"
  },
  {
    "text": "from OneComponent8 to OneComponent16Half. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=976"
  },
  {
    "text": "However, this isn't the whole story. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=979"
  },
  {
    "text": "Since the model was set up to perform computation ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=982"
  },
  {
    "text": "in Float16 precision, at some point, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=985"
  },
  {
    "text": "Core ML needs to convert these 8-bit inputs to Float16. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=988"
  },
  {
    "text": "It does the conversion efficiently, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=993"
  },
  {
    "text": "but when looking at an Instruments trace ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=995"
  },
  {
    "text": "with the app running, it shows this. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=996"
  },
  {
    "text": "Notice the data steps Core ML is performing ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=999"
  },
  {
    "text": "before and after Neural Engine computation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1002"
  },
  {
    "text": "When zooming in on the Data lane, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1007"
  },
  {
    "text": "it shows Core ML is copying data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1009"
  },
  {
    "text": "to prepare it for computation on the Neural Engine, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1011"
  },
  {
    "text": "which means converting it to Float16, in this case. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1014"
  },
  {
    "text": "This seems unfortunate since the original data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1017"
  },
  {
    "text": "was already Float16. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1019"
  },
  {
    "text": "Ideally, these data transformations can be avoided ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1022"
  },
  {
    "text": "both in-app and inside Core ML by making the model work ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1025"
  },
  {
    "text": "directly with Float16 inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1029"
  },
  {
    "text": "Starting in iOS 16 and macOS Ventura, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1032"
  },
  {
    "text": "Core ML will have native support ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1036"
  },
  {
    "text": "for one OneComponent16Half grayscale images, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1037"
  },
  {
    "text": "and Float16 MultiArrays. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1040"
  },
  {
    "text": "You can create a model that accepts Float16 inputs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1044"
  },
  {
    "text": "and outputs by specifying a new color layout for images ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1047"
  },
  {
    "text": "or a new data type for MultiArrays, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1050"
  },
  {
    "text": "while invoking the coremltools convert method. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1052"
  },
  {
    "text": "In this case, I'm specifying the input and output ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1056"
  },
  {
    "text": "of my model to be grayscale Float16 images. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1058"
  },
  {
    "text": "Since Float16 support is available ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1063"
  },
  {
    "text": "starting in iOS 16 and macOS Ventura, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1065"
  },
  {
    "text": "these features are only available ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1069"
  },
  {
    "text": "when the minimum deployment target is specified as iOS 16. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1070"
  },
  {
    "text": "This is how the reconverted version of the model looks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1076"
  },
  {
    "text": "Note that the inputs and outputs are marked as Grayscale16Half. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1079"
  },
  {
    "text": "With this Float16 support, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1084"
  },
  {
    "text": "my app can directly feed Float16 images to Core ML, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1085"
  },
  {
    "text": "which will avoid the need for downcasting the inputs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1089"
  },
  {
    "text": "and upcasting the outputs in the app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1091"
  },
  {
    "text": "This is how it looks in the code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1096"
  },
  {
    "text": "Since I have my input data in the form ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1098"
  },
  {
    "text": "of a OneComponent16Half CVPixelBuffer, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1100"
  },
  {
    "text": "I can simply send the pixel buffer ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1104"
  },
  {
    "text": "directly to Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1105"
  },
  {
    "text": "This does not incur any data copy or transformation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1107"
  },
  {
    "text": "I then get a OneComponent16Half CVPixelBuffer as the output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1111"
  },
  {
    "text": "This results in simpler code, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1116"
  },
  {
    "text": "and no data transformations required. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1118"
  },
  {
    "text": "There's also another cool thing you can do, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1122"
  },
  {
    "text": "and that's to ask Core ML to fill your preallocated buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1124"
  },
  {
    "text": "for outputs instead of having Core ML allocate ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1127"
  },
  {
    "text": "a new buffer for each prediction. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1130"
  },
  {
    "text": "You can do this by allocating an output backing buffer ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1133"
  },
  {
    "text": "and setting it on the prediction options. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1136"
  },
  {
    "text": "For my app, I wrote a function called outputBackingBuffer ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1139"
  },
  {
    "text": "which returns a OneComponent1 HalfCVPixelBuffer. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1142"
  },
  {
    "text": "I then set this on the prediction options, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1146"
  },
  {
    "text": "and finally call the prediction method on my model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1148"
  },
  {
    "text": "with those prediction options. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1151"
  },
  {
    "text": "By specifying output backings, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1154"
  },
  {
    "text": "you can gain better control over the buffer management ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1156"
  },
  {
    "text": "for model outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1158"
  },
  {
    "text": "So with those changes made, to recap, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1161"
  },
  {
    "text": "here's what was shown in the Instruments trace ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1164"
  },
  {
    "text": "when using the original version of the model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1166"
  },
  {
    "text": "that had 8-bit inputs and outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1168"
  },
  {
    "text": "And here's how the final Instruments trace looks ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1171"
  },
  {
    "text": "after modifying the code ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1174"
  },
  {
    "text": "to provide IOSurface-backed Float16 buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1175"
  },
  {
    "text": "to the new Float16 version of the model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1178"
  },
  {
    "text": "The data transformations that were previously shown ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1182"
  },
  {
    "text": "in the Data lane are now gone, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1184"
  },
  {
    "text": "since Core ML no longer needs to perform them. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1186"
  },
  {
    "text": "To summarize, Core ML now has end-to-end native support ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1189"
  },
  {
    "text": "for Float16 data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1193"
  },
  {
    "text": "This means you can provide Float16 inputs to Core ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1195"
  },
  {
    "text": "and have Core ML give you back Float16 outputs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1199"
  },
  {
    "text": "You can also use the new output backing API ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1203"
  },
  {
    "text": "to have Core ML fill up your preallocated output buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1205"
  },
  {
    "text": "instead of making new ones. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1209"
  },
  {
    "text": "And lastly, we recommend ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1211"
  },
  {
    "text": "using IOSurface-backed buffers whenever possible, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1213"
  },
  {
    "text": "as this allows Core ML to transfer the data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1216"
  },
  {
    "text": "between different compute units without data copies ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1218"
  },
  {
    "text": "by taking advantage of the unified memory. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1221"
  },
  {
    "text": "Next, I'll go through a quick tour ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1225"
  },
  {
    "text": "of some of the additional capabilities ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1226"
  },
  {
    "text": "being added to Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1228"
  },
  {
    "text": "First is weight compression. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1231"
  },
  {
    "text": "Compressing the weights of your model may allow you ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1233"
  },
  {
    "text": "to achieve similar accuracy while having a smaller model. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1235"
  },
  {
    "text": "In iOS 12, Core ML introduced post-training weight compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1239"
  },
  {
    "text": "which allows you to reduce the size ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1243"
  },
  {
    "text": "of Core ML neural network models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1245"
  },
  {
    "text": "We are now extending 16- and 8-bit support ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1248"
  },
  {
    "text": "to the ML Program model type, and additionally, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1251"
  },
  {
    "text": "introducing a new option to store weights ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1254"
  },
  {
    "text": "in a sparse representation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1256"
  },
  {
    "text": "With coremltools utilities, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1259"
  },
  {
    "text": "you will now be able to quantize, palettize, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1261"
  },
  {
    "text": "and sparsify the weights for your ML Program models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1264"
  },
  {
    "text": "Next is a new compute unit option. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1269"
  },
  {
    "text": "Core ML always aims to minimize inference latency ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1272"
  },
  {
    "text": "for the given compute unit preference. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1275"
  },
  {
    "text": "Apps can specify this preference by setting ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1278"
  },
  {
    "text": "the MLModelConfiguration computeUnits property. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1280"
  },
  {
    "text": "In addition to the three existing compute unit options, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1284"
  },
  {
    "text": "there is now a new one called cpuAndNeuralEngine. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1287"
  },
  {
    "text": "This tells Core ML to not dispatch computation on the GPU, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1291"
  },
  {
    "text": "which can be helpful when the app uses the GPU ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1294"
  },
  {
    "text": "for other computation and, hence, prefers Core ML ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1297"
  },
  {
    "text": "to limit its focus to the CPU and the Neural Engine. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1300"
  },
  {
    "text": "Next, we are adding a new way to initialize ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1304"
  },
  {
    "text": "your Core ML model instance that provides additional flexibility ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1307"
  },
  {
    "text": "in terms of model serialization. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1311"
  },
  {
    "text": "This allows you to encrypt your model data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1314"
  },
  {
    "text": "with custom encryption schemes ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1316"
  },
  {
    "text": "and decrypt it just before loading. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1318"
  },
  {
    "text": "With these new APIs, you can compile and load ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1321"
  },
  {
    "text": "an in-memory Core ML model specification ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1324"
  },
  {
    "text": "without requiring the compiled model to be on disk. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1326"
  },
  {
    "text": "The last update is about Swift packages ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1331"
  },
  {
    "text": "and how they work with Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1334"
  },
  {
    "text": "Packages are a great way to bundle and distribute ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1336"
  },
  {
    "text": "reusable code. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1338"
  },
  {
    "text": "With Xcode 14, you can include Core ML models ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1340"
  },
  {
    "text": "in your Swift packages, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1343"
  },
  {
    "text": "and now when someone imports your package, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1344"
  },
  {
    "text": "your model will just work. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1347"
  },
  {
    "text": "Xcode will compile and bundle your Core ML model automatically ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1348"
  },
  {
    "text": "and create the same code-generation interface ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1352"
  },
  {
    "text": "you're used to working with. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1354"
  },
  {
    "text": "We're excited about this change, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1356"
  },
  {
    "text": "as it'll make it a lot easier to distribute your models ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1358"
  },
  {
    "text": "in the Swift ecosystem. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1360"
  },
  {
    "text": "That brings us to the end of this session. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1363"
  },
  {
    "text": "Core ML performance reports and Instrument in Xcode 14 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1366"
  },
  {
    "text": "are here to help you analyze and optimize ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1369"
  },
  {
    "text": "the performance of the ML-powered features ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1371"
  },
  {
    "text": "in your apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1373"
  },
  {
    "text": "New Float16 support and output backing APIs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1376"
  },
  {
    "text": "gives you more control of how data flows in and out ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1379"
  },
  {
    "text": "of Core ML. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1381"
  },
  {
    "text": "Extended support for weight compression ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1383"
  },
  {
    "text": "can help you minimize the size of your models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1385"
  },
  {
    "text": "And with in-memory models and Swift package support, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1389"
  },
  {
    "text": "you have even more options when it comes ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1392"
  },
  {
    "text": "to how you represent, integrate, and share Core ML models. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1393"
  },
  {
    "text": "This was Ben from the Core ML team, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1398"
  },
  {
    "text": "and have a great rest of WWDC. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1400"
  },
  {
    "text": "♪",
    "link": "https://developer.apple.com/videos/play/wwdc2022-10027/?time=1402"
  }
]