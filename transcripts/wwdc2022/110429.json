[
  {
    "text": "♪ instrumental hip hop music ♪ ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=0"
  },
  {
    "text": "Hello, and welcome to ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=9"
  },
  {
    "text": "“Discover advancements in iOS camera capture”. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=11"
  },
  {
    "text": "I'm Nikolas Gelo from the Camera Software team, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=14"
  },
  {
    "text": "and I'll be presenting some exciting new camera features in iOS and iPadOS. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=16"
  },
  {
    "text": "I'll begin with how to stream depth from LiDAR Scanners using AVFoundation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=20"
  },
  {
    "text": "Next, a look at how your app will receive improved face rendering ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=25"
  },
  {
    "text": "with face-driven auto focus and auto exposure. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=28"
  },
  {
    "text": "Then, I'll take you through advanced AVCaptureSession streaming configurations. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=31"
  },
  {
    "text": "And lastly, I'll show you how your app will ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=36"
  },
  {
    "text": "be able to use the camera while multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=38"
  },
  {
    "text": "I'll begin with how to stream depth from LiDAR Scanners using AVFoundation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=41"
  },
  {
    "text": "The iPhone 12 Pro, iPhone 13 Pro, and iPad Pro are equipped ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=45"
  },
  {
    "text": "with LiDAR Scanners capable of outputting dense depth maps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=50"
  },
  {
    "text": "The LiDAR Scanner works by shooting light onto the surroundings, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=53"
  },
  {
    "text": "and then collecting the light reflected off the surfaces in the scene. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=57"
  },
  {
    "text": "The depth is estimated by measuring the time it took for the light to go ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=60"
  },
  {
    "text": "from the LiDAR to the environment and reflect back to the scanner. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=63"
  },
  {
    "text": "This entire process runs millions of times every second. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=67"
  },
  {
    "text": "I'll show you the LiDAR Scanner in action using AVFoundation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=71"
  },
  {
    "text": "Here on an iPhone 13 Pro Max, I'm running an app that uses ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=74"
  },
  {
    "text": "the new LiDAR Depth Camera AVCaptureDevice. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=77"
  },
  {
    "text": "The app renders streaming depth data on top of the live camera feed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=80"
  },
  {
    "text": "Blue is shown for objects that are close and red for objects that are further away. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=84"
  },
  {
    "text": "And using the slider, I can adjust the opacity of the depth. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=89"
  },
  {
    "text": "This app also takes photos with high resolution depth maps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=93"
  },
  {
    "text": "When I take a photo, the same depth overlay is applied ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=96"
  },
  {
    "text": "but with an even greater resolution for the still. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=99"
  },
  {
    "text": "This app has one more trick up its sleeve. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=102"
  },
  {
    "text": "When I press the torch button, the app uses the high resolution depth map ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=105"
  },
  {
    "text": "with the color image to render a spotlight on the scene using RealityKit. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=109"
  },
  {
    "text": "I can tap around and point the spotlight at different objects in the scene. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=112"
  },
  {
    "text": "Look how the spotlight highlights the guitar. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=117"
  },
  {
    "text": "Or if I tap on the right spot in the corner of the wall, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=119"
  },
  {
    "text": "the spotlight forms the shape of a heart. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=122"
  },
  {
    "text": "Let's go back to that guitar. It looks so cool.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=124"
  },
  {
    "text": "API for the LiDAR Scanner was first introduced in ARKit in iPadOS 13.4. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=129"
  },
  {
    "text": "If you haven't seen the WWDC 2020 presentation “Explore ARKit 4”, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=134"
  },
  {
    "text": "I encourage you to watch it. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=139"
  },
  {
    "text": "New in iOS 15.4, your app can access the LiDAR Scanner with AVFoundation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=141"
  },
  {
    "text": "We have introduced a new AVCapture Device Type, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=146"
  },
  {
    "text": "the built-in LiDAR Depth Camera, which delivers video and depth. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=149"
  },
  {
    "text": "It produces high-quality, high-accuracy depth information. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=153"
  },
  {
    "text": "This new AVCaptureDevice uses the rear-facing wide-angle camera ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=156"
  },
  {
    "text": "to deliver video with the LiDAR Scanner to capture depth. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=160"
  },
  {
    "text": "Both the video and depth are captured in the wide-angle camera's field of view. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=163"
  },
  {
    "text": "And like the TrueDepth AVCaptureDevice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=167"
  },
  {
    "text": "all of its formats support depth data delivery. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=170"
  },
  {
    "text": "This new AVCaptureDevice produces high quality depth data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=173"
  },
  {
    "text": "by fusing sparse output from the LiDAR Scanner ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=177"
  },
  {
    "text": "with the color image from the rear-facing wide-angle camera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=179"
  },
  {
    "text": "The LiDAR and color inputs are processed using a machine learning model ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=182"
  },
  {
    "text": "that outputs a dense depth map. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=186"
  },
  {
    "text": "Because the LiDAR Depth Camera uses the rear-facing wide-angle camera, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=188"
  },
  {
    "text": "the Telephoto and Ultra Wide cameras can be used in addition ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=191"
  },
  {
    "text": "with an AVCaptureMultiCamSession. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=194"
  },
  {
    "text": "This is useful for apps that wish to use multiple cameras at the same time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=197"
  },
  {
    "text": "The LiDAR Depth Camera exposes many formats, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=200"
  },
  {
    "text": "from video resolutions of 640 by 480 ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=204"
  },
  {
    "text": "to a full 12-megapixel image at 4032 by 3024. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=207"
  },
  {
    "text": "While streaming, it can output depth maps up to 320 by 240. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=212"
  },
  {
    "text": "And for photo capture, you can receive depth maps of 768 by 576. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=216"
  },
  {
    "text": "Note, the depth resolutions are slightly different for 16 by 9 and 4 by 3 formats. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=223"
  },
  {
    "text": "This is to match the video's aspect ratio. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=227"
  },
  {
    "text": "The LiDAR Depth Camera AVCaptureDevice is available ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=231"
  },
  {
    "text": "on iPhone 12 Pro, iPhone 13 Pro, and iPad Pro 5th generation. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=233"
  },
  {
    "text": "iPhone 13 Pro can deliver depth data using a combination of the rear facing cameras. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=238"
  },
  {
    "text": "The AVFoundation Capture API refers to these as “virtual devices” ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=243"
  },
  {
    "text": "that consist of physical devices. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=247"
  },
  {
    "text": "On the back of the iPhone 13 Pro, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=249"
  },
  {
    "text": "there are four virtual AVCaptureDevices available to use: ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=251"
  },
  {
    "text": "The new LiDAR Depth Camera uses the LiDAR Scanner ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=255"
  },
  {
    "text": "with the wide-angle camera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=258"
  },
  {
    "text": "The Dual Camera uses the Wide and Telephoto cameras. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=260"
  },
  {
    "text": "The Dual Wide Camera, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=264"
  },
  {
    "text": "which uses the Wide and Ultra Wide cameras. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=265"
  },
  {
    "text": "And the Triple Camera, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=268"
  },
  {
    "text": "that uses the Wide, Ultra Wide, and Telephoto cameras. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=270"
  },
  {
    "text": "There are differences in the type of depth these devices produce. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=273"
  },
  {
    "text": "The LiDAR Depth Camera produces “absolute depth.” ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=277"
  },
  {
    "text": "The time of flight technique used allows for real-world scale to be calculated. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=281"
  },
  {
    "text": "For example, this is great for computer vision tasks like measuring. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=285"
  },
  {
    "text": "The TrueDepth, Dual, Dual Wide, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=289"
  },
  {
    "text": "and Triple Cameras produce relative, disparity-based depth. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=292"
  },
  {
    "text": "This uses less power and is great for apps that render photo effects. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=296"
  },
  {
    "text": "AVFoundation represents depth using the AVDepthData class. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=300"
  },
  {
    "text": "This class has a pixel buffer containing the depth ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=304"
  },
  {
    "text": "with other properties describing it, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=307"
  },
  {
    "text": "including the depth data type, the accuracy, and whether it is filtered. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=309"
  },
  {
    "text": "It is delivered by a depth-capable AVCaptureDevice, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=313"
  },
  {
    "text": "like the new LiDAR Depth Camera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=316"
  },
  {
    "text": "You can stream depth from an AVCaptureDepthDataOutput ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=318"
  },
  {
    "text": "or receive depth attached to photos from an AVCapturePhotoOutput. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=320"
  },
  {
    "text": "Depth data is filtered by default. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=325"
  },
  {
    "text": "Filtering reduces noise ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=327"
  },
  {
    "text": "and fills in missing values, or holes, in the depth map. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=329"
  },
  {
    "text": "This is great for video and photography apps, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=332"
  },
  {
    "text": "so artifacts don't appear when using the depth map ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=334"
  },
  {
    "text": "to apply effects on a color image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=337"
  },
  {
    "text": "However, computer vision apps should prefer non-filtered depth data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=339"
  },
  {
    "text": "to preserve the original values in the depth map. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=343"
  },
  {
    "text": "When filtering is disabled, the LiDAR Depth Camera ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=346"
  },
  {
    "text": "excludes low confidence points. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=348"
  },
  {
    "text": "To disable depth data filtering, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=351"
  },
  {
    "text": "set the isFilteringEnabled property on your AVCaptureDepthDataOutput to false, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=353"
  },
  {
    "text": "and when you receive an AVDepthData object from your delegate callback, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=358"
  },
  {
    "text": "it will not be filtered. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=361"
  },
  {
    "text": "Since ARKit already provided access to the LiDAR Scanner, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=363"
  },
  {
    "text": "you might ask, “How does AVFoundation compare?” ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=366"
  },
  {
    "text": "AVFoundation is designed for video and photography apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=370"
  },
  {
    "text": "With AVFoundation, you can embed depth data ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=374"
  },
  {
    "text": "captured with the LiDAR Scanner into high-resolution photos. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=376"
  },
  {
    "text": "ARKit is best suited for augmented reality apps, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=380"
  },
  {
    "text": "as the name suggests. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=383"
  },
  {
    "text": "With the LiDAR Scanner, ARKit is capable of delivering features ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=384"
  },
  {
    "text": "like scene geometry and object placement. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=388"
  },
  {
    "text": "AVFoundation can deliver high-resolution video ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=391"
  },
  {
    "text": "that is great for recording movies and taking photos. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=394"
  },
  {
    "text": "AVFoundation's LiDAR Depth Camera can output depth up to 768 by 576. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=396"
  },
  {
    "text": "This is more than twice as big as ARKit's depth resolution of 256 by 192. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=402"
  },
  {
    "text": "ARKit uses lower resolution depth maps, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=407"
  },
  {
    "text": "so it can apply augmented reality algorithms for its features. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=410"
  },
  {
    "text": "For more “in-depth” information on how to use AVFoundation to capture depth data, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=415"
  },
  {
    "text": "watch our previous session “Capturing Depth in iPhone Photography” ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=419"
  },
  {
    "text": "from WWDC 2017. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=423"
  },
  {
    "text": "We're excited to see the interesting ways ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=425"
  },
  {
    "text": "you can use the LiDAR Depth Camera in your apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=427"
  },
  {
    "text": "Next up, I'll discuss how improvements to the auto focus and auto exposure systems ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=430"
  },
  {
    "text": "help to improve the visibility of faces in the scene for your app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=435"
  },
  {
    "text": "The auto focus and auto exposure systems analyze the scene ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=438"
  },
  {
    "text": "to capture the best image. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=441"
  },
  {
    "text": "The auto focus system adjusts the lens to keep the subject in focus, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=443"
  },
  {
    "text": "and the auto exposure system balances the brightest ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=447"
  },
  {
    "text": "and darkest regions of a scene to keep the subject visible. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=449"
  },
  {
    "text": "However, sometimes the automatic adjustments made ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=453"
  },
  {
    "text": "do not keep your subject's face in focus. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=456"
  },
  {
    "text": "And other times, the subject's face can be difficult ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=458"
  },
  {
    "text": "to see with bright backlit scenes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=461"
  },
  {
    "text": "A common feature of DSLRs and other pro cameras is to track faces in the scene ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=464"
  },
  {
    "text": "to dynamically adjust the focus and exposure to keep them visible. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=469"
  },
  {
    "text": "New in iOS 15.4, the focus and exposure systems will prioritize faces. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=472"
  },
  {
    "text": "We liked the benefits of this so much that we have enabled it by default ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=478"
  },
  {
    "text": "for all apps linked on iOS 15.4 or later. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=481"
  },
  {
    "text": "I'll show you some examples. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=484"
  },
  {
    "text": "Without face-driven auto focus, the camera stays focused ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=487"
  },
  {
    "text": "on the background without refocusing on the face. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=490"
  },
  {
    "text": "Watch it again. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=493"
  },
  {
    "text": "Look at how his face remains out of focus as he turns around ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=494"
  },
  {
    "text": "and that the trees in the background stay sharp. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=496"
  },
  {
    "text": "With face-driven auto focus enabled, you can clearly see his face. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=499"
  },
  {
    "text": "And when he turns away, the camera changes its focus to the background.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=503"
  },
  {
    "text": "When we compare the videos side by side, the difference is clear. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=508"
  },
  {
    "text": "On the right with face-driven auto focus enabled, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=512"
  },
  {
    "text": "you can see the finer details in his beard. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=514"
  },
  {
    "text": "With bright backlit scenes, it can be challenging to keep faces well exposed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=517"
  },
  {
    "text": "But with the auto exposure system prioritizing faces, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=522"
  },
  {
    "text": "we can easily see him.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=525"
  },
  {
    "text": "Comparing side by side, we can see the difference here again. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=528"
  },
  {
    "text": "Notice that by keeping his face well-exposed in the picture on the right, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=532"
  },
  {
    "text": "the trees in the background appear brighter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=536"
  },
  {
    "text": "And the sky does too. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=537"
  },
  {
    "text": "The exposure of the whole scene is adjusted when prioritizing faces.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=539"
  },
  {
    "text": "In iOS 15.4, there are new properties on AVCaptureDevice to control ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=544"
  },
  {
    "text": "when face-driven auto focus and auto exposure are enabled. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=548"
  },
  {
    "text": "You can control whether the device will “automatically adjust” these settings ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=551"
  },
  {
    "text": "and decide when it should be enabled. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=554"
  },
  {
    "text": "Before toggling the “isEnabled” properties, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=557"
  },
  {
    "text": "you must first disable the automatic adjustment. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=559"
  },
  {
    "text": "The automatic enablement of this behavior is great for photography apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=563"
  },
  {
    "text": "It's used by Apple's Camera app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=566"
  },
  {
    "text": "It's also great for video conferencing apps ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=568"
  },
  {
    "text": "to keep faces visible during calls. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=570"
  },
  {
    "text": "FaceTime takes advantage of this, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=572"
  },
  {
    "text": "but sometimes it's not best suited for an app ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=574"
  },
  {
    "text": "to have the auto focus and auto exposure systems be driven by faces. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=576"
  },
  {
    "text": "For example, if you want your app to give the user ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=580"
  },
  {
    "text": "manual control over the captured image, you might consider turning this off.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=583"
  },
  {
    "text": "If you decide face-driven auto focus or auto exposure is not right ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=588"
  },
  {
    "text": "for your app, you can opt out of this behavior. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=590"
  },
  {
    "text": "First, lock the AVCaptureDevice for configuration. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=593"
  },
  {
    "text": "Then, turn off the automatic adjustment ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=596"
  },
  {
    "text": "of face-driven auto focus or auto exposure. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=599"
  },
  {
    "text": "Next, disable face-driven auto focus or auto exposure. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=602"
  },
  {
    "text": "And lastly, unlock the device for configuration.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=605"
  },
  {
    "text": "I'll talk about how you can use advanced streaming configurations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=610"
  },
  {
    "text": "to receive audio and video data that is tailored for your app's needs. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=613"
  },
  {
    "text": "The AVFoundation Capture API allows ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=618"
  },
  {
    "text": "developers to build immersive apps using the camera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=620"
  },
  {
    "text": "The AVCaptureSession manages data flow from inputs like cameras and microphones ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=623"
  },
  {
    "text": "that are connected to AVCaptureOutputs, that can deliver video, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=627"
  },
  {
    "text": "audio, photos, and more. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=631"
  },
  {
    "text": "Let's take a common camera app use case for example: ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=633"
  },
  {
    "text": "Applying custom effects like filters or overlays to recorded video. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=636"
  },
  {
    "text": "An app like this would have: ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=640"
  },
  {
    "text": "An AVCaptureSession with two inputs, a camera and a mic, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=642"
  },
  {
    "text": "that are connected to two outputs, one for video data and one for audio data. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=646"
  },
  {
    "text": "The video data then has the effects applied, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=651"
  },
  {
    "text": "and the processed video is sent two places, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=654"
  },
  {
    "text": "to the video preview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=656"
  },
  {
    "text": "and an AVAssetWriter for recording. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=657"
  },
  {
    "text": "The audio data is also sent ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=660"
  },
  {
    "text": "to the AVAssetWriter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=661"
  },
  {
    "text": "New in iOS 16 and iPadOS 16, apps can use ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=663"
  },
  {
    "text": "multiple AVCaptureVideoDataOutputs at the same time. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=667"
  },
  {
    "text": "For each video data output, you can customize the resolution, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=670"
  },
  {
    "text": "stabilization, orientation, and pixel format. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=674"
  },
  {
    "text": "Let's go back to the example camera app. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=679"
  },
  {
    "text": "There are competing capture requirements this app is balancing. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=681"
  },
  {
    "text": "The app wants to show a live video preview of the content being captured ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=685"
  },
  {
    "text": "and record high quality video for later playback. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=688"
  },
  {
    "text": "For preview, the resolution needs to be just big enough for the device's screen. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=691"
  },
  {
    "text": "And the processing needs to be fast enough for low-latency preview. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=696"
  },
  {
    "text": "But when recording, its best to capture in high resolution ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=699"
  },
  {
    "text": "with quality effects applied. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=702"
  },
  {
    "text": "With the ability to add a second ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=704"
  },
  {
    "text": "AVCaptureVideoDataOutput, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=706"
  },
  {
    "text": "the capture graph can be extended. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=708"
  },
  {
    "text": "Now the video data outputs ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=710"
  },
  {
    "text": "can be optimized. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=712"
  },
  {
    "text": "One output can deliver smaller buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=714"
  },
  {
    "text": "for preview, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=715"
  },
  {
    "text": "and the other can provide ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=717"
  },
  {
    "text": "full-sized 4K buffers for recording. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=718"
  },
  {
    "text": "Also, the app could render a simpler, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=721"
  },
  {
    "text": "more performant version of the effect ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=724"
  },
  {
    "text": "on smaller preview buffers ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=725"
  },
  {
    "text": "and reserve high quality effects ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=727"
  },
  {
    "text": "for full-size buffers when recording. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=728"
  },
  {
    "text": "Now the app no longer has ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=731"
  },
  {
    "text": "to compromise its preview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=733"
  },
  {
    "text": "or recorded videos.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=734"
  },
  {
    "text": "Another reason to use separate video data outputs for preview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=737"
  },
  {
    "text": "and recording is to apply different stabilization modes. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=740"
  },
  {
    "text": "Video stabilization introduces additional latency ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=744"
  },
  {
    "text": "to the video capture pipeline. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=746"
  },
  {
    "text": "For preview, latency is not desirable, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=748"
  },
  {
    "text": "as the noticeable delay makes it hard to capture content. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=751"
  },
  {
    "text": "For recording, stabilization can be applied ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=754"
  },
  {
    "text": "for a better experience when watching the video later. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=756"
  },
  {
    "text": "So you can have no stabilization applied on one video data output ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=758"
  },
  {
    "text": "for low-latency preview ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=763"
  },
  {
    "text": "and apply stabilization to the other for later playback. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=765"
  },
  {
    "text": "There are many ways to configure the resolution of your video data output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=768"
  },
  {
    "text": "For full-size output, first, disable automatic configuration ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=772"
  },
  {
    "text": "of output buffer dimensions. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=776"
  },
  {
    "text": "Then disable delivery of preview-sized output buffers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=778"
  },
  {
    "text": "In most cases, however, the video data output ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=782"
  },
  {
    "text": "is already configured for full-size output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=784"
  },
  {
    "text": "For preview-sized output, again, disable the automatic configuration, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=788"
  },
  {
    "text": "but instead, enable delivery of preview-sized output buffers. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=792"
  },
  {
    "text": "This is enabled by default when using the photo AVCaptureSessionPreset. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=796"
  },
  {
    "text": "To request a custom resolution, specify the width and height ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=801"
  },
  {
    "text": "in the output's video settings dictionary. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=805"
  },
  {
    "text": "The aspect ratio of the width and height must match the aspect ratio ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=807"
  },
  {
    "text": "of the source device's activeFormat. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=811"
  },
  {
    "text": "There are more ways to configure your video data output. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=812"
  },
  {
    "text": "To apply stabilization, set the preferred stabilization to a mode ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=815"
  },
  {
    "text": "like cinematic extended, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=819"
  },
  {
    "text": "which produces videos that are great to watch. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=820"
  },
  {
    "text": "You can change the orientation to receive buffers that are portrait. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=823"
  },
  {
    "text": "And you can specify the pixel format, to receive 10-bit lossless YUV buffers.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=827"
  },
  {
    "text": "For more information on selecting pixel formats ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=833"
  },
  {
    "text": "for an AVCaptureVideoDataOutput, see Technote 3121.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=835"
  },
  {
    "text": "In addition to using multiple video data outputs, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=841"
  },
  {
    "text": "starting in iOS 16 and iPadOS 16, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=844"
  },
  {
    "text": "apps can record with AVCaptureMovieFileOutput ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=846"
  },
  {
    "text": "while receiving data from AVCaptureVideoDataOutput ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=849"
  },
  {
    "text": "and AVCaptureAudioDataOutput. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=852"
  },
  {
    "text": "To determine what can be added to a session, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=854"
  },
  {
    "text": "you can check whether an output can be added to it ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=857"
  },
  {
    "text": "and query the session's hardwareCost property ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=859"
  },
  {
    "text": "to determine whether the system can support your configuration. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=861"
  },
  {
    "text": "By receiving video data with a movie file output, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=865"
  },
  {
    "text": "you can inspect the video while recording and analyze the scene. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=868"
  },
  {
    "text": "And receiving audio data with a movie file output, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=873"
  },
  {
    "text": "you can sample audio while recording ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=875"
  },
  {
    "text": "and listen to what is being recorded. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=877"
  },
  {
    "text": "With a capture graph like this, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=880"
  },
  {
    "text": "you can offload the mechanics of recording to AVCaptureMovieFileOutput ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=882"
  },
  {
    "text": "while still receiving uncompressed video and audio samples.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=885"
  },
  {
    "text": "Implementing these advanced streaming configurations ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=890"
  },
  {
    "text": "requires use of no new API. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=893"
  },
  {
    "text": "We've enabled this by allowing you to do more with existing API.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=895"
  },
  {
    "text": "And lastly, I'll discuss how your app will ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=901"
  },
  {
    "text": "be able to use the camera while the user is multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=903"
  },
  {
    "text": "On iPad, users can multitask in many ways. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=906"
  },
  {
    "text": "For example, recording Voice Memos while reading Notes in Split View ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=909"
  },
  {
    "text": "or with Slide Over, write in Notes in a floating window ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=914"
  },
  {
    "text": "above Safari in full screen. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=916"
  },
  {
    "text": "With Picture in Picture, you can continue video playback ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=919"
  },
  {
    "text": "while adding reminders to watch more WWDC videos. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=922"
  },
  {
    "text": "And with Stage Manager new to iPadOS 16, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=926"
  },
  {
    "text": "users can open multiple apps in resizable floating windows. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=929"
  },
  {
    "text": "Starting in iOS 16, AVCaptureSessions will be able ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=933"
  },
  {
    "text": "to use the camera while multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=937"
  },
  {
    "text": "We prevented camera access while multitasking before ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=938"
  },
  {
    "text": "because of concerns of the quality of service ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=941"
  },
  {
    "text": "the camera system can deliver while multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=943"
  },
  {
    "text": "Resource-intensive apps like games running alongside an app using the camera ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=946"
  },
  {
    "text": "can induce frame drops and other latency, resulting in a poor camera feed. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=950"
  },
  {
    "text": "A user watching a video months or years later that has poor quality ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=954"
  },
  {
    "text": "may not remember that they recorded it while multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=958"
  },
  {
    "text": "Providing a good camera experience is our priority. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=960"
  },
  {
    "text": "When the system detects video from the camera was recorded ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=965"
  },
  {
    "text": "while multitasking, a dialog will be displayed ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=967"
  },
  {
    "text": "informing the user about the potential for lower quality videos. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=970"
  },
  {
    "text": "This dialog will be presented after recording has finished ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=973"
  },
  {
    "text": "with AVCaptureMovieFileOutput or AVAssetWriter. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=976"
  },
  {
    "text": "It will be shown only once by the system for all apps ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=980"
  },
  {
    "text": "and will have an OK button to dismiss. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=983"
  },
  {
    "text": "There are two new properties added to AVCaptureSession to indicate ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=986"
  },
  {
    "text": "when multitasking camera access is supported and enabled. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=989"
  },
  {
    "text": "Capture sessions that have this enabled will no longer be interrupted ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=993"
  },
  {
    "text": "with the reason “video device not available with multiple foreground apps.” ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=996"
  },
  {
    "text": "Some apps may wish to require a full screen experience ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1001"
  },
  {
    "text": "to use the camera. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1003"
  },
  {
    "text": "This may be useful if you wish for your app to not compete ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1005"
  },
  {
    "text": "with other foreground apps for system resources. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1007"
  },
  {
    "text": "For example, ARKit does not support using the camera while multitasking.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1010"
  },
  {
    "text": "You should ensure your app performs well when running alongside other apps. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1016"
  },
  {
    "text": "Make your app resilient to increasing system pressure ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1019"
  },
  {
    "text": "by monitoring for its notifications, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1022"
  },
  {
    "text": "and take action to reduce the impact, like lowering the frame rate. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1024"
  },
  {
    "text": "You can reduce your app's footprint on the system ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1028"
  },
  {
    "text": "by requesting lower-resolution, binned, or non-HDR formats. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1030"
  },
  {
    "text": "For more information on best practices of maintaining performance, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1035"
  },
  {
    "text": "read the article “Accessing the Camera While Multitasking”.",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1038"
  },
  {
    "text": "Also, video calling and video conferencing apps can display remote participants ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1043"
  },
  {
    "text": "in a system-provided Picture in Picture window. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1047"
  },
  {
    "text": "Now your app's users can seamlessly continue a video call ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1050"
  },
  {
    "text": "while multitasking on iPad. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1053"
  },
  {
    "text": "AVKit introduced API in iOS 15 for apps to designate a view controller ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1056"
  },
  {
    "text": "for displaying remote call participants in. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1061"
  },
  {
    "text": "The video call view controller allows you to customize ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1063"
  },
  {
    "text": "the content of the window. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1066"
  },
  {
    "text": "To learn more about adoption, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1068"
  },
  {
    "text": "please see the “Adopting Picture in Picture for Video Calls” article. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1070"
  },
  {
    "text": "And this concludes advancements in iOS camera capture. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1075"
  },
  {
    "text": "I showed how you can stream depth from LiDAR Scanners using AVFoundation, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1078"
  },
  {
    "text": "how your app will receive improved face rendering, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1082"
  },
  {
    "text": "Advanced AVCaptureSession streaming configurations tailored for your app, ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1085"
  },
  {
    "text": "and lastly, how your app can use the camera while multitasking. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1088"
  },
  {
    "text": "I hope your WWDC rocks. ",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1092"
  },
  {
    "text": "♪ ♪",
    "link": "https://developer.apple.com/videos/play/wwdc2022-110429/?time=1094"
  }
]