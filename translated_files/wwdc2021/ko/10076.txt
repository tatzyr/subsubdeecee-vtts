10076

♪ 베이스 음악 연주 ♪

♪

마이클 패트릭 존슨: 안녕!

제 이름은 마이클 패트릭 존슨이고, 저는 오브젝트 캡처 팀의 엔지니어입니다.

오늘, 제 동료 Dave McKinnon과 저는 macOS에서 새로운 사진 측량 API를 사용하여 실제 물체를 3D 모델로 바꾸는 방법을 보여줄 것입니다.

ARKit 및 RealityKit 프레임워크를 사용하여 증강 현실 앱을 만드는 데 이미 익숙할 수 있습니다.

Reality Composer와 Reality Converter를 사용하여 AR용 3D 모델을 제작했을 수도 있습니다.

그리고 이제 Object Capture API를 사용하면 실제 물체의 이미지를 상세한 3D 모델로 쉽게 바꿀 수 있습니다.

식탁 앞에 갓 구운 피자가 있다고 가정해 봅시다.

맛있어 보여, 그렇지?

우리가 전경에 있는 피자를 3D 모델로 포착하고 싶다고 가정해 봅시다.

일반적으로, 모양과 질감을 모델링하기 위해 몇 시간 동안 전문 예술가를 고용해야 합니다.

하지만, 잠깐, 네 오븐에서 굽는 데 몇 분밖에 안 걸렸어!

오브젝트 캡처를 사용하면 모든 각도에서 물체의 사진을 찍는 것으로 시작할 수 있습니다.

다음으로, 새로운 Object Capture API를 지원하는 Mac에 이미지를 복사합니다.

"사진 측량"이라고 불리는 컴퓨터 비전 기술을 사용하여, 2D 이미지 스택은 단 몇 분 만에 3D 모델로 바꾼다.

출력 모델에는 기하학적 메쉬와 다양한 재료 지도가 모두 포함되어 있으며, 앱에 바로 드롭하거나 AR 퀵 룩에서 볼 수 있습니다.

이제 이 각 단계를 조금 더 자세히 살펴봅시다.

먼저, 당신은 사방에서 물체의 사진을 찍습니다.

이미지는 iPhone 또는 iPad, DSLR 또는 드론으로 찍을 수 있습니다.

물체 주변의 모든 각도에서 선명한 사진을 찍기만 하면 됩니다.

우리는 세션 후반에 캡처를 위한 모범 사례를 제공할 것이다.

iPhone 또는 iPad에서 캡처하는 경우, 지원되는 장치의 스테레오 깊이 데이터를 사용하여 실제 물체 크기와 중력 벡터를 복구할 수 있으므로 모델이 자동으로 오른쪽으로 생성됩니다.

이미지 폴더를 캡처하면, Object Capture API를 사용하여 단 몇 분 만에 3D 모델로 전환할 수 있는 Mac에 복사해야 합니다.

이 API는 최근 인텔 기반 Mac에서 지원되지만, Apple Neural Engine을 활용하여 컴퓨터 비전 알고리즘의 속도를 높일 수 있기 때문에 모든 최신 Apple Silicon Mac에서 가장 빠르게 실행됩니다.

우리는 또한 당신이 시작하는 데 도움이 되는 샘플 명령줄 앱인 HelloPhotogrammetry를 제공합니다.

또한 이미지 폴더에서 직접 사용하여 코드를 작성하기 전에 직접 모델을 만들 수 있습니다.

마지막으로, Mac에서 바로 USDZ 출력 모델을 미리 볼 수 있습니다.

우리는 당신의 다양한 사용 사례에 최적화된 네 가지 세부 수준의 모델을 제공할 수 있으며, 나중에 더 자세히 논의할 것입니다.

축소, 중간 및 전체 세부 사항은 여기에 표시된 피자와 같이 상자에서 꺼내자마자 사용할 수 있습니다.

Raw는 사용자 지정 워크플로우를 위한 것이다.

중간 세부 수준에서 USDZ 출력을 선택하면 iPhone 또는 iPad에서 바로 AR Quick Look에서 새 모델을 볼 수 있습니다.

그리고 그것이 AR에 최적화된 실물 같은 물체를 얻는 데 필요한 전부입니다!

오 잠깐, 전에 먹었던 피자 기억나?

우리는 깨끗해 와야 해.

이 이미지는 실제로 사진이 아니었지만, 실제로 여러 피자에서 오브젝트 캡처를 사용하여 만들어졌다.

그런 다음 이 모델들은 포스트 프로덕션 도구에서 이 장면에 결합되었고 고급 재료 지도와 함께 레이 트레이서를 사용하여 렌더링되었다.

보시다시피, Object Capture는 iPhone 또는 iPad의 AR 앱에서 영화 준비 제작 자산에 이르기까지 다양한 대상 사용 사례를 지원할 수 있습니다.

이 세션의 나머지 부분에서, 우리는 Object Capture API 사용을 시작하는 방법을 보여주고 최고 품질의 결과를 얻기 위한 모범 사례를 제공할 것입니다.

시작하기 섹션에서, 우리는 Object Capture API에 대한 자세한 내용을 살펴보고 앱을 만들기 위한 필수 코드 개념을 소개할 것입니다.

다음으로 우리는 이미지 캡처, 개체 선택 및 세부 수준 선택에 대한 모범 사례에 대해 논의할 것입니다.

macOS에서 API를 사용하는 필수 단계를 진행하는 것으로 시작합시다.

이 섹션에서는 Object Capture API의 기본 구성 요소와 이를 구성하는 방법을 배우게 됩니다.

AR에서 볼 수 있는 3D 모델로 바꾸고 싶은 이 멋진 새 운동화가 있다고 가정해 봅시다.

여기서 우리는 이 섹션에서 살펴볼 기본 워크플로우의 그래픽 다이어그램을 볼 수 있습니다.

그 과정에는 두 가지 주요 단계가 있습니다: 우리가 물체의 이미지 세트를 가리키는 설정; 그리고 우리가 구성하고 싶은 모델의 생성을 요청하는 프로세스.

먼저, 우리는 두 가지 하위 단계로 구성된 설정 블록에 초점을 맞출 것입니다: 세션을 만든 다음 관련 출력 스트림을 연결합니다.

유효한 세션이 있으면, 모델을 생성하는 데 사용할 수 있습니다.

우리가 가장 먼저 해야 할 일은 PhotogrammetrySession을 만드는 것이다.

세션을 만들기 위해, 우리는 당신이 이미 객체의 이미지 폴더를 가지고 있다고 가정할 것입니다.

우리는 당신이 빨리 시작할 수 있도록 API 문서에 샘플 이미지 캡처 폴더를 제공했습니다.

PhotogrammetrySession은 API의 주요 최상위 클래스이며 주요 제어 지점이다.

세션은 결과 3D 모델을 생성하기 위해 사진 측량 알고리즘이 적용될 고정된 이미지 세트를 위한 컨테이너로 생각할 수 있다.

여기 iPhone 12 Pro Max를 사용하여 찍은 운동화의 123개의 HEIC 이미지가 있습니다.

현재 사용할 이미지 세트를 지정하는 몇 가지 방법이 있습니다.

가장 간단한 것은 이미지 디렉토리의 파일 URL일 뿐이다.

세션은 이것들을 하나씩 수집하고 발생한 문제에 대해 보고할 것이다.

HEIC 이미지에 깊이 데이터가 포함된 경우, 물체의 실제 크기를 복구하는 데 자동으로 사용됩니다.

우리는 대부분의 사람들이 폴더 입력을 선호할 것으로 예상하지만, 우리는 또한 일련의 사용자 지정 샘플을 제공하기 위해 고급 워크플로우를 위한 인터페이스를 제공합니다.

사진 측량 샘플은 이미지와 깊이 지도, 중력 벡터 또는 사용자 지정 세분화 마스크와 같은 다른 선택적 데이터를 포함합니다.

입력 소스에서 세션을 만들면, 모델 재구성을 요청할 것입니다.

세션은 결과 모델과 상태 메시지를 출력 메시지 스트림에 출력할 것이다.

이제 세션이 무엇인지 보았으니, API를 사용하여 세션을 만드는 방법을 봅시다.

여기서 우리는 이미지 폴더에서 세션의 초기 설정을 수행하는 코드를 봅니다.

PhotogrammetrySession은 RealityKit 프레임워크 내에 있다.

먼저, 입력 폴더를 파일 URL로 지정합니다.

여기서, 우리는 이미 로컬 디스크에 운동화의 이미지가 포함된 폴더가 있다고 가정합니다.

마지막으로, 우리는 URL을 입력 소스로 전달하여 세션을 만듭니다.

경로가 존재하지 않거나 읽을 수 없는 경우 이니셜라이저는 오류를 발생시킬 것이다.

선택적으로 고급 구성 매개 변수를 제공할 수 있지만, 여기서는 기본값만 사용할 것입니다.

그게 세션을 만드는 데 필요한 전부야!

이제 세션 객체를 성공적으로 만들었으므로, 메시지가 도착하면 처리할 수 있도록 세션의 출력 스트림을 연결해야 합니다.

메시지 스트림이 연결되면, 우리는 그 스트림에 도착할 모델을 요청하는 방법을 보게 될 것이다.

우리는 출력 스트림을 제공하기 위해 올해 새로운 Swift 기능인 AsyncSequence를 사용합니다.

출력 메시지에는 요청 결과와 진행 상황 업데이트와 같은 상태 메시지가 포함됩니다.

우리가 첫 번째 프로세스 호출을 하면, 메시지는 출력 메시지 스트림에서 흐르기 시작할 것이다.

세션이 살아 있는 동안 출력 메시지 시퀀스는 끝나지 않을 것이다.

세션이 초기화되거나 치명적인 오류가 발생할 때까지 메시지를 계속 생성할 것이다.

이제, 우리가 받게 될 메시지의 유형을 자세히 살펴봅시다.

요청이 이루어진 후, 우리는 각 요청에 대해 완성된 견적서와 함께 주기적인 요청 진행 메시지를 받을 것으로 예상합니다.

Object Capture API를 호출하는 앱을 빌드하는 경우, 이를 사용하여 각 요청에 대한 진행률 표시줄을 실행하여 상태를 표시할 수 있습니다.

요청 처리가 완료되면, 모델이나 경계 상자와 같은 결과 페이로드가 포함된 requestComplete 메시지를 받습니다.

처리 중에 무언가 잘못되었다면, 대신 그 요청에 대해 requestError가 출력될 것이다.

편의를 위해, 대기 중인 모든 요청이 처리를 마쳤을 때 처리 완료 메시지가 출력됩니다.

이제 세션 출력 스트림의 개념을 소개하고 기본 출력 메시지를 보았으므로, 메시지 스트림을 처리하는 몇 가지 예제 코드를 살펴보겠습니다.

일단 우리가 이것을 갖게 되면, 우리는 모델을 요청하는 방법을 볼 것이다.

여기 메시지가 도착할 때 메시지를 처리하는 비동기 작업을 만드는 몇 가지 코드가 있습니다.

그것은 많은 코드처럼 보일지 모르지만, 대부분은 우리가 볼 수 있듯이 단순히 메시지 발송이다.

우리는 "for try await" 루프를 사용하여 session.outputs의 메시지가 도착할 때 비동기적으로 반복합니다.

코드의 대부분은 출력 메시지를 켜는 메시지 디스패처이다.

출력은 다른 메시지 유형과 페이로드를 가진 열거형이다.

각 사례 진술은 다른 메시지를 처리할 것이다.

그들을 통과해 보자.

먼저, 진행 상황 메시지를 받으면, 값을 출력할 것입니다.

각 요청에 대한 진행 상황을 알 수 있습니다.

예를 들어, 요청이 완료되면, 우리는 결과 페이로드가 모델이 저장된 곳의 URL이 있는 모델 파일일 것으로 예상합니다.

우리는 그러한 요청을 하는 방법을 잠시 볼 것이다.

사진 측량 오류로 인해 요청이 실패하면, 대신 오류 메시지를 받게 될 것입니다.

프로세스 호출의 전체 요청 세트가 완료되면, processingComplete 메시지가 생성됩니다.

명령줄 앱의 경우, 여기에서 앱을 종료할 수 있습니다.

마지막으로 로드할 수 없는 폴더의 이미지에 대한 경고와 같이 문서에서 읽을 수 있는 다른 상태 메시지가 있습니다.

그리고 그게 메시지 처리를 위한 거야!

이 메시지 처리 작업은 세션이 살아 있는 한 메시지를 비동기적으로 반복하고 처리할 것이다.

좋아, 우리가 작업 흐름에서 어디에 있는지 보자.

우리는 설정 단계를 완전히 완료했고 세션을 진행할 준비가 되었습니다.

우리는 이제 모델을 처리하기 위한 요청을 할 준비가 되었습니다.

코드에 뛰어들기 전에, 우리가 할 수 있는 다양한 유형의 요청을 자세히 살펴봅시다.

세션에서 받을 수 있는 세 가지 데이터 유형이 있습니다: ModelFile, ModelEntity 및 BoundingBox.

이러한 유형은 요청 열거형에 연관된 사례가 있습니다: modelFile, modelEntity 및 bounds; 각각 다른 매개 변수가 있습니다.

모델 파일 요청은 가장 일반적이며 기본 워크플로우에서 사용할 것입니다.

USDZ 확장자와 세부 수준을 가진 파일 URL을 지정하는 modelFile 요청을 만들기만 하면 됩니다.

대화형 워크플로우에서 사용할 수 있는 선택적 지오메트리 매개 변수가 있지만, 여기서는 사용하지 않을 것입니다.

USDA 또는 OBJ 출력 형식이 필요할 수 있는 더 관련된 후처리 파이프라인의 경우, 세부 수준과 함께 출력 디렉토리 URL을 대신 제공할 수 있습니다.

그런 다음 세션은 텍스처와 재료와 같은 모든 참조 자산과 함께 USDA와 OBJ 파일을 해당 폴더에 쓸 것이다.

GUI 앱은 또한 대화형 미리보기 및 개선을 위해 RealityKit ModelEntity와 BoundingBox를 요청할 수 있습니다.

modelEntity 요청은 또한 세부 수준과 선택적 지오메트리를 취한다.

경계 요청은 객체에 대한 예상 캡처 볼륨 BoundingBox를 반환합니다.

이 상자는 UI에서 조정한 다음 재구성 볼륨을 조정하기 위한 후속 요청의 지오메트리 인수로 전달될 수 있습니다.

우리는 세션 후반에 이것이 어떻게 작동하는지 볼 것이다.

대부분의 요청은 또한 세부 수준을 취한다.

미리보기 수준은 대화형 워크플로우만을 위한 것입니다.

그것은 시각적 품질이 매우 낮지만 가장 빨리 만들어진다.

품질과 크기가 증가하는 순서에 따라 주요 세부 수준은 감소, 중간 및 전체입니다.

이 레벨들은 모두 즉시 사용할 준비가 되어 있다.

또한, Raw 레벨은 전문적인 사용을 위해 제공되며 제대로 사용하려면 포스트 프로덕션 워크플로우가 필요합니다.

우리는 모범 사례 섹션에서 이것들을 더 자세히 논의할 것이다.

좋아, 이제 우리가 어떤 종류의 요청을 할 수 있는지 보았으니, 코드에서 이것을 어떻게 하는지 보자.

우리는 이제 각각 다른 출력 파일 이름과 세부 수준을 가진 한 번의 호출에서 두 개의 모델을 동시에 생성하는 방법을 볼 것이다.

여기서 우리는 세션에서 처리해야 할 첫 번째 전화를 본다.

일련의 요청이 필요하다는 것을 주목하세요.

이것이 우리가 한 번에 두 개의 모델을 요청할 수 있는 방법이다.

우리는 감소된 세부 사항 수준에서 하나의 모델과 미디엄에서 하나의 모델을 요청할 것이며, 각각 다른 USDZ 파일에 저장할 것입니다.

한 번의 호출에서 객체 캡처에 대해 원하는 모든 세부 수준을 동시에 요청하면 엔진이 계산을 공유할 수 있으며 순차적으로 요청하는 것보다 더 빨리 모든 모델을 생성할 수 있습니다.

모든 세부 사항을 한 번에 요청할 수도 있습니다.

출력 위치를 쓸 수 없는 경우와 같이 요청이 유효하지 않은 경우 프로세스가 즉시 오류가 발생할 수 있습니다.

이 호출은 즉시 반환되며 곧 메시지가 출력 스트림에 나타나기 시작할 것입니다.

그리고 그게 기본 워크플로우의 끝이야!

이미지로 세션을 만들고, 출력 스트림을 연결한 다음, 모델을 요청합니다.

각 모델의 처리 시간은 이미지 수와 품질 수준에 따라 달라집니다.

처리가 완료되면, 모델을 사용할 수 있다는 출력 메시지를 받게 될 것입니다.

Mac에서 바로 만든 운동화의 결과 USDZ 파일을 열고 하단을 포함한 모든 각도에서 3D로 결과를 검사할 수 있습니다.

이 세션의 뒷부분에서, 우리는 한 번의 캡처 세션에서 물체의 모든 측면에 대한 커버리지를 달성하는 방법을 보여줄 것이며, 여러 캡처를 함께 결합할 필요가 없습니다.

멋져 보여!

이제 기본 워크플로우를 보았으므로, Object Capture API가 지원하는 고급 대화형 워크플로우에 대한 높은 수준의 개요를 제공할 것입니다.

대화형 워크플로우는 최종 재구성 전에 미리보기 모델에서 몇 가지 조정을 할 수 있도록 설계되어 포스트 프로덕션 모델 편집의 필요성을 없애고 메모리 사용을 최적화할 수 있습니다.

먼저, 이 워크플로우의 양쪽 끝에 있는 설정 단계와 프로세스 단계는 이전과 동일하다는 점에 유의하십시오.

당신은 여전히 세션을 만들고 출력 스트림을 연결할 것입니다.

당신은 또한 이전과 같이 최종 모델을 요청할 것입니다.

그러나, 미리보기 모델의 대화형 편집을 위해 3D UI가 제공되는 중간에 블록을 추가했습니다.

이 과정은 당신이 미리보기에 만족할 때까지 반복됩니다.

그런 다음 이전과 같이 최종 모델 요청을 계속할 수 있습니다.

먼저 미리보기의 세부 수준으로 모델 요청을 지정하여 미리보기 모델을 요청합니다.

미리보기 모델은 시각적 품질이 낮으며 가능한 한 빨리 생성됩니다.

모델 파일을 요청하고 직접 로드하거나 RealityKit ModelEntity를 표시하도록 직접 요청할 수 있습니다.

일반적으로, 경계 요청은 캡처 볼륨을 미리 보고 편집하기 위해 동시에 이루어집니다.

캡처 볼륨을 조정하여 캡처하는 동안 물체를 똑바로 유지하는 데 필요한 받침대와 같은 캡처에서 원치 않는 지오메트리를 제거할 수 있습니다.

또한 루트 변환을 조정하여 모델의 크기를 조정, 변환 및 회전할 수 있습니다.

앞서 본 요청의 지오메트리 속성은 모델이 생성되기 전에 캡처 볼륨과 상대 루트 변환을 제공할 수 있습니다.

이것은 사용할 준비가 된 3D 모델을 출력합니다.

이 과정을 실제로 살펴봅시다.

여기서 우리는 이 대화형 워크플로우를 시연하기 위해 API를 사용하여 만든 대화형 개체 캡처 앱의 예를 볼 수 있습니다.

먼저, 우리는 장식용 바위의 이미지가 포함된 이미지 폴더와 최종 USDZ가 기록될 출력 폴더를 선택합니다.

그런 다음 미리보기 모델과 예상 캡처 볼륨을 요청하기 위해 미리보기를 누르세요.

시간이 좀 지난 후, 우리 바위의 미리보기 모델과 캡처 볼륨이 나타납니다.

하지만 우리가 바닥이 지하에 있는 것처럼 출력에서 바위의 윗부분만 원한다고 가정해 봅시다.

우리는 모델의 바닥을 재구성하는 것을 피하기 위해 경계 상자를 조정할 수 있다.

일단 우리가 행복하면, 우리는 이 수정된 캡처 볼륨으로 제한된 새로운 미리보기를 생성하기 위해 Refine Model을 눌렀다.

이것은 또한 이 부분에 대한 출력 모델을 최적화한다.

세련된 모델이 준비되면, 새로운 미리보기가 나타납니다.

새 모델의 기하학이 상자 안에 머물기 위해 잘린 것을 볼 수 있습니다.

이것은 물체를 들고 있는 받침대와 같은 캡처에서 원치 않는 항목을 제거하는 데 유용합니다.

잘린 미리보기에 만족하면, 생성 프로세스를 시작하는 전체 세부 최종 렌더링을 선택할 수 있습니다.

얼마 후, 전체 세부 모델이 완성되고 미리보기 모델을 대체합니다.

이제 우리는 멋져 보이는 실제 모델의 전체 세부 사항을 볼 수 있습니다.

이 모델은 출력 디렉토리에 저장되며 추가 후처리 없이 사용할 수 있습니다.

그리고 그것이 새로운 Object Capture API를 시작하는 데 있는 전부입니다.

우리는 이미지 폴더와 같은 입력 소스에서 세션을 만드는 방법을 보았다.

우리는 비동기 출력 스트림을 메시지 발송에 연결하는 방법을 보았다.

그리고 나서 우리는 두 가지 다른 수준의 세부 모델을 동시에 요청하는 방법을 보았다.

마지막으로, 우리는 ObjectCapture용 RealityKit GUI 앱의 예로 대화형 워크플로우를 설명했습니다.

이제 나는 그것을 내 동료 Dave McKinnon에게 넘길 것이다. Dave McKinnon은 Object Capture와 모범 사례를 논의할 것이다.

데이브 맥키넌: 고마워, 마이클.

안녕하세요, 저는 Dave McKinnon이고, Object Capture 팀에서 일하는 엔지니어입니다.

다음 섹션에서는 최고 품질의 결과를 얻을 수 있도록 모범 사례를 다룰 것입니다.

먼저, 우리는 올바른 특성을 가진 물체를 선택하기 위한 팁과 요령을 살펴볼 것입니다.

최상의 결과를 얻기 위해 환경 조건과 카메라를 제어하는 방법에 대한 논의가 이어집니다.

다음으로, 우리는 CaptureSample 앱을 사용하는 방법을 살펴볼 것입니다.

이 앱을 사용하면 깊이 데이터와 중력 정보 외에도 이미지를 캡처하여 물체의 실제 규모와 방향을 복구할 수 있습니다.

우리는 턴테이블 캡처뿐만 아니라 손 모두에서 이 앱의 사용을 보여줍니다.

마지막으로, 우리는 당신의 사용 사례에 적합한 출력 세부 수준을 선택하는 방법과 추가 읽기를 위한 몇 가지 링크를 제공하는 방법에 대해 논의할 것입니다.

스캔을 할 때 가장 먼저 고려해야 할 것은 올바른 특성을 가진 물체를 고르는 것이다.

최상의 결과를 얻으려면, 적절한 질감 디테일이 있는 물체를 선택하세요.

물체에 질감이 없거나 투명한 영역이 포함되어 있다면, 결과 스캔에는 세부 사항이 부족할 수 있습니다.

게다가, 반사율이 높은 영역을 포함하는 물체를 피하세요.

물체가 반사되면, 스캔할 때 조명을 확산시켜 최상의 결과를 얻을 수 있습니다.

캡처 내내 물체를 뒤집을 계획이라면, 모양이 바뀌지 않도록 단단한지 확인하세요.

마지막으로, 미세한 표면 디테일이 포함된 물체를 스캔하려면, 디테일을 복구하기 위해 표면의 클로즈업 사진을 많이 찍는 것 외에도 고해상도 카메라를 사용해야 합니다.

우리는 이제 전형적인 스캔 과정을 시연할 것이다.

첫째, 최상의 결과를 위해, 물체가 명확하게 눈에 띄도록 물체를 깔끔한 배경에 놓으세요.

기본 과정은 물체 주위를 천천히 움직여서 모든 면에서 균일하게 포착하는 것을 포함한다.

물체의 바닥을 재구성하고 싶다면, 뒤집고 이미지를 계속 캡처하세요.

이미지를 찍을 때, 물체를 캡처하는 시야의 부분을 극대화하려고 노력하세요.

이것은 API가 가능한 한 많은 세부 사항을 복구하는 데 도움을 준다.

이를 수행하는 한 가지 방법은 물체의 크기와 방향에 따라 세로 또는 가로 모드를 사용하는 것입니다.

또한, 이미지 사이에 높은 수준의 중첩을 유지하려고 노력하세요.

물체에 따라, 20~200개의 클로즈업 이미지가 좋은 결과를 얻기에 충분할 것이다.

iOS에서 깊이와 중력으로 고품질 사진을 캡처할 수 있도록 CaptureSample 앱을 제공합니다.

이것은 당신의 앱의 출발점으로 사용될 수 있습니다.

그것은 SwiftUI로 작성되었으며 개발자 문서의 일부입니다.

이 앱은 개체 캡처를 위해 고품질 사진을 찍는 방법을 보여줍니다.

수동 및 타임 셔터 모드가 있습니다.

턴테이블과 동기화하도록 앱을 수정할 수도 있습니다.

듀얼 카메라와 함께 iPhone과 iPad를 사용하여 깊이 데이터를 캡처하고 출력 HEIC 파일에 바로 삽입하는 방법을 보여줍니다.

이 앱은 또한 중력 데이터를 저장하는 방법을 보여줍니다.

갤러리를 보고 깊이와 중력이 있는 모든 좋은 품질의 사진이 있는지 빠르게 확인하고 나쁜 사진을 삭제할 수 있습니다.

캡처 폴더는 iCloud 또는 AirDrop을 사용하여 Mac에 쉽게 복사할 수 있는 앱의 문서 폴더에 저장됩니다.

이 섹션에서 논의하는 좋은 캡처를 얻기 위한 모범 사례 지침을 요약한 도움말 화면도 있습니다.

이 정보는 개발자 문서에서도 찾을 수 있습니다.

최상의 결과를 얻으려면 턴테이블 캡처를 권장합니다.

시작하려면, 여기에 있는 것과 같은 설정이 필요합니다.

여기에는 캡처를 위한 iOS 장치가 포함되어 있지만, 디지털 SLR, 물체를 회전시키는 기계식 턴테이블, 조명 텐트 외에도 일부 조명 패널을 사용할 수도 있습니다.

목표는 균일한 조명을 가지고 딱딱한 그림자를 피하는 것이다.

가벼운 텐트는 이것을 달성하는 좋은 방법이다.

이 경우, CaptureSample 앱은 턴테이블의 움직임과 동기화된 타임 셔터 모드를 사용하여 이미지를 캡처합니다.

우리는 또한 물체를 뒤집고 여러 개의 턴테이블 패스를 수행하여 모든 측면에서 물체를 캡처할 수 있습니다.

다음은 macOS의 미리보기에 표시된 턴테이블 캡처의 결과 USDZ 파일입니다.

이제 이미지를 캡처하기 위한 팁과 요령을 다루었으니, 올바른 출력을 선택하는 방법에 대한 마지막 섹션으로 넘어가겠습니다.

스캔에 사용할 수 있는 다양한 출력 세부 설정이 있습니다.

한 번 보자.

여기 세부 수준을 보여주는 표가 있습니다.

지원되는 수준은 왼쪽을 따라 표시됩니다.

Reduced와 Medium은 AR Quick Look에서 3D 콘텐츠를 보는 것과 같은 웹 기반 및 모바일 경험에 사용하기에 최적화되어 있습니다.

그들은 삼각형과 재료 채널이 적고 결과적으로 메모리를 덜 소비한다.

Full과 Raw는 컴퓨터 게임이나 포스트 프로덕션 워크플로우와 같은 고급 인터랙티브 사용을 위한 것입니다.

그것들은 가장 높은 기하학적 디테일을 포함하고 있으며 구운 재료와 굽지 않은 재료 중에서 선택할 수 있는 유연성을 제공합니다.

축소 및 중간 세부 수준은 인터넷이나 모바일 장치에 표시하려는 콘텐츠에 가장 적합합니다.

이 경우, Object Capture는 Raw 결과의 기하학적 및 재료 정보를 AR 앱이나 AR Quick Look을 통해 표시하기에 적합한 수준으로 압축합니다.

감소 및 중간 세부 수준 모두 확산, 정상 및 주변 폐색 PBR 재료 채널을 포함합니다.

단일 스캔을 매우 자세하게 표시하려면, 미디엄은 파일 크기에 대한 품질을 극대화하여 더 많은 기하학적 및 재료 디테일을 제공합니다.

그러나, 같은 장면에서 여러 스캔을 표시하려면, 감소된 세부 설정을 사용해야 합니다.

오브젝트 캡처를 사용하여 모바일 또는 웹 AR 경험을 만드는 방법에 대해 자세히 알고 싶다면, "AR Quick Look, meet Object Capture" 세션을 참조하십시오.

전체 출력 수준으로 내보내는 것은 프로 워크플로우를 위한 훌륭한 선택입니다.

이 경우, 스캔에 사용할 수 있는 최대 세부 사항을 얻을 수 있습니다.

Full은 스캔의 기하학을 최적화하고 확산, 정상, 주변 폐색, 거칠기 및 변위 정보를 포함하는 PBR 재료로 세부 사항을 구울 것입니다.

우리는 이 출력 수준이 가장 어려운 렌더링에 필요한 모든 것을 제공할 것이라고 생각합니다.

마지막으로, 재료 베이킹이 필요하지 않거나 이를 위한 자체 파이프라인이 있는 경우, Raw 레벨은 추가 처리를 위해 최대 확산 텍스처 디테일과 함께 최대 폴리 카운트를 반환합니다.

macOS에서 프로 워크플로우에 Object Capture를 사용하는 방법에 대해 자세히 알고 싶다면, "Create 3D Workflows with USD" 세션을 참조하십시오.

마지막으로, 그리고 가장 중요한 것은, iOS와 macOS 모두에서 스캔을 사용할 계획이라면, 현재와 미래의 사용 사례에 적합한 모든 출력이 있는지 확인하기 위해 여러 세부 수준을 선택할 수 있습니다.

그리고 그건 포장이야.

우리가 배운 것을 요약해 봅시다.

먼저, 우리는 예를 통해 Object Capture API의 주요 개념을 다루었습니다.

개체 캡처 세션을 만들고 이 세션을 사용하여 이미지 컬렉션을 처리하여 3D 모델을 생성하는 방법을 보여주었습니다.

API가 캡처 볼륨과 모델 변환을 조정할 수 있도록 대화형 미리보기 애플리케이션을 지원하는 방법의 예를 보여주었습니다.

다음으로, 우리는 스캔을 위한 모범 사례를 다루었다.

우리는 최상의 결과를 제공하는 환경, 조명 및 카메라 설정뿐만 아니라 어떤 유형의 물체를 사용할지 논의했습니다.

마지막으로, 우리는 당신의 애플리케이션에 대한 올바른 출력 세부 설정을 선택하는 방법에 대해 논의했습니다.

개체 캡처를 자신의 앱으로 가져오는 방법을 배우고 싶다면, iOS 캡처와 macOS CLI 처리 앱을 모두 확인하여 시작하세요.

이러한 앱과 함께 모범 사례를 구현하고 자신의 스캔을 캡처하는 방법을 계획할 때 도움이 될 수 있는 다양한 샘플 데이터가 제공됩니다.

또한, developer.apple.com에서 온라인으로 모범 사례에 대한 자세한 문서와 관련 WWDC 세션을 확인하세요.

남은 유일한 것은 당신이 나가서 자신의 스캔을 위해 오브젝트 캡처를 사용하는 것입니다.

우리는 당신이 어떤 물건을 스캔하고 공유할지 보게 되어 기쁩니다.

♪