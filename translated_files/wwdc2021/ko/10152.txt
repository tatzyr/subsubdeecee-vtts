10152

안녕. 저는 사하르시 오자입니다.

저는 애플의 GPU 소프트웨어 엔지니어링 팀과 함께 있습니다.

오늘 제 동료인 Yuliya Pylypiv와 저는 Metal Performance Shaders Graph의 새로운 기능에 대해 이야기할 것입니다.

시작하자.

MPS는 이미지 처리, 선형 대수학, 레이 트레이싱 및 기계 학습과 같은 다양한 분야를 위한 금속 기반 고성능 GPU 가속 프리미티브 라이브러리입니다.

MPS 팀은 애플의 다양한 플랫폼에서 각 하드웨어에서 최고의 성능을 제공하기 위해 메탈 커널을 최적화합니다.

작년에, 우리는 GPU를 위한 범용 컴퓨팅 그래프인 MPSGraph 프레임워크를 도입했다.

MPS 프레임워크와 마찬가지로 macOS, iOS, iPadOS 및 tvOS에서 지원됩니다.

MPSGraph에 대한 더 많은 소개 세부 사항을 얻으려면 작년 세션을 시청하세요.

안건을 살펴봅시다.

우리는 다루어야 할 것이 많다.

우리는 MPSGraph를 통해 ML 추론과 훈련 가속에 대해 논의할 것이다.

우리는 흥미진진한 새로운 MPSGraph 운영을 소개할 것이다.

우리는 당신이 MPSGraph에서 편집을 제어할 수 있는 새로운 방법을 소개할 것입니다.

그리고 마지막으로, 우리는 MPSGraph의 모든 새로운 제어 흐름 기능을 살펴볼 것이다.

추론과 훈련 가속에 대한 흥미로운 업데이트를 공유할 제 동료 율리야를 소개하고 싶습니다.

고마워, 사하르시.

안녕. 저는 율리야 필리피브입니다.

저는 애플의 GPU 소프트웨어 팀의 일원입니다.

오늘, 저는 GPU에서 훈련과 추론 성능을 향상시키기 위해 우리가 만든 개선 사항을 공유하고 싶습니다.

바로 들어가자.

MPSGraph 프레임워크는 GPU 가속을 위해 Core ML 및 TensorFlow와 같은 더 높은 수준의 기계 학습 프레임워크에 의해 채택되었다.

올해, 우리는 커널 개선과 스티칭 채택의 조합으로 MPSGraph를 더욱 최적화했습니다.

이것은 MPS를 사용하는 기계 학습 프레임워크에 큰 성능 향상으로 이어졌다.

TensorFlow를 위한 새로운 금속 플러그인을 자세히 살펴봅시다.

TensorFlow는 인기 있는 기계 학습 교육 플랫폼이며, GPU는 주요 가속기 장치이다.

올해, 우리는 TensorFlow 2.5에 출시된 TensorFlow PluggableDevice Interface를 사용하여 새로운 금속 플러그인을 개발했습니다.

이것은 MPS와 MPSGraph를 사용하여 금속의 힘을 TensorFlow에 제공합니다.

이를 통해 수정 없이 Mac 플랫폼 GPU에서 모든 기계 학습 모델을 훈련시킬 수 있습니다.

이제, 이것들 중 하나가 작동하는 것을 봅시다.

이 데모를 위해, 나는 Jupyter 환경을 사용할 것이다.

M1 시스템에는 사용 가능한 최신 TensorFlow가 설치되어 있습니다.

우리가 물리적 장치를 나열할 때, 당신은 등록된 CPU 장치만 있다는 것을 알 수 있습니다.

여기서 저는 이미지 분류, 전송 학습 등에 널리 사용되는 인기 있는 기계 학습 모델인 ResNet50을 정의하고 있습니다.

현재 모델은 224 x 224 이미지 크기의 표준 ImageNet 데이터 세트를 사용합니다.

보시다시피, CPU에서 실행되는 첫 번째 시대의 현재 ETA는 약 20분입니다.

이전에 도입한 TensorFlow Metal Plugin을 설치하고 현재 네트워크에 속도를 추가할 수 있는지 알아보겠습니다.

그렇게 하기 위해, 나는 핍 설치 텐서플로우-메탈을 사용할 거야...

우리가 전에 사용했던 것과 같은 ResNet50 모델로 돌아갑니다.

이번에만, 새로운 GPU 장치가 등록된 것을 볼 수 있습니다.

이것은 우리가 Metal Plugin을 사용하는 TensorFlow 플랫폼의 일부로 도입한 GPU 장치입니다.

모든 콜백과 네트워크 정의는 변경되지 않습니다.

우리가 ETA를 비교할 수 있도록 네트워크를 다시 시작합니다.

동일한 네트워크의 GPU 버전이 TensorFlow Metal Plugin을 사용하여 약 4배 더 빠르게 훈련되고 있음을 알 수 있습니다.

이제 다른 네트워크를 자세히 살펴봅시다.

여기서 우리는 CPU와 관련된 주요 기계 학습 교육 벤치마크의 성능을 보여줍니다.

보시다시피, 우리는 모든 벤치마크에서 좋은 속도를 가지고 있으며, M1 맥북 프로에서 최대 8배 더 빨라집니다.

TensorFlow용 새로운 금속 플러그인을 설치하는 것은 쉽습니다.

Pip install tensorflow-macos를 사용하여 기본 TensorFlow를 설치한 후, pip install tensorflow-metal을 사용하여 금속 플러그인을 설치할 수 있습니다.

메탈 플러그인은 공식 파이썬 패키지 저장소인 pypi.org에서 사용할 수 있습니다.

환경 설정 및 설치에 대한 자세한 내용은 Metal Developer Resource를 참조하십시오.

그게 TensorFlow를 위한 거야.

다음으로, Core ML의 추론 가속에 대해 이야기해 봅시다.

코어 ML은 애플의 기계 학습 추론 프레임워크이다.

우리는 또한 MPSGraph로 Core ML에서 상당한 성능 개선을 보았다.

우리는 여기서 M1에서 기계 학습 네트워크의 주요 클래스의 추론 속도를 보여줍니다.

우리는 NLP 애플리케이션에 사용되는 표준 변압기 네트워크인 BERT에서 2배의 속도를 얻는다.

컴퓨터 비전 애플리케이션의 중심인 ResNet50은 이전 릴리스에서 텍스처 경로를 위해 조정되었습니다.

이것은 MPSGraph를 통한 새로운 버퍼 백엔드로 16%의 추가 성능 개선이다.

Core ML과 TensorFlow의 이러한 성능 개선은 Convolution2D와 같은 MPS 프리미티브의 성능 개선으로 인한 것입니다.

여기서, 우리는 각각 훈련과 추론에 사용되는 NHWC와 NCHW 데이터 레이아웃에서 Convolution2D의 속도를 보여줍니다.

그것은 추론과 훈련의 개선을 위한 것이다.

다음으로, Saharsh로 돌아가서 MPSGraph의 새로운 운영에 대해 자세히 알아봅시다.

고마워, 율리야.

이제 우리는 MPSGraph가 지원하는 새로운 작업 세트를 살펴볼 것이다.

우리는 컨벌루션과 감소의 여러 변형에서 컴퓨팅 그래프에 필요할 수 있는 모든 기본 수학 작업에 이르기까지 MPSGraph에 대한 많은 작업을 지원합니다.

올해, 우리는 당신이 MPSGraph로 더 많은 것을 할 수 있도록 특별 작업을 추가했습니다.

우리는 세 가지 새로운 프리미티브를 소개할 것입니다: 제어 종속성, 스텐실 연산자, 그리고 수집 연산자.

먼저, 우리는 통제 의존성을 살펴볼 것이다.

그래프에서 작업을 명시적으로 주문하려면 제어 의존성이 필요하다.

이것을 이해하기 위해, 그래프 연산을 공식적으로 정의해 봅시다.

그래프의 작업은 세 가지 종류의 에지를 통해 서로 연결됩니다: op에 대한 데이터 입력 역할을 하는 입력 텐서, op 자체에 의해 생성되는 출력 텐서, 그리고 마지막으로 제어 종속성이라고 불리는 특별한 종류의 에지.

현재 작업 자체가 그것에 의존하지 않더라도, 그들은 현재 작업 전에 실행해야 한다.

이 API는 또한 MPSGraph에 의해 작업이 최적화되는 것을 방지하는 편리한 방법을 제공합니다.

이것은 배치 정규화와 같은 기계 학습 계층을 구현하는 데 필요하다.

이걸 실제로 보자.

배치 정규화는 네트워크를 더 안정적이고 빠르게 수렴하기 위해 ML 훈련에 사용되는 표준 계층이다.

여기서 우리는 훈련에 사용되는 배치 정규화를 위한 계산 그래프를 볼 수 있다.

첫 번째 단계는 평균과 분산을 계산하는 것이다.

이것들은 차례로 추론에 필요한 실행 평균과 실행 분산을 업데이트하는 데 사용됩니다.

그러나, 훈련 그래프 결과는 이러한 변수를 요구하지 않으므로, MPSGraph는 그것들을 최적화할 수 있다.

우리는 제어 종속성을 사용하여 최종 정규화 연산자 전에 명시적으로 주문함으로써 이것을 해결할 수 있다.

이 API를 어떻게 사용할 수 있는지 보여주는 몇 가지 코드가 있는 간단한 예를 살펴봅시다.

이 그래프는 지수를 보여주고 연산자를 할당한다.

할당 연산자는 그래프의 다른 어떤 것도 사용되지 않는다.

그래서 그것은 최적화될 수 있다.

이것을 해결하는 한 가지 방법은 할당을 targetOperation으로 명시적으로 설정하는 것이다.

그러나, 이것은 개발자가 그래프 전반에 걸쳐 전 세계적으로 종속성을 추적할 것을 요구한다.

대신, 새로운 제어 종속성 API를 사용하면 지수 작업을 할당에 의존하게 할 수 있습니다.

이것은 targetOperation을 가질 필요성을 없애고 그래프가 그것을 최적화하지 않도록 한다.

다음으로, 우리는 이것을 코드로 볼 것이다.

우리는 먼저 지수가 의존하는 연산자를 정의한다.

다음으로, 우리는 지수 연산자를 정의하는 종속 블록을 만듭니다.

마지막으로, 우리는 이 그래프에서 실행 API를 호출합니다.

목표 운영은 전 세계적으로 추적할 필요가 없다는 점에 유의하십시오.

그것은 통제 의존성을 위한 것이다.

이제 스텐실 운영자에 대해 이야기해 봅시다.

스텐실 작업은 이미지 컨벌루션과 같은 슬라이딩 윈도우 연산자의 일반화이다.

이 연산자들은 유한 요소 방법, 기계 학습 및 이미지 처리 응용 프로그램에 필수적이다.

여기서, 우리는 라플라시안 작업을 구현하는 데 일반적으로 사용되는 5점 2D 스텐실을 본다.

여기에 표시된 스텐실 연산자는 이 7점 3D 스텐실 다이어그램과 같이 더 높은 치수에도 적용할 수 있습니다.

운영자를 좀 더 자세히 살펴봅시다.

각 출력 값에 대해, 그림과 같이 입력 텐서의 스텐실 창에 대한 가중 감소를 계산합니다.

운영자는 argmin/argmax를 포함한 다양한 감소 모드와 반사 및 clampToZero를 포함한 다양한 패딩 모드를 지원합니다.

MPSGraph는 최적의 성능을 위해 MPS 커널을 스티칭할 수 있게 해준다.

스티칭 지원을 통해 스텐실 연산자를 사용하면 단일 커널 실행에서 복잡한 수학적 연산을 표현할 수 있습니다.

그러한 예를 한 가지 예로 들어 봅시다.

로컬 응답 정규화는 채널 차원에서 정규화하는 데 사용되는 pytorch op이다.

새로운 스텐실 작업으로 이것을 구현하는 것은 매우 간단합니다.

여기서, 우리는 이 정규화 기술에 대한 그래프를 본다.

우리는 그것이 스텐실 작업 주변의 요소 현명한 작업이라는 것을 알 수 있다.

새로운 작업이 없다면, 여러 파견이 필요할 것이다.

이제, 스텐실 op은 바느질을 지원하기 때문에, 이 전체 그래프는 단일 디스패치로 시작할 수 있습니다.

그래서 그게 스텐실 운영자를 위한 거야.

다음으로, 수집 작업의 개선 사항을 살펴봅시다.

올해, 새로운 수집 작업이 MPSGraph에 추가되었습니다.

이것들은 인접하지 않은 메모리 위치에서 임의의 크기의 슬라이스를 효율적으로 복사할 수 있게 해준다.

개념적으로, 우리는 메모리 덩어리에서 파란색으로 표시된 위치에서 값을 수집하고 있다.

이러한 수집 레이어는 임베딩 조회 및 동적 매트릭스 복사본을 효율적으로 구현할 수 있게 해준다.

GatherND는 수집 작업의 강력한 확장이다.

일반 수집은 선형 인덱싱을 지원하지만, gatherND 작업은 N차원 인덱싱을 가능하게 한다.

이것은 N차원 입력의 어느 곳에서나 데이터를 원활하게 복사할 수 있게 해준다.

이 작업에 대한 입력은 좌표의 벡터이며, 각 좌표는 입력 텐서의 순위까지 될 수 있다.

좌표에 지정되지 않은 치수는 슬라이스 복사본을 생성한다.

우리는 3D 텐서에서 행 슬라이스를 모으는 예를 살펴볼 수 있다.

이 예에서, 인덱스는 행렬과 행 좌표에 해당하는 두 개의 좌표를 지정합니다.

열 인덱스에 대한 세 번째 좌표가 없기 때문에, 이 gatherND는 전체 행을 복사할 것이다.

결과 텐서는 입력 행렬에서 수집된 행의 2D 행렬이다.

GatherND는 거의 모든 형태의 수집 작업을 대표할 수 있으며 훌륭한 성능을 제공합니다.

예를 들어, 수집 작업을 사용하여 임베딩 조회를 어떻게 구현할 수 있는지 봅시다.

임베딩 조회는 제공된 입력 객체 집합에 대한 임베딩 벡터를 찾는 데 사용되는 일반적인 작업입니다.

일반적으로, 이 계층은 어휘의 각 단어를 임베딩 벡터와 연관시키는 임베딩 매트릭스가 생성되는 언어 처리 네트워크에서 사용됩니다.

어휘에 있는 단어의 ID는 수집 작업의 인덱스로 사용될 수 있으며, 임베딩 매트릭스는 우리의 입력 텐서이다.

우리는 수집 레이어를 사용하여 쉽게 할 수 있는 각 단어 ID에 대한 해당 행을 얻고 싶습니다.

우리는 하나의 좌표만 지정하므로, 각 입력 단어에 대해 전체 행이 복사됩니다.

결과 텐서는 행을 따라 각 입력 단어의 삽입 벡터의 2D 행렬이다.

그것이 우리가 올해 도입한 새로운 MPSGraph 운영을 위한 것이다.

이제 컴파일 API에 대해 이야기해 봅시다.

올해, 우리는 새로운 MPSGraphExecutable API를 소개합니다.

이 컴파일 API는 두 가지 방법으로 성능을 향상시킵니다.

첫째, 그것은 개발자에게 그래프를 컴파일할 때를 제어할 수 있게 해준다.

둘째, 지연된 유형 추론을 통해 컴파일 호출 수를 줄일 수 있습니다.

이제 각각을 좀 더 자세히 살펴봅시다.

작년에, 우리는 MPSGraph를 정의하고 실행할 수 있는 정말 편리한 API를 제공했습니다.

후드 아래에서, 평가가 처음 요청되었을 때, MPSGraph는 입력 유형에 대한 컴파일을 호출하고 내부적으로 실행 파일을 만들었습니다.

후속 실행의 경우, MPSGraph는 컴파일 비용이 다시 지불되지 않도록 이 실행 파일을 원활하게 캐시했습니다.

사용자는 이제 편집을 미리 호출할 수 있으므로 편집 타임라인을 선택할 수 있습니다.

컴파일된 실행 파일을 사용하면 MPSGraphExecutable에서 직접 실행을 호출할 수 있습니다.

이것은 그래프가 컴파일될 때 사용자 제어와 컴파일된 실행 파일을 캐시할 수 있는 기능을 제공하여 더 많은 성능을 얻을 수 있습니다.

이걸 코드로 보자.

여기, 우리는 두 개의 텐서를 추가하는 간단한 그래프가 있습니다.

이제 컴파일하기 위해, 우리는 작업과 함께 피드와 대상 텐서의 유형을 제공합니다.

우리가 얻는 것은 컴파일된 그래프와 실행 파일이다.

그리고 평가 방법은 간단하다.

우리는 금속 명령 대기열과 입력 텐서 데이터를 제공합니다.

그래서 그것들은 MPS 그래프를 컴파일하는 기본이다.

다음으로, 지연 유형 추론을 통해 컴파일 호출 수를 줄이는 방법에 대해 이야기해 봅시다.

유형 추론은 MPSGraph가 사용자가 지정하지 않은 텐서 모양을 결정해야 하는 컴파일 패스입니다.

이 그래프에서, 우리는 두 개의 2D 텐서의 행렬 곱셈을 수행하고 있다.

입력 텐서의 모양이 표시됩니다.

그러나, 출력 텐서는 알려지지 않은 모양이다.

유형 추론 패스가 완료되면, 출력 텐서 모양은 입력과 작업 유형에 따라 결정됩니다.

표준 신경망에서, 네트워크에 대한 입력이 항상 같은 크기는 아니다.

자연어 처리를 위해, 문장이나 시퀀스는 길이가 다를 수 있다.

CNN의 경우, 우리는 다른 크기의 이미지가 평가되는 것을 본다.

올해의 컴파일 업그레이드 전에, 모든 새로운 크기의 이미지에 대해, 전체 그래프에 대한 유형 추론을 수행하기 위해 컴파일이 호출될 것이다.

이제 컴파일을 제어할 수 있습니다. 개발자는 유형 추론 패스를 끄고 컴파일을 호출할 수 있습니다.

이것은 각 반복에서 수십 또는 수백 초의 편집 시간을 절약하고 최고의 성능을 얻을 수 있습니다.

MPSGraph 런타임은 인코딩 중에 제 시간에 유형을 추론하고 원활하게 작동하게 합니다.

그것은 편집 시간을 절약하는 것과 가장 최적의 그래프를 얻는 것 사이의 절충이다.

이전에 공유된 코드 예제에서 이것이 어떻게 사용될 수 있는지 봅시다.

그림과 같이 컴파일 설명자를 설정하여 유형 추론 패스를 비활성화할 수 있습니다.

그게 컴파일 API를 위한 거야.

마지막으로, MPSGraph의 새로운 제어 흐름 API에 대해 이야기해 봅시다.

이 API를 사용하면 이전에 그래프에서 평가한 텐서를 기반으로 작업을 동적으로 파견할 수 있습니다.

이것은 배치 정규화와 반복 신경망과 같은 응용 프로그램에서 일반적이다.

새로운 API 없이 MPSGraph로 "while 루프"를 어떻게 구현할 수 있는지 살펴봅시다.

먼저, 우리는 술어들을 계산하는 그래프를 만든다.

다음으로, 술어는 명시적인 메모리 동기화를 통해 CPU에서 평가된다.

술어가 참이면, 이전에 생성된 그래프는 새로운 입력으로 다시 실행됩니다.

그렇지 않으면, 술어자가 거짓이면, 루프가 끝나고 결과를 소비하기 위해 두 번째 MPSGraph가 생성되고 실행됩니다.

새로운 제어 흐름 API를 사용하면 이러한 모든 단계를 단일 MPSGraph 실행의 일부로 시작할 수 있습니다.

이것은 명시적인 메모리 동기화 프리미티브를 도입할 필요가 없기 때문에 구현하는 것이 더 편리합니다.

이제 이것이 어떻게 잠재적으로 더 효율적일 수 있는지 살펴봅시다.

여기서 우리는 새로운 API 없이 제어 흐름 타임라인을 본다.

우리는 CPU에서 첫 번째 커널을 인코딩합니다.

커널이 완료되면, 결과를 읽기 위해 메모리를 동기화해야 합니다.

CPU가 GPU가 실행을 마칠 때까지 기다려야 하기 때문에 이것은 잠재적으로 비효율적이다.

마찬가지로, GPU는 CPU 동기화와 후속 인코딩이 완료될 때까지 기다려야 한다.

이것은 각 반복에서 일어난다.

이제 새로운 MPSGraph API 사용의 이점을 봅시다.

우리는 하나의 CPU 인코딩 호출만 수행해야 합니다.

술어는 GPU 타임라인에서 평가되기 때문에 동기화 오버헤드가 발생하지 않으며, 커널은 거품 없이 시작할 수 있습니다.

이제 새로운 API가 무엇인지 봅시다.

우리는 세 가지 새로운 제어 흐름 API를 추가했습니다: if/else, for 루프, while 루프.

If/else 원시적인 것으로 시작합시다.

우리는 모두 이것에 익숙하다.

조건자를 기반으로, 다른 코드 경로가 실행된다.

"If" 및 "else" 조건에 대한 코드 블록과 함께 부울 조건자가 제공됩니다.

이 술어가 사실이라면, 우리는 그때의 코드 블록을 실행한다.

그렇지 않으면, 거짓이면, 다른 브랜치가 실행된다.

If/else 작업을 하는 것은 신경망에서 매우 유용하다.

한 가지 표준 사용법은 훈련과 추론에서 다른 행동을 하는 배치 정규화 작업에 있다.

isTraining Boolean을 사용하면, 우리는 노멀라이저의 두 변형을 모두 나타내는 단일 그래프를 가질 수 있습니다.

코드에서 if/else 브랜치를 설정하는 방법을 살펴봅시다.

두 개의 입력 스칼라 텐서의 아주 간단한 예를 들어 봅시다.

첫 번째 텐서가 두 번째 텐서보다 작다면, 우리는 연산의 합을 반환한다.

그렇지 않으면, 우리는 차이를 돌려줘.

먼저, 우리는 조건자를 계산하고 그것을 API에 전달한다.

다음으로, 술어가 참일 때, 우리는 그 다음 블록을 계산하고 텐서를 추가합니다.

마지막으로, 술어가 거짓일 때, 우리는 else 블록을 계산하고 텐서를 뺍니다.

다음으로, for 루프를 구현하는 방법을 봅시다.

For 루프 원시 루프는 고정된 횟수의 일련의 작업을 통해 반복된다.

이것은 훈련 중에 다른 길이의 시퀀스를 반복해야 하는 반복적인 신경망에서 일반적이다.

우리는 for 루프의 numberOfIterations를 제공해야 한다.

인덱스는 0으로 초기화되고 각 루프 반복의 numberOfIterations와 비교된다.

numberOfIterations보다 작으면, 우리는 for 루프의 본문을 실행하고 인덱스를 1 증가시킵니다.

인덱스가 numberOfIterations와 같거나 클 때, 우리는 루프를 끝낸다.

이것을 코드로 구현하는 방법을 봅시다.

우리가 정말 간단한 예시를 구현하고 싶다고 가정해 봅시다.

우리는 결과 변수를 일부 입력 값으로 초기화할 것이다.

그런 다음 우리는 네 번 반복하고, 매번 결과에 다른 입력 값을 곱합니다.

먼저, 우리는 두 개의 그래프 텐서를 만든다.

출력 텐서는 input0으로 초기화될 것이다.

각 반복에서, 이 텐서는 input1을 곱할 것이다.

다음으로, 인덱스 0에서 인덱스 3까지 루프를 네 번 실행할 수 있도록 numberOfIterations를 4로 설정합니다.

다음으로, 우리는 for 루프의 본문을 만듭니다.

이것은 단일 반복을 나타내는 폐쇄를 만들어 이루어진다.

각 반복은 현재 반복의 인덱스와 이전 반복의 출력을 전달한다.

그런 다음, 우리는 결과를 업데이트하고 반환하여 다음 반복으로 전달할 것입니다.

마지막으로, 우리는 이 모든 인수를 그래프의 for loop API에 전달합니다.

본문의 iterationArguments는 input0 텐서로 초기화됩니다.

그게 루프를 위한 거야.

이제 while 루프 API를 살펴봅시다.

이 기본은 조건이 충족되는 동안 일련의 작업을 실행한다.

우리는 이 API를 사용하기 위해 두 개의 코드 블록을 제공해야 한다.

첫 번째 블록에서, 조건은 술어로 확인된다.

술어가 참이면, 애프터 블록에서 while 루프의 본문이 실행된다.

이것은 술어의 재계산을 한다.

그런 다음 MPSGraph는 이전 블록의 다음 반복에서 이 조건자를 사용합니다.

평가된 조건이 거짓이면, 루프가 종료됩니다.

API는 또한 본문과 조건 평가 코드 블록을 교환하여 do-while 루프를 구현할 수 있다.

우리가 정말 간단한 예시를 구현하고 싶다고 가정해 봅시다.

우리는 결과 변수를 일부 입력 값으로 초기화할 것이다.

그런 다음 우리는 임계값을 초과할 때까지 루프에서 매번 결과에 승수를 곱할 것이다.

먼저, 우리는 이전 반복의 결과를 사용하여 술어를 평가할 코드 블록을 정의합니다.

그것은 또한 이전 반복의 결과를 returnTensors NSArray에 저장한다.

이 배열은 술어가 참일 때 다음 반복에 대한 입력으로 사용되며 술어가 거짓인 경우 최종 결과로 사용됩니다.

다음으로, 우리는 텐서가 곱한 while 루프의 본문을 정의합니다.

조건은 블록을 읽을 수 있도록 제품이 반환됩니다.

마지막으로, 우리는 그림과 같이 이 모든 인수를 while 루프 API에 전달할 것입니다.

initialInputs 인수는 이전 블록의 첫 번째 반복에 사용됩니다.

루프 동안 그게 다야.

다음으로, 우리는 이것이 실제 응용 프로그램에서 어떻게 사용될 수 있는지 볼 것이다.

이미지 구성은 일반적인 이미지 편집 유틸리티이다.

여기서, 물체는 대상 이미지에 이식된다.

우리는 그림과 같이 소스 이미지와 배경 이미지로 시작합니다.

다음으로, 우리는 소스 이미지에 마스크를 만듭니다.

소스 이미지의 이 마스크를 배경에 직접 놓자.

우리가 소스 이미지의 가장자리를 명확하게 볼 수 있기 때문에, 그것은 좋아 보이지 않는다.

이미지 구성을 통해, 우리는 이 가장자리를 부드럽게 하고 싶다.

라플라시안 에지 필터를 반복 선형 솔버와 페어링하는 것은 이것을 달성하는 일반적인 방법이다.

이제 세부 사항을 살펴봅시다.

여기서, 우리는 MPSGraph로 이미지 구성을 수행하는 데 필요한 파이프라인을 봅니다.

우리는 입력 텐서, 배경 이미지, 소스 이미지 및 개체의 마스크로 시작합니다.

다음으로 우리는 라플라시안 에지 검출기와 결합된 반복 선형 솔버를 사용합니다.

이 작업 세트의 출력은 매끄러운 가장자리를 가진 복합 이미지이다.

라플라시안 엣지 필터를 살펴봅시다.

라플라시안 에지 필터를 구현하는 것은 가중치 세트로 소스 이미지에 대한 창 감소를 포함한다.

스텐실 연산자는 그림과 같이 이것을 구현하는 데 사용된다.

이 연산자를 사용하여, 우리는 소스 객체의 가장자리를 볼 수 있다.

여기서 계산된 가장자리는 선형 솔버에 대한 입력으로 사용될 것이다.

다음으로, 선형 솔버를 살펴봅시다.

우리는 배경 이미지로 시작하여 선형 솔버에 공급합니다.

솔버는 이 이미지를 업데이트하고, 그 결과는 나중에 다시 읽힌다.

우리가 볼 수 있듯이, 이것은 반복적인 과정이다.

반복이 진행됨에 따라, 해결책 이미지는 가장자리에서 완벽한 혼합에 도달할 때까지 향상됩니다.

오류가 사용자 정의 허용 오차 미만일 때 루프가 종료됩니다.

이것은 잠시 루프가 필요하다.

이제 MPSGraph Control Flow API를 사용하여 이를 구현할 수 있습니다.

이제, 데모를 봅시다.

우리는 MPSGraph를 iPad Pro 애플리케이션으로 사용하여 이미지 구성 유틸리티를 구현했습니다.

우리는 상단의 소스 이미지와 아래의 대상 이미지로 시작합니다.

우리는 소스에서 타겟으로 물체를 복제할 것이다.

우리가 가장 먼저 해야 할 일은 우리가 옮기고 싶은 소 주위에 마스크를 그리는 것이다.

이것이 순진한 클론으로 어떻게 보이는지 봅시다.

우리가 거친 가장자리를 볼 수 있기 때문에, 그것은 별로 좋아 보이지 않는다.

이제 우리가 방금 설명한 이미지 구성 기술을 시도해 봅시다.

우리는 배경 이미지에 대한 초기 솔루션을 설정하는 것으로 시작할 것이다.

이것을 약 50번의 반복으로 실행합시다.

분명히, 해결책 이미지는 아직 수렴되지 않았다.

약 50번 더 반복하자.

이것은 가장자리가 부드러워지면서 훨씬 더 자연스러워 보인다.

MPSGraph로 쉽게 프로그래밍할 수 있어 다양한 기술을 쉽게 실험할 수 있다.

배경 이미지 대신 복제된 이미지로 솔버를 초기화하면 더 빠른 수렴을 초래할 수 있습니다.

이 스위치를 전환하여 이 초기화 모드를 활성화할 수 있습니다.

반복 횟수를 다시 50으로 설정하고 순진한 클론으로 재설정하여 이것을 실제로 봅시다.

이제 솔버를 다시 실행해 봅시다.

우리는 50번의 반복 후에 꽤 좋아 보이는 솔루션 이미지를 볼 수 있다.

우리는 이미 소스 객체로 시작하기 때문에, 우리는 또한 가장자리에서 출혈을 덜 관찰한다.

이건 훌륭해.

하지만 우리가 정말로 원하는 것은 오류 허용 오차에 기반한 융합을 자동화하는 것이다.

이것은 우리가 이 스위치를 사용하여 활성화할 동안 루프가 필요할 것이다.

우리는 새로운 MPSGraph API로 이것을 구현했습니다.

이 슬라이더로 오류 허용 오차를 제어할 수 있습니다.

우리는 그림과 같이 그것을 0.1로 설정했다.

이것을 순진한 클론으로 다시 재설정합시다.

이제 우리는 솔버를 시작합니다.

이 while 루프를 통해, 우리는 반복 횟수를 지정할 필요 없이 약 80번의 반복으로 솔루션 이미지로 수렴합니다.

이제 이 배경에 다른 동물들을 복제하여 재미있게 놀자.

이 귀여운 강아지를 먹어보자.

알았어, 추적 끝났어.

나는 그것이 이 이미지의 오른쪽 하단에서 멋지게 보일 것이라고 생각한다.

아마 우리는 다음에 새를 시도해 볼 수 있을 거야.

이것은 배경의 오른쪽 상단에 잘 어울릴 것이다.

이 모든 이미지가 있는 새로운 배경은 꽤 깔끔해 보인다.

그게 데모를 위한 거야.

요약하자면, 우리는 MPSGraph를 채택한 것이 어떻게 CoreML과 TensorFlow의 놀라운 성능 개선으로 이어졌는지 보여주었습니다.

추론은 이제 두 배까지 빠르다.

우리는 광범위한 애플리케이션을 가능하게 할 스텐실 연산자를 포함하여 유용한 새로운 컴퓨팅 프리미티브를 도입했습니다.

우리는 MPSGraph가 제공하는 새로운 편집 유연성을 보여주었다.

이것은 추론 네트워크에서 대기 시간을 줄일 것이다.

그리고 마지막으로, 우리는 MPSGraph의 모든 새로운 제어 흐름 기능을 보여주었다.

이 API는 기계 학습 네트워크 외에도 여러 선형 대수학 애플리케이션을 표현하는 데 핵심이다.

우리는 당신이 이러한 기능을 어떻게 활용할지 보게 되어 기쁩니다.

감사합니다, 그리고 멋진 WWDC 2021을 보내세요.

[쾌활한 음악].