10044

こんにちは、ようこそ。

私の名前はマールで、シャザム製品チームに所属しています。

WWDC21を楽しんでいることを願っています。オーディオ認識をアプリに統合する機能を提供するフレームワークであるShazamKitを紹介します。

今日は、ShazamKitとは何か、それを適用するためのいくつかのユースケースを説明します。

その後、同僚のJamesに渡します。JamesはShazamカタログ認識の仕組みを紹介し、始めるためのヒントを提供します。

ShazamKitとは何かから始めましょう。

2008年にApp Storeで最初のアプリの1つとしてデビューした音声認識アプリ、Shazamにすでに精通しているかもしれません。

13年後、アプリはかなり成長し、Shazamは動詞としても使われています。

その技術はSiriのWhat Song is Thisを強化し、ショートカットとコントロールセンターに統合されています。

そのコア技術は、バックグラウンドでのノイズでも、正確でほぼ瞬間的なオーディオマッチングであるオーディオ認識です。

認識は、オーディオの明確な音響署名を聴き、Shazam独自のコンテンツカタログ内または作成できるカスタムオーディオカタログ内で完全一致を検索することによって達成されます。

しかし、SoundAnalysisとは異なり、Shazamはスピーチ、歌、またはハミングのクラスを検出して分析するオーディオクラシファーではありません。

実際、Shazamは笑いや拍手などの特定の音を音声でまったく識別しません。

Jamesは数分でShazamの認識プロセスを案内し、音の検出と分類について学びたい場合は、SoundAnalysisセッションもチェックしてください。

それまでの間、アプリに認識機能をもたらすフレームワークであるShazamKitについてもっと話しましょう。

ShazamKitは3つのコンポーネントに分かれています。

Shazamカタログ認識、カスタムカタログ認識、図書館管理があります。

Shazamのカタログ認識により、アプリに曲の識別を追加できます。

カスタムカタログ認識を使用すると、これをさらに一歩進め、任意のオーディオに対してデバイス上のマッチングを実行できます。

このセッションでは、主にShazamカタログの認識とライブラリ管理に焦点を当てますが、「アプリのカスタムオーディオエクスペリエンスを作成する」方法を紹介する同僚のAlexと一緒にコーディングしてください。

次に、アプリ全体でShazamKitを活用するための素晴らしい機会をいくつかお見せします。

完璧なセルフィーを見つけることから始めましょう。

彼らは取るのが楽しく、特定の気分や雰囲気を作り出すときにさらに楽しいことができます。

Shazamカタログの認識は、環境で再生されている曲を認識し、曲のタイトルやアーティストなどの曲のメタデータを取得することで役立ちます。

しかし、少し異なる体験や雰囲気を作り出すこともできるので、あなたの自撮りはソファからのリスニングやテーピングを超えています。

ShazamKit APIは、代わりにダウンタウンのクラブでその曲を楽しむことをシミュレートするために使用できるジャンルのようなメタデータも返します。

ShazamKitはまた、音楽以上のものを認識しており、仮想学習の文脈で役立ちます。

リモートスクーリングは、画面上のレッスンに追いついたり、アプリ間をナビゲートするなど、教師と生徒にさまざまな課題を引き起こす可能性があります。

カスタムカタログ認識は、教育アプリの体験をさらにシームレスにする機会を提供します。

レッスンコンテンツのオーディオを一種のリモートコントロールとして使用することで、フレームワークはビデオ会議を介してコンテンツストリームとして学生アプリで同期されたアクティビティをトリガーすることができます。

教師は、レッスンの一部を一時停止または繰り返した後でも、生徒のアプリがフォローしていることを知って、より簡単に休むことができます。

あなたが私と同じくらいホームセンターテレビを楽しんでいるなら、作品が画面上で点滅するのと同じくらい早く家具を検索しようとするという挑戦に感謝するでしょう。

ShazamKitを使用して、インタラクティブなセカンドスクリーンAR体験でショーやビデオを購入できるようにします。

リアルタイムで視聴する場合でも、オンデマンドで視聴する場合でも、自宅の視聴者は視聴中にスタイルを同期的に閲覧、シミュレーション、購入できます。

さあ、実生活でこれを試してみましょう。

あなたとあなたの友人が共有した瞬間のビデオを見て、バックグラウンドで再生されている曲を知りたいと思ったことはありますか？

これは、例えば、私の友人が金曜日の夜を比較するために私に送ったものです。

私に雰囲気をキャッチさせ、周波数を感じ、雰囲気をキャッチさせる人を誰も知らない、あなたと私だけ。

ShazamKitを使用して、私のアプリは認識を開始し、Shazamのカタログでオーディオマッチを見つけました。

どの曲が再生されていたかがわかったので、ライブラリに保存するか、それを使って完璧な週末のプレイリストを始めることができます。

さて、JamesがShazamカタログ認識の仕組みを紹介します。

ありがとう、マール、そしてこんにちは、みんな。

私はShazamチームのエンジニアリングマネージャーのJamesです。

今日は、ShazamKitがマールのビデオの音楽を認識するためにどのように使用されたかを説明します。

それで、マールが曲の識別ボタンを押したときに何が起こったのですか?

ShazamKitは、ビデオ内のオーディオの表現をShazamのサーバーに送信しました。

Shazamの音楽カタログで一致するものが見つかり、曲に関する情報が返され、アプリに表示されました。

Shazamがオーディオにどのようにマッチするかを詳しく見てみましょう。

Shazamはオーディオ自体と一致しないことに注意することが重要です。

むしろ、それは私たちが署名と呼ぶそれの非可逆表現を作成し、それに対して一致します。

このアプローチには2つの利点があります。

第一に、署名は、それが派生したオーディオよりも少なくとも1桁小さいです。

これにより、ネットワーク経由で送信する必要があるデータの量が大幅に削減されます。

第二に、署名は可逆ではありません。つまり、元のオーディオは特定の署名から再構築できません。

これは、お客様のプライバシーを保護するために非常に重要です。

では、署名はどのように聞こえますか?

1つ再生して、曲を特定できるかどうか確認させてください。

その通りです。

ビリー・アイリッシュの「私の未来」です。

自分でシャザミングを試すこともできます。

では、カタログについて話しましょう。

カタログは署名のコレクションです。

もちろん、カタログの署名は、生成されたオーディオを記述する関連するメタデータがなければ、あまり役に立ちません。

メタデータは元のオーディオへの参照であるため、これらを参照署名と呼びます。

Shazamカタログは、世界の音楽の多くを構成する参照署名のコレクションです。

それはクラウド内にあり、Appleによってホストされ、維持されています。

最新のトラックで定期的に更新されます。

Shazamカタログのすべての署名は、曲の完全なオーディオから生成され、その曲のメタデータへの対応する参照があります。

さて、自分のオーディオとマッチしたい場合はどうなりますか?

この場合、カスタムカタログを使用できます。

これらは、音楽だけでなく、任意のオーディオから生成された署名のコレクションであり、独自のカスタムメタデータを追加できます。

クラウドにあるShazamカタログとは対照的に、カスタムカタログのマッチングはアプリ内で行われます。

詳細については、コード付きの「ShazamKitでカスタムオーディオ体験を作成する」をご覧ください。

カタログを検索する場合は、一致させたいオーディオのごく一部を表すクエリ署名が必要です。

このアプリでは、曲を含むオーディオの一部です。

この視覚化では、クエリ署名が曲の完全なオーディオを表す参照署名と比較され、一致するものが見つかりました。

この同じプロセスは、一致する候補者を識別するために、Shazamのカタログのすべての曲で発生します。

したがって、最初の図に戻ると、参照署名と曲情報のコレクションであるShazamカタログと照合するために、ネットワーク経由でクエリ署名を送信したことがわかっています。

マールが識別ボタンを押すと、一致するものが見つかり、曲情報が返されました。

さて、ShazamKitの素晴らしいところは、セッションオブジェクトを通じてこれらすべてを処理することです。

セッションは、オーディオまたは署名のいずれかを入力として取ることができます。

結果は、その代理人を介して伝達されます。

Shazamカタログと照合する前に、開発者ポータルでアプリ識別子のShazamKitアプリサービスを有効にする必要があります。

このステップは、カスタムカタログとの照合には必要ありません。

さて、これがコードでどのように見えるか見てみましょう。

まず、セッションオブジェクトを作成します。

デフォルトの初期化子は、Shazamカタログと一致します。

次に、その代理人を設定して、見つかった可能性のある一致が通知されるようにします。

たとえば、マイクからのオーディオの継続的なストリームと照合している場合は、そのシナリオに最適化されているため、セッションでmatchStreamingBufferメソッドを使用することをお勧めします。

しかし、私たちの場合、私はすでにビデオの完全なオーディオにアクセスできるので、署名ジェネレータを作成し、それにオーディオを渡します。

マッチを実行する準備ができたら、ジェネレータの署名メソッドを呼び出して、渡したオーディオを署名に変換します。

次に、生成された署名をセッションオブジェクトのマッチメソッドに渡します。

私たちのアプリに戻ります。

オーディオから署名を生成し、セッションを使用してShazamのカタログで一致する曲を見つけた後、次のステップは曲情報を表示することです。

先ほど、カタログが署名とメタデータでどのように作られているかを説明しました。

Shazamカタログの場合、このメタデータは、トラックのタイトルやアーティストなどの曲情報、およびアルバムアートなどの他のプロパティです。

ShazamKitでは、この情報を表すオブジェクトはメディアアイテムと呼ばれます。

一致したばかりの署名については、一致したオーディオの所在や、一致したオーディオと元のオーディオの周波数の違いなど、追加情報も返されます。

これはマッチしたメディアアイテムと呼ばれ、メディアアイテムのサブクラスです。

前のコード例では、セッションデリゲートを設定しました。

マッチを実行するときは、成功、ノーマッチ、またはエラーを知らせるためにそれに頼ることができます。

署名が複数のトラックと一致する可能性があります。

これらは、一致したメディアアイテムの配列として表されます。

私たちのアプリコードでは、最初のものを取ります。

これで、返されたプロパティの一部の設定を開始できます。

アルバムアートは、artworkURLプロパティを使用して取得されました。

曲の名前とパフォーマーは、タイトルとアーティストのプロパティから入力されました。

マッチした曲はApple Musicカタログで利用可能で、その詳細が表示されているため、Apple Musicアイデンティティガイドラインに記載されているようにアトリビューションを与える必要があります。

アプリには、メディアアイテムから返されたApple MusicのURLを起動するボタンが追加されました。

アプリで曲を認識したお客様は、これをShazamライブラリに保存したいと思うかもしれません。

Shazamライブラリは、インストールされている場合はShazamアプリから、または音楽認識コントロールセンターモジュールを長押しすることでアクセスでき、デバイス間で同期されます。

これを試してみましょう。

まず、音楽認識コントロールセンターモジュールを長押しします。

それは私がすでにそこにいくつかの曲を持っていることを示しています。

次に、アプリのプラスボタンをタップして、一致した曲をそのリストに追加します。

今、私は図書館を再開し、それが追加されたことを確認します。

素晴らしい、それはそこにあり、私のアプリの名前が試合のソースとして表示されます。

そして、コードはこんな感じです。

SHMediaLibraryは、顧客のShazamライブラリに対応するデフォルトインスタンスを提供します。

これはエンドツーエンドで暗号化されて保存され、2要素認証を有効にしたデバイスでのみ利用可能です。

ライブラリは、Shazamカタログの曲に対応するアイテムのみを受け入れます。

Shazamライブラリに書き込むのに特別な許可は必要ありませんが、顧客に知らせずにコンテンツを保存しないことを強くお勧めします。

ライブラリに保存されたすべての曲は、それらを追加したアプリに帰属します。

マッチが行われた曲の居場所を示すmatchOffsetなど、あなたが探索できるようにしたMediaItemには、さらに多くのプロパティが公開されています。

さらに、新しいMusicKitフレームワークは、曲とその関係を記述する強く型付けされたオブジェクトを提供します。

これをSongsのプロパティとしてSwiftで利用できるようにしました。

詳細については、「Meet MusicKit for Swift」セッションをご覧ください。

だから今、私たちは全体像を持っています。

私たちは、そのプロセスを管理するためのセッションを使用して、Shazamカタログと一致するオーディオ署名を送信しました。

その後、セッションは、デリゲートを介して一致したメディアアイテムの形で曲情報を返しました。

また、アプリのお客様にShazamライブラリに追加するオプションも提供しました。

さて、私はマールに返します。マールはいくつかのベストプラクティスを案内します。

あなたに、マール。

ありがとう、ジェームズ。

ShazamKitとは何か、どのように機能し、どのように適用するかがわかったので、構築を開始する準備が整いました。

ShazamKitで実装を開始する際には、これらのベストプラクティスを検討してください。

まず、例えばマイクからのリアルタイムオーディオと照合する場合は、matchStreamingBufferを使用します。

よりシンプルで、十分な範囲のシグネチャを生成するための多くの基礎となるロジックを処理します。

次に、ユースケースにマイクが必要な場合は、必要な結果が得られたらすぐに録音を中止してください。

そうすれば、不要なリソースを消費したり、顧客が意図するよりも長くマイクを起動したりすることを避けることができます。

最後に、顧客のライブラリに手紙を書く前に、顧客がオプトインするオプションを提供し、最初からこの行動を明確にすることを強くお勧めします。

ShazamKitを知るのを楽しんでいただければ幸いです。

あなたが作った魔法のような体験や機能を見るのが待ちきれません。

私たちが議論したすべての情報とドキュメントへのリンクは、このセッションに添付されているので、あなたは行く準備ができています。

そして、カスタムカタログ認識と一緒にコードを試すことを忘れないでください。

参加してくれてありがとう。WWDC21の残りの部分をお楽しみください。

[音楽]。