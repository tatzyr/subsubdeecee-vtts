10254

♪ベース音楽の演奏♪

♪

Rokhini Prabhu：こんにちは、「Swift Concurrency Behind the Scenes」へようこそ。

私の名前はロキニで、ダーウィンランタイムチームで働いています。

今日、同僚のVarunと私は、Swiftの並行性に関する根本的なニュアンスのいくつかについてお話しできることを非常に楽しみにしています。

これは、Swiftの並行性に関する以前の話し合いのいくつかに基づいて構築された高度な講演です。

非同期/待機、構造化並行性、および俳優の概念に慣れていない場合は、これらの他のトークを最初に見ることをお勧めします。

Swiftの並行性に関する前回の講演では、今年Swiftネイティブで利用可能なさまざまな言語機能と、それらの使用方法について学びました。

この講演では、これらのプリミティブが言語の安全性だけでなく、パフォーマンスと効率性のためにも、なぜそのように設計されているのかを理解するために、より深く掘り下げます。

独自のアプリでSwift並行性を実験して採用する際に、この講演が、Swift並行性について推論する方法と、Grand Central Dispatchなどの既存のスレッドライブラリとどのように連携するかについて、より良いメンタルモデルが提供できることを願っています。

今日はいくつかのことを話し合うつもりです。

まず、Swift並行性の背後にあるスレッドモデルについて話し、Grand Central Dispatchと対比します。

並行性言語機能を活用してSwiftの新しいスレッドプールを構築し、より良いパフォーマンスと効率を達成した方法について説明します。

最後に、このセクションでは、コードをSwift並行性を使用する際に留意すべき考慮事項について説明します。

その後、Varunはアクターを介したSwift並行性での同期について話します。

俳優が内部でどのように機能するか、シリアルディスパッチキューなど、あなたがすでに慣れ親しんでいるかもしれない既存の同期プリミティブとどのように比較するか、そして最後に、俳優とコードを書くときに心に留めておくべきいくつかのことについて話します。

今日はカバーすべきことがたくさんあるので、すぐに飛び込みましょう。

今日のスレッドモデルに関する議論では、Grand Central Dispatchのような今日利用可能な技術で書かれたサンプルアプリを見ることから始めます。

次に、Swift並行性で書き換えると、同じアプリケーションがどのように機能するかを見ていきます。

自分のニュースフィードリーダーアプリを書きたいとします。

私のアプリケーションの高レベルのコンポーネントが何であるかについて話しましょう。

私のアプリには、ユーザーインターフェイスを駆動するメインスレッドがあります。

ユーザーが購読しているニュースフィードを追跡するデータベースと、最後に、フィードから最新のコンテンツを取得するためのネットワークロジックを処理するサブシステムがあります。

グランドセントラルディスパッチキューでこのアプリをどのように構成するかを考えてみましょう。

ユーザーが最新のニュースを見るように頼んだとしましょう。

メインスレッドでは、ユーザーイベントのジェスチャーを処理します。

ここから、データベース操作を処理するシリアルキューにリクエストを非同期にディスパッチします。

この理由は2つあります。

まず、作業を別のキューにディスパッチすることで、潜在的に大量の作業が起こるのを待っている間でも、メインスレッドがユーザーの入力に応答し続けることができるようにします。

第二に、シリアルキューは相互排除を保証するため、データベースへのアクセスは保護されています。

データベースキューでは、ユーザーが購読しているニュースフィードを反復し、それぞれについて、URLSessionにネットワーク要求をスケジュールして、そのフィードの内容をダウンロードします。

ネットワーク要求の結果が入ると、URLSessionコールバックは、同時キューであるデリゲートキューで呼び出されます。

各結果の完了ハンドラでは、これらの各フィードからの最新のリクエストでデータベースを同期的に更新し、将来の使用のためにキャッシュします。

そして最後に、メインスレッドをウェイクアップしてUIを更新します。

これは、そのようなアプリケーションを構造化するための完全に合理的な方法のように思えます。

リクエストの作業中にメインスレッドをブロックしないようにしました。

また、ネットワーク要求を同時に処理することで、プログラムに固有の並列性を利用しました。

ネットワーク要求の結果をどのように処理するかを示すコードスニペットを詳しく見てみましょう。

まず、ニュースフィードからダウンロードを実行するためのURLSessionを作成しました。

ご覧のとおり、このURLSessionのデリゲートキューを同時キューに設定しました。

次に、更新する必要があるすべてのニュースフィードを反復し、それぞれについて、URLSessionでデータタスクをスケジュールします。

デリゲートキューで呼び出されるデータタスクの完了ハンドラでは、ダウンロードの結果をデシリアライズし、記事にフォーマットします。

次に、フィードの結果を更新する前に、データベースキューに対して同期をディスパッチします。

ここでは、かなり簡単なことをするために直線的なコードを書いたことがわかりますが、このコードにはいくつかの隠されたパフォーマンスの落とし穴があります。

これらのパフォーマンスの問題について詳しく理解するには、まず、GCDキューの作業を処理するためにスレッドがどのように取り上げられるかを掘り下げる必要があります。

グランドセントラルディスパッチでは、作業がキューにキューに入れられると、システムはその作業項目にサービスを提供するスレッドを呼び出します。

同時キューは一度に複数の作業項目を処理できるため、すべてのCPUコアを飽和させるまで、システムはいくつかのスレッドを呼び出します。

ただし、ここで最初のCPUコアに見られるように、スレッドがブロックされ、同時キューでより多くの作業がある場合、GCDは残りの作業項目を消耗するためにより多くのスレッドを呼び出します。

この理由は2つあります。

まず、プロセスに別のスレッドを与えることで、各コアがいつでも作業を実行するスレッドを持ち続けることを保証することができます。

これにより、アプリケーションに良好で継続的なレベルの並行性が得られます。

第二に、ブロックされたスレッドは、さらなる進歩を遂げる前に、セマフォのようなリソースを待っている可能性があります。

キューの作業を続けるために持ち込まれた新しいスレッドは、最初のスレッドで待機されているリソースのブロックを解除するのに役立つかもしれません。

GCDのスレッドブアップについてもう少し理解したので、戻って、ニュースアプリからコードのCPU実行を見てみましょう。

Apple Watchのような2コアデバイスでは、GCDは最初に2つのスレッドを表示してフィードの更新結果を処理します。

スレッドがデータベースキューへのアクセスをブロックすると、ネットワークキューの作業を続行するために、より多くのスレッドが作成されます。

CPUは、さまざまなスレッド間の白い垂直線で示されるように、ネットワーク結果を処理する異なるスレッド間でコンテキストを切り替える必要があります。

これは、私たちのニュースアプリケーションでは、非常に多数のスレッドで簡単に終わる可能性があることを意味します。

ユーザーが更新する必要がある100のフィードを持っている場合、ネットワーク要求が完了すると、これらのURLデータタスクのそれぞれが同時キューに完了ブロックを持つことになります。

GCDは、各コールバックがデータベースキューでブロックされると、より多くのスレッドを表示し、アプリケーションに多くのスレッドを持つことになります。

今、あなたは尋ねるかもしれません、私たちのアプリケーションに多くのスレッドを持つことの何がそんなに悪いのですか?

アプリケーションに多くのスレッドがあるということは、システムがCPUコアよりも多くのスレッドで過大コミットされていることを意味します。

6つのCPUコアを搭載したiPhoneを考えてみましょう。

ニュースアプリケーションに処理が必要な100のフィードアップデートがある場合、これはコアの16倍のスレッドでiPhoneを過剰にコミットしたことを意味します。

これは私たちがスレッド爆発と呼ぶ現象です。

以前のWWDCの講演のいくつかは、アプリケーションのデッドロックの可能性など、これに関連するリスクについてさらに詳しく説明しました。

スレッドの爆発には、すぐには明らかではないかもしれないメモリとスケジューリングのオーバーヘッドも付属しているので、これについてさらに調べてみましょう。

ニュースアプリケーションを振り返ってみると、ブロックされた各スレッドは、再び実行されるのを待っている間、貴重なメモリとリソースを保持しています。

ブロックされた各スレッドには、スレッドを追跡するためのスタックと関連するカーネルデータ構造があります。

これらのスレッドのいくつかは、実行されている他のスレッドが必要とするかもしれないロックを保持しているかもしれません。

これは、進歩していないスレッドのために保持する多数のリソースとメモリです。

また、スレッドの爆発の結果として、より大きなスケジューリングオーバーヘッドがあります。

新しいスレッドが起動されると、CPUは新しいスレッドの実行を開始するために古いスレッドから切り替えるために、完全なスレッドコンテキストスイッチを実行する必要があります。

ブロックされたスレッドが再び実行可能になると、スケジューラはすべて前進できるように、CPU上のスレッドをタイムシェアする必要があります。

さて、それが数回起こる場合、スレッドのタイムシェアリングは問題ありません - それは並行性の力です。

しかし、スレッドの爆発がある場合、コアが限られているデバイスで何百ものスレッドをタイムシェアしなければならないと、過剰なコンテキスト切り替えにつながる可能性があります。

これらのスレッドのスケジューリングレイテンシーは、有用な作業の量を上回るため、CPUの実行効率も低下します。

これまで見てきたように、GCDキューでアプリケーションを書くときのスレッド衛生に関するこれらのニュアンスのいくつかを見逃すのは簡単です。その結果、パフォーマンスが低下し、オーバーヘッドが大きくなります。

この経験に基づいて、Swiftは言語への並行性を設計する際に異なるアプローチを取りました。

アプリが制御され、構造化され、安全な並行性を享受できるように、パフォーマンスと効率性を念頭に置いてSwift並行性を構築しました。

Swiftでは、アプリの実行モデルを、多くのスレッドとコンテキストスイッチを持つ次のモデルからこれに変更したいと考えています。

ここでは、2コアシステムで実行されているスレッドが2つしかなく、スレッドコンテキストスイッチがないことがわかります。

ブロックされたスレッドはすべて消え、代わりに作業の再開を追跡するための継続として知られる軽量オブジェクトがあります。

スレッドがSwift並行性の下で作業を実行すると、フルスレッドコンテキストスイッチを実行するのではなく、継続を切り替えます。

これは、代わりに関数呼び出しの費用のみを支払うことを意味します。

したがって、Swiftの並行性に望むランタイムの動作は、CPUコアがあるのと同じくらい多くのスレッドのみを作成し、スレッドがブロックされたときに作業項目間を安価かつ効率的に切り替えることです。

私たちは、あなたが推論しやすく、安全で制御された並行性を提供する直線コードを書くことができることを望んでいます。

私たちが求めているこの動作を達成するために、オペレーティングシステムはスレッドがブロックしないランタイムコントラクトを必要とし、それは言語が私たちにそれを提供できる場合にのみ可能です。

したがって、Swiftの並行性モデルとその周りのセマンティクスは、この目標を念頭に置いて設計されています。

そのために、ランタイムとの契約を維持できるSwiftの2つの言語レベルの機能について掘り下げたいと思います。

1つ目はawaitのセマンティクスから、2つ目はSwiftランタイムでのタスク依存関係の追跡から来ています。

例のニュースアプリケーションの文脈で、これらの言語機能を考えてみましょう。

これは、ニュースフィードの更新の結果を処理する、先ほどのコードスニペットです。

代わりにSwift並行性プリミティブで書かれたとき、このロジックがどのように見えるか見てみましょう。

まず、ヘルパー関数の非同期実装を作成することから始めます。

次に、同時ディスパッチキューでネットワーク要求の結果を処理する代わりに、並行性を管理する代わりにタスクグループを使用しています。

タスクグループでは、更新が必要なフィードごとに子タスクを作成します。

各子タスクは、共有URLSessionを使用してフィードのURLからダウンロードを実行します。

次に、ダウンロードの結果をデシリアライズし、記事にフォーマットし、最後に非同期関数を呼び出してデータベースを更新します。

ここでは、非同期関数を呼び出すときに、awaitキーワードで注釈を付けます。

「Swiftで非同期/待機を満たす」トークから、待機は非同期待機であることを学びました。

つまり、非同期関数の結果を待っている間、現在のスレッドをブロックしません。

代わりに、関数は一時停止され、スレッドは他のタスクを実行するために解放されます。

これはどのように起こりますか?

どうやって糸をあきらめるのですか?

私の同僚のVarunは、これを可能にするために、Swiftランタイムでボンネットの下で何が行われているかに光を当てます。

ヴァルン・ガンジー:ありがとう、ロキニ。

非同期関数の実装方法に飛び込む前に、非非同期関数がどのように機能するかを簡単に復習しましょう。

実行中のプログラムのすべてのスレッドには1つのスタックがあり、関数呼び出しの状態を格納するために使用します。

とりあえず1つのスレッドに集中しましょう。

スレッドが関数呼び出しを実行すると、新しいフレームがスタックにプッシュされます。

この新しく作成されたスタックフレームは、関数によってローカル変数、リターンアドレス、および必要なその他の情報を格納するために使用できます。

関数の実行が終了して戻ると、そのスタックフレームがポップされます。

では、非同期関数を考えてみましょう。

updateDatabase関数からフィードタイプのadd(_:)メソッドを呼び出すスレッドを想定します。

この段階では、最新のスタックフレームはadd(_:)用になります。

スタックフレームは、サスペンションポイント全体で利用可能である必要のないローカル変数を格納します。

Add(_:)の本体には、awaitでマークされた1つのサスペンションポイントがあります。

ローカル変数、idとarticleは、定義後すぐにforループの本体で使用され、その間にサスペンションポイントはありません。

したがって、それらはスタックフレームに格納されます。

さらに、ヒープには2つの非同期フレームがあり、1つはupdateDatabase用、もう1つはadd用です。

非同期フレームは、サスペンションポイント間で利用できるようにする必要がある情報を保存します。

newArticles引数は待機前に定義されていますが、待機後に利用可能である必要があることに注意してください。

これは、追加用の非同期フレームが新しい記事を追跡することを意味します。

スレッドが引き続き実行されると仮定します。

保存関数の実行が開始されると、追加用のスタックフレームは保存用のスタックフレームに置き換えられます。

新しいスタックフレームを追加する代わりに、将来必要とされる変数がすでに非同期フレームのリストに保存されているため、一番上のスタックフレームが置き換えられます。

保存関数はまた、その使用のために非同期フレームを取得します。

記事がデータベースに保存されている間は、スレッドがブロックされるのではなく、いくつかの有用な作業を行うことができれば良いでしょう。

保存関数の実行が中断されているとします。

そして、スレッドはブロックされるのではなく、他の有用な作業を行うために再利用されます。

サスペンションポイント全体で保持されるすべての情報はヒープに保存されるため、後の段階で実行を継続するために使用できます。

この非同期フレームのリストは、継続のランタイム表現です。

しばらくすると、データベース要求が完了し、いくつかのスレッドが解放されたとします。

これは以前と同じスレッドかもしれないし、別のスレッドかもしれない。

保存関数がこのスレッドで実行を再開するとします。

実行が終了し、いくつかのIDを返すと、保存用のスタックフレームは再び追加用のスタックフレームに置き換えられます。

その後、スレッドはzipの実行を開始できます。

2つの配列を圧縮することは非非同期操作であるため、新しいスタックフレームが作成されます。

Swiftはオペレーティングシステムスタックを使用し続けているため、非同期と非同期の両方のSwiftコードは、CとObjective-Cを効率的に呼び出すことができます。

さらに、CおよびObjective-Cコードは、非非非同期Swiftコードを効率的に呼び出し続けることができます。

Zip機能が終了すると、スタックフレームがポップされ、実行が続行されます。

これまでのところ、他の作業を行うためにスレッドのリソースを解放しながら、効率的なサスペンションと再開を確保するためにawaitがどのように設計されているかを説明しました。

次に、Rokhiniは、タスク間の依存関係のランタイムの追跡である第二言語機能について説明します。

ロヒニ:ありがとう、ヴァルン。

先に説明したように、関数は待機時に継続に分割することができ、潜在的なサスペンションポイントとも呼ばれます。

この場合、URLSessionデータタスクは非同期関数であり、その後の残りの作業は継続です。

継続は、非同期関数が完了した後にのみ実行できます。

これは、Swift並行性ランタイムによって追跡される依存関係です。

同様に、タスクグループ内では、親タスクがいくつかの子タスクを作成することがあり、親タスクが続行する前に、それらの子タスクのそれぞれを完了する必要があります。

これは、タスクグループのスコープによってコードで表現される依存関係であり、したがって、Swiftコンパイラとランタイムに明示的に知られています。

Swiftでは、タスクは、継続タスクや子タスクなど、Swiftランタイムに知られている他のタスクのみを待つことができます。

したがって、Swiftの並行性プリミティブで構造化されたコードは、タスク間の依存関係チェーンを明確に理解してランタイムを提供します。

これまでのところ、Swiftの言語機能により、待機中にタスクを中断する方法を学びました。

代わりに、実行スレッドはタスクの依存関係について推論し、代わりに別のタスクを拾うことができます。

これは、Swift並行性で書かれたコードが、スレッドが常に前進できるランタイム契約を維持できることを意味します。

このランタイム契約を利用して、Swift並行性の統合OSサポートを構築しました。

これは、デフォルトの実行者としてSwift並行性をバックアップするための新しい共同スレッドプールの形式です。

新しいスレッドプールは、CPUコアがあるのと同じくらい多くのスレッドしか生成しないため、システムをオーバーコミットしないようにします。

ワークアイテムがブロックされたときにより多くのスレッドを生成するGCDの同時キューとは異なり、Swiftスレッドは常に前進することができます。

したがって、デフォルトのランタイムは、生成されるスレッドの数を制御することについて賢明です。

これにより、過度の並行性の既知の落とし穴を避けながら、アプリケーションに必要な並行性を与えることができます。

以前のWWDCでは、グランドセントラルディスパッチとの並行性について、アプリケーションを異なるサブシステムに統合し、サブシステムごとに1つのシリアルディスパッチキューを維持して、アプリケーションの並行性を制御することをお勧めします。

これは、スレッド爆発のリスクを冒すことなく、サブシステム内で1つより大きい並行性を得ることが困難であることを意味しました。

Swiftでは、この言語はランタイムが活用した強力な不変量を与え、デフォルトのランタイムでより制御された並行性を透過的に提供することができます。

Swift並行性のスレッドモデルについてもう少し理解したので、コードにこれらのエキサイティングな新機能を採用する際に留意すべきいくつかの考慮事項を見ていきます。

心に留めておく必要がある最初の考慮事項は、同期コードを非同期コードに変換するときのパフォーマンスに関係しています。

先ほど、Swiftランタイムにおける追加のメモリ割り当てやロジックなど、並行性に関連するコストのいくつかについて話しました。

そのため、コードに並行性を導入するコストが管理コストを上回る場合にのみ、Swift並行性を使用して新しいコードを書くように注意する必要があります。

ここのコードスニペットは、単にユーザーのデフォルトから値を読み取るために子タスクを生成するという追加の並行性から実際には恩恵を受けないかもしれません。

これは、子タスクによって行われる有用な作業が、タスクの作成と管理のコストによって削減されるためです。

したがって、Swift並行性を採用する際にパフォーマンス特性を理解するために、Instrumentsシステムトレースでコードをプロファイリングすることをお勧めします。

2番目に注意すべきことは、待機の周りの原子性の概念です。

Swiftは、待機前にコードを実行したスレッドが、継続を拾うのと同じスレッドであることを保証するものではありません。

実際、awaitは、タスクが自発的にスケジュール解除される可能性があるため、原子性が壊れていることを示すコードの明示的なポイントです。

そのため、待ち時間を越えてロックを保持しないように注意する必要があります。

同様に、スレッド固有のデータは、待機中にも保存されません。

スレッドの局所性を期待するコード内の仮定は、待機の一時停止動作を考慮して再検討する必要があります。

そして最後に、最終的な考慮事項は、Swiftの効率的なスレッドモデルの基礎であるランタイム契約に関係しています。

Swiftでは、この言語により、スレッドが常に前進できるランタイム契約を維持できることを思い出してください。

この契約に基づいて、Swiftのデフォルトの実行者となる協力的なスレッドプールを構築しました。

Swiftの並行性を採用する際には、協力的なスレッドプールが最適に機能できるように、この契約をコードで引き続き維持することが重要です。

コード内の依存関係を明示的かつ既知にする安全なプリミティブを使用することで、この契約を共同スレッドプール内で維持することが可能です。

await、アクター、タスクグループなどのSwift並行性プリミティブを使用すると、これらの依存関係はコンパイル時に認識されます。

したがって、Swiftコンパイラはこれを強制し、ランタイムコントラクトを維持するのに役立ちます。

os_unfair_locksやNSLocksのようなプリミティブも安全ですが、使用する際には注意が必要です。

同期コードでロックを使用することは、タイトでよく知られている重要なセクションの周りのデータ同期に使用する場合、安全です。

これは、ロックを保持しているスレッドが常にロックの解除に向けて前進できるためです。

そのため、プリミティブは競合の下で短期間スレッドをブロックする可能性がありますが、フォワードプログレスのランタイム契約に違反しません。

Swiftの並行性プリミティブとは異なり、ロックの正しい使用を支援するコンパイラのサポートがないため、このプリミティブを正しく使用するのはあなたの責任です。

一方、セマフォや条件変数などのプリミティブは、Swiftの並行性で使用するには安全ではありません。

これは、Swiftランタイムから依存関係情報を隠すが、コードの実行に依存関係を導入するためです。

ランタイムはこの依存関係を認識していないため、正しいスケジューリングの決定を下して解決することはできません。

特に、非構造化タスクを作成し、セマフォまたは安全でないプリミティブを使用してタスク境界を越えて依存関係を遡及的に導入するプリミティブを使用しないでください。

このようなコードパターンは、別のスレッドがブロックを解除できるまで、スレッドがセマフォに対して無期限にブロックできることを意味します。

これは、スレッドのフォワードプログレスのランタイム契約に違反しています。

コードベースでこのような安全でないプリミティブの使用を特定するために、次の環境変数を使用してアプリをテストすることをお勧めします。

これは、変更されたデバッグランタイムの下でアプリを実行し、フォワードプログレスの不変量を強制します。

この環境変数は、ここに示すように、プロジェクトスキームの「引数の実行」ペインでXcodeで設定できます。

この環境変数でアプリを実行する場合、ハングしているように見える協力スレッドプールのスレッドが表示された場合は、安全でないブロッキングプリミティブの使用を示します。

さて、スレッドモデルがSwift並行性のためにどのように設計されたかについて学んだので、この新しい世界で状態を同期するために利用できるプリミティブについてもう少し発見しましょう。

Varun：アクターに関するSwift並行性トークでは、アクターを使用して同時アクセスから可変状態を保護する方法を見てきました。

言い換えれば、アクターはあなたが使用できる強力な新しい同期プリミティブを提供します。

アクターが相互排除を保証することを思い出してください。アクターは一度に最大1つのメソッドコールを実行している可能性があります。

相互排除とは、アクターの状態が同時にアクセスされないことを意味し、データレースを防ぎます。

俳優が他の形態の相互排除とどのように比較されるかを見てみましょう。

シリアルキューに同期して、いくつかの記事でデータベースを更新する以前の例を考えてみましょう。

キューがまだ実行されていない場合は、競合がないと言います。

この場合、呼び出しスレッドは、コンテキストスイッチなしでキューで新しい作業項目を実行するために再利用されます。

代わりに、シリアルキューがすでに実行されている場合、キューは競合中であると言われます。

この状況では、呼び出しスレッドはブロックされます。

このブロッキング動作は、Rokhiniが講演の前半で説明したように、スレッドの爆発を引き起こしたものです。

ロックも同じ動作をします。

ブロッキングに関連する問題のため、一般的にはディスパッチ非同期の使用を好むことをお勧めします。

ディスパッチ非同期の主な利点は、ノンブロッキングであることです。

したがって、競合下でも、スレッドの爆発にはつながりません。

シリアルキューでディスパッチ非同期を使用する欠点は、競合がない場合、ディスパッチは非同期作業を行うために新しいスレッドを要求する必要があり、呼び出しスレッドが何か他のことを続けることです。

したがって、ディスパッチ非同期を頻繁に使用すると、過剰なスレッドウェイクアップやコンテキストスイッチが発生する可能性があります。

これは私たちを俳優に導きます。

スウィフトの俳優は、効率的なスケジューリングのために協力的なスレッドプールを利用して、両方の長所を組み合わせています。

実行されていないアクターでメソッドを呼び出すと、呼び出しスレッドを再利用してメソッド呼び出しを実行できます。

呼び出されたアクターがすでに実行されている場合、呼び出し元のスレッドは実行している関数を一時停止し、他の作業を拾うことができます。

サンプルニュースアプリの文脈で、これら2つのプロパティがどのように機能するかを見てみましょう。

データベースとネットワークサブシステムに焦点を当てましょう。

Swift並行性を使用するようにアプリケーションを更新すると、データベースのシリアルキューはデータベースアクターに置き換えられます。

ネットワーキングの同時キューは、ニュースフィードごとに1つのアクターに置き換えることができます。

簡単にするために、私はここでスポーツフィード、天気フィード、健康フィードの3つのフィードアクターしか示していませんが、実際にはもっとたくさんあるでしょう。

これらの俳優は、協力的なスレッドプールで実行されます。

フィードアクターはデータベースと対話して記事を保存し、他のアクションを実行します。

この相互作用には、あるアクターから別のアクターへの実行切り替えが含まれます。

私たちはこのプロセスを俳優ホッピングと呼んでいます。

俳優ホッピングの仕組みについて話し合いましょう。

スポーツフィードのアクターが協力プールのスレッドで実行され、いくつかの記事をデータベースに保存することを決定したとします。

今のところ、データベースが使用されていないことを考えてみましょう。

これは議論されていないケースです。

スレッドは、スポーツフィードアクターからデータベースアクターに直接ホップできます。

ここで気づくべきことが2つあります。

まず、俳優をホッピングしている間、スレッドはブロックされませんでした。

第二に、ホッピングは別のスレッドを必要としませんでした。ランタイムは、スポーツフィードアクターの作業項目を直接中断し、データベースアクターの新しい作業項目を作成できます。

データベースアクターがしばらく実行されているが、最初の作業項目を完了していないとします。

この瞬間、天気フィードアクターがデータベースにいくつかの記事を保存しようとしていると仮定します。

これにより、データベースアクターの新しい作業項目が作成されます。

俳優は、相互排除を保証することにより、安全を確保します。最大で、特定の時間に1つの作業項目がアクティブになる可能性があります。

すでにアクティブな作業項目D1が1つあるため、新しい作業項目D2は保留されます。

俳優もノンブロッキングです。

このような状況では、ウェザーフィードアクターが中断され、実行していたスレッドが他の作業を行うために解放されます。

しばらくすると、最初のデータベース要求が完了し、データベースアクターのアクティブな作業項目が削除されます。

この時点で、ランタイムはデータベースアクターの保留中の作業項目の実行を開始することを選択できます。

または、フィードアクターの1つを再開することを選択するかもしれません。

または、解放されたスレッドで他の作業を行うこともできます。

非同期作業が多く、特に競合が多い場合、システムはどのような作業がより重要かに基づいてトレードオフを行う必要があります。

理想的には、ユーザーインタラクションを含むような優先度の高い作業は、バックアップの保存などのバックグラウンド作業よりも優先されます。

アクターは、再入の概念により、システムが作業に優先順位を付けることができるように設計されています。

しかし、なぜここで再参入が重要なのかを理解するために、まずGCDが優先順位をどのように処理するかを見てみましょう。

シリアルデータベースキューでオリジナルのニュースアプリケーションを検討してください。

データベースが、UIを更新するために最新のデータを取得するなど、優先度の高い作業を受け取るとします。

また、データベースをiCloudにバックアップするなど、優先順位の低い作業も受け取ります。

これはある時点で行う必要がありますが、必ずしもすぐに行う必要はありません。

コードが実行されると、新しい作業項目が作成され、インターリーブされた順序でデータベースキューに追加されます。

ディスパッチキューは、厳密な先入れ先出し順で受信したアイテムを実行します。

残念ながら、これは、アイテムAが実行した後、次の優先度の高いアイテムにたどり着く前に、5つの低優先度アイテムを実行する必要があることを意味します。

これは優先度反転と呼ばれます。

シリアルキューは、優先度の高い作業に先立つキュー内のすべての作業の優先度を高めることで、優先度の反転を回避します。

実際には、これはキュー内の作業が早く行われることを意味します。

ただし、主な問題は解決しません。つまり、項目Bの実行を開始する前に、項目1から5はまだ完了する必要があるということです。

この問題を解決するには、セマンティックモデルを厳密な先着順から変更する必要があります。

これは私たちを俳優の再参入に導きます。

再入が注文にどのように関連しているかを例で探りましょう。

スレッドで実行されているデータベースアクターを検討してください。

それが中断され、いくつかの作業を待っていて、スポーツフィードアクターがそのスレッドで実行を開始するとします。

しばらくすると、スポーツフィードアクターがデータベースアクターを呼び出して、いくつかの記事を保存するとします。

データベースアクターは未指定であるため、保留中の作業項目が1つあるにもかかわらず、スレッドはデータベースアクターにホップできます。

保存操作を実行するには、データベースアクター用の新しい作業項目が作成されます。

これが俳優の再入を意味します。俳優の新しい作業項目は、1つ以上の古い作業項目が中断されている間、進歩する可能性があります。

俳優はまだ相互排除を維持しています:最大で1つの作業項目を特定の時間に実行することができます。

しばらくすると、アイテムD2は実行を終了します。

D2は、D1の後に作成されたにもかかわらず、D1の前に実行が終了したことに注意してください。

したがって、俳優の再入のサポートは、俳優が厳密に先入れ先出しではない順序でアイテムを実行できることを意味します。

以前の例を再検討しましょうが、シリアルキューの代わりにデータベースアクターを使ってください。

まず、作業項目Aは優先度が高いため実行されます。

それが終わったら、以前と同じ優先順位の反転があります。

俳優は再参入用に設計されているため、ランタイムは優先度の高いアイテムを優先度の低いアイテムよりも先にキューの先頭に移動することを選択できます。

このようにして、優先度の高い作業が最初に実行され、優先度の低い作業が後で実行されます。

これは、優先順位の反転の問題に直接対処し、より効果的なスケジューリングとリソースの利用を可能にします。

協力プールを使用するアクターが相互排除を維持し、仕事の効果的な優先順位付けをサポートするためにどのように設計されているかについて少し話しました。

別の種類の俳優、主役者があり、システム内の既存の概念であるメインスレッドを抽象化するため、その特徴は多少異なります。

俳優を使ったニュースアプリの例を考えてみましょう。

ユーザーインターフェイスを更新するときは、MainActorとの間で電話をかける必要があります。

メインスレッドは協力プールのスレッドから切り離されているため、これにはコンテキストスイッチが必要です。

これのパフォーマンスへの影響をコード例で見てみましょう。

データベースから記事をロードし、各記事のUIを更新するMainActorの機能updateArticlesがある次のコードを検討してください。

ループの各反復には、少なくとも2つのコンテキストスイッチが必要です。1つはメインアクターからデータベースアクターにホップし、もう1つはホップバックします。

このようなループのCPU使用率がどのように見えるか見てみましょう。

各ループ反復には2つのコンテキストスイッチが必要なため、2つのスレッドが短期間で次々に実行される繰り返しパターンがあります。

ループ反復の数が少なく、各反復で実質的な作業が行われている場合、それはおそらく大丈夫です。

ただし、実行がメインアクターを頻繁にオン/オフすると、スイッチングスレッドのオーバーヘッドが加算され始める可能性があります。

アプリケーションがコンテキストの切り替えに大部分の時間を費やす場合は、メインアクターの作業がバッチ処理されるようにコードを再構築する必要があります。

ループをloadArticlesとupdateUIメソッド呼び出しにプッシュし、一度に1つの値ではなく配列を処理することを確認することで、バッチ作業をすることができます。

バッチ処理により、コンテキストスイッチの数が減少します。

協同組合プールでの俳優間のホッピングは速いですが、アプリを書くときは、メイン俳優との間のホップに注意する必要があります。

振り返ってみると、この講演では、ノンブロッキングサスペンションのメカニズムである協調スレッドプールの設計から、アクターの実装方法まで、システムを最も効率的にするためにどのように取り組んできたかを学びました。

各ステップでは、ランタイム契約のいくつかの側面を使用して、アプリケーションのパフォーマンスを向上させています。

これらの信じられないほどの新しい言語機能を使用して、明確で効率的で楽しいSwiftコードを書く方法に興奮しています。

ご覧いただきありがとうございます。素晴らしいWWDCをお過ごしください。

♪