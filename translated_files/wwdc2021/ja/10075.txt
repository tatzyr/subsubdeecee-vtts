10075

♪ベース音楽の演奏♪

♪

コートランド・イドストローム:こんにちは、私の名前はコートランド・イドストロームで、RealityKitチームのエンジニアです。

このビデオでは、RealityKit 2の新しいレンダリング機能の使い方を紹介します。

RealityKitは、ARアプリをシンプルで直感的に構築できるように設計されたフレームワークです。

レンダリングは、非常に現実的で物理ベースのレンダリングを中心としたRealityKitの重要な部分です。

2019年の最初のリリース以来、私たちはあなたのフィードバックに取り組んでおり、RealityKitのメジャーアップデートを出荷しています。

「Dive into Reality Kit 2」セッションでは、RealityKitの進化を取り上げ、ECSシステムへのアップデート、より進化した素材とアニメーション機能、実行時のオーディオとテクスチャリソースの生成など、多くの機能強化を提供しました。

これらの改善を紹介するために、私たちはあなたのリビングルームを水中水族館に変えるアプリを構築しました。

この講演では、アプリに入った新しいレンダリング機能のいくつかを紹介します。

RealityKit 2は、オブジェクトのレンダリング方法の制御と柔軟性を提供し、さらに優れたAR体験を作成できます。

今年は、材料システムに進歩をもたらし、カスタムメタルシェーダーをオーサーディングすることで、独自の材料を追加することができます。

カスタムポストエフェクトを使用すると、RealityKitのポストエフェクトを独自のポストエフェクトで拡張できます。

新しいメッシュAPIは、実行時にメッシュの作成、検査、および変更を可能にします。

RealityKit 2で最も要求された機能から始めましょう。カスタムシェーダーのサポート。

RealityKitのレンダリングは、物理ベースのレンダリングモデルを中心にしています。

内蔵のシェーダーにより、さまざまな照明条件で実際のオブジェクトの隣で自然に見えるモデルを簡単に作成できます。

今年は、これらの物理ベースのシェーダーを構築し、シェーダーを使用してモデルのジオメトリと表面をカスタマイズする機能を公開します。

最初のシェーダーAPIはジオメトリ修飾子です。

ジオメトリ修飾子は、Metal Shading Languageで書かれたプログラムで、GPUでレンダリングされるすべてのフレームでオブジェクトの頂点を変更する機会を提供します。

これには、それらを移動し、色、通常、UVなどの属性をカスタマイズすることが含まれます。

RealityKitの頂点シェーダー内で実行され、アンビエントアニメーション、変形、パーティクルシステム、看板に最適です。

私たちの海藻は、アンビエントアニメーションの素晴らしい例です。

海藻は周りの水の動きでゆっくりと動いている。

詳しく見てみましょう。 

ここでは、私たちのアーティストによって作成された海藻のワイヤーフレームを見ることができます。これは、メッシュを構成する頂点と三角形を示しています。

モーションを作成するために各頂点で実行されるシェーダープログラムを作成します。

単純な周期関数である正弦波を使用して、動きを作成します。

私たちは水流をシミュレートしているので、モデルの規模や向きに関係なく、近くの頂点が同じように振る舞うことを望んでいます。

このため、頂点の世界位置を正弦関数の入力として使用します。

時間の経過とともに移動するように、時間値も含めます。

私たちの最初の正弦波は、上下の動きを作成するためにY次元にあります。

動きの期間を制御するために、空間スケールを追加します。

そして、私たちはその動きの量を振幅で制御することができます。

3つの軸すべてで移動するように、XとZの次元に同じ関数を適用します。

では、モデル全体を見てみましょう。

私たちがまだ説明していないことの1つは、茎の基部に近い頂点には移動の余地がほとんどなく、上部の頂点は移動する自由度が高いことです。

これをシミュレートするために、オブジェクトの原点に対する頂点のy座標を3つの軸すべてのスケーリング係数として使用することができ、最終的な公式が得られます。

シェーダーの計画を立てたので、これらのパラメータを見つける場所を見てみましょう。

ジオメトリパラメータは、いくつかのカテゴリに分類されます。

1つ目はユニフォームで、1つのフレーム内のオブジェクトのすべての頂点に対して同じ値です。

私たちは海藻のための時間が必要です。

テクスチャには、モデルの一部として作成されたすべてのテクスチャと、必要に応じて使用できる追加のカスタムスロットが含まれています。

マテリアル定数には、ティントや不透明度スケールなどのパラメータがあり、オブジェクトで作成されたか、コードで設定されています。

ジオメトリには、現在の頂点のモデル位置や頂点IDなど、いくつかの読み取り専用値が含まれています。

海藻運動には、モデルと世界の両方のポジションが必要です。

ジオメトリには、法線、UV、モデル位置オフセットなどの読み取り/書き込み値もあります。

オフセットを計算したら、ここに保存して頂点を移動します。

メタルシェーダーに飛び込みましょう。

RealityKit.hを含めることから始めます。

次に、可視関数属性を持つ関数を宣言します。

これは、他の関数とは別に使用できるようにコンパイラに指示します。

この関数は、RealityKitのgeometry_parametersである単一のパラメータを取ります。

このオブジェクトを介してすべての値を取得します。

パラメータのジオメトリメンバーを使用して、世界位置とモデル位置の両方を求めます。

次に、頂点と時刻の世界位置に基づいて、位相オフセットを計算します。

次に、この頂点のオフセットを計算するために数式を適用します。

オフセットをジオメトリに保存し、頂点のモデル位置に追加されます。

私たちはジオメトリ修飾子を持っていますが、まだ海藻に接続されていません。

Swiftで書かれたARViewサブクラスに切り替えましょう。

シェーダーを含むアプリのデフォルトのMetalライブラリをロードすることから始めます。

次に、シェーダーの名前とライブラリを使用してgeometryModifierを構築します。

海藻の素材ごとに、新しいカスタム素材を作成します。

既存のマテリアルを最初のパラメータとしてCustomMaterialに渡し、ジオメトリ修飾子を追加しながら、ベースマテリアルからテクスチャとマテリアルプロパティを継承します。

かなり素敵に見えます!私たちは水中にいるので、アニメーションをかなり遅くしてきました。

振幅と位相を微調整することで、同じ効果を草、木、または他の葉に拡張することができます。

ジオメトリを変更する方法を示したので、シェーディングについて話しましょう。

これは水中シーンのタコで、内蔵のシェーダーで見栄えがします。

彼らがそうであるように、私たちのタコは複数のルックスの間で移行します。

2番目の外観は赤みを帯びた色です。

私たちのアーティストは、ルックごとに1つずつ、2つのベースカラーテクスチャを執筆しました。

色の変化に加えて、赤いタコは粗さの値が高く、反射性が低くなります。

そして、私たちのタコをさらに特別なものにするために、私たちはルックスの間に素敵な移行を作りたかった。

ここでは、実際の移行を見ることができます。

魅惑的な。

各ルックは物理的ベースの素材として記述できますが、トランジション自体については、サーフェスシェーダーを書く必要があります。

では、サーフェスシェーダーとは何ですか?

サーフェスシェーダーを使用すると、オブジェクトの外観を定義できます。

オブジェクトの目に見えるピクセルごとにフラグメントシェーダー内で実行されます。

色に加えて、これには法線、鏡面、粗さなどの表面特性が含まれます。

オブジェクトの外観を強化したり、完全に置き換えたりして新しい効果を生み出すシェーダーを書くことができます。

私たちはタコの2つのベースカラーのテクスチャを見てきました。

トランジション効果のために、私たちのアーティストは私たちのために特別なテクスチャをエンコードしました。

このテクスチャは、実際には3つの異なるレイヤーの組み合わせです。

上部にノイズレイヤーがあり、ローカライズされたトランジションパターンを作成します。

頭から始めて触手に向かって移動する全体的な動きを指示する遷移層があります。

そして、目や触手の下側など、色を変えたくない領域のマスク層があります。

これらの3つのレイヤーは、カスタムテクスチャスロットに割り当てるテクスチャの赤、緑、青のチャンネルに組み合わされます。

テクスチャを設定して、サーフェスシェーダーからこれらにアクセスする方法を見てみましょう。

ジオメトリ修飾子と同様に、サーフェスシェーダーはユニフォーム、テクスチャ、およびマテリアル定数にアクセスできます。

時間はタコの移行への入力です。

モデルで作成されたテクスチャをサンプリングし、マテリアル定数を読み取り、アーティストがモデル全体の調整を行うことができます。

位置、法線、UVなどのジオメトリは、ジオメトリ構造に表示されます。

これらは、頂点シェーダーからの補間出力です。

テクスチャ座標としてUV0を使用します。

サーフェスシェーダーはサーフェス構造を書き込みます。

プロパティはデフォルト値で始まり、これらの値を自由に計算できます。

ベースカラーとノーマルを計算します。

次に、4つの表面パラメータ：粗さ、金属、周囲閉塞、鏡面。

私たちの価値観がどこにあるかがわかったので、シェーダーを書き始めましょう。

これを3つのステップで行います。

まず、遷移値を計算します。0は完全に紫色のタコで、1は完全に赤色です。

遷移値を使用して、色と法線を計算し、材料特性を割り当てて微調整します。

始めましょう。

最初のステップ: 移行。

私たちは、surface_parameters引数を取るタコサーフェス関数を構築しています。

テクスチャを使用しているので、サンプラーを宣言します。

右側では、私たちのタコが空の表面シェーダーでどのように見えるかを見ることができます - それは灰色で少し光沢があります。

RealityKitを使用すると、モデルの外観に貢献するもの、または貢献しないものを完全に制御できます。

色を計算するには、最初にやらなければならないことがいくつかあります。

いくつかの便利な変数を保存します。

UV0にアクセスし、テクスチャ座標として使用します。

金属とUSDはテクスチャ座標系が異なるため、USDからロードされたテクスチャに合わせてy座標を反転します。

次に、トランジションテクスチャをサンプリングします - アーティストが作成した3層のテクスチャです。

私たちのアーティストは、マスク値と時間を取る小さな関数を設定し、ブレンドとcolorBlendの0から1の値を返します。

2番目のステップ:色と普通。

以前に計算されたブレンド変数を使用して、タコの色を計算し、遷移を確認できるようになりました。

これを行うには、emissive_colorに保存したベースカラーとセカンダリベースカラーの2つのテクスチャをサンプリングします。

次に、以前に計算したcolorBlendを使用して2つの色をブレンドします。

素材の値であるbase_color_tintを乗算し、表面にベースカラーを設定します。

次に、頭と触手に最も顕著な表面偏差を追加するノーマルマップを適用します。

通常のマップテクスチャをサンプリングし、その値を解凍し、サーフェスオブジェクトに設定します。

材料の特性について。

これはこれまでのタコで、色と普通です。

表面特性がその外観にどのように影響するかを見てみましょう。

下半身に見られる粗さ、下部を暗くする周囲の閉塞、そして鏡面は、私たちに目に素敵な反射と体にいくつかの追加の定義を与えます。

これらをシェーダーに追加しましょう。

モデル上の4つのテクスチャをサンプリングし、プロパティごとに1つずつ。

次に、材料設定でこれらの値をスケーリングします。

さらに、紫から赤に移行するにつれて、粗さも増加しています。

次に、表面に4つの値を設定します。

以前と同様に、シェーダーをモデルに適用する必要があります。

このマテリアルをARViewサブクラスのモデルに割り当てます。

まず、2つの追加のテクスチャをロードし、次にサーフェスシェーダーをロードします。

以前と同様に、今回は表面シェーダーと2つの追加のテクスチャを使用して、オブジェクトの基材から新しい材料を構築しています。

そして、私たちは終わりました。

要約すると、ジオメトリ修飾子を使用した海藻アニメーションと、サーフェスシェーダーでタコの遷移を構築する方法を示しました。

私たちはそれらを別々に実演しましたが、さらに興味深い効果を得るために2つを組み合わせることができます。

別の非常に要求された機能に移り、カスタム後処理効果を追加するためのサポート。

RealityKitには、モーションブラー、カメラノイズ、被写界深度など、カメラにマッチしたポストエフェクトの豊富なセットが付属しています。

これらの効果はすべて、仮想オブジェクトと実際のオブジェクトが同じ環境の一部であるように感じるように設計されています。

これらはARViewでカスタマイズできます。

今年は、独自のフルスクリーンエフェクトを作成する機能も公開します。

これにより、PhotoリアリズムにRealityKitを活用し、新しいエフェクトを追加してアプリの結果を調整できます。

では、投稿プロセスとは何ですか?

ポストプロセスは、オブジェクトがレンダリングされて点灯した後に実行されるシェーダーまたは一連のシェーダーです。

また、RealityKitのポストエフェクトの後にも発生します。

その入力は、色と深度バッファの2つのテクスチャです。

深度バッファはここでグレースケールとして表示されます。カメラに対する各ピクセルの距離値が含まれています。

ポストプロセスは、結果をターゲットカラーテクスチャに書き込みます。

最も単純な投稿効果は、ソース色をターゲット色にコピーします。

私たちはいくつかの方法でこれらを構築することができます。

Appleのプラットフォームには、Core Image、Metal Performance Shaders、SpriteKitなど、ポストエフェクトとうまく統合する多くのテクノロジーが搭載されています。

メタルシェーディング言語で自分で書くこともできます。

コアイメージエフェクトから始めましょう。

Core Imageは、画像処理のためのAppleのフレームワークです。

画像やビデオに適用できる何百もの色処理、様式化、変形効果があります。

サーマルはきちんとした効果です - あなたが水中の魚群探知機のためにオンにするかもしれないものです。

RealityKitとの統合がどれほど簡単か見てみましょう。

私たちのポストエフェクトはすべて同じパターンに従います。

レンダリングコールバックを設定し、デバイスで準備するために応答し、ポストプロセスはすべてのフレームが呼び出されます。

レンダリングコールバックはRealityKitのARViewに存在します。

prepareWithDeviceとpostProcessの両方のコールバックが必要です。

デバイスで準備すると、MTLDeviceで一度呼び出されます。

これは、テクスチャを作成し、コンピューティングまたはレンダリングパイプラインをロードし、デバイスの機能をチェックする良い機会です。

これは、コアイメージのコンテキストを作成する場所です。

postProcessコールバックは各フレームで呼び出されます。

ソースカラーテクスチャを参照して、CIImageを作成します。

次に、サーマルフィルターを作成します。

別のコアイメージフィルターを使用している場合は、ここで他のパラメータを設定します。

次に、出力カラーテクスチャをターゲットにし、コンテキストのコマンドバッファを利用するレンダリング先を作成します。

Core Imageに、画像の向きを維持し、タスクを開始するよう依頼します。

それでおそれ！

Core Imageを使用すると、使用できる何百もの事前構築されたエフェクトのロックを解除しました。

それでは、メタルパフォーマンスシェーダーを使用して新しいエフェクトを構築する方法を見てみましょう。

ブルームについて話しましょう。

ブルームは、現実世界のレンズ効果をシミュレートし、明るく照らされたオブジェクトの周りに輝きを作り出すスクリーンスペーステクニックです。

コアイメージにはブルーム効果が含まれていますが、プロセスのすべてのステップを制御できるように、独自の効果を構築します。

高度に最適化されたコンピューティングとグラフィックスシェーダーのコレクションであるメタルパフォーマンスシェーダーでエフェクトを構築します。

このシェーダーを構築するには、色をソースとしてフィルターのグラフを作成します。

まず、明るい領域を隔離したい。

これを行うには、「ゼロへのしきい値」という操作を使用します。

色を輝度に変換し、特定の輝度レベル以下のすべてのピクセルを0に設定します。

次に、ガウスぼかしを使用して結果をぼかし、隣接する領域に光を広げます。

効率的なぼかしは実装が困難であり、多くの場合、複数の段階を必要とします。

メタルパフォーマンスシェーダーは私たちのためにこれを処理します。

次に、このぼやけたテクスチャを元の色に追加し、明るい領域の周りに輝きを加えます。

このグラフをポストエフェクトとして実装しましょう。

中間のbloomTextureを作成することから始めます。

次に、ThresholdToZero操作を実行し、sourceColorから読み取り、bloomTextureに書き込みます。

次に、gaussianBlurを所定の位置に実行します。

最後に、元の色とこの咲いた色を一緒に追加します。

それでおそれ！

ポストエフェクトを作成する方法をいくつか見てきたので、SpriteKitを使用して出力の上にエフェクトを置く方法について話しましょう。

SpriteKitは、高性能でバッテリー効率の高い2DゲームのためのAppleのフレームワークです。

3Dビューの上にいくつかの効果を追加するのに最適です。

同じprepareWithDeviceとpostProcessコールバックを使用して、ポストエフェクトとして画面にいくつかのバブルを追加します。

以前と同じ2つのステップがあります。

prepareWithDeviceでは、SpriteKitレンダラーを作成し、バブルを含むシーンをロードします。

次に、ポストプロセスコールバックで、ソースカラーをターゲットカラーにコピーし、SpriteKitシーンを更新し、3Dコンテンツの上にレンダリングします。

prepareWithDeviceはかなり簡単です - レンダラーを作成し、ファイルからシーンをロードします。

これをARシーンに描くので、SpriteKitの背景を透明にする必要があります。

postProcessでは、まずソースカラーをtargetColorTextureにブリットします。これはSpriteKitが前でレンダリングする背景になります。

その後、SpriteKitのシーンを新しい時間に進め、泡が上に移動します。

RenderPassDescriptorを設定し、それにレンダリングします。

そして、それだけです!

既存のフレームワークを活用してポストエフェクトを作成する方法を示しましたが、実際にはゼロから作成する必要がある場合があります。

コンピューティングシェーダーを書くことで、フルスクリーンエフェクトを作成することもできます。

水中デモでは、仮想オブジェクトとカメラのパススルーに適用されるフォグ効果が必要でした。

霧は媒体を通る光の散乱をシミュレートします。その強度は距離に比例します。

この効果を生み出すには、各ピクセルがデバイスからどれくらい離れているかを知る必要がありました。

幸いなことに、ARKitとRealityKitはどちらも深度情報へのアクセスを提供します。

LiDAR対応デバイスの場合、ARKitはカメラからメートル単位の距離を含むsceneDepthへのアクセスを提供します。

これらの値は、フルスクリーンよりも低い解像度で非常に正確です。

この深さを直接使用できますが、仮想オブジェクトは含まれていないため、正しく曇りません。

ポストプロセスでは、RealityKitは仮想コンテンツの深さへのアクセスを提供し、シーンの理解が有効になっている場合、現実世界のオブジェクトの近似メッシュを提供します。

メッシュは移動するにつれて徐々に構築されるため、現在スキャンしていない穴がいくつかあります。

これらの穴は、まるで無限に遠く離れているかのように霧を示すだろう。

この不一致を解決するために、これら2つの深度テクスチャからのデータを結合します。

ARKitはテクスチャとして深度値を提供します。

各ピクセルは、サンプリングされた点の距離（メートル単位）です。

センサーはiPhoneまたはiPadの固定方向にあるため、ARKitにセンサーの向きから現在の画面の向きへの変換を構築し、結果を反転させるように依頼します。

仮想コンテンツの深さを読むには、RealityKitがどのように深さをパックするかについて少し情報が必要です。

ARKitのシーンデプスとは異なり、より明るい値がカメラに近いことに気づくでしょう。

値は、Infinite Reverse-Z投影を使用して、0から1の範囲で格納されます。

これは、0が無限に遠くを意味し、1がカメラの飛行機の近くにあることを意味します。

ほぼ平面の深さをサンプリングされた深さで割ることで、この変換を簡単に逆転させることができます。

これを行うためのヘルパー関数を書いてみましょう。

サンプルの深さと投影マトリックスを取る金属関数があります。

仮想コンテンツのないピクセルは正確に0です。

ゼロで割るのを防ぐために、小さなイプシロンにクランプします。

遠近法分割を元に戻すには、最後の列のz値を取り、サンプリングされた深さで割ります。

すごい！

2つの深度値がわかったので、2つの最小値をフォグ関数の入力として使用できます。

私たちの霧には、最大距離、その距離での最大強度、パワーカーブ指数など、いくつかのパラメータがあります。

正確な値は実験的に選ばれました。

彼らは私たちの望ましい霧密度を達成するために私たちの深さの値を形作ります。

今、私たちはピースをまとめる準備が整いました。

ARKitの深度値、RealityKitの線形化された深度値、およびフォグの関数があります。

計算シェーダーを書いてみましょう。

各ピクセルについて、両方の線形深度値をサンプリングから始めます。

次に、チューニングパラメータを使用してフォグ関数を適用し、線形深度を0対1の値に変換します。

次に、fogBlendの値に応じて、ソースカラーとフォグカラーをブレンドし、結果をoutColorに格納します。

要約すると、RealityKitの新しいポストプロセスAPIは、幅広いポストエフェクトを可能にします。

Core Imageでは、何百もの既製のエフェクトのロックを解除しました。

メタルパフォーマンスシェーダーで新しいものを簡単に構築したり、SpriteKitでスクリーンオーバーレイを追加したり、Metalでゼロから自分で書いたりできます。

コアイメージまたはメタルパフォーマンスシェーダーの詳細については、リストされているセッションを参照してください。

レンダリング効果について説明したので、次のトピックであるダイナミックメッシュに移りましょう。

RealityKitでは、メッシュリソースはメッシュデータを保存します。

以前は、この不透明なタイプでは、エンティティにメッシュを割り当てることができました。

今年は、実行時にメッシュを検査し、作成し、更新する機能を提供します。

ダイバーに特殊効果を追加する方法を見てみましょう。

このデモでは、スパイラルがダイバーの周りの輪郭を描くスパイラル効果を見せたい。

また、スパイラルがその動きをアニメーション化するために、時間の経過とともにメッシュをどのように変化させているかを見ることができます。

新しいメッシュAPIを使用してこれを作成する方法を見てみましょう。 

効果は3つのステップに集約されます。

メッシュ検査を使用して、頂点を調べてモデルを測定します。

次に、測定値をガイドとして使用して、スパイラルを構築します。

そして最後に、時間の経過とともにスパイラルを更新することができます。

メッシュ検査から始めます。

メッシュの保存方法を説明するために、ダイバーモデルを見てみましょう。

RealityKitでは、ダイバーのメッシュはメッシュリソースとして表されます。

今年のリリースにより、MeshResourceにはContentsというメンバーが含まれるようになりました。

処理されたすべてのメッシュジオメトリが存在する場所があります。

コンテンツには、インスタンスとモデルのリストが含まれています。

モデルには生の頂点データが含まれていますが、インスタンスはそれらを参照して変換を追加します。

インスタンスを使用すると、データをコピーせずに同じジオメトリを複数回表示できます。

モデルは複数の部品を持つことができます。

部品は、1つの材料を持つジオメトリのグループです。

最後に、各部分には、位置、法線、テクスチャ座標、インデックスなど、関心のある頂点データが含まれています。

まず、コードでこのデータにアクセスする方法を見てみましょう。

MeshResource.Contentsを拡張し、各頂点の位置でクロージャを呼び出します。

私たちはすべてのインスタンスを通過することから始めます。

これらの各インスタンスはモデルにマッピングされます。

インスタンスごとに、エンティティに対する相対的な変換を見つけます。

その後、モデルの各部品に入り、部品の属性にアクセスできます。

この機能のために、私たちはポジションにしか興味がありません。

その後、頂点をエンティティ空間の位置に変換し、コールバックを呼び出すことができます。

頂点を訪問できるので、このデータをどのように使用したいかを見てみましょう。

ダイバーを水平スライスに分割します。

スライスごとに、モデルの境界半径を見つけ、スライスごとにこれを行います。

これを実装するには、numSlices要素でゼロで満たされた配列を作成することから始めます。

次に、y軸に沿ったメッシュの境界を把握して、スライスを作成します。

先ほど作成した関数を使用して、モデル内の各頂点について、どのスライスに入るかを把握し、そのスライスの最大の半径で半径を更新します。

最後に、半径と境界を含むスライスオブジェクトを返します。

メッシュの大きさを知るためにメッシュを分析したので、スパイラルメッシュの作成方法を見てみましょう。

スパイラルは動的に生成されたメッシュです。

このメッシュを作成するには、RealityKitにデータを記述する必要があります。

メッシュ記述子でこれを行います。

メッシュ記述子には、位置、法線、テクスチャ座標、プリミティブ、およびマテリアルインデックスが含まれています。

メッシュ記述子があれば、メッシュリソースを生成できます。

これは、メッシュを最適化するRealityKitのメッシュプロセッサを呼び出します。

重複した頂点をマージし、クワッドとポリゴンを三角測量し、レンダリングのための最も効率的な形式でメッシュを表現します。

この処理の結果、エンティティに割り当てることができるメッシュリソースが得られます。

法線、テクスチャ座標、およびマテリアルはオプションであることに注意してください。

当社のメッシュプロセッサは、自動的に正しい法線を生成し、それらを入力します。

最適化プロセスの一環として、RealityKitはメッシュのトポロジを再生成します。

特定のトポロジが必要な場合は、MeshResource.Contentsを直接使用できます。

メッシュの作成方法がわかったので、スパイラルを作成する方法を見てみましょう。

スパイラルをモデル化するために、セクションを詳しく見てみましょう。

スパイラルはらせんとも呼ばれます。

これを均等に間隔をあけたセグメントで構築します。

らせんの数学的定義と分析されたメッシュの半径を使用して、各点を計算できます。

らせん上の各セグメントにこの関数を使用して、4つの頂点を定義できます。

P0 と P1 はまさに p() が返す値です。

P2とP3を計算するには、与えられた厚さでP0とP1を垂直にオフセットすることができます。

三角形を作っているので、対角線が必要です。

これらの点を使って2つの三角形を作ります。

すべてをまとめる時間です。

当社のgenerateSpiral関数は、ポジションとインデックスを保存する必要があります。

インデックスは、ポジションの値を参照します。

セグメントごとに、4つの位置を計算し、そのインデックスを保存します。i0は、配列に追加されたp0のインデックスです。

次に、2つの三角形の4つの位置と6つのインデックスを配列に追加します。

ジオメトリを取得したら、メッシュの作成は簡単です。

まず、新しいMeshDescriptorを作成します。

次に、位置とプリミティブを割り当てます。

三角形のプリミティブを使用していますが、クワッドやポリゴンを選択することもできます。

これら2つのフィールドが入力されると、MeshResourceを生成するのに十分です。

法線、テクスチャ座標、マテリアル割り当てなど、他の頂点属性を提供することもできます。

メッシュの作成方法を取り上げました。

私たちのスパイラルの例の最後のものは、メッシュの更新です。

メッシュの更新を使用して、スパイラルを取得してダイバーの周りを移動します。

メッシュを更新するには、2つの方法があります。

MeshDescriptors APIを使用して、各フレームに新しいMeshResourceを作成できます。

しかし、これは各フレームのメッシュオプティマイザを通過するため、効率的なルートではありません。

より効率的なルートは、MeshResourceの内容を更新することです。

新しいMeshContentsを生成し、それを使用してメッシュを置き換えることができます。

しかし、注意点が1つあります。

MeshDescriptorを使用してオリジナルのメッシュを作成した場合、RealityKitのメッシュプロセッサはデータを最適化します。

トポロジーも三角形に縮小されます。

その結果、更新を適用する前に、メッシュがどのように影響を受けるかを確認してください。

スパイラルを更新する方法のコードを見てみましょう。

既存のスパイラルの内容を格納することから始めます。

既存のモデルから新しいモデルを作成します。

次に、各部分について、triangleIndicesをインデックスのサブセットに置き換えます。

最後に、新しいコンテンツでは、既存のMeshResourceの置き換えを呼び出すことができます。

そして、それはダイナミックメッシュのためのものです。

動的メッシュに関する重要なことを要約するために、MeshResourceに新しいコンテンツフィールドを導入しました。

このコンテナを使用すると、メッシュの生データを検査および変更できます。

MeshDescriptorを使用して新しいメッシュを作成できます。

この柔軟なルートでは、三角形、クワッド、さらにはポリゴンを使用でき、RealityKitはレンダリング用に最適化されたメッシュを生成します。

最後に、メッシュを更新するために、MeshResourceのコンテンツを更新する機能を提供しました。これは、頻繁な更新に最適です。

最後に、今日はRealityKit 2の新しいレンダリング機能のいくつかを披露しました。

ジオメトリ修飾子を使用すると、頂点を移動および変更できます。

サーフェスシェーダーを使用すると、モデルの表面の外観を定義できます。

ポストエフェクトを使用して最終的なフレームにエフェクトを適用でき、ダイナミックメッシュを使用すると、実行時にメッシュを簡単に作成および変更できます。

今年の機能をもっと見るには、「Dive into RealityKit 2」をお見逃しなく。

また、RealityKitの詳細については、「RealityKitでアプリを構築する」をご覧ください。

私たちは今年のリリースに非常に興奮しており、あなたがそれで構築する経験を見るのが待ちきれません。

ありがとうございます。

♪