10074

♪ ♪

こんにちは。私はアマンダで、同僚のオリヴィエが少し加わります。

この講演では、2021年にRealityKitに追加した機能について説明します。

RealityKitは、2019年に導入された拡張現実オーサリングフレームワークで、現実的なレンダリングに焦点を当て、ARアプリを簡単に作成できます。

ARKitを活用してデバイスのセンサーデータを読み取り、RealityKitを使用すると、3Dコンテンツを現実世界の環境に配置し、そのコンテンツをできるだけリアルに見せることができます。

実際のRealityKit体験の素晴らしい例をいくつか紹介します。

現実世界でスカベンジャーハントに行き、事実上あなたの友人に対してボウリングし、博物館で彫刻になり、いくつかのカラフルなバグを見つけます。

過去数年間、私たちはRealityKitで作成されたいくつかの素晴らしいアプリを見て、このフレームワークをさらに良くするために本当に良いフィードバックを受けました。

そして、私たちはあなたのフィードバックに耳を傾けました。

RealityKit 2は、さらに没入感のあるARアプリやゲームを作るのに役立つ多くの新機能を導入していることを共有できることを嬉しく思います。

このセッションでは、カスタムシェーダーやマテリアル、カスタムシステム、新しいキャラクターコントローラーのコンセプトなど、最も要求された機能など、それらのいくつかを強調します。

だから、シュノーケルマスクを着用して、飛び込みましょう。

中東で育ったとき、私は湾岸でスキューバダイビングを学びました。

私はこれらの超かわいいスチームパンクヘルメットの1つを着用することはできませんでしたが、私はすべてのカラフルな魚のスクーリングを見るのが大好きでした。

私のリビングルームでその水中の雰囲気を再現するのは楽しいかもしれないと思いました。

オリヴィエと私は、このセッションと今週後半の2回目のRealityKitセッションで紹介する多くの機能を使って、このデモを書きました。

私たちは、深霧効果と水苛材を作成するための後処理、海藻を波の中で踊らせるためのカスタムジオメトリ修飾子などを持っています。

基本的に、RealityKit 2では、今では非常に多くのものをカスタマイズできます。

このサンプルコードは、developer.apple.comで試すことができます。

今日取り上げる5つの主要なトピックがあります。

ECSとは何か、新しいカスタムシステム機能を使用して、アプリで魚の群れ行動を実装する方法についてまとめを行います。

素材やアニメーション、新しいキャラクターコントローラーでできることの進歩を紹介します。これは、ダイバーがリビングルームのARメッシュとシームレスに対話できるようにし、実行時にリソースを生成する方法を紹介します。

では、ECSから始めましょう。

ECSは、エンティティコンポーネントシステムの略で、データと動作を構造化する方法であり、ゲームやシミュレーションで一般的に使用されています。

これは、アイテムの機能と、そのアイテムに関連する状態の両方のカプセル化されたバンドルとしてモデル化する傾向があるオブジェクト指向プログラミングとは異なります。

しかし、ECSでは、エンティティ、コンポーネント、システムの3つのプロングがあり、機能はシステムに入り、状態はコンポーネントに入り、エンティティはコンポーネントのグループの識別子です。

今年は、RealityKit 2で、より純粋なECS実装に移行し、新しいカスタムシステムでシステムレイヤーでより多くの機能を維持するように導きます。

エンティティは私たちにとって何を意味しますか?

エンティティは、あなたのシーンで1つのことを表します。

ここに私たちのシーンで海の生き物を表すエンティティがあります。

エンティティは子エンティティを持つことができ、作業するグラフ構造を提供します。

たとえば、変換コンポーネントは、親エンティティの変換を使用して独自の位置を追加します。

エンティティ自体は画面上に何もレンダリングしません。

そのために、モデルコンポーネントを与えるか、モデルエンティティを作成する必要があります。

属性、プロパティ、および動作を追加するには、エンティティにコンポーネントを追加します。

そういえば、コンポーネントについて話しましょう。

コンポーネントは、フレーム間に状態を保存し、エンティティのシステムへの参加をマークするためのものです。

ただし、ここではその状態に対処するためのロジックを含める必要はありません。

あなたの論理と行動は、あなたのカスタムシステムに行きます。

作成したエンティティにすでに存在するコンポーネントがいくつかあります。

ここに示されていないのは、組み込みコンポーネントです。変換コンポーネントと同期コンポーネントです。

彼らはこれらの3つのエンティティすべてにいます。

エンティティを画面に表示させるメッシュと素材を含むモデルコンポーネントなど、頻繁に追加したいものが他にもあります。

動作を動的に変更したい場合は、実行時にエンティティからコンポーネントを追加および削除することもできます。

この最初の魚を群れシステムに参加しているとマークし、藻類を食べるのが好きだと伝えます。

この2番目の魚は、最初の魚と一緒に群がるつもりですが、今はプランクトンを食べることを好みます。

この3人目の男はプランクトンです。

それは2番目の魚の餌になります。

私たちのアプリには、いくつかの空腹の生き物がいるので、それはその背中を見るべきです。

AlgaeEaterまたはPlanktonEaterのコンポーネントが載っているので、どれが空腹か知っています。

すべてのフレーム、私たちの食事システムには更新機能があります。

ここでは、これらのコンポーネントのいずれかを持つシーン内のすべてのエンティティに加えて、食べ物であるすべてのエンティティを見つけるので、空腹の魚を彼らが好む食べ物に導くことができます。

しかし、食事システムがどのエンティティが空腹であるか、どのエンティティが食べ物であり、どのエンティティがどちらでもないかを把握するためのパフォーマンスの高い方法は何ですか?

エンティティグラフを横断して、それぞれのコンポーネントをチェックしたくありません。

代わりに、エンティティクエリを実行します。

RealityKitに簿記をさせてください。

Flocking Systemは、FlockingComponentを持つすべてのエンティティを見つけたいと考えています。

食事システムは、両方の種類の空腹のエンティティに加えて、食品の一種であるエンティティを望んでいます。

それでは、システムがエンティティクエリを使用するときに正確に何が起こっているのかを詳しく見てみましょう。

システムには、すべてのフレームと呼ばれる更新機能があります。

黄色い唐の魚のフロックシステムを見てみましょう。

このフレームで一時停止して、何が起こっているのかを確認します。

Flocking Systemの更新機能では、FlockingComponentとMotionComponentの両方を持つシーン内のすべてのエンティティを照会します。

多くのものにはMotionComponentがありますが、私たちはそれらのすべてを望んでいません、私たちはただ私たちの群れが欲しいだけです。

私たちのクエリは群がる魚を返すので、今、私たちは群れの各魚に古典的なBoidsシミュレーションを適用することによって、私たちのカスタムゲーム物理学を駆動することができます。

私たちは、各魚のMotionComponentに力を追加し、フレームの間に状態を保ち、一緒に固執し、一定の距離を保つことを好む力、鼻を同じ方向に向けようとします。

モーションシステムが実行されると、同じフレームで、フロッキングシステムが実行された後、これらすべての力をロールアップして、魚の新しい加速度、速度、位置を決定します。

他のどのシステムがそれらを追加したかは気にしません。

食事システムや恐怖システムなど、モーションコンポーネントで動作して魚をさまざまな方向にプッシュするものもあります。

では、コードを見てみましょう。

これが私たちのフロッキングシステムの概要です。

RealityKit.Systemプロトコルに準拠したクラスです。

アプリの起動時にカスタムシステムを登録すると、アプリのシーンごとにこのタイプの1つをインスタンス化したいとエンジンに伝えます。

Initが必要で、deinitを提供することもできます。

依存関係を指定できます。

このシステムは常にMotionSystemの前に実行する必要があります。そのため、ここで列挙値を使用しました。

更新機能では、MotionComponentに保存されている状態を変更し、MotionSystemは提供する状態に基づいて動作するため、生産者と消費者の関係のように、MotionSystemの前にFlockingSystemが実行されていることを確認する必要があります。

.Afterオプションを使用することもできます。

依存関係を指定しない場合、システムの更新機能は登録した順序で実行されます。

EntityQueryは、フロックコンポーネントとモーションコンポーネントを持つすべてのエンティティが欲しいと言っています。

シミュレーション期間中は変更されないため、静的レットです。

マルチプレイヤーAR体験では、codableに準拠したコンポーネントがネットワーク上で自動的に同期されます。

ただし、システム内のデータはネットワーク上で自動的に同期されません。

データは一般的にコンポーネントに保存する必要があります。

それでは、FlockingSystemの更新機能に飛び込みましょう。

そのフレームのデルタタイムとシーン自体への参照を含むSceneUpdateContextが必要です。

まず、シーンでEntityQueryを実行し、FlockingComponentを持つエンティティに対して反復処理できるクエリ結果を返します。

それぞれのMotionComponentを取得し、それを修正します。

なぜFlockingComponent自体を入手しないのですか?

なぜなら、それに関連付けられたデータがないからです。

私たちは、群れのメンバーシップを示すためにタグのようにそれを使用します。

次に、標準のBoidsシミュレーションを実行して群れを誘導し、MotionComponentの力の収集を変更します。

最後に、各魚に力を追加して目的の方向にプッシュし、コンポーネントは値タイプであるSwift構造体であるため、MotionComponentを元のものに戻す必要があります。

システムはカスタム更新機能を実装する必要はありません。

また、シーンイベントのイベントハンドラを登録するなど、initのみを提供するシステムを作成すると便利です。

これまでのところ、エンティティ、コンポーネント、およびカスタムシステム間の関係を見てきました。

では、少しズームアウトして、RealityKit 2にもたらした高レベルのアーキテクチャの変更について話しましょう。

以前は、すべてのフレームが呼び出されるクロージャを使用してSceneEvents.updateイベントをサブスクライブしました。

この種のイベントハンドラーは、多くの場合、ゲームマネージャーのようなクラスに住んでいるか、少なくとも登録されます。

そのようなクロージャの代わりに、更新ロジックをきれいに分離し、別々のシステム更新機能で正式に注文できるようになりました。

つまり、ゲームマネージャーは役割をあまり果たせないということです。

そこでイベントの更新のためにすべての登録を行い、ゲーム内のすべてのものについて更新を呼び出す順序を管理する代わりに、ゲームマネージャーはエンティティにコンポーネントを追加して、それらのエンティティがクエリに含めるべきであることをシステムに示すだけです。

以前は、エンティティサブクラスでプロトコルの適合性を宣言して、そのエンティティタイプに特定のコンポーネントがあることを表現していました。

これで、エンティティをサブクラスにする必要はありません。なぜなら、それもあまり役割を果たさないからです。

それは単なるオブジェクトの識別子であり、その属性はコンポーネントとしてモデル化することができます。

なぜなら、サブクラスエンティティをしない場合、オブジェクトをそれらのコンポーネントを永遠に保持するために結び付けないからです。

体験中にコンポーネントを自由に追加および削除できます。

したがって、RealityKit 2では、カスタムシステムを持っているので、カスタムコンポーネントははるかに便利です。

しかし、あなたはまだどちらの方法でもそれを行うことができます。

それがゲーム開発の美しさです。

世界はあなたの牡蠣です。

水中デモでは、両方の方法を使用しています。

また、新しいタイプのコンポーネント、TransientComponentも追加しました。

例えば、あなたの魚はタコを恐れていましたが、彼らがそれを見たことがある場合に限ります。

新しい魚の実体をクローンアップすると、クローンがその魚のタコの恐怖を継承したくないかもしれません。

FearComponentをTransientComponentに適合させることができます。

そうすれば、新しいエンティティには存在しません。

ただし、TransientComponentは、他の種類のコンポーネントと同様に、codableに準拠している場合は、ネットワーク同期にまだ含まれています。

もう1つの追加は、キャンセル可能な新しい拡張機能です。

エンティティのイベントの購読解除を手動で管理する必要はもうありません。

あなたがstoreWhileEntityActiveを使用するとき、私たちはあなたのためにそれを行います。

ここでは、魚の実体の衝突イベントを扱っています。

魚自体よりも長生きするためにこのサブスクリプションを必要としないので、storeWhileEntityActiveを使用しています。

いつものように、ゲームを構築するときは、再コンパイルすることなく、その場で微調整したい設定がたくさんあります。

私たちのゲームでは、SwiftUIで設定ビューを構築し、CustomComponentsでラップすることで、そのバッキングモデルをさまざまなCustomSystemsに渡します。

Settingsインスタンスを@StateObjectとして作成し、ARViewContainerとSwiftUIビューの両方に環境オブジェクトとして渡します。

SettingsオブジェクトをCustomComponent、SettingsComponentでラップします。

次に、魚のエンティティを作成するときに、設定コンポーネントを与えます。

そうすれば、これらの設定を望むカスタムシステムが登場すると、「最高速度」の値を取り、それを使用して各魚の速度を上限として、そこから読み取ることができます。

そして今、私はそれを同僚のオリヴィエに渡して、材料についてあなたに話します。

ありがとう、アマンダ。

今年は、材料用の新しいAPIを追加しました。

ベースカラー、粗さ、金属特性を持つSimpleMaterialなど、すでにいくつかのタイプがありました。

また、色だけで照明のないUnlitMaterialもありました。

仮想オブジェクトを隠すためのマスクとして使用できるOclusionMaterialsがありました。

そして昨年、ビデオを色として使用するUnlitMaterialsであるVideoMaterialsを導入しました。

今年は透明性のサポートを追加したことに注意してください。

ビデオファイルに透明度が含まれている場合は、オブジェクトをレンダリングするために使用されます。

今年は、USDでの材料のスキーマと非常によく似たPhysicallyBasedMaterialタイプから始めて、材料をより高度に制御できる新しいAPIを追加しました。

これはSimpleMaterialのスーパーセットであり、他のレンダラーで見つけることができる標準的なPBRプロパティのほとんどを持っています。

これは、米ドルからロードされたエンティティで見つけることができる資料です。

たとえば、ピエロの魚のUSDをロードし、その材料の個々の特性を変更して金または紫にすることができます。

素材の特性の中で、たとえば、通常のマップを変更して、メッシュの一部ではない小さな詳細を追加できます。

モデルの透明度を定義するテクスチャを割り当てることもできます。

デフォルトでは、透明度はアルファブレンドを使用していますが、不透明度Thresholdも割り当てると、そのしきい値以下のすべてのフラグメントが破棄されます。

アンビエントオクルージョンのテクスチャを設定し、モデル内のあいまいな影を定義できます。

そして、より高度な特性の例は、材料上の反射塗料の追加層をシミュレートするクリアコートです。

また、PhysicallyBasedMaterialタイプには他にも多くのプロパティがあります。

また、独自の金属コードを使用して材料を作るために、カスタム材料と呼ばれる新しいタイプを追加しました。

これは、このタコモデルに色遷移効果をもたらすために使用したものです。

レンダリングに関する2番目の講演では、このシェーダーとカスタムマテリアルについて説明します。

素材に加えて、RealityKitのアニメーションのコントロールも強化しました。

まず、アニメーションの既存のAPIについて調べてみましょう。これは主にUSDからロードされたアニメーションの再生に関するものです。

USDからアニメーションを読み込むと、一度再生できます。

また、無限にループするように繰り返すこともできます。これは、ここでダイバーのアイドルアニメーションに望むものです。

アニメーションを一時停止、再開、停止することもできます。

最後に、新しいアニメーションを再生するときは、トランジション時間を指定することができます。

指定しないと、キャラクターは即座に新しいアニメーションに切り替わります。

トランジション期間を指定すると、その間にRealityKitは古いアニメーションと新しいアニメーションをブレンドします。

これは、例えば、ダイバーのウォークサイクルとアイドルサイクルの間を移行するときに便利です。

しかし、私たちはまだそこの足のアニメーションを改善することができます。

ブレンドレイヤーに新しいAPIを使用して、アニメーションをよりリアルにすることができます。

私たちは2つの別々のブレンドレイヤーでウォーキングアニメーションとアイドルアニメーションを再生し、最上層でウォーキングアニメーションを再生したので、それは私たちが現在見ている唯一のアニメーションです。

しかし、ウォーキングアニメーションのブレンドファクターを変更して、下のアイドルアニメーションを明らかにすることができます。

ブレンド係数が小さくなるにつれて、足音も小さくなることに注意してください。

また、アニメーションの再生速度を変更して、ダイバーの歩行を速くまたは遅くすることもできます。

ここでは、ダイバーは半分の速度で歩いています。

最後に、地面に対する文字の速度を使用して、これらの値の両方を制御します。

このようにして、地面と比較してアニメーションをより滑らかにし、足の滑りを減らすことができます。

これまでのところ、アイドルサイクルやウォークサイクルなど、複数のアニメーションクリップを使用してきました。

これらはRealityKitのAnimationResourcesとして保存されます。

また、USDファイルから読み込む方法は複数あります。

最初の方法は、クリップごとに1つのUSDファイルを持つことです。

各USDをエンティティとしてロードし、そのアニメーションをAnimationResourcesとして取得できます。

AnimationResourceは、スケルトン内のジョイントの名前がアニメーションと一致する限り、任意のエンティティで再生できます。

複数のアニメーションクリップをロードするもう1つの方法は、同じタイムラインで1つのUSDにそれらを持ち、AnimationViewsを使用してこのタイムラインを複数のクリップにスライスすることです。

これには、各クリップ間のタイムコードを知る必要があります。

その後、各AnimationViewをAnimationResourceに変換し、前の方法とまったく同じ方法で使用できます。

それでは、アプリでタコのアニメーションを見てみましょう。 タコのアニメーションを見てみましょう。

タコは隠れていますが、プレイヤーが近づくと怖くなり、新しい隠れ場所に移動します。

それをアニメーション化する方法を見てみましょう。

タコの骨格アニメーションをロードすることから始めます:ジャンプ、水泳、着陸。

これらのアニメーションは、私たちがダイバーのためにやったのと同じように、米ドルから読み込まれます。

しかし、私たちはまた、ある場所から次の場所に移動するためにタコの変換をアニメーション化したいと考えています。

変換をアニメーション化するには、新しいAPIを使用して、FromToByAnimationタイプのアニメーションをプログラムで作成します。

このようにして、位置をアニメーション化できます。

タコがどのように見えるか見てみましょう。 タコでどのように見えるか見てみましょう

もっと面白くするために、回転もアニメーション化しましょう。

タコは動いている間に回転しますが、横向きに泳いでいますが、あまり現実的ではありません。

一連のアニメーションを作ることで、これを改善できます。

まず、タコを新しい場所に向かって回転させます。

その後、それを新しい場所に翻訳します。

そして最後に、タコをカメラに向かって回転させます。

そして、これが完全なアニメーションです。

アニメーション用の新しいAPIに加えて、キャラクターの物理を管理する方法も追加しました。

それはキャラクターコントローラーと呼ばれています。

これにより、シーン内のコライダーと物理的に対話できるキャラクターを作成できます。

ここでは、ダイバーが床からソファに飛び降りてその上を歩いているのが見えます。

これは、ダイバーにキャラクターコントローラーを追加することで達成されます。

これにより、ダイバーはLiDARセンサーから生成された環境のメッシュと自動的に相互作用します。

キャラクターコントローラーの作成は簡単です。

あなたがする必要があるのは、あなたのキャラクターの形に合ったカプセルを定義することだけです。

作成時に、カプセルの高さとその半径を指定する必要があります。

キャラクターコントローラーがエンティティに割り当てられた後、すべてのフレームでmove(to:)関数を呼び出すことができます。

キャラクターを目的の場所に移動させますが、障害物を通り抜けることはありません。

一方、障害物を無視したい場合は、テレポート機能を使用できます。

今、私はそれをアマンダに渡します。アマンダは、私たちがRealityKitのこのリリースに追加したいくつかの楽しい機能を通してあなたを連れて行きます。

すごい。ありがとう、オリヴィエ。

さて、ディスクからロードすることなく、その場でリソースを作成できる2つの新しいAPIを強調します。

まず、SceneUnderstandingから人の顔のメッシュを取得する方法を紹介し、次にオーディオを生成する方法を説明します。

これらが手続き的に生成された芸術のために開く可能性の海があります。

まず、フェイスメッシュ。

私はデモアプリにある紫とオレンジのタコの外観にとても触発され、私は私の顔に1つをペイントしようとしましたが、事実上、新しいフェイスメッシュ機能を使用していました。

SceneUnderstandingは、人々の顔を表すエンティティを提供することができ、それらのエンティティにはModelComponentsがあります。つまり、フェイスエンティティのメッシュ上の材料のプロパティを交換できます。

私たちは、ライブドローイングでその場でフェイスメッシュに適用するテクスチャを生成するのがとても楽しかったです。

コードを見てみましょう。 

SceneUnderstandingComponentには、EntityTypeと呼ばれる列挙プロパティがあります。これはSceneUnderstandingSystemによって設定され、2つの値のいずれかを取ることができます。顔、つまり、現実世界の人の顔の表現、またはmeshChunk、つまり再構築された世界メッシュの他の部分です。

また、そのタイプがまだ知られていないことを意味する、nilである可能性があります。

これは再びEntityQueryです。

SceneUnderstandingComponentを持つエンティティを照会し、そのentityTypeをチェックして顔を見つけることができます。

その後、これらのエンティティからModelComponentsを取得し、それらを使って好きなことをすることができます。

フェイスペイントのサンプルでは、PencilKitを使用してキャンバスに描画し、そのCGImageからTextureResourceを作成して、結果のCGImageをfaceEntityにラップしています。

私たちは、このフェイスペイントをできるだけ現実的に見せることができるようにPhysicallyBasedMaterialを使用しており、私たちの外観のためにそれをダイヤルインするためにいくつかのプロパティを設定しています。

キラキラペイント効果を作るために、物理的ベースのレンダラーに、単に材料を金属のままにした場合とは異なる方法でこの表面に光を反射する方法を伝える通常のマップテクスチャを使用します。

次に、鉛筆で描かれたTextureResourceを素材に渡し、エンティティに設定します。

だから、それは私たちの新しく生成されたリソースで作業する1つの方法です。

生成できるもう1つのタイプのリソースは、AudioBufferResourceです。

AVAudioBufferは、マイク入力を録音したり、自分で生成したり、AVSpeechSynthesizerを使用したりすることで、好きなように入手できます。

その後、AVAudioBufferを使用してAudioBufferResourceを作成し、それを使用してアプリでサウンドを再生できます。

AVSpeechSynthesizerにAVSpeechUtteranceを書くことで、テキストをスピーチに変える方法は次のとおりです。

コールバックでAVAudioBufferを受け取ります。

ここでは、AudioBufferResourceを作成し、3D位置オーディオを利用するためにinputModeを.spatialに設定しています。

他の利用可能な入力モードは、非空間とアンビエントです。

次に、エンティティにそのオーディオを再生するように指示します。

もちろん、派手なトリックでオーディオバッファを処理して、魚が水中で話すときに泡を吹いているように聞こえるようにすることができます。

これは、今年のRealityKitの新機能の概要でした。

私たちは、あなたのシーンの外観と行動をよりコントロールすることに重点を置いています。

ECSを修正してカスタムシステムを提供し、アプリの動作をより柔軟に構築できるようにしました。

素材とアニメーションAPIに多くの進歩を加えました。

エンティティが現実世界の環境と簡単にやり取りできるように、キャラクターコントローラーを導入しました。

最後に、その場でリソースを生成できる方法のいくつかを強調しました。

しかし、それは間違いなくRealityKit 2で新しいすべての完全なリストではありません。

今週後半の2回目のRealityKitセッションでは、新しいレンダリング機能の詳細を学び、水中デモでいくつかのものを実装した方法を見ることができます。

ジオメトリ修飾子は、海藻をアニメーション化するために使用するものです。

タコは表面シェーダーを使用して、その色間を美しく遷移します。

青い深さの霧効果と水腐食作用は、後処理を使用して作成されました。

そして、生成リソースのテーマでは、動的メッシュの使い方を学びます。

復習のために、2019年のセッション「RealityKitでアプリを構築する」もチェックしてみてください。

ありがとう、そして私たちはこれらのAPIであなたの創造性の深さを見ることを楽しみにしています。

[明るい音楽]。