10153

♪ベース音楽の演奏♪

♪

ユージン・ジドコフ:こんにちは、WWDCへようこそ。

私の名前はユージン・ジドコフです。私はGPUソフトウェアの出身です。

そして、MacシステムアーキテクチャのHarsh Patilと一緒に、Appleシリコン上のMetalを搭載した画像処理アプリケーションを作成する方法を紹介します。

まず、ベストプラクティスと教訓に焦点を当て、昨年の開発者エンゲージメントに基づいてM1の画像処理アプリケーションを最適化します。

そして、Harshは、Appleシリコンで最適なパフォーマンスを得るために画像処理パイプラインを再設計する方法のステップバイステップガイドを提供します。

だから、すぐに飛び込みましょう!

まず、Appleのシステムオンザチップアーキテクチャとその利点を簡単に再検討しましょう。

多くの画像処理およびビデオ編集アプリは、ディスクリートGPUを念頭に置いて設計されています。

したがって、Apple GPUの何がそんなに違うのかを強調することが重要です。

まず、すべてのAppleチップはUnified Memory Architectureを使用しています。

CPU、GPU、ニューラル、メディアエンジンなどのすべてのブロックは、ユニファイドメモリインターフェイスを使用して同じシステムメモリにアクセスできます。

そして第二に、私たちのGPUはタイルベースの遅延レンダラー、またはTBDRです。

TBDRには2つの主要なフェーズがあります。レンダリングサーフェス全体がタイルに分割され、処理されたジオメトリが独立して処理されるタイリングと、すべてのピクセルが各タイルに対して処理されるレンダリングです。

したがって、Appleシリコンで最も効率的であるためには、画像処理アプリは、パイプラインがかつて持っていたコピーを避けるために統一メモリと、タイルメモリとローカル画像ブロックを利用してTBDRアーキテクチャを活用する必要があります。

Apple TBDRが低レベルでどのように機能し、シェーダーコアをターゲットにする方法の詳細については、昨年のこれらのセッションをご覧ください。

そして今、Appleシリコンの画像処理コンピューティングワークロードを最適化するために私たちがやろうとしている正確なことについて話しましょう。

昨年、私たちは多くの優れた開発者と画像パイプラインの移行に緊密に協力してきました。

私たちは共有する6つの最もやりがいのあるヒントを選びました。

まず、不要なメモリコピーやブリットを回避する方法について説明します。

現在、最大8Kの画像に取り組んでいることを考えると、これは本当に重要です。

次に、バッファでコンピューティングを使用する代わりにレンダリングパイプラインとテクスチャを使用する利点と、独自の画像処理パイプラインでそれを行う方法を強調したいと思います。

レンダリングとテクスチャのパスを稼働させたら、適切なロード/ストアアクションとメモリレスアタッチメントの重要性を紹介したいと思いました。

これは、タイルのメモリを最大限に活用するのに役立ちます。

次に、動的制御フローでUber-shadersにアプローチする方法と、短いデータタイプや半分などの小さなデータタイプを活用してパフォーマンスと効率を向上させる方法について話します。

そして、最高のスループットを得るために、テクスチャフォーマットに関する重要なアドバイスで締めくくります。

わかった。

それでは、最もやりがいのあるヒントの1つから始めましょう。Appleシリコンの不要なブリッツを避けることです。

ほとんどの画像処理アプリは、ディスクリートGPUを中心に設計されています。

ディスクリートGPUを使用すると、システムメモリとビデオメモリが分離されます。

フレーム画像をGPUに表示または常駐させるには、明示的なコピーが必要です。

さらに、通常、GPUがそれを処理するためのデータをアップロードし、それを引き戻すために2回必要です。

8Kビデオをデコードし、処理し、ディスクに保存することを考えてみましょう。

したがって、この場合、これはCPUスレッド、デコードです。

そこで、デコードされたフレームをGPU VRAMにコピーする必要があります。

そして、これはすべてのエフェクトとフィルターが適用されるGPUタイムラインです。

さらに一歩進んで、結果をディスクに保存する必要があることを思い出しましょう。

したがって、処理されたフレームをシステムメモリに戻し、フレームの実際のエンコーディングも検討する必要があります。

したがって、これらは「コピー」または「ブリットギャップ」として知られており、高度な画像処理アプリケーションは、それらを埋めるために深いパイプラインやその他のスマートなことをしなければなりませんでした。

さて、良いニュースは、Apple GPUでは、居住のためのブリットはもはや必要ないということです。

メモリは共有されているため、CPUとGPUの両方が直接アクセスできます。

したがって、ユニファイドメモリシステムで実行しているかどうかを検出し、不要なコピーを避けるために、簡単なチェックを追加してください。

それはあなたの記憶、時間を節約し、絶対的な最初のステップです。

だから、これは私たちがブリットを削除したユニファイドメモリアーキテクチャに着陸する場所です。

ブリットを取り除くことで、コピーのギャップを完全に回避し、すぐに処理を開始できます。

これにより、より少ない手間でより良いCPUとGPUのパイプラインも提供されます。

コピーを伴わない統一されたメモリパスを実装しましょう。

ブリットコピーをディスクリートGPUとまったく同じままにしておくと、システムメモリ帯域幅、実際の処理のためのGPU時間の短縮、および潜在的なスケジューリングオーバーヘッドで支払います。

言うまでもなく、個別のVRAMイメージを割り当てる必要がなくなりました。

GPUフレームキャプチャは、大きなブリットを見つけるのに役立ちます。

アプリケーションのブリットを検査し、必要なコピーのみを行うことを確認してください。

さて、画像処理にApple GPU TBDRアーキテクチャをどのように活用すべきかについて話しましょう。

ほとんどの画像処理アプリケーションは、一連のコンピューティングカーネルをディスパッチすることによって画像バッファで動作します。

デフォルトのシリアルモードでコンピューティングカーネルをディスパッチすると、Metalは後続のすべてのディスパッチがすべてのメモリ書き込みを見ることを保証します。

この保証は、すべてのシェーダーコアのメモリの一貫性を意味するため、すべてのメモリ書き込みは、次のディスパッチが開始されるまでに他のすべてのコアに表示されます。

これはまた、メモリトラフィックが本当に高くなる可能性があることを意味します。画像全体を読み取り、書きする必要があります。

M1では、Apple GPUはMacOSでタイルディスパッチを可能にします。

通常のコンピューティングとは対照的に、タイルのみの同期ポイントを持つタイルメモリで動作します。

畳み込みのような一部のフィルターはタイルパラダイムにマッピングできませんが、他の多くのフィルターはできます!

エンコーダのエンドポイントが堅実な効率向上になるまで、システムメモリのフラッシュを延期します。

システムメモリ帯域幅に制限されていない場合、より有用なGPU作業を実行できます。

さらに、多くのピクセルごとの操作は近隣のピクセルへのアクセスを必要としないため、タイル同期ポイントは必要ありません。

これはフラグメント関数に本当によくマッピングされます。

フラグメント関数は、暗黙のタイル同期なしで実行でき、エンコーダ境界でのみ、またはタイルカーネルがフラグメントカーネルの後に連続してディスパッチされる場合にのみ同期する必要があります。

Apple GPUは、より効率的な画像処理のためにフラグメント機能とタイルカーネルを可能にすることを学びました。

それをどう使うか見てみましょう。

バッファ上の通常の計算ディスパッチを変換して、テクスチャにコマンドエンコーダをレンダリングすることによってそれを行います。

先ほど説明したように、経験則は次のとおりです。

ピクセル間の依存関係のないピクセルごとの操作は、フラグメント関数を使用して実装する必要があります。

スレッドグループスコープ操作を持つフィルタは、タイル内のネイバーピクセルアクセスが必要なため、タイルシェーディングで実装する必要があります。

スキャッターギャザーと畳み込みフィルタは、ランダムアクセスを必要とするため、タイルパラダイムにマッピングできないため、これらはまだコンピューティングディスパッチのままである必要があります。

レンダリングコマンドエンコーダは、独自のApple GPU機能も可能にします。テクスチャとレンダリングターゲットのロスレス帯域幅圧縮です。

これは、特に画像処理パイプラインにとって、本当に素晴らしい帯域幅の節約なので、どのように使用すべきか見てみましょう。

さて、可逆圧縮を有効にすることといえば、実際にはあなたがすべきではないことを言う方が簡単です。

まず、すでに圧縮されているテクスチャフォーマットは、ロスレスの恩恵を受けることはできません。

第二に、この圧縮では動作しない3つの特定のテクスチャフラグがあるので、偶然に設定しないようにしてください。

そして第三に、線形テクスチャ、またはMTLBufferに裏打ちされたテクスチャも許可されていません。

非プライベートテクスチャにも特別な処理が必要です。最速のパスにとどまるには、必ずOptimizeContentsForGPUAccessを呼び出してください。

GPUフレームキャプチャサマリーペインに、ロスレス圧縮警告が表示され、テクスチャがオプトアウトした理由が強調表示されます。

この例では、PixelFormatViewフラグが設定されました。

多くの場合、開発者は意図せずにこれらのフラグを設定しています。

必要なのはコンポーネントのスウィズルまたはsRGB変換だけの場合は、PixelFormatViewを設定しないでください。

さて、レンダリングとテクスチャのパスが稼働しています。

では、タイルメモリを適切に使用しましょう。

ロード/ストアアクションやメモリレスアタッチメントなどのタイルメモリTBDRの概念は、デスクトップの世界ではまったく新しいものです。

だから、それらを適切に使用するようにしましょう。

ロード/ストアアクションから始めましょう!

すでに知っているように、レンダリングターゲット全体がタイルに分割されています。

ロード/ストアは、メモリ階層を通じて最適なパスを取ることが保証されたタイルごとのバルクアクションです。

それらはレンダリングパスの開始時に実行され、GPUにタイルメモリの初期化方法を指示し、パスの最後にどの添付ファイルを書き戻す必要があるかをGPUに通知します。

ここで重要なのは、必要のないものをロードするのを避けることです。

画像全体を上書きしている場合、またはリソースが一時的である場合は、ロードアクションをLoadActionDontCareに設定します。

レンダリングエンコーダを使用すると、専用のコンピューティングパスまたはfillBufferコールで以前に行ったように、出力または一時データをクリアする必要がなくなります。

LoadActionClearを設定することで、クリア値を効率的に指定できます。

そして、同じことが店の行動にも当てはまります。

メインの添付ファイルのように、後で必要なデータのみを保存し、一時的なものは保存しないでください。

明示的なロードとストアアクションに加えて、Apple GPUはメモリレスアタッチメントでメモリフットプリントを節約します。

添付ファイルをメモリレスストレージモードとして明示的に定義できます。

これにより、タイルのみのメモリ割り当てが可能になります。つまり、リソースはエンコーダの寿命内にのみ、すべてのタイルに対して持続します。

これにより、特にすべてのフレームが数百メガバイトかかる6K / 8K画像の場合、メモリフットプリントを大幅に削減できます。

このすべてをコードでどのように行うことができるか見てみましょう。

まず、textureDescriptorを作成し、次にoutputTextureを作成します。

次に、一時的なテクスチャを作成します。

ここにストレージが欲しくないので、メモリレスとマークしたことに注意してください。

次に、最初に添付ファイルが何であるか、次にロード/ストアアクションが何であるかを記述して、レンダリングパスを作成します。

完全に上書きされているため、出力の読み込みは気にしませんが、保存する必要があります。

一時的なテクスチャについては、ロードするのではなくクリアし、保存する必要もありません。

最後に、記述子からrenderPassを作成します。

それでおそれ。

そのため、ユニファイドメモリを使用し、画像処理パイプラインを移動してコマンドエンコーダをレンダリングし、タイルメモリを適切に活用しています。

さて、ウーバーシェーダーについて話しましょう。

Uber-shaders、またはuber-kernelsは、開発者の生活を楽にするための非常に人気のある方法です。

ホストコードは制御構造を設定し、シェーダーは、トーンマッピングが有効になっている場合や、入力がHDRまたはSDR形式の場合など、一連のif/elseステートメントをループするだけです。

このアプローチは「ubers-shader」とも呼ばれ、パイプライン状態オブジェクトの総数を下げるのが本当に得意です。

しかし、それには欠点があります。

主なものは、より複雑な制御フローに追いつくためのレジスタ圧力の増加です。

より多くのレジスタを使用すると、シェーダーが実行されている最大占有率を簡単に制限できます。

制御構造体を渡す単純なカーネルを考えてみましょう。

構造体内のフラグを使用して、何をするかを制御します。

ここには2つの機能があります。入力がHDRの場合とトーンマッピングが有効になっている場合です。

みんな良さそうだよね？

さて、これがGPUで起こることです。

コンパイル時には何も推測できないため、HDRと非HDRの両方のパスを取り、フラグに基づいて組み合わせることができると仮定する必要があります。

トーンマッピングも同様です。

私たちはそれを評価し、入力フラグに基づいてマスクインまたはマスクアウトします。

ここでの問題はレジスタです。

すべての制御フローパスにはライブレジスタが必要です。

これは、ユーバーシェーダーがそれほど良くないところです。

思い出すように、カーネルで使用されるレジスタは、シェーダーが実行できる最大占有率を定義します。

これは、レジスタファイルがシェーダーコア上のすべてのsimdlanesによって共有されているために発生します。

必要なものだけを実行できれば、simdgroupの並行性とGPUの使用率を高めることができます。

これを修正する方法について話しましょう。

Metal APIには仕事に適したツールがあり、「function_constants」と呼ばれています。

両方の制御パラメータをfunction_constantsとして定義し、それに応じてコードを変更します。

ここでは、修正されたカーネルコードを表示しています。

パイプライン作成時にfunction_constant値を提供するために、ホスト側も更新する必要があります。

レジスタ圧力を下げるもう1つの素晴らしい方法は、シェーダーで16ビットタイプを使用することです。

Apple GPUは、ネイティブの16ビット型をサポートしています。

したがって、より小さなデータ型を使用する場合、シェーダーはレジスタが少なくなり、占有率が増加します。

ハーフタイプとショートタイプもより少ないエネルギーを必要とし、より高いピークレートを達成する可能性があります。

したがって、タイプ変換は通常無料であるため、可能であればfloatとintの代わりにハーフタイプとショートタイプを使用してください。

この例では、いくつかの計算のためにthreadgroupのthread_positionを使用するカーネルを考えてみましょう。

私たちはunsigned intを使用していますが、Metalがサポートする最大スレッドグループサイズは、unsigned shortに簡単に収まります。

ただし、threadgroup_position_in_gridは、より大きなデータ型が必要になる可能性があります。

しかし、画像処理で使用しているグリッドサイズ（最大8Kまたは16K）では、符号なしショートでも十分です。

代わりに16ビット型を使用すると、結果のコードは少数のレジスタを使用し、占有率が増加する可能性があります。

さて、レジスタの詳細をすべて表示できる場所をお見せしましょう。

Xcode13のGPUフレームデバッガには、レンダリング、タイル、およびコンピューティングPSO用の高度なパイプライン状態オブジェクトビューが追加されました。

詳細なパイプライン統計（レジスタの使用状況）を検査し、すべてのシェーダーを微調整できます。

レジスタの懸念をカバーして、テクスチャフォーマットについて話しましょう。

まず、ピクセルフォーマットによってサンプリングレートが異なる可能性があることに注意してください。

ハードウェアの生成とチャネルの数によっては、より広い浮動小数点タイプにより、ポイントサンプリングレートが低下する可能性があります。

特にRGBA32Fなどの浮動小数点形式は、フィルタリングされた値をサンプリングする場合、FP16バリアントよりも遅くなります。

小規模なタイプは、メモリストレージ、帯域幅、キャッシュフットプリントも削減します。

したがって、繰り返しますが、可能な限り最小のタイプを使用することをお勧めしますが、この場合は、テクスチャストレージに使用します。

これは実際には、画像処理における3D LUTの一般的なケースでした。私たちが取り組んだほとんどのアプリケーションは、バイリニアフィルタリングが有効になっている3D LUTアプリケーションフェーズにfloat RGBAを使用していました。

アプリが代わりに半分を使用でき、精度で十分であるかどうかを検討してください。

その場合は、すぐにFP16に切り替えてピークサンプリングレートを取得します。

半分の精度が十分でない場合、固定小数点符号なしショートが大きな均一な値範囲を提供することがわかったので、LUTを単位スケールでエンコードし、シェーダーにLUT範囲を提供することは、ピークサンプリングレートと十分な数値精度の両方を得るための素晴らしい方法でした。

さて、Apple GPUアーキテクチャを活用して、画像処理パイプラインをできるだけ効率的に実行する方法について説明しました。

すぐに適用するには、ハーシュに会ってください!

厳しいパティル:ありがとう、ユージーン。

それでは、これまでに学んだすべてのベストプラクティスに基づいて、Appleシリコンの画像処理パイプラインを再設計してみましょう。

具体的には、Apple GPU用のビデオ処理パイプラインの画像処理フェーズを調整します。

リアルタイムの画像処理は、非常にGPUコンピューティングとメモリ帯域幅集約的です。

まず、それが通常どのように設計されているかを理解し、次にAppleシリコン用に最適化する方法を理解します。

このセクションでは、ビデオ編集ワークフローの詳細については説明しませんので、2年前の講演を参照してください。

画像処理の計算部分をレンダリングパスに移行することだけに焦点を当てます。

始める前に、典型的なビデオ処理パイプラインで画像処理フェーズがどこにあるかをすばやく見てみましょう。

ProResでエンコードされた入力ファイルを例に挙げます。

まず、ディスクまたは外部ストレージからProResエンコードされたフレームを読みました。

次に、CPU上のフレームをデコードし、画像処理フェーズはGPU上のこのデコードされたフレームで実行され、最終的な出力フレームをレンダリングします。

最後に、この出力フレームを表示します。

さらに、配信のために最終的なレンダリングされたフレームをエンコードすることもできます。

次に、画像処理パイプラインを構成するものを見てみましょう。

画像処理は、最初にアルファのソース画像RGBの異なるチャンネルを別々のバッファに解凍することから始まります。

これらの各チャネルは、画像処理パイプラインで、一緒にまたは別々に処理します。

次に、目的の色管理環境で動作する色空間変換があるかもしれません。

次に、3D LUTを適用し、色補正を行い、空間的・時間的ノイズリダクション、畳み込み、ぼかし、その他の効果を適用します。

そして最後に、最終出力のために個別に処理されたチャネルを一緒にパックします。

これらの選択されたステップの共通点は何ですか?

それらはすべてポイントフィルタであり、ピクセル間の依存関係のない単一のピクセルでのみ動作します。

これらは、フラグメントシェーダーの実装によくマップされます。

空間および畳み込みスタイルの操作には、大きな半径のピクセルへのアクセスが必要であり、読み取り/書き込みアクセスパターンも散在しています。

これらはコンピューティングカーネルに適しています。 

この知識は後で使います。

とりあえず、これらの操作がどのように実行されるかを見てみましょう。

アプリケーションは、画像に適用される効果の連鎖をフィルターグラフとして表します。

すべてのフィルタは独自のカーネルであり、前段階からの入力を処理し、次の段階の出力を生成します。

ここのすべての矢印は、あるステージの出力との間で書き込まれ、次のステージの入力として読み込まれるバッファを意味します。

メモリは限られているため、アプリケーションは通常、トポロジカルソートを行うことでグラフを線形化します。

これは、競争条件を避けながら、中間リソースの総数をできるだけ低く保つために行われます。

この例のこの単純なフィルタグラフは、競合条件なしで動作し、最終的な出力を生成するには、2つの中間バッファが必要です。

ここでの線形化されたグラフは、GPUコマンドバッファエンコーディングも大まかに表しています。

このフィルタグラフが非常にデバイスメモリ帯域幅集約的である理由を詳しく見てみましょう。

すべてのフィルタ操作は、デバイスメモリからレジスタに画像全体をロードし、結果をデバイスメモリに書き戻す必要があります。

そして、それはかなりのメモリトラフィックです。

画像処理グラフの例に基づいて、4Kフレームの画像処理のメモリフットプリントを推定しましょう。

4Kデコードされたフレーム自体は、浮動小数点16精度には67メガバイトのメモリ、浮動小数点32精度には135メガバイトのメモリが必要で、プロのワークフローには浮動小数点32精度が絶対に必要です。

この画像処理グラフを介して浮動小数点32精度で1つの4Kフレームを処理するために、デバイスメモリへの2ギガバイト以上の読み取り/書き込みトラフィックについて話しています。

また、中間出力を保持するバッファへの書き込みは、キャッシュ階層をスラッシュし、チップ上の他のブロックにも影響を与えます。

通常のコンピューティングカーネルは、暗黙的にオンチップタイルメモリの恩恵を受けません。

カーネルは、オンチップタイルメモリによってバックアップされるスレッドグループスコープのメモリを明示的に割り当てることができます。

ただし、そのタイルメモリは、コンピューティングエンコーダ内のディスパッチ間で永続的ではありません。

対照的に、タイルメモリは実際には1つのレンダリングコマンドエンコーダ内のドローパス全体で永続的です。

タイルメモリを活用するために、この代表的な画像処理パイプラインを再設計する方法を見てみましょう。

私たちは3つのステップでこれに対処します。

まず、計算パスをレンダリングパスに変更し、すべての中間出力バッファをテクスチャに変更します。

次に、1つのレンダリングコマンドエンコーダ内のフラグメントシェーダー呼び出しとして、ピクセル間の依存関係のないピクセルごとの操作をエンコードし、すべての中間結果を考慮し、適切なロード/ストアアクションを設定します。

そして最後に、単なるポイントフィルターよりも複雑な状況で何をするかについて話し合います。

最初のステップは、個別のMTLRenderCommandEncoderを使用して、適格なシェーダーをエンコードすることです。

このフィルターグラフでは、アンパック、色空間変換、LUT、および色補正フィルターはすべてピクセルごとのポイントフィルターであり、フラグメントシェーダーに変換し、1つのレンダリングコマンドエンコーダを使用してエンコードできます。

同様に、この画像処理パイプラインの終わりに向かっているミキサーとパックシェーダーは、フラグメントシェーダーに変換し、別のMTLRenderCommandEncoderを使用してエンコードすることもできます。

その後、それぞれのレンダリングパス内でこれらのシェーダーを呼び出すことができます。

レンダリングパスを作成すると、そのレンダリングパスのカラーアタッチメントに添付されているすべてのリソースが暗黙的にタイル化されます。

フラグメントシェーダーは、タイル内のフラグメントの位置に関連付けられた画像ブロックデータのみを更新できます。

同じレンダリングパスの次のシェーダーは、タイルメモリから直接前のシェーダーの出力を拾うことができます。

次のセクションでは、これらのフィルタにマップするフラグメントシェーダーを構造化する方法を見ていきます。

また、これらのフラグメントシェーダー内から基礎となるタイルメモリへのアクセスを可能にするために定義し、使用する必要がある構造も見ていきます。

最後に、1つのフラグメントシェーダーによってタイルメモリで生成された出力が、同じレンダリングコマンドエンコーダ内の次のフラグメントシェーダーによってタイルメモリから直接消費される方法を見ていきます。

これはあなたのコードでしなければならないことです。

ここでは、レンダリングパス記述子のカラーアタッチメント0に添付されたテクスチャとして出力画像を添付しました。

レンダリングパス記述子のカラーアタッチメント1に中間結果を保持するテクスチャを添付しました。

これらは両方ともあなたのために暗黙的にタイル張りになります。

先ほどの講演で説明したように、適切な負荷/店舗のプロパティを設定してください。

次に、フラグメントシェーダーでこれらのテクスチャにアクセスするための構造を設定します。

今後の例では、フラグメントシェーダー内でこの構造を使用する方法を紹介します。

先ほど定義した構造を使用して、強調表示されているように、フラグメントシェーダー内の出力と中間テクスチャにアクセスするだけです。

これらのテクスチャへの書き込みは、フラグメントに対応する適切なタイルメモリ位置に行われます。

アンパックシェーダーによって生成された出力は、以前に定義したのと同じ構造を使用して、色空間変換シェーダーによる入力として消費されます。

このフラグメントシェーダーは、独自の処理を行い、出力と中間テクスチャを更新し、対応するタイルメモリの位置を再度更新できます。

同じレンダリングエンコーダパス内の他のすべてのフラグメントシェーダーに対して同じ手順を続行します。

次に、これらの変更で、この一連の操作がどのように見えるかを視覚化しましょう。

ご覧のとおり、開梱、色空間変換、3D LUTの適用、および色補正ステップがすべてタイルメモリで実行され、その間にデバイスメモリが通過することはありません。

レンダリングパスの最後に、メモリレスではないレンダリングターゲットがデバイスメモリにフラッシュされます。

その後、次のクラスのフィルタを実行できます。

スキャターギャザーアクセスパターンを持つフィルタについて少し話しましょう。

このようなフィルタを表すカーネルは、デバイスメモリ内のデータを直接操作できます。

畳み込みフィルタは、コンピューティングカーネルのタイルベースの操作に非常に適しています。

ここでは、スレッドグループスコープのメモリを宣言することで、タイルメモリを使用する意図を表現できます。

次に、フィルター半径に応じて、必要なすべてのハローピクセルとともにピクセルのブロックをタイルメモリに取り込み、タイルメモリで直接畳み込み操作を実行します。

タイルメモリは、コンピューティングエンコーダ内のコンピューティングディスパッチ全体では永続的ではないことを覚えておいてください。

したがって、Filter1を実行した後、タイルメモリの内容をデバイスメモリに明示的にフラッシュする必要があります。

そうすれば、Filter2はFilter1の出力を消費することができます。

では、これらすべての変更を加えたら、どこに着陸しますか?

再構築された画像処理グラフの例を使用して、浮動小数点32の精度で1つの4Kフレームを処理するために、私たちが今持っているものは次のとおりです。

帯域幅は2.16ギガバイトから810メガバイト相当のロードとストアに低下し、デバイスメモリへのメモリトラフィックが62%減少します。

フレームあたり270メガバイトのメモリを節約する2つの中間デバイスバッファは必要ありません。

そして最後に、キャッシュスラッシングを減らしました。それは、そのレンダリングパス内のすべてのフラグメントシェーダーがタイルメモリ上で直接動作しているためです。

Appleシリコンの主な特徴の1つは、ユニファイドメモリアーキテクチャです。

Appleシリコン上の異なるブロック間の相互作用のために、このユニファイドメモリアーキテクチャを活用する方法の例を見てみましょう。

GPUによってレンダリングされた最終的なビデオフレームのHEVCエンコーディングをケーススタディとして取ります。

このエンコーディングは、Appleシリコン上の専用のハードウェアメディアエンジンを使用して行われます。

GPUによってレンダリングされた最終的な出力フレームは、余分なメモリコピーなしで当社のメディアエンジンによって直接消費することができます。

次のセクションでは、GPUによって生成された最終出力フレームのHEVCエンコーディングのパイプラインを最も効率的な方法で設定する方法の例を説明します。

そのために、まずCoreVideo APIを活用して、IOSurfacesに裏打ちされたピクセルバッファのプールを作成します。

次に、Metal APIを使用して、作成したばかりのプールからIOSurfacesに裏打ちされたMetalテクスチャに最終的なフレームをレンダリングします。

そして最後に、これらのピクセルバッファをメディアエンジンに直接ディスパッチして、GPUによって生成された出力フレームの追加コピーなしでエンコードし、ユニファイドメモリアーキテクチャを活用します。

この方法を段階的に実行し、このフローを有効にするために必要なすべての構造をカバーしましょう。

まず、IOSurfaceに裏打ちされたCVPixelBufferPoolを目的のピクセル形式で作成します。

ここでは、HEVCエンコードにバイプラナークロマサブサンプリングピクセルフォーマットを使用します。

今、あなたはこのCVPixelBufferPoolからCVPixelBufferを取得します。

このCVPixelBufferを正しい平面インデックスでMetalTextureCacheに渡して、CVMetalTextureReferenceを取得します。

二平面ピクセル形式を使用しているため、二平面ピクセルバッファの両方の平面に対してこのステップを実行する必要があります。

次に、CVMetalTextureReferenceオブジェクトから基礎となるMetalテクスチャを取得します。

ルマ面とクロマ面の両方でこのステップを実行します。

これらのメタルテクスチャは、CVPixelBuffer平面もバックアップしている同じIOSurfacesによって裏打ちされていることを忘れないでください。

Metal APIを使用して、ルミナンス面とクロマ平面に対応するテクスチャにレンダリングします。

これにより、これらのメタルテクスチャもバックアップするIOSurfaceが更新されます。

画像処理パイプライン内のシェーダーパスとして、GPU自体のクロマプレーンでクロマサブサンプリングステップを行うことを強くお勧めします。

注意すべき重要なことは、CVPixelBufferと、レンダリングしたばかりのMetalテクスチャの両方が、システムメモリ内の同じ基礎となるIOSurfaceコピーによって裏付けられていることです。

このCVPixelBufferをメディアエンジンに直接送信してエンコードできるようになりました。

ご覧のとおり、ユニファイドメモリアーキテクチャにより、メモリコピーなしでGPUとメディアエンジンブロック間でデータをシームレスに移動できます。

そして最後に、すべてのフレームの後にCVPixelBufferとCVMetalTextureリファレンスをリリースすることを忘れないでください。

CVPixelBufferをリリースすることで、このバッファを将来のフレームにリサイクルできます。

まとめに、もう一度次のことを行うことをお勧めします。ユニファイドメモリアーキテクチャを活用し、該当する場合は計算の代わりにMTLRenderCommandEncoderを使用し、単一のレンダリングコマンドエンコーダ内ですべての適格なレンダリングパスをマージし、適切なロード/ストアアクションを設定し、一時的なリソースにメモリレスを使用し、該当する場合はタイルシェーディングを活用し、ゼロコピーのために他のAPIとバッファプールを使用します。

本日、このセッションにご参加いただき、ありがとうございます。

WWDC 2021の残りの部分をお楽しみください!

♪