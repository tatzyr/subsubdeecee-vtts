10152

こんにちは。私はサハルシュ・オザです。

私はアップルのGPUソフトウェアエンジニアリングチームに所属しています。

今日は同僚のYuliya Pylypivと、Metal Performance Shaders Graphの新機能について話します。

始めましょう。

MPSは、画像処理、線形代数、レイトレーシング、機械学習など、さまざまな分野向けの金属ベースの高性能GPUアクセラレーションプリミティブのライブラリです。

MPSチームは、Appleのさまざまなプラットフォームで各ハードウェアで最高のパフォーマンスを提供するために、Metalカーネルを最適化しています。

昨年、GPU用の汎用計算グラフであるMPSGraphフレームワークを導入しました。

MPSフレームワークと同様に、macOS、iOS、iPadOS、tvOSでサポートされています。

MPSGraphの紹介の詳細については、昨年のセッションをご覧ください。詳細はこちらをご覧ください。

議題を見てみましょう。 では、議題を見てみましょう

私たちはカバーすることがたくさんあります。

MPSGraphを通じて、ML推論とトレーニングアクセラレーションについて議論します。

いくつかのエキサイティングな新しいMPSGraph操作を紹介します。

MPSGraphでコンパイルを制御するための新しい方法を紹介します。

そして最後に、MPSGraphのすべての新しい制御フロー機能を見ていきます。

推論とトレーニングの加速に関するエキサイティングなアップデートを共有する同僚のユリヤを紹介したいと思います。

ありがとう、サハーシュ。

こんにちは。私はユリヤ・ピリピフです。

私はアップルのGPUソフトウェアチームの一員です。

今日は、GPUのトレーニングと推論のパフォーマンスを向上させるために行った改善点を共有したいと思います。

すぐにそれに入りましょう。

MPSGraphフレームワークは、GPUアクセラレーションのためにCore MLやTensorFlowなどの高レベルの機械学習フレームワークに採用されています。

今年は、カーネルの改善とステッチの採用を組み合わせて、MPSGraphをさらに最適化しました。

これは、MPSを使用する機械学習フレームワークに大きなパフォーマンスの向上に変換されました。

TensorFlow用の新しいメタルプラグインを詳しく見てみましょう。

TensorFlowは人気のある機械学習トレーニングプラットフォームであり、GPUは主要なアクセラレータデバイスです。

今年は、TensorFlow 2.5でリリースされたTensorFlow PluggableDevice Interfaceを使用して、新しいメタルプラグインを開発しました。

これは、MPSとMPSGraphを使用してTensorFlowにMetalの力をもたらします。

これにより、変更することなく、MacプラットフォームのGPUであらゆる機械学習モデルをトレーニングできます。

さて、これらのうちの1つが実際に動作しているのを見てみましょう。

このデモでは、Jupyter環境を使用します。

私のM1システムには、利用可能な最新のTensorFlowがインストールされています。

物理デバイスをリストすると、CPUデバイスのみが登録されていることがわかります。

ここでは、画像の分類、転送学習などに広く使用されている人気のある機械学習モデル、ResNet50を定義しています。

現在のモデルは、224×224の画像サイズの標準ImageNetデータセットを使用しています。

ご覧のとおり、CPUで実行されている最初のエポックの現在のETAは約20分です。

先ほど導入したTensorFlowメタルプラグインをインストールして、現在のネットワークにスピードアップを追加できるかどうかを確認します。

これを行うには、pip install tensorflow-metalを使用します。

以前使用したのと同じResNet50モデルに戻ります。

今回だけ、新しいGPUデバイスが登録されていることがわかります。

これは、Metal Pluginを使用してTensorFlowプラットフォームの一部として導入したGPUデバイスです。

すべてのコールバックとネットワーク定義は変更されません。

ETAを比較できるように、再びネットワークを開始します。

同じネットワークのGPUバージョンは、TensorFlow Metal Pluginを使用して約4倍速くトレーニングされていることがわかります。

では、他のネットワークを詳しく見てみましょう。

ここでは、CPUに対する主要な機械学習トレーニングベンチマークのパフォーマンスを示します。

ご覧のとおり、すべてのベンチマークで優れたスピードアップがあり、M1 MacBook Proでは最大8倍高速です。

TensorFlow用の新しいメタルプラグインのインストールは簡単です。

Pip install tensorflow-macosを使用してベースTensorFlowをインストールした後、pip install tensorflow-metalを使用してMetal Pluginをインストールできます。

メタルプラグインは、公式のPythonパッケージリポジトリ、pypi.orgで利用可能になります。

環境のセットアップとインストールの詳細については、Metal Developer Resourceを参照してください。

TensorFlowはそれだけです。

次に、Core MLの推論アクセラレーションについて話しましょう。

Core MLは、Appleの機械学習推論フレームワークです。

また、MPSGraphを使用したCore MLのパフォーマンスが大幅に向上しました。

ここでは、M1上の機械学習ネットワークの主要なクラスの推論のスピードアップを示します。

NLPアプリケーションに使用される正規のトランスネットワークであるBERTで2倍のスピードアップを取得します。

コンピュータビジョンアプリケーションの中心であるResNet50は、以前のリリースでテクスチャパスに合わせて調整されています。

これは、MPSGraphを介した新しいバッファバックエンドによる16%の追加パフォーマンス改善です。

Core MLとTensorFlowのこれらのパフォーマンスの向上は、Convolution2DのようなMPSプリミティブのパフォーマンスの向上によるものです。

ここでは、それぞれトレーニングと推論に使用されるNHWCとNCHWのデータレイアウトでConvolution2Dのスピードアップを示します。

推論とトレーニングの改善はそれだけです。

次に、Saharshに戻って、MPSGraphの新しい操作について詳しく学びましょう。

ありがとう、ユリヤ。

次に、MPSGraphでサポートされている新しい一連の操作を見ていきます。

畳み込みと削減の複数のバリアントから、計算グラフに必要なすべての基本的な数学操作まで、MPSGraphの多数の操作をサポートしています。

今年は、MPSGraphでさらに多くのことができるよう、特別な操作を追加しました。

制御依存関係、ステンシル演算子、収集演算子の3つの新しいプリミティブを紹介します。

まず、制御依存性を見ていきます。

グラフ内の操作を明示的に順序設定するには、制御依存関係が必要です。

これを理解するために、グラフ操作を正式に定義しましょう。

グラフ内の操作は、3種類のエッジを介して互いに接続します。入力テンソルは、どのテンソルがopへのデータ入力として機能するかを表す、出力テンソルは、op自体によって作成され、最後に、制御依存関係と呼ばれる特別な種類のエッジです。

現在の操作自体がそれに依存していなくても、現在の操作の前に実行する必要があります。

このAPIは、MPSGraphによって操作が最適化されるのを防ぐ便利な方法も提供します。

これは、バッチ正規化のような機械学習レイヤーを実装するために必要です。

これを実際に見てみましょう。

バッチ正規化は、ネットワークをより安定させ、より速く収束させるためにMLトレーニングで使用される標準層です。

ここでは、トレーニングに使用されるバッチ正規化の計算グラフを参照してください。

最初のステップは、平均と分散を計算することです。

これらは、推論に必要な実行平均と実行分散を更新するために使用されます。 推論に必要です。

ただし、トレーニンググラフの結果はこれらの変数を必要としないため、MPSGraphはそれらを最適化する可能性があります。

制御依存関係を使用して、最終的な正規化演算子の前にそれらを明示的に順序付けすることで、これを解決できます。

このAPIの使用方法を示すコードを含む簡単な例を見てみましょう。

このグラフは指数を示し、演算子を割り当てます。

割り当て演算子は、グラフ内の他の誰によっても使用されません。

だから、それは離れて最適化されるかもしれません。

これを解決する1つの方法は、割り当てをtargetOperationとして明示的に設定することです。

ただし、これにより、開発者はグラフ全体で依存関係をグローバルに追跡する必要があります。

代わりに、新しい制御依存関係APIを使用すると、指数操作を割り当てに依存させることができます。

これにより、targetOperationを持つ必要がなくなり、グラフが最適化されないことが保証されます。

次に、これをコードで見ます。

まず、指数が依存している演算子を定義します。

次に、指数演算子を定義する依存ブロックを作成します。

最後に、このグラフで実行APIを呼び出します。

targetOperationsをグローバルに追跡する必要はないことに注意してください。

制御依存性については、それだけです。

では、ステンシル演算子について話しましょう。

ステンシル操作は、画像畳み込みのようなスライドウィンドウ演算子の一般化です。

これらの演算子は、有限要素法、機械学習、および画像処理アプリケーションに不可欠です。

ここでは、ラプラシアン操作を実装するために一般的に使用される5点の2Dステンシルが見られます。

ここに示されているステンシル演算子は、この7点式3Dステンシル図に示すように、より高い次元にも適用できます。

オペレーターを詳しく見てみましょう。

出力値ごとに、図に示すように、入力テンソルのステンシルウィンドウに対して加重削減を計算します。

オペレータは、argmin/argmaxを含むさまざまなリダクションモードと、反射やclampToZeroを含むさまざまなパディングモードをサポートしています。

MPSGraphは、最適なパフォーマンスのためにMPSカーネル間のステッチを可能にします。

ステッチサポートにより、ステンシル演算子を使用すると、単一のカーネル起動で複雑な数学的操作を表現できます。

そのような例を1つ見てみましょう。

ローカル応答の正規化は、チャネル次元で正規化するために使用されるpytorch opです。

新しいステンシル操作でこれを実装するのは非常に簡単です。

ここでは、この正規化手法のグラフを参照してください。

ステンシル操作の周りの単なる要素賢明な操作であることがわかります。

新しい操作がなければ、複数のディスパッチが必要になります。

現在、ステンシル操作はステッチをサポートしているため、このグラフ全体を1回のディスパッチで起動できます。

ステンシルオペレーターはそれでおそれです。

次に、収集操作の改善を見てみましょう。 収集操作の改善を見てみましょう。

今年は、新しい収集操作がMPSGraphに追加されました。

これらは、非連続したメモリの場所に任意のサイズのスライスを効率的にコピーすることを可能にします。

概念的には、メモリの塊から青でマークされた場所から値を集めています。

これらの収集レイヤーは、埋め込みルックアップと動的マトリックスコピーの効率的な実装を可能にします。

GatherNDは、収集操作の強力な拡張です。

通常の収集は線形インデックスをサポートしていますが、gatherND操作はN次元インデックスを可能にします。

これにより、N次元入力のどこからでもデータをシームレスにコピーできます。

この操作への入力は座標のベクトルであり、各座標は入力テンソルのランクまですることができます。

座標で指定されていない寸法は、スライスコピーになります。

3Dテンソルからの行スライスの収集の例をステップスルーすることができます。

この例では、インデックスは行列座標と行座標に対応する2つの座標を指定します。

列インデックスへの3番目の座標がないため、このgatherNDは行全体をコピーします。

結果テンソルは、入力行列から収集された行の2次元行列です。

GatherNDは、ほぼすべての形態の収集操作を代表し、優れたパフォーマンスを発揮することができます。

たとえば、収集操作を使用して埋め込みルックアップを実装する方法を見てみましょう。

埋め込みルックアップは、提供された入力オブジェクトのセットの埋め込みベクトルを見つけるために使用される一般的な操作です。

一般的に、このレイヤーは言語処理ネットワークで使用され、語彙の各単語を埋め込みベクトルに関連付ける埋め込み行列が生成されます。

語彙内の単語のIDは、収集操作のインデックスとして使用でき、埋め込み行列は入力テンソルです。

各単語IDに対応する行を取得したいのですが、これはギャザーレイヤーを使用して簡単に行うことができます。

座標を1つだけ指定するので、入力単語ごとに行全体がコピーされます。

結果のテンソルは、行に沿った各入力ワードの埋め込みベクトルの2D行列です。

今年導入した新しいMPSGraph操作については、これでおそれです。

では、コンパイルAPIについて話しましょう。

今年は、新しいMPSGraphExecutable APIを導入します。

このコンパイルAPIは、2つの方法でパフォーマンスを向上させます。

まず、開発者がいつグラフをコンパイルするかを制御できます。

第二に、遅延型推論によってコンパイル呼び出しの数を減らすことができます。

では、それぞれを詳しく見てみましょう。

昨年、MPSGraphを定義して実行するための本当に便利なAPIを提供しました。

内部では、評価が初めて要求されたとき、MPSGraphは入力タイプのコンパイルを呼び出し、内部で実行可能ファイルを作成しました。

その後の実行では、MPSGraphはこの実行可能ファイルをシームレスにキャッシュして、コンパイルコストが再び支払われないようにしました。

ユーザーは事前にコンパイルを呼び出すことができるようになったので、コンパイルのタイムラインを選択できます。

コンパイルされた実行可能ファイルを使用すると、MPSGraphExecutableで直接runを呼び出すことができます。

これにより、グラフがコンパイルされたときにユーザーが制御でき、コンパイルされた実行可能ファイルをキャッシュできるため、さらに多くのパフォーマンスを得ることができます。

これをコードで見てみましょう。

ここには、2つのテンソルを追加するための簡単なグラフがあります。

コンパイルするには、操作とともにフィードとターゲットテンソルの型を提供します。

私たちが得るのは、コンパイルされたグラフと実行可能ファイルです。

そして、評価方法も同じように簡単です。

メタルコマンドキューと入力テンソルデータを提供します。

したがって、これらはMPSグラフのコンパイルの基本です。

次に、遅延型推論によるコンパイル呼び出しの数を減らす方法について話しましょう。

型推論は、MPSGraphがユーザーによって指定されていないテンソル形状を決定する必要があるコンパイルパスです。

このグラフでは、2つの2次元テンソルの行列乗算を実行しています。

入力テンソルの形状が表示されます。

しかし、出力テンソルは未知の形状です。

型推論パスが完了すると、入力と操作タイプに基づいて出力テンソル形状が決定されます。

標準ニューラルネットワークでは、ネットワークへの入力が常に同じサイズであるとは限りません。

自然言語処理の場合、文章やシーケンスは長さが異なる場合があります。

CNNでは、異なるサイズの画像が評価されるのが見られます。

今年のコンパイルアップグレードの前に、新しいサイズの画像ごとに、グラフ全体の型推論を行うためにコンパイルが呼び出されます。

コンパイルを制御できるようになったので、開発者は、型推論パスをオフにしてコンパイルを呼び出すことができます。

これにより、各反復で数十秒または数百秒のコンパイル時間を節約し、最高のパフォーマンスを得ることができます。

MPSGraphランタイムは、エンコード中にちょうど間に合うようにタイプを推測し、シームレスに物事を機能させます。

これは、コンパイル時間の節約と最適なグラフの取得のトレードオフです。

以前に共有したコード例でこれをどのように使用できるか見てみましょう。

タイプ推論パスを無効にすることは、図のようにコンパイル記述子を設定することで実現できます。

コンパイルAPIはそれだけです。

最後に、MPSGraphの新しいコントロールフローAPIについて話しましょう。

これらのAPIを使用すると、以前にグラフで評価されたテンソルに基づいて操作を動的にディスパッチできます。

これは、バッチ正規化やリカレントニューラルネットワークなどのアプリケーションで一般的です。

新しいAPIなしで、今日MPSGraphで「whileループ」を実装する方法を見てみましょう。

まず、述語を計算するグラフを作成します。

次に、プレディケートは明示的なメモリ同期を通じてCPU上で評価されます。

述語がtrueの場合、以前に作成されたグラフは新しい入力で再実行されます。

それ以外の場合、述語がfalseの場合、ループは終了し、2番目のMPSGraphが作成され、結果を消費するために実行されます。

新しい制御フローAPIを使用すると、これらすべてのステップを単一のMPSGraph実行の一部として起動できます。

これは、明示的なメモリ同期プリミティブを導入する必要がないため、実装する方が便利です。

それでは、これがどのように潜在的により効率的になるかを見てみましょう。

ここでは、新しいAPIなしで制御フローのタイムラインを見ることができます。

CPU上の最初のカーネルをエンコードします。

カーネルが完了したら、結果を読み取るためにメモリを同期する必要があります。

CPUはGPUの実行が完了するのを待たなければならないため、これは潜在的に非効率的です。

同様に、GPUはCPUの同期とその後のエンコーディングが完了するのを待つ必要があります。

これは各反復で起こります。

それでは、新しいMPSGraph APIを使用する利点を見てみましょう。

CPUエンコードコールを1つだけ実行する必要があります。

述語はGPUタイムラインで評価されるため、同期オーバーヘッドは発生せず、カーネルはバブルなしで起動できます。

では、新しいAPIが何であるかを見てみましょう。

If/else、for loops、while loopsの3つの新しい制御フローAPIを追加しました。

If/elseプリミティブから始めましょう。

私たちは皆、これに精通しています。

述語に基づいて、異なるコードパスが実行されます。

「If」と「else」条件のコードブロックとともに、ブール述語が提供されます。

この述語がtrueの場合、コードのthenブロックを実行します。

そうでなければ、falseの場合、elseブランチが実行されます。

If/else操作は、ニューラルネットワークで非常に便利です。

1つの正規の用途はバッチ正規化操作であり、トレーニングと推論の動作が異なります。

isTraining Booleanを使用すると、ノーマライザーの両方のバリアントを表す単一のグラフを持つことができます。

コードでif/elseブランチを設定する方法を見てみましょう。

2つの入力スカラーテンソルの非常に簡単な例を見てみましょう。

最初のテンソルが2番目のテンソルよりも小さい場合は、操作の合計を返します。

そうでなければ、私たちは差額を返します。

まず、述語を計算し、それをAPIに渡します。

次に、述語が真の場合、thenブロックを計算し、テンソルを追加します。

最後に、述語がfalseの場合、elseブロックを計算し、テンソルを減算します。

次に、forループを実装する方法を見てみましょう。

Forループは、一連の操作を一定回数にわたってループします。

これは、トレーニング中に異なる長さのシーケンスをループしなければならないリカレントニューラルネットワークで一般的です。

forループのnumberOfIterationsを提供する必要があります。

インデックスは0に初期化され、各ループ反復のnumberOfIterationsと比較されます。

numberOfIterationsより小さい場合は、forループの本体を実行し、インデックスを1増やします。

インデックスがnumberOfIterations以上の場合、ループを終了します。

これをコードで実装する方法を見てみましょう。

本当に簡単な例を実装したかったとしましょう。

結果変数を何らかの入力値に初期化します。

次に、4回ループし、毎回結果に別の入力値を掛けます。

まず、2つのグラフテンソルを作成します。

出力テンソルはinput0に初期化されます。

各反復では、このテンソルに入力1が乗算されます。

次に、index 0からindex 3までループを4回実行できるように、numberOfIterationsを4に設定します。

次に、forループの本体を作成します。

これは、単一の反復を表すクロージャを作成することによって行われます。

各反復には、現在の反復のインデックスと、以前の反復の出力が渡されます。

次に、結果を更新して返して、次のイテレーションに渡します。

最後に、これらの引数をすべてグラフ内のforループAPIに渡します。

Body の iterationArguments は input0 テンソルに初期化されることに注意してください。

ループはそれだけです。

では、whileループAPIを見てみましょう。

このプリミティブは、条件が満たされている間に一連の操作を実行します。

このAPIを使用するには、2つのコードブロックを提供する必要があります。

最初のブロックでは、条件は述語でチェックされます。

述語がtrueの場合、afterブロックのwhileループの本体が実行されます。

これは述語を再計算します。

MPSGraphは、beforeブロックの次の反復でこの述語を使用します。

評価された条件がfalseの場合、ループを終了します。

APIでは、本文と条件の評価コードブロックを交換することで、do-whileループを実装することもできます。

本当に簡単な例を実装したかったとしましょう。

結果変数を何らかの入力値に初期化します。

次に、しきい値を超えるまで、ループで毎回結果に乗数を掛けます。

まず、前回の反復の結果を使用して述語を評価するコードブロックを定義します。

また、前回の反復の結果をreturnTensors NSArrayに保存します。

この配列は、述語がtrueの場合に次の反復への入力として使用され、述語がfalseの場合は最終結果として使用されます。

次に、テンソルが乗算されるwhileループの本体を定義します。

製品は、条件ブロックを読み取るために返されます。

最後に、図に示すように、これらすべての引数をwhileループAPIに渡します。

initialInputs引数は、beforeブロックの最初の反復で使用されることに注意してください。

ループの間はそれだけです。

次に、これを実際のアプリケーションでどのように使用できるかを見ていきます。

画像合成は、一般的な画像編集ユーティリティです。

ここでは、オブジェクトがターゲット画像に埋め込まれます。

図に示すように、ソース画像と背景画像から始めます。

次に、ソース画像にマスクを作成します。

ソース画像のこのマスクを背景に直接配置しましょう。

ソース画像の端がはっきりと見えるので、それは見栄えがよくありません。

画像構成を通じて、これらのエッジを滑らかにしたい。

ラプラシアンエッジフィルターと反復線形ソルバーをペアリングすることは、これを達成するための一般的な方法です。

では、詳細を見てみましょう。

ここでは、MPSGraphで画像合成を実行するために必要なパイプラインを確認します。

入力テンソル、背景画像、ソース画像、およびオブジェクトのマスクから始めます。

次に、ラプラシアンエッジ検出器と組み合わせた反復線形ソルバーを使用します。

この一連の操作の出力は、滑らかなエッジを持つ複合画像です。

ラプラシアンエッジフィルターを見てみましょう。 

ラプラシアンエッジフィルターの実装には、一連の重みを持つソース画像のウィンドウ化された縮小が含まれます。

ステンシル演算子は、図のようにこれを実装するために使用されます。

この演算子を使用すると、ソースオブジェクトのエッジを見ることができます。

ここで計算されたエッジは、線形ソルバーへの入力として使用されます。

次に、線形ソルバーを見てみましょう。 

背景画像から始めて、それを線形ソルバーにフィードします。

ソルバーはこの画像を更新し、結果はその後読み戻されます。

ご覧のとおり、これは反復的なプロセスです。

反復が進むにつれて、エッジで完璧なブレンドに到達するまで、ソリューションイメージが改善されます。

ループは、エラーがユーザー定義の許容範囲を下回ると終了します。

これにはwhileループが必要です。

MPSGraph Control Flow APIを使用してこれを実装できるようになりました。

では、デモを見てみましょう。

MPSGraphをiPad Proアプリケーションとして使用した画像合成ユーティリティを実装しました。

上部のソース画像と下のターゲット画像から始めます。

ソースからターゲットにオブジェクトを複製します。

私たちが最初にする必要があるのは、移動したい牛の周りにマスクを描くことです。

これがナイーブなクローンでどのように見えるか見てみましょう。

粗いエッジが見えるので、それはあまり良く見えません。

では、先ほど説明した画像合成テクニックを試してみましょう。

まず、背景画像に初期ソリューションを設定することから始めます。

これを約50回の反復で実行しましょう。

明らかに、ソリューションイメージはまだ収束していません。

さらに約50回の反復で実行しましょう。

エッジが滑らかになるにつれて、これはより自然に見えます。

MPSGraphでのプログラミングの容易さにより、さまざまなテクニックの実験が簡単になります。

背景画像の代わりにクローン画像でソルバーを初期化すると、収束が速くなります。

このスイッチを切り替えることで、この初期化モードを有効にすることができます。

反復カウントを50に再度設定し、ナイーブクローンにリセットすることで、これを実際に見てみましょう。

では、ソルバーを再実行しましょう。

50回の反復後にソリューション画像がかなり良く見えるのを見ることができます。

すでにソースオブジェクトから始めているので、エッジでの出血も少なくなっています。

これは素晴らしいです。

しかし、私たちが本当に望んでいることは、エラー許容度に基づいて収束を自動化することです。

これには、このスイッチを使用して有効にするwhileループが必要です。

私たちは新しいMPSGraph APIでこれを実装しました。

誤差許容差はこのスライダーで制御できます。

図に示すように、0.1に設定しました。

これをナイーブなクローンにリセットしましょう。

今、ソルバーを開始します。

このwhileループでは、反復回数を指定することなく、約80回の反復でソリューションイメージに収束します。

では、この背景に他の動物をクローニングして楽しみましょう。

このかわいい子犬を試してみましょう。

よし、追跡は終わった。

この画像の右下が似合うと思います。

たぶん、私たちは次に鳥を試すことができます。

これは背景の右上に似合うでしょう。

これらすべての画像を含む新しい背景はかなりきれいに見えます。

デモはそれだけです。

要約すると、MPSGraphの採用がどのようにCoreMLとTensorFlowの驚くべきパフォーマンス向上につながったかを示しました。

推論は現在、最大2倍の速さです。

幅広いアプリケーションを可能にするステンシル演算子を含む、便利な新しい計算プリミティブを導入しました。

MPSGraphが提供する新しいコンパイルの柔軟性を示しました。

これにより、推論ネットワークからのレイテンシが削減されます。

そして最後に、MPSGraphのすべての新しい制御フロー機能を示しました。

このAPIは、機械学習ネットワークに加えて、いくつかの線形代数アプリケーションを表現するための鍵です。

私たちは、あなたがこれらの機能をどのように活用するかを見て興奮しています。

ありがとう、そして素晴らしいWWDC 2021をお過ごしください。

[明るい音楽]。