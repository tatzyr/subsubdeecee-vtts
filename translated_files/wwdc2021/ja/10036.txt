10036

♪ ♪

こんにちは。

WWDCのサウンド分析セッションへようこそ。

私の名前はジョン・フアンです。

私はオーディオチームの研究者です。

今日、同僚のケビンと私は、SoundAnalysisフレームワークとCreateMLを通じて利用可能なサウンド分類の強化を紹介します。

2019年には、CreateMLを使用してサウンド分類モデルをトレーニングできるようにしました。

サウンド分類モデルを作成し、Appleデバイスに展開するのが簡単であることを示しました。

このフレームワークを使用すると、すべての計算がハードウェアアクセラレーション用に最適化され、ローカルでデバイス上で行われます。

これは、オーディオがクラウドに送信されないため、ユーザーのプライバシーを保護するのに役立ちます。

サウンド分析フレームワークを活用して、サウンド認識と呼ばれるアクセシビリティ機能を導入しました。

この機能は、アラーム、ペット、その他の家庭の音などの環境で特定の音が聞こえたときにユーザーに通知を提供できます。

これは音の分類の1つのアプリケーションにすぎません。

それで他に何ができるか見てみましょう。

デモアプリは、私のMacの内蔵マイクを使って、環境の音を聴いています。

音声分類器にオーディオを渡し、分類結果をUIに表示しています。

だから、私があなたとチャットしているとき、音声が検出されます。

少し私と一緒に座って、何が起こるか見てください。

快適に過ごしてください。

音楽から始めましょう。

ねえSiri、KarunとMombruの「Catch a Vibe」をプレイして。

現在、KarunとMombruの「Catch a Vibe」を演奏しています。

♪ ♪

♪ああ、ああ、ああ♪

分類器が音楽と歌の音の両方を拾っていることに注意してください。

♪私は誰も知りません♪

♪誰がそんなに正しいと感じているのか♪

♪私を作る人を誰も知らない♪

♪雰囲気をキャッチし、周波数を感じる...♪

さあ、私と一緒にお茶を飲んでください。

♪大丈夫だよ、ベイビー♪

♪私たちは見ることができました♪

♪私たちが正しければ♪

♪あなたの笑顔の仕方について何かあるかどうか確かめてください♪

♪息を止めて、ベイビー、私たちはできるよ♪

♪雰囲気をキャッチし、周波数を感じる♪

♪雰囲気をつかんで、あなたと私だけ♪

♪大丈夫、ベイビー、私たちは見ることができた♪

♪もし私たちがなれたら♪

♪私は言った、私は言った♪

♪それは私の一部です♪

♪あなたが見るすべての部分♪

♪あなたは誇りに思うべきです...♪

これはおいしいお茶です。

♪あなたは私の赤ちゃんです、ジー♪

♪あなたはカートです、なるほど...♪

♪どうしてこうなるの？♪

♪どうしてこうなるの?...♪

ねえ、Siri。止まる。

さて、これらのサウンドカテゴリごとにいくつかのデータを収集し、CreateMLを使用してカスタムモデルをトレーニングしたと仮定するのが妥当です。

はい、それはできましたが、実際には、使用される分類器が組み込まれています。

今年は初めてですが、サウンド分析フレームワークにサウンド分類器が組み込まれています。

アプリでサウンド分類を有効にするのは、かつてないほど簡単になりました。

すべてのプラットフォームでサポートされています。

組み込みの分類器は、開発者のエクスペリエンスを簡素化するためのものです。

高精度モデルを開発するために、大量のデータ、専門的な機械学習とオーディオの専門知識、および多くの計算能力を収集し、ラベル付けする必要がなくなります。

これらの詳細を心配する時間が少なければ少ないほど、アプリのユーザーエクスペリエンスを豊かにするのにより多くの時間を費やすことができます。

健全な分類を可能にするには、数行のコードしかかかりません。

この分類器で何ができるかをお見せします。

あなたが使用できる300以上のカテゴリがあります。

詳しく見てみましょう。 

家畜、家畜、野生動物の音を分類できます。

音楽については、キーボード楽器、打楽器、弦楽器、管楽器など、多くの楽器を認識できます。

グループ活動、呼吸音、発声など、さまざまな人間の音を検出できます。

それから、車、アラーム、道具、液体などの音があります。

これらのすぐに使用できるカテゴリは、あなたが試すことができます。

ケビンに渡して、このサウンド分類器の使い方を説明します。

ありがとう、ジョン。

こんにちは、私はオーディオチームのソフトウェアエンジニアのケビンです。

私が構築した小さなアプリケーションを見て、新しい内蔵のサウンド分類器の使い方をお見せしたいと思います。

ジョンが分類器がカウベルでどれほどうまく機能するかを示すことを望んでいましたが、彼のデモに収まらなかったので、私は別のアイデアを思いつきました。

このセッションの準備中に収集したメディアがMacにいくつかあり、カウベルを含む古い映像があると確信しています。

あなたに見せたいのですが、まずそれを見つけなければなりません。

これは、適切なファイルを見つけなければならず、適切な部分を見つけるために中を見なければならないことを意味します。

では、どうすればいいのでしょうか?

内蔵のサウンド分類器を使用してファイルを読み取り、特定の音が中にあるかどうか教えてくれる簡単なプログラムを作成します。

音が見つかった場合、プログラムは分類器を使用して、それが発生した時間を伝えることができます。

その後、macOSで利用可能なショートカットを使用して、多くのファイルでプログラムを実行するワークフローを作成できます。

私のプログラムが音を見つけると、ワークフローは自動的に報告された検出時間を使用して、音を含むビデオクリップを抽出することができます。

これはカウベルクリップを見つけるのに最適です。

だから、それを実際に見てみましょう。

ここには、ビデオでいっぱいのフォルダがあります。

すべてのファイルを選択し、クイックアクションメニューを使用してショートカットを開始します。

見つけたい音を選択するように頼まれたので、オプションのリストからカウベルを選択します。

今、私のショートカットは実行されており、ほんの数分後、それは私が探している音を見つけ、ファインダーウィンドウで私にそれを表示します。

見てみましょう。 

元気そうだね、ジョン。

私が使ったショートカットを詳しく見てみましょう。 

ショートカットが始まると、認識できるすべての音のリストが収集され、1つを選ぶように求められます。

私の選択を使用して、Finderで選択した各ファイルにアクセスし、内部の音を探します。

音が検出されると、音が発生した頃にビデオから数秒を抽出し、結果のクリップを表示します。

これらのステップのうち、そのうちの2つは組み込みの分類器を使用しています。

これらは、ショートカットがオンデマンドで使用するために、私自身のカスタムアプリケーションに実装した手順です。

ショートカットについては詳しく説明しませんが、もっと知りたい場合は、「Meet Shortcuts for macOS」というタイトルのWWDCセッションを参照してください。

それでは、私のアプリの2つのカスタムアクションの実装を見てみましょう。

最初のアクションは、アプリが認識できるすべてのサウンドを報告します。

アプリは内蔵のサウンド分類器を使用しているため、数百の音を認識できます。

これは私がこれらの音を得るために書いた関数です。

組み込みの分類器を選択できる新しい初期化子を使用してSNClassifySoundRequestを作成します。

このリクエストを受け取ったら、それを使用して、分類器がサポートするサウンドのリストを照会できます。

アプリの2番目のアクションは、ファイル内で音が聞こえたときにショートカットに伝えます。

これを実装するために、私は音の分類を実行し、音がまったく検出された場合、音が最初に検出されたときに報告します。

音の分類を実行するには、3つのオブジェクトを準備する必要があります。

まず、サウンド分類の設定に使用できるSNClassifySoundRequestが必要です。

次に、特定のファイルに分類をターゲットにできるSNAudioFileAnalyzerが必要です。

3番目のオブジェクトには、少し特別な注意が必要です。

分類の結果を処理する独自のオブザーバータイプを定義する必要があります。

今のところオブザーバーをスキップして、ここにこれらのオブジェクトの最初の2つを準備するためのいくつかのコードがあります。

組み込みの分類器を使用してSNClassifySoundRequestを作成し、分類したいファイルのURLを使用してSNAudioFileAnalyzerを作成できます。

この時点で、オブザーバーの準備ができたら、音の分類を開始するのは簡単ですが、オブザーバーを定義することは欠けている部分です。

だから、そうしましょう。

私はここで、NSObjectを継承し、SNResultsObservingプロトコルに準拠した裸のObserverから始めます。

検索したいサウンドラベルでインスタンスを初期化し、CMTimeメンバー変数を追加して、サウンドを検出した時間を格納します。

リクエストを実装するだけです：didProduce結果メソッド。

このメソッドは、健全な分類によって結果が生成されたときに呼び出されるので、SNClassificationResultのインスタンスを受け取ることを期待しています。

結果のclassificationForIdentifierメソッドを使用して、探しているラベルに関する情報を抽出できます。

ラベルに関連する信頼度スコアを照会し、そのスコアが特定のしきい値を超えた場合は、音が検出されたとみなします。

初めて検出に気付いたら、後でショートカットに提供できるように、音が発生した時間を節約します。

それだけで、私のオブザーバーは完成し、ファイル内でいつ音が鳴るかを判断するために必要なすべてのピースを持っています。

この例では、さらに議論したい2つの重要なトピックに触れています。

まず、検出時間について話し、次に検出しきい値について話します。

検出時間から始めましょう。

オーディオを分類すると、信号は重なり合うウィンドウに分割されます。

これらの各ウィンドウについて、どの音が検出され、どの程度自信を持って検出されたかを示す結果が得られます。

また、オーディオのどの部分が分類されたかを示す時間範囲も取得されます。

私のアプリでは、音を検出すると、結果の時間範囲を使用して、音がいつ発生したかを判断します。

しかし、ウィンドウの期間が変わると、時間範囲が影響を受ける可能性があります。

ウィンドウの期間をカスタマイズして、ユースケースに基づいて大きくまたは小さくすることができます。

短いウィンドウは、ドラムタップのような短い音で作業するときにうまく機能します。

これは、小さな時間枠でその音の重要な機能をすべて捉えることができるからです。

小さな窓は重要な情報を切り取らない。

小さなウィンドウの持続時間を使用する利点は、音が発生した瞬間をより密接に特定できることです。

しかし、より長い音で作業する場合、小さなウィンドウの持続時間は適切ではないかもしれません。

たとえば、サイレンには、長期間にわたって上昇ピッチと下降ピッチの両方が含まれている場合があります。

これらすべてのピッチを1つのウィンドウにまとめると、音の分類が音を正しく検出するのに役立ちます。

一般的に、興味のあるサウンドの重要な部分をすべてキャプチャするのに十分な長さのウィンドウ期間を使用するのは良いことです。

ウィンドウの期間を編集したい場合は、SNClassifySoundRequestのwindowDurationプロパティを設定できます。

ただし、すべてのウィンドウ期間がサポートされているわけではないことに注意してください。

異なる分類器は、異なるウィンドウ期間をサポートする場合があります。

SNClassifySoundRequestのwindowDurationConstraintプロパティを読むことで、サポートされているウィンドウ期間を確認できます。

内蔵の分類器は、1/2秒から15秒のウィンドウ持続時間をサポートします。

1秒以上の持続時間は、アプリで分類器を採用する際の素晴らしい出発点です。

次に、信頼のしきい値について話しましょう。

私のアプリでは、その音に対する自信が固定されたしきい値を超えると、いつでも音が検出されると考えました。

私はしきい値に0.5の値を選択しましたが、自分のアプリのしきい値を選択する際に考慮すべきことがいくつかあります。

分類器は同時に複数の音を検出できます。

これが起こると、いくつかのラベルが自信を持って採点していることに気付くかもしれません。

CreateMLを使用して訓練されたカスタムモデルを使用する場合とは異なり、ラベルスコアは1の値に加算されません。

信頼は独立しており、互いに比較すべきではありません。

信頼スコアは独立しているため、異なるサウンドに対して異なる信頼しきい値を選択すると便利かもしれません。

しきい値を選択するにはトレードオフが必要です。

信頼しきい値が高いと、音が誤って検出される確率が低下しますが、十分に強くなかったため、真の検出が見逃される可能性も高まります。

アプリケーションのしきい値を選択するときは、ユースケースでこれらの要因の適切なバランスを達成する値を見つける必要があります。

カスタムウィンドウの期間を設定すると、信頼スコアが変化する可能性があるため、しきい値にも影響する可能性があることに注意してください。

組み込みの分類器を使用する際に覚えておくべき最後のことの1つは、いくつかの音が似ているということです。

分類器が識別できる多数の音の中には、人間であっても、オーディオ単独で区別するのが難しい音のグループがいくつかあります。

可能であれば、あなたが注意を払う音について選択するのが最善です。

アプリが使用されるコンテキストで発生する可能性のあるサウンドのみを監視するようにしてください。

では、ジョンに戻って、サウンドの分類に関するCreateMLの新機能について学びましょう。

ケビン、その素晴らしい例をありがとう。

カウベルのビデオを楽しんでくれてうれしいです。

それでは、CreateMLの新機能、具体的には、組み込みの分類器の力を活用してカスタムモデルを改善する方法を紹介します。

組み込みの分類器は、膨大な数のカテゴリにわたる大量のデータで訓練されました。

したがって、このモデルには、実際には健全な分類に関する多くの知識が含まれています。

この知識はすべて、CreateMLを使用したカスタムモデルのトレーニングに活用できます。

これがどのように機能するかをお見せします。

サウンド分類器は2つの異なるネットワークに分けることができます。

最初の部分は特徴抽出器で、2番目の部分は分類器モデルです。

フィーチャーエクストラクタは、埋め込みモデルとも呼ばれ、ネットワークのバックボーンです。

それはオーディオ波形を取り、それを低次元空間に変換します。

よく訓練された特徴抽出器は、音響的に似た音を空間の近くの場所に整理します。

例えば、ギターの音は一緒に集まりますが、ドラムや車の音から離れて配置されます。

さて、このパイプラインの2番目の部分は分類器モデルです。

特徴抽出器の出力を受け取り、クラスの確率を計算します。

分類器は、組み込みの分類器に埋め込んだような、優れた機能抽出器とペアになっていることから利益を得ます。

組み込みの分類器の機能抽出器を利用できるようにしています。

それはオーディオフィーチャープリントと呼ばれています。

CreateMLで独自のカスタムモデルをトレーニングすると、モデルはオーディオ機能プリントとペアリングされます。

これにより、モデルは組み込みの分類器に含まれるすべての知識の恩恵を受けます。

前世代のフィーチャーエクストラクタと比較して、オーディオフィーチャープリントは全面的に改善されています。

このネットワークは小さくて高速ですが、比較したすべてのベンチマークデータセットでより高い精度を実現します。

また、組み込みの分類器と同様に、オーディオ機能印刷を使用するモデルは、柔軟なウィンドウ期間をサポートします。

長いウィンドウ時間を選択して、サイレンのような音に最適化するか、ドラムタップのような音に短いウィンドウ時間を選択できます。

オーディオ機能印刷は、CreateMLを使用してカスタムモデルをトレーニングするときの新しいデフォルトの機能抽出器です。

ウィンドウの持続時間は、トレーニング中に単一の機能を生成するために使用されるオーディオの長さです。

デフォルトは3秒ですが、ニーズに合わせて調整できます。

CreateMLは、1/2秒から15秒の間のウィンドウの持続時間を選択するオプションを提供します。

カスタムモデルのトレーニングのより詳細な例については、「CreateMLでのサウンド分類モデルのトレーニング」に関する2019年のセッションをご覧ください。

また、サウンド分析フレームワークを使用してカスタムモデルを実行する方法も示します。

サウンド分析のセッションにご参加いただきありがとうございます。

本日、OSに組み込まれた強力な新しいサウンド分類器を導入しました。

それに伴い、CreateMLの機能抽出器をアップグレードしました。

これらは新しい可能性を解き放ち、あなたのアプリでそれらをどうするかを見るのが待ちきれません。

WWDCの残りの部分を楽しんでください。

[明るい音楽]。