10040

♪ベース音楽の演奏♪

♪

セルゲイ・カメンスキー：皆さん、こんにちは、WWDCへようこそ。

私の名前はセルゲイ・カメンスキーで、ビジョンフレームワークチームのソフトウェアエンジニアです。

今日のセッションのトピックは、ビジョンフレームワークが人々の分析にどのように役立つかを示すことです。

今日の議題は2つの主要な項目で構成されています。

まず、ビジョンフレームワークの人材分析技術の概要を説明します。

その間、私たちは特に新しい追加に焦点を当てます。

第二に、新しい人物セグメンテーション機能の詳細なレビューを行います。

まず、人材分析技術から始めましょう。

ビジョンにおける人物分析の礎石は、人物の顔分析です。

ビジョンフレームワークの開始以来、私たちは人間の顔分析機能を追加し、強化してきました。

現在、顔検出、顔ランドマーク検出、顔キャプチャ品質検出を提供しています。

ビジョンフレームワークの顔検出機能は、DetectFaceRectanglesRequestによって公開されます。

私たちの顔検出器は、高精度とリコールメトリックを提供し、任意の向き、異なるサイズ、そして部分的に閉塞された顔を見つけることができます。

これまでのところ、私たちはメガネや帽子のような閉塞をサポートしてきました。

現在、顔検出器をリビジョン3号にアップグレードしており、既存のすべての優れた品質を向上させることに加えて、マスクで覆われた顔も検出できるようになりました。

私たちの顔検出器の主な機能は、もちろん顔のバウンディングボックスを見つけることですが、顔のポーズメトリックを検出することもできます。

以前は、ロールとヨーメトリックのみを提供していました。

ほとんどのメトリックはラジアンで報告され、その値は離散ビンで返されます。

新しいリビジョンの導入により、ピッチメトリックも追加し、全体像を完成させています。

しかし、私たちはそこで止まりませんでした。

また、3つのメトリクスすべてを連続空間で報告しています。

すべてのフェイスポーズメトリクスは、DetectFaceRectanglesRequestを実行した結果であるFaceObservationオブジェクトのプロパティとして返されます。

顔のポーズ検出機能を示すように設計されたデモアプリを見てみましょう。

このアプリは、ビジョンフェイスディテクタを実行してカメラフィードを処理し、結果をラジアンから度に変換した後、フェイスポーズメトリックをユーザーに提示します。

メトリクスの変化をよりよく追跡するために、アプリは赤い色のグラデーションを使用して、顔のポーズメトリクスが正の方向に増加したときに表示し、青色の色のグラデーションを使用して、メトリクスが負の方向に増加したときに表示します。

どちらの場合も、色が明るいほど、メトリックはゼロの位置に近くなります。

各メトリックのゼロ位置は、人がまっすぐ見ているときに、人間の頭の中立的な位置と呼ぶものです。

すでに説明したように、ロール、ヨー、ピッチの3つのフェイスポーズメトリックがあります。

これらの用語は飛行力学に由来し、航空機の重心に関する航空機の原理軸を記述します。

人間の頭のポーズを記述するためにも同じ用語が採用されています。

頭のポーズ、または顔のポーズと呼ばれるものに適用すると、人間の頭の動きを次のように追跡します。

ロールは、この方向に頭の動きを追跡しています。

ロールの最も否定的な値から最も肯定的な値に行くと、背景色が濃い青から水色、ニュートラル、そして明るい赤、そして最後に濃い赤に変わることがわかります。

同様の色の変化は、頭が右または左に曲がっているときに角度を追跡するヨーメトリックで起こっています。

そして最後に、ピッチメトリックは、私の頭が上下にうなずいているときに私の頭の動きを追跡しています。

ここでは、私がスペクトルの最も否定的な端から最も肯定的な端に行くとき、同様の色の変化を再び見ることができます。

顔のランドマーク検出は、私たちの顔分析スイートのもう一つの重要な機能です。

顔のランドマークの検出は、DetectFaceLandmarksRequestによって提供され、最新のリビジョンはリビジョン番号3です。

この改訂は、主要な顔領域をよりよく表し、正確な瞳孔検出を提供するために76点の星座を提供します。

顔分析スイートには、顔キャプチャ品質検出も含まれています。

この全体的な測定は、人間の顔の表情、照明、閉塞、ぼかし、フォーカスなどの属性を考慮に入れます。

これはDetectFaceCaptureQualityRequest APIを介して公開され、このリクエストの最新のリビジョンはリビジョン番号2です。

顔のキャプチャ品質は、同じ主題の比較尺度であることを覚えておくことが重要です。

この機能は、例えば、フォトバーストシリーズから最高の写真を選んだり、フォトライブラリの人を表すのに最適な写真を選んだりするのに最適です。

この機能は、異なる人々の顔を比較するようには設計されていません。

人体分析は、ビジョンフレームワークによって提供される人材分析技術のもう一つの大きなセクションです。

ビジョンは、人体検出、人間のポーズ検出、そして最後に、人間の手のポーズ検出を含む、この分野でいくつかの機能を提供します。

まず、人体の検出を見てみましょう。

この機能はDetectHumanRectanglesRequestを介して提供され、現在は人間の上半身のみを検出します。

このリクエストに新しい機能を追加しているため、このリビジョンをリビジョン番号2にアップグレードします。

新しい改訂では、上半身検出に加えて、全身検出も提供します。

上半身と全身検出の選択は、DetectHumanRectanglesRequestの新しいupperBodyOnlyプロパティを介して制御されます。

このプロパティのデフォルト値は、下位互換性を維持するためにtrueに設定されています。

人体のポーズ検出は、DetectHumanBodyPoseRequestを介してビジョンフレームワークで提供されています。

このリクエストを処理すると、人体の関節の場所のコレクションが提供されます。

改訂番号1は、このリクエストの最新かつ唯一の利用可能な改訂版です。

ビジョンフレームワークは、DetectHumanHandPoseRequestとして人間の手のポーズ検出も提供します。

人体のポーズ検出と同様に、手のポーズ要求の処理は、人間の手の関節の位置のコレクションを返します。

結果の観察に重要なプロパティであるハンドキラリティを追加することで、このリクエストの機能をアップグレードしています。

HumanHandPoseObservationの新しいキラリティプロパティには、検出された手が左か右かの情報が含まれます。

ハンドポーズ検出の詳細を知りたい場合は、「Create MLでハンドポーズとアクションを分類する」セッションを見ることをお勧めします。

これで、人材分析技術スイートの新しいアップグレードの概要が終わります。

今、私たちのセッションの2番目のトピック、つまり人のセグメンテーションに移る時が来ました。

人のセグメンテーションとは何ですか?

非常に簡単に言えば、それは人々を現場から切り離す能力です。

今日、人のセグメンテーション技術には多くのアプリケーションがあります。

たとえば、ビデオ会議アプリの仮想バックグラウンド機能に精通しています。

また、ライブスポーツ分析、自動運転、その他多くの場所で使用されています。

人物セグメンテーションは、私たちの有名なポートレートモードにも力を与えます。

ビジョンフレームワークの個人セグメンテーションは、単一のフレームで動作するように設計された機能です。

ストリーミングパイプラインで使用でき、オフライン処理にも適しています。

この機能は、macOS、iOS、iPadOS、tvOSなどの複数のプラットフォームでサポートされています。

ビジョンフレームワークは、セマンティックパーソンセグメンテーションを実装しています。これは、フレーム内のすべての人に単一のマスクを返すことを意味します。

人セグメンテーションのためのビジョンAPIは、GeneratePersonSegmentationRequestによって実装されています。これはステートフルなリクエストです。

ビジョンフレームワークの従来のリクエストとは対照的に、ステートフルリクエストオブジェクトはフレームのシーケンス全体で再利用されます。

私たちの特定のケースでは、リクエストオブジェクトを使用すると、高速品質レベルモデルのフレーム間の時間的変化を滑らかにするのに役立ちます。

ビジョンフレームワークが提供するPerson Segmentation APIを見てみましょう。

このAPIは、すでに身近で確立されたパターンに従います。

リクエストを作成し、リクエストハンドラーを作成し、リクエストハンドラーでリクエストを処理し、最後に結果を確認します。

GeneratePersonSegmentationRequestオブジェクトのデフォルトの初期化は、リビジョン、qualityLevel、およびoutputPixelFormatプロパティをデフォルト値に設定するのと同じです。

すべてのプロパティを1つずつ見直しましょう。

まず、リビジョンプロパティです。

ここでは、リビジョンをリビジョン番号1に設定します。

新しいリクエストタイプを扱っているため、これはデフォルトであり、利用可能な唯一のリビジョンです。

今日は技術的には選択の余地はありませんが、将来的に決定論的な行動を保証するように明示的に設定することを常にお勧めします。

これは、新しいリビジョンが導入された場合、デフォルトも利用可能な最新のリビジョンを表すように変更されるためです。

2つ目はqualityLevelプロパティです。

ビジョンAPIは3つの異なるレベルを提供します。正確で、これもデフォルトレベルです。バランスが取れています。そして高速です。

ユースケースに関しては、計算写真に正確なレベルを使用することをお勧めします。

これは、可能な限り最高の品質を達成したいユースケースであり、通常は時間に制限されません。

同様のロジックを使用して、ビデオフレームごとのセグメンテーションにはバランスの取れたレベルが推奨され、ストリーミング処理には高速です。

3番目のプロパティは、出力マスク形式です。

結果のマスクを詳細に確認しますが、ここでは、クライアントとして、結果のマスクが返される形式を指定できることに言及したいと思います。

ここには3つの選択肢があります。典型的な0〜255の量子化範囲を持つ符号なし8ビット整数マスクと、2つの浮動小数点マスク形式です。1つは32ビットの完全精度で、もう1つは16ビットの半精度です。

16ビットの半精度は、Metalを使用したさらなるGPUベースの処理に直接挿入できる縮小メモリ浮動小数点フォーマットを提供することを目的としています。

これまでのところ、個人セグメンテーション要求を作成、設定、実行する方法を学びました。

今、結果を見る時が来ました。

人のセグメンテーション要求を処理した結果は、PixelBufferObservationオブジェクトの形式になります。

PixelBufferObservationは観測から派生し、重要なpixelBufferプロパティを追加します。

このプロパティに格納されている実際のCVPixelBufferオブジェクトは、個人セグメンテーション要求が設定されたのと同じピクセル形式です。

人セグメンテーション要求の処理は、セグメンテーションマスクを生成します。

元の画像と、個人セグメンテーション要求の実行によって生成された3つの異なる品質レベルマスクを見てみましょう。

速く、バランスが取れていて、正確です。

ズームインして、各マスクの詳細を見てみましょう。

予想通り、高速からバランスのとれた、そして最終的には正確になると、マスクの品質が向上し、より多くの詳細が見え始めます。

それでは、品質とパフォーマンスの関数として、さまざまなマスクレベルを調べてみましょう。

高速からバランスのとれたもの、そして最終的には正確に移行すると、マスクの品質は向上しますが、リソースの使用量も向上します。

ダイナミックレンジ、マスクの解像度、メモリ消費、処理時間はすべて、マスクの品質が上がると上がります。

これは、セグメンテーションマスクの品質とマスクの計算に必要なリソース消費の間のトレードオフを表しています。

だから、あなたはすでにマスクの生成とその特性についてすべてを知っています。

マスクで実際に何ができますか?

3つの画像から始めましょう。

入力画像、入力画像を処理して得られたセグメンテーションマスク、および背景画像。

私たちがしたいのは、マスク領域の外側の領域の元の画像の背景を別の画像の背景に置き換えることです。

そのようなブレンド操作を実行すると、元の画像の若者がビーチの遊歩道から森に運ばれます。

このブレンドシーケンスはコード内でどのように見えますか?

まず、関連するすべての処理を行い、入力画像、マスク、背景の3つの画像がすでにあると仮定しましょう。

次に、マスクと背景の両方を元の画像のサイズに拡大縮小する必要があります。

次に、Core Imageブレンドフィルターを作成して初期化します。

あなたはおそらく、私が赤いマスクで私のブレンドフィルターを作成したことに気づいたでしょう。

これは、すべてのマスクがそうであるように、CIImageが1つのコンポーネントPixelBufferで初期化されると、デフォルトで赤いチャンネルを持つオブジェクトが作成されるためです。

最後に、結果を得るためにブレンド操作を実行します。

ビジョンフレームワークで個人セグメンテーション機能を使用する方法を見てみましょう。

ダウンロード可能な2番目のデモアプリは、顔のポーズメトリック検出と新しい人物セグメンテーション機能を兼ね備えています。

このアプリは、顔検出と人物セグメンテーションを実行してカメラフィードを処理します。

次に、エンドセグメンテーションマスクを取り、それを使用してマスクピクセルの外側の領域の背景を別の色に置き換えます。

使用する背景色の決定は、任意の時点でのロール、ヨー、ピッチの値の組み合わせから行われます。

私は現在、テーブルと椅子のある部屋にいて、デモアプリは、私の頭の位置に対応するカラーミックスである新しい背景の上に私のセグメント化されたシルエットを示しています。

ロール、ヨー、ピッチの変化を追跡するかどうか見てみましょう。

私がこのように頭を向けるとき、ロールは背景色ミックスの決定に大きく貢献します。

頭を左右に回すと、ヨーが主な貢献者になります。

そして最後に、頭を上下にうなずくと、ピッチが主要な貢献者になります。

ビジョンフレームワークは、個人セグメンテーションAPIを提供する唯一の場所ではありません。

同じ技術で駆動される同様の機能を提供する他のいくつかのフレームワークがあります。

それぞれを簡単に見てみましょう。 それぞれを見てみましょう。

まずはAVFoundationです。

AVFoundationは、フォトキャプチャセッション中に、一部の新世代のデバイスで個人セグメンテーションマスクを返すことができます。

セグメンテーションマスクは、AVCapturePhotoのPortraitEffectsMatteプロパティを介して返されます。

それを取得するには、まずそれがサポートされているかどうかを確認する必要があります。もしそうなら、それの配信を有効にしてください。

人物セグメンテーションAPIを提供する2番目のフレームワークはARKitです。

この機能は、A12 Bionic以降のデバイスでサポートされており、カメラフィードを処理するときに生成されます。

セグメンテーションマスクは、ARFrameのsegmentationBufferプロパティを介して返されます。

取得しようとする前に、ARWorldTrackingConfigurationクラスのsupportsFrameSemanticsプロパティを調べて、サポートされているかどうかを確認する必要があります。

3番目のフレームワークはコアイメージです。

Core Imageは、Vision personセグメンテーションAPIの上に薄いラッパーを提供しているため、Core Imageドメイン内でユースケース全体を実行できます。

Core Image APIを使用して個人セグメンテーションを実装する方法を見てみましょう。

セグメンテーションを実行するために画像をロギングすることから始めます。

次に、person segmentation CIFilterを作成し、inputImageを割り当て、フィルタを実行してセグメンテーションマスクを取得します。

人物セグメンテーションAPIとApple SDKの複数のバージョンをレビューしたところです。

それぞれがどこで使用できるかをまとめてみましょう。

AVFoundationは、AVCaptureSessionを搭載した一部のiOSデバイスで利用できます。

キャプチャセッションが実行されている場合は、これが選択できます。

ARKitアプリを開発している場合は、セグメンテーションマスクを取得できるARセッションがすでにあるはずです。

この場合、ARKit APIが推奨されます。

Vision APIは、オンラインとオフラインのシングルフレーム処理のために複数のプラットフォームで利用できます。

そして最後に、Core ImageはVision APIの薄いラッパーを提供します。これは、Core Imageドメイン内にとどまりたい場合に便利なオプションです。

他のアルゴリズムと同様に、人のセグメンテーションにはベストプラクティスがあります。言い換えれば、それが最もよく機能する一連の条件です。

人セグメンテーション機能の使用を計画している場合、これらのルールに従おうとすると、アプリはより良いパフォーマンスを発揮します。

まず、おそらく自然な閉塞で、すべての人々がほとんど見えるシーンで最大4人をセグメント化しようとする必要があります。

第二に、各人の高さは画像の高さの少なくとも半分で、理想的には背景と比較して良いコントラストでなければなりません。

そして第三に、彫像、人の写真、遠くにいる人などの曖昧さを避けることをお勧めします。

これで私たちのセッションは終わりです。

今日学んだことを簡単に見てみましょう。そして、私たちが学んだことを簡単に見てみましょう

まず、マスクされた顔検出、フェイスピッチメトリックの追加、すべてのフェイスポーズメトリックを連続空間で報告するなどのアップグレードに焦点を当てながら、ビジョンフレームワークの人物分析技術の概要を把握しました。

また、人間の手のポーズ検出に新しい手のキラリティメトリックを導入しました。

第2部では、Visionフレームワークに追加された新しい人物セグメンテーションAPIを深く掘り下げました。

また、同様の機能を提供する他のAPIについても検討し、それぞれが使用できるガイダンスを提供しました。

このセッションを見ることで、アプリを開発するための新しいツールを学び、すぐに試してみることを本当に熱望していることを願っています。

今日を終える前に、見てくれてありがとう、幸運を祈ります、そしてWWDCの素晴らしい残りをお過ごしください。

♪