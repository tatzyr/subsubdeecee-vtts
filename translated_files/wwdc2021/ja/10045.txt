10045

♪ベース音楽の演奏♪

♪

アレックス・テレク:こんにちは、私はアレックスです。

私はShazamチームのエンジニアです。

このセッションにご参加いただきありがとうございます。

今日は、カスタムカタログ認識を使用してShazamKitを使用してアプリのカスタムオーディオエクスペリエンスを作成する方法を紹介します。

このセッションでは、カタログ、署名、メディアアイテムなど、既存のShazamKitの概念の一部を使用します。

まだそれらに慣れていない場合は、「Explore ShazamKit」トークをチェックしてください。

今日取り上げるものを見てみましょう。私たちは何をカバーするかを見てみましょう。

カスタムオーディオとメタデータを使用してカタログを作成する方法について説明します。

マイクとAVFAudioフレームワークを使用してオーディオを録音するときに、オーディオを独自のカスタムカタログに一致させる方法を学びます。

次に、アプリをカスタマイズして、コンテンツをカスタムオーディオに同期させます。

最後に、カスタムカタログを扱う際に使用できるベストプラクティスのいくつかを取り上げます。

これはコードアロングです。

開発者ポータルには、このセッションを通して使用するプロジェクトがあります。

始める前にプロジェクトをダウンロードすることをお勧めします。

学習がますますデジタルになるにつれて、私たちは子供たちを夢中にさせる方法を考え出す必要があります。

Apple TVでビデオを再生して、適切なタイミングで質問を表示するコンパニオンアプリがあればどうでしょうか？

今日は、カスタムカタログ認識を使用して教育ビデオに同期して反応するリモートアプリを構築する方法を紹介します。

まず、カスタムカタログとは正確に何であり、どのように構築するのですか?

カスタムカタログは、任意のオーディオから生成する署名のコレクションです。

署名ごとに関連するメタデータを追加することもできます。

カスタムカタログに署名を追加するには、SignatureGeneratorオブジェクトを使用できます。

オーディオバッファをシグネチャに変換します。

まず、シグネチャジェネレータを作成し、audioEngineのinputNodeでinstallTap機能を使用して、バッファとaudioTimeをジェネレータに追加します。

バッファパラメータは、inputNodeの出力からキャプチャされたオーディオのバッファです。

audioTimeは、バッファがキャプチャされた時刻です。

audioFormatを指定するときは、サポートされているサンプルレートの1つでフォーマットがPCMであることを確認してください。

ジェネレータの署名関数を呼び出すと、オーディオバッファが署名に変換されます。

私たちはこれを参照署名と呼び、カスタムカタログに追加することができます。

Shazamsignatureファイルを使用して、カタログに署名を追加することもできます。

これは、デバイス間で共有できる不透明なファイルです。

ShazamKitでカスタムカタログを簡単に採用できるように、このセッションでは、このファイルを含めました。

始める前に、ダウンロードしたプロジェクトを開いて、そこに何があるか見てみましょう。

質問オブジェクトを詳しく見てみましょう。 

質問は、アプリ内のカスタムコンテンツを表します。

まず、タイトルとオフセットがあります。

タイトルは、ビデオのセクションを説明する文字列です。

オフセットは、このセクションが表示される時刻です。

例えば、45秒で、先生は数学の方程式について話し始めます。

そのタイトルと45をオフセットとして質問を作成します。

方程式は、数学の方程式を示す教育の瞬間を表します。

これを増分ビルディングブロックとして使用できます。

たとえば、方程式の左側と右側を異なるオフセットで表示したい場合があります。

最後に、answerRangeとrequiresAnswerは、インタラクティブなUIがいつ表示されるかを示すために使用されるので、子供たちは質問に答える練習をすることができます。

これが私たちの教育ビデオでどのように見えるかを見てみましょう。

最初の質問は14秒から始まります。

私は21秒で1つの赤いリンゴを持ち、25秒で3つの緑のリンゴを追加します。

最後に、31秒で、学生は質問に答える機会があります。

ビデオは通常、時、分、秒でフォーマットされるので、ここでやったようにオフセットを作成するには、まず時間を秒に変換する必要があります。

たとえば、「3分14秒とは何ですか？」など、Siriに助けを求めることができます。

では、コードに飛び込んで、カスタムカタログを使い始める方法を見てみましょう!

まず、メタデータが関連付けられた署名を追加してカタログを作成します。

ここには、カタログを作成する機能を備えたCatalogProviderがあります。

カタログに追加する参照署名は、FoodMath.shazamsignatureと呼ばれます。

そのファイルをロードして、そこから署名オブジェクトを作成しましょう。

それを取得したら、メディアアイテムを使用してメタデータを定義します。

タイトルやサブタイトルなど、定義済みのメディアアイテムのプロパティキーをいくつか設定します。

これは教育ビデオを説明するつもりです。

また、教師とエピソードの2つのカスタムキーを使用して、SHMediaItemPropertyに拡張機能を作成しました。

エピソード番号と教師の名前を設定すると、カタログの内容がさらにカスタマイズされます。

あなたが今しなければならないのは、customCatalogオブジェクトを作成することだけです。

次に、addReferenceSignatureを呼び出し、署名とmediaItemオブジェクトを渡します。

これにより、作成したばかりのメタデータが、ディスクからロードした参照署名に関連付けられます。

完璧！

それを整えたので、オーディオをカタログに照合し始め、その結果を実際に見ることができます。

では、マッチャーを開きましょう。

マイクからの入力音声を、作成したばかりのカスタムカタログの内容と一致させます。

マイクからオーディオをキャプチャするには、AVFAudioのAVAudioEngineを使用できます。

このプロジェクトでは、すでにInfo.plistファイルにマイクの使用に関する説明を追加しました。

また、マッチャーには、マイクの許可を要求し、オーディオセッションを設定するためのコードを含めました。

まず、マッチの更新を受け取るには、セッションオブジェクトを作成し、デリゲートを設定します。

マッチ関数は、以前に作成したカスタムカタログを取るので、それをセッションに渡すことができます。

これで、audioEngineのinputNodeのinstallTap機能を使用してオーディオを一致させる準備が整いました。

この関数は、マイクから変換されたオーディオであるaudioBufferと、バッファがキャプチャされた時間であるaudioTimeを返します。

次に、セッションでmatchStreamingBufferを呼び出し、オーディオバッファとオーディオ時間をパスします。

提供されたオーディオが連続していることを確認するために、セッションによって検証されるため、利用可能な時間を含めることをお勧めします。

最初にセッションデリゲートを設定したので、更新を処理するために、セッションデリゲートからセッション:didFind match:関数を実装できます。

このため、MatchResultというオブジェクトを作成しました。

セッションによって返されるMatchedMediaItemが含まれています: didFind match: 関数、これはカタログの参照署名に関連付けられているメタデータです。

エピソード番号や先生の名前など、先ほど作成した詳細が含まれます。

マッチからのみ生成でき、それに関連する追加情報が含まれています。

また、MatchResultには、先ほどお見せした質問オブジェクトがあります。

これは、数学の方程式を持つビデオのセクションを表しています。

これを使用して、試合に関連するコンテンツを検索します。

したがって、デリゲート内では、最初のMatchedMediaItemオブジェクトを取るようにMatchResultを設定し、今のところ、質問には何も設定しません。

さあ、ビルドして実行して、試合の動作を見てみましょう。

これは私たちのFoodMathアプリで、学生が利用できるエピソードのリストがあります。

私はビデオを再生することができ、同僚のニールと一緒に、いくつかの数学の問題を解くことを学ぶことができます。

ニール、今日は私たちに何がありますか？

ニール：フォーマットは、私はあなたに質問をします、あなたはそれについて考える時間があるでしょう、そして、あなたがそれを正しくしたかどうかを確認します

私たちのアプリがあれば、あなたも一緒に遊ぶことができます。<私がビデオを始めたとき、アプリは私たちがエピソード3「Count on Me」を聴いていることを認識しました。

これはすごい！

次に、Questionオブジェクトを使用して、オーディオの特定のオフセットに表示するセクションを把握します。

MatchedMediaItemを使用して、どのビデオを見ているかを知りますが、predictedCurrentMatchOffsetなどの試合に関する追加情報も含まれています。

これは、秒単位の時間間隔として表される参照署名の自動更新位置です。

これを使用して、ビデオのどこにいるかを把握し、関連する質問オブジェクトを見つけることができます。

コードに戻ると、デリゲートコールバックで、nilを設定する代わりに、述語CurrentMatchOffsetの直後に来る最後の質問を見つけたいです。

質問のオフセットを使用して値を比較できます。

session:didFindMatchは、同じ一致で複数回呼び出すことができます。

では、新しいQuestionオブジェクトを取得したときにのみ結果を更新するフィルタを実装しましょう。

それを手に入れたら、結果を値で更新できます。

それでは、それがどのように見えるか見てみましょう。構築して実行します。

今回は、加算について学びたいです。

もう一度ビデオを再生して、質問の内容がビデオと同期して表示されるかどうかを確認します。

ニール：質問1。始めましょう。

今日はお店に行って、リンゴが好きだったので、赤いリンゴを1つ買いました。そして、緑のリンゴを1つ、2つ、3つ買いました。

全部で何個のリンゴを買いましたか？

あなたのタイマーが始まります...今。<アレックス：今は質問の時間です。1足し3って何？

5つかな？

ああ。いいえ、私はそれを間違えました。もう一度やってみましょう。

ビデオを巻き戻して、今回はもっと注意を払います！

ニール：質問1。始めましょう。

今日はお店に行って、リンゴが好きだったので、赤いリンゴを1つ買いました。そして、緑のリンゴを1つ、2つ、3つ買いました。

全部で何個のリンゴを買いましたか？

あなたのタイマーが始まります...今。<アレックス：もう一度聞いたので、答えは4だと知っています。

この質問が簡単すぎる場合はどうなりますか?

先にスキップして、ニールが私たちに教えるためにもう少し複雑なものを持っているかどうかを確認します。

ニール：質問4。最後の質問です。

だから今日、私はかなりお腹が空いています。

だから私は14個のリンゴを買うことに決めました。

1... 2... 3... 4 -- < アレックス：それはたくさんのリンゴですもう少し先に行かせてください。

20秒先をスキップします。

ニール：それで、私はさらに28個のリンゴを買うことにしました。

1...2...3...

4...5...6...

26...27...

28個のリンゴ。

全部で何個のリンゴを買いましたか？

あなたのタイマーは今始まります。<アレックス：さて、それは素晴らしい質問です。

フォローしましたか?

お気に入りの番号で行くよ！

その通りです！

究極の質問に対する答えは42です!

それは簡単です:学生がビデオのどこにいても、リモートアプリはコンテンツに追いつき、更新します。

カスタムカタログを使用する際のベストプラクティスのいくつかを取り上げましょう。

カスタムカタログは、shazamcatalogファイル拡張子を使用してデバイス間でシームレスに共有できます。

ファイルURLを使用してディスクにロードして保存したり、ネットワーク経由で配信したりできます。

リモートWebサービスを使用する場合は、まずカタログをダウンロードしてから、カスタムカタログオブジェクトに追加機能を使用することをお勧めします。

ネットワーク上で利用可能なカタログが存在しない場合は、必ずローカルカタログを提供してください。

カタログは、ユースケースに固有のデータを返すためにカスタムキーを保存できます。

カタログに追加するデータが有効なプロパティリスト値の1つであることを確認してください。

matchStreamingBufferを使用する場合、ShazamKitはオーディオストリームを一致させ、パフォーマンスと検索の強度のバランスを取り、署名の生成と自動更新のすべての作業を行います。

だから今、あなたは教育ビデオに同期された完全なアプリを構築し、学生が現在署名とカスタムカタログのみを使用している場所にコンテンツを更新しました。

これは可能な多くの例の1つに過ぎず、ShazamKitを使用して何を構築するかを本当に楽しみにしています。

ありがとう、そして素晴らしいWWDCをお過ごしください。

♪