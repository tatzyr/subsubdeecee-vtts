10037

♪ベース音楽の演奏♪

♪

タオ・ジア：こんにちは、私の名前はタオです。

今日、同僚のジャックと私は、Create MLフレームワークを使用した動的iOSアプリの構築について話します。

では、アプリが動的であるとはどういう意味ですか?

ダイナミックアプリは、ユーザーにアプリの特定の要素をカスタマイズする柔軟性を与えるアプリです。

ダイナミックアプリはまた、さまざまなユーザーのニーズに合わせてコンテンツを調整します。

これらの適応可能なアプリ内機能は、ユーザーに合わせて、よりインテリジェントでパーソナライズされた体験を提供します。

単純なヒューリスティックと事前定義されたルールによって、そのような特定の体験を提供できます。

しかし、多くの場合、これらのアプローチは、背景や好みが異なる可能性があるため、すべてのアプリユーザーにとって最高の体験を提供できない場合があります。

一方、機械学習技術を使用すると、ユーザーデータから直接学習するモデルを作成できます。

これは多くの場合、より一般化可能であり、ヒューリスティックや事前定義されたルールよりも多くのユーザーに適している可能性が高い。

では、そのような経験を提供するためにどのようなツールを使用できますか?

Macで利用可能なCreate MLアプリを使用すると、トレーニングデータを選択して列車ボタンを押すだけで、モデルを簡単に作成できます。

豊富なテンプレートセットを通じて、あらゆる種類のモデルタイプをサポートしています。

このアプリは、機械学習モデルの加速トレーニングを提供するCreate MLフレームワークの上に構築されています。

Create ML FrameworkはもともとmacOS Mojaveで導入され、モデルをSwiftコードとmacOSアプリ内からトレーニングできるようにしました。

そして今、私たちはそのフレームワークをiOS 15とiPadOS 15に導入しています。

デバイスで利用可能で、アプリはあらゆる種類の新しくてダイナミックなことを行うことができます。

言い換えれば、デバイス上のモデルを作成するために、アプリケーションから直接プログラマティックAPIにアクセスできます。

それはあなたのアプリにあなたのユーザーから学び、したがってあなたのユーザーに適応する機能を与えます。

最後になりましたが、最も重要なことは、ユーザーデータがデバイスを離れる必要がないことです。したがって、ユーザーのプライバシーは保持されます。

さあ、飛び込みましょう。

Create MLにはさまざまなタスクがあります。

これがmacOSで利用可能なすべてのものであり、これらは現在iOSで利用可能です。

その中には、画像、音声、テキストの分類器などの一般的なタスクがあります。

最近追加されたものには、スタイル転送だけでなく、今年のハンドポーズとハンドアクション分類器の新しい追加が含まれます。

これらのツールを使用すると、多くの興味深いアイデアやユースケースがあります。

ここにいくつかの例があります。

画像分類を使用すると、アプリは子供のお気に入りのぬいぐるみがどのように見えるかを学び、一緒に彼らの冒険についての物語を作成するのを助けるために、それらのより多くの写真を見つけるのに役立ちます。

テキスト分類器は、ユーザーが過去のアクションから学んだ提案されたタグとフォルダで書いたメモをすばやく整理するのに役立ちます。

今年新しく追加されたハンドアクション分類器は、カスタムハンドアクションでアプリ内の視覚効果をトリガーする力をユーザーに与えることができます。

iOSのCreate MLでできるクールなことはたくさんありますが、デモで私が何を意味するのかを示す方が良いです。

私はフォトブースアプリに少し似ているアプリを持っていますが、カスタマイズされたフォトフィルターを作成できるため、よりダイナミックです。

それがどのように機能するかをお見せしましょう。

ここ私のiPadでは、Create MLスタイルの転送タスクを使用してMacでトレーニングした既存のフィルターのリストが上部に表示されます。

それらのそれぞれは、フィルターの作成に使用される特定のスタイル画像で表されます。

下部にあるアプリは、写真を撮ったり選択したりして、これらのフィルターを試す写真を待っています。

今すぐ写真を撮らせてください。

自撮りはいかがですか？

これらのフィルターがどのように見えるか見てみましょう。

まず、この波形の最初の写真をクリックしてください。

ああ、顔と髪に水滴が滴り落ちました。昔のマイアミでの休暇を思い出します。

このバーディーの写真はどうですか？

私がどれほどカラフルか見てください。

割れた氷のように見えるこの3枚目の写真はどうですか？

ああ、私はかっこよくて凍って見える。

今、これらは本当に楽しそうに見えますが、私はまだ何かを見逃していると感じています。

選択した写真を使ってフィルターを作成できるとしたら？

これにより、このアプリを使うのが本当に楽しくなるでしょう。

試してみましょう。

私は娘が3歳の時に描いたこの絵を持っています。

私は本当に質感と色が大好きです。

私は娘の芸術的なスタイルでどのように見えるか興味があります。

この「+フィルター」ボタンをクリックし、カメラを選択して写真を撮ります。

「写真を使う」

今、フィルターが作成されています。

ボンネットの下では、カスタマイズされたスタイル転送モデルをトレーニングしています。

それがどのように機能するか説明しましょう。

まず、単一のスタイル画像を選択します。

私が使ったスタイルイメージは娘の絵です。

次に、これらの画像の元のコンテンツを保存しながらスタイルを適用する方法を学ぶために、モデル用のコンテンツ画像のセットを提供する必要があります。

このデモでは、風光明媚な写真やセルフィーなど、アルバムから数十枚の写真を使用しました。

ペットの写真など、他の写真タイプにスタイルを適用したい場合は、コンテンツセットにそのような写真をいくつか含めることもできます。

次に、アプリケーションのシナリオに応じて、フィルタータイプを画像またはビデオとして選択します。

このデモでは、静的な写真にスタイルを適用したいので、画像を選びました。

また、スタイルの強さとスタイル密度、および反復回数を試して、スタイル化とオリジナルのコンテンツのお気に入りの組み合わせを得ることもできます。

これらのパラメータの設定方法の詳細については、昨年のWWDCセッションを参照してください。

では、新しく作成したフィルターを私の写真で試してみましょう。

うわー、それが私の娘の絵の見方です。

それは実際にこれらの質感と色を拾いました。

別の写真を試してみるのはどうですか？

私は娘が一緒に遊ぶのが本当に大好きなこのウサギを持っています。

バニーと一緒にセルフィーを撮ってフィルターを塗るのはどうですか？

バニーも彼女の絵によって様式化されました。

これを彼女に見せて、彼女の他の絵を試着するのが待ちきれません。

とても楽しいでしょう。とても楽しいでしょう

このデモでは、iOSのCreate MLフレームワークで利用可能なスタイル転送モデルを活用して、カスタマイズされた写真フィルターを作成する方法を紹介しました。

それで、それはコードでどのように見えますか?

まず、1つのスタイル画像と一連のコンテンツ画像を指定するトレーニングデータソースを定義します。

次に、セッションパラメータを定義して、チェックポイントを保存する場所などを指定します。

次に、これらのパラメータを使用してトレーニングジョブを定義します。

最後に、トレーニングジョブを派遣し、正常に完了したら、トレーニングされたモデルを保存して画像を様式化し、Core MLモデルをコンパイルしてインスタンス化し、予測を開始します。

そして、それだけです。

これは、Create MLフレームワークのスタイル転送APIを使用して、カスタマイズされた写真フィルターを作成するために使用したものです。

他のタスクは、同様のAPIパターンに従います。

これまでのところ、画像、テキスト、オーディオ、ビデオなどのリッチメディアデータタイプからモデルを作成できるタスクについて話しました。

しかし、あなたのアプリがそのようなデータタイプと相互作用しない場合はどうなりますか?

同僚のジャックを招待して、このような場合にアプリをダイナミックにする方法について話しましょう。

ジャック・カックラー:ありがとう、タオ。

これまでに取り上げたタスクに加えて、iOSのCreate MLフレームワークは、構造化された表形式データの分類器と回帰器もサポートしています。

これらがよりダイナミックなアプリ体験を生み出す方法の例を見てみましょう。

まず、分類器と回帰器に関するいくつかの背景。

分類器は、トレーニングデータセットのデータから特定のクラスを予測することを学習します。

回帰器は似ていますが、離散クラスラベルの代わりに数値を予測することを学習します。

ここでは、一般的な表形式データから分類器と回帰器を訓練するためのAPIがあり、さまざまなシナリオで使用できます。

特に、iOSでのCreate MLは、これらのそれぞれに4つの異なるアルゴリズムを提供します。

一般的な表形式モデルでの作業は、モデルで使用する機能と目標値を決定する必要があるため、使用するにはもう少し作業が必要です。

しかし、これはしばしば簡単です。

パーソナライズされたエクスペリエンスを追加するために、表形式の回帰を使用するアプリを考えてみましょう。

これは、レストランから食事を注文するためのシンプルなアプリです。

このアプリには、その地域にレストランがあります。

これはアメージング・タイという地元のタイ料理レストランです。

選択すると、アプリにはレストランから注文できる料理と各料理に関する情報が表示されます。

シンプルなアプリですが、もっと良くできるとしたらどうでしょうか？

本当に素晴らしいのは、時間が経つにつれて私のアプリが私の行動を学び、私が好もうと思うかもしれないインテリジェントなレストランや料理の提案を表面化させるのに役立った場合です。

これは、シンプルなアプリから本当にダイナミックな体験にこれを取るでしょう。

アプリで表形式の回帰をトレーニングすることで、これを達成できます。

私は3種類の情報を取り、それらを構造化されたテーブルにまとめてモデルを訓練し、新しいダイナミックな体験を提供します。

1つ目はコンテンツで、これは私がアプリにロードしたデータです。

私たちのレストランアプリの場合、それは料理に関する情報です。

2つ目は文脈です。

この場合、ユーザーが注文している時刻です。

最後に、ユーザーの注文履歴を追加し、デバイス上でユーザーのためだけに調整されたエクスペリエンスを作成します。

コンテンツとコンテキスト、および過去のユーザーインタラクションを組み合わせることで、将来のインタラクションを予測できます。パーソナライゼーションの絶好の機会であり、この場合、ユーザーが将来気に入るかもしれない料理を予測するのに役立ちます。

モデルが追加されたアプリに戻りましょう。 ではモデルが追加されています。

今日は昼食を注文して、ピザが食べたい気分です。

私は食事をランチに設定し、ピザパーラーを選択し、マルゲリータピザを選んで注文します。

このウィンドウには、表形式の回帰を訓練している情報がいくつかあります。

内容は、この料理のキーワードです。材料のようなもの - トマト、モッツァレラ - だけでなく、レストラン自体 - ピザパーラー - そして食べ物のジャンル - ピザ。

このモデルのコンテキストは時間帯です。

これは昼食からのものです、そして今、私はこれらが昼食時に好きかもしれないものであることを私のモデルに教えました。

最後に、私の相互作用は、他の料理ではなく、この料理を注文したということです。

私が訓練している回帰者は、私が注文するかもしれない各料理の好みのスコアを予測しています、そして今日、私は他の料理ではなく、この料理を注文したことを学びました。

メイン画面に戻ると、モデルはすでに訓練されており、私だけの料理を提案する新しいウィンドウがあります。

私が実際に注文した料理 - マルゲリータピザ - は最初のお勧めですが、次のお勧めは全く別のレストランのカプレーゼサンドイッチです。

他のいくつかのピザも一番上にあります。

別の例を挙げてみましょう。

今、夕食を注文していると言ってください。

今回はアメージングタイからイエローカレーを注文します。

これで、モデルが再び更新されました。

それは私が注文している時間帯の文脈で、私の新しい好みを学びました。

注文したばかりのイエローカレーが今一番のおすすめで、似たようなカレーが2番目のおすすめです。

次のおすすめはベジタリアンピザです。

注文したばかりのカレーと同じようにキノコとピーマンが入っていて、アプリは夕食の最初の選択ではないかもしれないとしても、私がピザが好きかもしれないことを知っています。

翌日昼食を注文しに行くと、モデルは昼食に注文するものと夕食に注文するものを区別することを学びました。

これは、私が欲しい時に欲しいものを正確に見つけるのに役立つ本当にパーソナライズされた経験を与え、それはたった2つの注文です。

表形式の分類器または回帰器をアプリに追加するには、データの設定、トレーニング、予測の3つの実際のステップがあります。

ここでの最初の機能は、食事とキーワードからこの回帰器で活用される機能を作成します。

私は各料理に関連付けられたキーワードを取り、それらを現在の食事(コンテキスト)と組み合わせて、モデルがコンテンツ(皿)キーワードとコンテキスト(食事)キーワードの間の相互作用をキャプチャすることを可能にする新しいキーワードを作成します。

辞書に1.0の値を入れて、単に特定のキーワードがデータ入力に存在することを示します。

まず、ユーザーが注文した料理ごとに、以前に生成された機能と正の目標値を持つエントリを追加します。

しかし、これを含めるだけでは、モデルは私が好きな料理と嫌いな料理を見分けることを学ばないでしょう。

これを行うには、ディッシュに存在しないすべてのキーワードを使用して、負の目標値が-1のエントリも追加します。

これにより、モデルはユーザーの好みに最も適したキーワードを学習できます。

この結合された情報をDataFrameに変換し、キーワードとターゲットの両方を指定します。

最後に、予測しようとしている列が1または-1に設定したターゲット列であることを指定して、モデルをトレーニングします。

この場合、モデルは単純な線形回帰器であり、アプリで使用できる有意義な結果を生成します。

予測時には、推論を実行したいデータを取り、トレーニングしたモデルから予測を呼び出すだけです。

これまでのところ、iPadOSとiOSアプリでスタイル転送モデルと表形式の回帰をトレーニングする方法を示しました。

機械学習トレーニングをアプリに統合するためのベストプラクティスについて話しましょう。

一般的に機械学習のベストプラクティスに従うことを忘れないでください。

たとえば、トレーニングデータセットにないデータに対してモデルのパフォーマンスを常にテストします。

長時間のトレーニングタスクでは、非同期トレーニング制御とチェックポイントメカニズムを活用して、モデル作成ワークフローをカスタマイズします。

モデル作成のいくつかの側面は、計算集約的であったり、追加のメモリを消費したり、追加の資産をダウンロードしたりする必要があります。

アプリに統合するときは、これらを考慮してください。

詳細については、APIとドキュメントを参照してください。

ベストプラクティスについてもっと知りたい場合は、「素晴らしいMLエクスペリエンスの設計」と「SwiftでMLを作成する際のコントロールトレーニング」に関する過去数年間の他のWWDCセッションを確認することを強くお勧めします。

このセッションでは、iOSでCreate MLフレームワークを使用する方法について説明しました。

スタイル転送と表形式の回帰を使用して例を挙げましたが、Create MLテンプレートのほとんどは、iPhoneまたはiPadで直接トレーニングできるようになりました。

iOSのトレーニングを通じて、ユーザーのプライバシーを維持しながら、ユーザーにカスタマイズされたパーソナライズされた体験を提供するダイナミックなアプリを作成できます。

トレーニングと推論は完全にアプリ内であるため、どちらも心配するモデルの展開はありません。

私たちはあなたが思いつくものを見るのを本当に楽しみにしています。

聞いてくれてありがとう、WWDCの残りの部分を楽しんでください。

♪