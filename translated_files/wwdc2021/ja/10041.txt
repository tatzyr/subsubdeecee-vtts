10041

こんにちは、WWDCへようこそ。

私の名前はフランク・ドゥープケで、ビジョンチームのエンジニアです。

ビジョンフレームワークは、画像分析に重点を置いて、長年にわたって成長してきました。

よりよく把握するために、使用の焦点の観点からビジョンの能力を見ることができます。

スポーツ。

オブジェクトの追跡と人間のポーズの分析は、スポーツアプリケーションを作成するのに役立つリクエストのほんの一部です。

アクセシビリティ。

OCRや画像分類や物体検出などのビジョン要求は、視覚障害のあるユーザーを支援しています。

人々。

ビジョンは、アプリが使用できる多くの顔と体関連のリクエストを提供します。

これについては、「ビジョンを使用して人、顔、ポーズを検出する」セッションで詳しく知ることができます。

健康。

バーコードスキャンやOCRから人間のポーズの分析まで、ビジョンはスマートな健康アプリケーションを作成するためのビルディングブロックを提供します。

計算写真。

ポートレートモードのような機能は、顔検出とセグメンテーションに依存しています。

セキュリティ。

顔や人間の検出などのリクエストは、防犯カメラの動き検出などのアプリケーションに役立ちます。

そして書類。

これがこのセッションで焦点を当てたいことです。

ビジョンは、バーコード検出、テキスト認識、または一般的に知られているOCR、輪郭検出、長方形検出、および今年の新しいドキュメントセグメンテーション検出など、ドキュメントの分析に役立つ多くのリクエストを提供しています。

これが私たちの議題です。

まず、バーコード検出について話します。

次に、テキスト認識について話します。

そして最後に、文書の検出について話します。

バーコード検出を見てみましょう。

今年は、バーコード検出要求の新しい改訂版を導入します。

VNDetectBarcodesRequestRevision2は、新しいシンボルをサポートしています。

Codabar、GS1Databarには、Expanded and Limited、MicroPDF、MicroQRが含まれています。後者は、URLのQRコードを作成し、スペースが少なくて済むため、小さなラベルやパッケージに配置する必要がある場合に特に役立ちます。

この新しいリビジョンの動作を、クライアントが指定した関心のある領域に関連して、結果のバウンディングボックスがどのように報告されるかに関して、ビジョンの残りの部分に沿った動作を変更しました。

その変化を詳しく見てみましょう。

ここには、QRコード付きの文書があります。

ROIとも呼ばれる関心のある領域を指定しない場合、境界ボックスは完全な画像に関連して報告されます。

さて、カメラが見ているものの中央部分だけに焦点を当てたいように、ROIを指定しましょう。

リビジョン2は、他のビジョンリクエストと同様に、ROIに関連してバウンディングボックスを報告するようになりました。

残念ながら、リビジョン1は常に完全な画像に関連して報告します。

しかし、既存のクライアントを壊す可能性があるため、その行動を変えたくありません。

念のため、最新のSDKに対してアプリケーションをコンパイルし、特定のリビジョンを指定しない場合、常に最新のリビジョンを取得します。

しかし、リビジョン1を指定するアプリケーション、または新しいSDKに対して再コンパイルしないアプリケーションの場合、古いリビジョン1の動作は引き続き取得されます。

ビジョンでのバーコード検出要求のいくつかの興味深い側面を強調させてください。

ビジョンは1Dおよび2Dバーコードをサポートしています。

しかし、本当に興味深いのは、1つの画像内で、複数のコードと複数のシンボルを一度に検出できることです。

つまり、複数のコードを取得するために何度も何度もスキャンする必要がないということです。

これは、ほとんどのハンドヘルドスキャナーよりも大きな利点です。

複数のシンボルをスキャンすると、指定したシンボルが多いほど時間がかかることを覚えておいてください。

したがって、ユースケースに関連するシンボルのみを使用してリクエストを設定したいと考えています。

バーコードスキャンの新しいシンボルの拡張により、ビジョンは健康分野で特に役立つ役割を果たすことができます。

iPhoneを使用すると、一度に複数のコードを分析でき、インターネットへの接続のおかげで、別のスキャナを必要とせずに情報を引き出すことができます。

また、iPhoneの強力な低照度機能のおかげで、暗いシナリオでも、レーザーを撃ったり、休憩中に患者を邪魔したりすることなく、コードをスキャンすることができます。

では、Visionがバーコード検出をどのように実行するかを見てみましょう。

1Dコードは行としてスキャンされます。

つまり、同じコードに対して複数の検出が得られる可能性が高いということです。

バーコードに含まれている実際のデータであるペイロードを見ることで、それらを重複排除するのは簡単です。

2Dコードは1つのユニットとしてスキャンされます。

つまり、コード全体のバウンディングボックスを1つ取り戻すということです。

2Dコードの例はQRコードです。

各バーコードは、独自の観察で報告されます。

しかし、前に述べたように、1Dコードは、同じ内容で、異なる物理的な場所で複数の観測を返すことができます。

ペイロードは、バーコードの内容、つまり、この機械可読コードに含まれるデータです。

特にQRコードのペイロードについては、データ検出器を使用してエンコードされたURLを分析することをお勧めします。

さて、これをちょっとしたデモで見てみましょう。

さて、ここにはXcodeの遊び場があり、すべてのバーコードが入った画像があることがわかります。

VNDetectBarcodesRequestを使用し、リビジョンを2に設定しました。

さて、シンボルとして、私はコーダバーを持っているだけで、これを見ると、コーダバーが赤で強調表示されていることがわかります。

さて、これをQRに変更しましょう。 

今起こることは、リクエストを再度実行し、QRコードが強調表示されることがわかります。

しかし、それは配列なので、ean8としましょう、それで他のリクエストを指定することもできます。

そして、私がそれを行うと、私たちは今、ean8とQRコードの両方を持っていることがわかります。

しかし、私がそれらすべてを手に入れたい場合はどうなりますか?

私は単に空の配列を通過し、その瞬間に、すべてのシンボルが読まれます。

そして、ご覧のとおり、今はすべてが下部のコードで強調表示されています。

スライドに戻りましょう。 

バーコードから、私たちは今、テキスト認識に目を向けています。

ビジョンは2019年にテキスト認識を導入しました。

高速と正確な2つのモードで動作します。

それ以来、ビジョンは言語サポートを拡大してきました。

テキスト認識がどのように機能し、言語がどこで役割を果たすかを見てみましょう。

ファストパスには、ラテン文字認識器があります。

一方、正確なパスは、単語や行で動作する機械学習ベースのリコグナイザを使用します。

認識が完了すると、各パスは言語修正段階を経ます。

そして、最終的には、認識されたテキストを取り戻します。

言語の選択は認識段階に影響します。

ファストパスでは、ドイツ語のウムラウトのように、異なるラテン文字セットがサポートされていることを意味します。

正確なパスでは、中国語の構造がラテン語ベースの言語とは大きく異なるため、中国語を認識する必要があるときにまったく異なるモデルが使用されます。

つまり、中国語のテキストを読む必要がある場合は、中国語が要求の主要言語であることが重要です。

言語選択は、その仕事のために正しい辞書を選ぶので、言語修正にも影響します。

では、テキスト認識で言語を使用する際のベストプラクティスは何ですか?

固定された言語セットがサポートされているように見えるかもしれませんが、supportedRecognitionLanguages()を使用して、特定の要求設定でサポートされている言語を照会することをお勧めします。

複数の言語を指定でき、その場合、順序が重要です。

曖昧さがある場合、それは言語の順序で解決されます。

特に正確なパスについては、第一言語がどの認識モデルが使用されるかを決定します。

つまり、ユースケースによって、リクエストで使用する言語が決まります。

ちょっとしたデモでこれを見てみましょう。

だから、私は今ここに私たちのサンプルコードの改訂版を持っています、そしてあなたは私がその中にテキストの異なる言語を持つ画像を持っていることがわかります。

さて、リビジョン2を指定して、どの言語がサポートされているかを確認できます。

私たちは英語、フランス語などを持っています。

たとえば、リビジョン1に戻すと、英語しかないことがわかります。

そして、それは高速の場合と正確なパスの場合と同じです。

では、リビジョン2に戻りましょう。

例えば、私が今ドイツ語に切り替えるとき、私は実際にGrüsse aus Cupertinoでウムラウトを正しく取得することに注意してください。

しかし、私は中国人のためのファストパスでサポートを持っていません。

正確なパスで、私は今中国語を選ぶことができます。

そして今、私たちはついに「Hello World」の正しい中国語の文字を手に入れました。

スライドに戻りましょう。 スライドに戻りましょう

最後になりましたが、ドキュメントの検出を見てみましょう。

ビジョンは、VNDocumentSegmentationRequestと呼ばれる新しいリクエストを導入します。

これは、紙、サイン、メモ、領収書、ラベルなど、さまざまな種類の文書で訓練した機械学習ベースの検出器です。

リクエストの結果は、低解像度のセグメンテーションマスクであり、各ピクセルは、そのピクセルが検出されたドキュメントの一部であるかどうかの信頼を表します。

さらに、四角形の4つの角点を提供します。

ニューラルエンジンを搭載したデバイスでは、リクエストはカメラやビデオフィードでリアルタイムで実行できます。

VisionKitのVNDocumentCameraは、ニューラルエンジンを搭載した最新のデバイスで、VNDetectRectanglesRequestの代わりにリクエストを使用しています。

VNDetectRectanglesRequestと言えば、どちらもドキュメントの検出に使用できるため、これら2つの要求はどのように異なりますか?

DetectDocumentsRequestは、私が述べたように、機械学習ベースであり、ニューラルエンジンで最速で実行します。

しかし、GPUやCPUでも使用できますが、リアルタイムのパフォーマンスには十分な速さではありません。

長方形検出器は、CPUでのみ実行され、CPUが他のタスクで飽和していない限り、リアルタイムのパフォーマンスに追いつくことができる従来のコンピュータビジョンアルゴリズムです。

文書要求はさまざまな文書で訓練されており、その主な強みの1つであるすべての長方形である必要はありません。

一方、長方形検出器は、四角形を形成するエッジと交差点を見つけることによって機能します。これは、文書内のあいまいな角や折り畳みで課題になる可能性があります。

ドキュメント要求はセグメンテーションマスクとコーナーポイントを提供しますが、長方形検出器はコーナーポイントのみを提供します。

そして、文書検出器は1つの文書だけを探すように訓練されています。

長方形検出器を使用すると、複数の長方形を返します。

これらの長方形はネストすることさえできます。

これをもう少し見てみましょう。 

私が述べたように、文書検出器は、検出されたオブジェクトの四角形でここで見られる1つの文書を見つけます。

しかし、長方形検出器は、画像で見つけたすべての長方形の複数の観察を返し、私はここでいくつかを強調しました。

どの長方形が文書であるかを決めるのはアプリ次第です。

デモでこれをすべて試してみるのはどうですか？

さて、私たちはWWDCでどれだけうまくやっているか、ちょっとした調査を作りたかったのです。

さて、残念ながら、あなたは私と一緒にいないので、私はここのカメラチームにあなたのためにアンケートに記入するように頼まなければなりませんでした。

そこで、アンケートカードをスキャンできる小さなアプリを作成しました。

そして、私たちは何を手に入れますか?

初心者向けのQuickDrawは時代遅れだと感じました。

まあ、今では少し古いです。

次に行きましょう。"

ああ、ビジョンは面白くて有益でした。

最後になりましたが、コボル、まさに私が必要としていたものです。

誰かがここで間違ったセッションに参加しています。

さて、コードでこれをどのように行ったかを見てみましょう。

だから、私たちのためにこのようなものを構築する方が簡単なので、私はここで再び小さな遊び場を作りました。

すでにご覧のとおり、画像をロードし、画像操作を行う必要があるため、CIImageを使用しました。

requestHandlerを作成し、新しいVNDetectDocument SegmentationRequest()を使用しました。

リクエストを実行すると、結果が返され、コア画像を使用して透視補正画像として使用した小さなヘルパー機能を作成し、透視補正形式で切り取られたカードだけを取り戻します。

だから、それは簡単です。

それで、私たちは次に何をしなければなりませんか?

バーコードを検出し、長方形を検出し、テキストを認識する必要があります。

このリクエストを実行したら、チェックボックスをスキャンして、どれがチェックされているかを確認する必要があります。

さて、私はこれを少し準備したので、バーコードの検出から始めましょう。

そして、私はシンボルとして、QRコードだけを使っています。

私はそれが知っていることを知っているので、私は文書のタイトルにロードしました--私のQRコードの内容は、私たちがそれから得るもののタイトルになります。

次に、長方形を検出する必要があります。

繰り返しますが、そのための小さなコード矩形があります。

だから、私は2つの配列を作成します。

分析に必要なデータであるすべてのcheckBoxImagesを取得したいです。

そして、私はすべての長方形を取り出します。

そこで、私はVNDetectRectanglesRequestを使用しました。

さて、私がここで行うことは、正しい順序で結果を得るように、それらを垂直順に並べ替えることです。

さて、今、私たちはテキストを認識する必要があります。

それは簡単です。

結果のすべてのテキストブロックを保存し、VNRecognizeTextRequestを使用します。

だから今、私たちがしなければならないのは、単に要求を実行することです。

そして、ご覧のとおり、私はトリミングされた画像を使用したdocumentRequestHandlerを使用し、その要求を実行しました。

そして、私がここに戻ると、私はすでに正しいQRコードを取得していることがわかりますが、私の長方形では何かが正しくありません。

長方形は手がありません。

それで、私は何をしなければなりませんか?

まあ、デフォルトでは、長方形検出器は画像の少なくとも20%である長方形のみを探します。

だから、私たちはそれを修正する必要があります。

だから、私は中に入って、最小サイズを10%のようなものに設定します。

そして、それを行うと、長方形になります。

さて、まあ、それは1つだけです。

さて、長方形検出器のもう1つのことは、それがいくつ戻るべきかを伝える必要があるということです。

デフォルトでは、長方形の検出は、最も目立つ長方形の1つだけを返します。

しかし、私はそれらすべてを手に入れたい。

これを行うには、maximumObservationsを0に設定します。

そして、それを行うと、それは長方形のように見えるので、すべてのチェックボックスとバーコードを取得します。

さて、私たちは大丈夫です。

今、最後の部分が来て、私は実際にチェックボックスをスキャンする必要があります。

だから、そのために、私は実際に少し機械学習のデモを準備しました。

ここには、先ほどCreate MLでトレーニングしたモデルがあります。

それは画像分類器であり、私がやったのは、マークされたこれらのチェックボックス画像のいくつかを使用し、そのうちのいくつかは私の「はい」と「いいえ」のラベルにマークされていません。

そして、私はまた、それらのどちらでもないいくつかの画像を集めました。

それは私のNotItです。

繰り返しますが、これをコードで使用できます。

それで、私たちは何を持っていますか?

モデルをロードしてリクエストを作成し、Create MLリクエストを作成します。

そして、すべてのチェックボックス画像を反復し、そこからImageRequestHandlerを作成し、分類を実行します。

今、私は私のトップ分類を見ることができます。

それが「はい」の場合、私が持っているチェックボックスとどのテキスト行が並んでいるかを見つけ、最終的に何を得るのですか?

ビジョンは面白くて有益でした。

スライドに戻りましょう。 スライドに戻りましょう

私たちが見たものについてまとめてみましょう。

ドキュメント分析は、Vision APIの焦点です。

ビジョンのバーコード検出はスキャナーよりも汎用性が高く、新しいドキュメントセグメンテーション検出を導入しています。

OCRの使い方についてもっと知りたい場合は、WWDC 2019のセッションをご覧ください。

WWDC 2020の「ビジョンとコアイメージ」セッションは、画像を前処理し、輪郭を検出することにより、独自のカスタムドキュメント分析を行うための追加の洞察を提供します。

ありがとう、そしてWWDCの残りの部分を楽しんでください。

[音楽]。