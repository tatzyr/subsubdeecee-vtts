10040

♪ Nhạc bass đang phát ♪

♪

Sergey Kamensky: Xin chào mọi người và chào mừng đến với WWDC.

Tên tôi là Sergey Kamensky và tôi là một kỹ sư phần mềm trong nhóm khung Vision.

Chủ đề của phiên hôm nay là chỉ ra cách khung Tầm nhìn có thể giúp phân tích con người.

Chương trình nghị sự của chúng tôi hôm nay bao gồm hai mục chính.

Đầu tiên chúng ta sẽ có một cái nhìn tổng quan về công nghệ phân tích con người trong khuôn khổ Tầm nhìn.

Trong khi làm điều đó, chúng tôi sẽ đặc biệt tập trung vào những bổ sung mới.

Và thứ hai, chúng ta sẽ có đánh giá chuyên sâu về tính năng phân khúc người mới.

Trước tiên hãy bắt đầu với công nghệ phân tích con người.

Nền tảng của phân tích con người trong Tầm nhìn là phân tích khuôn mặt con người.

Kể từ khi bắt đầu khuôn khổ Tầm nhìn, chúng tôi đã bổ sung và nâng cao khả năng phân tích khuôn mặt con người.

Chúng tôi hiện đang cung cấp tính năng phát hiện khuôn mặt, phát hiện mốc khuôn mặt và phát hiện chất lượng chụp khuôn mặt.

Chức năng phát hiện khuôn mặt trong khung Vision được hiển thị bằng phương tiện DetectFaceRectanglesRequest.

Máy dò khuôn mặt của chúng tôi cung cấp các chỉ số thu hồi và độ chính xác cao, nó có thể tìm thấy các khuôn mặt có hướng tùy ý, kích thước khác nhau và cũng bị che khuất một phần.

Cho đến nay chúng tôi đã hỗ trợ các tắc nghẽn như kính và mũ.

Bây giờ chúng tôi đang nâng cấp máy dò khuôn mặt của mình lên bản sửa đổi số ba, ngoài việc cải thiện tất cả các phẩm chất tuyệt vời hiện có, giờ đây cũng có thể phát hiện các khuôn mặt được che bởi mặt nạ.

Chức năng chính của máy dò khuôn mặt của chúng tôi tất nhiên là tìm hộp giới hạn khuôn mặt, nhưng nó cũng có thể phát hiện các chỉ số tư thế khuôn mặt.

Trước đây, chúng tôi chỉ cung cấp các chỉ số liệu cuộn và ngáp.

Hầu hết các số liệu được báo cáo bằng radian và giá trị của chúng được trả về trong các thùng rời rạc.

Với phần giới thiệu sửa đổi mới, chúng tôi cũng đang thêm một số liệu cao độ và do đó hoàn thành bức tranh đầy đủ.

Nhưng chúng tôi đã không dừng lại ở đó.

Chúng tôi cũng đang báo cáo cả ba số liệu trong không gian liên tục.

Tất cả các chỉ số tư thế khuôn mặt được trả về dưới dạng thuộc tính của đối tượng FaceObservation của chúng tôi, đó là kết quả của việc thực hiện Yêu cầu DetectFaceRectangles.

Hãy xem ứng dụng demo được thiết kế để hiển thị chức năng phát hiện tư thế khuôn mặt.

Ứng dụng xử lý nguồn cấp dữ liệu máy ảnh bằng cách chạy máy dò khuôn mặt Vision và trình bày số liệu tư thế khuôn mặt cho người dùng sau khi chuyển đổi kết quả từ radian sang độ.

Để theo dõi tốt hơn các thay đổi số liệu, ứng dụng sử dụng gradient màu đỏ để hiển thị khi số liệu tư thế khuôn mặt tăng theo hướng dương và gradient màu xanh lam để hiển thị khi số liệu tăng theo hướng âm.

Trong cả hai trường hợp, màu càng nhạt, số liệu càng gần vị trí 0.

Vị trí 0 cho mỗi số liệu là cái mà bạn sẽ gọi là vị trí trung lập của đầu người, khi người đó nhìn thẳng - giống như thế này.

Như chúng ta đã thảo luận, chúng ta có ba chỉ số tư thế khuôn mặt: cuộn, ngáp và cao độ.

Những thuật ngữ này xuất phát từ động lực bay và chúng mô tả các trục nguyên lý của máy bay đối với trọng tâm của máy bay.

Các thuật ngữ tương tự cũng đã được áp dụng để mô tả tư thế đầu của con người.

Khi áp dụng cho tư thế đầu - hoặc như chúng ta cũng gọi nó, tư thế khuôn mặt - chúng theo dõi chuyển động đầu của con người như sau.

Roll đang theo dõi chuyển động của đầu theo hướng này.

Khi tôi chuyển từ giá trị tiêu cực nhất sang tích cực nhất của cuộn, bạn có thể thấy rằng màu nền thay đổi từ xanh đậm sang xanh nhạt, trung tính, sau đó là đỏ nhạt và cuối cùng là đỏ sẫm.

Những thay đổi màu sắc tương tự đang xảy ra với số liệu ngáp, đang theo dõi góc khi đầu quay sang phải hoặc trái.

Và cuối cùng, số liệu cao độ đang theo dõi chuyển động đầu của tôi khi đầu tôi gật đầu lên hoặc xuống.

Ở đây bạn có thể thấy lại những thay đổi màu sắc tương tự khi tôi đi từ đầu tiêu cực nhất đến đầu tích cực nhất của quang phổ.

Phát hiện mốc khuôn mặt là một chức năng quan trọng khác của bộ phân tích khuôn mặt của chúng tôi.

Phát hiện mốc khuôn mặt được cung cấp bằng phương tiện DetectFaceLandmarksRequest và bản sửa đổi mới nhất là bản sửa đổi số ba.

Bản sửa đổi này cung cấp chòm sao 76 điểm để thể hiện tốt hơn các vùng khuôn mặt chính và cũng cung cấp khả năng phát hiện đồng tử chính xác.

Bộ phân tích khuôn mặt cũng bao gồm phát hiện chất lượng chụp khuôn mặt.

Biện pháp tổng thể này tính đến các thuộc tính như biểu cảm khuôn mặt con người, ánh sáng, tắc nghẽn, mờ, lấy nét, v.v.

Nó được hiển thị thông qua DetectFaceCaptureQualityRequest API và bản sửa đổi mới nhất của yêu cầu này là bản sửa đổi số hai.

Điều quan trọng cần nhớ là chất lượng chụp khuôn mặt là thước đo so sánh của cùng một chủ đề.

Tính năng này hoạt động rất tốt, ví dụ, để chọn bức ảnh đẹp nhất trong loạt ảnh bùng nổ hoặc để chọn bức ảnh đẹp nhất để đại diện cho một người trong thư viện ảnh.

Tính năng này không được thiết kế để so sánh khuôn mặt của những người khác nhau.

Phân tích cơ thể con người là một phần lớn khác của công nghệ phân tích con người được cung cấp bởi khung Tầm nhìn.

Tầm nhìn cung cấp một số chức năng trong lĩnh vực này, bao gồm phát hiện cơ thể người, phát hiện tư thế người và cuối cùng nhưng không kém phần quan trọng, phát hiện tư thế bàn tay người.

Đầu tiên chúng ta hãy xem xét việc phát hiện cơ thể con người.

Chức năng này được cung cấp thông qua DetectHumanRectanglesRequest và hiện tại nó chỉ phát hiện phần thân trên của con người.

Chúng tôi đang thêm chức năng mới vào yêu cầu này, và do đó nâng cấp bản sửa đổi này lên bản sửa đổi số hai.

Với bản sửa đổi mới, ngoài tính năng phát hiện phần thân trên, chúng tôi cũng cung cấp tính năng phát hiện toàn thân.

Sự lựa chọn giữa phát hiện phần thân trên và phần thân trên được kiểm soát thông qua thuộc tính upperBodyOnly mới của DetectHumanRectanglesRequest.

Giá trị mặc định cho thuộc tính này được đặt thành true để duy trì khả năng tương thích ngược.

Phát hiện tư thế cơ thể con người được cung cấp trong khuôn khổ Tầm nhìn thông qua DetectHumanBodyPoseRequest.

Xử lý yêu cầu này cung cấp một bộ sưu tập các vị trí khớp của cơ thể người.

Bản sửa đổi số một là bản sửa đổi mới nhất và duy nhất có sẵn của yêu cầu này.

Khung tầm nhìn cũng cung cấp khả năng phát hiện tư thế bàn tay người dưới dạng DetectHumanHandPoseRequest.

Tương tự như phát hiện tư thế cơ thể con người, việc xử lý yêu cầu tư thế tay trả về một bộ sưu tập các vị trí khớp tay người.

Chúng tôi đang nâng cấp chức năng của yêu cầu này bằng cách thêm một thuộc tính quan trọng vào kết quả quan sát, tính chirality bằng tay.

Thuộc tính chirality mới của HumanHandPoseObservation sẽ chứa thông tin cho dù bàn tay được phát hiện là trái hay phải.

Nếu bạn muốn tìm hiểu thêm chi tiết về phát hiện tư thế tay, tôi khuyên bạn nên xem phiên "Phân loại tư thế và hành động tay với Tạo ML".

Điều này kết thúc tổng quan của chúng tôi về các nâng cấp mới cho bộ công nghệ phân tích con người.

Bây giờ là lúc chuyển sang chủ đề thứ hai trong phiên của chúng tôi, đó là phân khúc người.

Phân khúc người là gì?

Nói một cách rất đơn giản, đó là khả năng tách mọi người khỏi hiện trường.

Ngày nay có rất nhiều ứng dụng của công nghệ phân khúc con người.

Ví dụ, tất cả các bạn đều quen thuộc với tính năng nền ảo trên các ứng dụng hội nghị truyền hình.

Nó cũng được sử dụng trong phân tích thể thao trực tiếp, lái xe tự động và nhiều nơi khác.

Phân đoạn người cũng cung cấp năng lượng cho chế độ Chân dung nổi tiếng của chúng tôi.

Phân đoạn người trong khung Tầm nhìn là một tính năng được thiết kế để hoạt động với một khung duy nhất.

Bạn có thể sử dụng nó trong đường ống phát trực tuyến và nó cũng phù hợp cho việc xử lý ngoại tuyến.

Tính năng này được hỗ trợ trên nhiều nền tảng như macOS, iOS, iPadOS và tvOS.

Khung tầm nhìn thực hiện phân đoạn người ngữ nghĩa, có nghĩa là nó sẽ trả lại một mặt nạ duy nhất cho tất cả mọi người trong khung.

Vision API cho phân khúc người được triển khai bằng GeneratePersonSegmentationRequest, Đây là một yêu cầu trạng thái.

Trái ngược với các yêu cầu truyền thống trong khung Vision, các đối tượng yêu cầu trạng thái được sử dụng lại trong toàn bộ chuỗi khung.

Trong trường hợp cụ thể của chúng tôi, việc sử dụng đối tượng yêu cầu giúp làm mịn các thay đổi thời gian giữa các khung trong mô hình mức chất lượng nhanh.

Chúng ta hãy xem API Phân đoạn Cá nhân được cung cấp bởi khung Tầm nhìn.

API này tuân theo một mô hình đã quen thuộc và đã được thiết lập.

Tạo một yêu cầu, tạo một trình xử lý yêu cầu, xử lý yêu cầu của bạn với trình xử lý yêu cầu và cuối cùng, xem lại kết quả.

Khởi tạo mặc định của đối tượng GeneratePersonSegmentationRequest tương đương với việc thiết lập các thuộc tính sửa đổi, qualityLevel và outputPixelFormat thành các giá trị mặc định của chúng.

Hãy xem lại từng tài sản một.

Đầu tiên là thuộc tính sửa đổi.

Ở đây chúng tôi đặt bản sửa đổi thành bản sửa đổi số một.

Đây là bản sửa đổi mặc định và duy nhất có sẵn, vì chúng tôi đang xử lý loại yêu cầu mới.

Mặc dù về mặt kỹ thuật không có lựa chọn nào ở đây ngày hôm nay, chúng tôi luôn khuyên bạn nên thiết lập rõ ràng để đảm bảo hành vi xác định trong tương lai.

Điều này là do nếu các bản sửa đổi mới được giới thiệu, mặc định cũng sẽ thay đổi để đại diện cho bản sửa đổi mới nhất có sẵn.

Thứ hai là tài sản qualityLevel.

Vision API cung cấp ba cấp độ khác nhau: chính xác, cũng là cấp độ mặc định; cân bằng; và nhanh chóng.

Theo như các trường hợp sử dụng, chúng tôi khuyên bạn nên sử dụng mức độ chính xác để chụp ảnh tính toán.

Đây là trường hợp sử dụng mà bạn muốn đạt được chất lượng cao nhất có thể và thường không bị giới hạn về thời gian.

Sử dụng logic tương tự, mức cân bằng được khuyến nghị cho phân đoạn video theo từng khung hình và nhanh chóng để xử lý phát trực tuyến.

Thuộc tính thứ ba là định dạng mặt nạ đầu ra.

Chúng tôi sẽ xem xét chi tiết mặt nạ kết quả, nhưng ở đây tôi muốn đề cập rằng, với tư cách là khách hàng, bạn có thể chỉ định định dạng mặt nạ kết quả sẽ được trả lại.

Có ba lựa chọn ở đây: mặt nạ nguyên 8 bit không dấu với phạm vi lượng tử hóa từ 0 đến 255 điển hình và hai định dạng mặt nạ dấu phẩy động - một định dạng có độ chính xác đầy đủ 32 bit và một định dạng khác có độ chính xác một nửa 16 bit.

Độ chính xác một nửa 16 bit nhằm cung cấp cho bạn định dạng dấu phẩy động bộ nhớ giảm có thể được chèn trực tiếp vào quá trình xử lý dựa trên GPU hơn nữa với Metal.

Cho đến nay chúng tôi đã học được cách tạo, cấu hình và thực hiện yêu cầu phân đoạn người của mình.

Bây giờ là lúc để xem kết quả.

Kết quả của việc xử lý yêu cầu phân đoạn người đến dưới dạng đối tượng PixelBufferObservation.

PixelBufferObservation bắt nguồn từ quan sát và nó bổ sung một thuộc tính pixelBuffer quan trọng.

Đối tượng CVPixelBuffer thực tế được lưu trữ trong thuộc tính này có cùng định dạng pixel với yêu cầu phân đoạn người của chúng tôi đã được định cấu hình.

Việc xử lý yêu cầu phân đoạn người sẽ tạo ra mặt nạ phân đoạn.

Hãy nhìn vào hình ảnh gốc và ba mặt nạ mức chất lượng khác nhau được tạo ra bằng cách thực hiện yêu cầu phân đoạn người.

Nhanh chóng, cân bằng và chính xác.

Hãy phóng to để xem chi tiết của từng mặt nạ.

Đúng như dự đoán, khi chúng ta đi từ nhanh đến cân bằng và cuối cùng đến chính xác, chất lượng của mặt nạ tăng lên và chúng ta sẽ bắt đầu thấy ngày càng nhiều chi tiết.

Bây giờ hãy kiểm tra các mức mặt nạ khác nhau như một chức năng của chất lượng so với hiệu suất.

Khi chúng ta chuyển từ nhanh sang cân bằng, và cuối cùng sang chính xác, chất lượng của mặt nạ sẽ tăng lên nhưng việc sử dụng tài nguyên cũng vậy.

Phạm vi động, độ phân giải mặt nạ, mức tiêu thụ bộ nhớ, thời gian xử lý đều tăng lên khi chất lượng mặt nạ tăng lên.

Điều này thể hiện sự đánh đổi giữa chất lượng của mặt nạ phân đoạn và mức tiêu thụ tài nguyên cần thiết để tính toán mặt nạ.

Vì vậy, bạn đã biết mọi thứ về việc tạo mặt nạ và tính chất của chúng.

Bạn thực sự có thể làm gì với mặt nạ?

Hãy bắt đầu với ba hình ảnh.

Hình ảnh đầu vào, mặt nạ phân đoạn thu được bằng cách xử lý hình ảnh đầu vào và hình nền.

Những gì chúng tôi muốn làm là thay thế nền trong hình ảnh gốc ở khu vực bên ngoài vùng mặt nạ bằng nền từ một hình ảnh khác.

Khi bạn thực hiện thao tác pha trộn như vậy, chúng tôi kết thúc với chàng trai trẻ trong hình ảnh gốc được vận chuyển từ lối đi dạo trên bãi biển vào rừng.

Trình tự pha trộn này trông như thế nào trong mã?

Trước tiên, giả sử chúng ta đã thực hiện tất cả các quá trình xử lý có liên quan và đã có ba hình ảnh của mình: hình ảnh đầu vào, mặt nạ và nền.

Bây giờ chúng ta cần chia tỷ lệ cả mặt nạ và nền theo kích thước của hình ảnh gốc.

Sau đó, chúng tôi sẽ tạo và khởi tạo bộ lọc pha trộn Core Image.

Bạn có thể nhận thấy rằng tôi đã tạo ra bộ lọc pha trộn của mình với mặt nạ màu đỏ.

Điều này là do khi CIImage được khởi tạo với một thành phần PixelBuffer - như tất cả các mặt nạ của chúng tôi - nó sẽ tạo ra một đối tượng với kênh màu đỏ theo mặc định.

Cuối cùng, chúng tôi thực hiện thao tác pha trộn để có được kết quả của mình.

Hãy xem cách chúng ta có thể sử dụng tính năng phân đoạn người trong khuôn khổ Tầm nhìn.

Ứng dụng demo thứ hai của chúng tôi, có sẵn để tải xuống, kết hợp phát hiện số liệu tư thế khuôn mặt với khả năng phân đoạn người mới.

Ứng dụng xử lý nguồn cấp dữ liệu máy ảnh bằng cách chạy tính năng nhận diện khuôn mặt và phân đoạn người.

Sau đó, điều đó chiếm mặt nạ phân đoạn cuối và sử dụng nó để thay thế nền trong khu vực bên ngoài các điểm ảnh mặt nạ bằng một màu khác.

Quyết định sử dụng màu nền nào đến từ sự kết hợp của các giá trị cho cuộn, ngáp và cao độ tại bất kỳ thời điểm nào.

Tôi hiện đang ở trong một căn phòng có bàn ghế, và ứng dụng demo hiển thị hình bóng được phân đoạn của tôi trên nền mới, đó là sự pha trộn màu sắc tương ứng với vị trí đầu của tôi.

Hãy xem liệu nó có theo dõi sự thay đổi của cuộn, ngáp và cao độ hay không.

Khi tôi quay đầu lại như thế này, roll là một đóng góp chính cho quyết định pha trộn màu nền.

Khi tôi quay đầu sang trái và phải, ngáp trở thành người đóng góp chính.

Và cuối cùng, gật đầu lên xuống khiến quảng cáo chiêu hàng trở thành người đóng góp chính.

Khung tầm nhìn không phải là nơi duy nhất cung cấp API phân khúc người.

Có một số khuôn khổ khác cung cấp chức năng tương tự được cung cấp bởi cùng một công nghệ.

Chúng ta hãy xem xét ngắn gọn từng người trong số họ.

Đầu tiên là AVFoundation.

AVFoundation có thể trả lại mặt nạ phân đoạn người trong một số thiết bị thế hệ mới hơn trong phiên chụp ảnh.

Mặt nạ phân đoạn được trả về thông qua thuộc tính PortraitEffectsMatte của AVCapturePhoto.

Để có được nó, trước tiên bạn sẽ cần kiểm tra xem nó có được hỗ trợ hay không; và nếu có, hãy kích hoạt việc phân phối nó.

Khung thứ hai cung cấp API phân đoạn người là ARKit.

Chức năng này được hỗ trợ trên A12 Bionic và các thiết bị mới hơn, và được tạo ra khi xử lý nguồn cấp dữ liệu máy ảnh.

Mặt nạ phân đoạn được trả về thông qua thuộc tính segmentationBuffer của ARFrame.

Trước khi cố gắng truy xuất nó, bạn cần kiểm tra xem nó có được hỗ trợ hay không bằng cách kiểm tra thuộc tính supportsFrameSemantics của lớp ARWorldTrackingConfiguration.

Khung thứ ba là Core Image.

Core Image cung cấp một trình bao bọc mỏng trên API phân đoạn người Vision, vì vậy bạn có thể thực hiện toàn bộ trường hợp sử dụng trong miền Core Image.

Bây giờ chúng ta hãy xem cách phân đoạn người có thể được triển khai bằng cách sử dụng Core Image API.

Chúng ta sẽ bắt đầu với việc ghi lại một hình ảnh để thực hiện phân đoạn.

Sau đó, chúng tôi sẽ tạo một CIFilter phân đoạn người, gán một Hình ảnh đầu vào cho nó và thực hiện bộ lọc để lấy mặt nạ phân đoạn của chúng tôi.

Chúng tôi vừa xem xét nhiều phiên bản của API phân đoạn người và Apple SDK.

Hãy tóm tắt để xem mỗi cái có thể được sử dụng ở đâu.

AVFoundation có sẵn trên một số thiết bị iOS với AVCaptureSession.

Nếu bạn có một phiên chụp đang chạy, đây sẽ là lựa chọn của bạn.

Nếu bạn đang phát triển một ứng dụng ARKit, bạn nên có một phiên AR nơi bạn có thể lấy mặt nạ phân đoạn của mình.

Trong trường hợp này, ARKit API là API được khuyến nghị sử dụng.

Vision API có sẵn trên nhiều nền tảng để xử lý khung hình đơn trực tuyến và ngoại tuyến.

Và cuối cùng, Core Image cung cấp một trình bao bọc mỏng xung quanh Vision API, đây là một lựa chọn thuận tiện nếu bạn muốn ở trong miền Core Image.

Như bất kỳ thuật toán nào, phân đoạn người có các phương pháp hay nhất - hay nói cách khác, tập hợp các điều kiện mà nó hoạt động tốt nhất.

Nếu bạn dự định sử dụng tính năng phân đoạn người, ứng dụng của bạn sẽ hoạt động tốt hơn nếu bạn cố gắng tuân theo các quy tắc này.

Đầu tiên, bạn nên cố gắng phân đoạn tối đa bốn người trong cảnh mà hầu hết mọi người đều có thể nhìn thấy, trong khi có thể có tắc nghẽn tự nhiên.

Thứ hai, chiều cao của mỗi người nên ít nhất bằng một nửa chiều cao hình ảnh, lý tưởng nhất là có độ tương phản tốt so với hậu cảnh.

Và thứ ba, chúng tôi cũng khuyên bạn nên tránh những điều mơ hồ như tượng, hình ảnh của mọi người, những người ở khoảng cách xa.

Điều này kết thúc phiên họp của chúng tôi.

Chúng ta hãy xem ngắn gọn những gì chúng ta đã học được ngày hôm nay.

Đầu tiên, chúng tôi đã có một cái nhìn tổng quan về công nghệ phân tích con người trong khuôn khổ Tầm nhìn trong khi tập trung vào các nâng cấp như phát hiện khuôn mặt đeo mặt nạ, thêm số liệu cao độ khuôn mặt và làm cho tất cả các chỉ số tư thế khuôn mặt được báo cáo trong không gian liên tục.

Chúng tôi cũng đã giới thiệu số liệu chirality tay mới để phát hiện tư thế bàn tay người.

Trong phần thứ hai, chúng tôi đã đi sâu vào API phân đoạn người mới được thêm vào khung Tầm nhìn.

Chúng tôi cũng đã xem xét các API khác cung cấp chức năng tương tự và cung cấp hướng dẫn nơi mỗi API có thể được sử dụng.

Tôi thực sự hy vọng rằng bằng cách xem phiên này, bạn đã học được các công cụ mới để phát triển ứng dụng của mình và thực sự mong muốn thử chúng ngay lập tức.

Trước khi chúng ta kết thúc ngày hôm nay, tôi muốn cảm ơn bạn đã xem, chúc bạn may mắn và có một phần còn lại tuyệt vời của WWDC.

♪