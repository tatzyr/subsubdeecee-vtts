10073

Xin chào.

Tôi là David, một kỹ sư từ nhóm ARKit.

Hôm nay Christopher và tôi sẽ chia sẻ một loạt các cải tiến cho ARKit 5.

Chúng tôi rất vui khi thảo luận về những thay đổi sắp tới đối với iOS 15.

Năm nay, chúng tôi đã thực hiện nhiều nâng cấp trên diện rộng và chúng tôi sẽ thảo luận về nhiều tính năng.

Trước khi chúng tôi làm điều đó, chúng tôi muốn giới thiệu những trải nghiệm mà tất cả các bạn đã xây dựng với LiDAR.

Chúng tôi đã thấy nhiều ứng dụng hỗ trợ LiDAR sử dụng API độ sâu và tái tạo cảnh: năng suất, hiệu ứng bộ lọc ảnh, giải trí và thậm chí cả các trò chơi mà bạn có thể chơi trong phòng khách của mình.

Chúng tôi thực sự vui khi thấy sự sáng tạo và tháo vát được thể hiện bởi cộng đồng ARKit.

Trong khi bạn đang tạo các ứng dụng này, chúng tôi đang làm việc chăm chỉ để mang đến cho bạn khuôn khổ AR tốt nhất thế giới và vượt qua ranh giới của những gì có thể.

Hãy xem qua những thay đổi sắp tới trong ARKit 5.

Đầu tiên, chúng tôi sẽ chia sẻ một số cập nhật và phương pháp hay nhất cho neo vị trí, cho phép trải nghiệm AR ở các địa điểm ngoài trời trong thế giới thực.

Tiếp theo, chúng tôi sẽ đề cập đến Mã clip ứng dụng, đây là một cách tuyệt vời để khám phá các clip ứng dụng và cũng cho phép bạn định vị nội dung của mình trong AR.

Chúng tôi sẽ nêu bật một số cải tiến để theo dõi khuôn mặt bằng cách sử dụng camera trước siêu rộng trên iPad Pro mới.

Và chúng ta sẽ kết thúc với một số cải tiến để chụp chuyển động ARKit.

Chúng tôi sẽ bắt đầu với các neo vị trí, nơi chúng tôi đã làm việc để mở rộng hỗ trợ khu vực và cung cấp một số cải tiến về chất lượng cuộc sống.

Chúng tôi cũng sẽ đề xuất một số phương pháp hay nhất để tạo ứng dụng.

Các neo vị trí đã được giới thiệu vào năm ngoái để cho phép đặt nội dung AR ở một vĩ độ và kinh độ cụ thể.

Mục đích của họ là cho phép tạo ra các trải nghiệm AR gắn liền với các vị trí địa lý.

Hãy xem xét một ví dụ.

Đây là trải nghiệm New Nature từ ứng dụng ScavengAR, được xây dựng bằng API neo vị trí.

ScavengAR lưu trữ nội dung AR tại các địa điểm trong thế giới thực và cho phép tạo ra các hoạt động và sắp đặt nghệ thuật công cộng ảo.

Đó là một ví dụ điển hình về cách neo vị trí có thể cung cấp năng lượng cho trải nghiệm ngoài trời khi thế giới mở cửa trở lại.

Ứng dụng Bản đồ cũng đang giới thiệu một tính năng AR mới sử dụng API trong iOS 15.

Hãy cùng xem nào.

Năm nay Bản đồ đang thêm các chỉ dẫn đi bộ từng bước được hiển thị trong AR, sử dụng API neo vị trí.

Họ kết hợp một số phương pháp mà chúng tôi đề xuất.

Chúng tôi sẽ đề cập đến những điều này sau để chỉ ra cách bạn có thể xây dựng các ứng dụng tuyệt vời.

Bây giờ chúng ta đã thấy một vài mẫu, hãy tóm tắt lại cách các neo vị trí có thể được sử dụng để tạo chúng, bắt đầu với các bước cần thiết để thiết lập Cấu hình theo dõi địa lý.

Đầu tiên, xác minh rằng tính năng này được hỗ trợ trên thiết bị.

Các neo vị trí yêu cầu chip A12 hoặc mới hơn và hỗ trợ di động và GPS.

Tiếp theo, hãy kiểm tra xem tính năng có sẵn tại địa điểm trước khi khởi chạy hay không.

Quyền sử dụng máy ảnh và vị trí phải được chủ sở hữu thiết bị chấp thuận.

ARKit sẽ nhắc nhở các quyền nếu cần.

Bài thuyết trình năm ngoái giới thiệu ARKit 4 và dự án mẫu, "Theo dõi vị trí địa lý trong AR", bao gồm tất cả các chủ đề này và việc sử dụng API sâu hơn.

Chúng tôi thực sự khuyên bạn nên tự làm quen với cả hai nguồn này.

Mẫu mã này cho thấy cách thực hiện kiểm tra từ trang chiếu trước đó.

Nó truy vấn hỗ trợ thiết bị và sau đó xác minh xem tính năng có khả dụng tại vị trí hiện tại hay không trước khi cố gắng chạy Cấu hình theo dõi địa lý.

GeoAnchors sau đó có thể được thêm vào ARSession giống như các loại neo khác.

Chúng được chỉ định với tọa độ vĩ độ-kinh độ và, tùy chọn, độ cao.

Điều quan trọng là phải theo dõi trạng thái của GeoTrackingConfiguration để xem liệu tính năng đó có được bản địa hóa hay không và những vấn đề nào có thể vẫn cần được giải quyết.

Mẫu nhà phát triển chứa một ví dụ về cách triển khai phương pháp nhận cập nhật trạng thái.

Kiểm tra tính khả dụng gần vị trí thiết bị rất quan trọng để bắt đầu một ứng dụng với theo dõi địa lý.

Chúng tôi liên tục làm việc để hỗ trợ nhiều khu vực hơn.

Các mỏ neo vị trí bị giới hạn ở năm khu vực đô thị để phát hành ban đầu và kể từ đó, hỗ trợ đã mở rộng đến hơn 25 thành phố trên khắp Hoa Kỳ.

Chúng tôi cũng đang làm việc chăm chỉ để đưa các mỏ neo vị trí đến các thành phố trên toàn cầu.

Lần đầu tiên, chúng tôi vui mừng thông báo một thị trường bên ngoài Hoa Kỳ.

Các mỏ neo địa điểm đang đến London.

Chúng tôi sẽ tiếp tục làm việc để thêm các khu vực mới theo thời gian.

Nếu bạn không sống trong khu vực tàu điện ngầm được hỗ trợ, bạn cũng có thể bắt đầu thử nghiệm với các neo vị trí thông qua việc sử dụng ghi âm và phát lại, chúng tôi sẽ đề cập sau trong phiên này.

Để biết danh sách các khu vực được hỗ trợ, hãy tham khảo tài liệu trực tuyến cho ARGeoTrackingConfiguration bất cứ lúc nào.

Khi các neo vị trí có sẵn ở nhiều khu vực hơn, chúng tôi nhận ra sự cần thiết phải có một ngôn ngữ hình ảnh chung để hướng dẫn mọi người.

Để hỗ trợ quy trình giới thiệu nhất quán, chúng tôi đang thêm mục tiêu .geoTracking mới để sử dụng với ARCoachingOverlayView.

Tương tự như lớp phủ hiện có để theo dõi thế giới, nó hiển thị một hình ảnh động để giúp mọi người đạt được trải nghiệm tốt.

Vì lớp phủ huấn luyện được sử dụng trên nhiều ứng dụng AR khác nhau, bao gồm cả Bản đồ, mọi người sẽ quen thuộc với chúng và biết cách phản hồi.

Chúng tôi khuyến khích bạn bao gồm lớp phủ huấn luyện để giảm bớt đường cong học tập cho tính năng này.

Ngay cả khi sử dụng lớp phủ huấn luyện, vẫn nên theo dõi các cập nhật trạng thái .geoTracking, chứa thông tin chi tiết hơn về trạng thái theo dõi.

Đây là lớp phủ huấn luyện .geoTracking trông như thế nào.

Giao diện người dùng hiển thị hướng dẫn hướng thiết bị ra khỏi mặt đất và sau đó hướng tới mặt tiền tòa nhà.

Sau vài giây, theo dõi thành công và ứng dụng của bạn có thể đặt nội dung được theo dõi theo địa lý.

Mã để hiển thị hình ảnh động này rất giống với mã được sử dụng cho các lớp phủ huấn luyện khác.

Điều độc đáo là sự ra đời của mục tiêu .geoTracking cho lớp phủ.

Đảm bảo đặt mục tiêu này để hiển thị hướng dẫn chính xác.

Chúng tôi đã thấy lớp phủ huấn luyện có thể tạo ra một quy trình giới thiệu đồng phục như thế nào.

Bây giờ chúng ta sẽ xem xét một số phương pháp hay nhất khác sẽ giúp bạn tạo ra trải nghiệm AR được theo dõi theo địa lý.

Đề xuất đầu tiên của chúng tôi là sử dụng ghi âm và phát lại để phát triển nhanh hơn.

Các phiên ARKit có thể được ghi lại trên các thiết bị sử dụng Reality Composer, có sẵn trên App Store.

Điều này đặc biệt hữu ích cho việc neo vị trí nên bạn không cần phải ra ngoài thường xuyên để kiểm tra.

Nó cũng cho phép cộng tác với những người sáng tạo nằm ở xa.

Các bản ghi âm có thể được phát lại trên một thiết bị sử dụng Xcode.

Để tránh các vấn đề không tương thích, bạn nên sử dụng cùng một thiết bị và phiên bản iOS.

Điều này cũng hoạt động cho các loại ứng dụng ARKit khác.

Phát lại không dành riêng cho các neo vị trí.

Hãy cùng xem qua quy trình ghi lại bản ghi âm.

Để ghi lại, hãy mở Reality Composer và nhấn để có thêm tùy chọn ở phía trên bên phải.

Sau đó mở ngăn Nhà phát triển và chọn Ghi lại Phiên AR.

Đảm bảo rằng các dịch vụ định vị được bật.

Nhấn vào nút màu đỏ để bắt đầu và dừng ghi âm.

Để phát lại bản ghi âm, hãy kết nối thiết bị với máy tính đang chạy Xcode.

Nhấp vào Chỉnh sửa Sơ đồ và đặt tùy chọn Dữ liệu Phát lại ARKit cho cấu hình đang chạy.

Sau đó chạy ứng dụng.

Mặc dù ghi âm và phát lại có thể giúp tăng tốc độ phát triển, nhưng có những phương pháp khác mà chúng tôi đề xuất cho việc đặt nội dung.

Đây là một video minh họa những điều này.

Lưu ý cách nội dung AR lớn và có thể nhìn thấy rõ ràng, và thông tin được truyền tải mà không cần phải phủ một cấu trúc trong môi trường.

Như một sự đánh đổi giữa thời gian phát triển và độ chính xác của vị trí, hãy cân nhắc việc tạo ra nội dung trôi nổi trong không khí thay vì cố gắng chồng chéo chặt chẽ các vật thể trong thế giới thực.

Chúng tôi có một vài đề xuất khác để đặt nội dung.

Để có được tọa độ vĩ độ và kinh độ để đặt các đối tượng, hãy sử dụng ứng dụng Apple Maps và sao chép tọa độ với độ chính xác ít nhất sáu chữ số.

Các bước cho việc này đã được hiển thị trong video giới thiệu ARKit 4, vì vậy vui lòng tham khảo ở đó để biết thêm chi tiết.

Khi tạo một ứng dụng, điều quan trọng là phải điều chỉnh độ cao của nội dung so với neo vị trí khi cần thiết để tạo ra trải nghiệm tốt.

Nếu ứng dụng yêu cầu vị trí nội dung chính xác hơn, hãy thêm neo địa lý khi thiết bị cách vị trí của nó trong vòng 50 mét.

Nếu ARKit đặt mỏ neo với độ cao chính xác, nó sẽ cập nhật trường nguồn độ cao của mỏ neo để chỉ ra điều này.

Lớp CLLocation có một phương pháp có thể được sử dụng để tính toán khoảng cách tính bằng mét giữa hai điểm.

Điều này có thể được sử dụng để xác minh rằng ai đó đang ở gần một vị trí trước khi thêm neo.

Điều này kết thúc phiên họp của chúng tôi về vị trí neo đậu.

Có nhiều cách hơn để đặt nội dung AR trong ứng dụng của bạn bằng ARKit 5.

Vì vậy, hãy để tôi giao nó cho Christopher, người sẽ cho bạn biết thêm.

Cảm ơn bạn, David.

Xin chào, tên tôi là Christopher, và tôi là một kỹ sư trong nhóm ARKit.

Tôi rất vui được cho bạn biết thêm về các tính năng mới tuyệt vời khác trong ARKit 5.

Hãy để tôi bắt đầu với App Clip Codes trong ARKit.

Bạn có thể nhớ rằng chúng tôi đã giới thiệu App Clips tại WWDC vào năm ngoái.

Clip ứng dụng là một phần nhỏ của ứng dụng đưa mọi người qua một quy trình làm việc theo ngữ cảnh của ứng dụng của bạn mà không cần phải cài đặt toàn bộ ứng dụng.

Do kích thước tệp nhỏ, một clip ứng dụng tiết kiệm thời gian tải xuống và ngay lập tức đưa mọi người trực tiếp đến một phần cụ thể của ứng dụng có liên quan cao đến ngữ cảnh của họ vào lúc này.

Chúng tôi cũng đã giới thiệu App Clip Codes, đây là một cách tuyệt vời để mọi người khám phá và khởi chạy trực quan các clip ứng dụng của bạn.

Không cần chuyến đi đến App Store.

Đây là mã clip ứng dụng trông như thế nào.

Chúng có thể có nhiều hình dạng và màu sắc khác nhau.

Với tư cách là nhà phát triển, bạn có thể tạo ra một giao diện phù hợp nhất với kịch bản của mình.

Bạn cũng quyết định dữ liệu nào cần mã hóa trong Mã clip ứng dụng và clip ứng dụng nào được liên kết với mã nào.

Tất cả các mã clip ứng dụng đều chứa mẫu có thể quét trực quan và một số mã màu đỏ, xanh dương và cam được hiển thị ở đây, cũng chứa thẻ NFC để thuận tiện cho người dùng.

Mọi người có thể quét mã bằng máy ảnh của họ hoặc giữ điện thoại vào thẻ NFC được nhúng để khởi chạy clip ứng dụng liên quan của bạn.

Và bây giờ, bạn cũng có thể nhận ra và theo dõi Mã Clip Ứng dụng trong trải nghiệm AR của mình.

Chúng ta sẽ xem xét điều đó được thực hiện như thế nào sau trong phiên này.

Nhưng trước tiên, chúng ta hãy xem clip ứng dụng này được phát triển bởi Primer, nơi họ sử dụng Mã clip ứng dụng để khởi chạy trải nghiệm AR.

Primer hợp tác với Cle Tile để cho mọi người thấy các mẫu của họ sẽ trông như thế nào trong AR với sự trợ giúp của App Clip Codes.

Chỉ cần đặt iPhone và iPad của bạn qua App Clip Code để gọi trải nghiệm AR.

Giờ đây, mọi người có thể xem trước mẫu gạch trên tường của họ mà không cần tải xuống ứng dụng.

Điều đó khá tuyệt, phải không?

Vì vậy, bắt đầu với iOS và iPad 14.3, bạn có thể phát hiện và theo dõi Mã clip ứng dụng trong trải nghiệm AR.

Lưu ý rằng việc theo dõi Mã Clip Ứng dụng yêu cầu các thiết bị có bộ xử lý A12 Bionic trở lên, như iPhone XS.

Chúng ta hãy xem xét kỹ hơn cách sử dụng Mã Clip Ứng dụng trong ARKit.

Trong iOS 14.3, chúng tôi đã giới thiệu một loại ARAnchor mới, ARAppClipCodeAnchor.

Neo này có ba thuộc tính mới: URL được nhúng trong App Clip Code, trạng thái giải mã URL và bán kính của App Clip Code tính bằng mét.

Để tôi giải thích.

Mỗi App Clip Code chứa một URL được giải mã để hiển thị nội dung chính xác.

Giải mã URL không phải là ngay lập tức.

ARKit có thể phát hiện sự hiện diện của Mã Clip Ứng dụng một cách nhanh chóng.

Nhưng có thể mất nhiều thời gian hơn một chút để ARKit giải mã URL, tùy thuộc vào khoảng cách của người dùng đến mã và các yếu tố khác như ánh sáng.

Đây là lý do tại sao neo App Clip Code chứa thuộc tính trạng thái .decoding và nó có thể ở một trong ba trạng thái.

Trạng thái ban đầu .decoding chỉ ra rằng ARKit vẫn đang giải mã URL.

Ngay sau khi ARKit giải mã thành công URL, trạng thái sẽ chuyển sang .decoded.

Khi không thể giải mã URL, thay vào đó trạng thái sẽ chuyển sang .failed.

Ví dụ, điều này có thể xảy ra khi ai đó quét Mã clip ứng dụng không được liên kết với clip ứng dụng.

Để sử dụng theo dõi Mã Clip Ứng dụng, trước tiên bạn nên kiểm tra xem nó có được hỗ trợ trên thiết bị hay không.

Hãy nhớ rằng việc theo dõi Mã Clip Ứng dụng chỉ được hỗ trợ trên các thiết bị có bộ xử lý A12 Bionic trở lên.

Sau đó đặt thuộc tính appClipCodeTrackingEnabled trên cấu hình của bạn thành true và chạy phiên.

Để đọc URL của Mã Clip Ứng dụng, hãy theo dõi các phiên AR đã cập nhật lệnh gọi lại Anchors và kiểm tra trạng thái giải mã của bất kỳ neo Mã Clip Ứng dụng nào được phát hiện.

Trong khi ARKit đang giải mã mã App Clip Code, bạn có thể muốn hiển thị hình ảnh trình giữ chỗ trên đầu App Clip Code để cung cấp cho người dùng phản hồi tức thì rằng App Clip Code đã được phát hiện nhưng vẫn cần được giải mã.

Như đã đề cập trước đây, giải mã mã App Clip cũng có thể thất bại. Ví dụ, khi ai đó chĩm điện thoại vào Mã clip ứng dụng không thuộc về clip ứng dụng của bạn.

Chúng tôi khuyên bạn cũng nên đưa ra phản hồi trong trường hợp đó.

Khi Mã Clip Ứng dụng đã được giải mã, cuối cùng bạn có thể truy cập URL của nó và bắt đầu hiển thị nội dung phù hợp cho Mã Clip Ứng dụng này.

Ví dụ, trong trường hợp clip ứng dụng Primer mà bạn đã thấy trước đó, URL chứa thông tin về mẫu gạch nào sẽ hiển thị.

Khi Mã Clip Ứng dụng đã được giải mã, câu hỏi đặt ra là, bạn nên hiển thị nội dung được liên kết với mã này ở đâu?

Một lựa chọn là hiển thị nó trực tiếp trên đầu neo App Clip Code.

Tuy nhiên, tùy thuộc vào trường hợp sử dụng của bạn, bản thân App Clip Code có thể không phải là nơi tốt nhất để hiển thị nội dung.

Vì vậy, ví dụ, bạn có thể định vị nội dung gần Mã clip ứng dụng với vị trí tương đối cố định.

Điều này hoạt động tốt khi App Clip Code được in trên một đối tượng, chẳng hạn như máy pha cà phê và bạn muốn hiển thị hướng dẫn ảo về cách vận hành nó trên các nút của máy.

Hoặc bạn có thể kết hợp theo dõi App Clip Code với các công nghệ theo dõi khác được hỗ trợ bởi ARKit.

Ví dụ, theo dõi hình ảnh.

Chúng ta hãy xem xét việc thực hiện điều đó.

Các video và mã mà bạn thấy tiếp theo dựa trên mã mẫu "Tương tác với mã clip ứng dụng trong AR" mà bạn có thể tải xuống trên developer.apple.com.

Những gì bạn thấy bây giờ là bản ghi lại trải nghiệm AR của mẫu.

Đầu tiên, tôi đang bắt đầu trong ứng dụng Camera, quét một gói hạt hướng dương.

Có lẽ tôi đang mua sắm trong cửa hàng làm vườn, cố gắng quyết định nên mua hạt giống cây trồng nào.

iOS nhận ra Mã Clip Ứng dụng trên gói và khởi chạy clip ứng dụng Seed Shop được liên kết.

Ở đây, tôi đang quét App Clip Code lần thứ hai, và sau đó hoa hướng dương đã trưởng thành xuất hiện trên gói hạt giống.

Lưu ý rằng clip ứng dụng sử dụng theo dõi hình ảnh của toàn bộ gói hạt giống và đặt hoa hướng dương lên đó.

Cách tiếp cận này có ý nghĩa trong trường hợp sử dụng này, vì sự chú ý của người đó rất có thể là trên toàn bộ gói hạt giống chứ không phải trên Mã clip ứng dụng nhỏ hơn ở trên cùng bên phải.

Nhưng nếu ai đó muốn nhìn thấy cây mọc trong vườn của họ thì sao?

Đây là những gì có thể trông như thế nào.

Ở đây chúng ta thấy rằng khi mã được quét lần đầu tiên, nó sẽ gọi tải xuống clip ứng dụng.

Sau đó, khi cùng một mã được quét lại từ bên trong clip ứng dụng, nó sẽ liên kết mã với hộp hạt hướng dương và sau đó chạm vào bãi cỏ sẽ làm cho hoa hướng dương xuất hiện ở đó.

Thay vào đó, nếu clip ứng dụng nhìn thấy mã trên hộp hạt giống hoa hồng, nó sẽ sinh ra một cây hoa hồng trên bãi cỏ.

Lưu ý rằng các clip ứng dụng được cho là chỉ chứa một quy trình làm việc.

Nhưng clip ứng dụng có thể cung cấp một nút để tải xuống ứng dụng Seed Shop đầy đủ để trải nghiệm các loại cây khác mà họ có thể xem trước trong không gian của mình.

Hãy nhớ rằng, theo dõi Mã Clip Ứng dụng cũng hoạt động trong ứng dụng mẹ của App Clip.

Chúng ta hãy xem mã mà chúng ta cần để đặt hoa hướng dương trên bãi cỏ.

Đầu tiên, bạn thêm một tapGestureRecognizer vào chế độ xem để phát hiện các vòi trên màn hình.

Khi người đó chạm vào màn hình, bạn có thể chiếu một tia vào thế giới và lấy lại vị trí kết quả trên mặt phẳng nằm ngang phía trước thiết bị của họ.

Trong kịch bản của chúng tôi, đây sẽ là bãi cỏ của người đó.

Sau đó, bạn lấy URL Mã Clip Ứng dụng cuối cùng đã được giải mã và thêm một ARAnchor mới trên bãi cỏ.

Cuối cùng, bạn tải xuống mô hình 3D hướng dương và hiển thị nó trên bãi cỏ.

Bây giờ, hãy nói về một số phương pháp hay nhất cho App Clip Codes trong ARKit.

Các clip ứng dụng có thể được sử dụng trong các môi trường khác nhau và cho các trường hợp sử dụng khác nhau.

Xem xét liệu đó có phải là một lựa chọn để bạn tạo Mã Clip Ứng dụng NFC hay không.

Chúng tôi đề xuất Mã kẹp ứng dụng NFC cho các môi trường mà mọi người có thể truy cập mã một cách vật lý.

Khi sử dụng Mã kẹp ứng dụng NFC, hãy sử dụng văn bản kêu gọi hành động thích hợp hướng dẫn mọi người nhấn vào thẻ hoặc, cách khác, cung cấp khả năng rõ ràng để quét mã.

Cuối cùng nhưng không kém phần quan trọng, bạn cần đảm bảo rằng Mã clip ứng dụng của bạn được in trên kích thước phù hợp với môi trường của người dùng.

Ví dụ, thực đơn nhà hàng có thể được in trên giấy A4 và mọi người sẽ cảm thấy thoải mái khi quét Mã kẹp ứng dụng 2,5 cm trên thực đơn đó từ khoảng cách lên đến 50 cm.

Tuy nhiên, một áp phích phim thường lớn hơn nhiều và có thể có đủ không gian cho Mã clip ứng dụng 12 cm mà mọi người có thể quét bằng điện thoại của họ từ khoảng cách lên đến 2,5 mét.

Vui lòng xem Hướng dẫn Giao diện Con người của chúng tôi về Mã Kẹp Ứng dụng để biết thêm thông tin về kích thước mã được đề xuất.

Vậy đó là cách bạn sử dụng App Clip Codes trong ARKit.

Nếu bạn muốn đi sâu hơn vào các clip ứng dụng và Mã clip ứng dụng, hãy nhớ xem các phiên "Có gì mới trong clip ứng dụng" và "Xây dựng clip ứng dụng nhẹ và nhanh".

Bây giờ chúng ta hãy chuyển sang theo dõi khuôn mặt.

Theo dõi khuôn mặt cho phép bạn phát hiện khuôn mặt trong camera phía trước, phủ nội dung ảo và tạo hiệu ứng động cho biểu cảm khuôn mặt trong thời gian thực.

Kể từ khi ra mắt iPhone X, ARKit đã thấy rất nhiều ứng dụng tuyệt vời tận dụng tính năng theo dõi khuôn mặt.

Từ việc theo dõi nhiều khuôn mặt đến chạy theo dõi khuôn mặt trong trường hợp sử dụng camera trước và sau đồng thời, API này đã nhận được một số tiến bộ trong những năm qua.

Năm ngoái, chúng tôi đã giới thiệu tính năng theo dõi khuôn mặt trên các thiết bị không có cảm biến TrueDepth, miễn là chúng có bộ xử lý A12 Bionic trở lên.

Và đầu năm nay, chúng tôi đã ra mắt iPad Pro mới cung cấp cho bạn camera mặt trước trường nhìn cực rộng cho trải nghiệm theo dõi khuôn mặt AR của bạn.

Hãy cùng xem nào.

Ở đây bạn thấy trường nhìn của máy ảnh mặt trước thông thường.

Và đây là trường nhìn siêu rộng mới trên iPad Pro mới.

Nó thực sự tạo ra sự khác biệt, phải không?

Lưu ý rằng các ứng dụng hiện tại của bạn sẽ tiếp tục sử dụng máy ảnh bình thường để theo dõi khuôn mặt.

Nếu bạn muốn nâng cấp trải nghiệm của người dùng lên trường nhìn siêu rộng trên iPad Pro mới, bạn phải kiểm tra định dạng video nào có sẵn và chọn tham gia định dạng siêu rộng mới.

Bạn có thể làm điều này bằng cách lặp lại tất cả các định dạng video được hỗ trợ và kiểm tra tùy chọn builtInUltraWideCamera.

Sau đó, bạn đặt định dạng này trên cấu hình AR của mình và chạy phiên.

Một điều cần lưu ý là camera siêu rộng của iPad Pro mới có trường nhìn lớn hơn nhiều so với cảm biến TrueDepth.

Do đó, bạn sẽ không nhận được bộ đệm capturedDepthData trên ARFrame khi sử dụng định dạng video siêu rộng.

Cuối cùng nhưng không kém phần quan trọng, hãy nói về chụp chuyển động.

Kể từ khi ra mắt vào năm 2019, chụp chuyển động đã cho phép tích hợp mạnh mẽ người thật trong các cảnh AR, chẳng hạn như tạo hoạt ảnh cho các nhân vật ảo cùng với việc được sử dụng trong mô phỏng 2D và 3D.

Trong iOS 15, chụp chuyển động thậm chí còn tốt hơn.

Trên các thiết bị có bộ xử lý Apple A14 Bionic như iPhone 12, tính năng chụp chuyển động hiện hỗ trợ nhiều tư thế cơ thể hơn.

Và điều này không yêu cầu thay đổi mã nào cả.

Tất cả các ứng dụng chụp chuyển động trên iOS 15 sẽ được hưởng lợi từ điều này.

Đáng chú ý nhất, các vòng quay chính xác hơn bao giờ hết, giúp bạn theo dõi các hành động thể thao với độ chính xác cao hơn nhiều.

Một cải tiến lớn khác là máy ảnh thiết bị của bạn giờ đây có thể theo dõi các khớp cơ thể từ một khoảng cách xa hơn nhiều.

Ngoài ra, đã có sự gia tăng đáng kể trong việc theo dõi phạm vi chuyển động của chi.

Hãy xem xét một ví dụ.

Đây là một trong những đồng nghiệp của tôi, Ejler, theo dõi quá trình tập luyện của anh ấy với ứng dụng Driven2win.

Kết quả trên iOS 15 chính xác hơn bao giờ hết.

Tóm lại, ARKit 5 mang đến rất nhiều tính năng và cải tiến mới.

Các mỏ neo vị trí có sẵn ở các thành phố mới và có lớp phủ huấn luyện mới.

Theo dõi mã clip ứng dụng hỗ trợ dễ dàng khám phá và sử dụng AR trong clip ứng dụng của bạn, cũng như định vị chính xác nội dung ảo của bạn.

Theo dõi khuôn mặt hoạt động với trường nhìn siêu rộng mới trên iPad Pro mới và chụp chuyển động tăng thêm độ chính xác tốt hơn và phạm vi chuyển động lớn hơn.

Tôi rất hào hứng khi thấy tất cả những trải nghiệm tuyệt vời mà bạn sẽ tạo ra với ARKit 5.

[Âm nhạc].