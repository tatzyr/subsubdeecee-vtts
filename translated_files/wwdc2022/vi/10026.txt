10026

♪ Nhạc hip-hop nhạc cụ êm dịu ♪

♪

Xin chào! Tên tôi là Adam Bradford.

Tôi là một kỹ sư trong nhóm VisionKit và nếu bạn đang muốn thêm Live Text vào ứng dụng của mình, bạn đã đến đúng nơi.

Nhưng trước tiên, Live Text là gì?

Live Text phân tích một hình ảnh và cung cấp các tính năng để người dùng tương tác với nội dung của nó, chẳng hạn như chọn và sao chép văn bản, thực hiện các hành động như tra cứu và dịch, cung cấp quy trình phát hiện dữ liệu, chẳng hạn như lập bản đồ địa chỉ, quay số hoặc chuyển đến URL.

Văn bản trực tiếp thậm chí còn cho phép tương tác mã QR.

Hãy tưởng tượng làm thế nào bạn có thể đưa cái này vào sử dụng trong ứng dụng của mình?

Bạn muốn biết thêm? Chà, bạn đang ở đúng nơi.

Đối với phiên này, tôi sẽ bắt đầu với tổng quan chung về API Văn bản Trực tiếp.

Sau đó tôi sẽ khám phá cách triển khai API này trong một ứng dụng hiện có.

Tiếp theo, tôi sẽ đi sâu vào một số mẹo và thủ thuật có thể giúp bạn khi thêm Live Text vào ứng dụng của bạn.

Bây giờ để có cái nhìn tổng quan về API Văn bản Trực tiếp.

Ở cấp độ cao, Live Text API có sẵn trong Swift.

Nó hoạt động tốt trên các hình ảnh tĩnh và có thể được điều chỉnh để sử dụng cho các khung hình video bị tạm dừng.

Nếu bạn cần phân tích video trong luồng camera trực tiếp để tìm kiếm các mục như văn bản hoặc mã QR, VisionKit cũng có sẵn trình quét dữ liệu.

Kiểm tra phiên này từ đồng nghiệp Ron của tôi để biết thêm thông tin.

Live Text API có sẵn bắt đầu từ iOS 16 cho các thiết bị có Apple Neural Engine và cho tất cả các thiết bị hỗ trợ macOS 13.

Nó bao gồm bốn lớp chính.

Để sử dụng nó, trước tiên, bạn sẽ cần một hình ảnh.

Hình ảnh này sau đó được đưa vào ImageAnalyzer, thực hiện phân tích không đồng bộ.

Khi phân tích hoàn tất, đối tượng ImageAnalysis kết quả được cung cấp cho ImageAnalysisInteraction hoặc ImageAnalysisOverlayView, tùy thuộc vào nền tảng của bạn.

Có vẻ khá đơn giản cho đến nay, phải không?

Bây giờ, tôi sẽ chứng minh cách người ta sẽ thêm nó vào một ứng dụng hiện có.

Và đây là ứng dụng của chúng tôi.

Đây là một trình xem hình ảnh đơn giản, có chế độ xem hình ảnh bên trong chế độ xem cuộn.

Lưu ý, tôi có thể vừa phóng to vừa xoay.

Nhưng hãy cố gắng hết sức có thể, tôi không thể chọn bất kỳ văn bản nào trong số này hoặc kích hoạt bất kỳ máy dò dữ liệu nào trong số này.

Điều này đơn giản là sẽ không làm được.

Đây là dự án trong Xcode.

Để thêm Live Text vào ứng dụng này, tôi sẽ sửa đổi một lớp con của bộ điều khiển chế độ xem.

Đầu tiên, tôi sẽ cần một ImageAnalyzer, và một ImageAnalysisInteraction.

Ở đây, tôi chỉ đơn giản là ghi đè viewDidLoad và thêm tương tác vào chế độ xem hình ảnh.

Tiếp theo, tôi cần biết khi nào nên thực hiện phân tích.

Lưu ý rằng khi một hình ảnh mới được đặt, trước tiên tôi đặt lại các Loại Tương tác ưa thích và phân tích dành cho hình ảnh cũ.

Bây giờ mọi thứ đã sẵn sàng cho một phân tích mới.

Tiếp theo, tôi sẽ tạo ra chức năng mà chúng ta sẽ sử dụng và sau đó kiểm tra xem hình ảnh của chúng ta có tồn tại không.

Nếu vậy, hãy tạo một nhiệm vụ.

Tiếp theo, tạo một cấu hình để cho máy phân tích biết những gì nó nên tìm kiếm.

Trong trường hợp này, tôi sẽ sử dụng văn bản và mã có thể đọc được bằng máy.

Tạo ra phân tích có thể ném, vì vậy hãy xử lý điều đó khi thích hợp.

Và bây giờ cuối cùng, tôi đã sẵn sàng gọi phương thức analyzeImageWithConfiguration, phương thức này sẽ bắt đầu quá trình phân tích.

Sau khi phân tích hoàn tất, một khoảng thời gian không xác định đã trôi qua và trạng thái của ứng dụng có thể đã thay đổi, vì vậy tôi sẽ kiểm tra xem cả hai phân tích đã thành công và hình ảnh được hiển thị không thay đổi.

Nếu tất cả các kiểm tra này vượt qua, tôi có thể chỉ cần đặt phân tích về tương tác và đặt các Loại Tương tác ưa thích.

Tôi đang sử dụng .automatic ở đây, điều này sẽ cho tôi hành vi hệ thống mặc định.

Tôi nghĩ cái này đã sẵn sàng cho một bài kiểm tra.

Ồ, nhìn kìa!

Tôi thấy nút Văn bản Trực tiếp đã xuất hiện, và vâng, bây giờ tôi có thể chọn văn bản.

Chú ý cách các yếu tố giao diện này được định vị tự động cho tôi và giữ vị trí của chúng bên trong cả giới hạn hình ảnh và khu vực hiển thị, mà không cần làm việc từ phía tôi.

Được rồi, lưu ý rằng nhấn vào nút Văn bản Trực tiếp sẽ làm nổi bật bất kỳ mục nào có thể lựa chọn, gạch chân máy dò dữ liệu và hiển thị Hành động nhanh.

Tôi có thể dễ dàng nhấn vào Hành động nhanh này để thực hiện cuộc gọi và thậm chí xem nhiều tùy chọn hơn bằng cách nhấn và giữ.

Bạn phải thừa nhận, điều này khá tuyệt.

Chỉ với vài dòng mã này, tôi đã chụp một bức ảnh bình thường và đưa nó vào cuộc sống.

Ứng dụng đơn giản này hiện có khả năng chọn văn bản trên hình ảnh, kích hoạt máy dò dữ liệu, mã QR, tra cứu, dịch văn bản và hơn thế nữa.

Không quá tồi tàn chỉ từ vài dòng mã này, nếu bạn hỏi tôi.

Và bây giờ bạn đã thấy cách triển khai Live Text, tôi sẽ xem xét một vài mẹo và thủ thuật có thể giúp bạn áp dụng.

Tôi sẽ bắt đầu bằng cách khám phá các loại tương tác.

Hầu hết các nhà phát triển sẽ muốn .automatic, cung cấp lựa chọn văn bản, nhưng cũng sẽ làm nổi bật các trình phát hiện dữ liệu nếu nút Live Text đang hoạt động.

Điều này sẽ vẽ một đường bên dưới bất kỳ mục nào được phát hiện có thể áp dụng và cho phép truy cập một lần nhấn để kích hoạt chúng.

Đây chính xác là hành vi mà bạn sẽ thấy từ các ứng dụng tích hợp sẵn.

Nếu ứng dụng của bạn chỉ có lựa chọn văn bản mà không có trình phát hiện dữ liệu, bạn có thể đặt loại thành .textSelection và nó sẽ không thay đổi theo trạng thái của nút Văn bản Trực tiếp.

Tuy nhiên, nếu ứng dụng của bạn chỉ có máy dò dữ liệu mà không có lựa chọn văn bản, hãy đặt loại thành .dataDetectors.

Lưu ý rằng trong chế độ này, vì lựa chọn bị vô hiệu hóa, bạn sẽ không thấy nút Văn bản Trực tiếp, nhưng các trình phát hiện dữ liệu sẽ được gạch chân và sẵn sàng để truy cập một lần nhấn.

Đặt các Loại Tương tác ưa thích thành một tập hợp trống sẽ vô hiệu hóa tương tác.

Ngoài ra, lưu ý cuối cùng, với lựa chọn văn bản hoặc chế độ tự động, bạn sẽ thấy mình vẫn có thể kích hoạt máy dò dữ liệu bằng cách nhấn và giữ.

Điều này được kiểm soát bởi thuộc tính allowLongPressForDataDetectorsIn TextMode, sẽ hoạt động khi được đặt thành true, mặc định.

Chỉ cần đặt thành sai để vô hiệu hóa điều này nếu cần thiết.

Bây giờ tôi muốn dành một chút thời gian và nói về các nút này ở dưới cùng, được gọi chung là giao diện bổ sung.

Điều này bao gồm nút Văn bản Trực tiếp, thường nằm ở góc dưới cùng bên phải, cũng như Hành động Nhanh xuất hiện ở phía dưới bên trái.

Hành động nhanh đại diện cho bất kỳ máy dò dữ liệu nào từ phân tích và hiển thị khi nút Văn bản Trực tiếp đang hoạt động.

Kích thước, vị trí và khả năng hiển thị được kiểm soát bởi sự tương tác.

Và trong khi vị trí và giao diện mặc định phù hợp với hệ thống, ứng dụng của bạn có thể có các yếu tố giao diện tùy chỉnh có thể can thiệp hoặc sử dụng các phông chữ và trọng số biểu tượng khác nhau.

Hãy xem cách bạn có thể tùy chỉnh giao diện này.

Trước hết, thuộc tính isSupplementary InterfaceHidden.

Nếu tôi muốn cho phép ứng dụng của mình vẫn chọn văn bản nhưng tôi không muốn hiển thị nút Văn bản Trực tiếp, nếu tôi đặt Giao diện Bổ sung Ẩn thành đúng, bạn sẽ không thấy bất kỳ nút Văn bản Trực tiếp hoặc Hành động Nhanh nào.

Chúng tôi cũng có sẵn một thuộc tính nội dung.

Nếu bạn có các yếu tố giao diện chồng lên giao diện bổ sung, bạn có thể điều chỉnh nội dung để nút Văn bản trực tiếp và Hành động nhanh thích ứng tốt với nội dung ứng dụng hiện có của bạn khi hiển thị.

Nếu ứng dụng của bạn đang sử dụng phông chữ tùy chỉnh mà bạn muốn giao diện áp dụng, việc đặt Phông chữ giao diện bổ sung sẽ khiến nút Văn bản trực tiếp và Hành động nhanh sử dụng phông chữ được chỉ định cho văn bản và trọng lượng phông chữ cho các ký hiệu.

Xin lưu ý rằng để nhất quán về kích thước nút, Live Text sẽ bỏ qua kích thước điểm.

Chuyển đổi bánh răng trong giây lát, nếu bạn không sử dụng UIImageview, bạn có thể phát hiện ra rằng các điểm nổi bật không khớp với hình ảnh của bạn.

Điều này là do với UIImageView, VisionKit có thể sử dụng thuộc tính ContentMode của nó để tính toán contentsRect tự động cho bạn.

Ở đây, chế độ xem của tương tác có giới hạn lớn hơn nội dung hình ảnh của nó nhưng đang sử dụng trực tràng nội dung mặc định, là một hình chữ nhật đơn vị.

Điều này có thể dễ dàng giải quyết bằng cách triển khai phương thức đại diện contentsRectForInteraction và trả về một hình chữ nhật trong không gian tọa độ đơn vị mô tả cách nội dung hình ảnh liên quan đến giới hạn của tương tác để sửa lỗi này.

Ví dụ: trả về một hình chữ nhật với các giá trị này sẽ khắc phục sự cố, nhưng vui lòng trả lại hình chữ nhật chuẩn hóa chính xác dựa trên nội dung và bố cục hiện tại của ứng dụng của bạn.

contentsRectForInteraction sẽ được gọi bất cứ khi nào giới hạn của tương tác thay đổi, tuy nhiên, nếu contentsRect của bạn đã thay đổi nhưng giới hạn tương tác của bạn thì không, bạn có thể yêu cầu tương tác cập nhật bằng cách gọi setContentsRectNeedsUpdate().

Một câu hỏi khác mà bạn có thể có khi áp dụng Live Text có thể là, Đâu là nơi tốt nhất để đặt sự tương tác này?

Lý tưởng nhất, các tương tác Văn bản Trực tiếp được đặt trực tiếp trên chế độ xem lưu trữ nội dung hình ảnh của bạn.

Như đã đề cập trước đó, UIImageView sẽ xử lý các phép tính contentsRect cho bạn và trong khi không cần thiết, được ưu tiên hơn.

Nếu bạn đang sử dụng UIImageview, chỉ cần đặt tương tác trên imageView và VisionKit sẽ xử lý phần còn lại.

Tuy nhiên, nếu ImageView của bạn nằm bên trong ScrollView, bạn có thể bị cám dỗ để đặt tương tác trên ScrollView, tuy nhiên, điều này không được khuyến khích và có thể khó quản lý vì nó sẽ có nội dung thay đổi liên tụcRect.

Giải pháp ở đây là như nhau, đặt tương tác trên chế độ xem lưu trữ nội dung hình ảnh của bạn, ngay cả khi nó nằm trong ScrollView với độ phóng đại được áp dụng.

Tôi sẽ nói về cử chỉ trong giây lát, Live Text có một bộ nhận dạng cử chỉ rất, rất phong phú, để nói rằng ít nhất.

Tùy thuộc vào cách ứng dụng của bạn được cấu trúc, bạn có thể thấy sự tương tác phản hồi với các cử chỉ và sự kiện mà ứng dụng của bạn thực sự nên xử lý hoặc ngược lại.

Đừng hoảng sợ.

Đây là một vài kỹ thuật bạn có thể sử dụng để giúp sửa chữa nếu bạn thấy những vấn đề này xảy ra.

Một cách phổ biến để sửa lỗi này là triển khai phương thức đại diện interactionShouldBeginAtPointFor InteractionType.

Nếu bạn trả về false, hành động sẽ không được thực hiện.

Một nơi tốt để bắt đầu là kiểm tra xem tương tác có một mục tương tác tại điểm đã cho hay nó có lựa chọn văn bản đang hoạt động hay không.

Kiểm tra lựa chọn văn bản được sử dụng ở đây để bạn có thể có khả năng nhấn vào văn bản để bỏ chọn nó.

Mặt khác, nếu bạn thấy sự tương tác của mình dường như không phản hồi với cử chỉ, có thể là do có một công cụ nhận dạng cử chỉ trong ứng dụng của bạn đang xử lý chúng thay thế.

Trong trường hợp này, bạn có thể tạo ra một giải pháp tương tự bằng cách sử dụng phương thức ủy quyền gestureRecognizerShouldBegin của gestureRecognizer.

Ở đây, tôi thực hiện kiểm tra tương tự và trả về sai nếu có một mục tương tác tại vị trí hoặc có lựa chọn văn bản đang hoạt động.

Trên một lưu ý phụ.

Trong ví dụ này, trước tiên tôi chuyển đổi vị trí của gestureRecognizer thành không gian tọa độ của cửa sổ bằng cách chuyển bằng nil, và sau đó chuyển đổi nó sang chế độ xem tương tác.

Điều này có thể cần thiết nếu sự tương tác của bạn nằm bên trong ScrollView với độ phóng đại được áp dụng.

Nếu bạn thấy điểm của mình không khớp, hãy thử kỹ thuật này.

Một lựa chọn tương tự khác mà tôi thấy hữu ích là ghi đè hitTest:WithEvent của UIView.

Ở đây, một lần nữa, câu chuyện tương tự, tôi thực hiện các loại kiểm tra giống như trước đây, và trong trường hợp này, trả lại chế độ xem thích hợp.

Như mọi khi, chúng tôi muốn ứng dụng của bạn phản hồi nhanh nhất có thể và trong khi Neural Engine giúp phân tích cực kỳ hiệu quả, có một vài mẹo ImageAnalyzer mà tôi muốn chia sẻ để có hiệu suất tốt nhất.

Lý tưởng nhất, bạn chỉ muốn một ImageAnalyzer được chia sẻ trong ứng dụng của mình.

Ngoài ra, chúng tôi hỗ trợ một số loại hình ảnh.

Bạn nên luôn giảm thiểu chuyển đổi hình ảnh bằng cách chuyển sang loại gốc mà bạn có; tuy nhiên, nếu bạn tình cờ có CVPixelBuffer, đó sẽ là hiệu quả nhất.

Ngoài ra, để sử dụng tốt nhất tài nguyên hệ thống, bạn chỉ nên bắt đầu phân tích khi hoặc ngay trước đó, một hình ảnh xuất hiện trên màn hình.

Nếu cuộn nội dung của ứng dụng của bạn - ví dụ, nó có dòng thời gian - chỉ bắt đầu phân tích khi quá trình cuộn đã dừng lại.

Bây giờ API này không phải là nơi duy nhất bạn sẽ thấy Live Text, hỗ trợ được cung cấp tự động trong một vài khuôn khổ trên toàn hệ thống mà ứng dụng của bạn có thể đã sử dụng.

Ví dụ, UITextField hoặc UITextView có hỗ trợ Văn bản Trực tiếp sử dụng Máy ảnh để nhập bàn phím.

Và Live Text cũng được hỗ trợ trong WebKit và Quick Look.

Để biết thêm thông tin, vui lòng xem các phiên này.

Mới trong năm nay cho iOS 16, chúng tôi đã thêm hỗ trợ Văn bản Trực tiếp trong AVKit.

AVPlayerView và ViewController tự động hỗ trợ Live Text trong các khung hình bị tạm dừng thông qua thuộc tính allowsVideoFrameAnalysis, được bật theo mặc định.

Xin lưu ý, điều này chỉ khả dụng với nội dung không được bảo vệ FairPlay.

Nếu bạn đang sử dụng AVPlayerLayer, thì bạn có trách nhiệm quản lý phân tích và tương tác nhưng điều rất quan trọng là sử dụng thuộc tính currentlyDisplayedPixelBuffer để có được khung hiện tại.

Đây là cách duy nhất để đảm bảo khung thích hợp đang được phân tích.

Điều này sẽ chỉ trả về một giá trị hợp lệ nếu tốc độ phát video bằng 0 và đây là một bản sao nông và hoàn toàn không an toàn để ghi vào.

Và một lần nữa, chỉ có sẵn cho nội dung không được bảo vệ FairPlay.

Chúng tôi rất vui mừng được giúp mang chức năng Live Text đến ứng dụng của bạn.

Thay mặt cho tất cả mọi người trong nhóm Live Text, cảm ơn bạn đã tham gia cùng chúng tôi trong phiên này.

Tôi rất vui khi thấy cách bạn sử dụng nó cho hình ảnh trong ứng dụng của mình.

Và như mọi khi, hãy vui vẻ!

♪