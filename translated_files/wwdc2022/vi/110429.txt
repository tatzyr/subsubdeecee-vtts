110429

♪ nhạc cụ hip hop ♪

Xin chào, và chào mừng đến với "Khám phá những tiến bộ trong việc chụp ảnh iOS".

Tôi là Nikolas Gelo từ nhóm Phần mềm Máy ảnh, và tôi sẽ giới thiệu một số tính năng máy ảnh mới thú vị trong iOS và iPadOS.

Tôi sẽ bắt đầu với cách truyền độ sâu từ Máy quét LiDAR bằng AVFoundation.

Tiếp theo, hãy xem ứng dụng của bạn sẽ nhận được kết xuất khuôn mặt được cải thiện như thế nào với tính năng lấy nét tự động điều khiển bằng khuôn mặt và phơi sáng tự động.

Sau đó, tôi sẽ đưa bạn qua các cấu hình phát trực tuyến AVCaptureSession nâng cao.

Và cuối cùng, tôi sẽ chỉ cho bạn cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi đa nhiệm.

Tôi sẽ bắt đầu với cách truyền độ sâu từ Máy quét LiDAR bằng AVFoundation.

iPhone 12 Pro, iPhone 13 Pro và iPad Pro được trang bị Máy quét LiDAR có khả năng xuất bản đồ độ sâu dày đặc.

Máy quét LiDAR hoạt động bằng cách chụp ánh sáng vào môi trường xung quanh, và sau đó thu thập ánh sáng phản xạ từ các bề mặt trong cảnh.

Độ sâu được ước tính bằng cách đo thời gian cần thiết để ánh sáng đi từ LiDAR đến môi trường và phản xạ trở lại máy quét.

Toàn bộ quá trình này chạy hàng triệu lần mỗi giây.

Tôi sẽ chỉ cho bạn Máy quét LiDAR đang hoạt động bằng AVFoundation.

Ở đây trên iPhone 13 Pro Max, tôi đang chạy một ứng dụng sử dụng LiDAR Depth Camera AVCaptureDevice mới.

Ứng dụng hiển thị dữ liệu độ sâu phát trực tuyến trên nguồn cấp dữ liệu camera trực tiếp.

Màu xanh lam được hiển thị cho các vật thể ở gần và màu đỏ cho các vật thể ở xa hơn.

Và sử dụng thanh trượt, tôi có thể điều chỉnh độ mờ của độ sâu.

Ứng dụng này cũng chụp ảnh với bản đồ độ sâu độ phân giải cao.

Khi tôi chụp ảnh, lớp phủ độ sâu tương tự được áp dụng nhưng với độ phân giải thậm chí còn lớn hơn cho ảnh tĩnh.

Ứng dụng này có thêm một mẹo nữa.

Khi tôi nhấn nút ngọn đuốc, ứng dụng sử dụng bản đồ độ sâu độ phân giải cao với hình ảnh màu để hiển thị ánh sáng trên hiện trường bằng RealityKit.

Tôi có thể chạm xung quanh và hướng ánh đèn sân khấu vào các vật thể khác nhau trong cảnh.

Hãy nhìn cách ánh đèn sân khấu làm nổi bật cây đàn guitar.

Hoặc nếu tôi chạm vào đúng vị trí ở góc tường, đèn chiếu sáng tạo thành hình trái tim.

Hãy quay lại với cây đàn guitar đó. Nó trông thật ngầu.

API cho Máy quét LiDAR lần đầu tiên được giới thiệu trong ARKit trong iPadOS 13.4.

Nếu bạn chưa xem bài thuyết trình WWDC 2020 "Khám phá ARKit 4", tôi khuyến khích bạn xem nó.

Mới trong iOS 15.4, ứng dụng của bạn có thể truy cập Máy quét LiDAR với AVFoundation.

Chúng tôi đã giới thiệu một loại thiết bị AVCapture mới, Camera độ sâu LiDAR tích hợp, cung cấp video và chiều sâu.

Nó tạo ra thông tin độ sâu chất lượng cao, độ chính xác cao.

AVCaptureDevice mới này sử dụng camera góc rộng phía sau để cung cấp video với Máy quét LiDAR để ghi lại độ sâu.

Cả video và độ sâu đều được ghi lại trong trường nhìn của máy ảnh góc rộng.

Và giống như TrueDepth AVCaptureDevice, tất cả các định dạng của nó đều hỗ trợ phân phối dữ liệu độ sâu.

AVCaptureDevice mới này tạo ra dữ liệu độ sâu chất lượng cao bằng cách kết hợp đầu ra thưa thớt từ Máy quét LiDAR với hình ảnh màu từ camera góc rộng quay mặt về phía sau.

LiDAR và đầu vào màu sắc được xử lý bằng cách sử dụng mô hình học máy xuất ra bản đồ độ sâu dày đặc.

Bởi vì Máy ảnh Độ sâu LiDAR sử dụng máy ảnh góc rộng quay mặt về phía sau, máy ảnh Telephoto và Ultra Wide có thể được sử dụng cùng với AVCaptureMultiCamSession.

Điều này hữu ích cho các ứng dụng muốn sử dụng nhiều máy ảnh cùng một lúc.

Máy ảnh độ sâu LiDAR hiển thị nhiều định dạng, từ độ phân giải video 640 x 480 đến hình ảnh 12 megapixel đầy đủ ở 4032 x 3024.

Trong khi phát trực tuyến, nó có thể xuất bản đồ độ sâu lên đến 320 x 240.

Và để chụp ảnh, bạn có thể nhận bản đồ độ sâu 768 x 576.

Lưu ý, độ phân giải độ sâu hơi khác nhau đối với các định dạng 16 x 9 và 4 x 3.

Điều này phù hợp với tỷ lệ khung hình của video.

Máy ảnh độ sâu LiDAR AVCaptureDevice có sẵn trên iPhone 12 Pro, iPhone 13 Pro và iPad Pro thế hệ thứ 5.

iPhone 13 Pro có thể cung cấp dữ liệu độ sâu bằng cách sử dụng kết hợp camera phía sau.

AVFoundation Capture API gọi đây là "thiết bị ảo" bao gồm các thiết bị vật lý.

Ở mặt sau của iPhone 13 Pro, có bốn AVCaptureDevice ảo có sẵn để sử dụng: Máy ảnh độ sâu LiDAR mới sử dụng Máy quét LiDAR với máy ảnh góc rộng.

Máy ảnh kép sử dụng máy ảnh rộng và máy ảnh tele.

Camera rộng kép, sử dụng camera rộng và siêu rộng.

Và Triple Camera, sử dụng máy ảnh Wide, Ultra Wide, và Telephoto.

Có sự khác biệt về loại độ sâu mà các thiết bị này tạo ra.

Máy ảnh độ sâu LiDAR tạo ra "độ sâu tuyệt đối". Thời gian của kỹ thuật bay được sử dụng cho phép tính toán quy mô trong thế giới thực.

Ví dụ, điều này rất tốt cho các tác vụ thị giác máy tính như đo lường.

Máy ảnh TrueDepth, Dual, Dual Wide và Triple tạo ra độ sâu tương đối, dựa trên sự chênh lệch.

Điều này sử dụng ít năng lượng hơn và rất tốt cho các ứng dụng hiển thị hiệu ứng ảnh.

AVFoundation đại diện cho chiều sâu bằng cách sử dụng lớp AVDepthData.

Lớp này có bộ đệm pixel chứa độ sâu với các thuộc tính khác mô tả nó, bao gồm kiểu dữ liệu độ sâu, độ chính xác và liệu nó có được lọc hay không.

Nó được cung cấp bởi một AVCaptureDevice có khả năng sâu, giống như Máy ảnh Độ sâu LiDAR mới.

Bạn có thể truyền độ sâu từ AVCaptureDepthDataOutput hoặc nhận độ sâu đính kèm với ảnh từ AVCapturePhotoOutput.

Dữ liệu độ sâu được lọc theo mặc định.

Lọc làm giảm nhiễu và lấp đầy các giá trị bị thiếu, hoặc các lỗ hổng, trong bản đồ độ sâu.

Điều này rất tốt cho các ứng dụng video và nhiếp ảnh, vì vậy các hiện vật không xuất hiện khi sử dụng bản đồ độ sâu để áp dụng các hiệu ứng trên hình ảnh màu.

Tuy nhiên, các ứng dụng thị giác máy tính nên ưu tiên dữ liệu độ sâu không được lọc để bảo toàn các giá trị ban đầu trong bản đồ độ sâu.

Khi bộ lọc bị vô hiệu hóa, Máy ảnh Độ sâu LiDAR loại trừ các điểm tin cậy thấp.

Để vô hiệu hóa tính năng lọc dữ liệu độ sâu, hãy đặt thuộc tính isFilteringEnabled trên AVCaptureDepthDataOutput của bạn thành sai và khi bạn nhận được đối tượng AVDepthData từ cuộc gọi lại đại diện của mình, nó sẽ không được lọc.

Vì ARKit đã cung cấp quyền truy cập vào Máy quét LiDAR, bạn có thể hỏi, "AVFoundation so sánh như thế nào?" AVFoundation được thiết kế cho các ứng dụng video và nhiếp ảnh.

Với AVFoundation, bạn có thể nhúng dữ liệu độ sâu được chụp bằng Máy quét LiDAR vào các bức ảnh có độ phân giải cao.

ARKit phù hợp nhất cho các ứng dụng thực tế tăng cường, như tên cho thấy.

Với Máy quét LiDAR, ARKit có khả năng cung cấp các tính năng như hình học cảnh và vị trí đối tượng.

AVFoundation có thể cung cấp video có độ phân giải cao tuyệt vời để quay phim và chụp ảnh.

Máy ảnh độ sâu LiDAR của AVFoundation có thể xuất độ sâu lên đến 768 x 576.

Cái này lớn hơn gấp đôi độ phân giải độ sâu 256 x 192 của ARKit.

ARKit sử dụng bản đồ độ sâu độ phân giải thấp hơn, vì vậy nó có thể áp dụng các thuật toán thực tế tăng cường cho các tính năng của nó.

Để biết thêm thông tin "chuyên sâu" về cách sử dụng AVFoundation để thu thập dữ liệu độ sâu, hãy xem phiên trước của chúng tôi "Chụp chiều sâu trong chụp ảnh iPhone" từ WWDC 2017.

Chúng tôi rất vui khi thấy những cách thú vị mà bạn có thể sử dụng Máy ảnh Độ sâu LiDAR trong ứng dụng của mình.

Tiếp theo, tôi sẽ thảo luận về cách cải tiến hệ thống lấy nét tự động và phơi sáng tự động giúp cải thiện khả năng hiển thị của khuôn mặt trong cảnh cho ứng dụng của bạn.

Hệ thống lấy nét tự động và phơi sáng tự động phân tích cảnh để chụp được hình ảnh đẹp nhất.

Hệ thống lấy nét tự động điều chỉnh ống kính để giữ cho đối tượng lấy nét và hệ thống phơi sáng tự động cân bằng các vùng sáng nhất và tối nhất của cảnh để giữ cho đối tượng có thể nhìn thấy được.

Tuy nhiên, đôi khi các điều chỉnh tự động được thực hiện không giữ cho khuôn mặt của đối tượng của bạn được lấy nét.

Và những lần khác, khuôn mặt của đối tượng có thể khó nhìn thấy với những cảnh có đèn nền sáng.

Một tính năng phổ biến của máy ảnh DSLR và các máy ảnh chuyên nghiệp khác là theo dõi khuôn mặt trong cảnh để tự động điều chỉnh tiêu cự và độ phơi sáng để giữ cho chúng có thể nhìn thấy được.

Mới trong iOS 15.4, hệ thống lấy nét và phơi sáng sẽ ưu tiên các khuôn mặt.

Chúng tôi thích những lợi ích của điều này đến nỗi chúng tôi đã bật nó theo mặc định cho tất cả các ứng dụng được liên kết trên iOS 15.4 trở lên.

Tôi sẽ chỉ cho bạn một số ví dụ.

Nếu không có tính năng lấy nét tự động điều khiển bằng khuôn mặt, máy ảnh vẫn lấy nét trên nền mà không lấy nét lại vào khuôn mặt.

Xem lại lần nữa.

Hãy nhìn xem khuôn mặt của anh ấy vẫn mất nét như thế nào khi anh ấy quay lại và những cái cây ở hậu cảnh vẫn sắc nét.

Khi bật tính năng lấy nét tự động điều khiển bằng khuôn mặt, bạn có thể nhìn rõ khuôn mặt của anh ấy.

Và khi anh ấy quay đi, máy ảnh sẽ chuyển tiêu điểm sang hậu cảnh.

Khi chúng tôi so sánh các video cạnh nhau, sự khác biệt là rõ ràng.

Ở bên phải với tính năng lấy nét tự động điều khiển bằng khuôn mặt, bạn có thể thấy các chi tiết nhỏ hơn trên bộ râu của anh ấy.

Với những cảnh có đèn nền sáng, có thể là một thách thức để giữ cho khuôn mặt được phơi sáng tốt.

Nhưng với hệ thống phơi sáng tự động ưu tiên khuôn mặt, chúng ta có thể dễ dàng nhìn thấy anh ấy.

So sánh cạnh nhau, chúng ta có thể thấy sự khác biệt ở đây một lần nữa.

Lưu ý rằng bằng cách giữ cho khuôn mặt của anh ấy được phơi sáng tốt trong bức ảnh bên phải, những cái cây ở hậu cảnh trông sáng hơn.

Và bầu trời cũng vậy.

Độ phơi sáng của toàn bộ cảnh được điều chỉnh khi ưu tiên khuôn mặt.

Trong iOS 15.4, có các thuộc tính mới trên AVCaptureDevice để kiểm soát khi tính năng lấy nét tự động điều khiển bằng khuôn mặt và phơi sáng tự động được bật.

Bạn có thể kiểm soát xem thiết bị có "tự động điều chỉnh" các cài đặt này hay không và quyết định khi nào nó sẽ được bật.

Trước khi chuyển đổi các thuộc tính "isEnabled", trước tiên bạn phải tắt tính năng điều chỉnh tự động.

Việc kích hoạt tự động hành vi này rất tốt cho các ứng dụng chụp ảnh.

Nó được sử dụng bởi ứng dụng Máy ảnh của Apple.

Nó cũng tuyệt vời cho các ứng dụng hội nghị truyền hình để giữ khuôn mặt hiển thị trong các cuộc gọi.

FaceTime tận dụng điều này, nhưng đôi khi nó không phù hợp nhất cho một ứng dụng để có hệ thống lấy nét tự động và phơi sáng tự động được điều khiển bởi các khuôn mặt.

Ví dụ: nếu bạn muốn ứng dụng của mình cung cấp cho hướng dẫn sử dụng quyền kiểm soát đối với hình ảnh đã chụp, bạn có thể cân nhắc tắt nó đi.

Nếu bạn quyết định lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động không phù hợp với ứng dụng của mình, bạn có thể chọn không tham gia hành vi này.

Đầu tiên, khóa AVCaptureDevice để cấu hình.

Sau đó, tắt tính năng tự động điều chỉnh lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động.

Tiếp theo, vô hiệu hóa tính năng lấy nét tự động điều khiển bằng khuôn mặt hoặc phơi sáng tự động.

Và cuối cùng, mở khóa thiết bị để cấu hình.

Tôi sẽ nói về cách bạn có thể sử dụng các cấu hình phát trực tuyến nâng cao để nhận dữ liệu âm thanh và video phù hợp với nhu cầu ứng dụng của bạn.

AVFoundation Capture API cho phép các nhà phát triển xây dựng các ứng dụng nhập vai bằng máy ảnh.

AVCaptureSession quản lý luồng dữ liệu từ các đầu vào như máy ảnh và micrô được kết nối với AVCaptureOutputs, có thể cung cấp video, âm thanh, ảnh và hơn thế nữa.

Hãy lấy một trường hợp sử dụng ứng dụng máy ảnh phổ biến làm ví dụ: Áp dụng các hiệu ứng tùy chỉnh như bộ lọc hoặc lớp phủ cho video đã quay.

Một ứng dụng như thế này sẽ có: Một AVCaptureSession với hai đầu vào, một máy ảnh và một micrô, được kết nối với hai đầu ra, một cho dữ liệu video và một cho dữ liệu âm thanh.

Dữ liệu video sau đó có các hiệu ứng được áp dụng và video được xử lý được gửi đến hai nơi, đến bản xem trước video và AVAssetWriter để ghi.

Dữ liệu âm thanh cũng được gửi đến AVAssetWriter.

Tính năng mới trong iOS 16 và iPadOS 16, các ứng dụng có thể sử dụng nhiều AVCaptureVideoDataOutputs cùng một lúc.

Đối với mỗi đầu ra dữ liệu video, bạn có thể tùy chỉnh độ phân giải, ổn định, định hướng và định dạng pixel.

Hãy quay lại ứng dụng máy ảnh ví dụ.

Có những yêu cầu chụp ảnh cạnh tranh mà ứng dụng này đang cân bằng.

Ứng dụng muốn hiển thị bản xem trước video trực tiếp của nội dung được quay và quay video chất lượng cao để phát lại sau này.

Để xem trước, độ phân giải cần phải đủ lớn cho màn hình của thiết bị.

Và quá trình xử lý cần phải đủ nhanh để xem trước độ trễ thấp.

Nhưng khi ghi âm, tốt nhất là chụp ở độ phân giải cao với các hiệu ứng chất lượng được áp dụng.

Với khả năng thêm AVCaptureVideoDataOutput thứ hai, biểu đồ chụp có thể được mở rộng.

Bây giờ đầu ra dữ liệu video có thể được tối ưu hóa.

Một đầu ra có thể cung cấp bộ đệm nhỏ hơn để xem trước và đầu kia có thể cung cấp bộ đệm 4K kích thước đầy đủ để ghi.

Ngoài ra, ứng dụng có thể hiển thị một phiên bản hiệu ứng đơn giản hơn, hiệu quả hơn trên các bộ đệm xem trước nhỏ hơn và dự trữ các hiệu ứng chất lượng cao cho các bộ đệm kích thước đầy đủ khi ghi.

Bây giờ ứng dụng không còn phải thỏa hiệp xem trước hoặc quay video của nó nữa.

Một lý do khác để sử dụng đầu ra dữ liệu video riêng biệt để xem trước và ghi âm là áp dụng các chế độ ổn định khác nhau.

Ổn định video giới thiệu độ trễ bổ sung cho đường ống quay video.

Để xem trước, độ trễ là không mong muốn, vì độ trễ đáng chú ý khiến việc nắm bắt nội dung trở nên khó khăn.

Để ghi âm, tính năng ổn định có thể được áp dụng để có trải nghiệm tốt hơn khi xem video sau này.

Vì vậy, bạn không thể áp dụng tính năng ổn định trên một đầu ra dữ liệu video để xem trước độ trễ thấp và áp dụng tính năng ổn định cho đầu ra còn lại để phát lại sau.

Có nhiều cách để định cấu hình độ phân giải đầu ra dữ liệu video của bạn.

Đối với đầu ra kích thước đầy đủ, trước tiên, hãy tắt cấu hình tự động của kích thước bộ đệm đầu ra.

Sau đó vô hiệu hóa việc phân phối bộ đệm đầu ra có kích thước xem trước.

Tuy nhiên, trong hầu hết các trường hợp, đầu ra dữ liệu video đã được định cấu hình cho đầu ra kích thước đầy đủ.

Đối với đầu ra có kích thước xem trước, một lần nữa, hãy tắt cấu hình tự động, nhưng thay vào đó, cho phép phân phối bộ đệm đầu ra có kích thước xem trước.

Điều này được bật theo mặc định khi sử dụng ảnh AVCaptureSessionPreset.

Để yêu cầu độ phân giải tùy chỉnh, hãy chỉ định chiều rộng và chiều cao trong từ điển cài đặt video của đầu ra.

Tỷ lệ khung hình của chiều rộng và chiều cao phải khớp với tỷ lệ khung hình của Định dạng hoạt động của thiết bị nguồn.

Có nhiều cách hơn để định cấu hình đầu ra dữ liệu video của bạn.

Để áp dụng tính năng ổn định, hãy đặt tính năng ổn định ưa thích ở chế độ như điện ảnh mở rộng, tạo ra các video tuyệt vời để xem.

Bạn có thể thay đổi hướng để nhận bộ đệm là chân dung.

Và bạn có thể chỉ định định dạng pixel, để nhận bộ đệm YUV không mất dữ liệu 10-bit.

Để biết thêm thông tin về việc chọn định dạng pixel cho AVCaptureVideoDataOutput, hãy xem Technote 3121.

Ngoài việc sử dụng nhiều đầu ra dữ liệu video, bắt đầu từ iOS 16 và iPadOS 16, các ứng dụng có thể ghi lại bằng AVCaptureMovieFileOutput trong khi nhận dữ liệu từ AVCaptureVideoDataOutput và AVCaptureAudioDataOutput.

Để xác định những gì có thể được thêm vào một phiên, bạn có thể kiểm tra xem đầu ra có thể được thêm vào nó hay không và truy vấn thuộc tính hardwareCost của phiên để xác định xem hệ thống có thể hỗ trợ cấu hình của bạn hay không.

Bằng cách nhận dữ liệu video với đầu ra tệp phim, bạn có thể kiểm tra video trong khi quay và phân tích cảnh.

Và nhận dữ liệu âm thanh với đầu ra tệp phim, bạn có thể lấy mẫu âm thanh trong khi ghi và nghe những gì đang được ghi.

Với biểu đồ chụp như thế này, bạn có thể giảm tải cơ chế ghi vào AVCaptureMovieFileOutput trong khi vẫn nhận được các mẫu video và âm thanh không nén.

Việc triển khai các cấu hình phát trực tuyến nâng cao này yêu cầu sử dụng API mới.

Chúng tôi đã kích hoạt điều này bằng cách cho phép bạn làm nhiều hơn với API hiện có.

Và cuối cùng, tôi sẽ thảo luận về cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi người dùng đang đa nhiệm.

Trên iPad, người dùng có thể đa nhiệm theo nhiều cách.

Ví dụ: ghi lại Bản ghi nhớ bằng giọng nói trong khi đọc Ghi chú ở Chế độ xem chia nhỏ hoặc bằng Slide Over, hãy ghi chú trong cửa sổ nổi phía trên Safari ở chế độ toàn màn hình.

Với Picture in Picture, bạn có thể tiếp tục phát lại video trong khi thêm lời nhắc để xem thêm video WWDC.

Và với Trình quản lý giai đoạn mới sử dụng iPadOS 16, người dùng có thể mở nhiều ứng dụng trong các cửa sổ nổi có thể thay đổi kích thước.

Bắt đầu từ iOS 16, AVCaptureSessions sẽ có thể sử dụng máy ảnh trong khi đa nhiệm.

Chúng tôi đã ngăn chặn truy cập máy ảnh trong khi đa nhiệm trước đây vì lo ngại về chất lượng dịch vụ mà hệ thống máy ảnh có thể cung cấp trong khi đa nhiệm.

Các ứng dụng sử dụng nhiều tài nguyên như trò chơi chạy cùng với ứng dụng sử dụng máy ảnh có thể gây giảm khung hình và độ trễ khác, dẫn đến nguồn cấp dữ liệu máy ảnh kém.

Người dùng xem video nhiều tháng hoặc nhiều năm sau đó có chất lượng kém có thể không nhớ rằng họ đã quay nó trong khi đa nhiệm.

Cung cấp trải nghiệm máy ảnh tốt là ưu tiên hàng đầu của chúng tôi.

Khi hệ thống phát hiện video từ máy ảnh được ghi lại trong khi đa nhiệm, một hộp thoại sẽ được hiển thị thông báo cho người dùng về khả năng cho các video chất lượng thấp hơn.

Hộp thoại này sẽ được trình bày sau khi quá trình ghi kết thúc với AVCaptureMovieFileOutput hoặc AVAssetWriter.

Nó sẽ chỉ được hiển thị một lần bởi hệ thống cho tất cả các ứng dụng và sẽ có một nút OK để loại bỏ.

Có hai thuộc tính mới được thêm vào AVCaptureSession để cho biết khi nào truy cập máy ảnh đa nhiệm được hỗ trợ và bật.

Các phiên ghi lại đã bật tính năng này sẽ không còn bị gián đoạn với lý do "thiết bị video không khả dụng với nhiều ứng dụng tiền cảnh." Một số ứng dụng có thể muốn yêu cầu trải nghiệm toàn màn hình để sử dụng máy ảnh.

Điều này có thể hữu ích nếu bạn muốn ứng dụng của mình không cạnh tranh với các ứng dụng tiền cảnh khác về tài nguyên hệ thống.

Ví dụ, ARKit không hỗ trợ sử dụng máy ảnh trong khi đa nhiệm.

Bạn nên đảm bảo ứng dụng của mình hoạt động tốt khi chạy cùng với các ứng dụng khác.

Làm cho ứng dụng của bạn có khả năng phục hồi để tăng áp lực hệ thống bằng cách theo dõi các thông báo của nó và thực hiện hành động để giảm tác động, như giảm tốc độ khung hình.

Bạn có thể giảm dấu chân ứng dụng của mình trên hệ thống bằng cách yêu cầu các định dạng có độ phân giải thấp hơn, binned hoặc không phải HDR.

Để biết thêm thông tin về các phương pháp hay nhất để duy trì hiệu suất, hãy đọc bài viết "Truy cập máy ảnh trong khi đa nhiệm".

Ngoài ra, các ứng dụng gọi điện video và hội nghị truyền hình có thể hiển thị những người tham gia từ xa trong cửa sổ Ảnh trong Hình ảnh do hệ thống cung cấp.

Giờ đây, người dùng ứng dụng của bạn có thể liên tục cuộc gọi video trong khi đa nhiệm trên iPad.

AVKit đã giới thiệu API trong iOS 15 cho các ứng dụng để chỉ định bộ điều khiển chế độ xem để hiển thị những người tham gia cuộc gọi từ xa.

Bộ điều khiển chế độ xem cuộc gọi video cho phép bạn tùy chỉnh nội dung của cửa sổ.

Để tìm hiểu thêm về việc nhận con nuôi, vui lòng xem bài viết "Nhận hình ảnh trong hình ảnh cho các cuộc gọi video".

Và điều này kết thúc những tiến bộ trong chụp ảnh iOS.

Tôi đã chỉ ra cách bạn có thể phát trực tuyến độ sâu từ Máy quét LiDAR bằng AVFoundation, cách ứng dụng của bạn sẽ nhận được kết xuất khuôn mặt được cải thiện, cấu hình phát trực tuyến AVCaptureSession nâng cao được thiết kế riêng cho ứng dụng của bạn và cuối cùng, cách ứng dụng của bạn có thể sử dụng máy ảnh trong khi đa

Tôi hy vọng WWDC của bạn sẽ thành công.

♪ ♪