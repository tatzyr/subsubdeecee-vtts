10128

♪ 부드러운 기악 힙합 음악 ♪

♪

하오 탕: 안녕하세요, 제 이름은 하오입니다.

저는 오브젝트 캡처 팀의 엔지니어입니다.

오늘, 제 동료 리사와 저는 Object Capture API와 RealityKit을 사용하여 실제 물체의 3D 모델을 만들고 AR로 가져오는 방법을 보여줄 것입니다.

시작하자.

먼저, 작년에 macOS에서 RealityKit API로 출시한 Object Capture를 요약해 드리겠습니다.

그런 다음 ARKit의 몇 가지 카메라 개선 사항을 소개하겠습니다. 이를 통해 개체의 고해상도 사진을 캡처하고 개체 캡처를 AR 애플리케이션에 더 잘 통합하는 데 도움이 될 수 있습니다.

그 후, 저는 당신이 이 기술을 최대한 활용할 수 있도록 오브젝트 캡처의 모범 사례 지침을 살펴볼 것입니다.

마지막 섹션에서 Risa는 RealityKit의 Object Capture로 엔드투엔드 워크플로우를 안내하고 실제 객체를 AR 경험으로 가져올 수 있는 방법을 시연할 것입니다.

오브젝트 캡처의 빠른 요약부터 시작합시다.

오브젝트 캡처는 실제 물체의 이미지를 상세한 3D 모델로 쉽게 전환할 수 있는 컴퓨터 비전 기술입니다.

iPhone, iPad 또는 DSLR로 다양한 각도에서 물체의 사진을 찍는 것으로 시작합니다.

그런 다음, 그 사진들을 개체 캡처를 지원하는 Mac에 복사합니다.

Photogrammetry API를 사용하여 RealityKit은 단 몇 분 만에 사진을 3D 모델로 변환할 수 있습니다.

출력 모델에는 기하학적 메쉬와 텍스처를 포함한 다양한 재료 맵이 모두 포함되어 있으며, 이는 모델에 자동으로 적용됩니다.

오브젝트 캡처 API에 대한 자세한 내용은 작년의 WWDC 세션을 오브젝션 캡처에 시청하는 것이 좋습니다.

많은 개발자들이 Object Capture를 사용하여 놀라운 3D 캡처 앱을 만들었습니다: Unity, Cinema4D, Qlone, PolyCam, PhotoCatch 등.

이 외에도, 우리는 이 API를 사용하여 만들어진 아름다운 모델을 가지고 있습니다.

다음은 PhotoCatch 앱 내에서 Object Capture의 힘을 사용하여 Ethan Saadia가 만든 몇 가지 모델입니다.

그리고 Shopify의 친구 Mikko Haapoja도 이 API를 사용하여 멋진 3D 모델을 많이 생성했습니다.

오브젝트 캡처로 얻을 수 있는 출력 3D 모델의 상세한 품질은 전자 상거래에 매우 유용합니다.

예를 들어, 발에 다양한 신발을 신어볼 수 있는 GOAT 앱이 있습니다.

이 모든 신발 모델은 최고의 수준의 디테일을 포착하도록 설계된 Object Capture API로 만들어졌습니다.

이것은 제품에 대한 구매 결정을 돕는 데 큰 도움이 될 수 있으며, 심지어 당신의 공간에 있는 물체에 대한 정확한 적합성을 시험해 볼 수도 있습니다.

예를 들어, 플랜트 스토리 앱을 사용하면 공간의 다양한 식물의 실제 3D 모델을 미리 볼 수 있으며, 모두 개체 캡처로 만들어졌습니다.

이것은 당신이 식물에 얼마나 많은 공간이 필요한지 알거나, 단순히 당신의 공간에서 현실적인 세부 사항으로 보는 데 도움이 될 수 있습니다.

리얼리즘에 대해 말하자면, 이 비디오에서 진짜 식물을 발견할 수 있었나요?

네, 그것은 테이블의 가장 왼쪽 모서리에 있는 흰색 화분에 있는 것입니다.

우리는 2021년 출시 이후 Object Capture API의 놀랍고 광범위한 사용을 보게 되어 매우 기쁩니다.

이제, 개체 캡처로 재구성 품질에 크게 도움이 될 ARKit의 몇 가지 카메라 개선 사항에 대해 이야기해 봅시다.

훌륭한 물체 캡처 경험은 사방에서 물체의 좋은 사진을 찍는 것으로 시작됩니다.

이를 위해 iPhone이나 iPad, DSLR 또는 미러리스 카메라와 같은 고해상도 카메라를 사용할 수 있습니다.

iPhone 또는 iPad에서 카메라 앱을 사용하는 경우, Object Capture API가 물체의 실제 규모와 방향을 자동으로 복구할 수 있는 깊이와 중력 정보로 고품질 사진을 찍을 수 있습니다.

그 외에도, iPhone 또는 iPad를 사용하는 경우, ARKit의 추적 기능을 활용하여 모델 위에 3D 안내 UI를 오버레이하여 모든 면에서 물체를 잘 커버할 수 있습니다.

주목해야 할 또 다른 중요한 점은 캡처의 이미지 해상도가 높을수록 오브젝트 캡처가 생성할 수 있는 3D 모델의 품질이 더 좋다는 것입니다.

이를 위해, 올해의 ARKit 출시와 함께 우리는 새로운 고해상도 배경 사진 API를 소개합니다.

이 API를 사용하면 ARSession을 실행하는 동안 네이티브 카메라 해상도로 사진을 캡처할 수 있습니다.

장치의 카메라 센서를 최대한 활용하면서 물체 위에 3D UI 오버레이를 사용할 수 있습니다.

iPhone 13에서, 그것은 와이드 카메라의 전체 12메가픽셀 기본 해상도를 의미합니다.

이 API는 비침입적이다.

현재 ARSession의 지속적인 비디오 스트림을 방해하지 않으므로, 앱은 사용자에게 원활한 AR 경험을 계속 제공할 것입니다.

또한, ARKit은 사진에서 EXIF 메타데이터를 사용할 수 있도록 하여 앱이 사후 처리에 유용할 수 있는 화이트 밸런스, 노출 및 기타 설정에 대한 유용한 정보를 읽을 수 있도록 합니다.

ARKit을 사용하면 앱에서 이 새로운 API를 매우 쉽게 사용할 수 있습니다.

ARWorldTrackingConfguration에서 고해상도 프레임 캡처를 지원하는 비디오 형식을 쿼리할 수 있으며, 성공하면 새 비디오 형식을 설정하고 ARSession을 실행할 수 있습니다.

고해상도 사진을 캡처할 때, ARSession의 새로운 captureHighResolutionFrame API 기능을 호출하면 완료 핸들러를 통해 고해상도 사진을 비동기적으로 반환합니다.

그건 그렇게 간단해.

우리는 또한 초점, 노출 또는 화이트 밸런스와 같은 카메라 설정보다 수동 제어를 선호할 수 있는 사용 사례가 있다는 것을 인식했습니다.

그래서 우리는 기본 AVCaptureDevice에 직접 액세스하고 세밀한 카메라 제어를 위해 속성을 변경할 수 있는 편리한 방법을 제공하고 있습니다.

이 코드 예제에서 볼 수 있듯이, ARWorldTrackingConfiguration에서 configurableCaptureDevice ForPrimaryCamera를 호출하기만 하면 기본 AVCaptureDevice에 액세스할 수 있습니다.

이러한 개선 사항에 대한 자세한 내용은 올해 WWDC의 "Discover ARKit 6 세션"을 확인하는 것이 좋습니다.

이제, Object Capture와 함께 몇 가지 모범 사례 지침을 살펴봅시다.

먼저; 우리는 객체 캡처에 적합한 특성을 가진 객체를 선택해야 합니다.

좋은 물체는 표면에 적절한 질감을 가지고 있다.

물체의 일부 영역이 질감이 없거나 투명하다면, 그 영역의 세부 사항은 잘 재구성되지 않을 수 있다.

좋은 물건은 또한 눈부심과 반사가 없어야 한다.

물체에 무광택 표면이 없다면, 확산 조명을 사용하여 반사를 줄일 수 있습니다.

물체를 뒤집어 바닥을 잡고 싶다면, 물체가 단단하게 유지되도록 하십시오.

다시 말해서, 뒤집을 때 모양을 바꾸면 안 된다.

그리고 마지막으로, 좋은 물체는 어느 정도 미세한 구조를 포함할 수 있지만, 물체의 미세한 디테일을 복구하려면 고해상도 카메라를 사용하고 클로즈업 사진을 찍어야 합니다.

다음으로 중요한 것은 이상적인 캡처 환경을 설정하는 것이다.

당신은 당신의 캡처 환경이 좋고, 균일하고, 확산된 조명을 가지고 있는지 확인하고 싶을 것입니다.

안정적인 배경을 확보하고 물체 주변에 충분한 공간을 확보하는 것이 중요하다.

방이 어두우면, 조명이 잘 켜진 턴테이블을 사용할 수 있습니다.

다음으로, 우리는 당신의 물체의 좋은 사진을 캡처하기 위한 몇 가지 지침을 살펴볼 것이며, 이는 차례로 당신이 물체 캡처에서 좋은 품질의 3D 모델을 얻을 수 있도록 할 것입니다.

예를 들어, 제 동료 Maunesh가 어떻게 그의 iPhone을 사용하여 우리의 사랑하는 ARKit 엔지니어인 Christian Lipski가 만든 아름다운 해적선의 이미지를 캡처했는지 보여드리겠습니다.

마우네쉬는 깨끗한 테이블 한가운데에 해적선을 놓는 것으로 시작한다.

이것은 사진에서 배를 분명히 돋보이게 한다.

그는 두 손으로 아이폰을 꾸준히 잡고 있다.

그가 배 주위를 천천히 돌면서, 그는 다양한 높이에서 사진을 찍는다.

그는 배가 카메라의 시야 중앙에 충분히 커서 최대한의 디테일을 포착할 수 있도록 한다.

그는 또한 인접한 두 사진 사이에 항상 높은 수준의 중복을 유지하도록 한다.

그가 많은 사진을 찍은 후 - 이 경우 약 80장 - 그는 배를 옆으로 뒤집어 바닥을 재구성할 수 있다.

그는 뒤집힌 방향으로 배의 사진을 약 20장 더 계속 찍고 있다.

주목해야 할 한 가지는 그가 iPhone을 가로 모드로 잡고 있다는 것이다.

이것은 그가 긴 물체를 포착하고 있기 때문이며, 이 경우 가로 모드는 물체의 최대 디테일을 포착하는 데 도움을 준다.

그러나, 그는 대신 키가 큰 물체를 캡처하려면 iPhone을 세로 모드로 사용해야 할 수도 있다.

그게 다야!

이 과정의 마지막 단계는 그 사진을 Mac에 복사하고 Object Capture API를 사용하여 처리하는 것입니다.

다양한 사용 사례에 최적화된 네 가지 세부 수준 중에서 선택할 수 있습니다.

감소된 중간 세부 수준은 AR QuickLook에서 3D 콘텐츠를 보는 것과 같은 웹 기반 및 모바일 경험에서 사용하기에 최적화되어 있습니다.

이러한 세부 수준에 대한 재구성된 모델은 삼각형과 재료 채널이 적기 때문에 메모리를 덜 소비한다.

전체 및 원시 세부 수준은 컴퓨터 게임이나 포스트 프로덕션 워크플로우와 같은 고급 대화형 사용 사례를 위한 것입니다.

이 모델에는 가장 높은 기하학적 디테일이 포함되어 있으며 구운 재료와 굽지 않은 재료 중에서 선택할 수 있는 유연성을 제공하지만, 재구성하려면 더 많은 메모리가 필요합니다.

사용 사례에 따라 올바른 출력 수준을 선택하는 것이 중요합니다.

해적선의 경우, 우리는 M1 Mac에서 처리하는 데 몇 분 밖에 걸리지 않은 중간 세부 수준을 선택했습니다.

출력 3D 모델은 너무 멋져 보여서 우리는 실제로 공해에서 항해하는 해적선의 애니메이션 클립을 만들었다.

그리고 그것이 당신을 위한 오브젝트 캡처의 힘입니다!

아호!

이제 RealityKit에서 Object Capture로 엔드투엔드 워크플로우를 안내할 Risa에게 넘겨줄게.

리사 요네야마: 고마워, 하오.

이제 Object Capture API를 검토했으므로 RealityKit을 사용하여 실제 개체를 AR로 가져오기 위해 엔드 투 엔드 개발자 워크플로우를 검토하게 되어 기쁩니다.

우리는 예시 워크플로우와 함께 각 단계를 자세히 살펴볼 것이므로, 데모로 바로 들어가 봅시다.

내 동료 잭은 가끔 목공이며 최근에 여섯 개의 대형 나무 체스 조각을 만들었다 - 각각의 독특한 조각마다 하나씩.

이 체스 조각들을 보면서, 나는 인터랙티브 AR 체스 게임을 만드는 데 영감을 받았다.

이전에는 실제 물체의 고품질 3D 모델을 만들기 위해 3D 모델러와 재료 전문가가 필요했습니다.

이제 Object Capture API를 사용하면 이러한 체스 조각을 직접 캡처하여 증강 현실로 가져올 수 있습니다.

루크를 잡는 것으로 시작합시다.

내 동료 브라이언은 이전 섹션에서 다룬 모범 사례를 염두에 두고 이 전문적인 설정을 사용할 것이다.

이 경우, 브라이언은 최종 출력에서 거친 그림자를 피하기 위해 전문적인 조명으로 이 턴테이블에 루크를 놓고 있다.

출력 USDZ에서 자동 스케일 추정 및 중력 벡터 정보를 제공하는 턴테이블과 함께 iPhone 카메라를 사용할 수도 있습니다.

이에 대한 자세한 내용은 2021년의 오브젝트 캡처 세션을 참조하십시오.

물론, 브라이언처럼 정교한 설정이 없다면, 단순히 iOS 장치를 들고 물체를 돌아다니며 이미지를 캡처할 수도 있습니다.

이제 우리가 루크 피스의 모든 사진을 가지고 있으니, 나는 이것들을 Mac으로 옮길 것이다.

2021년에 도입된 PhotogrammetrySession API를 사용하여 이 사진들을 처리할 것입니다.

모범 사례 지침에 따라, AR 앱이 잘 작동하는지 확인하고 싶기 때문에 축소된 세부 수준을 사용하여 재구성할 것입니다.

API의 최종 출력은 USDZ 파일 형식 모델이 될 것이다.

여기 제가 방금 재구성한 루크 체스 조각의 최종 결과물이 있습니다.

우리의 시간을 절약하기 위해, 나는 앞서 가서 다른 다섯 조각을 미리 포착했다.

당신은 우리가 체스 조각을 위한 단 하나의 색 구성표로 체스 게임을 어떻게 만들 것인지 궁금할 것입니다.

여섯 개의 독특한 조각을 복제하여 리얼리티 컨버터로 드래그합시다.

나는 원래 텍스처의 색상을 반전시켰고 복제된 세트를 이 새로운 반전된 텍스처로 교체했다.

이렇게 하면, 우리는 각 플레이어마다 하나씩 더 가벼운 버전과 더 어두운 버전의 체스 조각을 가질 수 있습니다.

내보내기 메뉴에서 압축된 텍스처 옵션이 켜져 있는 모델을 내보낼 것입니다.

이것은 텍스처의 메모리 발자국을 줄이는 데 도움이 될 것이다.

이제 우리는 체스 조각의 전체 세트를 가지고 있기 때문에, 우리는 모델을 Xcode 프로젝트에 가져올 준비가 되었습니다.

저는 Y축의 원시 큐브를 축소하고 흑백의 색상을 번갈아 가며 RealityKit을 사용하여 체스판을 만들었습니다.

여기 내가 재구성한 모든 체스 조각들이 체스판에 놓여 있다.

우리 애플리케이션에서 실제 물체를 보는 것은 이미 흥미롭지만, 실제 대화형 게임으로 만들기 위해 몇 가지 기능을 추가하기 시작합시다.

데모의 이 부분에서, 저는 몇 가지 다른 기존 기술을 선보이고 싶습니다. 그래서 우리는 당신이 원하는 출력을 달성하기 위해 기술을 어떻게 결합하고 싶은지에 대한 예를 제공할 수 있습니다.

RealityKit의 고급 주제의 실용적인 사용 사례를 검토할 예정이기 때문에, 아직 API에 익숙하지 않다면 2021년부터 RealityKit 세션을 확인하는 것이 좋습니다.

애플리케이션을 처음 시작할 때 시작 애니메이션을 추가하는 것으로 시작하고 싶습니다.

나는 체커 타일이 최종 위치보다 약간 높은 곳에서 천천히 제자리에 떨어지는 애니메이션을 상상하고 있으며, 체스 조각도 함께 번역된다.

코드에서 이 효과를 복제하려면, 두 단계만 거치면 됩니다.

첫 번째 단계는 우리의 두 엔티티를 y축을 따라 번역하는 동시에 체스 조각을 균일하게 축소하는 것이다.

두 번째 단계와 마지막 단계는 두 엔티티를 원래의 변형으로 되돌려 움직이는 것이다.

이것에 대한 코드는 꽤 간단하다.

나는 체커 타일 엔티티를 반복하는 것으로 시작할 것이다.

각 엔티티에 대해, 나는 이것이 최종 위치가 될 것이기 때문에 체커 타일의 현재 변환을 저장할 것이다.

그런 다음, 나는 y축에서 각 사각형을 10cm 위로 움직일 것이다.

우리는 이제 이동 기능을 활용하여 이것을 원래의 변형으로 되돌릴 수 있습니다.

나는 또한 바둑판의 윤곽을 그리는 이 테두리 USDZ에 애니메이션이 내장되어 있다는 것을 알고 있다.

우리는 playAnimation API를 사용하여 애니메이션을 동시에 시작할 수 있습니다.

나는 체스 조각에 정확히 같은 애니메이션을 추가했지만 그들이 번역할 때 스케일을 수정했다.

그리고 여기 있습니다: 단 몇 줄의 코드로 간단한 시작 애니메이션.

그러나, 우리는 체스 조각을 움직일 수 있는 능력 없이는 실제로 체스를 할 수 없을 것이다.

다음에 그거 해보자.

우리가 체스 조각을 움직이기 시작하기 전에, 우리는 하나를 선택할 수 있어야 할 것이다.

저는 이미 ARView에 UITapGestureRecognizer를 추가했습니다.

사용자가 특정 위치를 탭할 때, 우리는 카메라 원점에서 시작하여 그 2D 지점을 통과하는 광선을 정의할 것이다.

그런 다음 우리는 그 레이와 함께 3D 장면으로 레이캐스트를 수행하여 엔티티를 쳤는지 확인할 수 있습니다.

나는 내 장면에서 체스 조각만 선택할 수 있기를 원하기 때문에 체스 조각 충돌 그룹을 마스크로 지정했다.

레이캐스트 함수는 CollisionComponent가 없는 모든 엔티티를 무시한다는 것을 명심하세요.

만약 우리가 체스 조각을 찾는다면, 우리는 마침내 그것을 선택할 수 있다.

이제 어떤 작품이 선택되었는지 알았으니, 나는 그 작품이 빛나는 것처럼 보이게 하는 효과를 추가하고 싶다.

우리는 이것을 달성하기 위해 맞춤형 재료를 활용할 수 있습니다; 더 구체적으로, 표면 셰이더.

표면 셰이더를 사용하면 Metal을 통해 재료 매개 변수를 계산하거나 지정할 수 있으며, RealityKit의 프래그먼트 셰이더는 각 픽셀당 한 번 호출됩니다.

우리는 금속에서 이 화재 효과처럼 보이는 표면 셰이더를 쓸 수 있다.

그런 다음 이 표면 셰이더를 직사각형 프리즘에 적용하여 셰이더가 우리 엔티티의 모양에 영향을 미치도록 사용자 지정 재료를 적용하십시오.

우리가 원하는 효과를 얻기 위해 코드를 작성해 봅시다.

나는 이미 이 표면 셰이더에서 사용할 프로젝트에 노이즈 텍스처를 추가했다.

우리는 텍스처를 두 번 샘플링할 것입니다. 하나는 효과의 전체적인 모양을 위해, 다른 하나는 세부 사항을 위해.

그런 다음 RGB 값을 가지고 우리가 원하는 대로 보이도록 다시 매핑합니다.

그런 다음, 방금 추출한 처리된 값으로, y 위치를 이미지 값과 비교하여 샘플 포인트의 불투명도를 계산할 것입니다.

약간의 움직임을 주기 위해, 우리는 시간의 함수로서 텍스처의 y축을 통해 움직일 것이다.

또한, 우리는 또한 카메라의 보기 방향과 함께 각 샘플 포인트의 대면 각도를 사용하여 측면의 효과를 퇴색시킬 것입니다.

이것은 가장자리를 부드럽게 하고 기본 모델의 규칙적인 특성을 숨길 것이다.

마지막으로, 표면 매개 변수 함수를 사용하여 방금 계산한 색상과 불투명도를 설정할 것입니다.

그리고 여기 선택 셰이더가 적용된 체스 조각이 있습니다.

그들은 정말 내부에서 빛나는 것처럼 보인다.

이제, 우리가 그것을 세 개의 개별 번역 애니메이션과 결합한다면, 그것은 다음과 같은 결과를 낳을 것이다.

체스 조각을 옮기는 기능을 구현하면, 우리는 또한 상대의 조각을 잡을 수 있을 것이다.

표면 셰이더와 마찬가지로, 지오메트리 수정자는 사용자 지정 재료를 사용하여 구현할 수 있습니다.

위치, 법선, 텍스처 좌표 등과 같은 정점 데이터를 변경할 수 있기 때문에 매우 강력한 도구입니다.

이러한 각 금속 함수는 RealityKit의 정점 셰이더에 의해 정점당 한 번 호출됩니다.

이러한 수정은 순전히 일시적이며 실제 엔티티의 정점 정보에 영향을 미치지 않습니다.

나는 우리가 조각들이 잡혔을 때 그 조각들을 으깨기 위해 재미있는 지오메트리 수정자를 추가할 수 있다고 생각하고 있어.

나는 0에서 1까지의 캡처 애니메이션의 진행 상황을 나타내기 위해 capturedProgress라는 체스 조각에 이 속성을 가지고 있다.

캡처는 사용자가 시작한 작업이기 때문에, 우리는 어떻게든 지오메트리 수정자에게 언제 애니메이션을 시작해야 하는지 말해야 한다.

좋은 점은 customMaterial에 사용자 지정 속성을 설정하여 이것을 할 수 있다는 것입니다.

이것은 CPU와 GPU 간에 데이터를 공유할 수 있게 해준다.

우리는 특히 여기서 사용자 지정 값 속성을 사용하고 애니메이션 진행 상황을 지오메트리 수정자에 전달할 것입니다.

금속 쪽에서 애니메이션 진행 상황을 추출하려면, 유니폼에 사용자 지정 매개 변수를 사용할 수 있습니다.

물체를 수직으로 스케일링하고 싶기 때문에, 마치 다른 조각에 의해 찌그러지는 것처럼, 우리는 스케일 축을 y 방향으로 설정할 것이다.

애니메이션에 약간의 복잡성을 더하기 위해, 우리는 또한 파동 효과를 만들기 위해 x축의 지오메트리를 변경할 것이다.

정점의 오프셋은 set_model_position_ 오프셋 함수를 사용하여 설정할 수 있습니다.

여기 우리의 기하학 수정자의 최종 제품이 있습니다.

X축을 따라 수직으로 늘어나면서, 무너지기 전에 약간 확장되는 것을 볼 수 있습니다.

체스 초보자로서, 나는 내가 게임을 배우는 데 도움이 되도록 선택한 조각이 어디로 이동할 수 있는지 나타내는 기능을 추가하는 것이 도움이 될 수 있다고 생각했다.

체커 조각은 자체 모델 구성 요소를 가진 각각의 개별 엔티티이기 때문에, 표면 셰이더를 사용하여 다른 사람들과 구별하기 위해 잠재적인 움직임에 펄스 효과를 적용할 수 있습니다.

다음으로, 나는 그 효과를 더욱 강조하기 위해 "bloom"이라는 후처리 효과를 추가할 것이다.

다시 말하지만, 우리는 글로우 효과를 위해 표면 셰이더에 사용한 사용자 지정 매개 변수를 사용하고 있습니다.

이 경우, 우리는 CPU 측에서 금속 표면 셰이더로 부울을 전달하고 있습니다.

이 체커가 가능한 움직임이라면, 색상을 변경하여 펄싱 효과를 추가하고 싶습니다.

우리는 특히 여기서 방출 색상에 펄스를 추가할 것입니다.

마지막으로, 나는 전체 보기에 꽃 효과를 추가할 것이다.

블룸은 밝은 영역의 경계에서 빛의 깃털을 생성하는 후처리 효과이다.

우리는 ARView의 렌더링 콜백 속성을 활용하여 이 효과를 달성할 수 있습니다.

우리는 이미 내장된 금속 성능 셰이더 기능을 사용하여 블룸 효과를 작성할 것입니다.

다음으로, 우리는 방금 정의한 bloom 함수로 renderCallbacks.postProcess 클로저를 설정할 것입니다.

우리가 체커를 펄럭일 때, 우리는 이제 꽃 효과로 더욱 강조될 흰색으로 펄럭이고 있다.

표면 셰이더와 블룸 효과를 함께 사용하면, 우리는 조각을 어디로 옮길 수 있는지 정확히 볼 수 있습니다.

마지막으로, AR 앱에서 실제 체스 조각이 살아나는 것을 보기 위해 우리가 가진 모든 것을 결합합시다.

우리는 우리가 추가한 모든 기능이 우리 환경에서 어떻게 보이는지 볼 수 있다.

당신의 편의를 위해 우리는 Capture Chess 샘플 프로젝트를 세션 리소스에 연결했습니다.

그것을 다운로드하고 당신의 환경에서 볼 수 있도록 직접 시도해 보세요.

그리고 그건 그렇게 간단해.

캡처부터 대형 체스 조각의 재구성까지, 그리고 우리의 증강 현실 앱으로.

우리는 오늘 이 세션에서 많은 것을 다루었으니 몇 가지 요점을 요약해 봅시다.

우리는 2021년에 발표한 Object Capture API를 요약하는 것으로 처음 시작했습니다.

그런 다음 활성 ARSession 동안 네이티브 카메라 해상도로 주문형 사진을 캡처할 수 있는 ARKit의 새로운 API를 검토했습니다.

개체 캡처 기술을 최대한 활용할 수 있도록, 우리는 재구성에 적합한 개체 유형, 고품질 이미지를 얻을 수 있는 이상적인 환경 및 개체를 캡처하는 동안 따라야 할 권장 흐름을 나열했습니다.

이 세션의 후반부에서, 우리는 엔드 투 엔드 개발자 워크플로우의 예를 살펴보았다.

우리는 대형 체스 조각의 사진을 캡처하고 이미지를 PhotogrammetrySession API의 입력으로 사용하여 3D 모델을 만들었습니다.

그런 다음, 우리는 일부 텍스처를 대체하기 위해 모델을 리얼리티 컨버터로 가져왔습니다.

그리고 마지막으로, 우리는 AR에서 작동하는 체스 조각을 보기 위해 천천히 체스 게임을 구축했다.

그리고 그게 오늘 우리 세션을 위한 거야.

봐줘서 정말 고마워.

아호!

♪