10127

♪ (부드러워 기악 힙합 음악) ♪

♪

프라빈 샤르마: 안녕하세요. 제 이름은 프라빈이고, 저는 여기 애플의 프로토타이핑 팀에서 왔습니다.

카이 강: 안녕. 제 이름은 카이이고 비디오 엔지니어링 팀에서 왔어요.

프라빈: 지난 몇 년 동안 애플은 사람들이 세상을 앱으로 가져올 수 있는 강력한 새로운 방법을 가능하게 했다.

작년에, 우리는 실제 물체의 사진을 찍는 Object Capture를 도입했고, RealityKit의 Photogrammetry API를 사용하여 앱에서 사용할 수 있는 3D 모델로 바꿉니다.

개체 캡처에 앞서, 우리는 공간의 기하학적 구조를 거칠게 이해하고 앱에서 새로운 증강 현실 사용 사례를 가능하게 하는 장면 재구성 API를 출시했습니다.

올해, 우리는 RoomPlan이라는 새로운 프레임워크를 발표하게 되어 매우 기쁩니다.

RoomPlan을 사용하면 LiDAR 지원 iPhone 또는 iPad를 사용하여 방을 스캔할 수 있습니다.

앱에서 사용할 수 있는 방과 방 정의 객체의 파라메트릭 3D 모델을 생성합니다.

RoomPlan 스캐닝 경험이 어떻게 생겼는지 살펴봅시다.

RoomPlan은 ARKit으로 구동되는 정교한 기계 학습 알고리즘을 사용하여 벽, 창문, 개구부 및 문뿐만 아니라 벽난로, 소파, 테이블 및 캐비닛과 같은 방을 정의하는 물체를 감지합니다.

RealityKit을 사용하여 스캔 진행 상황을 실시간으로 렌더링하는 RoomCaptureView API를 사용하면 스캔 경험을 앱에 쉽게 통합할 수 있습니다.

그리고 스캔을 마치면, RoomCaptureView는 사용 사례에 가장 잘 맞는 최종 후처리 결과를 제공합니다.

처음으로, 기계 학습과 컴퓨터 비전 알고리즘을 구현하는 복잡성 없이, 사람들은 이제 새로운 방식으로 그들의 방과 상호 작용할 수 있다.

예를 들어, 인테리어 디자인 앱은 벽 색상 변화를 미리 보고 방을 다시 칠하는 데 필요한 페인트의 양을 정확하게 계산할 수 있습니다.

건축 앱은 이제 누군가가 방 레이아웃의 변경 사항을 실시간으로 미리 보고 편집할 수 있도록 쉽게 할 수 있습니다.

부동산 앱은 이제 에이전트가 목록의 평면도와 3D 모델을 캡처할 수 있도록 원활하게 할 수 있습니다.

그리고 전자상거래 앱은 물리적 공간에서 제품 시각화를 통해 고객을 참여시킬 수 있다.

이것들은 RoomPlan이 활성화하는 응용 프로그램의 몇 가지 예일 뿐이며, RoomPlan을 앱에 통합하는 것이 얼마나 간단한지 보고 놀랄 것입니다.

한 번 보자.

RoomPlan을 사용할 수 있는 두 가지 주요 방법이 있습니다.

첫 번째는 RoomPlan을 앱에 원활하게 통합할 수 있는 즉시 사용 가능한 스캔 경험입니다.

두 번째는 앱이 스캔의 실시간 파라메트릭 데이터를 사용할 수 있도록 하는 데이터 API이지만 사용 사례에 가장 적합합니다.

이 두 API를 모두 사용하면 최상의 스캔 결과를 얻을 수 있도록 몇 가지 모범 사례를 권장하며, 이 프레젠테이션의 마지막 섹션에서 검토할 것입니다.

먼저, 새로운 RoomCaptureView API를 사용하여 앱에 가져올 수 있는 스캔 경험에 대해 이야기해 봅시다.

RoomCaptureView는 앱에 쉽게 배치할 수 있는 UIView 하위 클래스입니다.

그것은 세계 공간 스캐닝 피드백, 실시간 룸 모델 생성, 코칭 및 사용자 지침의 프레젠테이션을 처리합니다.

RoomCaptureView 기반 스캔 중에 제시된 디자인 요소를 자세히 살펴봅시다.

활성 RoomCaptureView 세션 동안, 애니메이션 라인은 벽, 창문, 개구부, 문 및 방을 정의하는 물체를 실시간으로 감지합니다.

RoomCaptureView 하단에서 실시간으로 생성된 대화형 3D 모델은 스캔 진행 상황에 대한 개요를 한 눈에 제공합니다.

마지막으로, 텍스트 코칭은 최상의 스캔 결과를 안내합니다.

간단한 네 단계로 RoomCaptureView를 어떻게 사용할 수 있는지 살펴봅시다.

먼저, 우리는 ViewController에서 RoomCaptureView 참조를 만듭니다.

둘째, 우리는 RoomCaptureSession 구성 객체에 대한 참조를 만듭니다.

셋째, 우리는 스캔 세션을 시작하고, 구성을 캡처 세션의 실행 기능으로 전달합니다.

그리고 마지막으로, 우리의 응용 프로그램은 캡처 세션에 스캔을 중지하라고 말한다.

선택적으로, 앱은 RoomCaptureViewDelegate 프로토콜을 준수하고 사후 처리된 결과와 프레젠테이션을 거부하거나 사후 처리된 스캔 결과를 처리할 수 있습니다.

예를 들어, 제공된 CapturedRoom 데이터 구조체에서 사용할 수 있는 내보내기 기능을 호출하여 결과의 USDZ를 내보낼 수 있습니다.

그리고 그것이 RoomPlan을 앱에 통합하는 것이 얼마나 간단한지입니다.

우리는 당신이 이 API로 무엇을 만드는지 보게 되어 매우 기쁩니다.

이제 내 동료 Kai는 RoomCaptureSession과 RoomPlan의 데이터 API에 대해 이야기할 것이다.

카이: 고마워, 프라빈.

이 섹션에서는 스캔하는 동안 기본 데이터 구조에 대한 액세스를 제공하고 처음부터 스캐닝 경험의 사용자 지정 시각화를 구축하는 데 도움이 되는 데이터 API를 안내할 것입니다.

기본 워크플로우는 스캔, 프로세스 및 내보내기의 세 부분으로 구성되어 있습니다.

스캔을 위해, 우리는 캡처 세션을 설정하고 시작하는 방법과 캡처 프로세스를 표시하고 모니터링하는 방법에 대한 기본 사항을 다룰 것입니다.

그런 다음 스캔한 데이터가 어떻게 처리되고 최종 모델이 프레젠테이션을 위해 수신되는지 살펴볼 것입니다.

마지막으로, USD 워크플로우에서도 사용할 수 있는 출력 USD 파일을 생성하고 내보내는 방법에 대해 논의할 것입니다.

이제, 스캔 단계를 자세히 살펴봅시다.

우리는 RoomCaptureSession API를 사용하여 세션을 설정하고 스캔을 계속할 때 진행 상황을 표시할 것입니다.

코드로 보여줄게.

다음은 간단한 RealityKit 앱의 예입니다.

시작하려면, RoomPlan을 Swift 프로젝트로 가져오기만 하면 됩니다.

앱의 ViewController에서 결과를 시각화하고 RoomCaptureSession 인스턴스를 시작하는 사용자 지정 유형을 가질 수 있습니다.

또한, RoomCaptureSession은 앱이 AR 보기에서 평면과 개체 경계 상자를 그릴 수 있도록 기본 AR 세션에 핸들을 제공합니다.

RoomCaptureSession은 위임 패턴을 채택한다.

ViewController 클래스에서 ViewController 자체를 captureSession의 대리인으로 할당할 수 있습니다.

이를 통해 ViewController는 RoomCaptureSession에서 실시간 업데이트를 받을 수 있습니다.

이러한 업데이트에는 캡처하는 동안 사람들을 안내하기 위한 3D 모델과 지침이 포함됩니다.

이러한 업데이트를 받으려면, ViewController는 RoomCaptureSessionDelegate 프로토콜을 준수하고 두 가지 방법을 구현해야 합니다.

첫 번째는 실시간 CapturedRoom 데이터 구조를 얻기 위한 captureSession(_ session: didUpdate room:) 방법입니다.

비주얼라이저를 사용하여 3D 모델의 AR 뷰를 업데이트할 수 있으며, 이는 사람들에게 진행 상황에 대한 실시간 피드백을 제공합니다.

우리는 대화의 후반부에서 CapturedRoom 구조에 더 깊이 빠져들 것이다.

이 방법은 캡처된 방에 대한 업데이트를 감지할 때 호출될 것이다.

두 번째 방법은 captureSession(_ session: didProvide instruction:)이다.

이 방법은 실시간 피드백이 포함된 명령 구조를 제공합니다.

당신의 시각 자료는 스캔하는 동안 사람들을 안내하기 위해 지침을 사용할 수 있습니다.

이 API가 제공하는 지침을 살펴봅시다.

이러한 지침에는 물체와의 거리, 스캔 속도, 방에 대한 조명 조정뿐만 아니라 더 많은 질감을 가진 방의 특정 영역에 초점을 맞추는 것이 포함됩니다.

이러한 지침은 실시간 피드백으로 사람들을 안내하기 위해 스캔 중에 제공될 것입니다.

다음으로, 우리는 프로세스 부분으로 넘어갈 것이다.

이 섹션에서는 RoomBuilder 클래스를 사용하여 스캔한 데이터를 처리하고 최종 3D 모델을 생성할 것입니다.

캡처된 데이터를 처리하려면, 첫 번째 단계는 ViewController 클래스에서 RoomBuilder 인스턴스를 시작하는 것입니다.

다음으로, 캡처 프로세스 후 센서 데이터를 받으려면, 앱은 captureSession(_ session: didEndWith data: error:) 메소드를 구현해야 합니다.

RoomCaptureSession이 중지되면, 앱에서 stop() 함수를 호출하거나 오류로 인해, 이 함수는 CaptureRoomData 객체와 선택적 오류를 반환하기 위해 호출됩니다.

마지막으로, 캡처된 데이터를 처리하기 위해, 우리는 await 키워드를 사용하여 roomBuilder의 비동기 roomModel(from:) 메소드를 호출합니다.

이 방법은 스캔된 데이터를 처리하고 최종 3D 모델을 구축하기 위해 비동기적으로 실행됩니다.

그것은 우리가 작년 WWDC에서 도입한 Swift async/await 기능을 활용한다.

단 몇 초 안에, 그 모델은 당신의 앱에서 최종 프레젠테이션에 사용할 수 있을 것입니다.

이제 CapturedRoom 데이터 구조의 세부 사항과 앱에서 사용하기 위해 내보낼 수 있는 방법에 대해 자세히 알아보겠습니다.

최상위 수준에는 표면과 물체로 구성된 CapturedRoom이 있다.

표면에는 반경, 시작 및 종료 각도, 표면의 네 개의 다른 가장자리, 벽, 개구부, 창문, 문과 같은 곡선을 나타내는 독특한 속성이 포함되어 있습니다.

물건에는 테이블, 침대, 소파 등과 같은 가구 카테고리가 포함되어 있습니다.

표면과 물체는 치수, 스캔된 표면이나 물체에 대한 세 가지 수준의 자신감을 제공하는 자신감, 3D 변환 매트릭스 및 고유 식별자와 같은 몇 가지 공통 속성을 공유합니다.

그들이 코드에서 어떻게 표현되는지 봅시다.

CapturedRoom 구조는 방 안의 요소에 대한 완전한 파라메트릭 표현이다.

그것은 벽, 개구부, 문, 창문, 그리고 방 안의 물건을 포함한 다섯 가지 속성을 포함한다.

처음 네 요소의 경우, 그들은 2D 평면 건축 구조를 나타내는 표면 구조로 표현된다.

오른쪽에서, 당신은 우리가 이전에 다루었던 표면의 다양한 특성을 볼 수 있습니다.

마지막 속성은 방에 있는 3D 물체의 배열이며, 그것들은 입체체로 표현된다.

오른쪽에서, 당신은 객체의 다양한 속성을 볼 수 있습니다.

다음은 RoomPlan에서 지원하는 객체 유형 목록입니다.

여기에는 소파, 테이블, 의자, 침대 등과 같은 다양한 일반적인 가구 유형이 포함됩니다.

마지막으로, 내보내기 기능을 사용하면 이 CapturedRoom을 기존 워크플로우의 USD 또는 USDZ 데이터로 내보낼 수 있습니다.

다음은 Cinema 4D에서 USD 출력을 직접 열어 방의 계층적 데이터 구조와 각 방 요소 또는 개체의 크기와 위치를 탐색하고 편집하는 방법을 보여주는 예입니다.

또한 기존 USD 및 USDZ 워크플로우를 활용하여 캡처된 방의 렌더링을 부동산, 전자 상거래, 유틸리티 및 인테리어 디자인과 같은 다양한 애플리케이션에 추가할 수 있습니다.

지금까지, 우리는 스캐닝 경험과 기본 RoomPlan API를 다루었습니다.

우리는 이제 RoomPlan으로 좋은 결과를 얻을 수 있도록 몇 가지 모범 사례를 살펴볼 것입니다.

우리는 좋은 스캔을 허용하는 권장 조건, 방을 선택하는 동안 살펴봐야 할 방 기능, 그리고 명심해야 할 몇 가지 스캔 및 열 고려 사항을 다룰 것입니다.

RoomPlan API는 전형적인 가정에서 가장 일반적인 건축 구조와 물체를 지원합니다.

최대 방 크기가 30피트 x 30피트 또는 약 9 x 9미터인 싱글 주거용 방에 가장 적합합니다.

조명은 또한 API가 선명한 비디오 스트림과 좋은 AR 추적 성능을 얻는 데 중요하다.

밤에 가족 거실에서 전형적인 API를 사용하려면 최소 50럭스 이상을 사용하는 것이 좋습니다.

하드웨어의 경우, RoomPlan API는 모든 LiDAR 지원 iPhone 및 iPad Pro 모델에서 지원됩니다.

API에 도전할 수 있는 몇 가지 특별한 조건이 있다.

예를 들어, 전체 높이 거울과 유리는 LiDAR 센서가 예상 출력을 생성하는 데 어려움을 제기한다.

높은 천장조차도 LiDAR 센서의 스캐닝 범위 한계를 초과할 수 있다.

또한, 매우 어두운 표면은 장치가 스캔하기 어려울 수 있다.

더 나은 스캔 결과를 얻기 위한 몇 가지 고려 사항이 있습니다.

첫째, 정확도 요구 사항이 높은 응용 프로그램의 경우, 스캔하기 전에 방을 준비하면 스캔의 품질을 향상시킬 수 있습니다.

예를 들어, 커튼을 열면 더 많은 자연광이 들어오고 창문 폐색을 줄일 수 있으며, 이는 주간 스캔에 가장 적합합니다.

문을 닫으면 방 밖의 불필요한 영역을 스캔할 가능성을 줄일 수 있다.

좋은 스캐닝 동작을 따르는 것은 API로 좋은 스캐닝 결과를 달성하는 데 매우 중요합니다.

그리고 그것이 우리가 스캔하는 동안 사람들에게 텍스처, 거리, 속도 및 조명 조건에 대한 피드백을 제공하기 위해 사용자 지시 위임 방법을 제공하는 이유입니다.

명심해야 할 또 다른 것은 장치의 배터리와 열전이다.

우리는 좋은 스캐닝 경험을 보장하기 위해 RoomPlan API에서 많은 최적화를 수행했습니다.

그럼에도 불구하고, 5분 동안 반복적인 스캔이나 한 번의 긴 스캔을 피하는 것이 가장 좋습니다.

이것들은 피로를 유발할 뿐만 아니라 배터리를 소모하고 앱의 사용자 경험에 영향을 미칠 수 있는 열 문제를 일으킬 수 있습니다.

오늘 우리가 다룬 많은 것들이 있다.

우리는 새로운 API인 RoomPlan을 도입했다.

방을 캡처할 수 있는 직관적인 스캔 경험, 환경을 이해하기 위한 강력한 기계 학습 모델, 앱에 쉽게 통합할 수 있는 완전한 파라메트릭 USD 출력 형식을 제공합니다.

새로운 RoomPlan 경험을 더 잘 설계하고 구현하는 방법에 대한 지침은 아래의 관련 회담을 확인하세요.

Praveen: 앱에서 RoomPlan을 시도해 볼 시간입니다.

우리는 당신이 이 새로운 API로 무엇을 만들 수 있는지 빨리 보고 싶습니다.

카이: 봐줘서 고마워!

♪