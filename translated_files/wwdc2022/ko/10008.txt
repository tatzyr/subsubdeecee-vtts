10008

♪ 기악 힙합 음악 ♪

♪

안녕하세요, 저는 존 쇤버그이고, 애플의 위치 기술 팀의 엔지니어입니다.

이 세션에서, 나는 당신이 공간 인식으로 더 풍부하고 다양한 경험을 구축할 수 있도록 가까운 상호 작용에 가져온 새로운 기능을 다룰 것입니다.

Nearby Interaction 프레임워크를 사용하면 Ultra Wideband 기술을 위한 Apple의 칩인 U1의 기능을 쉽게 활용할 수 있으며, Ultra Wideband용 Apple의 U1 칩과 호환되는 인근 Apple 장치 또는 액세서리 간에 정확하고 공간적으로 인식하는 상호 작용을 만들 수 있습니다.

지난 2년 동안 당신이 이용할 수 있었던 것에 대한 빠른 검토를 시작합시다.

WWDC 2020에서 Nearby Interaction이 도입되었을 때, 기능은 U1과 함께 두 iPhone 간의 세션을 만들고 실행하는 데 중점을 두었습니다.

WWDC 2021에서, 이 기능은 Apple Watch와 타사 초광대역 호환 액세서리로 실행 세션을 지원하도록 확장되었습니다.

인근 인터랙션 프레임워크의 API에 대한 심층 조사에 관심이 있다면, 2020년부터 WWDC 토크 "Get Nearby Interaction"와 2021년부터 "Explore Nearby Interaction with third-party accessories"를 검토하십시오.

우리는 인근 상호 작용에 대한 커뮤니티의 반응에 깜짝 놀랐고, 이 세션에서 당신을 위한 새로운 기능과 개선 사항을 공개하게 되어 기쁩니다.

나는 두 가지 주요 주제에 초점을 맞출 것이다: ARKit과의 주변 상호 작용 강화와 배경 세션.

그 과정에서, 저는 Nearby Interaction 프레임워크를 더 쉽게 사용할 수 있는 몇 가지 개선 사항을 공유하고 작년에 발표된 타사 하드웨어 지원에 대한 업데이트로 마무리할 것입니다.

우리는 당신이 새로운 기능으로 무엇을 할 것인지에 대해 흥분되니, 세부 사항에 바로 들어가 봅시다.

ARKit과 Nearby Interaction을 긴밀하게 통합하는 흥미진진한 새로운 기능으로 시작하겠습니다.

이 새로운 기능은 ARKit에서 계산된 장치 궤적을 활용하여 Nearby Interaction을 향상시킵니다.

ARKit이 강화한 Nearby Interaction은 AirTag로 정밀 검색을 지원하는 동일한 기본 기술을 활용하며, Nearby Interaction을 통해 사용할 수 있도록 하고 있습니다.

가장 좋은 사용 사례는 잘못된 항목, 관심 대상 또는 사용자가 상호 작용하고자 하는 객체와 같은 특정 주변 객체로 사용자를 안내하는 경험입니다.

ARKit과 Nearby Interaction을 통합함으로써, 거리와 방향 정보는 Nearby Interaction만을 사용하는 것보다 더 일관되게 사용할 수 있으며, 초광대역 시야를 효과적으로 넓혀준다.

마지막으로, 이 새로운 기능은 고정 장치와 상호 작용하는 데 가장 잘 사용된다.

ARKit과 Nearby Interaction의 새로운 통합이 애플리케이션과 함께 가능하게 하는 가능성에 대한 시연으로 바로 넘어갑시다.

사용자를 전시회로 안내하는 데 도움이 되는 초광대역 액세서리가 있는 제트팩 박물관을 위한 신청서가 있습니다.

다음 제트팩을 찾으러 가자.

사용자가 다음 전시회로 이동하도록 선택하면, 애플리케이션은 초광대역 액세서리를 발견하고 인근 상호 작용을 사용하기 위해 필요한 교환을 수행합니다.

그런 다음 응용 프로그램은 ARKit과 함께 향상된 주변 상호 작용 모드를 사용하여 다음 전시회의 물리적 위치를 결정하기 시작하는 동안 사용자에게 전화를 좌우로 이동하도록 지시합니다.

이제 응용 프로그램이 다음 전시회에 해당하는 방향을 이해했으므로, 사용자에게 확인할 방향을 알려주는 간단한 화살표 아이콘이 나타납니다.

ARKit과 Nearby Interaction의 조합을 활용하는 이 풍부하고 공간적으로 인식하는 정보는 전시회가 사용자 뒤에 있고 사용자가 전시회에서 멀리 떨어진 방향으로 향하고 있을 때를 나타낼 수도 있습니다.

마지막으로, 응용 프로그램은 AR 세계에서 다음 전시회 위치의 오버레이를 표시할 수 있으며, 응용 프로그램은 사용자가 AR 세계에서 전시회가 어디에 있는지 해결하기 위해 iPhone을 약간 위아래로 이동하라는 메시지를 표시합니다.

AR 콘텐츠가 장면에 배치되면, 초광대역 측정과 함께 인근 상호 작용과 ARKit의 강력한 조합을 통해 사용자는 다음 제트팩을 쉽게 확인할 수 있습니다.

나는 제트팩을 찾지 못했을지 모르지만, 여왕을 찾았다.

이제 이 향상된 주변 상호 작용 모드를 활성화하는 방법을 알아봅시다.

iOS 15를 사용하면 애플리케이션에 가까운 피어로부터 NIDiscoveryToken을 수락하고, 세션 구성을 만들고, NISession을 실행하는 방법이 있을 것입니다.

ARKit으로 향상된 모드를 활성화하면 NIConfiguration의 하위 클래스에서 새로운 isCameraAssistanceEnabled 속성으로 Nearby Interaction의 신규 및 기존 사용이 쉽습니다.

isCameraAssistanceEnabled 속성을 설정하는 것은 ARKit으로 향상된 모드를 활용하는 데 필요한 전부입니다.

카메라 지원은 두 개의 Apple 장치와 Apple 장치를 타사 초광대역 액세서리와 상호 작용할 때 사용할 수 있습니다.

카메라 지원이 활성화된 상태에서 NISession이 실행될 때 어떤 일이 일어나는지에 대한 세부 사항을 살펴봅시다.

카메라 지원이 활성화되면, ARSession은 Nearby Interaction 프레임워크 내에서 자동으로 생성됩니다.

당신은 이 ARSession을 만들 책임이 없습니다.

카메라 지원이 활성화된 NISession을 실행하면 Nearby Interaction 프레임워크 내에서 자동으로 생성된 ARSession도 실행됩니다.

ARSession은 신청 절차 내에서 실행되고 있다.

결과적으로, 애플리케이션은 애플리케이션의 Info.plist 내에서 카메라 사용 설명 키를 제공해야 합니다.

카메라가 좋은 경험을 제공하기 위해 왜 필요한지 사용자에게 알리기 위해 이것을 유용한 문자열로 만들어야 합니다.

주어진 애플리케이션에 대해 하나의 ARSession만 실행할 수 있습니다.

즉, 이미 앱에 ARKit 경험이 있다면, 만든 ARSession을 NISession과 공유해야 합니다.

ARSession을 NISession과 공유하기 위해, NISession 클래스에서 새로운 setARSession 방법을 사용할 수 있습니다.

NISession에서 실행하기 전에 setARSession이 호출되면, 세션이 실행될 때 Nearby Interaction 프레임워크 내에서 ARSession이 자동으로 생성되지 않습니다.

이것은 애플리케이션 ARKit 경험이 Nearby Interaction의 카메라 지원과 동시에 발생할 수 있도록 합니다.

이 SwiftUI 예제에서 makeUIView 함수의 일부로 ARView 내의 기본 ARSession은 새로운 setARSession 방법을 통해 NISession과 공유됩니다.

ARSession을 직접 사용하는 경우, ARWorldTrackingConfiguration을 사용하여 ARSession에서 실행을 호출해야 합니다.

또한, 카메라 지원의 고품질 성능을 보장하기 위해 이 ARConfiguration 내에서 몇 가지 속성을 특정 방식으로 구성해야 합니다.

worldAlignment는 중력, 협업 및 userFaceTracking 비활성화, nil initialWorldMap 및 sessionShouldAttempt Relocalization 메서드가 false를 반환하는 대리인으로 설정되어야 합니다.

당신이 만든 ARSession을 공유할 때 몇 가지 모범 사례로 돌아가 봅시다.

NISessionDelegate didInvalidateWith 오류 방법에서 항상 오류 코드를 검사하십시오.

공유 ARSession을 실행하는 데 사용된 ARConfiguration이 설명된 속성을 준수하지 않으면 NISession이 무효화됩니다.

새로운 NIError 코드 invalidARConfiguration이 반환됩니다.

앱에서 가까운 개체 업데이트를 받으려면, NISessionDelegate에서 didUpdateNearbyObjects 메소드를 계속 사용하세요.

didUpdateNearbyObjects 메소드에서, 당신은 아마도 원하는 피어에 대한 근처의 객체를 확인하고 사용 가능한 경우 NINearbyObject의 거리와 방향 속성을 기반으로 UI를 업데이트할 것입니다.

카메라 지원이 활성화되면, NINearbyObject 내에서 두 개의 새로운 속성을 사용할 수 있습니다.

첫 번째는 수평 각도이다.

이것은 근처의 물체에 대한 방위각 방향을 나타내는 라디안의 1D 각도이다.

사용할 수 없을 때, 이 값은 0이 될 것이다.

둘째, verticalDirectionEstimate는 수직 차원의 인근 물체와의 위치 관계이다.

이것은 새로운 VerticalDirectionEstimate 유형이다.

거리와 방향은 사용자의 장치와 인근 물체 사이의 주요 공간 관계를 나타낸다.

거리는 미터로 측정되며 방향은 장치에서 인근 물체까지의 3D 벡터입니다.

수평 각도는 NISession을 실행하는 장치와 로컬 수평면 내의 인근 물체 사이의 각도로 정의됩니다.

이것은 두 장치 사이의 수직 변위 오프셋과 장치 자체의 수평 회전을 설명한다.

방향은 3D이지만, 수평 각도는 두 장치 사이의 방향의 1D 표현이다.

이 수평 각도 속성은 방향 속성과 보완되며, 방향을 해결할 수 없는 경우, 수평 각도를 사용하여 사용자를 가까운 물체로 안내하는 데 도움이 될 수 있습니다.

수직 방향 추정은 수직 위치 정보에 대한 질적 평가이다.

당신은 그것을 사용하여 층층 사이에서 사용자를 안내해야 합니다.

이제 새로운 VerticalDirectionEstimate 유형을 살펴봅시다.

VerticalDirectionEstimate는 NINearbyObject 내에 중첩된 열거형이며 근처의 물체와의 수직 관계에 대한 질적 평가를 나타낸다.

속성을 사용하기 전에 VerticalDirectionEstimate를 알 수 없는지 확인하세요.

수직 관계는 동일하거나, 위, 아래, 또는 근처의 물체를 나타내는 특별한 aboveOrBelow 값이 같은 수준에 있지 않지만, 장치 위 또는 아래에 명확하게 있지 않을 수 있습니다.

초광대역 측정은 시야와 장애물의 대상이 된다.

방향 정보의 시야는 장치 뒤쪽에서 투영되는 원뿔에 해당한다.

카메라 지원이 활성화될 때 ARKit에서 계산된 장치 궤적을 사용하면 더 많은 시나리오에서 거리, 방향, 수평 각도 및 수직 방향 추정을 사용할 수 있어 초광대역 센서 시야를 효과적으로 확장할 수 있습니다.

이제 ARKit과 Nearby Interaction의 통합을 활용하여 장면에 AR 개체를 배치해 봅시다.

근처의 물체를 나타내는 3D 가상 콘텐츠를 카메라 피드 시각화에 더 쉽게 오버레이할 수 있도록, 우리는 도우미 방법을 추가했습니다: worldTransform on NISession.

이 방법은 사용 가능할 때 물리적 환경에서 주어진 주변 물체의 위치를 나타내는 ARKit의 좌표 공간에서 worldTransform을 반환합니다.

사용할 수 없는 경우, 이 방법은 nil을 반환합니다.

우리는 다음 전시회 위에 떠다니는 구체를 배치하기 위해 시연에서 이 방법을 사용했다.

우리는 당신이 가까운 상호 작용 위치 출력을 활용하여 앱에서 AR 세계의 콘텐츠를 조작할 수 있도록 가능한 한 쉽게 만들고 싶습니다.

결합된 iOS의 두 가지 강력한 시스템.

사용자는 카메라 지원이 세계 변환을 적절하게 계산할 수 있도록 장치를 수직 및 수평 방향으로 충분히 휩쓸어야 합니다.

이 방법은 카메라 지원이 ARKit 세계 변환에 완전히 수렴할 수 있도록 사용자 움직임이 불충분할 때 nil을 반환할 수 있습니다.

이 변환이 앱 경험에 중요할 때, 사용자가 이 변환을 생성하기 위한 조치를 취하도록 지도하는 것이 중요합니다.

이제 시연에서 본 것과 유사한 사용자를 안내할 수 있도록 NISessionDelegate에 추가한 몇 가지를 살펴보겠습니다.

사용자를 객체로 안내하기 위해, NISessionDelegate 콜백은 새로운 didUpdateAlgorithmConvergence 위임 방법을 통해 Nearby Interaction 알고리즘 수렴에 대한 정보를 제공합니다.

알고리즘 융합은 수평 각도, 수직 방향 추정 및 worldTransform을 사용할 수 없는 이유와 사용자가 이러한 속성을 해결하기 위해 취할 수 있는 조치를 이해하는 데 도움이 될 수 있습니다.

대리인은 새로운 NIAlgorithmConvergence 객체와 선택적 NINearbyObject를 제공한다.

이 위임 방법은 NIConfiguration에서 카메라 지원을 활성화한 경우에만 호출됩니다.

새로운 NIAlgorithmConvergence 유형을 살펴봅시다.

NIAlgorithmConvergence는 NIAlgorithm ConvergenceStatus 유형인 단일 상태 속성을 가지고 있다.

NIAlgorithmConvergenceStatus 유형은 알고리즘이 수렴되었는지 여부를 나타내는 열거형이다.

알고리즘이 수렴되지 않으면, NIAlgorithmConvergenceStatus 관련 값의 배열. 이유가 제공되었다.

새로운 대리자 방법으로 돌아가서 카메라 지원 상태를 사용자에게 업데이트하고 싶다고 말하고, 컨버전스 상태를 켜고 알 수 없거나 컨버전스된 경우 해당 정보를 사용자에게 표시할 수 있습니다.

NINearbyObject를 반드시 검사하세요.

객체가 0일 때, NIAlgorithmConvergence 상태는 특정 NINearbyObject가 아닌 세션 자체에 적용됩니다.

상태가 수렴되지 않을 때, 알고리즘이 수렴되지 않은 이유를 설명하는 관련 값도 포함한다.

이러한 이유로 현지화된 설명을 사용하면 사용자와 더 잘 소통할 수 있습니다.

다음으로 이 값들을 어떻게 사용하는지 살펴봅시다.

notConverged 사례와 관련 이유 값을 더 면밀히 검사하면, 사용자가 인근 물체에 대해 원하는 정보를 생성하는 데 도움이 되는 조치를 취하도록 안내할 수 있습니다.

관련 값은 NIAlgorithmConvergence StatusReasons의 배열이다.

그 이유는 총 움직임이 불충분하고, 수평 또는 수직 스윕의 움직임이 불충분하며, 조명이 불충분하다는 것을 나타낼 수 있다.

여러 가지 이유가 동시에 존재할 수 있다는 것을 염두에 두고 애플리케이션에 가장 중요한 각 작업을 통해 사용자를 순차적으로 안내하십시오.

내가 시연에서 어떻게 전화기를 옮겼고 세계 변화를 해결하기 위해 수평 및 수직 방향으로 휩쓸어야 했는지 기억하세요.

그것은 카메라 지원과 함께 향상된 주변 상호 작용 모드에 대한 가장 중요한 부분이다.

우리는 당신이 이 모드를 더 잘 활용할 수 있도록 몇 가지 추가 변경을 했습니다.

이전에는 NISession의 단일 isSupported 클래스 변수가 Nearby Interaction이 주어진 장치에서 지원되는지 확인하는 데 필요한 전부였습니다.

이것은 이제 더 이상 사용되지 않는다.

카메라 지원을 추가하여, 우리는 새로운 NIDeviceCapability 객체를 반환하는 NISession의 새로운 deviceCapabilities 클래스 멤버와 함께 Nearby Interaction에서 지원하는 장치 기능을 더 자세하게 설명했습니다.

최소한, supportsPreciseDistance Measurement 속성을 확인하는 것은 현재 더 이상 사용되지 않는 isSupported 클래스 변수와 동일합니다.

장치가 정확한 거리 측정을 지원한다는 것을 확인하면, NIDeviceCapability를 사용하여 애플리케이션을 실행하는 장치의 Nearby Interaction에서 사용할 수 있는 기능을 완전히 이해해야 합니다.

NIDeviceCapability 객체의 추가 supportsDirectionMeasurement 및 supportsCameraAssistance 속성을 확인하여 앱 경험을 장치의 기능에 맞게 조정하는 것이 좋습니다.

모든 장치가 방향 측정이나 카메라 지원을 지원하는 것은 아니므로, 이 장치의 기능에 맞는 경험을 포함해야 합니다.

특히, Apple Watch를 가장 잘 지원하기 위해 거리 전용 경험을 포함하는 것을 염두에 두세요.

그것이 ARKit과의 주변 상호 작용을 향상시키는 방법으로 카메라 지원을 위한 전부입니다. 그러니 이제 액세서리 배경 세션으로 관심을 돌봅시다.

오늘날, 앱에서 Nearby Interaction을 사용하여 사용자가 다른 장치를 가리키고, 친구를 찾고, 액세서리의 거리와 방향에 따라 컨트롤이나 다른 UI를 표시할 수 있습니다.

그러나, 앱이 백그라운드로 전환되거나 사용자가 iOS 및 watchOS에서 화면을 잠글 때, 실행 중인 모든 NISessions는 애플리케이션이 포그라운드로 돌아올 때까지 일시 중지됩니다.

이것은 당신이 액세서리와 상호 작용할 때 실제 사용자 경험에 집중해야 한다는 것을 의미합니다.

iOS 16부터, 주변 상호 작용은 핸즈프리가 되었다.

이제 근처 인터랙션을 사용하여 스마트 스피커로 방에 들어갈 때 음악을 재생하거나, eBike를 켜거나, 액세서리에서 다른 핸즈프리 동작을 트리거할 수 있습니다.

사용자가 액세서리 백그라운드 세션을 통해 앱을 적극적으로 사용하지 않는 경우에도 이를 수행할 수 있습니다.

이 흥미진진한 새로운 기능을 어떻게 성취할 수 있는지 봅시다.

액세서리로 NISession을 구성하고 실행하는 방법에 대한 순서를 잠시 검토해 봅시다.

작년 WWDC 프레젠테이션에서 이 시퀀스를 알아볼 수 있습니다.

액세서리는 데이터 채널을 통해 초광대역 액세서리 구성 데이터를 애플리케이션으로 전송하고, 이 데이터에서 NINearbyAccessoryConfiguration을 생성합니다.

NISession을 만들고, 액세서리에서 초광대역 측정을 얻기 위해 NISessionDelegate를 설정합니다.

구성으로 NISession을 실행하면 세션은 응용 프로그램과 상호 작용하도록 액세서리를 설정하기 위해 공유 가능한 구성 데이터를 반환합니다.

이 공유 가능한 구성 데이터를 액세서리로 다시 보낸 후, 이제 애플리케이션과 액세서리에서 초광대역 측정을 받을 수 있습니다.

타사 액세서리와의 인근 상호 작용 구성 및 실행에 대한 모든 세부 사항은 작년 WWDC 세션을 검토하십시오.

이제 새로운 배경 세션을 어떻게 설정했는지 살펴봅시다.

이전 시퀀스 다이어그램은 애플리케이션과 액세서리 사이에 흐르는 데이터를 보여주었습니다.

액세서리와 애플리케이션 간의 통신 채널이 블루투스 LE를 사용하는 것은 매우 일반적입니다.

블루투스 LE를 사용하여 액세서리와 페어링하면, 백그라운드에서 세션을 시작하고 계속하기 위해 Nearby Interaction을 활성화할 수 있습니다.

이것이 어떻게 가능한지 자세히 살펴봅시다.

오늘날, 앱이 백그라운드에 있는 동안 Core Bluetooth를 사용하여 Bluetooth LE 액세서리로 데이터를 검색, 연결 및 교환하도록 앱을 구성할 수 있습니다.

자세한 내용은 기존 코어 블루투스 프로그래밍 가이드 또는 2017년 WWDC 세션을 확인하세요.

코어 블루투스의 강력한 백그라운드 작업을 활용하여 액세서리를 효율적으로 발견하고 백그라운드에서 애플리케이션을 실행하면, 애플리케이션은 백그라운드에서 초광대역을 지원하는 블루투스 LE 액세서리로 NISession을 시작할 수 있습니다.

이제 이 새로운 모드를 반영하기 위해 시퀀스 다이어그램이 어떻게 업데이트되는지 살펴봅시다.

이 액세서리와 상호 작용하려면, 먼저 블루투스 LE 페어링인지 확인하세요.

그런 다음, 액세서리에 연결하세요.

액세서리가 액세서리 초광대역 구성 데이터를 생성할 때, 애플리케이션으로 보내고 Nearby Interaction GATT 서비스를 채워야 합니다. 다음에 더 자세히 알아보세요.

마지막으로, 애플리케이션이 액세서리의 구성 데이터를 받으면, 액세서리의 UWB 구성 데이터와 블루투스 피어 식별자를 모두 제공하는 새로운 이니셜라이저를 사용하여 NINearbyAccessoryConfiguration 객체를 구성하십시오.

이 구성으로 NISession을 실행하고 NISessionDelegate에서 공유 가능한 구성을 수신하여 설정을 완료하고 공유 가능한 구성을 액세서리로 보내십시오.

액세서리가 블루투스 식별자와 초광대역 구성 간의 관계를 만들려면, 새로운 인근 상호 작용 GATT 서비스를 구현해야 합니다.

Nearby Interaction 서비스에는 Accessory Configuration Data라는 단일 암호화된 특성이 포함되어 있습니다.

NINearbyAccessoryConfiguration 객체를 초기화하는 데 사용된 것과 동일한 UWB 구성 데이터가 포함되어 있습니다.

iOS는 이 특성을 사용하여 블루투스 피어 식별자와 NISession 간의 연관성을 확인합니다.

당신의 앱은 이 특성을 직접 읽을 수 없습니다.

Developer.apple.com/ nearby-interaction에서 이 새로운 Nearby Interaction GATT 서비스의 세부 사항에 대해 자세히 알아볼 수 있습니다.

액세서리가 여러 NISessions를 병렬로 지원하는 경우, 각각 다른 NISession의 UWB 구성을 가진 액세서리 구성 데이터의 여러 인스턴스를 만드세요.

그게 액세서리에 필요한 거야.

코드에 뛰어들어 애플리케이션에서 구현해야 할 것으로 전환해 봅시다!

액세서리 배경 세션은 액세서리가 사용자의 iPhone과 LE 페어링되어야 합니다.

당신의 앱은 이 과정을 트리거할 책임이 있습니다.

이렇게 하려면, 액세서리를 스캔하고, 연결하고, 서비스와 특성을 발견하는 방법을 구현하세요.

그런 다음, 액세서리의 암호화된 특성 중 하나를 읽는 방법을 구현하세요.

넌 이걸 한 번만 하면 돼.

그것은 사용자에게 페어링을 수락하라는 메시지를 보여줄 것이다.

액세서리 배경 세션은 또한 액세서리에 블루투스 연결이 필요합니다.

당신의 앱은 백그라운드가 되어 있어도 이 연결을 형성할 수 있어야 합니다.

이렇게 하려면, 액세서리에 대한 연결 시도를 시작하는 방법을 구현하십시오.

액세서리가 블루투스 범위 내에 있지 않더라도 이렇게 해야 합니다.

그런 다음, Core Bluetooth에 의해 앱을 다시 실행한 후 상태를 복원하고 연결이 설정될 때 처리하기 위해 CBManagerDelegate 메소드를 구현하십시오.

이제 액세서리 배경 세션을 실행할 준비가 되었습니다.

액세서리의 UWB 구성 데이터와 CBPeripheral 식별자에서 Bluetooth 피어 식별자를 모두 제공하여 NINearbyAccessoryConfiguration 객체를 만드세요.

해당 구성으로 NISession을 실행하면 앱이 백그라운드에 있는 동안 실행됩니다.

그게 다야!

음, Xcode에서 앱에 대해 업데이트해야 할 설정이 하나 더 있습니다.

이 백그라운드 모드는 앱의 Info.plist의 UIBackgroundModes 배열에 있는 Nearby Interaction 문자열이 필요합니다.

Xcode 기능 편집기를 사용하여 이 백그라운드 모드를 추가할 수도 있습니다.

또한 앱이 백그라운드에서 액세서리와 연결할 수 있도록 "블루투스 LE 액세서리 사용"을 활성화해야 합니다.

이 새로운 액세서리 배경 세션에 대한 한 가지 중요한 사항.

애플리케이션이 백그라운드에 있을 때, NISession은 계속 실행되고 중단되지 않으므로 액세서리에서 초광대역 측정을 사용할 수 있습니다.

액세서리의 초광대역 측정을 소비하고 행동해야 합니다.

애플리케이션은 런타임을 받지 않으며, 애플리케이션이 포그라운드로 돌아올 때까지 didUpdateNearbyObject 대리자 콜백을 받지 못할 것입니다.

이 새로운 백그라운드 모드를 사용할 때, 다음 모범 사례를 검토해 봅시다.

액세서리와 LE 페어링을 트리거하면 사용자에게 페어링을 수락하라는 메시지가 표시됩니다.

사용자가 액세서리를 페어링하고 싶은 이유에 대해 직관적인 시간에 이것을 하세요.

이것은 설정 흐름에서 액세서리와의 관계를 만들거나 사용자가 액세서리와 상호 작용하려는 욕구를 명확하게 나타낼 때일 수 있습니다.

앱이 백그라운드인 동안, NISession은 중단되지 않지만, didUpdateNearbyObject 대리자 콜백은 받지 않습니다.

그러나, 당신의 액세서리는 초광대역 측정을 받을 것입니다.

이러한 측정을 액세서리에서 직접 처리하여 사용자에게 어떤 조치가 일어나야 하는지 결정하십시오.

마지막으로, 중요한 사용자 상호 작용 중에 액세서리에서 앱으로 데이터만 전송하여 배터리 사용량을 관리하십시오. 예를 들어, 사용자에게 알림을 표시합니다.

그것이 당신이 백그라운드 세션에서 알아야 할 전부이며 제3자 하드웨어 지원에 대한 마지막 주제로 이어집니다.

오늘, 저는 이전에 사용 가능했던 베타 U1 호환 개발 키트가 이제 베타에서 벗어났고 더 광범위하게 사용할 수 있다는 것을 발표하게 되어 기쁩니다.

호환 가능한 초광대역 개발 키트에 대해 자세히 알아보려면 developer.apple.com /nearby-interaction을 방문하십시오.

우리는 또한 인근 상호 작용 GATT 서비스를 포함한 새로운 액세서리 배경 세션을 지원하기 위해 액세서리 제조업체의 사양을 업데이트했으며, 동일한 웹사이트에서 사용할 수 있습니다.

그래서, 우리가 이 세션에서 논의한 것을 요약해 봅시다.

Nearby Interaction에는 이제 ARKit과 Nearby Interaction을 긴밀하게 통합하는 새로운 카메라 지원 모드가 포함되어 있어 사용자를 인근 물체로 안내하는 공간 인식 경험을 만들 수 있는 원활한 경험을 제공합니다.

액세서리 배경 세션을 사용하면 세션을 시작하고 백그라운드로 확장하여 사용자를 위한 더 많은 실습 경험을 구축할 수 있습니다.

우리는 타사 호환 초광대역 하드웨어 지원에 대한 흥미로운 업데이트를 발표했습니다.

그것이 올해 인근 상호 작용 업데이트를 위한 것입니다.

데모를 다운로드하고, 업데이트된 기능에 대한 피드백을 받고, 업데이트된 타사 사양을 검토하고, 공간 경험으로 놀라운 앱을 만드세요.

고마워.

♪