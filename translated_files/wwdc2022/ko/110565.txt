110565

♪ ♪

켄 그린바움: 안녕하세요 여러분! WWDC 2022에 오신 것을 환영합니다.

제 이름은 켄 그린바움이고, 저는 애플의 컬러 및 디스플레이 테크놀로지 팀과 함께 있습니다.

우리는 올해 세 번의 EDR 회담을 갖게 되어 기쁩니다.

iOS에 대한 EDR API 지원을 발표한 "Explore EDR on iOS"와 "Display EDR content with Core Image, Metal, and SwiftUI"를 볼 수 있는 기회를 가졌기를 바랍니다.

여러분 중 일부는 작년에 제 EDR 강연을 보았을 수도 있습니다. 여기서 우리는 EDR을 사용하여 AVPlayer를 사용하여 HDR 비디오를 재생하는 방법을 시연했습니다.

이 강연에서 우리는 더 깊이 들어가고, 코어 미디어 인터페이스를 사용하여 EDR 재생뿐만 아니라 HDR 비디오를 자신의 EDR 레이어 또는 뷰로 디코딩하고 재생하는 방법을 탐구할 것입니다.

그런 다음 우리는 단순히 콘텐츠를 재생하는 것 외에도 Core Video의 디스플레이 링크를 통해 실시간으로 디코딩된 비디오 프레임에 액세스하는 방법을 보여주고, 해당 프레임을 CoreImage 필터 또는 Metal Shader로 보내 색상 관리, 시각 효과를 추가하거나 다른 신호 처리를 적용하고, 마지막으로 결과 프레임을 Metal에 배치하여 렌더링할 것입니다.

우리는 당신이 애플리케이션의 요구 사항에 가장 잘 맞는 것을 결정할 수 있도록 EDR 호환 비디오 미디어 프레임워크를 검토하는 것으로 시작할 것입니다.

다음으로 우리는 애플리케이션에 직접 재생이 필요한 경우 HDR 비디오를 재생하는 모든 작업을 수행할 수 있는 높은 수준의 AVKit 및 AVFoundation 프레임워크에 대해 간략하게 논의할 것입니다.

그리고 마지막으로, 우리는 EDR 재생, 편집 또는 이미지 처리 엔진에서 코어 비디오 및 메탈과 함께 디코딩된 비디오 프레임을 사용하는 모범 사례에 대해 논의할 것입니다.

Apple의 비디오 프레임워크에 대한 빠른 설문 조사를 통해 시작합시다; 가장 사용하기 쉬운 최고 수준의 인터페이스부터 시작하며, 코드에 복잡성을 추가하는 비용으로 더 많은 기회를 제공하는 낮은 수준의 프레임워크를 계속 진행합시다.

자동으로 제공되는 최적화를 활용하기 위해 가능한 최고 수준의 프레임워크를 사용하는 것이 가장 좋습니다.

이를 통해 우리는 간단한 EDR 재생에서 디코딩된 비디오 프레임의 보다 정교한 배관, 실시간 처리를 위한 CoreImage 또는 Metal에 이르기까지 다양한 시나리오를 탐구할 수 있는 대화의 본문에 뛰어들 준비를 할 것입니다.

최고 수준에는 AVKit이 있다.

AVKit을 사용하면 미디어 재생을 위한 사용자 인터페이스를 만들 수 있습니다. 전송 컨트롤, 챕터 탐색, Picture in Picture 지원, 자막 및 청각 장애인용 자막 표시가 있습니다.

AVKit은 AVPlayerViewController를 사용하여 시연할 것처럼 HDR 콘텐츠를 EDR로 재생할 수 있습니다.

그러나, 애플리케이션에 비디오 프레임의 추가 처리가 필요한 경우, 파이프라인을 더 잘 제어할 수 있는 미디어 프레임워크를 사용해야 합니다.

다음은 AVFoundation입니다.

AVFoundation은 Apple 플랫폼에서 시간 기반 시청각 미디어로 작업하기 위한 모든 기능을 갖춘 프레임워크입니다.

AVFoundation을 사용하면 QuickTime 영화와 MPEG 4 파일을 쉽게 재생, 생성 및 편집하고, HLS 스트림을 재생하고, 앱에 강력한 미디어 기능을 구축할 수 있습니다.

우리는 이 강연에서 AVPlayer와 관련 AVPlayerLayer 인터페이스의 사용을 탐구할 것입니다.

코어 비디오는 디지털 비디오를 위한 파이프라인 모델을 제공하는 프레임워크이다.

프로세스를 개별 단계로 분할하여 비디오 작업 방식을 단순화합니다.

또한 Core Video를 사용하면 데이터 유형 간의 번역이나 디스플레이 동기화에 대해 걱정할 필요 없이 개별 프레임에 더 쉽게 액세스하고 조작할 수 있습니다.

우리는 DisplayLink와 CVPixelBuffer의 Core Image의 사용을 시연할 것입니다.

그리고 금속이 있는 CVMetalTextureCache.

다음은 비디오 툴박스입니다.

이것은 하드웨어 인코더와 디코더에 직접 접근할 수 있는 저수준 프레임워크이다.

비디오 툴박스는 비디오 압축 및 압축 해제, 그리고 코어 비디오 픽셀 버퍼에 저장된 래스터 이미지 형식 간의 변환 서비스를 제공합니다.

VTDecompressionSession은 이 이야기의 범위를 벗어나는 강력한 저수준 인터페이스이지만, 고급 개발자들은 더 조사하고 싶어할 수도 있다.

그리고 마지막으로, 핵심 미디어가 있다.

이 프레임워크는 AVFoundation에서 사용하는 미디어 파이프라인과 다른 고급 미디어 프레임워크를 정의합니다.

Core Media의 낮은 수준의 데이터 유형과 인터페이스를 사용하여 미디어 샘플을 효율적으로 처리하고 미디어 데이터 대기열을 관리할 수 있습니다.

이 이야기의 나머지 부분에서 우리는 앱에서 이러한 프레임워크를 언제 어떻게 사용해야 하는지 보여줄 것입니다.

먼저, AVKit과 AVFoundation을 사용하여 EDR로 렌더링된 HDR 비디오를 쉽게 재생하는 방법.

그런 다음 AVPlayer의 일련의 더 정교한 응용 프로그램: 자신의 레이어로 렌더링하고, CADisplayLink를 통해 개별적으로 디코딩된 프레임에 액세스하고, 처리를 위해 결과 CVPixelBuffers를 코어 이미지로 보내고, 마지막으로 Metal에서 처리 및 렌더링을 위해 CVMetalTextureCache를 통해 금속 텍스처로 디코딩된 프레임에 액세스합니다.

이제 Apple 플랫폼의 비디오 미디어 레이어에 대한 개요가 있으니, AVKit과 AVFoundation 프레임워크에 초점을 맞출 것입니다.

먼저 AVFoundation의 AVPlayer 인터페이스를 사용하여 HDR 비디오 콘텐츠 재생에 대해 논의하는 것으로 시작합시다.

AVPlayer는 미디어 자산의 재생과 타이밍을 관리하는 데 사용되는 컨트롤러 객체이다.

AVPlayer 인터페이스는 HDR 비디오의 고성능 재생에 사용할 수 있으며, 가능하면 자동으로 결과를 EDR로 렌더링합니다.

AVPlayer를 사용하면 QuickTime 영화와 같은 로컬 및 원격 파일 기반 미디어를 재생할 수 있으며, HLS를 사용하여 제공되는 스트리밍 미디어도 재생할 수 있습니다.

본질적으로, AVPlayer는 한 번에 하나의 미디어 자산을 재생하는 데 사용됩니다.

플레이어 인스턴스를 재사용하여 추가 미디어 자산을 연속적으로 재생하거나 여러 인스턴스를 만들어 하나 이상의 자산을 동시에 재생할 수 있지만, AVPlayer는 한 번에 하나의 미디어 자산만 재생을 관리합니다.

AVFoundation 프레임워크는 또한 순차 HDR 미디어 자산의 대기열 및 재생을 만들고 관리하는 데 사용할 수 있는 AVQueuePlayer라는 AVPlayer의 하위 클래스를 제공합니다.

애플리케이션이 EDR로 렌더링된 HDR 비디오 미디어의 간단한 재생이 필요한 경우, AVPlayerViewController가 있는 AVPlayer가 최선의 접근 방식일 수 있습니다.

AVPlayerLayer와 함께 AVPlayer를 사용하여 iOS 또는 macOS에서 자신의 뷰를 재생하세요.

이것들은 AVPlayer를 사용하는 가장 간단한 방법이다.

둘 다의 예를 살펴봅시다.

먼저 AVKit의 AVPlayer 뷰 컨트롤러와 함께 AVFoundation의 AVPlayer 인터페이스를 어떻게 사용할 수 있는지 살펴보겠습니다.

여기서, 우리는 미디어의 URL에서 AVPlayer를 인스턴스화하는 것으로 시작합니다.

다음으로 AVPlayerViewController를 만든 다음, 뷰어 컨트롤러의 플레이어 속성을 미디어의 URL에서 방금 만든 플레이어로 설정합니다.

그리고 비디오 재생을 시작하기 위해 뷰 컨트롤러를 모달로 제시하세요.

AVKit은 모든 세부 사항을 관리하고 EDR을 지원하는 디스플레이에서 HDR 비디오를 EDR로 자동으로 재생합니다.

내가 언급했듯이, 일부 응용 프로그램은 HDR 비디오 미디어를 자체 보기로 재생해야 할 것이다.

AVPlayerLayer와 함께 AVPlayer를 사용하여 이것을 달성하는 방법을 살펴봅시다.

자신의 보기에서 HDR 비디오 미디어를 EDR로 재생하려면, 미디어의 URL로 AVPlayer를 만드는 것으로 다시 시작합니다.

그러나 이번에는 우리가 방금 만든 플레이어로 AVPlayerLayer를 인스턴스화합니다.

다음으로 우리는 뷰에서 얻은 플레이어 레이어의 경계를 설정해야 합니다.

이제 플레이어 레이어가 뷰에서 경계를 가지고 있으므로, 플레이어 레이어를 뷰에 하위 레이어로 추가할 수 있습니다.

마지막으로, HDR 비디오 미디어를 재생하기 위해, 우리는 AVPlayer의 재생 방법이라고 부른다.

그것이 AVPlayer와 AVPlayerLayer를 사용하여 자신의 레이어에서 HDR 비디오 미디어를 EDR로 재생하는 데 필요한 전부입니다.

우리는 방금 AVPlayer를 사용하여 가장 간단한 두 가지 HDR 비디오 재생 워크플로우를 탐구했습니다.

그러나, 많은 응용 프로그램은 단순한 미디어 재생 이상의 것을 필요로 한다.

예를 들어, 응용 프로그램은 비디오에 적용하기 위해 컬러 그레이딩이나 크로마 키잉과 같은 이미지 처리를 요구할 수 있습니다.

AVPlayer에서 비디오 프레임을 디코딩하고, 코어 이미지 필터 또는 메탈 셰이더를 실시간으로 적용하고, 결과를 EDR로 렌더링하는 워크플로우를 살펴봅시다.

우리는 AVPlayer와 AVPlayerItem을 사용하여 HDR 비디오 미디어에서 EDR 프레임을 디코딩하고, 코어 비디오 디스플레이 링크에서 디코딩된 프레임에 액세스하고, 처리를 위해 결과 픽셀 버퍼를 코어 이미지 또는 메탈로 보낸 다음, EDR을 지원하는 디스플레이의 EDR로 CAMetalLayer에서 결과를 렌더링하는 방법을 시연할 것입니다.

이를 염두에 두고, 먼저 HDR 미디어가 EDR로 올바르게 렌더링되도록 하는 데 필요한 CAMetalLayer에 몇 가지 주요 속성을 설정하는 것을 보여줍시다.

먼저 우리는 HDR 비디오 콘텐츠를 렌더링할 CAMetalLayer를 가져와야 합니다.

그 레이어에서 우리는 wantsExtendedDynamicRangeContent 플래그를 true로 설정하여 EDR을 선택합니다.

확장된 다이내믹 레인지 콘텐츠를 지원하는 픽셀 형식을 사용해야 합니다.

다음 AVPlayer 예제의 경우, 우리는 CAMetalLayer를 하프 플로트 픽셀 형식을 사용하도록 설정할 것이지만, PQ 또는 HLG 전송 기능과 함께 사용되는 10비트 형식도 작동합니다.

결과를 SDR로 제한하지 않으려면, 레이어를 EDR 호환 확장 범위 색상 공간으로 설정해야 합니다.

우리의 예에서 우리는 반 플로트 금속 질감을 확장된 선형 디스플레이 P3 색 공간으로 설정할 것이다.

우리는 방금 EDR, 색상 공간 및 픽셀 버퍼 형식에 관한 표면을 긁었다.

자세한 내용은 작년의 내 세션인 "EDR을 사용한 HDR 렌더링"과 올해의 "iOS의 EDR"을 확인할 수 있습니다.

이제 CAMetalLayer의 기본 속성을 설정했으므로, Core Image 또는 Metal 셰이더를 사용하여 실시간 이미지 처리를 추가하여 시연을 계속해 봅시다.

우리는 AVPlayer와 함께 디스플레이 링크를 사용하여 디코딩된 비디오 프레임에 실시간으로 액세스할 것입니다.

이 워크플로우의 경우, AVPlayerItem에서 AVPlayer를 만드는 것으로 시작합니다.

다음으로, EDR을 위한 적절한 픽셀 버퍼 형식과 색상 공간으로 구성된 AVPlayerItemVideoOutput을 인스턴스화합니다.

그런 다음 디스플레이 링크를 만들고 구성합니다.

그리고 마지막으로, 디스플레이 링크를 실행하여 처리를 위해 코어 이미지 또는 금속으로 픽셀 버퍼를 가져오세요.

우리는 iOS에서 사용되는 CADisplayLink를 시연할 것입니다.

macOS용으로 개발할 때 동등한 CVDisplayLink 인터페이스를 사용하세요.

이번에는 미디어의 URL에서 AVPlayerItem을 만들고, 방금 만든 AVPlayerItem으로 AVPlayer를 인스턴스화하기로 선택합니다.

이제 우리는 디코딩된 프레임의 색상 공간과 픽셀 버퍼 형식을 지정하기 위해 한 쌍의 사전을 만듭니다.

첫 번째 사전인 videoColorProperties는 색 공간과 전송 기능이 지정된 곳이다.

이 예에서 우리는 대부분의 Apple 디스플레이의 색상 공간에 해당하는 디스플레이 P3 색상 공간과 AVFoundation이 EDR에 필요한 확장된 범위 값을 유지할 수 있는 선형 전송 기능을 요청합니다.

두 번째 사전인 outputVideoSettings는 픽셀 버퍼 형식의 특성을 지정하고 우리가 방금 만든 videoColorProperties 사전에 대한 참조를 제공합니다.

이 예에서, 우리는 넓은 색과 하프 플로트 픽셀 버퍼 형식을 요청합니다.

AVPlayerItemVideoOutput은 출력 설정 사전에서 지정한 픽셀 버퍼 형식으로 비디오를 디코딩할 뿐만 아니라 픽셀 전송 세션을 통해 필요한 색상 변환을 자동으로 수행하는 것이 매우 유용합니다.

기억하세요, 비디오는 잠재적으로 다른 색 공간을 가진 여러 클립을 포함할 수 있습니다.

AVFoundation은 우리를 위해 이것들을 자동으로 관리하며, 우리가 곧 시연할 것처럼, 이 동작은 또한 결과 디코딩된 비디오 프레임을 디스플레이의 색 공간으로 자동 색 공간 변환을 제공하지 않는 메탈과 같은 낮은 수준의 프레임워크로 보낼 수 있게 해준다.

이제 우리는 outputVideoSettings 사전을 사용하여 AVPlayerItemVideoOutput을 만듭니다.

세 번째 단계로, 우리는 실시간으로 디코딩된 프레임에 액세스하는 데 사용될 디스플레이 링크를 설정합니다.

CADisplayLink는 각 디스플레이 업데이트에서 실행되는 콜백을 받습니다.

우리의 예에서 우리는 처리를 위해 Core Image로 보낼 CVPixelBuffers를 얻기 위해 잠시 후에 탐색할 로컬 함수를 호출합니다.

다음으로 지정된 플레이어 항목 속성에 대한 변경 사항을 처리할 수 있도록 비디오 플레이어 항목 관찰자를 만듭니다.

우리의 예제는 플레이어 아이템의 상태 변경에 대해 매번 이 코드를 실행할 것이다.

플레이어 항목의 상태가 readyToPlay로 변경되면, 방금 반환된 새로운 AVPlayerItemItem에 AVPlayerItemVideoOutput을 추가하고, 공통 모드로 설정된 메인 실행 루프로 CADisplayLink를 등록하고, 비디오 플레이어에서 재생을 호출하여 HDR 비디오의 실시간 디코딩을 시작합니다.

마지막으로, 우리는 이전에 `displayLinkCopyPixelBuffers` 로컬 함수라고 언급한 CADisplayLink 콜백 구현의 예를 살펴보겠습니다.

HDR 비디오가 재생되기 시작하면, 각 디스플레이 새로 고침에서 CADisplayLink 콜백 기능이 호출됩니다.

예를 들어, 그것은 전형적인 디스플레이의 경우 초당 60번 호출될 수 있다.

이것은 새로운 CVPixelBuffer가 있는 경우 표시된 프레임을 업데이트할 수 있는 우리 코드의 기회입니다.

각 디스플레이 콜백에서, 우리는 현재 벽시계 시간에 표시될 디코딩된 비디오 프레임이 포함된 CVPixelBuffer를 복사하려고 시도합니다.

그러나, 특히 화면 재생률이 재생 중인 비디오의 재생률을 초과할 때 모든 디스플레이 새로 고침에서 사용할 수 있는 새로운 CVPixelBuffer가 항상 있는 것은 아니기 때문에 `copyPixelBuffer` 호출이 실패할 수 있습니다.

새로운 CVPixelBuffer가 없다면, 호출이 실패하고 렌더링을 건너뜁니다.

이로 인해 이전 프레임이 다른 디스플레이 새로 고침을 위해 화면에 남아 있습니다.

하지만 복사본이 성공하면, CVPixelBuffer에 새로운 비디오 프레임이 있습니다.

우리가 이 새로운 프레임을 처리하고 렌더링할 수 있는 방법은 여러 가지가 있다.

한 가지 기회는 처리를 위해 CVPixelBuffer를 Core Image로 보내는 것이다.

코어 이미지는 하나 이상의 시필터를 함께 묶어 비디오 프레임에 GPU 가속 이미지 처리를 제공할 수 있습니다.

모든 CIFilters가 EDR과 호환되는 것은 아니며 SDR 또는 더 나쁜 것으로 클램핑하는 것을 포함하여 HDR 콘텐츠에 문제가 있을 수 있습니다.

코어 이미지는 많은 EDR 호환 필터를 제공한다.

CICategoryHighDynamicRange와 함께 필터 이름을 사용하여 EDR 호환 코어 이미지 필터를 열거하십시오.

우리의 예에서, 우리는 간단한 세피아 톤 효과를 추가할 것이다.

이제 우리의 예시로 돌아가서 핵심 이미지를 통합해 봅시다.

새로운 CVPixelBuffer를 생성하는 각 디스플레이 링크 콜백에서 해당 픽셀 버퍼에서 CIImage를 만드세요.

원하는 효과를 구현하기 위해 CIFilter를 예시하세요.

저는 매개 변수가 없는 단순성 때문에 세피아 톤 필터를 사용하고 있지만, 시스템에는 많은 CIFilters가 내장되어 있으며, 직접 작성하는 것도 간단합니다.

CIFilter의 inputImage를 우리가 방금 만든 CIImage로 설정하세요.

그리고 처리된 비디오 결과는 필터의 출력 이미지에서 사용할 수 있습니다.

원하는 효과를 얻기 위해 필요한 만큼의 CIFilters를 함께 연결하세요.

그런 다음 CIRenderDestination을 사용하여 결과 이미지를 애플리케이션의 보기 코드로 렌더링하십시오.

이 워크플로우에 대한 자세한 내용은 WWDC 2020 토크 "비디오 앱의 핵심 이미지 파이프라인 최적화"를 참조하십시오.

또 다른 기회는 Metal 및 사용자 지정 Metal 셰이더를 사용하여 신선한 CVPixelBuffer를 처리하고 렌더링하는 것입니다.

우리는 CVPixelBuffer를 금속 텍스처로 변환하는 과정을 간략하게 설명할 것이다.

그러나, 최고의 성능을 유지하면서 이 전환을 구현하는 것은 다른 이야기에 가장 좋은 깊은 주제이다.

대신 CoreVideo Metal 텍스처 캐시에서 Metal 텍스처를 추출하는 것이 권장되며, 이 강연의 마지막 예로 그 과정을 진행할 것입니다.

일반적으로, 이 과정은 CVPixelBuffer에서 IOSurface를 가져오고, MetalTextureDescriptor를 만든 다음, 'newTextureWithDescriptor'를 사용하여 MetalDevice에서 MetalTexture를 만드는 것입니다.

그러나, 신중한 잠금이 적용되지 않으면 텍스처가 재사용되고 과도하게 당겨질 위험이 있습니다.

또한, 모든 PixelBuffer 형식이 MetalTexture에서 기본적으로 지원되는 것은 아니기 때문에 이 예제에서 하프 플로트를 사용합니다.

이러한 합병증 때문에, 이제 시연할 것처럼 코어 비디오에서 메탈 텍스처에 직접 액세스하는 것이 좋습니다.

코어 비디오와 메탈을 더 자세히 살펴봅시다.

언급했듯이, CVMetalTextureCache는 CVPixelBuffers를 Metal과 함께 사용하는 간단하고 효율적인 방법입니다.

CVMetalTextureCache는 추가 변환 없이 캐시에서 직접 금속 텍스처를 얻을 수 있기 때문에 편리합니다.

CVMetalTextureCache는 CVPixelBuffer와 MetalTexture를 자동으로 연결하여 코드를 단순화하고 빠른 경로를 유지합니다.

CVPixelBufferPools와 함께, CVMetalTextureCache는 MTLTexture to IOSurface 매핑을 유지함으로써 성능 이점을 제공합니다.

마지막으로, CVMetalTextureCache를 사용하면 IOSurfaces를 수동으로 추적할 필요가 없습니다.

이제 우리 이야기의 마지막 예: CVMetalTextureCache를 사용하여 코어 비디오에서 직접 금속 텍스처를 추출하는 방법.

여기서, 우리는 시스템 기본 금속 장치를 얻는 것으로 시작합니다.

우리는 그것을 사용하여 메탈 텍스처 캐시를 만든 다음, 메탈 텍스처 캐시와 관련된 코어 비디오 메탈 텍스처 캐시를 인스턴스화합니다.

그런 다음 금속 엔진에서 직접 사용할 수 있는 금속 텍스처로 디코딩된 비디오 프레임에 액세스하는 데 사용할 수 있습니다.

이 예에서, 우리는 금속 시스템 기본 장치를 만들고 사용합니다.

다음으로 우리는 방금 만든 금속 장치를 지정하여 CVMetalTextureCacheCreate로 CVMetalTextureCache를 만듭니다.

우리는 코어 비디오 메탈 텍스처를 만드는 데 필요한 CVPixelBuffer의 높이와 너비를 얻는다.

그런 다음 'CVMetalTextureCacheCreateTextureFromImage'를 호출하여 CVMetalTexture 객체를 인스턴스화하여 CVPixelBuffer와 연결합니다.

마지막으로 우리는 원하는 금속 질감을 얻기 위해 `CVMetalTextureGetTexture`를 호출합니다.

Swift 애플리케이션은 CVMetalTexture에 대한 강력한 참조를 사용해야 하지만, Objective-C를 사용할 때 CVMetalTextureRef를 출시하기 전에 Metal이 텍스처로 완료되었는지 확인해야 합니다.

이것은 금속 명령 버퍼 완료 핸들러를 사용하여 수행될 수 있다.

그리고 그게 다야, 얘들아!

검토하기 위해, 우리는 재생, 편집 또는 이미지 처리를 위해 HDR 비디오 미디어를 EDR로 렌더링하는 많은 워크플로우를 탐구했습니다.

HDR 미디어를 재생하기 위해 AVPlayer에서 AVKit의 AVPlayerViewController로 가는 방법을 배웠습니다.

또한 AVPlayerLayer와 함께 AVPlayer를 사용하여 자신의 보기에 HDR 미디어를 표시하는 방법을 배웠습니다.

그리고 마지막으로, 우리는 재생 중에 실시간 효과를 추가하는 방법을 탐구했다.

AVFoundation의 AVPlayer를 CoreVideo에 연결한 다음 렌더링을 위해 Metal에 연결합니다.

그리고 CoreImage 필터와 금속 셰이더를 사용하여 실시간 효과를 적용합니다.

더 깊이 파고들고 싶다면, 비디오 워크플로우를 만들고 HDR 미디어를 EDR과 통합하는 것과 관련된 몇 가지 WWDC 세션을 추천합니다.

저는 특히 "AVFoundation으로 HDR 비디오를 편집하고 재생하세요"라는 세션을 부르고 싶습니다.

이 세션은 HDR 미디어에 효과를 적용하기 위해 `applyingCIFiltersWithHandler`와 함께 AVVideoComposition의 사용을 탐구합니다.

이 세션에서는 각 비디오 프레임을 처리할 수 있게 되면 CVPixelBuffer와 함께 사용할 수 있는 사용자 지정 컴포지터를 사용하는 방법을 배우게 됩니다.

처음에 언급했듯이, 올해 우리는 EDR에 대한 두 개의 다른 세션을 발표할 것입니다: EDR API 지원이 iOS를 포함하도록 확장되었다고 발표한 "iOS의 EDR"과 EDR을 다른 미디어 프레임워크와 통합하는 것을 더 탐구하는 "CoreImage, Metal 및 SwiftUI를 사용한 HDR 콘텐츠 표시"입니다.

macOS와 현재 iOS 모두에서 HDR 비디오를 EDR 지원 응용 프로그램에 통합하기를 바랍니다.

봐줘서 고마워.