10026

♪ 부드러운 기악 힙합 음악 ♪

♪

안녕! 제 이름은 아담 브래드포드입니다.

저는 VisionKit 팀의 엔지니어이며, 앱에 라이브 텍스트를 추가하고 싶다면, 당신은 올바른 위치에 있습니다.

하지만 먼저, 라이브 텍스트가 뭐야?

라이브 텍스트는 이미지를 분석하고 사용자가 텍스트 선택 및 복사, 조회 및 번역과 같은 작업을 수행하고, 주소 매핑, 번호 다이얼 또는 URL로 점프와 같은 데이터 감지 워크플로우를 제공하는 등 콘텐츠와 상호 작용할 수 있는 기능을 제공합니다.

라이브 텍스트는 QR 코드 상호 작용도 허용합니다.

이것을 앱에서 어떻게 사용할 수 있는지 상상해 보세요.

더 알고 싶어? 음, 당신은 올바른 장소에 있습니다.

이 세션을 위해, 저는 라이브 텍스트 API에 대한 일반적인 개요로 시작하겠습니다.

그런 다음 기존 애플리케이션에서 이 API를 구현하는 방법을 살펴보겠습니다.

다음으로, 앱에 라이브 텍스트를 추가할 때 도움이 될 수 있는 몇 가지 팁과 요령을 살펴보겠습니다.

이제 라이브 텍스트 API에 대한 개요를 확인하세요.

높은 수준에서, 라이브 텍스트 API는 스위프트에서 사용할 수 있다.

그것은 정적 이미지에서 아름답게 작동하며 일시 정지된 비디오 프레임에 사용하도록 조정할 수 있습니다.

텍스트나 QR 코드와 같은 항목을 검색하기 위해 라이브 카메라 스트림에서 비디오를 분석해야 하는 경우, VisionKit에는 데이터 스캐너도 사용할 수 있습니다.

더 많은 정보를 위해 제 동료 론의 이 세션을 확인하세요.

라이브 텍스트 API는 Apple Neural Engine이 있는 장치와 macOS 13을 지원하는 모든 장치에서 iOS 16부터 사용할 수 있습니다.

그것은 네 개의 주요 수업으로 구성되어 있다.

그것을 사용하려면, 먼저 이미지가 필요합니다.

그런 다음 이 이미지는 비동기 분석을 수행하는 ImageAnalyzer에 공급됩니다.

분석이 완료되면, 결과 ImageAnalysis 객체는 플랫폼에 따라 ImageAnalysisInteraction 또는 ImageAnalysisOverlayView에 제공됩니다.

지금까지는 꽤 간단해 보여, 그렇지?

이제, 나는 그것을 기존 애플리케이션에 어떻게 추가할지 보여줄 것이다.

그리고 여기 우리의 신청서가 있습니다.

이것은 스크롤 뷰 내부에 이미지 뷰가 있는 간단한 이미지 뷰어입니다.

주목하세요, 저는 줌과 팬을 둘 다 할 수 있습니다.

하지만 내가 할 수 있는 한, 나는 이 텍스트 중 어느 것도 선택하거나 이 데이터 탐지기를 활성화할 수 없다.

이건 그냥 안 될 거야.

여기 Xcode의 프로젝트가 있습니다.

이 응용 프로그램에 라이브 텍스트를 추가하려면, 뷰 컨트롤러 하위 클래스를 수정할 것입니다.

먼저, 저는 ImageAnalyzer와 ImageAnalysisInteraction이 필요합니다.

여기서, 저는 단순히 viewDidLoad를 재정의하고 imageview에 상호 작용을 추가하고 있습니다.

다음으로, 나는 언제 분석을 수행해야 하는지 알아야 한다.

새 이미지가 설정되면, 먼저 이전 이미지에 대한 선호하는 상호 작용 유형과 분석을 재설정합니다.

이제 모든 것이 새로운 분석을 위한 준비가 되었다.

다음으로, 나는 우리가 사용할 기능을 만들고 우리의 이미지가 존재하는지 확인할 것이다.

그렇다면, 작업을 만드세요.

다음으로, 분석기에게 무엇을 찾아야 하는지 말하기 위해 구성을 만드세요.

이 경우, 나는 텍스트와 기계가 읽을 수 있는 코드로 갈 것이다.

분석을 생성하는 것은 던질 수 있으므로, 적절하게 처리하세요.

그리고 이제 마지막으로, 저는 분석 프로세스를 시작할 method analyzeImageWithConfiguration을 호출할 준비가 되었습니다.

분석이 완료되면, 불확실한 시간이 지났고, 응용 프로그램의 상태가 변경되었을 수 있으므로, 분석이 모두 성공적이었고 표시된 이미지가 변경되지 않았는지 확인하겠습니다.

이 모든 검사가 통과되면, 상호 작용에 대한 분석을 설정하고 선호하는 상호 작용 유형을 설정할 수 있습니다.

저는 여기서 .automatic을 사용하고 있으며, 이는 저에게 기본 시스템 동작을 제공할 것입니다.

내 생각에 이건 시험 준비가 된 것 같아.

오, 그거 봐!

라이브 텍스트 버튼이 나타났고, 네, 이제 텍스트를 선택할 수 있습니다.

이러한 인터페이스 요소가 나를 위해 어떻게 자동으로 배치되는지 주목하고, 내 부분 작업 없이 이미지 경계와 가시 영역 모두에서 위치를 유지하세요.

좋아요, 라이브 텍스트 버튼을 탭하면 선택 가능한 항목을 강조하고, 데이터 검출기에 밑줄을 긋고, 빠른 동작을 표시할 수 있습니다.

이 빠른 동작을 쉽게 탭하여 전화를 걸 수 있으며, 길게 눌러 더 많은 옵션을 볼 수도 있습니다.

넌 인정해야 해, 이건 꽤 멋져.

이 몇 줄의 코드로, 나는 평범한 이미지를 찍었고 그것에 생명을 불어넣었다.

이 간단한 응용 프로그램은 이제 이미지에서 텍스트를 선택하고, 데이터 탐지기, QR 코드, 조회, 텍스트 번역 등을 활성화할 수 있습니다.

네가 나에게 묻는다면, 이 몇 줄의 코드에서 너무 초라하지 않아.

그리고 이제 라이브 텍스트를 구현하는 방법을 보았으니, 입양에 도움이 될 수 있는 몇 가지 팁과 요령을 살펴볼 것입니다.

나는 상호 작용 유형을 탐구하는 것으로 시작할 것이다.

대부분의 개발자는 텍스트 선택을 제공하는 .automatic을 원하지만, 라이브 텍스트 버튼이 활성화되면 데이터 검출기를 강조할 것이다.

이것은 적용 가능한 감지된 항목 아래에 선을 그을 것이며 한 번의 탭으로 활성화할 수 있습니다.

이것은 당신이 내장된 응용 프로그램에서 볼 수 있는 것과 똑같은 행동입니다.

앱이 데이터 검출기 없이 텍스트 선택만 하는 것이 합리적이라면, 유형을 .textSelection으로 설정할 수 있으며 라이브 텍스트 버튼의 상태로 변경되지 않습니다.

그러나 앱에 텍스트 선택 없이 데이터 탐지기만 있는 것이 합리적이라면, 유형을 .dataDetectors로 설정하십시오.

이 모드에서는 선택이 비활성화되어 있기 때문에 라이브 텍스트 버튼이 표시되지 않지만, 데이터 검출기는 밑줄이 긋고 한 번의 탭으로 액세스할 수 있습니다.

선호하는 상호 작용 유형을 빈 세트로 설정하면 상호 작용이 비활성화됩니다.

또한, 텍스트 선택 또는 자동 모드가 있는 마지막 메모는 길게 눌러 데이터 탐지기를 활성화할 수 있다는 것을 알 수 있습니다.

이것은 allowLongPressForDataDetectorsIn TextMode 속성에 의해 제어되며, 기본값인 true로 설정하면 활성화됩니다.

필요한 경우 이것을 비활성화하려면 false로 설정하기만 하면 됩니다.

저는 이제 잠시 시간을 내어 보충 인터페이스로 알려진 하단의 이 버튼들에 대해 이야기하고 싶습니다.

이것은 일반적으로 오른쪽 하단 모서리에 있는 라이브 텍스트 버튼과 왼쪽 하단에 나타나는 빠른 동작으로 구성되어 있습니다.

빠른 동작은 분석의 모든 데이터 검출기를 나타내며 라이브 텍스트 버튼이 활성화되어 있을 때 볼 수 있습니다.

크기, 위치 및 가시성은 상호 작용에 의해 제어됩니다.

그리고 기본 위치와 모양이 시스템과 일치하지만, 앱에는 다른 글꼴과 기호 가중치를 방해하거나 활용할 수 있는 사용자 지정 인터페이스 요소가 있을 수 있습니다.

이 인터페이스를 어떻게 사용자 정의할 수 있는지 봅시다.

우선, isSupplementary InterfaceHidden 속성.

앱이 여전히 텍스트를 선택할 수 있도록 허용하고 싶지만 라이브 텍스트 버튼을 표시하고 싶지 않다면, SupplementaryInterfaceHidden을 true로 설정하면 라이브 텍스트 버튼이나 빠른 동작을 볼 수 없습니다.

우리는 또한 사용 가능한 콘텐츠 삽입 속성이 있습니다.

보충 인터페이스와 겹치는 인터페이스 요소가 있는 경우, 라이브 텍스트 버튼과 빠른 동작이 보일 때 기존 앱 콘텐츠에 잘 적응하도록 콘텐츠 삽입을 조정할 수 있습니다.

앱이 인터페이스를 채택하고 싶은 사용자 지정 글꼴을 사용하는 경우, supplementaryInterfaceFont를 설정하면 라이브 텍스트 버튼과 빠른 동작이 텍스트에 지정된 글꼴을 사용하고 기호에 글꼴 가중치를 사용할 수 있습니다.

버튼 크기 일관성을 위해 라이브 텍스트는 포인트 크기를 무시한다는 점에 유의하십시오.

잠시 기어를 바꾸면, UIImageview를 사용하지 않는다면, 하이라이트가 이미지와 일치하지 않는다는 것을 발견할 수 있습니다.

이는 UIImageView를 통해 VisionKit이 ContentMode 속성을 사용하여 contentsRect를 자동으로 계산할 수 있기 때문입니다.

여기서, 상호 작용의 보기는 이미지 콘텐츠보다 큰 경계를 가지고 있지만 단위 직사각형인 기본 콘텐츠 rect를 사용하고 있습니다.

이것은 대리 메서드 contentsRectForInteraction을 구현하여 쉽게 해결하고 이를 수정하기 위해 이미지 콘텐츠가 상호 작용의 경계와 어떻게 관련되는지 설명하는 단위 좌표 공간에 직사각형을 반환합니다.

예를 들어, 이러한 값으로 직사각형을 반환하면 문제가 해결되지만, 앱의 현재 콘텐츠와 레이아웃에 따라 올바른 정규화된 직사각형을 반환하십시오.

contentsRectForInteraction은 상호 작용의 경계가 변경될 때마다 호출되지만, contentsRect가 변경되었지만 상호 작용의 경계가 변경되지 않은 경우, setContentsRectNeedsUpdate()를 호출하여 상호 작용을 업데이트하도록 요청할 수 있습니다.

라이브 텍스트를 채택할 때 가질 수 있는 또 다른 질문은, 이 상호 작용을 하기에 가장 좋은 장소는 어디입니까?

이상적으로, 라이브 텍스트 상호 작용은 이미지 콘텐츠를 호스팅하는 보기에 직접 배치됩니다.

앞서 언급했듯이, UIImageView는 당신을 위해 contentsRect 계산을 처리할 것이며, 필요하지는 않지만 선호됩니다.

UIImageview를 사용하는 경우, imageView에서 상호 작용을 설정하면 VisionKit이 나머지를 처리합니다.

그러나, ImageView가 ScrollView 내부에 있다면, ScrollView에 상호 작용을 배치하고 싶은 유혹을 받을 수 있지만, 이것은 권장되지 않으며 지속적으로 변화하는 contentsRect가 있기 때문에 관리하기 어려울 수 있습니다.

여기서의 해결책은 동일하며, 확대가 적용된 ScrollView 내부에 있더라도 이미지 콘텐츠를 호스팅하는 뷰에 상호 작용을 배치하십시오.

나는 잠시 제스처에 대해 이야기할 것이다, 라이브 텍스트는 매우, 매우 풍부한 제스처 인식기 세트를 가지고 있다.

앱이 어떻게 구성되어 있는지에 따라, 앱이 실제로 처리해야 하는 제스처와 이벤트에 응답하는 상호 작용을 찾을 수 있으며 그 반대의 경우도 마찬가지입니다.

당황하지 마.

다음은 이러한 문제가 발생하는 경우 수정하는 데 사용할 수 있는 몇 가지 기술입니다.

이것을 수정하는 한 가지 일반적인 방법은 위임 방법 interactionShouldBeginAtPointFor InteractionType을 구현하는 것입니다.

False를 반환하면, 그 행동은 수행되지 않을 것이다.

시작하기에 좋은 장소는 상호 작용에 주어진 시점에 대화형 항목이 있는지 또는 활성 텍스트 선택이 있는지 확인하는 것입니다.

텍스트 선택 확인이 여기에 사용되므로 선택을 해제하기 위해 텍스트를 탭할 수 있습니다.

반면에, 상호 작용이 제스처에 반응하지 않는 것 같다면, 앱에 제스처 인식기가 있기 때문일 수 있습니다.

이 경우, gestureRecognizer의 gestureRecognizerShouldBegin 위임 방법을 사용하여 유사한 솔루션을 만들 수 있습니다.

여기서, 나는 비슷한 검사를 수행하고 위치에 대화형 항목이 있거나 활성 텍스트 선택이 있는 경우 false를 반환합니다.

참고로.

이 예에서, 저는 먼저 nil을 전달하여 gestureRecognizer의 위치를 창의 좌표 공간으로 변환한 다음 상호 작용의 보기로 변환합니다.

상호 작용이 확대가 적용된 ScrollView 내부에 있는 경우 필요할 수 있습니다.

만약 당신의 포인트가 일치하지 않는다면, 이 기술을 시도해 보세요.

내가 유용하다고 생각한 또 다른 유사한 옵션은 UIView의 hitTest:WithEvent를 재정의하는 것이다.

여기서, 다시 한 번, 비슷한 이야기, 나는 이전과 같은 유형의 검사를 수행하고, 이 경우 적절한 보기를 반환합니다.

언제나처럼, 우리는 당신의 앱이 가능한 한 반응하기를 원하며, 신경 엔진은 분석을 매우 효율적으로 만드는 반면, 최고의 성능을 위해 공유하고 싶은 몇 가지 ImageAnalyzer 팁이 있습니다.

이상적으로, 당신은 앱에서 하나의 ImageAnalyzer만 공유하기를 원합니다.

또한, 우리는 몇 가지 유형의 이미지를 지원합니다.

가지고 있는 네이티브 유형을 전달하여 항상 이미지 변환을 최소화해야 합니다. 그러나 CVPixelBuffer가 있다면 가장 효율적일 것입니다.

또한, 시스템 리소스를 최대한 활용하려면, 이미지가 화면에 나타날 때 또는 그 직전에만 분석을 시작해야 합니다.

앱의 콘텐츠 스크롤(예를 들어, 타임라인이 있는 경우) 스크롤이 중지된 후에만 분석을 시작하세요.

이제 이 API는 라이브 텍스트를 볼 수 있는 유일한 장소가 아니며, 지원은 앱이 이미 사용할 수 있는 시스템 전반에 걸쳐 몇 가지 프레임워크에서 자동으로 제공됩니다.

예를 들어, UITextField 또는 UITextView는 키보드 입력을 위해 카메라를 사용하여 라이브 텍스트를 지원합니다.

그리고 라이브 텍스트는 WebKit과 Quick Look에서도 지원됩니다.

더 많은 정보를 원하시면, 이 세션들을 확인하세요.

올해 iOS 16의 새로운 기능, 우리는 AVKit에 라이브 텍스트 지원을 추가했습니다.

AVPlayerView와 ViewController는 기본적으로 활성화된 allowsVideoFrameAnalysis 속성을 통해 일시 중지된 프레임의 라이브 텍스트를 자동으로 지원합니다.

이것은 FairPlay로 보호되지 않은 콘텐츠에서만 사용할 수 있습니다.

AVPlayerLayer를 사용하는 경우, 분석과 상호 작용을 관리할 책임이 있지만 현재 프레임을 얻기 위해 currentDisplayedPixelBuffer 속성을 사용하는 것이 매우 중요합니다.

이것이 적절한 프레임이 분석되고 있다는 것을 보장하는 유일한 방법이다.

이것은 비디오 재생률이 0인 경우에만 유효한 값을 반환하며, 이것은 얕은 복사본이며 쓰기에 절대적으로 안전하지 않습니다.

그리고 다시 한번, FairPlay로 보호되지 않은 콘텐츠에서만 사용할 수 있습니다.

우리는 당신의 앱에 라이브 텍스트 기능을 제공하는 것을 돕게 되어 기쁩니다.

라이브 텍스트 팀의 모든 사람들을 대표하여, 이 세션에 참여해 주셔서 감사합니다.

저는 당신이 당신의 앱에서 이미지에 그것을 어떻게 사용하는지 보게 되어 기쁩니다.

그리고 언제나처럼, 재밌게 놀아!

♪