10020

♪ 기악 힙합 음악 ♪

♪

안녕하세요, 제 이름은 데이비드 핀들레이이고, 저는 Create ML 팀의 엔지니어입니다.

이 세션은 자신만의 기계 학습 작업을 구축하는 강력한 새로운 방법인 ML 구성 요소 만들기에 관한 것입니다.

제 동료 알레한드로는 "ML 구성 요소 만들기에 대해 알아보세요" 세션에서 소개했습니다.

그는 Create ML 작업을 구성 요소로 해체하는 것을 탐구하고 사용자 지정 모델을 만드는 것이 얼마나 쉬운지 밝혔다.

트랜스포머와 추정기는 이미지 회귀와 같은 사용자 지정 모델을 구축하기 위해 함께 구성할 수 있는 주요 빌딩 블록입니다.

이 세션에서, 저는 기본을 넘어 Create ML Components로 가능한 것을 보여주고 싶습니다.

안건을 검토해 봅시다; 다루어야 할 것이 많습니다.

비디오 데이터에 대해 이야기하고 시간이 지남에 따라 값을 처리하도록 설계된 새로운 구성 요소에 대해 자세히 살펴보겠습니다.

그런 다음 나는 그 개념들을 작동시키고 변압기만을 사용하여 인간 행동 반복 카운터를 만들 것이다.

마지막으로, 나는 맞춤형 사운드 분류기 모델을 훈련하는 것으로 넘어갈 것이다.

배치로 모델을 업데이트하고, 훈련을 일찍 중단하고, 모델을 체크포인트할 수 있는 증분 피팅에 대해 논의하겠습니다.

이 수준의 유연성에는 많은 기회가 있다.

빨리 뛰어들고 싶어.

시작하자.

WWDC 2020에서, 우리는 비디오에서 작업을 분류할 수 있는 Create ML에 액션 분류를 도입했습니다.

그리고 우리는 점프 잭, 런지, 스쿼트와 같은 사람의 운동 루틴을 인식하기 위해 피트니스 분류기를 만드는 방법을 시연했습니다.

예를 들어, 액션 분류기를 사용하여 이 비디오의 액션을 점프 잭으로 인식할 수 있습니다.

하지만 네가 점프 잭을 세고 싶다면?

가장 먼저 고려해야 할 것은 점프 잭이 연속 프레임에 걸쳐 있다는 것이며, 시간이 지남에 따라 값을 처리하는 방법이 필요할 것입니다.

고맙게도, 스위프트의 비동기 시퀀스는 이것을 정말 쉽게 만든다.

비동기 시퀀스에 익숙하지 않다면, "Meet AsyncSequence" 세션을 확인해야 합니다.

Create ML Components를 사용하면 비디오 리더를 사용하여 비디오를 비동기 프레임 시퀀스로 읽을 수 있습니다.

그리고 AsyncSequence는 비디오에서 수신된 프레임을 반복하는 방법을 제공합니다.

예를 들어, 지도 방법을 사용하여 각 비디오 프레임을 비동기적으로 쉽게 변환할 수 있습니다.

이것은 한 번에 하나씩 프레임을 처리하고 싶을 때 유용합니다.

하지만 한 번에 여러 프레임을 처리하고 싶다면 어떨까요?

그곳이 일시적인 변압기가 들어오는 곳이다.

예를 들어, 비디오의 작업 속도를 높이기 위해 프레임을 다운샘플링하고 싶을 수도 있습니다.

비동기 시퀀스를 취하고 다운샘플링된 비동기 시퀀스를 반환하는 다운샘플러를 사용할 수 있습니다.

또는 작업 반복을 계산하는 데 중요한 프레임을 창으로 그룹화하고 싶을 수도 있습니다.

그곳은 슬라이딩 윈도우 변압기를 사용할 수 있는 곳이다.

창에서 그룹화하려는 프레임 수인 창 길이와 슬라이딩 간격을 제어하는 방법인 보폭을 지정할 수 있습니다.

입력은 다시 비동기 시퀀스이며, 이 경우 출력은 창이 있는 비동기 시퀀스이다.

일반적으로 말하자면, 시간 변압기는 비동기 시퀀스를 새로운 비동기 시퀀스로 처리하는 방법을 제공한다.

그러니 이 개념들을 작동하게 합시다.

나는 너에 대해 모르지만, 내가 운동할 때, 나는 항상 내 담당자의 수를 잃는다.

그래서 나는 상황을 조금 흔들고 Create ML Components로 액션 반복 카운터를 만들기로 결정했다.

이 예에서, 나는 변압기와 시간 변압기를 함께 구성하는 방법을 살펴볼 것이다.

포즈 추출부터 시작합시다.

나는 인체 자세 추출기를 사용하여 포즈를 추출할 수 있다.

입력은 이미지이고 출력은 인체 포즈의 배열이다.

무대 뒤에서, 우리는 포즈를 추출하기 위해 비전 프레임워크를 활용합니다.

이미지에는 여러 사람이 포함될 수 있으며, 이는 그룹 운동에 일반적입니다.

그것이 출력이 포즈의 배열인 이유이다.

하지만 나는 한 번에 한 사람의 행동 반복을 세는 것에만 관심이 있다.

그래서 나는 포즈 선택기로 인체 포즈 추출기를 구성할 것이다.

포즈 선택기는 다양한 포즈와 선택 전략을 취하고 단일 포즈를 반환합니다.

선택할 수 있는 몇 가지 선택 전략이 있지만, 이 예에서는 올바른 MostJointLocation 전략을 사용할 것입니다.

다음 단계는 포즈를 창문으로 그룹화하는 것이다.

나는 그것을 위해 슬라이딩 윈도우 변압기를 추가할 것이다.

그리고 나는 90개의 창 길이와 보폭을 사용할 것이며, 이는 90개의 포즈의 겹치지 않는 창을 생성할 것이다.

슬라이딩 윈도우 변압기는 일시적이어서 전체 작업을 일시적으로 만들고, 예상되는 입력은 이제 프레임의 비동기 시퀀스라는 것을 기억하세요.

마지막으로, 나는 인체 액션 카운터를 추가할 것이다.

이 시간 변압기는 창이 있는 비동기 포즈 시퀀스를 소비하고 지금까지의 누적 동작 반복 횟수를 반환합니다.

지금쯤이면, 당신은 카운트가 부동 소수점이라는 것을 눈치챘을 것입니다.

그리고 그것은 그 작업이 부분적인 행동도 계산하기 때문이다.

그렇게 쉬워.

이제 나는 내 운동 비디오에서 내 담당자를 셀 수 있고 내가 바람을 피우지 않는지 확인할 수 있다.

하지만 현재 운동을 추적할 수 있도록 앱에서 반복을 실시간으로 세는 것이 훨씬 더 나을 것이다.

네가 그걸 어떻게 할 수 있는지 보여줄게.

먼저, 카메라 구성을 취하고 카메라 프레임의 비동기 시퀀스를 반환하는 readCamera 방법을 사용할 것입니다.

다음으로, 나는 업데이트된 카운트를 더 자주 얻을 수 있도록 보폭 매개 변수를 15프레임으로 조정할 것이다.

내 카메라가 초당 30프레임의 속도로 프레임을 캡처한다면, 나는 0.5초마다 카운트를 얻는다.

이제 나는 운동을 할 수 있고 담당자를 놓치는 것에 대해 걱정하지 않는다.

지금까지, 나는 비동기 시퀀스를 변환하기 위한 시간적 구성 요소를 탐구했다.

다음으로, 저는 시간 데이터에 의존하는 사용자 지정 모델을 훈련하는 데 집중하고 싶습니다.

2019년에, 우리는 Create ML에서 사운드 분류기를 훈련시키는 방법을 시연했습니다.

그리고 2021년에, 우리는 사운드 분류를 개선했다.

나는 더 나아가 맞춤형 사운드 분류기를 점진적으로 훈련시키고 싶다.

Create ML 프레임워크의 MLSoundClassifier는 여전히 사용자 지정 사운드 분류기 모델을 훈련시키는 가장 쉬운 방법입니다.

하지만 더 많은 사용자 정의와 제어가 필요할 때, 후드 아래의 구성 요소를 사용할 수 있습니다.

가장 간단한 형태로, 사운드 분류기에는 두 가지 구성 요소가 있습니다: 오디오 기능 인쇄 기능 추출기와 원하는 분류기.

AudioFeaturePrint는 비동기 시퀀스의 오디오 버퍼에서 오디오 기능을 추출하는 시간 변압기입니다.

슬라이딩 윈도우 변압기와 유사하게, AudioFeaturePrint는 비동기 시퀀스를 윈도우한 다음 기능을 추출합니다.

선택할 수 있는 몇 가지 분류기가 있지만, 이 예에서는 로지스틱 회귀 분류기를 사용한 다음 기능 추출기와 함께 구성하여 사용자 지정 사운드 분류기를 만들 것입니다.

다음 단계는 라벨이 지정된 훈련 데이터에 사용자 지정 사운드 분류기를 맞추는 것입니다.

훈련 데이터 수집에 대한 자세한 내용은 "ML 구성 요소 만들기" 세션이 시작하기에 좋은 곳입니다.

지금까지, 나는 행복한 길을 덮었다.

하지만 기계 학습 모델을 구축하는 것은 반복적인 과정이 될 수 있다.

예를 들어, 시간이 지남에 따라 새로운 훈련 데이터를 발견하고 수집하고 모델을 새로 고치고 싶을 수 있습니다.

모델 품질을 향상시킬 수 있습니다.

하지만 당신의 모델을 처음부터 재교육하는 것은 시간이 많이 걸립니다.

이전 모든 데이터에 대해 기능 추출을 다시 해야 하기 때문입니다.

새로 발견된 데이터로 모델을 훈련할 때 시간을 절약할 수 있는 방법을 보여드리겠습니다.

핵심은 모델을 맞추는 것과 별도로 훈련 데이터를 사전 처리하는 것입니다.

이 예에서는 분류기 피팅과 별도로 오디오 기능을 추출할 수 있습니다.

그리고 이것은 일반적으로도 작동한다.

일련의 변압기와 추정기가 있을 때마다, 추정기로 이어지는 변압기를 통해 입력을 사전 처리할 수 있습니다.

전처리 방법을 호출한 다음 전처리된 기능에 모델을 맞추기만 하면 됩니다.

나는 사운드 분류기 구성을 바꿀 필요가 없었기 때문에 이것이 편리하다고 생각한다.

이제 기능을 별도로 추출했으므로, 새로운 데이터에 대한 오디오 기능만 추출할 수 있는 유연성이 있습니다.

모델에 대한 새로운 훈련 데이터를 발견하면, 이 데이터를 별도로 쉽게 사전 처리할 수 있습니다.

그리고 나서 이전에 추출한 것들에 추가 기능을 추가하세요.

이것은 전처리가 시간을 절약할 수 있는 첫 번째 예일 뿐입니다.

모델 구축 수명 주기로 돌아가자.

모델의 품질에 만족할 때까지 추정 매개 변수를 조정해야 할 수도 있습니다.

피팅에서 특징 추출을 분리함으로써, 당신은 당신의 특징을 한 번만 추출한 다음 다른 추정 매개 변수로 모델을 맞출 수 있습니다.

기능 추출을 다시 실행하지 않고 분류기 매개 변수를 변경하는 예를 살펴봅시다.

내가 이미 기능을 추출했다고 가정하면, 분류기의 L2 페널티 매개 변수를 수정할 것이다.

그리고 나서 오래된 기능 추출기에 새로운 분류기를 추가해야 합니다.

추정기를 조정할 때 기능 추출기를 변경하지 않는 것이 중요합니다. 왜냐하면 그것은 이전에 추출된 기능을 무효화할 것이기 때문입니다.

당신의 모델을 배치로 점진적으로 맞추는 것으로 넘어갑시다.

기계 학습 모델은 일반적으로 많은 양의 훈련 데이터로부터 이익을 얻는다.

그러나, 당신의 앱에는 제한된 메모리 제약이 있을 수 있습니다.

그래서 넌 뭐해?

Create ML Components를 사용하여 한 번에 데이터 배치만 메모리에 로드하여 모델을 훈련시킬 수 있습니다.

내가 가장 먼저 해야 할 일은 분류기를 업데이트 가능한 분류기로 교체하는 것이다.

배치로 사용자 지정 모델을 훈련시키려면, 분류기를 업데이트할 수 있어야 합니다.

예를 들어, 완전히 연결된 신경망 분류기는 업데이트할 수 없는 로지스틱 회귀 분류기 대신 쉽게 사용할 수 있습니다.

좋아, 이제 내가 훈련 루프를 쓸게.

기본 초기화 모델을 만드는 것으로 시작하겠습니다.

당신은 아직 예측을 할 수 없을 것입니다; 그것은 이것이 훈련의 출발점에 불과하기 때문입니다.

그런 다음 교육이 시작되기 전에 오디오 기능을 추출하겠습니다.

모든 반복의 기능을 추출하고 싶지 않기 때문에 이것은 중요한 단계이다.

다음 단계는 훈련 루프를 정의하고 훈련하고 싶은 반복 횟수를 지정하는 것입니다.

계속하기 전에, 알고리즘의 스위프트 패키지를 가져올 것이다.

훈련 데이터 배치를 만들기 위해 그게 필요할 거야.

자세한 내용은 WWDC 2021의 "Meet the Swift Algorithms and Collections packages" 세션을 확인하세요.

훈련 루프 내에서 일괄 처리가 일어나는 곳이다.

나는 청크 방법을 사용하여 기능을 훈련을 위해 배치로 그룹화할 것이다.

청크 크기는 한 번에 메모리에 로드되는 기능의 수입니다.

그런 다음, 배치를 반복하고 업데이트 방법을 호출하여 모델을 업데이트할 수 있습니다.

모델을 점진적으로 훈련시키면, 몇 가지 훈련 기술을 더 잠금 해제할 수 있습니다.

예를 들어, 이 훈련 그래프에서, 약 10번의 반복 후에, 모델 정확도는 95%로 정체된다.

이 시점에서, 모델은 수렴되었고 당신은 일찍 멈출 수 있습니다.

훈련 루프에서 조기 중지를 실행합시다.

내가 가장 먼저 해야 할 일은 검증 세트에 대한 예측을 하는 것이다.

검증 예측을 주석과 페어링해야 하기 때문에 여기서 mapFeatures 방법을 사용하고 있습니다.

다음 단계는 모델의 품질을 측정하는 것이다.

지금은 내장된 메트릭을 사용할 것이지만, 자신만의 사용자 지정 메트릭을 구현하는 것을 막을 수 있는 것은 없습니다.

그리고 마지막으로, 나는 내 모델이 95%의 정확도에 도달하면 훈련을 중단할 것이다.

훈련 루프 밖에서, 나는 나중에 예측하는 데 사용할 수 있도록 모델을 디스크에 쓸 것이다.

일찍 멈추는 것 외에도, 나는 모델 체크포인트에 대해 이야기하고 싶다.

끝날 때까지 기다리는 대신 훈련 중에 모델의 진행 상황을 저장할 수 있습니다.

그리고 훈련을 재개하기 위해 체크포인트를 사용할 수도 있는데, 이는 특히 모델이 훈련하는 데 오랜 시간이 걸릴 때 편리합니다.

훈련 루프에 모델을 작성하기만 하면 됩니다.

체크포인트 간격을 정의하여 몇 번의 반복마다 이것을 하는 것이 좋습니다.

그렇게 쉬워.

이 세션에서, 나는 오디오와 비디오와 같은 시간 데이터로 기계 학습 작업을 구축하는 새로운 방법인 시간적 구성 요소를 소개했다.

나는 인간의 행동 반복 카운터를 만들기 위해 시간적 구성 요소를 함께 구성했다.

그리고 마지막으로, 나는 증분 피팅에 대해 이야기했다.

이것은 당신이 당신의 앱에 기계 학습을 구축할 수 있는 새로운 가능성을 열어줄 것입니다.

나와 함께 해줘서 고맙고 남은 WWDC를 즐겨.

♪