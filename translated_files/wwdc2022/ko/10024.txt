10024

♪ ♪

안녕하세요, 제 이름은 브렛 키팅이고, 비전 프레임워크의 새로운 기능을 소개하게 되어 기쁩니다.

넌 비전이 처음일지도 몰라.

아마도 이것은 당신이 비전 프레임워크에 대해 본 첫 번째 세션일 것입니다.

그렇다면, 환영해.

당신의 이익을 위해, 비전 프레임워크에 대한 몇 가지 하이라이트를 간략하게 요약해 봅시다.

당신을 위한 몇 가지 비전 프레임워크 사실.

비전은 2017년에 처음 소개되었으며, 그 이후로 비전이 제공하는 기술로 수천 개의 훌륭한 앱이 개발되었습니다.

비전은 시간이 지남에 따라 계속 성장하는 컴퓨터 비전 알고리즘의 모음이며 얼굴 감지, 이미지 분류 및 윤곽 감지와 같은 것들을 포함합니다.

이러한 각 알고리즘은 사용하기 쉽고 일관된 API를 통해 사용할 수 있습니다.

비전 프레임워크에서 하나의 알고리즘을 실행하는 방법을 알고 있다면, 그것들을 모두 실행하는 방법을 알고 있습니다.

그리고 비전은 지원하는 모든 플랫폼에서 애플 실리콘을 최대한 활용하여 비전의 많은 알고리즘의 핵심에서 기계 학습을 강화합니다.

비전은 tvOS, iOS 및 macOS에서 사용할 수 있으며, Mac에서 Apple Silicon을 완전히 활용할 것입니다.

비전 프레임워크에 대한 최근 추가 사항에는 여기에 표시된 사람 세분화가 포함됩니다.

또한 이 데모에 표시된 손 포즈 추정.

그리고 여기 신체 자세 추정과 궤적 분석을 사용하는 액션 앤 비전 샘플 앱이 있습니다.

오늘 우리의 의제는 향상된 기능을 제공하거나, 성능을 개선하거나, 정확성을 향상시킬 수 있는 기존 요청에 대한 업데이트인 몇 가지 새로운 개정에 대한 개요로 시작됩니다.

먼저, 텍스트 인식을 위한 새로운 개정판이 있습니다.

이것은 VNRecognizeTextRequestRevision3에 의해 주어진 세 번째 개정판이다.

이것은 놀라운 라이브 텍스트 기능을 지원하는 텍스트 인식기입니다.

텍스트 인식기는 여러 언어를 지원하며, supportedRecognitionLanguages를 호출하여 지원되는 언어를 찾을 수 있습니다.

우리는 이제 몇 가지 새로운 언어를 추가했고, 몇 가지 예를 보여드리겠습니다.

우리는 이제 비전에서 한국어를 지원하고 있다.

여기 한국어 영수증을 전사하는 직장에서의 비전의 예가 있습니다.

그리고 여기에 현재 지원되는 이 언어에 대한 Vision의 텍스트 인식 결과를 보여주는 일본어에 대한 해당 예가 있습니다.

텍스트 인식을 위해, 우리는 새로운 자동 언어 식별을 가지고 있습니다.

recognitionLanguages 속성을 사용하여 사용할 인식 언어를 지정할 수 있습니다.

하지만 앱 사용자가 어떤 언어를 인식하려고 하는지 미리 모른다고 가정해 봅시다.

이제, 정확한 인식 모드를 위해서만, 자동으로DetectsLanguage를 true로 설정하여 텍스트 인식기에 언어를 자동으로 감지하도록 요청할 수 있습니다.

언어 감지가 때때로 이것을 틀릴 수 있기 때문에, 어떤 언어를 인식해야 할지 모르는 상황에 이것을 사용하는 것이 가장 좋습니다.

어떤 언어를 인식해야 하는지에 대한 사전 지식이 있다면, 이러한 언어를 Vision에 지정하고 자동으로DetectsLanguage를 끄는 것이 가장 좋습니다.

다음으로, VNDetectBarcodesRequestRevision3이라고 불리는 바코드 감지를 위한 새로운 세 번째 개정판이 있습니다.

이 개정판은 이전 개정판에서 벗어난 현대 기계 학습을 활용한다.

바코드는 매장의 제품에서 자주 볼 수 있는 바코드부터 QR 코드, 의료 애플리케이션에 사용되는 특수 코드에 이르기까지 다양한 기호로 제공됩니다.

비전이 어떤 기호를 지원하는지 알기 위해, 당신은 supportedSymbologies라고 부를 수 있습니다.

공연에 대해 이야기해 봅시다.

부분적으로는 ML을 사용하고 있기 때문에 한 번에 하나가 아닌 한 번에 여러 코드를 감지하고 있으므로 여러 코드가 포함된 이미지에 대한 요청이 더 빠를 것입니다.

또한, 정확도 증가로 인해 많은 코드가 포함된 주어진 이미지에서 더 많은 코드가 감지됩니다.

게다가, 중복 탐지는 거의 없다.

경계 상자는 일부 코드, 특히 이전에 선이 반환된 ean13과 같은 선형 코드에 대해 개선되었다.

이제, 경계 상자는 보이는 전체 코드를 둘러싸고 있다.

마지막으로, ML 모델은 과거에 탐지 정확도를 방해한 곡선 표면, 반사 및 기타 아티팩트와 같은 것들을 더 잘 무시할 수 있다.

텍스트 인식과 바코드 감지를 위한 이 두 가지 새로운 개정판은 바코드와 텍스트를 스캔하고 반환하기 위해 카메라 스트림을 설정하는 드롭인 UI 요소인 VisionKit 데이터 스캐너 API의 기술적 토대를 형성합니다.

그것은 우리의 SDK에 정말 환상적인 추가이며, 더 많은 것을 배우기 위해 그것에 대한 세션을 확인하는 것이 좋습니다.

오늘 말씀드리는 마지막 새로운 개정판은 VNGenerateOpticalFlowRequestRevision2라는 광학 흐름 요청에 대한 새로운 개정판입니다.

바코드 탐지기와 마찬가지로, 이 새로운 개정판은 후드 아래에서 현대 기계 학습을 사용한다.

광학 흐름은 가장 오래 연구된 컴퓨터 비전 문제 중 하나이지만, 텍스트와 바코드와 같은 모든 일상 생활의 일부를 구성하는 것들을 감지하는 것에 비해 그것이 무엇을 하는지 알지 못할 수도 있습니다.

광학 흐름은 두 개의 연속적인 이미지, 일반적으로 비디오의 프레임을 분석한다.

사용 사례에 따라, 두 개의 인접한 프레임 사이의 움직임을 보거나 그 사이의 몇 프레임을 건너뛸 수 있지만, 어쨌든 두 이미지는 연대순이어야 합니다.

분석은 움직임의 방향과 크기, 또는 두 번째 이미지에서 올바르게 배치하기 위해 첫 번째 이미지의 얼마나 많은 부분이 "움직여야 하는지"에 대한 추정치를 제공한다.

VNPixelBufferObservation은 이미지의 모든 장소에서 이 움직임을 나타내는 결과이다.

그것은 두 채널 이미지이다.

한 채널은 X 등급을 포함하고, 다른 채널은 Y 등급을 포함한다.

함께, 이것들은 이 2D 이미지에 배열된 각 픽셀에서 2D 벡터를 형성하여 그들의 위치가 입력으로 제공된 이미지의 해당 위치에 매핑되도록 한다.

이것을 시각적으로 살펴봅시다.

들어오는 비디오가 있고 여러 프레임이 들어오고 있다고 가정하지만, 특히 이 두 이미지를 살펴봅시다.

여기 해변에서 달리는 개가 있어.

왼쪽 이미지에서 오른쪽 이미지로, 개가 왼쪽으로 조금 움직인 것 같다.

이 동의를 어떻게 추정하고 표현하시겠습니까?

음, 당신은 광학 흐름을 실행하고 아래 이미지와 비슷한 것에 도달할 것입니다.

더 어두운 지역은 움직임이 발견된 곳이며, 그것이 실제로 개의 모양처럼 보인다는 것을 알아차리세요.

그것은 오직 개만이 이 장면에서 정말로 움직이기 때문이다.

우리는 벡터의 x,y를 컬러 팔레트로 매핑하는 "거짓 색상"을 사용하여 이 이미지의 모션 벡터를 보여주고 있습니다.

이 잘못된 색상 표현에서, "빨간색" 색조는 주로 왼쪽으로의 움직임을 나타낸다.

이제 한 프레임에서 예시를 보았으니, 전체 비디오 클립이 어떻게 보이는지 봅시다.

여기서 우리는 해변에서 물병을 가져오는 이 강아지의 짧은 클립을 위한 광학 흐름을 계산합니다.

왼쪽은 개정판 1의 결과이다.

오른쪽은 우리의 새로운 ML 기반 개정판 2의 결과이다.

수정본 2의 개선 사항 중 일부가 분명해지기를 바랍니다.

우선, 아마도 가장 명백하게, 물병의 움직임은 훨씬 더 정확하게 포착된다.

당신은 또한 개의 예상 움직임 중 일부에서 개선을 느낄 수 있습니다.

나는 꼬리의 개선을 가장 분명하게 알아차렸지만 새로운 개정판에서 그의 귀가 펄럭이는 것을 볼 수 있다.

첫 번째 개정판에는 약간의 배경 소음 움직임도 포함되어 있으며, 두 번째 개정판은 배경이 움직이지 않는 것으로 더 일관성 있게 나타낸다.

그 예시가 당신에게 이 기술이 무엇을 하는지 좋은 아이디어를 주길 바랍니다.

이제 앱에서 어떻게 사용할 수 있는지에 대해 조금 알아봅시다.

분명히 주요 사용 사례는 비디오에서 로컬 모션을 발견하는 것이다.

이것은 배경에서 벗어난 움직임을 식별하고 현지화하는 것이 가장 중요한 보안 비디오 사용 사례에 직접 공급되며, 광학 흐름이 대부분의 보안 카메라와 같은 고정 카메라에 가장 잘 작동한다는 것을 언급해야 합니다.

Vision의 개체 추적기를 사용하여 비디오에서 움직이는 개체를 추적할 수 있지만, 추적기를 초기화할 위치를 알아야 합니다.

광학 흐름은 그곳에서도 당신을 도울 수 있습니다.

컴퓨터 비전이나 이미지 처리에 정통한 경우, 광학 흐름 결과를 활용하여 추가 비디오 처리를 가능하게 할 수 있습니다.

비디오 보간 또는 비디오 액션 분석은 광학 흐름이 제공하는 정보로부터 큰 이익을 얻을 수 있다.

이제 개정판 1과 개정판 2 사이의 몇 가지 중요한 추가 차이점을 살펴봅시다.

개정 1은 항상 입력과 동일한 해상도를 가진 광학 흐름 필드를 반환합니다.

개정판 2도 기본적으로 이것을 할 것이다.

그러나, 작은 주름이 있다: 부분적으로 개정판 2가 ML 기반이라는 사실 때문에, 기본 모델의 출력은 대부분의 입력 이미지 해상도에 비해 상대적으로 낮은 해상도이다.

따라서, 개정 1의 기본 동작과 일치하려면, 일부 업샘플링을 수행해야 하며, 우리는 이를 위해 이중선형 업샘플링을 사용하고 있습니다.

다음은 업샘플링이 무엇을 하는지 설명하는 시각적 예시입니다.

왼쪽에는 네트워크 출력의 확대된 부분이 있는데, 이는 해상도가 낮기 때문에 픽셀화된 것처럼 보입니다.

전체 흐름 필드는 종횡비가 7:5일 수 있다.

오른쪽에는 원본 이미지 해상도로 업샘플링된 같은 필드에서 가져온 유사한 영역이 있습니다.

아마도 그 이미지도 다른 종횡비를 가지고 있을 것이다, 16:9라고 가정해 봅시다.

당신은 흐름 필드의 가장자리가 이중 선형 업샘플링에 의해 매끄러워진다는 것을 알게 될 것입니다.

종횡비가 다를 가능성이 있기 때문에, 업샘플링 과정의 일환으로, 흐름 필드를 이미지에서 일어나는 일에 적절하게 대응하기 위해 흐름 이미지가 늘어날 것이라는 점을 명심하십시오.

네트워크 출력으로 직접 작업할 때, 흐름 결과를 원본 이미지에 매핑할 때 비슷한 방식으로 해상도와 종횡비를 고려해야 합니다.

요청에 대해 keepNetworkOutput을 켜서 업샘플링을 건너뛸 수 있는 옵션이 있습니다.

이것은 당신에게 원시 모델 출력을 제공할 것입니다.

사용 가능한 출력 해상도를 선택하기 위해 요청에 적용할 수 있는 네 가지 계산 정확도 설정이 있습니다.

이 표에서 각 정확도 설정에 대한 해상도를 볼 수 있지만, 항상 관찰에 포함된 픽셀 버퍼의 너비와 높이를 확인하십시오.

언제 네트워크 출력을 사용해야 하며, 언제 Vision을 업샘플링하도록 허용해야 하나요?

기본 동작은 이미 광학 흐름을 사용하고 있고 동작이 이전 버전과 호환되기를 원한다면 가장 좋습니다.

업샘플링된 출력을 원한다면 좋은 옵션이며, 이중선은 받아들일 수 있으며 추가 메모리와 대기 시간의 가치가 있습니다.

전체 해상도가 필요하지 않고 즉석에서 서신을 형성하거나 추적기를 초기화하고 싶은 경우 네트워크 출력이 가장 좋습니다.

전체 해상도 흐름이 필요한 경우 네트워크 출력이 올바른 선택일 수도 있지만, 자신만의 업샘플링 방법을 사용하는 것을 선호합니다.

그것은 이 세션의 새로운 알고리즘 개정을 다룹니다.

우리가 비전 프레임워크에서 하고 있는 봄 청소와 그것이 당신에게 어떤 영향을 미칠 수 있는지에 대해 논의해 봅시다.

우리는 비전이 5년 전에 처음 출시되었을 때 각 알고리즘에 대한 "개정 1"으로 얼굴 감지와 얼굴 랜드마크를 처음 도입했습니다.

그 이후로 우리는 더 효율적이고 정확한 기술을 사용하는 두 가지 새로운 개정판을 출시했습니다.

따라서, 우리는 비전 프레임워크에서 이러한 알고리즘의 첫 번째 개정판을 제거하고 있으며, 두 번째와 세 번째 개정판만 유지하고 있습니다.

하지만, 개정판 1을 사용한다면, 절대 두려워하지 마세요.

우리는 개정판 1을 지정하는 코드 또는 개정판 1만 포함된 SDK에 대해 컴파일된 코드를 계속 지원할 것입니다.

그게 어떻게 가능해, 물어볼 수 있어?

개정판 1은 이 다이어그램에서 내가 "수정 1 검출기"라고 부른 후드 아래에서 알고리즘을 실행한다.

같은 방식으로, 개정판 2는 개정판 2 탐지기를 사용한다.

우리가 이번 비전 출시를 위해 한 일은 개정 2 검출기의 출력으로 개정 1 요청을 만족시키는 것이다.

게다가, 개정 1 요청은 더 이상 사용되지 않는 것으로 표시될 것이다.

이를 통해 이전 개정판 1 검출기를 완전히 제거하여 비전 프레임워크를 간소화할 수 있습니다.

여기에는 몇 가지 이점이 있으며, 그 중 가장 중요한 것은 디스크의 공간을 절약하여 OS 릴리스와 SDK를 다운로드하고 설치하는 데 비용이 적게 드는 것입니다.

모든 비전 전문가들은 스스로에게 "하지만 잠시만요, "수정 2는 거꾸로 돌아가고 1은 그렇지 않습니다.

이 행동 차이가 일부 앱에 영향을 미칠 수 없었나요?"

우리가 개정 1 행동을 보존하기 위해 예방 조치를 취할 것이라는 점을 제외하면, 그것은 확실히 그럴 것이다.

우리는 개정판 2 탐지기에서 거꾸로 된 얼굴을 반환하지 않을 것이다.

마찬가지로, 개정 2 랜드마크 탐지기는 개정 1 랜드마크 별자리와 일치하는 결과를 반환할 것이다.

실행 시간은 동등하며, 당신은 정확성 향상을 경험해야 합니다.

어쨌든, 이 변경은 어떤 앱도 코드를 수정할 필요가 없으며, 계속 작동할 것이다.

여전히, 우리는 당신을 위한 행동 촉구가 있습니다.

훨씬 더 나은 옵션을 사용할 수 있을 때 개정판 1을 사용하는 것에 만족해서는 안 됩니다.

우리는 항상 최신 개정판을 사용하는 것을 권장하며, 이러한 요청에 대해서는 개정판 3이 될 것입니다.

물론 이 권장 사항의 주된 이유는 최고 수준의 정확성과 성능을 제공하는 최신 기술을 사용하는 것이며, 누가 그것을 원하지 않습니까?

게다가, 우리는 여러 번 설립하고 소통했으며, 기본 행동에 의존하기보다는 항상 수정 사항을 명시적으로 지정하는 모범 사례입니다.

그리고 그게 우리가 봄 대청소를 위해 한 일이야.

이제 비전 프레임워크를 사용하는 앱을 어떻게 더 쉽게 디버깅할 수 있었는지에 대해 이야기해 봅시다.

우리는 비전에 퀵 룩 프리뷰 지원을 추가했습니다.

이것은 특히 비전에 어떤 의미인가요?

음, 이제 디버거에서 VNObservations 위에 마우스를 올려놓을 수 있으며, 한 번의 클릭으로 입력 이미지에서 결과를 시각화할 수 있습니다.

우리는 또한 이것을 Xcode Playgrounds에서 사용할 수 있게 했다.

이것이 당신의 디버깅에 어떻게 도움이 될 수 있는지 설명할 수 있는 유일한 방법은 당신에게 보여주는 것이라고 생각합니다.

Xcode 데모로 넘어갑시다.

여기에는 얼굴 랜드마크를 감지하고 얼굴 관찰을 반환하는 간단한 루틴이 있습니다.

먼저, 우리는 얼굴 랜드마크 요청을 설정했다.

그런 다음, 우리 수업에 갈 준비가 된 이미지가 있다면, 우리는 그것을 전시한다.

그런 다음, 우리는 결과를 유지하기 위해 배열을 선언합니다.

오토릴리스풀 내부에서, 우리는 그 이미지로 요청 핸들러를 인스턴스화한 다음, 요청을 수행합니다.

모든 것이 잘 진행되었다고 가정하면, 우리는 요청에서 결과를 검색할 수 있다.

우리가 결과를 검색한 후에 나는 그것을 실행하고 중단점에 도착할 것이다.

그래서 나는 지금 디버거에 있어.

결과 위에 마우스를 올려놓으면, 오버레이는 내가 세 개의 얼굴을 감지했다는 것을 보여준다.

그거 좋네. 내 입력 이미지에는 세 개의 얼굴이 있다.

하지만 어떤 관찰이 어떤 얼굴인지 어떻게 알 수 있나요?

그것이 퀵 룩 프리뷰 지원이 들어오는 곳이다.

이 요청에 들어갈 때, 결과를 시각화하기 위해 각 "눈" 아이콘을 클릭할 수 있습니다.

이미지는 랜드마크 별자리와 얼굴 경계 상자를 위해 그려진 오버레이와 함께 나타납니다.

이제 당신은 이미지에서 첫 번째 관찰이 어디에 있는지 알고 있습니다.

나는 두 번째 관찰과 세 번째 관찰을 위한 오버레이를 그리기 위해 다음 것을 클릭할 수 있다.

다음 중단점으로 계속하여, 우리는 얼굴 관찰을 디버그 콘솔에 인쇄하는 코드를 실행합니다.

상상할 수 있듯이, 얼굴 정보가 인쇄된 디버그 콘솔에서, 어떤 얼굴이 어떤 얼굴인지 또는 이 인쇄된 좌표에서 결과가 올바르게 보이는지 즉시 시각화하는 것은 꽤 어렵습니다.

하지만 여기서 지적해야 할 것이 하나 더 있다.

자동 릴리스 풀을 도입하여 요청 핸들러를 다소 인위적으로 범위를 벗어냈다는 것을 주목하세요.

이제 요청 핸들러가 범위를 벗어났으니, 결과에 대한 퀵 룩 미리보기 지원을 다시 사용합시다.

음, 당신이 알고 있는 것은, 오버레이는 여전히 그려져 있지만, 이미지는 사용할 수 없습니다.

이것은 명심해야 할 사항입니다: 관찰을 생성하는 데 사용된 이미지 요청 핸들러는 퀵 룩 미리보기 지원이 원본 이미지를 표시하기 위해 여전히 어딘가에 있어야 합니다.

그것은 이미지 요청 핸들러가 입력 이미지가 있는 곳이기 때문입니다.

상황은 계속 작동할 것이지만, 이미지는 사용할 수 없을 것이다.

이 퀵 룩 미리보기 지원은 Xcode Playgrounds 세션에서 특히 유용할 수 있으며, 어떻게 작동하는지 확인하기 위해 빠른 실험을 할 수 있습니다.

지금 그걸 한 번 보자.

여기에 바코드 이미지를 분석하기 위한 간단한 놀이터가 있습니다.

이 코드를 살펴보는 대신, 몇 가지 수정을 하고 그것이 결과에 어떤 영향을 미치는지 확인해 봅시다.

우리는 서로 다른 기호의 두 개의 바코드가 있는 이미지에 개정판 2를 사용하는 것으로 시작할 것입니다.

모든 결과를 요청하면 한 번에 모든 결과가 표시되며, 첫 번째 결과도 마지막에 표시됩니다.

개정판 2에는 몇 가지 문제가 있다는 것을 주목하세요.

먼저, 그것은 첫 번째 바코드를 놓쳤다.

또한, 그것은 두 번째 바코드를 두 번 감지했다.

그리고 그것은 당신에게 완전한 경계 상자가 아닌 바코드를 통해 한 줄을 제공합니다.

지금 개정판 2 대신 개정판 3으로 변경하면 어떻게 되나요?

우선, 우리는 두 바코드를 모두 감지합니다.

그리고, 한 줄 대신에, 우리는 완전한 경계 상자를 받았다.

이 퀵 룩 프리뷰 지원의 좋은 점은 결과를 시각화하기 위해 다양한 유틸리티 기능을 작성할 필요성을 제거했다는 것입니다.

그것들은 디버거나 Xcode 플레이그라운드에서 이미지에 직접 오버레이될 수 있습니다.

그래서 그것은 Vision의 Quick Look Preview 지원입니다.

이제 당신은 어떤 관찰이 무엇인지 더 쉽게 알 수 있습니다.

입력 이미지와 함께 사용하기 위해 이미지 요청 핸들러를 범위에 유지해야 하며, Xcode Playground 지원으로 Vision 프레임워크 코드의 라이브 튜닝이 훨씬 쉬워지기를 바랍니다.

우리는 오늘 비전에 대한 몇 가지 중요한 업데이트를 다루었습니다.

빠르게 검토하기 위해, 우리는 텍스트 인식, 바코드 감지 및 광학 흐름에 몇 가지 훌륭한 새로운 개정판을 추가했습니다.

업데이트된 개정판을 계속 추가함에 따라, 오래된 개정판도 제거할 것이므로, 개정판을 최신 상태로 유지하고 최신의 최고의 기술을 사용하십시오.

우리는 또한 올해 퀵 룩 프리뷰 지원으로 비전 애플리케이션 디버깅을 훨씬 쉽게 만들었습니다.

나는 네가 이 세션을 즐겼기를 바라, 그리고 멋진 WWDC를 보내길 바라. ♪ ♪