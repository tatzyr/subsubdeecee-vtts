10020

♪インストゥルメンタルヒップホップ音楽♪

♪

こんにちは、私の名前はDavid Findlayで、Create MLチームのエンジニアです。

このセッションでは、独自の機械学習タスクを構築するための強力な新しい方法であるCreate ML Componentsについてです。

同僚のアレハンドロは、「Create ML Componentsを知ろう」というセッションで紹介しました。

彼は、Create MLタスクをコンポーネントに分解し、カスタムモデルを構築するのがいかに簡単かを明らかにしました。

トランスフォーマーとエスティメータは、画像回帰などのカスタムモデルを構築するために一緒に構成できる主な構成要素です。

このセッションでは、基本をはるかに超えて、Create ML Componentsで何が可能かを実証したいと思います。

議題を確認しましょう。カバーすべきことがたくさんあります。

まず、ビデオデータについて話し、時間の経過とともに値を処理するように設計された新しいコンポーネントについて詳しく説明します。

次に、これらの概念を機能させ、変圧器のみを使用して人間の行動の繰り返しカウンターを構築します。

最後に、カスタムサウンド分類モデルのトレーニングに進みます。

バッチでモデルを更新し、トレーニングを早期に停止し、モデルをチェックポイントできる増分フィッティングについて説明します。

このレベルの柔軟性には非常に多くの機会があります。

飛び込むのが待ちきれません。

始めましょう。

WWDC 2020では、Create MLでアクション分類を導入しました。これにより、ビデオからアクションを分類できます。

そして、ジャンピングジャック、ランジ、スクワットなどの人のトレーニングルーチンを認識するためのフィットネス分類器を作成する方法を実証しました。

たとえば、アクション分類器を使用して、このビデオのアクションをジャンピングジャックとして認識できます。

しかし、ジャンピングジャックを数えたい場合はどうなりますか?

最初に考慮する必要があるのは、ジャンピングジャックが連続したフレームにまたがることであり、時間の経過とともに値を処理する方法が必要になります。

ありがたいことに、SwiftのAsyncSequenceはこれを本当に簡単にします。

非同期シーケンスに慣れていない場合は、セッション「Meet AsyncSequence」をチェックする必要があります。

Create ML Componentsを使用すると、ビデオリーダーを使用して、ビデオをフレームの非同期シーケンスとして読み取ることができます。

また、AsyncSequenceは、ビデオから受信したフレームを反復する方法を提供します。

たとえば、マップメソッドを使用して、各ビデオフレームを非同期に簡単に変換できます。

これは、フレームを1つずつ処理したい場合に便利です。

しかし、一度に複数のフレームを処理したい場合はどうなりますか?

そこで時間的変圧器の出番です。

たとえば、ビデオのアクションを高速化するためにフレームをダウンサンプリングしたい場合があります。

非同期シーケンスを取り、ダウンサンプリングされた非同期シーケンスを返すものに対してダウンサンプラーを使用できます。

または、アクションの繰り返しを数えるために重要なウィンドウにフレームをグループ化することもできます。

そこでスライディングウィンドウトランスを使用できます。

ウィンドウの長さを指定できます。これは、ウィンドウでグループ化するフレーム数であり、ストライドはスライディング間隔を制御する方法です。

入力は、再び、非同期シーケンスであり、この場合の出力はウィンドウ化された非同期シーケンスです。

一般的に言えば、時間トランスフォーマーは、非同期シーケンスを新しい非同期シーケンスに処理する方法を提供します。

では、これらの概念を機能させましょう。

あなたのことは知りませんが、運動しているとき、私はいつも担当者の数を失います。

だから私は物事を少し揺るがして、Create ML Componentsでアクション繰り返しカウンターを構築することにしました。

この例では、変圧器と時間変圧器を一緒に構成する方法について説明します。

ポーズ抽出から始めましょう。

人体のポーズ抽出器を使ってポーズを抽出できます。

入力は画像であり、出力は人体のポーズの配列です。

舞台裏では、ビジョンフレームワークを活用してポーズを抽出します。

画像には複数の人を含めることができることに注意してください。これはグループワークアウトで一般的です。

そのため、出力はポーズの配列です。

しかし、私は一度に1人のアクションの繰り返しを数えることにしか興味がありません。

だから私はポーズセレクターで人体のポーズ抽出器を構成します。

ポーズセレクターは、一連のポーズと選択戦略を取り、単一のポーズを返します。

選択できる選択戦略はいくつかありますが、この例では、rightMostJointLocation戦略を使用します。

次のステップは、ポーズをウィンドウにグループ化することです。

そのためにスライディングウィンドウトランスを追加します。

そして、私は90のポーズの重複しないウィンドウを生成する90のウィンドウの長さとストライドを使用します。

スライディングウィンドウトランスフォーマーは一時的であり、タスク全体が一時的になり、期待される入力はフレームの非同期シーケンスになったことを思い出してください。

最後に、人体アクションカウンターを追加します。

この時間的トランスフォーマーは、ウィンドウ化されたポーズの非同期シーケンスを消費し、これまでのアクションの繰り返しの累積カウントを返します。

今では、カウントが浮動小数点数であることに気づいたかもしれません。

それは、タスクが部分的なアクションもカウントされるからです。

それはとても簡単です。

今、私は私のトレーニングビデオで私の担当者を数え、私が浮気していないことを確認することができます。

しかし、現在のトレーニングを追跡できるように、アプリで繰り返しをライブで数えるのがさらに良いでしょう。

あなたがそれをする方法をお見せしましょう。

まず、カメラ構成を取り、カメラフレームの非同期シーケンスを返すreadCameraメソッドを使用します。

次に、より頻繁に更新されたカウントを取得できるように、ストライドパラメータを15フレームに調整します。

私のカメラが毎秒30フレームの速度でフレームをキャプチャすると、半秒ごとにカウントされます。

今、私はトレーニングすることができ、担当者を逃すことを心配する必要はありません。

これまでのところ、私は非同期シーケンスを変換するための時間的コンポーネントを調査しました。

次に、時間データに依存するカスタムモデルのトレーニングに焦点を当てたいと思います。

2019年には、Create MLでサウンド分類器をトレーニングする方法を実演しました。

そして2021年には、健全な分類の強化を導入しました。

私はさらに進んで、カスタムサウンド分類器を段階的に訓練したい。

Create MLフレームワークのMLSoundClassifierは、カスタムサウンド分類器モデルをトレーニングする最も簡単な方法です。

しかし、より多くのカスタマイズ性と制御が必要な場合は、ボンネットの下のコンポーネントを使用できます。

最も単純な形式では、サウンド分類器には、オーディオ機能印刷機能抽出器と選択した分類器の2つのコンポーネントがあります。

AudioFeaturePrintは、オーディオバッファの非同期シーケンスからオーディオ機能を抽出する一時的なトランスフォーマーです。

スライディングウィンドウトランスフォーマーと同様に、AudioFeaturePrintは非同期シーケンスをウィンドウし、機能を抽出します。

選択できる分類器はいくつかありますが、この例では、ロジスティック回帰分類器を使用して、機能抽出器と一緒に構成して、カスタムサウンド分類器を構築します。

次のステップは、カスタムサウンド分類器をラベル付けされたトレーニングデータに合わせることです。

トレーニングデータの収集の詳細については、「MLコンポーネントの作成を知る」セッションは始めるのに良い場所です。

これまでのところ、私は幸せな道をカバーしてきました。

しかし、機械学習モデルの構築は反復的なプロセスになる可能性があります。

たとえば、時間の経過とともに新しいトレーニングデータを発見して収集し、モデルを更新したいと思うかもしれません。

モデルの品質を向上させることができる可能性があります。 

しかし、モデルをゼロから再訓練するのは時間がかかります。

これは、以前のすべてのデータに対して機能抽出をやり直す必要があるためです。

新しく発見されたデータでモデルをトレーニングするときに時間を節約する方法の例を挙げましょう。

重要なのは、モデルに適合させることとは別に、トレーニングデータを前処理することです。

この例では、分類器のフィッティングとは別にオーディオ機能を抽出できます。

そして、これは一般的にも機能します。

一連の変圧器に続いて見積もりがあるときはいつでも、見積もりにつながる変圧器を介して入力を前処理できます。

あなたがする必要があるのは、前処理メソッドを呼び出して、前処理された機能にモデルを合わせることだけです。

サウンド分類器の構成を変更する必要がなかったので、これは便利だと思います。

機能を別々に抽出したので、新しいデータのオーディオ機能のみを抽出する柔軟性があります。

モデルの新しいトレーニングデータを発見すると、このデータを別々に簡単に前処理できます。

そして、以前に抽出されたものに補足機能を追加します。

これは、前処理が時間を節約できる最初の例にすぎません。

モデル構築のライフサイクルに戻りましょう。

モデルの品質に満足するまで、見積もりパラメータを調整する必要があるかもしれません。 

フィーチャ抽出をフィッティングから分離することで、フィーチャを一度だけ抽出し、異なる推定パラメータでモデルに合わせることができます。

特徴抽出をやり直さずに分類器パラメータを変更する例を見てみましょう。

すでに機能を抽出したと仮定して、分類器のL2ペナルティパラメータを変更します。

そして、新しい分類器を古い機能抽出器に追加する必要があります。

見積もりをチューニングするときに機能抽出器を変更しないことが重要です。これは、以前に抽出された機能を無効にするからです。

バッチでモデルを段階的にフィッティングすることに移りましょう。

機械学習モデルは、一般的に大量のトレーニングデータの恩恵を受けます。

ただし、アプリのメモリ制約が限られている可能性があります。

それで、あなたは何をしますか?

Create ML Componentsを使用して、一度にデータのバッチのみをメモリにロードすることで、モデルをトレーニングできます。

最初にする必要があるのは、分類器を更新可能な分類器に置き換えることです。

バッチでカスタムモデルをトレーニングするには、分類器が更新可能である必要があります。

たとえば、完全に接続されたニューラルネットワーク分類器は、更新不可能なロジスティック回帰分類器の代わりに簡単に使用できます。

さて、今からトレーニングループを書きます。

デフォルトの初期化モデルを作成することから始めます。

あなたはまだ予測をすることはできません。これはトレーニングの出発点にすぎないからです。

その後、トレーニングが始まる前にオーディオ機能を抽出します。

すべての反復で機能を抽出したくないので、これは重要なステップです。

次のステップは、トレーニングループを定義し、トレーニングする反復回数を指定することです。

続ける前に、アルゴリズムのSwiftパッケージをインポートします。

トレーニングデータのバッチを作成するために必要です。

詳細については、WWDC 2021のセッション「Meet the Swift Algorithms and Collections packages」をチェックしてください。

トレーニングループ内では、バッチ処理が行われる場所です。

チャンクメソッドを使用して、機能をトレーニング用のバッチにグループ化します。

チャンクサイズは、一度にメモリにロードされる機能の数です。

その後、バッチを反復して更新メソッドを呼び出すことで、モデルを更新できます。

モデルを段階的にトレーニングすると、さらにいくつかのトレーニングテクニックのロックを解除できます。

たとえば、このトレーニンググラフでは、約10回の反復の後、モデルの精度は95%で推移します。

この時点で、モデルは収束しており、早期に停止することができます。

トレーニングループで早期停止を実施しましょう。

最初にすべきことは、検証セットの予測をすることです。

検証予測とその注釈をペアリングする必要があるため、ここではmapFeaturesメソッドを使用しています。

次のステップは、モデルの品質を測定することです。

今のところ、組み込みのメトリクスを使用しますが、独自のカスタムメトリクスを実装するのを妨げるものは何もありません。

そして最後に、私のモデルが95%の精度に達したら、トレーニングを中止します。

トレーニングループ以外では、後で予測に使用できるように、モデルをディスクに書き出します。

早めに停止することに加えて、モデルのチェックポイントについて話したいと思います。

最後まで待つのではなく、トレーニング中にモデルの進捗状況を保存できます。

また、トレーニングを再開するためにチェックポイントを使用することもできます。これは、特にモデルのトレーニングに長い時間がかかる場合に便利です。

あなたがする必要があるのは、トレーニングループにモデルを書き出すことだけです。

チェックポイント間隔を定義して、数回の反復ごとにこれを行うことをお勧めします。

それはとても簡単です。

このセッションでは、オーディオやビデオなどの時間的データを使用して機械学習タスクを構築する新しい方法である時間的コンポーネントを紹介しました。

私は人間の行動の繰り返しカウンターを作るために一緒に時間的コンポーネントを構成しました。

そして最後に、私はインクリメンタルフィッティングについて話しました。

これにより、アプリに機械学習を組み込む新しい可能性が解き放ちます。

参加してくれてありがとう、WWDCの残りの部分を楽しんでください。

♪