10128

♪まろやかなインストゥルメンタルヒップホップ音楽♪

♪

ハオ・タン:こんにちは、私の名前はハオです。

私はオブジェクトキャプチャチームのエンジニアです。

今日、同僚のRisaと私は、Object Capture APIとRealityKitを使用して、現実世界のオブジェクトの3Dモデルを作成し、それらをARに取り込む方法を紹介します。

始めましょう。

まず、昨年macOSでRealityKit APIとして立ち上げたObject Captureの要約をお伝えします。

次に、ARKitのカメラ機能強化をいくつか紹介します。これにより、オブジェクトの高解像度写真をキャプチャでき、オブジェクトキャプチャをARアプリケーションによりよく統合するのに役立ちます。

その後、オブジェクトキャプチャのベストプラクティスガイドラインに目を通し、この技術を最大限に活用し続けることができます。

最後のセクションでは、RisaがRealityKitのオブジェクトキャプチャを使用したエンドツーエンドのワークフローを案内し、現実世界のオブジェクトをAR体験に持ち込む方法を実演します。

オブジェクトキャプチャの簡単な要約から始めましょう。

オブジェクトキャプチャは、現実世界のオブジェクトの画像を詳細な3Dモデルに簡単に回転させることができるコンピュータビジョン技術です。

iPhone、iPad、またはデジタル一眼レフでさまざまな角度からオブジェクトの写真を撮ることから始めます。

次に、それらの写真をオブジェクトキャプチャをサポートするMacにコピーします。

Photogrammetry APIを使用すると、RealityKitはわずか数分で写真を3Dモデルに変換できます。

出力モデルには、幾何学的なメッシュと、モデルに自動的に適用されるテクスチャを含むさまざまなマテリアルマップの両方が含まれています。

オブジェクトキャプチャAPIの詳細については、オブジェクトキャプチャに関する昨年のWWDCセッションを見ることを強くお勧めします。

多くの開発者は、Unity、Cinema4D、Qlone、PolyCam、PhotoCatchなど、オブジェクトキャプチャを使用して素晴らしい3Dキャプチャアプリを作成しました。

これに加えて、このAPIを使用して作成された美しい外観のモデルがあります。

これは、PhotoCatchアプリ内のオブジェクトキャプチャのパワーを使用してEthan Saadiaによって作成されたいくつかのモデルです。

そして、Shopifyの友人Mikko Haapojaも、このAPIを使用して見栄えの良い3Dモデルの束を生成しました。

オブジェクトキャプチャで得られる出力3Dモデルの詳細な品質は、電子商取引において非常に有益です。

たとえば、足にさまざまな靴を試着できるGOATアプリがあります。

これらの靴のモデルはすべて、最高級の詳細をキャプチャするように設計されたオブジェクトキャプチャAPIで作成されています。

これは、製品の購入決定を支援したり、スペース内のオブジェクトに正確にフィットするように試してみたりするのに大いに役立ちます。

たとえば、Plant Storyアプリを使用すると、スペース内のさまざまな植物の実際の3Dモデルをプレビューできます。これらはすべてオブジェクトキャプチャで作成されています。

これは、植物に必要なスペースの感覚を得たり、単に現実的に詳細にあなたのスペースでそれらを見るのに役立ちます。

リアリズムについて言えば、このビデオで本物の植物を見つけることができましたか?

はい、それはテーブルの一番左隅にある白いプランターにあるものです。

2021年の発売以来、Object Capture APIがこのような驚くほど広く使用されているのを見て、私たちは非常に興奮しています。

さて、オブジェクトキャプチャによる再構築の品質に大きく役立つARKitのカメラ機能強化について話しましょう。

優れたオブジェクトキャプチャ体験は、あらゆる側面からオブジェクトの良い写真を撮ることから始まります。

この目的のために、iPhoneやiPadなどの高解像度カメラ、さらにはデジタル一眼レフカメラやミラーレスカメラを使用できます。

iPhoneまたはiPadでカメラアプリを使用すると、深度と重力情報を含む高品質の写真を撮ることができ、Object Capture APIはオブジェクトの実際のスケールと向きを自動的に回復できます。

それに加えて、iPhoneまたはiPadを使用している場合は、ARKitの追跡機能を利用して、モデルの上に3DガイダンスUIをオーバーレイして、あらゆる側面からオブジェクトをうまくカバーすることができます。

注意すべきもう1つの重要な点は、キャプチャからの画像解像度が高いほど、オブジェクトキャプチャが生成できる3Dモデルの品質が向上するということです。

そのために、今年のARKitのリリースでは、まったく新しい高解像度の背景写真APIを導入します。

このAPIを使用すると、ARSessionを実行している間に、ネイティブカメラの解像度で写真をキャプチャできます。

デバイス上のカメラセンサーを最大限に活用しながら、オブジェクトの上に3D UIオーバーレイを使用できます。

iPhone 13では、それはワイドカメラの完全な12メガピクセルのネイティブ解像度を意味します。

このAPIは非侵入的です。

現在のARSessionの継続的なビデオストリームを中断しないため、アプリはユーザーにスムーズなAR体験を提供し続けます。

さらに、ARKitはEXIFメタデータを写真で使用できるようにします。これにより、アプリはホワイトバランス、露出、および後処理に価値のあるその他の設定に関する有用な情報を読むことができます。

ARKitを使用すると、この新しいAPIをアプリで非常に簡単に使用できます。

ARWorldTrackingConfgurationで高解像度フレームキャプチャをサポートするビデオフォーマットを照会するだけで、成功したら、新しいビデオフォーマットを設定してARSessionを実行できます。

高解像度写真のキャプチャに関しては、ARSessionの新しいcaptureHighResolutionFrame API関数を呼び出すだけで、非同期に完了ハンドラを介して高解像度の写真が返されます。

それはとても簡単です。

また、フォーカス、露出、ホワイトバランスなどのカメラ設定を手動で制御することを好むユースケースもあることも認識しています。

そのため、基礎となるAVCaptureDeviceに直接アクセスし、きめ細かなカメラ制御のためにそのプロパティを変更する便利な方法を提供しています。

このコード例に示すように、ARWorldTrackingConfigurationでconfigurableCaptureDevice ForPrimaryCameraを呼び出すだけで、基盤となるAVCaptureDeviceにアクセスできます。

これらの機能強化の詳細については、今年のWWDCの「Discover ARKit 6セッション」をチェックすることを強くお勧めします。

では、オブジェクトキャプチャに関するベストプラクティスのガイドラインをいくつか確認しましょう。

まず最初に、オブジェクトキャプチャに適切な特性を持つオブジェクトを選択する必要があります。

良い物体は、その表面に十分な質感を持っています。

オブジェクトの一部の領域がテクスチャレスまたは透明である場合、それらの領域の詳細はうまく再構築されない可能性があります。

良い物体はまた、まぶしさや反射がないはずです。

オブジェクトにマットな表面がない場合は、拡散照明を使用して鏡面を減らすことができます。

オブジェクトを裏返して底をキャプチャしたい場合は、オブジェクトが硬いままであることを確認してください。

言い換えれば、ひっくり返したときに形を変えるべきではありません。

そして最後に、良いオブジェクトはある程度細かい構造を含むことができますが、オブジェクトの細かい詳細を回復するには、高解像度カメラを使用してクローズアップ写真を撮る必要があります。

次に重要なことは、理想的なキャプチャ環境を設定することです。

キャプチャ環境に良好で均一で拡散した照明があることを確認する必要があります。

安定した背景を確保し、オブジェクトの周りに十分なスペースを確保することが重要です。

部屋が暗い場合は、明るいターンテーブルを利用できます。

次に、オブジェクトの良い写真をキャプチャするためのいくつかのガイドラインを見ていきます。これにより、オブジェクトキャプチャから良質の3Dモデルが確実に取得されます。

例として、同僚のマウネシュがiPhoneを使って、私たちの最愛のARKitエンジニア、クリスチャン・リプスキーによって作成された美しい海賊船の画像をキャプチャする方法を紹介します。

マウネシュは、海賊船を清潔なテーブルの真ん中に置くことから始めます。

これにより、船は写真ではっきりと目立ちます。

彼は両手でiPhoneを着実に握っている。

ゆっくりと船の周りを回っていると、さまざまな高さで写真を撮ります。

彼は、最大限の詳細をキャプチャできるように、船がカメラの視野の中央に十分な大きさであることを確認します。

彼はまた、隣接する2枚の写真の間に常に高い重なりを維持していることを確認しています。

彼がかなりの数の写真を撮った後(この場合は約80枚)、彼は船を横にひっくり返して、底を再構築することもできます。

彼は反転した向きで船のさらに約20枚の写真を撮り続けています。

注意すべきことの1つは、彼がiPhoneを横向きモードで保持していることです。

これは、彼が長いオブジェクトをキャプチャしているためであり、この場合、ランドスケープモードはオブジェクトの最大量の詳細をキャプチャするのに役立ちます。

しかし、代わりに背の高い物体をキャプチャする場合は、ポートレートモードでiPhoneを使用する必要があるかもしれません。

それでおそれ！

プロセスの最後のステップは、これらの写真をMacにコピーし、Object Capture APIを使用して処理することです。

さまざまなユースケースに最適化された4つの異なる詳細レベルから選択できます。

縮小および中程度の詳細レベルは、AR QuickLookで3Dコンテンツを表示するなど、Webベースおよびモバイルエクスペリエンスでの使用に最適化されています。

これらの詳細レベルの再構築されたモデルは、三角形や材料チャネルが少ないため、メモリの消費が少なくなります。

完全および生の詳細レベルは、コンピュータゲームやポストプロダクションワークフローなど、ハイエンドのインタラクティブなユースケースを対象としています。

これらのモデルには最高の幾何学的ディテールが含まれており、焼きたての材料と未焼いた材料のどちらかを選択する柔軟性を提供しますが、再構築するにはより多くのメモリが必要です。

ユースケースに応じて、適切な出力レベルを選択することが重要です。

海賊船では、M1 Macで処理するのに数分しかかからなかった中程度の詳細レベルを選択しました。

出力3Dモデルはとても見事に見えたので、実際に公海を航行する海賊船のアニメーションクリップをまとめました。

そして、それがあなたのためのオブジェクトキャプチャの力です!

アホイ！

今、私はそれをRisaに引き渡します。Risaは、RealityKitのObject Captureを使用してエンドツーエンドのワークフローを案内します。

米山理沙:ありがとう、ハオ。

オブジェクトキャプチャAPIを確認したので、RealityKitを使用して実際のオブジェクトをARに取り込むために、エンドツーエンドの開発者ワークフローを確認できることを嬉しく思います。

ワークフローの例で各ステップを詳細に説明しますので、デモに飛び込みましょう。

私の同僚のザックは時折木工職人であり、最近6つの特大の木製のチェスの駒を建てました - それぞれのユニークな駒に1つずつ。

これらのチェスの駒を見て、私はインタラクティブなARチェスゲームを作成することに触発されています。

以前は、現実世界のオブジェクトの高品質の3Dモデルを作成するには、3Dモデラーと材料の専門家が必要でした。

これで、Object Capture APIを使用すると、これらのチェスの駒を直接キャプチャし、拡張現実に持ち込むことができます。

ルークを捕獲することから始めましょう。

私の同僚のブライアンは、前のセクションで説明したベストプラクティスを念頭に置いて、このプロのセットアップを使用します。

この場合、ブライアンは、最終的な出力で厳しい影を避けるために、いくつかのプロの照明でこのターンテーブルにルークを置いています。

また、出力USDZで自動スケール推定と重力ベクトル情報を提供するターンテーブルでiPhoneカメラを使用することもできます。

詳細については、2021年からのオブジェクトキャプチャセッションを参照してください。

もちろん、ブライアンがここで行うような精巧なセットアップがない場合は、iOSデバイスを持ち、オブジェクトの周りを歩き回って画像をキャプチャすることもできます。

ルークピースのすべての写真がわかったので、これらをMacに転送します。

2021年に導入されたPhotogrammetrySession APIを使用して、これらの写真を処理します。

ベストプラクティスのガイドラインに従って、ARアプリがうまく機能することを確認したいので、縮小された詳細レベルを使用して再構築します。

APIの最終出力は、USDZファイルタイプモデルになります。

これが私が再構築したばかりのルークチェスの駒の最終出力です。

時間を節約するために、私は先に進み、他の5つの作品を事前にキャプチャしました。

チェスの駒の配色が1つしかないチェスゲームをどうやって作るのか疑問に思うかもしれません。

6つのユニークなピースを複製して、Reality Converterにドラッグしましょう。

元のテクスチャの色を反転し、重複したセットをこの新しい反転テクスチャに置き換えました。

このようにして、各プレイヤーに1つずつ、より軽いバージョンと暗いバージョンのチェスの駒を持つことができます。

エクスポートメニューで圧縮テクスチャオプションをオンにしてモデルをエクスポートします。

これは、テクスチャのメモリフットプリントを減らすのに役立ちます。

チェスの駒のフルセットができたので、モデルをXcodeプロジェクトに持ち込む準備が整いました。

Y軸のプリミティブキューブを縮小し、黒と白の色を交互にすることで、RealityKitを使用してチェス盤を作成しました。

ここに私が再建したすべてのチェスの駒がチェス盤にレイアウトされています。

これは、私たちのアプリケーションで実際のオブジェクトを見るのはすでにエキサイティングですが、実際のインタラクティブなゲームにするためにいくつかの機能を追加し始めましょう。

デモのこの部分を通して、いくつかの異なる既存の技術を紹介したいと思いますので、目的の出力を達成するために技術を組み合わせる方法の例を提供できます。

RealityKitの高度なトピックの実用的なユースケースをいくつか見上げるので、まだAPIに精通していない場合は、2021年からのRealityKitセッションをチェックすることをお勧めします。

最初にアプリケーションを起動するときに、スタートアップアニメーションを追加することから始めたいと思います。

チェスの駒も一緒に翻訳されている間、チェッカータイルが最終的な位置の少し上からゆっくりと所定の位置に落ちるアニメーションを想像しています。

この効果をコードに再現するには、2つのステップが必要です。

最初のステップは、両方のエンティティをy軸に沿って翻訳し、チェスの駒を均一に縮小することです。

2番目のステップと最後のステップは、両方のエンティティを元の変換に戻すことです。

これのコードは非常に簡単です。

チェッカータイルエンティティを反復することから始めます。

各エンティティについて、これが着地する最終的な位置になるため、チェッカータイルの現在の変換を保存します。

次に、各正方形をy軸で10cm上に移動します。

これで、移動機能を利用して、これを元の変換に戻すことができます。

また、チェッカーボードを概説するこのボーダーUSDZには、アニメーションが組み込まれていることも知っています。

playAnimation APIを使用して、アニメーションを同時に開始できます。

チェスの駒にまったく同じアニメーションを追加しましたが、翻訳されるにつれてスケールも変更しました。

そして、ここにそれがあります:ほんの数行のコードでシンプルなスタートアップアニメーション。

しかし、チェスの駒を動かす能力がなければ、実際にはチェスをすることはできません。

次はそれに取り組みましょう。

チェスの駒を動かし始める前に、1つを選択できるようにする必要があります。

私はすでにARViewにUITapGestureRecognizerを追加しました。

ユーザーが特定の場所をタップすると、カメラの原点から始まり、その2Dポイントを通過する光線を定義します。

その後、そのレイで3Dシーンにレイキャストを実行して、エンティティにヒットしたかどうかを確認できます。

私は自分のシーンでチェスの駒を選択できるようにしたいだけなので、チェスの駒の衝突グループをマスクとして指定しました。

レイキャスト関数は、CollisionComponentを持っていないすべてのエンティティを無視することに注意してください。

チェスの駒を見つけたら、最終的にそれを選ぶことができます。

どの作品が選択されているかがわかったので、作品が光っているように見せる効果を追加したい。

これを達成するためにカスタム材料を活用することができます。より具体的には、表面シェーダーです。

サーフェスシェーダーを使用すると、Metalを介して材料パラメータを計算または指定することができ、その後、各ピクセルごとに1回、RealityKitのフラグメントシェーダーによって呼び出されます。

メタルでこの火災効果のように見える表面シェーダーを書くことができます。

次に、カスタム素材を適用し、このサーフェスシェーダーを長方形のプリズムに適用し、シェーダーがエンティティの外観に影響を与えます。

望ましい効果を達成するために、いくつかのコードを書きましょう。

このサーフェスシェーダーで使用するノイズテクスチャをプロジェクトに追加しました。

テクスチャを2回サンプリングします。1回は効果の全体的な形状で、もう1回は詳細です。

次に、RGB値を取り、私たちが望むように見えるように再マップします。

次に、抽出したばかりの処理値を使用して、y位置と画像値を比較して、サンプルポイントの不透明度を計算します。

効果にいくらかの動きを与えるために、私たちは時間の関数としてテクスチャのy軸を通って移動します。

さらに、各サンプルポイントの面角をカメラの表示方向と組み合わせて使用して、側面の効果をフェードします。

これにより、エッジが柔らかくなり、基礎となるモデルの規則的な性質が隠されます。

最後に、サーフェスパラメータ関数を使用して計算した色と不透明度を設定します。

そして、ここに選択シェーダーが適用されたチェスの駒があります。

彼らは本当に内側から輝いているように見えます。

さて、それを3つの別々の翻訳アニメーションと組み合わせると、このようなものになります。

チェスの駒を動かす機能が実装されているため、相手の駒をキャプチャすることもできます。

サーフェスシェーダーと同様に、ジオメトリ修飾子はカスタムマテリアルを使用して実装できます。

位置、法線、テクスチャ座標などの頂点データを変更できるため、非常に強力なツールです。

これらのメタル関数のそれぞれは、RealityKitの頂点シェーダーによって頂点ごとに1回呼び出されます。

これらの変更は純粋に一時的なものであり、実際のエンティティの頂点情報には影響しません。

キャプチャされたときにピースをつぶすために、楽しいジオメトリ修飾子を追加できると思います。

私は0から1までのキャプチャアニメーションの進行状況を表すために、 capturedProgressと呼ばれる私のチェスの駒にこのプロパティを持っています。

キャプチャはユーザーが開始したアクションであるため、どういうわけかジオメトリ修飾子にアニメーションを開始するタイミングを伝える必要があります。

良いことは、customMaterialにカスタムプロパティを設定することでこれを行うことができることです。

これにより、CPUとGPUの間でデータを共有できます。

ここでは特にカスタム値プロパティを使用し、アニメーションの進行状況をジオメトリ修飾子に渡します。

メタル側からアニメーションの進行状況を抽出するには、ユニフォームのカスタムパラメータを使用できます。

別のピースに押しつぶされているかのように、オブジェクトを垂直にスケーリングしたいので、スケール軸をy方向として設定します。

アニメーションに複雑さを加えるために、x軸のジオメトリを変更して波効果を作成します。

頂点のオフセットは、set_model_position_ offset関数を使用して設定できます。

これが私たちのジオメトリ修飾子の最終製品です。

X軸に沿って垂直に引き伸ばされながら、崩壊する前に少しスケールアップすることがわかります。

チェスの初心者として、私がゲームを学ぶのを助けるために、選択したピースがどこに移動できるかを示す機能を追加すると役立つかもしれないと思いました。

チェッカーピースは、独自のモデルコンポーネントを持つ個々のエンティティであるため、サーフェスシェーダーを使用して潜在的な動きにパルス効果を適用して、他の要素と区別することができます。

次に、「ブルーム」と呼ばれる後処理効果を追加して、効果をさらに強調します。

繰り返しになりますが、グロー効果のためにサーフェスシェーダーで使用したカスタムパラメータを使用しています。

この場合、CPU側からメタルサーフェスシェーダーにブール値を渡しています。

このチェッカーが可能な動きであれば、色を変更して脈動効果を加えたいです。

ここでは、特に発光色にパルスを追加します。

最後に、ビュー全体にブルーム効果を追加します。

ブルームは、明るい領域の境界から光の羽を生成する後処理効果です。

ARViewのrender callbacksプロパティを活用することで、この効果を実現できます。

すでに内蔵されているメタルパフォーマンスシェーダー機能を使用して、ブルーム効果を書きます。

次に、先ほど定義したブルーム関数としてrenderCallbacks.postProcessクロージャを設定するだけです。

チェッカーを脈打つと、白い色に脈動し、ブルーム効果でさらに強調されます。

表面シェーダーとブルーム効果を合わせると、ピースをどこに移動できるかを正確に見ることができます。

最後に、私たちが持っているすべてのものを組み合わせて、ARアプリで現実のチェスの駒が生き生きとしているのを見てみましょう。

私たちは、私たちが追加したすべての機能が私たちの環境でどのように見えるかを見ることができます。

あなたの便宜のために、キャプチャチェスのサンプルプロジェクトをセッションリソースにリンクしました。

ダウンロードして、自分の環境で見るために自分で試してみてください。

そして、それは簡単です。

キャプチャから特大のチェスの駒の再構築まで、そして私たちの拡張現実アプリに。

今日のこのセッションでは多くのことを取り上げたので、いくつかの重要なポイントをまとめましょう。

私たちはまず、2021年に発表したオブジェクトキャプチャAPIを要約することから始めました。

その後、アクティブなARSession中にネイティブカメラ解像度でオンデマンドで写真をキャプチャできるARKitの新しいAPIを調べました。

オブジェクトキャプチャ技術を最大限に活用するために、再構築に適したオブジェクトの種類、高品質の画像を取得するための理想的な環境、およびオブジェクトのキャプチャ中に従うべき推奨フローをリストアップしました。

このセッションの後半では、エンドツーエンドの開発者ワークフローの例を見てきました。

特大のチェスの駒の写真をキャプチャし、PhotogrammetrySession APIへの入力として画像を使用して3Dモデルを作成しました。

次に、いくつかのテクスチャを置き換えるために、モデルをReality Converterにインポートしました。

そして最後に、私たちはゆっくりとチェスゲームを構築し、ARでチェスの駒が動作しているのを見ました。

そして、今日のセッションはそれだけです。

ご覧いただき、誠にありがとうございます。

アホイ！

♪