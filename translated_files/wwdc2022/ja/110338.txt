110338

♪ ♪

こんにちは、私の名前はニックで、ビデオチームのエンジニアです。

今日は、メディアメタデータの公開と再生のインタラクションについてお話しできることを嬉しく思います。

それで、それは正確にはどういう意味ですか?

Appleデバイスには、再生情報が表示され、再生を制御できる場所がいくつかあります。

たとえば、コントロールセンターの「再生中」セクションには、デバイスで現在再生中のメディアのアートワーク、タイトル、進行状況が表示されます。

また、再生したり、一時停止したり、前方または後方にスキップすることもできます。

再生中タイルを展開すると、アートワークや進捗状況など、詳細が表示されます。

また、スクラブしたり、ボリュームを増減したりすることもできます。

ロック画面には同じ情報とコントロールも表示され、ロックを解除することなく、進捗状況、一時停止、または別のデバイスへのAirPlayをチェックするのに便利な場所をユーザーに提供します。

どのデバイスが再生していても、Apple Watchの「Now Playing」アプリは同じ体験を提供します。

Apple TVのリモコンも内蔵されています。

AVKitを使用する場合のtvOSでは、コントロールが提示されたときの情報オーバーレイには、タイトルとチャプター情報が表示されます。

情報ペインまで下にスワイプすると、アートワークや説明などの詳細が表示されます。

Apple TVのリモコンのテレビボタンを長押しすると、コントロールセンターが表示されます。iOSのように、再生中タイルも拡張できます。

オーディオコンテンツがtvOSのバックグラウンドから再生を開始すると、リモコンの再生ボタンを押すか、別のデバイスからミュージックアプリでトラックを選択するかにかかわらず、再生中の情報を含む通知が表示されます。

さらに、オーディオを再生するときにtvOSで短時間非アクティブになった後、現在再生されているものを示すフルスクリーンオーバーレイが表示されます。

最後に、iOSでは、[他のスピーカーとテレビを制御する]ボタンを使用すると、すべてのデバイスで再生中の情報を表示したり、再生を制御したりできます。

再生中情報が提示され、再生を制御できるデバイスやUIの数が増えるにつれて、再生中の情報を適切に公開し、リモートコマンドに応答することがこれまで以上に重要になっています。

このセッションの残りの部分では、リモートコマンド、自動メタデータ公開、AVKitによる公開、手動公開の形での再生インタラクションへの応答について説明します。

メディア再生にAVFoundationを使用する場合、再生中のメタデータを公開し、再生インタラクションに応答する最善の方法は、MPNowPlayingSessionクラスを使用することです。

歴史的に、このクラスはtvOSでのみ利用可能でしたが、現在はiOS 16で利用可能です。

これは、明確な再生セッションを表すために使用され、アプリに複数のアクティブなセッションが含まれている場合は、再生中のステータスを制御できます。

手動メタデータパブリッシングと、iOSとtvOS 16で利用可能な新しい自動パブリッシングの両方をサポートしています。

MPNowPlayingSessionは、セッションの後半で取り上げる独自の自動公開メカニズムを持つAVKitを使用する場合、tvOSで使用するべきではありません。

「再生中」アプリであることは、アプリがコントロールセンター、ロック画面などに入力され、ユーザーがこれらのインターフェイスの1つから一時停止を押すと再生コントロールを受け取ることを意味します。

MPNowPlayingSessionを使用すると、1つのアプリ内で複数の同時再生セッションを表現できます。

ただし、複数のセッションを使用する場合、アプリはアプリをリモートコントロールするときにシステム全体に表示されるアクティブなセッションとして1つを宣伝する必要があります。

たとえば、ピクチャー・イン・ピクチャーでは、2つの同時再生セッションがあり、フルスクリーン再生はアクティブな再生セッションと見なされるべきです。

このシステムには、アプリを「Now Playing」として適格と認定するためのいくつかのヒューリスティックもあります。

まず、少なくとも1つのリモートコマンドのハンドラを登録する必要があります。

ご想像のとおり、再生インタラクションに応答しないアプリは、再生中のアプリとして表示するのに理想的な候補ではない可能性が最も高いです。

第二に、アプリのAVAudioSessionは、混在できないカテゴリとカテゴリオプションで設定する必要があります。

ミックス可能な再生カテゴリとオプションは、通知を再生するときに一般的に使用されるため、これは再生されているものがNow Playingの良い候補ではないというシステムにとって良い兆候です。

再生セッションを理解するのに役立つ例をいくつか紹介します。

この例では、単一のコンテンツが再生されているため、これは単一のMPNowPlayingSessionを使用して表現されます。

アプリがPiPをサポートしている場合は、2つのMPNowPlayingSessionsがあります。1つはメインプレーヤー用、もう1つはPiP再生用です。

より複雑なシナリオは、複数のプレーヤーを持つ単一のMPNowPlayingSessionです。

この例では、各象限に1人ずつ4人の選手がいて、同じレースで異なる視点を示しています。

同じMPNowPlayingSessionに追加されたプレイヤーは、常に同じコンテンツの一部である必要があります。

そして、これらの各サンプルセッションがどのようにインスタンス化されるかを次に示します。

1つ目は、単一のコンテンツを再生しているだけなので、シングルプレイヤーとのシングルセッションがあります。

2番目の例はピクチャー・イン・ピクチャーを使用しているため、2つのセッションがあり、それぞれが1つのプレーヤーです。

1つ目はフルスクリーンコンテンツで、2つ目はPiPのコンテンツです。

最後の例であるマルチビューレースは、4人のプレーヤーとの1回のセッションで表されます。

アプリに複数のセッションがある場合、該当する場合、特定のセッションをアクティブとして宣伝するのはアプリの責任です。

たとえば、メディアがピクチャー・イン・ピクチャーで再生されている場合、ユーザーがフルスクリーンに展開すると、以前のフルスクリーンセッションはアクティブではなくなり、再生中になり、フルスクリーンになったPiPセッションがアクティブになります。

この移行は、MPNowPlayingSessionでbecomeActiveIfPossibleを呼び出すことで実行できます。

MPNowPlayingSessionのインスタンスの設定と「再生中」セッションの制御の基本について説明したので、ロック画面からでも、別の部屋のHomePodからでも、リモートコマンドの受信と応答について話しましょう。

再生と一時停止コマンドに登録する基本的な例から始めましょう。

そうすることで、ユーザーが別のデバイスから再生または一時停止を押したり、Siriを使用してコマンドを発行したりすると、アプリがコールバックを受信できるようになります。

まず、MPNowPlayingSessionをインスタンス化します。

セッションは1つしかないので、「becomeActiveIfPossible」メソッドを呼び出す必要はありません。

セッションが1つしかない場合、アプリが再生中アプリの場合、デフォルトのセッションになります。

各MPNowPlayingSessionインスタンスには、再生セッションが応答できるリモートコマンドを宣言するために使用される独自のMPRemoteCommandCenterインスタンスがあります。

次に、プレイヤーのplayメソッドを呼び出すplayCommandのハンドラーを追加し、成功を返します。

次に、pauseCommandに対しても同じことをします。

アプリがサポートし、現在再生中のコンテンツに適用されるすべてのコマンドにハンドラーを追加する必要があります。

もう1つの例は、スキップフォワードとスキップバックコマンドです。

このコマンドはほとんどのコンテンツに使用する必要があり、たとえば、前方にジャンプできないライブストリームには適用されません。

まず、好みの間隔、またはどちらかの方向にジャンプしたい秒数を示す必要があります。

この場合、15秒を使用します。

次に、再生と一時停止のコマンドで行ったのと同様に、ユーザーがスキップフォワードボタンを押すか、Siriにスキップを依頼したときに呼び出されるハンドラを追加します。

ハンドラでは、MPSkipIntervalCommandEventを受け取るので、まずイベントをそのタイプにキャストします。

次に、現在の時間とMPSkipIntervalCommandEventで提供された間隔を取って新しい経過時間を計算し、それを求め、成功を返して、新しい位置にジャンプしたことを示しています。

また、広告中にスキップするなど、アプリにコマンドが一時的に許可されていない状況がある可能性もあります。

その場合、skipForwardCommandを無効にすることができます。

リモートコマンドに応答する今、自動メタデータの公開について説明します。

自動パブリッシングは、持続時間、現在の経過時間、再生状態、再生進行状況など、プレーヤーから直接観察できるメタデータプロパティを自動的に維持することで、メタデータを正確に保つ作業を取り除きます。

コンテンツに広告が組み込まれていて、総期間と経過時間に寄与すべきではない場合は、ネットタイムを計算し、代わりにそれを報告することもできます。

タイトル、説明、アートワークなどの他のメタデータは、nowPlayingInfoプロパティを使用してAVPlayerItemsに直接追加できます。

この例では、自動公開を使用して作業の大部分を行い、タイトルとアートワークを自分で設定します。

まず、新しいMPMediaItemArtworkインスタンスを作成し、アートワーク画像を渡します。

ほとんどのアプリは、これを取得するためにネットワーク要求を実行します。

次に、コンテンツの文字列タイトルを設定します。

次に、アートワークとタイトルを取り、MPMediaItemPropertyTitleとMPMediaItemPropertyArtworkを使用して、現在のプレーヤーアイテムのnowPlayingInfo辞書として設定します。

Now Playingメタデータは、MPMediaItemPropertyとMPNowPlayingInfoPropertyの両方から構成できます。

最後に、プレーヤーに渡すMPNowPlayingSessionインスタンスを作成し、自動的にPublishNowPlayingInfoをtrueに設定します。

automaticallyPublishNowPlayingInfoがtrueに設定されると、MPNowPlayingSessionインスタンスは、スクラブ、再生/一時停止イベント、または現在のプレーヤーアイテムの変更などの状態変更についてプレーヤーを観察し始めます。

広告がアセットに焼き込まれ、合計期間や現在の経過時間に広告時間を含めたくない場合に、自動公開を使用する方法を示す別の例を次に示します。

これを行うには、私たちが焼き上げたすべての広告に対してMPAdTimeRangeのインスタンスを作成します。

この例では、冒頭から始まる30秒の広告が1つあります。

そこで、ゼロの開始点と30秒の持続時間で作成します。

先ほどのタイトルとアートワークと同様に、MPNowPlayingInfoPropertyAdTimeRangesを使用して、プレーヤーアイテムのnowPlayingInfo辞書にMPAdTimeRangeの配列を追加するだけです。

その後、以前と同じように、MPNowPlayingSessionを作成し、自動公開を有効にします。

次はAVKitによるメタデータの公開です。

tvOSのAVKitを使用した再生メタデータの公開は、MPNowPlayingSessionと非常によく似ています。メタデータはAVPlayerItemに直接追加され、経過時間、期間、再生状態などの値が公開され、最新の状態に保たれます。

プレーヤーとアセットから直接収集されたメタデータは、AVPlayerItem上のアプリが提供するメタデータと組み合わせて、プレーヤーUIの情報ペインに入力するためにも使用されます。

AVKitは、リモートコマンドの登録と応答も処理します。

AVKitを使用することは、これまでに議論したプラットフォーム機能や、AirPlayやピクチャー・イン・ピクチャーなどの他の機能と統合するための最善かつ最も簡単な方法です。

AVKitを使用する際のメタデータの設定は、コンテンツを記述するためのAVMetadataItemインスタンスで構成されるAVPlayerItemのexternalMetadata配列を使用して行われます。

通常、各AVMetadataItemに3つの値を設定します。

まず、識別子は、AVMetadataItemが表すメタデータを示す鍵です。

たとえば、コンテンツタイトルのAVMetadataCommonIdentifierTitle、またはアートワークのAVMetadataCommonIdentifierArtwork。

2つ目は値です。

タイトルの場合、これはタイトルを含む文字列になります。

アートワークの場合、これは画像データを含むNSDataインスタンスになります。

dataTypeは、提供されたアートワークの形式を示すために使用されます。

JPEGデータが含まれている場合は、kCMMetadatabaseDataType_JPEGが使用されます。

最後に、extendedLanguageTagは、タイトルや説明などの文字列に使用される言語を示すために使用されます。

ほとんどの場合、すべての視聴者が同じ値を見るようにするために、ここでは値「und」を使用する必要があります。

値が英語の場合、「en-us」を使用したくなるかもしれませんが、そうすると、言語がスペイン語などの他の言語に設定されているデバイスにメタデータが表示されなくなる可能性があります。

ここでは、アートワークとタイトルを設定する例があります。

まず、バンドルからアートワークの画像データを取得します。

ほとんどのアプリは、ネットワークリソースからこれを取得します。

次に、新しい可変AVMetadataItemをインスタンス化します。

識別子を.commonIdentifierArtworkに設定しました。

次に、値を生のアートワーク画像データとしてNSDataとして設定します。

画像データはJPEGなので、dataTypeをkCMMetadataBaseDataType_JPEGに設定します。

アートワークが代わりにPNGの場合は、kCMMetadataBaseDataType_PNGを使用します。

このメタデータを任意の言語に設定したデバイスを持つユーザーに表示させたいため、extendedLanguageTagを「und」または「undefined」に設定します。

次に、.commonIdentifierTitleと値の文字列タイトル、extendedLanguageTagの「und」を使用して、タイトルに対して同じ手順を繰り返します。

すべてのメタデータ項目を設定したら、それらを配列に追加し、AVPlayerItemのexternalMetadataプロパティに設定します。

プレイヤーアイテムにアートワークとタイトルが追加されたので、これがiOSのコントロールセンターとロック画面に表示されるものにどのようにマッピングされるかを確認できます。

アートワークと同様に、説明、字幕情報、コンテンツ評価など、設定できる他のメタデータタイプがあります。

アプリは、できるだけ豊富な体験をユーザーに提供するために、これらをできるだけ多く設定する必要があります。

これまでのところ、MPNowPlayingSessionでの自動公開とAVKitでの公開を取り上げました。

しかし、MPNowPlayingSessionとその自動公開機能は、AVPlayerインスタンスを渡す必要があります。

それはすべてのアプリのオプションではないかもしれませんし、手動公開はまだ可能です。

手動で公開するには、すべてのメタデータの値を提供する必要があります。

自動公開とは異なり、経過時間や再生速度などの情報はシステムで決定することはできません。

これは、低レベルの再生状態を手動で細かく制御できることを意味し、アプリは再生が変化するにつれて時間の経過とともに正確に保つ責任があります。

リモートコマンドの登録と応答も引き続き必要であり、MPNowPlayingSessionを使用していないため、MPRemoteCommandCenterの共有インスタンスを使用する必要があることに注意してください。

以下は、Now Playing Info辞書を更新する方法を示す基本的な例です。

まず、自動公開のために行ったのと同様に、画像を含むMPMediaItemArtworkインスタンスを作成します。

次に、利用可能なメタデータを含む辞書を作成します。

この場合、タイトル、アートワーク、プレイヤー値の持続時間、経過時間、再生速度を設定します。

次に、MPNowPlayingInfoCenterのデフォルトインスタンスに設定します。

このメタデータの更新は、再生や一時停止、ユーザーが前方または後方にスクラブしたり、新しいコンテンツの再生を開始するなど、再生中に重要な変更が行われるときはいつでも行う必要があります。

経過時間を定期的に更新する必要はありません。

システムは、前回の更新から経過した時間に基づいて、常に正しい経過時間を推測します。

再生中のメタデータを公開し、他のデバイスやインターフェイスからのリモートコマンドに応答するさまざまな方法に精通したので、ユーザーエクスペリエンスを最大化するために統合する必要があります。

これまで以上に簡単です。

既存の統合も恩恵を受けることができます。自動公開への切り替えは、将来の回帰を防ぎ、維持する必要があるコードの量を最小限に抑える簡単な方法です。

詳細については、developer.apple.comのMediaPlayerを参照してください。

見てくれてありがとう。