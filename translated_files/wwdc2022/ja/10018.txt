10018

♪インストゥルメンタルヒップホップ音楽♪

♪

こんにちは、私の名前はカレン・シンです。

私はカメラソフトウェアチームのエンジニアです。

「macOSアプリにContinuityカメラのサポートをブリングする」へようこそ。このセッションを開始するには、Continuity Cameraとは何ですか？

次に、アプリケーションがContinuity Cameraで自動カメラ選択体験を構築する方法について説明します。

そして最後に、Continuity Camera用のmacOS 13の新しいAPIについて説明しておきます。

連係カメラを使えば、iPhoneをウェブカメラとして使えるようになりました。

セットアップはシームレスです。iPhoneをMacに近づけるだけです。

また、ワイヤレスで機能するので、すぐに通話に参加できます。

あなたのiPhoneは、いくつかの条件下で外付けカメラとマイクとしてMacに表示されます。

まず、macOS 13とiOS 16を実行している必要があります。

MacとiPhoneの両方は、2要素認証を使用して同じApple IDにサインインする必要があります。

有線接続の場合、電話をUSB経由でMacに接続する必要があります。

または、ワイヤレス接続の場合、2つのデバイスが近接しており、BluetoothとWi-Fiの両方がオンになっている必要があります。

それを通して話すのではなく、魔法の連続性カメラがデバイスでどのように見えるかをすぐにお見せしましょう。

ここにMacBook ProとiPhone 13 Proがあります。

両方のデバイスが同じApple IDでサインインしています。

電話は私のMacBookに取り付けられたスタンドの上に置かれています。

今日は同僚のエリックとビデオ会議に参加し、ZoomでContinuity Cameraを使用する方法を紹介します。

アプリは最初に内蔵カメラを使用して起動され、その後、新しいカメラで何ができるかを説明するオンボーディングダイアログが表示されます。

ダイアログは、MacがmacOS 13にアップグレードされた後、カメラアプリケーションを初めて開くと、Continuity Cameraの対象となるiPhoneが1回表示されます。

こんにちは、エリック！

エリック：ああ、カレン！こんにちは！

カレン：オンボーディングダイアログがシステムに表示されると、Continuity Cameraとマイクデバイスがすべてのアプリケーションで利用可能になります。

このカメラを使うように切り替えて、それがどのように見えるか見てみましょう。

連係カメラはiPhoneのリアカメラシステムを使用しているため、iPhoneに期待するのと同じ素晴らしいビデオ品質が得られます。

そして、それは電話の4つの向きすべてで動作します。

縦向きは、横向きに比べて視野が拡大されます。

連続カメラでは、いくつかの新しいビデオエフェクトなど、ウェブカメラでこれまでに不可能だったことを行うこともできます。

おそらく、iOS 14.5とmacOS 12.3で導入されたセンターステージとポートレートのビデオエフェクトにすでに精通しているでしょう。

そうでない場合は、WWDC 2021の「カメラキャプチャの新機能」セッションを見て、システムのビデオエフェクトとアプリケーションでそれらと対話する方法について詳しく学ぶことを強くお勧めします。

コントロールセンターに行って、連係カメラでシステムビデオエフェクトを有効にしましょう。

センターステージは、シーン内を動き回るときにあなたをフレームに保ちます。

ポートレートは背景をぼかし、自然にあなたに焦点を合わせます。

ポートレートはAppleシリコンMacでのみサポートされていますが、Continuity Cameraを使用すると、すべてのIntelおよびAppleシリコンMacで利用可能になりました。

Studio Lightは、macOS 13で利用可能な新しいシステムビデオエフェクトです。

iPhone 12以降を使用する場合は、Continuity Cameraでサポートされています。

画面上で最高に見せたいときは、これを有効にしてください。

それは背景を暗くし、あなたの顔を照らす見事な照明効果を提供します。

スタジオライトは、窓の前にいるときなど、厳しい照明状況に最適です。

明確な比較のために各ビデオエフェクトを別々に見せていますが、それらはすべてうまく機能します。

そして、効果の任意の組み合わせを同時に適用することができます。

連続カメラのために本当にお見せしたいもう1つのエキサイティングな機能があります。

一緒に仕事をして机の上にあるものを共有したいときは、デスクビューを使用できるようになりました。

デスクビューアプリにはmacOS 13が付属しており、コントロールセンターですぐに起動できます。

それは、すべての複雑な機器を必要とせずに、オーバーヘッドカメラのセットアップのように動作します。

iPhoneは超広角カメラフィードを2つに分割し、机と顔の両方を同時に見せるので、学校のプロジェクトでコラボレーションしたり、友人に編みステッチを教えたりできます。

超広角カメラの拡張垂直視野を活用し、トリミングされたフレームに遠近法歪み補正を適用し、フレームを回転させてこのデスクビューを作成します。

ほとんどのビデオ会議アプリで利用可能な共有ウィンドウ機能を使用して、メインのビデオカメラフィードと並行して実行されるこのデスクビューフィードを共有できます。

デスクビューは、メインカメラから同時にストリーミングすることなく、単独で使用することもできます。

しかし、デスクビューとメインカメラの両方からストリーミングする場合は、メインカメラでセンターステージを有効にして、顔と体をキャプチャするためのより良いフレーミングを行うことをお勧めします。

この機能は、電話が横向きまたは縦向きのいずれかに配置されている場合にサポートされます。

縦向きは、垂直視野が大きいため、最も汎用性を提供します。

アプリケーションに適したカスタマイズされた統合を提供するデスクビューカメラAPIもあります。

すぐにAPIについて話します。

Macでのビデオ会議通話中に、セッションに集中してほしいのですが、重要なことを見逃さないようにしたいと考えています。

コンティニュイティカメラが使用されている場合、携帯電話上のすべての通知が消音され、重要な通話通知がMacに転送されます。

さようなら、エリック！

エリック：さようなら、カレン！

カレン：アプリケーションに新しいコードを1行も書き込むことなく、ユーザーが利用できるすべての素晴らしい体験について話しました。

しかし、新しいAPIの採用により、Continuity Cameraの体験をアプリでさらに魔法のように洗練されたものにすることができます。

ほとんどのユーザーがMacで少なくとも2つのカメラデバイスを手に入れるようになったので、カメラをどのように管理すべきかについてもっと考えました。

macOS 13より前は、デバイスのプラグを抜いた場合、またはより良いカメラがシステムで利用可能になった場合、通常、アプリケーションでは手動選択ステップが必要です。

アプリケーションでカメラを自動的に切り替えることで、お客様に魔法のような体験を提供したいと考えています。

アプリでこの機能を構築するのに役立つ2つの新しいAPIをAVFoundationフレームワークに追加しました。クラスプロパティuserPreferredCameraとAVCaptureDeviceのsystemPreferredCameraです。

userPreferredCameraは読み取り/書き込みプロパティです。

ユーザーがアプリケーションでカメラを選択するたびに、このプロパティを設定する必要があります。

これにより、AVCaptureDeviceクラスはユーザーの好みを学習し、アプリの起動と再起動で各アプリケーションのカメラのリストを保存し、その情報を使用してカメラを提案することができます。

また、カメラが接続されるか切断されるかも考慮されます。

このプロパティはキー値で観察可能で、ユーザーの好みに基づいて最適な選択をインテリジェントに返します。

最新の優先デバイスが切断されると、リスト内の次の利用可能なカメラに自発的に変更されます。

ユーザー選択履歴がない場合や、優先デバイスが接続されていない場合でも、プロパティは常にすぐに使用できるカメラデバイスを返し、以前にストリーミングされたカメラを優先しようとします。

システムにカメラがない場合にのみnilを返します。

systemPreferredCameraは読み取り専用プロパティです。

これは、userPreferredCameraだけでなく、システムに存在するカメラの最良の選択を提案するために、他のいくつかの要因を組み込んでいます。

たとえば、このプロパティは、Continuity Cameraが自動的に選択する必要があるというシグナルを表示すると、userPreferredCameraとは異なる値を返します。

このプロパティはまた、デバイスのサスペンションを内部的に追跡するので、中断されたデバイスよりもサスペンドされていないデバイスを優先します。

これは、内蔵カメラがMacBookの蓋を閉じることから中断された場合に、別のカメラに変更する自動切り替え動作を構築するのに役立ちます。

連続性カメラは、電話が横向きの固定スタンドに置かれ、画面がオフになり、USB経由でMacに接続されているか、Macの近い範囲内に接続されているときに、自動的に選択されるように通知します。

このシナリオでは、デバイスが継続カメラとして使用されるべきであるというユーザーの意図は明らかです。

systemPreferredCamera APIを採用する場合は、常にキー値でこのプロパティを観察し、それに応じてAVCaptureSessionのビデオ入力デバイスを更新して、魔法のカメラの選択体験を提供する必要があります。

userPreferredCameraとsystemPreferredCameraはすでにファーストパーティアプリケーションで採用されています。

これらのAPIを採用するアプリケーションが増えているため、Appleデバイスでユニバーサルで一貫したカメラ選択方法をお客様に提供できるようになります。

連続カメラによる自動切り替えがFaceTimeでどのように見えるかを説明するデモをお見せしましょう。

ここFaceTimeでは、自動カメラ選択モードになっています。

手動と自動の両方の動作を提供したいアプリケーションには、自動モードを有効または無効にするための新しいUIを追加することをお勧めします。

FaceTimeは現在、内蔵カメラからストリーミング中です。

机から電話を取り、MacBookの後ろのスタンドに置くと...

...FaceTimeは、Continuity Cameraからシームレスにストリーミングに切り替わります。

そこで、新しいクラスプロパティsystemPreferredCameraが登場します。電話がストリーミングする準備ができている位置にあるとき、プロパティ値はContinuity Cameraに変わります。

同様の方法でアプリケーションを構築したいと思うかもしれません。

これは、自動カメラ選択と手動選択モードを実装する方法に関する私のレシピです。

自動カメラ選択がオンのときは、systemPreferredCameraプロパティを観察するキー値を開始します。

セッションの入力デバイスを更新して、変更されるたびにsystemPreferredCameraに従ってください。

オートモードでは、ユーザーが自分でカメラを選択できるようにするオプションを提供することを強くお勧めします。

別のカメラが選択されたら、userPreferredCameraをそのデバイスに設定すると、systemPreferredCameraのプロパティ値に反映されます。

自動カメラ選択がオフの場合、systemPreferredCameraプロパティのキー値の観察を停止します。

systemPreferredCameraに従う代わりに、手動モードでユーザーが選んだカメラでセッションの入力デバイスを更新する必要があります。

しかし、自動モードと同様に、ユーザーが別のカメラを選択するたびにuserPreferredCameraプロパティを設定する必要があるため、優先カメラのユーザーの履歴を維持し、自動カメラ選択モードに戻るときに適切なカメラを提案します。

userPreferredCameraとsystemPreferredCamera APIを組み込む方法に関するベストプラクティスについては、新しいサンプルアプリ「Continuity Camera Sample」をご覧ください。

Continuity Cameraは、Macに魔法のウェブカメラ体験をもたらすだけでなく、MacアプリでiPhone固有のカメラ機能のパワーを活用する新しい機会を提供します。

アプリケーションがContinuity Cameraデバイスをよりよく活用できるように、macOS 13にいくつかのAVCapture APIを追加しました。

Continuity Cameraのおかげで、iPhoneの写真撮影の驚くべき品質をmacOSにもたらしています。

まず、高解像度の写真のキャプチャをサポートします。

以前は、macOSはビデオ解像度での写真撮影のみをサポートしていました。

macOS 13以降では、Continuity Cameraで最大12メガピクセルの写真を撮影できます。

これは、キャプチャセッションを開始する前に、まずAVCapturePhotoOutputオブジェクトでhighResolutionCaptureEnabledをtrueに設定し、各キャプチャのphotoSettingsオブジェクトでhighResolutionPhotoEnabledプロパティをtrueに設定することで有効にできます。

高解像度の写真をキャプチャすることに加えて、Continuity Cameraは、最初にphotoOutputオブジェクトで最大写真品質の優先順位を設定し、AVCapturePhotoSettingsオブジェクトにphotoQualityPrioritizationプロパティを設定して各キャプチャの優先順位を選択することで、写真の品質を速度に対して優先順位を付ける方法を制御することをサポートしています。

アプリケーションの適切な優先順位の選択の詳細については、WWDC2021の「ビデオフォーマットを使用して高品質の写真をキャプチャする」をご覧ください。

もう1つの写真関連の機能はフラッシュキャプチャです。

photoSettingsオブジェクトにflashModeを設定して、シーンと照明条件に基づいてフラッシュをオン、オフ、または自動的に選択するかどうかを制御できるようになりました。

また、キャプチャセッションによって生成された時付けされたメタデータを処理できるように、macOSでAVCaptureMetadataOutputを利用できるようにしています。

iPhoneから顔のメタデータオブジェクトと人体のメタデータオブジェクトをストリーミングできるようになりました。

顔のメタデータオブジェクトを受信するためのセッションを設定する方法を見てみましょう。

適切なビデオ入出力でセッションを設定した後、AVCaptureMetadataOutputを作成し、addOutputを呼び出してセッションに追加する必要があります。

特にフェイスメタデータを受信するには、フェイスオブジェクトタイプを含めるように出力にオブジェクトタイプ配列を設定します。

availableMetadataObjectTypesプロパティをチェックして、要求されたメタデータ型がサポートされていることを確認してください。

次に、メタデータコールバックを受信するようにデリゲートを設定します。

セッションの実行が開始されると、リアルタイムで生成されたフェイスメタデータオブジェクトでコールバックを取得します。

先ほど話したAVCapturePhotoOutputとAVCaptureMetadataOutputに加えて、Continuity Cameraはビデオデータ出力、ムービーファイル出力、AVCaptureVideoPreviewLayerもサポートしています。

これは、このカメラをアプリケーションに統合する際に注意すべきContinuity Cameraでサポートされているビデオフォーマットのリストです。

640×480から1080pまでの3つの16×9フォーマットと、1920×1440の1つの4×3フォーマットをサポートしています。

必要に応じて、最大30フレーム/秒または60フレーム/秒をサポートするフォーマットを選択できます。

もう1つの大きな追加は、デスクビューデバイスAPIです。

デスクビューカメラは、別のAVCaptureDeviceとして公開されます。

このデバイスを見つけるには2つの方法があります。

1つ目は、デバイス検出セッションでAVCaptureDeviceType DeskViewCameraを調べることです。

または、メインビデオカメラのAVCaptureDeviceオブジェクトをすでに知っている場合は、そのデバイスのcompanionDeskViewCameraプロパティを使用してデスクビューデバイスにアクセスできます。

このAPIは、複数のContinuity Cameraデバイスがある場合に、メインカメラとデスクビューデバイスをペアリングするのに役立ちます。

目的のデスクビューカメラのAVCaptureDeviceオブジェクトを取得したら、他のカメラデバイスと同様に、キャプチャセッションでAVCaptureビデオデータ出力、ムービーファイル出力、またはビデオプレビューレイヤーで使用できます。

デスクビューデバイスは現在、420Vピクセルフォーマットの1つのストリーミングフォーマットをサポートしています。

フォーマットの解像度は1920×1440で、サポートされている最大フレームレートは30fpsです。

これでセッションは終わりです。

コンティニュイティカメラ、macOSで魔法のカメラの選択を構築する方法、およびMacアプリケーションにコンティニュイティカメラを統合するためのいくつかの新しいAPIについて学びました。

私はあなたがこれらすべてのAPIを採用し、WWDCの素晴らしい残りを持っているのを見て興奮しています。

♪