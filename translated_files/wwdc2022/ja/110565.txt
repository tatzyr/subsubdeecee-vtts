110565

♪ ♪

ケン・グリーンバウム:皆さん、こんにちは!WWDC 2022へようこそ。

私の名前はケン・グリーンバウムで、アップルのカラー&ディスプレイテクノロジーチームに所属しています。

今年は3回のEDR講演ができることに興奮しています。

iOSのEDR APIサポートを発表した「Explore EDR on iOS」と「Core Image、Metal、SwiftUIでEDRコンテンツを表示する」を見る機会があったことを願っています。

昨年の私のEDRトークを見た人もいるかもしれません。そこでは、AVPlayerを使用してEDRを使用してHDRビデオを再生する方法を実演しました。

この講演では、Core Mediaインターフェイスを使用して、EDR再生だけでなく、HDRビデオを独自のEDRレイヤーまたはビューにデコードして再生する方法を探ります。

次に、単にコンテンツを再生するだけでなく、Core Videoのディスプレイリンクを介してリアルタイムでデコードされたビデオフレームにアクセスする方法を示し、それらのフレームをCoreImage Filters、またはMetal Shaderに送信して、カラー管理、視覚効果を追加したり、その他の信号処理を適用したり、最後に、結果のフレームをMetalにプラムしてレンダリングします。

まず、EDR互換のビデオメディアフレームワークを見直して、アプリケーションの要件に最も適したフレームワークを決定するのに役立ちます。

次に、アプリケーションが直接再生を必要とする場合、HDRビデオを再生するすべての作業を行うことができる高レベルのAVKitとAVFoundationフレームワークについて簡単に説明します。

最後に、EDR再生、編集、または画像処理エンジンで、Core VideoとMetalを使用して、デコードされたビデオフレームを使用するためのベストプラクティスについて説明します。

まず、Appleのビデオフレームワークの簡単な調査から始めましょう。最高レベルのインターフェイスから始めて、最も使いやすいです。そして、コードに複雑さを加えることを犠牲にして、より多くの機会を提供する低レベルのフレームワークを続けます。

自動的に提供される最適化を利用するには、可能な限り最高レベルのフレームワークを使用するのが最善です。

これにより、簡単なEDR再生から、デコードされたビデオフレームのより洗練された配管、リアルタイム処理のためのCoreImageやMetalまで、多くのシナリオを探求するトークの本体に飛び込む準備が整います。

最高レベルでは、AVKitがあります。

AVKitを使用すると、メディア再生用のユーザーインターフェイスを作成できます。トランスポートコントロール、チャプターナビゲーション、ピクチャーインピクチャーのサポート、字幕とクローズドキャプションの表示が付属しています。

AVKitは、AVPlayerViewControllerを使用してデモンストレーションを行うように、HDRコンテンツをEDRとして再生できます。

ただし、アプリケーションでビデオフレームのさらなる処理が必要な場合は、パイプラインをより詳細に制御できるメディアフレームワークを使用する必要があります。

次はAVFoundationです。

AVFoundationは、Appleプラットフォームで時間ベースのオーディオビジュアルメディアを扱うためのフル機能のフレームワークです。

AVFoundationを使用すると、QuickTimeムービーやMPEG 4ファイルを簡単に再生、作成、編集したり、HLSストリームを再生したり、強力なメディア機能をアプリに組み込んだりできます。

この講演では、AVPlayerと関連するAVPlayerLayerインターフェースの使用を探ります。

コアビデオは、デジタルビデオのパイプラインモデルを提供するフレームワークです。

プロセスを個別のステップに分割することで、ビデオの操作方法を簡素化します。

また、Core Videoを使用すると、データタイプ間の変換やディスプレイの同期を心配することなく、個々のフレームへのアクセスと操作が容易になります。

DisplayLinkとCVPixelBufferのCore Imageの使用を実演します。

そして、金属を使ったCVMetalTextureCache。

次に、ビデオツールボックスがあります。

これは、ハードウェアエンコーダとデコーダへの直接アクセスを提供する低レベルのフレームワークです。

Video Toolboxは、ビデオの圧縮と解凍、およびCore Videoピクセルバッファに保存されているラスター画像フォーマット間の変換のためのサービスを提供します。

VTDecompressionSessionは、この講演の範囲外の強力な低レベルのインターフェースですが、高度な開発者はさらに調査したいかもしれません。

そして最後に、コアメディアがあります。

このフレームワークは、AVFoundationで使用されるメディアパイプライン、およびその他の高レベルのメディアフレームワークを定義します。

Core Mediaの低レベルのデータタイプとインターフェイスをいつでも使用して、メディアサンプルを効率的に処理し、メディアデータのキューを管理できます。

この講演の残りの部分では、アプリでこれらのフレームワークを使用する方法と時期を紹介します。

まず、AVKitとAVFoundationを使用して、EDRとしてレンダリングされたHDRビデオを簡単に再生する方法。

次に、AVPlayerの一連のより洗練されたアプリケーション：独自のレイヤーにレンダリングし、CADisplayLinkを介して個別にデコードされたフレームにアクセスし、結果のCVPixelBuffersをCore Imageに送信して処理し、最後に、Metalで処理およびレンダリングするためにCVMetalTextureCacheを介してMetalテクスチャとしてデコードされたフレームにアクセスします。

Appleプラットフォームのビデオメディアレイヤーの概要がわかったので、AVKitとAVFoundationのフレームワークに焦点を当てます。

まず、AVFoundationのAVPlayerインターフェイスを使用してHDRビデオコンテンツの再生について話し合うことから始めましょう。

AVPlayerは、メディアアセットの再生とタイミングを管理するために使用されるコントローラーオブジェクトです。

AVPlayerインターフェースは、HDRビデオの高性能再生に使用でき、可能であれば自動的にEDRとして結果をレンダリングします。

AVPlayerを使用すると、QuickTimeムービーなどのローカルおよびリモートファイルベースのメディア、およびHLSを使用して提供されるストリーミングメディアを再生できます。

基本的に、AVPlayerは一度に1つのメディアアセットを再生するために使用されます。

プレーヤーインスタンスを再利用して、追加のメディアアセットを連続再生したり、複数のインスタンスを作成して複数のアセットを同時に再生することもできますが、AVPlayerは一度に1つのメディアアセットの再生のみを管理します。

AVFoundationフレームワークは、シーケンシャルHDRメディアアセットのキューイングと再生を作成および管理するために使用できるAVQueuePlayerと呼ばれるAVPlayerのサブクラスも提供します。

アプリケーションがEDRにレンダリングされたHDRビデオメディアの簡単な再生が必要な場合は、AVPlayerViewControllerを使用したAVPlayerが最善のアプローチかもしれません。

AVPlayerLayerでAVPlayerを使用して、iOSまたはmacOSで独自のビューを再生します。

これらはAVPlayerを使用する最も簡単な方法です。

両方の例を見てみましょう。

まず、AVKitのAVPlayer View Controllerと組み合わせて、AVFoundationのAVPlayerインターフェイスを使用する方法を見ていきます。

ここでは、メディアのURLからAVPlayerをインスタンス化することから始めます。

次に、AVPlayerViewControllerを作成し、ビューアコントローラーのプレーヤープロパティをメディアのURLから作成したプレーヤーに設定します。

そして、ビデオの再生を開始するために、ビューコントローラーをモーダルに提示します。

AVKitはすべての詳細を管理し、EDRをサポートするディスプレイでHDRビデオをEDRとして自動的に再生します。

前述したように、一部のアプリケーションでは、HDRビデオメディアを独自のビューに再生する必要があります。

AVPlayerLayerでAVPlayerを使用してこれを達成する方法を見てみましょう。

自分のビューでHDRビデオメディアをEDRとして再生するには、メディアのURLでAVPlayerを作成することから始めます。

しかし、今回は作成したばかりのプレーヤーでAVPlayerLayerをインスタンス化します。

次に、ビューから取得したプレイヤーレイヤーの境界を設定する必要があります。

プレイヤーレイヤーがビューからの境界を持つようになったので、プレイヤーレイヤーをサブレイヤーとしてビューに追加できます。

最後に、HDRビデオメディアを再生するには、AVPlayerの再生方式と呼びます。

AVPlayerとAVPlayerLayerを使用して、独自のレイヤーでHDRビデオメディアをEDRとして再生するために必要なのはそれだけです。

AVPlayerを使用して、2つの最も簡単なHDRビデオ再生ワークフローを調査しました。

しかし、多くのアプリケーションは単純なメディア再生以上のものを必要とします。

たとえば、アプリケーションでは、カラーグレーディングやクロマキーイングなどの画像処理をビデオに適用する必要がある場合があります。

AVPlayerからデコードされたビデオフレームを取得し、コアイメージフィルターまたはメタルシェーダーをリアルタイムで適用し、結果をEDRとしてレンダリングするワークフローを探りましょう。

AVPlayerとAVPlayerItemを使用して、HDRビデオメディアからEDRフレームをデコードする方法を実演し、Core Videoディスプレイリンクからデコードされたフレームにアクセスし、結果のピクセルバッファをCore ImageまたはMetalに送信して処理し、EDRをサポートするディスプレイでCAMetalLayerでEDRとして結果をレンダリングします。

これを念頭に置いて、まず、HDRメディアがEDRとして正しくレンダリングされるようにするために必要なCAMetalLayerにいくつかの重要なプロパティを設定することを実演しましょう。

まず、HDRビデオコンテンツをレンダリングするCAMetalLayerを入手する必要があります。

そのレイヤーでは、wansExtendedDynamicRangeContentフラグをtrueに設定してEDRを選択します。

拡張ダイナミックレンジコンテンツをサポートするピクセル形式を必ず使用してください。

以下のAVPlayerの例では、CAMetalLayerをハーフフロートピクセル形式を使用するように設定しますが、PQまたはHLG転送関数と組み合わせて使用される10ビット形式も機能します。

結果をSDRに制限しないようにするには、レイヤーをEDR互換の拡張範囲の色空間に設定する必要があります。

この例では、ハーフフロートメタルテクスチャを拡張リニアディスプレイP3色空間に設定します。

EDR、色空間、ピクセルバッファフォーマットに関する表面を引っ掻いただけです。

詳細については、昨年の私のセッション「EDRによるHDRレンダリング」と今年の「iOSのEDR」をチェックしてください。

CAMetalLayerの基本的なプロパティを設定したので、Core ImageまたはMetalシェーダーを使用してリアルタイムの画像処理を追加して、デモンストレーションを続けましょう。

AVPlayerと組み合わせてディスプレイリンクを使用して、デコードされたビデオフレームにリアルタイムでアクセスします。

このワークフローでは、AVPlayerItemからAVPlayerを作成することから始めます。

次に、EDRの適切なピクセルバッファ形式と色空間で構成されたAVPlayerItemVideoOutputをインスタンス化します。

次に、表示リンクを作成して設定します。

そして最後に、ディスプレイリンクを実行して、ピクセルバッファをコアイメージまたはメタルに取得して処理します。

iOSで使用されているCADisplayLinkを実演します。

macOS用に開発する場合は、同等のCVDisplayLinkインターフェースを使用してください。

今回は、メディアのURLからAVPlayerItemを作成し、作成したばかりのAVPlayerItemでAVPlayerをインスタンス化することを選択します。

次に、デコードされたフレームの色空間とピクセルバッファ形式を指定する辞書のペアを作成します。

最初の辞書であるvideoColorPropertiesは、色空間と転送関数が指定されている場所です。

この例では、ほとんどのAppleディスプレイの色空間に対応するディスプレイP3色空間と、AVFoundationがEDRに必要な拡張範囲値を維持できるようにする線形転送機能を要求します。

2番目の辞書であるoutputVideoSettingsは、ピクセルバッファ形式の特性を指定し、作成したばかりのvideoColorProperties辞書への参照も提供します。

この例では、ワイドカラーとハーフフロートピクセルバッファ形式を要求します。

AVPlayerItemVideoOutputは、出力設定辞書で指定したピクセルバッファ形式にビデオをデコードするだけでなく、ピクセル転送セッションを介して必要な色変換を自動的に実行することは非常に役に立ちます。

思い出してください、ビデオには複数のクリップが含まれている可能性があり、潜在的に異なる色空間を持つ可能性があります。

AVFoundationはこれらを自動的に管理し、すぐに実演するように、この動作により、結果としてデコードされたビデオフレームを、ディスプレイの色空間への自動色空間変換を提供しないMetalのような低レベルのフレームワークに送信することもできます。

次に、outputVideoSettings辞書を使用してAVPlayerItemVideoOutputを作成します。

3番目のステップとして、デコードされたフレームにリアルタイムでアクセスするために使用されるディスプレイリンクを設定します。

CADisplayLinkは、各ディスプレイアップデートで実行されるコールバックを受けます。

この例では、処理のためにCore Imageに送信するCVPixelBuffersを取得するために、すぐに探索するローカル関数を呼び出します。

次に、ビデオプレーヤーアイテムオブザーバーを作成して、指定されたプレーヤーアイテムプロパティの変更を処理できるようにします。

私たちの例では、プレイヤーアイテムのステータスが変更されるたびにこのコードを実行します。

プレーヤーアイテムのステータスがreadyToPlayに変更されると、AVPlayerItemVideoOutputを返されたばかりの新しいAVPlayerItemに追加し、メイン実行ループを共通モードに設定してCADisplayLinkを登録し、ビデオプレーヤーで再生を呼び出してHDRビデオのリアルタイムデコードを開始します。

最後に、先ほど「displayLinkCopyPixelBuffers」ローカル関数と呼んだCADisplayLinkコールバック実装の例を見ていきます。

HDRビデオの再生が始まると、ディスプレイの更新ごとにCADisplayLinkコールバック機能が呼び出されます。

たとえば、典型的なディスプレイでは1秒間に60回呼び出されるかもしれません。

これは、新しいCVPixelBufferがある場合に表示されるフレームを更新するコードの機会です。

各ディスプレイコールバックでは、現在のウォールクロック時間に表示されるデコードされたビデオフレームを含むCVPixelBufferをコピーしようとします。

ただし、特に画面のリフレッシュレートが再生されているビデオのリフレッシュレートを超える場合、すべてのディスプレイの更新で常に新しいCVPixelBufferが利用できるわけではないため、「copyPixelBuffer」呼び出しは失敗する可能性があります。

新しいCVPixelBufferがない場合は、呼び出しが失敗し、レンダリングをスキップします。

これにより、前のフレームは別のディスプレイの更新のために画面に残ります。

しかし、コピーが成功した場合、CVPixelBufferに新しいビデオフレームがあります。

この新しいフレームを処理してレンダリングする方法はいくつかあります。

1つの機会は、処理のためにCVPixelBufferをCore Imageに送信することです。

Core Imageは、1つ以上のシチクターをストリングして、ビデオフレームにGPU加速画像処理を提供できます。

すべてのシフィッターがEDRと互換性があるわけではないため、SDRへのクランプなど、HDRコンテンツに問題がある可能性があることに注意してください。

コアイメージは、多くのEDR互換フィルターを提供します。

CICategoryHighDynamicRangeでフィルター名を使用して、EDR互換のコアイメージフィルターを列挙します。

この例では、シンプルなセピアトーン効果を追加します。

では、例に戻り、Core Imageを統合しましょう。

新鮮なCVPixelBufferを生成する各表示リンクコールバックで、そのピクセルバッファからCIImageを作成します。

目的の効果を実装するためにCIFilterをインスタンスします。

パラメータレスのシンプルさのためにセピアトーンフィルターを使用していますが、システムには多くのシフィッターが組み込まれており、自分で書くのも簡単です。

CIFilterのinputImageを、先ほど作成したCIImageに設定します。

そして、処理されたビデオの結果は、フィルターのoutputImageで利用可能になります。

望ましい効果を達成するために、必要なだけ多くのCIFiltersをチェーンでつなぎます。

次に、CIRenderDestinationを使用して、結果の画像をアプリケーションのビューコードにレンダリングします。

このワークフローの詳細については、WWDC 2020トーク「ビデオアプリのコアイメージパイプラインの最適化」を参照してください。

もう1つの機会は、メタルとカスタムメタルシェーダーを使用して、新鮮なCVPixelBufferを処理してレンダリングすることです。

CVPixelBufferをMetalテクスチャに変換するプロセスを簡単に説明します。

しかし、最高のパフォーマンスを維持しながらこの変換を実装することは、別の講演に残すのに最適な深いトピックです。

代わりに、CoreVideo MetalテクスチャキャッシュからMetalテクスチャを導出することを推奨し、この講演の最後の例としてそのプロセスを説明します。

一般的に言えば、プロセスはCVPixelBufferからIOSurfaceを取得し、MetalTextureDescriptorを作成し、「newTextureWithDescriptor」を使用してMetalDeviceからMetalTextureを作成することです。

ただし、慎重なロックが適用されない場合、テクスチャが再利用され、オーバードローされる危険性があります。

さらに、すべてのPixelBufferフォーマットがMetalTextureでネイティブにサポートされているわけではないため、この例ではハーフフロートを使用しています。

これらの複雑さのため、代わりに、これから実演するように、Core VideoからMetalテクスチャに直接アクセスすることをお勧めします。

コアビデオとメタルをさらに探求しましょう。

前述のように、CVMetalTextureCacheは、MetalでCVPixelBuffersを使用するための簡単で効率的な方法です。

CVMetalTextureCacheは、さらなる変換を必要とせずにキャッシュから直接Metalテクスチャを取得するので便利です。

CVMetalTextureCacheは、CVPixelBufferとMetalTextureを自動的にブリッジし、コードを簡素化し、高速パスを維持します。

CVPixelBufferPoolsと組み合わせて、CVMetalTextureCacheは、MTLTextureとIOSurfaceマッピングを存続させることで、パフォーマンス上の利点も提供します。

最後に、CVMetalTextureCacheを使用すると、IOSurfacesを手動で追跡する必要がなくなります。

さて、私たちの講演の最後の例は、CVMetalTextureCacheを使用してCore Videoから直接Metalテクスチャを抽出する方法です。

ここでは、システムのデフォルトのMetalデバイスを取得することから始めます。

それを使用してメタルテクスチャキャッシュを作成し、メタルテクスチャキャッシュに関連付けられたコアビデオメタルテクスチャキャッシュをインスタンス化します。

その後、デコードされたビデオフレームにメタルテクスチャとしてアクセスすることができ、便利なメタルエンジンで直接使用できます。

この例では、Metalシステムのデフォルトデバイスを作成して使用します。

次に、CVMetalTextureCacheCreateを使用してCVMetalTextureCacheを作成し、作成したばかりのMetalデバイスを指定します。

コアビデオメタルテクスチャを作成するために必要なCVPixelBufferの高さと幅を取得します。

次に、「CVMetalTextureCacheCreateTextureFromImage」を呼び出すと、CVMetalTextureオブジェクトをインスタンス化し、それをCVPixelBufferに関連付けます。

最後に、「CVMetalTextureGetTexture」を呼び出すと、目的のメタルテクスチャを取得します。

Swiftアプリケーションは、CVMetalTextureの強力なリファレンスを使用する必要がありますが、Objective-Cを使用する場合は、CVMetalTextureRefをリリースする前に、Metalがテクスチャで完了していることを確認する必要があります。

これは、金属コマンドバッファ補完ハンドラを使用して達成できます。

そして、それだけです、皆さん!

レビューするために、HDRビデオメディアをEDRにレンダリングし、再生、編集、または画像処理を行う多くのワークフローを調査しました。

HDRメディアを再生するために、AVPlayerからAVKitのAVPlayerViewControllerに行く方法を学びました。

また、AVPlayerLayerと一緒にAVPlayerを使用して、自分のビューでHDRメディアを表示する方法も学びました。

そして最後に、再生中にリアルタイムエフェクトを追加する方法を探りました。

AVFoundationのAVPlayerをCoreVideoに接続し、次にMetalに接続してレンダリングします。

また、CoreImageフィルターとメタルシェーダーを使用してリアルタイムエフェクトを適用します。

より深く掘り下げたい場合は、ビデオワークフローの作成と、HDRメディアとEDRの統合に関連するいくつかのWWDCセッションをお勧めします。

特に「AVFoundationでHDRビデオを編集して再生する」というセッションを呼び出したい。

このセッションでは、HDRメディアにエフェクトを適用するための「applyingCIFiltersWithHandler」を使用したAVVideoCompositionの使用を探ります。

このセッションでは、各ビデオフレームが処理可能になったときに、CVPixelBufferで使用できるカスタムコンポジターの使用方法も学びます。

冒頭で述べたように、今年はEDRに関する他の2つのセッションも発表します。EDR APIサポートがiOSを含むように拡大されたと発表した「iOSのEDR」と、「CoreImage、Metal、SwiftUIを使用したEDRを使用したHDRコンテンツ表示」で、EDRと他のメディアフレームワークとの統合をさらに検討します。

macOSとiOSの両方で、HDRビデオをEDR対応アプリケーションに組み込むことを願っています。

見てくれてありがとう。