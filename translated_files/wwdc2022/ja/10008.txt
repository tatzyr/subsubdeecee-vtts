10008

♪インストゥルメンタルヒップホップ音楽♪

♪

こんにちは、私はジョン・シェーンバーグで、アップルのロケーションテクノロジーチームのエンジニアです。

このセッションでは、近くのインタラクションにもたらした新機能について説明します。これにより、空間認識でより豊かで多様な体験を構築することができます。

近くのインタラクションフレームワークは、超広帯域技術のためのAppleのチップであるU1の機能を簡単に活用し、超広帯域用のAppleのU1チップと互換性のある近くのAppleデバイスまたはアクセサリ間で正確で空間的に認識された相互作用を作成することができます。

過去2年間に利用可能なものの簡単なレビューから始めましょう。

WWDC 2020でNearby Interactionが導入されたとき、その機能はU1を搭載した2台のiPhone間のセッションの作成と実行に焦点を当てました。

WWDC 2021では、Apple Watchとサードパーティの超広帯域対応アクセサリとのランニングセッションをサポートするように機能が拡張されました。

近くのインタラクションフレームワークのAPIを深く掘り下げることに興味がある場合は、2020年のWWDCトーク「近くのインタラクションに会う」と2021年の「サードパーティのアクセサリーで近くのインタラクションを探索する」を確認してください。

私たちは、近くのインタラクションに対するコミュニティの反応に圧倒され、このセッションでは、あなたのために新しい機能と改善を発表することに興奮しています。

私は2つの主要なトピックに焦点を当てます:ARKitとの近くの相互作用の強化とバックグラウンドセッション。

その過程で、近くのインタラクションフレームワークをより簡単に使用するいくつかの改善点を共有し、昨年発表されたサードパーティのハードウェアサポートのアップデートで締めくくります。

私たちは、あなたが新しい機能で何をするかに興奮しているので、詳細を掘り下げてみましょう。

ARKitと近くのインタラクションを緊密に統合するエキサイティングな新機能から始めます。

この新しい機能は、ARKitから計算されたデバイスの軌道を活用することで、近くのインタラクションを強化します。

ARKitで強化された近くのインタラクションは、AirTagでPrecision Findingを強化するのと同じ基盤技術を活用し、近くのインタラクションを介して利用できるようにしています。

最良のユースケースは、置き忘れたアイテム、関心のあるオブジェクト、またはユーザーが対話したいオブジェクトなど、特定の近くのオブジェクトにユーザーを誘導するエクスペリエンスです。

ARKitとNearby Interactionを統合することで、Nearby Interactionを単独で使用するよりも距離と方向情報がより一貫して利用でき、超広帯域の視野を効果的に広げます。

最後に、この新しい機能は、固定デバイスとの相互作用に最もよく使用されます。

ARKitと近くのインタラクションのこの新しい統合がアプリケーションで可能になる可能性のデモンストレーションに飛び込みましょう。

私はここに展示にユーザーを案内するのに役立つウルトラワイドバンドアクセサリーを持っている私のジェットパック博物館のためのアプリケーションを持っています。

次のジェットパックを探しに行きましょう。

ユーザーが次の展示に行くことを選択すると、アプリケーションは超広帯域アクセサリを発見し、近くのインタラクションの使用を開始するために必要な交換を実行します。

その後、アプリケーションは、ARKitを使用した強化された近くのインタラクションモードを使用して、次の展示の物理的な場所を決定し始める間、電話を左右に移動するようにユーザーに指示します。

アプリケーションが次の展示に対応する方向を理解したので、それをチェックアウトするために向かう方向をユーザーに指示する単純な矢印アイコンが表示されます。

ARKitと近くのインタラクションの組み合わせを利用したこの豊富で空間的に認識された情報は、展示がユーザーの後ろにあり、ユーザーが展示から離れた方向に向かっていることを示すことさえできます。

最後に、アプリケーションは、ARの世界で、次の展示の場所のオーバーレイを表示することができ、アプリケーションは、展示がARの世界でどこにあるかを解決するために、iPhoneを少し上下に動かすようにユーザーに促します。

ARコンテンツがシーンに配置されると、近くのインタラクションと超広帯域測定とARKitの強力な組み合わせにより、ユーザーは簡単に次のジェットパックをチェックアウトできます。

ジェットパックは見つからなかったかもしれませんが、女王を見つけました。

それでは、この強化された近くのインタラクションモードを有効にする方法を見てみましょう。

iOS 15では、おそらくアプリケーションに、近くのピアからNIDiscoveryTokenを受け入れ、セッション設定を作成し、NISessionを実行する方法があります。

ARKitで拡張モードを有効にすることは、NIConfigurationのサブクラスの新しいisCameraAssistanceEnabledプロパティを使用した近くのインタラクションの新規および既存の使用で簡単にできます。

ARKitで拡張モードを活用するために必要なのは、isCameraAssistanceEnabledプロパティの設定だけです。

2つのAppleデバイスとAppleデバイスからサードパーティの超広帯域アクセサリを操作する場合、カメラアシスタンスが利用できます。

カメラアシスタンスを有効にしてNISessionが実行されたときに何が起こるかの詳細を見てみましょう。

カメラ支援を有効にすると、近くのインタラクションフレームワーク内にARSessionが自動的に作成されます。

あなたはこのARSessionを作成する責任を負いません。

カメラアシスタンスを有効にしてNISessionを実行すると、Nearby Interactionフレームワーク内で自動的に作成されたARSessionも実行されます。

ARSessionは申請プロセス内で実行されています。

その結果、アプリケーションはアプリケーションのInfo.plist内でカメラの使用状況説明キーを提供する必要があります。

良い体験を提供するためにカメラが必要な理由をユーザーに知らせるために、これを便利な文字列にしてください。

特定のアプリケーションに対して実行できるARSessionは1つだけです。

つまり、アプリにすでにARKitエクスペリエンスがある場合は、作成したARSessionをNISessionと共有する必要があります。

ARSession を NISession と共有するには、NISession クラスで新しい setARSession メソッドを使用できます。

実行前にNISessionでsetARSessionが呼び出されると、セッションの実行時にARSessionは近くのインタラクションフレームワーク内で自動的に作成されません。

これにより、アプリケーションARKitエクスペリエンスは、近くのインタラクションのカメラアシスタンスと同時に実行されます。

このSwiftUIの例では、makeUIView関数の一部として、ARView内の基礎となるARSessionは、新しいsetARSessionメソッドを介してNISessionと共有されます。

ARSessionを直接使用する場合は、ARWorldTrackingConfigurationを使用してARSessionでrunを呼び出す必要があります。

さらに、カメラアシスタンスから高品質のパフォーマンスを確保するために、このARConfiguration内で特定の方法でいくつかのプロパティを設定する必要があります。

worldAlignmentは、重力、コラボレーション、userFaceTracking無効、nil initialWorldMap、およびsessionShouldAttempt Relocalizationメソッドがfalseを返すデリゲートに設定する必要があります。

作成したARSessionを共有する際のベストプラクティスに目を向けてみましょう。

NISessionDelegate didInvalidateWithエラーメソッドでは、常にエラーコードを検査します。

共有ARSessionの実行に使用されたARConfigurationが概説されたプロパティに準拠していない場合、NISessionは無効になります。

新しいNIErrorコードinvalidARConfigurationが返されます。

アプリで近くのオブジェクトの更新を受信するには、NISessionDelegateでdidUpdateNearbyObjectsメソッドを引き続き使用してください。

didUpdateNearbyObjectsメソッドでは、おそらく目的のピアの近くのオブジェクトをチェックし、利用可能な場合はNINearbyObjectの距離と方向のプロパティに基づいてUIを更新し、常にこれらを思い出すように注意してnilになる可能性があります。

カメラアシスタンスを有効にすると、NINearbyObject内で2つの新しいプロパティが利用可能になります。

1つ目は水平角度です。

これは、近くの物体への方位角方向を示すラジアンの1次元角度です。

利用できない場合、この値はnilになります。

第二に、verticalDirectionEstimateは、垂直次元の近くの物体との位置関係です。

これは新しいVerticalDirectionEstimateタイプです。

距離と方向は、ユーザーのデバイスと近くのオブジェクトとの間の重要な空間関係を表します。

距離はメートル単位で測定され、方向はデバイスから近くの物体までの3Dベクトルです。

水平角度は、NISessionを実行しているデバイスと、ローカル水平面内の近くのオブジェクトとの間の角度として定義されます。

これは、2つのデバイス間の垂直変位オフセットとデバイス自体の水平回転を考慮します。

方向は3Dですが、水平角度は2つのデバイス間の見出しの1D表現です。

この水平角度プロパティは、方向プロパティと補完され、方向を解決できない場合は、水平角度を使用して、ユーザーを近くのオブジェクトに誘導するのに役立ちます。

垂直方向の推定は、垂直位置情報の定性的評価です。

フロアレベル間でユーザーを導くためにそれを使用する必要があります。

それでは、新しいVerticalDirectionEstimateタイプを見てみましょう。

VerticalDirectionEstimateは、NINearbyObject内のネストされた列挙型であり、近くのオブジェクトとの垂直関係の定性的評価を表します。

プロパティを使用する前に、VerticalDirectionEstimateが不明かどうかを必ず確認してください。

垂直関係は、同じ、上、下、または近くのオブジェクトを表す特別なaboveOrBelow値が同じレベルではなく、デバイスの上または下に明確ではありません。

超広帯域測定は、視野と障害物の影響を受けます。

方向情報の視野は、デバイスの背面から投影する円錐に対応します。

カメラ支援が有効になっているときにARKitから計算されたデバイスの軌道により、距離、方向、水平角度、垂直方向の見積もりをより多くのシナリオで利用でき、超広帯域センサーの視野を効果的に拡大します。

それでは、ARKitと近くのインタラクションの統合を活用して、ARオブジェクトをシーンに配置しましょう。

近くのオブジェクトを表す3D仮想コンテンツをカメラフィードの視覚化に簡単にオーバーレイできるように、ヘルパーメソッドを追加しました。worldTransform on NISession。

このメソッドは、利用可能な場合、物理環境内の指定された近くのオブジェクトの位置を表すARKitの座標空間にworldTransformを返します。

利用できない場合、このメソッドはnilを返します。

デモンストレーションでこの方法を使用して、次の展示の上に浮遊球を配置しました。

近くのインタラクションの位置出力をできるだけ簡単に活用して、アプリのAR世界のコンテンツを操作できるようにしたいと考えています。

iOSの2つの強力なシステムの組み合わせ。

ユーザーは、カメラ支援が世界変換を適切に計算できるように、デバイスを垂直方向と水平方向で十分にスイープする必要があります。

この方法は、カメラの支援がARKitの世界変換に完全に収束するために、ユーザーの動きが不十分である場合、nilを返すことができます。

この変換がアプリ体験にとって重要な場合、この変換を生成するために行動を起こすようにユーザーを指導することが重要です。

デモンストレーションで見たものと同じようにユーザーを導くことを可能にするために、NISessionDelegateに加えたいくつかの追加を見てみましょう。

ユーザーをオブジェクトに導くのを助けるために、NISessionDelegateコールバックは、新しいdidUpdateAlgorithmConvergenceデリゲートメソッドを介して、近くのインタラクションアルゴリズムの収束に関する情報を提供します。

アルゴリズム収束は、水平角度、垂直方向推定、およびworldTransformが利用できない理由と、ユーザーがこれらのプロパティを解決するために実行できるアクションを理解するのに役立ちます。

デリゲートは、新しいNIAAlgorithmConvergenceオブジェクトとオプションのNINearbyObjectを提供します。

このデリゲートメソッドは、NIConfigurationでカメラアシスタンスを有効にした場合にのみ呼び出されます。

新しいNIAlgorithmConvergenceタイプを見てみましょう。

NIAlgorithmConvergenceには、NIAlgorithm ConvergenceStatusタイプであるシングルステータスプロパティがあります。

NIAlgorithmConvergenceStatus型は、アルゴリズムが収束しているかどうかを表す列挙型です。

アルゴリズムが収束しない場合、関連する値の配列 NIAlgorithmConvergenceStatus 。理由が提供されています。

新しいデリゲートメソッドに戻り、カメラアシスタンスのステータスをユーザーに更新したいとしましょう。コンバージェンスステータスをオンにして、不明または収束している場合は、その情報をユーザーに表示できます。

必ずNINearbyObjectを検査してください。

オブジェクトがnilの場合、特定のNINearbyObjectではなく、NIAAlgorithmConvergence状態がセッション自体に適用されます。

ステータスがコンバージされていない場合、アルゴリズムがコンバージされていない理由を説明する関連する値も含まれます。

このため、ローカライズされた説明は、ユーザーとのより良いコミュニケーションに役立ちます。

次に、これらの値の使い方を見てみましょう。

notConvergedのケースと関連する理由の値をより詳細に検査することで、近くのオブジェクトに関する必要な情報を生成するのに役立つアクションを実行するようにユーザーを導くことができます。

関連する値は、NIAlgorithmConvergence StatusReasonsの配列です。

その理由は、総動きが不十分、水平または垂直のスイープの動きが不十分、照明が不十分であることを示している可能性があります。

複数の理由が同時に存在する可能性があることに注意し、アプリケーションにとって最も重要なことに基づいて、各アクションを順番にユーザーを導きます。

デモンストレーションで電話を動かし、世界の変革を解決するために水平方向と垂直方向の両方をスイープする必要があったことを思い出してください。

これは、カメラアシスタンスによる強化された近くのインタラクションモードに関する最も重要な部分です。

このモードをよりよく活用できるように、いくつかの追加の変更を加えました。

以前は、特定のデバイスで近くのインタラクションがサポートされているかどうかを確認するために必要なのは、NISessionの単一のisSupportedクラス変数だけでした。

これは現在非推奨です。

カメラアシスタンスの追加により、新しいNIDeviceCapabilityオブジェクトを返すNISessionの新しいdeviceCapabilitiesクラスメンバーを使用して、Nearby Interactionでサポートされているデバイス機能をよりわかりやすくしました。

少なくとも、supportsPreciseDistance Measurementプロパティをチェックすることは、現在非推奨のisSupportedクラス変数と同等です。

デバイスが正確な距離測定をサポートしていることを確立したら、NIDeviceCapabilityを使用して、アプリケーションを実行しているデバイス上の近くのインタラクションから利用可能な機能を完全に理解する必要があります。

NIDeviceCapabilityオブジェクトの追加supportsDirectionMeasurementとsupportsCameraAssistanceプロパティをチェックして、アプリのエクスペリエンスをデバイスの機能に合わせて調整することをお勧めします。

すべてのデバイスが方向測定やカメラ支援をサポートするわけではないので、このデバイスの機能に合わせた体験を必ず含めてください。

特に、Apple Watchを最大限にサポートするために、距離のみの体験を含めることに留意してください。

ARKitとの近くのインタラクションを強化する方法として、カメラ支援のためのすべてです。では、アクセサリーのバックグラウンドセッションに注意を向けましょう。

今日では、アプリで近くのインタラクションを使用して、ユーザーが他のデバイスをポイントしたり、友達を見つけたり、アクセサリまでの距離や方向に基づいてコントロールやその他のUIを表示したりできます。

ただし、アプリがバックグラウンドに移行したり、ユーザーがiOSとwatchOSで画面をロックしたりすると、アプリケーションがフォアグラウンドに戻るまで、実行中のNISessionsは一時停止されます。

これは、アクセサリと対話する際に、実践的なユーザーエクスペリエンスに焦点を当てる必要があることを意味します。

iOS 16以降、近くのインタラクションはハンズフリーになりました。

近くのインタラクションを使用して、スマートスピーカーで部屋に入ったときに音楽の再生を開始したり、eBikeに乗ったときにeBikeをオンにしたり、アクセサリーで他のハンズフリーアクションをトリガーしたりできるようになりました。

ユーザーがアクセサリのバックグラウンドセッションでアプリを積極的に使用していない場合でも、これを行うことができます。

このエキサイティングな新しい機能を達成する方法を見てみましょう。

アクセサリでNISessionを設定して実行する方法について、シーケンスを確認しましょう。

昨年のWWDCプレゼンテーションからこのシーケンスを認識しているかもしれません。

アクセサリは、超広帯域アクセサリ構成データをデータチャネルを介してアプリケーションに送信し、このデータからNINearbyAccessoryConfigurationを作成します。

NISessionを作成し、NISessionDelegateを設定して、アクセサリから超広帯域測定を取得します。

設定でNISessionを実行すると、セッションは共有可能な設定データを返し、アプリケーションと相互運用するようにアクセサリをセットアップします。

この共有可能な構成データをアクセサリに送り返した後、アプリケーションとアクセサリで超広帯域測定を受信できるようになりました。

サードパーティ製アクセサリとの近くのインタラクションの設定と実行に関するすべての詳細については、昨年のWWDCセッションを確認してください。

それでは、新しいバックグラウンドセッションの設定方法を見てみましょう。

前のシーケンス図は、アプリケーションとアクセサリの間を流れるデータを示しました。

アクセサリとアプリケーション間の通信チャネルがBluetooth LEを使用することは非常に一般的です。

Bluetooth LEを使用してアクセサリとペアリングすると、近くのインタラクションを有効にして、バックグラウンドでセッションを開始および継続できます。

これがどのように可能かをよく見てみましょう。

今日では、アプリがバックグラウンドにある間に、Core Bluetoothを使用してBluetooth LEアクセサリでデータを検出、接続、交換するようにアプリを設定できます。

詳細については、既存のコアBluetoothプログラミングガイドまたは2017年のWWDCセッションをご覧ください。

Core Bluetoothの強力なバックグラウンド操作を利用して、アクセサリを効率的に検出し、バックグラウンドでアプリケーションを実行すると、アプリケーションはバックグラウンドで超広帯域をサポートするBluetooth LEアクセサリでNISessionを開始できます。

それでは、この新しいモードを反映するためにシーケンス図がどのように更新されるかを見てみましょう。

このアクセサリと対話するには、まずBluetooth LE-pairedであることを確認してください。

次に、アクセサリに接続します。

アクセサリがアクセサリの超広帯域構成データを生成すると、アプリケーションに送信し、近くのインタラクションGATTサービスに入力する必要があります。これについては次の詳細です。

最後に、アプリケーションがアクセサリの構成データを受信したら、アクセサリのUWB構成データとそのBluetoothピア識別子の両方を提供する新しい初期化子を使用して、NINearbyAccessoryConfigurationオブジェクトを構築します。

この構成でNISessionを実行し、NISessionDelegateで共有可能な構成を受信してセットアップを完了し、共有可能な構成をアクセサリに送信します。

アクセサリがBluetooth識別子と超広帯域構成の間に関係を作成するには、新しい近くのインタラクションGATTサービスを実装する必要があります。

近くのインタラクションサービスには、アクセサリ構成データと呼ばれる単一の暗号化された特性が含まれています。

NINearbyAccessoryConfigurationオブジェクトの初期化に使用されたのと同じUWB設定データが含まれています。

iOSはこの特性を使用して、Bluetoothピア識別子とNISessionの関連性を検証します。

あなたのアプリはこの特性から直接読み取ることはできません。

この新しいNearby Interaction GATTサービスの詳細については、developer.apple.com/ nearby-interactionをご覧ください。

アクセサリが複数のNISessionsを並行してサポートしている場合は、それぞれが異なるNISessionのUWB構成を持つアクセサリ構成データの複数のインスタンスを作成します。

それがアクセサリーに必要なものです。

いくつかのコードに飛び込んで、アプリケーションに実装する必要があるものに目を向けましょう!

アクセサリのバックグラウンドセッションでは、アクセサリがユーザーのiPhoneにLEペアリングされている必要があります。

あなたのアプリは、このプロセスをトリガーする責任があります。

これを行うには、アクセサリをスキャンし、接続し、そのサービスと特性を発見する方法を実装します。

次に、アクセサリの暗号化された特性の1つを読み取る方法を実装します。

あなたはこれを一度だけ行う必要があります。

ペアリングを受け入れるプロンプトがユーザーに表示されます。

アクセサリのバックグラウンドセッションには、アクセサリへのBluetooth接続も必要です。

アプリは、バックグラウンドでバックグラウンドされている場合でも、この接続を形成できる必要があります。

これを行うには、アクセサリへの接続試行を開始する方法を実装します。

アクセサリがBluetoothの範囲内にない場合でも、これを行う必要があります。

次に、CBManagerDelegateメソッドを実装して、Core Bluetoothによってアプリが再起動された後に状態を復元し、接続が確立されたときに処理します。

これで、アクセサリのバックグラウンドセッションを実行する準備が整いました。

アクセサリのUWB構成データとCBPeripheral識別子からのBluetoothピア識別子の両方を提供することで、NINearbyAccessoryConfigurationオブジェクトを作成します。

その設定でNISessionを実行すると、アプリがバックグラウンドになっている間に実行されます。

それでおそれ！

さて、Xcodeでアプリを更新する必要がある設定がもう1つあります。

このバックグラウンドモードでは、アプリのInfo.plistのUIBackgroundModes配列の近くのインタラクション文字列が必要です。

Xcodeの機能エディタを使用して、このバックグラウンドモードを追加することもできます。

また、アプリがバックグラウンドでアクセサリに接続できるように、「Bluetooth LEアクセサリを使用」が有効になっていることを確認する必要があります。

この新しいアクセサリーのバックグラウンドセッションに関する1つの重要な注意事項。

アプリケーションがバックグラウンドにある場合、NISessionは引き続き実行され、中断されないため、超広帯域測定はアクセサリで利用できます。

アクセサリの超広帯域測定値を消費し、行動する必要があります。

アプリケーションはランタイムを受信せず、アプリケーションがフォアグラウンドに戻るまでdidUpdateNearbyObjectデリゲートコールバックを受信しません。

この新しいバックグラウンドモードを使用する場合は、次のベストプラクティスを確認しましょう。

アクセサリとのLEペアリングをトリガーすると、ペアリングを受け入れるプロンプトがユーザーに表示されます。

アクセサリをペアリングしたい理由をユーザーにとって直感的な時間にこれを行います。

これは、セットアップフローで、アクセサリとの関係を作成するか、ユーザーがアクセサリと対話したいという欲求を明確に示している可能性があります。

アプリがバックグラウンドになっている間、NISessionは中断されませんが、didUpdateNearbyObjectデリゲートコールバックは受信されません。

しかし、あなたのアクセサリーは超広帯域測定を受けます。

これらの測定値をアクセサリで直接処理して、ユーザーにどのようなアクションが起こるべきかを判断します。

最後に、重要なユーザーインタラクション中にアクセサリからアプリにデータを送信するだけで、バッテリー使用量を管理します。たとえば、ユーザーに通知を表示します。

バックグラウンドセッションで知っておくべきことはそれだけであり、サードパーティのハードウェアサポートに関する最後のトピックに私を導きます。

本日、以前に利用可能なベータU1互換開発キットがベータ版から外れ、より広く使用できることを発表できることを嬉しく思います。

互換性のある超広帯域開発キットの詳細については、developer.apple.com /nearby-interactionをご覧ください。

また、近くのインタラクションGATTサービスを含む新しいアクセサリーバックグラウンドセッションをサポートするために、アクセサリーメーカーの仕様を更新し、同じウェブサイトで入手できます。

では、このセッションで話し合ったことをまとめましょう。

近くのインタラクションには、ARKitと近くのインタラクションを緊密に統合する新しいカメラ支援モードが含まれており、ユーザーを近くのオブジェクトに導く空間認識体験を作成するためのシームレスな体験を提供します。

アクセサリのバックグラウンドセッションを使用すると、セッションをバックグラウンドに開始および拡張して、ユーザーにとってよりハンズオフなエクスペリエンスを構築できます。

サードパーティ互換のウルトラワイドバンドハードウェアサポートのエキサイティングなアップデートを発表しました。

今年の近くのインタラクションのアップデートはこれで終わりです。

デモをダウンロードし、更新された機能に関するフィードバックを提供し、更新されたサードパーティの仕様を確認し、空間体験を備えた素晴らしいアプリを構築してください。

ありがとうございます。

♪