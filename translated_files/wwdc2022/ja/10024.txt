10024

♪ ♪

こんにちは、私の名前はブレット・キーティングです。ビジョンフレームワークの新機能をご紹介できることを嬉しく思います。

あなたはビジョンに不慣れかもしれません。

おそらく、これはあなたがビジョンフレームワークについて見た最初のセッションです。

もしそうなら、ようこそ。

あなたの利益のために、ビジョンフレームワークに関するいくつかのハイライトを簡単に要約しましょう。

あなたのためのいくつかのビジョンフレームワークの事実。

ビジョンは2017年に初めて導入され、それ以来、ビジョンが提供する技術で何千もの素晴らしいアプリが開発されてきました。

ビジョンは、時間の経過とともに成長し続けるコンピュータビジョンアルゴリズムのコレクションであり、顔検出、画像分類、輪郭検出などが含まれます。

これらの各アルゴリズムは、使いやすく一貫性のあるAPIを通じて利用可能になります。

ビジョンフレームワークで1つのアルゴリズムを実行する方法を知っていれば、それらをすべて実行する方法を知っています。

そして、Visionは、サポートするすべてのプラットフォームでApple Siliconを最大限に活用し、Visionの多くのアルゴリズムの中核となる機械学習を強化しています。

ビジョンはtvOS、iOS、macOSで利用でき、MacでApple Siliconを十分に活用します。

ビジョンフレームワークへの最近の追加には、ここに示されている人セグメンテーションが含まれます。

また、このデモで示されている手のポーズの見積もり。

そして、これはボディポーズの推定と軌道分析を使用するアクションとビジョンのサンプルアプリです。

今日の議題は、機能の向上、パフォーマンスの向上、または精度の向上を提供する可能性のある既存のリクエストの更新であるいくつかの新しいリビジョンの概要から始まります。

まず、テキスト認識の新しい改訂版があります。

これは、VNRecognizeTextRequestRevision3によって与えられた3回目の改訂版です。

これは、素晴らしいライブテキスト機能を強化するテキストリコグナイザです。

テキストリコグナイザはいくつかの言語をサポートしており、supportedRecognitionLanguagesを呼び出すことで、どの言語がサポートされているかを発見できます。

私たちは今、いくつかの新しい言語を追加しました、そして私はあなたにいくつかの例を紹介します。

私たちは今、ビジョンで韓国語をサポートしています。

これは、韓国語の領収書を転写する職場でのビジョンの例です。

そして、これは日本語の対応する例であり、この現在サポートされている言語でのVisionのテキスト認識の結果も示しています。

テキスト認識のために、新しい自動言語識別があります。

recognitionLanguages プロパティを使用して、使用する認識言語を指定できます。

しかし、アプリユーザーが認識しようとしている可能性のある言語を事前に知らないとします。

さて、正確な認識モードのためだけに、automaticDetectsLanguageをtrueに設定することで、テキストリコグナイザに言語を自動的に検出するように依頼することができます。

言語検出は時折これを間違える可能性があるため、どの言語を認識すべきかわからないような状況のためだけにこれを使用するのが最善です。

どの言語を認識するかについて予備知識がある場合は、これらの言語をVisionに指定し、automaticDetectsLanguageをオフにしておくのが最善です。

次に、VNDetectBarcodesRequestRevision3と呼ばれるバーコード検出の新しい3番目のリビジョンがあります。

この改訂は、以前の改訂から逸脱した、ボンネットの下で現代の機械学習を活用します。

バーコードには、店舗の製品によく見られるバーコードから、QRコード、ヘルスケアアプリケーションで使用される特殊コードまで、さまざまなシンボルがあります。

ビジョンがどのシンボルをサポートしているかを知るには、supportedSymbologiesを呼び出すことができます。

パフォーマンスについて話しましょう。

MLを使用していることもあり、一度に1つではなく、1つのショットで複数のコードを検出しているため、複数のコードを含む画像のリクエストが高速になります。

また、精度の向上により、多くのコードを含む特定の画像でより多くのコードが検出されます。

さらに、重複した検出はほとんどありません。もしあれば、

バウンディングボックスは、一部のコード、特に行が以前に返されたean13などの線形コードで改善されています。

これで、バウンディングボックスが表示されているコード全体を囲んでいます。

最後に、MLモデルは、過去に検出精度を妨げた曲面、反射、その他のアーティファクトなどを無視することができます。

テキスト認識とバーコード検出のためのこれらの新しい改訂の両方は、バーコードとテキストをスキャンして返すためにカメラストリームを設定するドロップインUI要素であるVisionKit Data Scanner APIの技術的基盤を形成します。

これは私たちのSDKへの本当に素晴らしい追加であり、詳細については、それについてのセッションをチェックすることを強くお勧めします。

今日お話しする最後の新しいリビジョンは、VNGenerateOpticalFlowRequestRevision2と呼ばれるオプティカルフロー要求の新しいリビジョンです。

バーコード検出器と同様に、この新しいリビジョンは、ボンネットの下で最新の機械学習も使用しています。

光学フローは最も長く研究されたコンピュータビジョンの問題の1つですが、テキストやバーコードなど、私たちの日常生活の一部を形成するものの検出と比較して、それが何をするのか気づいていないかもしれません。

オプティカルフローは、2つの連続した画像、通常はビデオからのフレームを分析します。

ユースケースによっては、2つの隣接するフレーム間の動きを見たり、その間にいくつかのフレームをスキップしたりするかもしれませんが、いずれにせよ、2つの画像は時系列順にする必要があります。

この分析は、動きの方向と大きさ、または第2の画像に正しく配置するために、いわば最初の画像のどれだけの部分を「移動」する必要があるかの推定値を提供します。

VNPixelBufferObservationは、画像内のすべての場所でこの動きを表す結果です。

それは2チャンネルの画像です。

1つのチャネルにはX等級が含まれ、もう1つのチャネルにはY等級が含まれています。

一緒に、これらはこの2D画像に配置された各ピクセルで2Dベクトルを形成し、その位置が入力として提供された画像の対応する場所にマップされるようにします。

これを視覚的に見てみましょう。

着信ビデオがあり、いくつかのフレームが入ってくるとしますが、特にこの2つの画像を見てみましょう。

ここでは、ビーチで走っている犬がいます。

左の画像から右の画像へ、犬が少し左に移動したようです。

この動議をどのように推定し、表現しますか?

さて、あなたはオプティカルフローを実行し、下の画像に似た何かに到達するでしょう。

暗い領域は動きが見つかった場所であり、それが実際に犬の形にそそのように見えることに注目してください。

それは、このシーンで犬だけが本当に動いているからです。

ベクトルからx、yをカラーパレットにマップする「偽色」を使用して、この画像のモーションベクトルを示しています。

この偽の色の表現では、「赤」の色合いは主に左への動きを示しています。

1つのフレームから例を見たので、ビデオクリップ全体でどのように見えるかを見てみましょう。

ここでは、ビーチで水筒を取ってくるこの犬の短いクリップの光学的流れを計算します。

左側はリビジョン1の結果です。

右側は、新しいMLベースのリビジョン2の結果です。

うまくいけば、リビジョン2の改善のいくつかは明らかです。

一つには、おそらく最も明らかに、水筒の動きははるかに正確にキャプチャされます。

また、犬の推定運動の一部の改善に気づくかもしれません。

私は尾の改善に最もはっきりと気づきますが、新しい改訂で彼の耳の動きが羽ばたきしているのも見ることができます。

最初のリビジョンには少しのバックグラウンドノイズの動きも含まれていますが、2番目のリビジョンは背景が動いていないことをより一貫して表しています。

うまくいけば、その例は、この技術が何をするかをあなたに良いアイデアを与えてくれました。

では、アプリでどのように使用するかについて少し掘り下げてみましょう。

明らかに、主なユースケースは、ビデオで局所的な動きを発見することです。

これは、セキュリティビデオのユースケースに直接フィードされ、バックグラウンドから逸脱した動きを特定してローカライズすることが最も重要であり、オプティカルフローはほとんどのセキュリティカメラなどの固定カメラに最も適していることに言及する必要があります。

Visionのオブジェクトトラッカーを使用して、ビデオ内で移動しているオブジェクトを追跡したい場合がありますが、トラッカーを初期化する場所を知る必要があります。

オプティカルフローはそこでもあなたを助けることができます。

独自のコンピュータビジョンや画像処理に精通している場合は、当社のオプティカルフロー結果を活用して、さらなるビデオ処理を可能にすることができます。

ビデオ補間、またはビデオアクション分析は、オプティカルフローが提供する情報から大きな利益を得ることができます。

それでは、リビジョン1とリビジョン2の重要な追加の違いを掘り下げてみましょう。

リビジョン1は、常に入力と同じ解像度の光フローフィールドを返します。

リビジョン2もデフォルトでこれを行います。

しかし、小さなしわがあります。部分的には、リビジョン2がMLベースであるという事実のために、基礎となるモデルの出力は、ほとんどの入力画像解像度と比較して比較的低い解像度です。

したがって、リビジョン1のデフォルトの動作に一致させるには、いくつかのアップサンプリングを行う必要があり、これを行うにはバイリニアアップサンプリングを使用しています。

これは、アップサンプリングが何をするかを説明する視覚的な例です。

左側には、ネットワーク出力のズームイン部分があり、これは低解像度であるため、ピクセル化されているように見えます。

全体的なフローフィールドのアスペクト比は7:5である可能性があります。

右側には、同じフィールドから取得した同様の領域があり、元の画像解像度にアップサンプリングされています。

おそらく、その画像も異なるアスペクト比を持っています、16:9としましょう。

フローフィールドのエッジがバイリニアアップサンプリングによって平滑化されていることに気付くでしょう。

アスペクト比が異なる可能性があるため、アップサンプリングプロセスの一環として、フローフィールドを画像で何が起こっているかに適切に対応するために、フロー画像が引き伸ばされることに注意してください。

ネットワーク出力を直接操作する場合は、フロー結果を元の画像にマッピングするときに、同様の方法で解像度とアスペクト比を考慮する必要があります。

リクエスト時にKeepNetworkOutputをオンにすることで、アップサンプリングをスキップするオプションがあります。

これにより、生のモデル出力が得られます。

利用可能な出力解像度を選択するために、リクエストに適用できる4つのcomputationAccuracy設定があります。

この表では、各精度設定の解像度を確認できますが、オブザベーションに含まれるピクセルバッファの幅と高さを常に確認してください。

いつネットワーク出力を使用し、いつVisionをアップサンプリングできるようにする必要がありますか?

デフォルトの動作は、すでにオプティカルフローを使用していて、その動作を下位互換性を維持したい場合に最適です。

アップサンプリング出力が必要な場合は良い選択肢であり、バイリニアは許容され、追加のメモリとレイテンシの価値があります。

ネットワーク出力は、完全な解像度を必要とせず、その場で対応を形成することができる場合、またはトラッカーを初期化したい場合に最適です。

フル解像度のフローが必要な場合は、ネットワーク出力も正しい選択かもしれませんが、独自のアップサンプリング方法を使用することを好みます。

これは、このセッションの新しいアルゴリズムの改訂をカバーしています。

ビジョンフレームワークで行っている春の大掃除と、それがあなたにどのような影響を与えるかについて話し合いましょう。

ビジョンが5年前に最初にリリースされたときに、各アルゴリズムの「リビジョン1」として、顔検出と顔のランドマークを最初に導入しました。

それ以来、より効率的で正確な技術を使用する2つの新しいリビジョンをリリースしました。

したがって、これらのアルゴリズムの最初のリビジョンをVisionフレームワークから削除し、2番目と3番目のリビジョンのみを維持します。

ただし、リビジョン1を使用する場合は、恐れることはありません。

リビジョン1を指定するコード、またはリビジョン1のみを含むSDKに対してコンパイルされたコードを引き続きサポートします。

どうしてそんなことが可能なの、あなたは尋ねるかもしれません。

リビジョン1は、この図で「リビジョン1検出器」と呼んだアルゴリズムをボンネットの下で実行します。

同様に、リビジョン2はリビジョン2検出器を使用します。

ビジョンのこのリリースのために行ったことは、リビジョン2検出器の出力でリビジョン1の要求を満たすことです。

さらに、リビジョン1のリクエストは非推奨としてマークされます。

これにより、古いリビジョン1検出器を完全に削除し、ビジョンフレームワークを合理化することができます。

これにはいくつかの利点があり、少なくともディスクのスペースを節約することで、OSのリリースとSDKのダウンロードとインストールが安価になります。

そこにいるすべてのビジョンの専門家は、「しかし、ちょっと待ってください」と自分自身に言っているかもしれません。リビジョン2は逆さまの顔を返しますが、リビジョン1はそうではありません。

この行動の違いは、いくつかのアプリに影響を与えませんでしたか?

リビジョン1の行動を維持するための予防措置を講じることを除いて、それは確かにそうするでしょう。

リビジョン2検出器から逆さまの面を返すことはありません。

同様に、リビジョン2のランドマーク検出器は、リビジョン1のランドマークコンステレーションと一致する結果を返します。

実行時間は同等であり、精度の向上を経験するはずです。

いずれにせよ、この変更は、アプリがコードに変更を加える必要はなく、物事は引き続き機能します。

それでも、私たちはあなたのために行動を促す呼びかけがあります。

はるかに優れたオプションが利用可能な場合、リビジョン1を使用することに満足すべきではありません。

常に最新のリビジョンを使用することをお勧めします。これらのリクエストについては、リビジョン3になります。

もちろん、この推奨事項の主な理由は、利用可能な最高レベルの精度とパフォーマンスを提供する最新の技術を使用することであり、誰がそれを望んでいませんか?

さらに、私たちは何度か確立し、コミュニケーションをとっており、デフォルトの動作に頼るのではなく、常にリビジョンを明示的に指定するベストプラクティスをここで繰り返します。

そして、それが私たちが春の大掃除のためにやったことです。

それでは、Visionフレームワークを使用するアプリのデバッグを容易にした方法について話しましょう。

ビジョンにクイックルックプレビューのサポートを追加しました。

これは特にビジョンにとって何を意味しますか?

さて、デバッガでVNObservationsにマウスポインタを合わせることができ、ワンクリックで入力画像で結果を視覚化できます。

また、これをXcode Playgroundsでも利用できるようにしました。

これがあなたのデバッグにどのように役立つかを本当に説明する唯一の方法は、あなたに示すことだと思います。

Xcodeのデモに移りましょう。

ここでは、顔のランドマークを検出し、顔の観察を返す簡単なルーチンがあります。

まず、顔のランドマークのリクエストを設定します。

その後、クラスで行く準備ができている画像があれば、それを表示します。

次に、結果を保持する配列を宣言します。

オートリリースプール内では、そのイメージでリクエストハンドラをインスタンス化し、リクエストを実行します。

すべてがうまくいったと仮定すると、リクエストから結果を取得できます。

結果を取得した後、それを実行してブレークポイントにたどり着きます。

だから今、私はデバッガの中にいます。

結果にマウスポインタを合わせると、オーバーレイは3つの顔を検出したことを示しています。

それはすごい。入力画像には3つの顔があります。

しかし、どの観察がどの顔であるかをどうやって知ることができますか?

そこで、クイックルックプレビューのサポートが登場します。

このリクエストに入ると、各「目」アイコンをクリックして結果を視覚化できます。

画像は、ランドマークの星座と顔の境界ボックスのために描かれたオーバーレイで表示されます。

これで、最初の観察が画像のどこにあるかがわかりました。

次のものをクリックして、2回目の観察と3回目の観察のオーバーレイを描くことができます。

次のブレークポイントに進み、フェイスオブザベーションをデバッグコンソールに出力するコードを実行します。

ご想像のとおり、顔情報が印刷されているデバッグコンソールでは、どの顔がどの顔であるか、またはこれらの印刷された座標からの結果が正しいように見えるかどうかをすぐに視覚化することはかなり困難です。

しかし、ここで指摘すべきことがもう1つあります。

自動リリースプールを導入することで、リクエストハンドラーを人為的にスコープから追い出したことに注意してください。

リクエストハンドラが範囲外になったので、結果にクイックルックプレビューのサポートをもう一度使用しましょう。

さて、あなたは何を知っていますか、オーバーレイはまだ描かれていますが、画像は利用できません。

これは覚えておくべきことです。オブザベーションを生成するために使用された画像要求ハンドラは、クイックルックプレビューが元の画像を表示に使用するために、まだどこかの範囲内にある必要があります。

これは、画像要求ハンドラが入力画像が存在する場所であるためです。

物事は引き続き機能しますが、画像は利用できません。

このクイックルックプレビューのサポートは、物事がどのように機能するかを確認するための簡単な実験を行いながら、Xcode Playgroundsセッションで特に役立ちます。

今、それを見てみましょう。 

ここでは、バーコードの画像を分析するためのシンプルなプレイグラウンドが設定されています。

このコードを通過するのではなく、いくつかの変更を加え、それが結果にどのように影響するかを確認しましょう。

異なるシンボルの2つのバーコードを持つ画像にリビジョン2を使用することから始めます。

すべての結果を要求すると、すべての結果が一度に表示され、最初の結果も最後に表示されます。

リビジョン2にはいくつかの問題があることに注意してください。

まず、最初のバーコードを見逃しました。

また、2番目のバーコードを2回検出しました。

そして、完全なバウンディングボックスではなく、バーコードを通る線を提供します。

リビジョン2ではなく、リビジョン3に変更するとどうなりますか？

まず、両方のバーコードを検出します。

そして、線の代わりに、完全なバウンディングボックスが与えられます。

このクイックルックプレビューサポートの素晴らしいところは、結果を視覚化するためにさまざまなユーティリティ関数を書く必要がなくなってきたことです。

デバッガまたはXcode Playgroundで画像に直接オーバーレイできます。

それがビジョンのクイックルックプレビューサポートです。

これで、どの観察がどれであるかをより簡単に知ることができます。

入力画像で使用するには、イメージリクエストハンドラをスコープ内に保つようにしてください。Xcode Playgroundのサポートにより、Visionフレームワークコードのライブチューニングがはるかに簡単になることを願っています。

本日、ビジョンの重要なアップデートを取り上げました。

すばやく確認するために、テキスト認識、バーコード検出、および光フローにいくつかの素晴らしい新しい改訂を追加しました。

更新されたリビジョンを追加し続けるにつれて、古いリビジョンも削除しますので、リビジョンを最新の状態に保ち、最新かつ最高の技術を使用してください。

また、今年はクイックルックプレビューのサポートにより、Visionアプリケーションのデバッグがはるかに簡単になりました。

このセッションを楽しんで、素晴らしいWWDCをお過ごしください。♪ ♪