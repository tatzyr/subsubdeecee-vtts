10063

♪ ♪

Dhruva: WWDC 2022へようこそ。

私の名前はDhruvaで、GPUSWエンジニアです。

今日、マッテオと私は、メタルで今年機械学習のために導入されたすべての新機能と機能強化を探ります。

機械学習トレーニングは、MLパイプラインの最も計算集約的なプロセスです。

並行性のため、GPUはMLワークロードに優れています。

メタル機械学習APIは、メタルパフォーマンスシェーダー、またはMPSと呼ばれるフレームワークを通じて公開されます。

MPSは、画像処理、線形代数、レイトレーシング、機械学習など、さまざまな分野の高性能GPUプリミティブのコレクションです。

これらのメタルカーネルは、すべてのプラットフォームで最高のパフォーマンスを提供するために最適化されています。

たとえば、MPSImageCannyフィルターは、入力画像のエッジマップを返します。

これは、画像セグメンテーションアプリケーションで一般的な操作です。

今年、Cannyフィルターは4Kの高解像度画像を最大8倍の速さで処理できます。

MPSグラフは、MPSフレームワークの上にあり、多次元テンソルへのサポートを拡張するGPUの汎用計算グラフです。

MPSグラフの使い方の詳細については、前のセッションを見ることをお勧めします。

CoreMLやTensorflowのような高レベルのMLフレームワークは、MPSグラフの上にあります。

TensorFlow Metalプラグインを使用して、GPU上でTensorFlowネットワークを高速化できます。

TensorFlowを最大限に活用する方法の詳細については、昨年のセッションをご覧ください。

Matteoと私はこのセッションで取り上げる3つのトピックがあります。

まず、Apple GPUに搭載される最新のMLフレームワーク、PyTorchを紹介します。

次に、今年のTensorFlowの機能強化について詳しく説明します。

最後に、マッテオはMPSグラフフレームワークの新機能について話します。

Mac GPUでPyTorchネットワークを高速化できることに本当に興奮しています。

PyTorchは、人気のあるオープンソースの機械学習フレームワークです。

PyTorchコミュニティで最も要求された機能の1番は、AppleシリコンでのGPUアクセラレーションのサポートでした。

PyTorchエコシステムに新しいMPSバックエンドを導入することで、MetalのパワーをPyTorchにもたらしています。

このバックエンドは、公式のPyTorch 1.12リリースの一部になります。

MPSバックエンドは、PyTorch操作カーネルとランタイムフレームワークを実装しています。

操作はMPSグラフとMPSを呼び出し、ランタイムコンポーネントはMetalを使用します。

これにより、PyTorchは、Metalのコマンドキュー、コマンドバッファ、および同期プリミティブとともに、MPSの高効率カーネルを使用できます。

オペレーションカーネルとPyTorch MPSランタイムコンポーネントは、オープンソースコードの一部であり、公式のPyTorch GitHubリポジトリにマージされています。

MPS PyTorchバックエンドの使用は、簡単な3段階のプロセスです。

まず、PyTorch 1.12から始めて、「pip install torch」を使用してベースパッケージをインストールできます。

このパッケージは、公式のPythonパッケージリポジトリで入手できます。

環境のセットアップとインストールの詳細については、Metal Developer ResourcesのWebページを参照してください。

次に、PyTorchをインポートし、MPSデバイスを作成します。

このコードスニペットは、利用可能な場合はMPSデバイスのバックエンドを使用し、そうでない場合はCPUにフォールバックします。

最後のステップは、モデルと入力をMPSデバイスを使用するように変換することです。

これを行う方法を実証するために、torchvisionから事前に訓練されたResNet50モデルで推論を実行する例を使用します。

デフォルトでは、モデルはCPUで実行されます。

「to」メソッドを使用して、モデルをMPSデバイスに変換することができます。

これにより、モデル内の中間テンソルも加速されたMPSバックエンドを使用することが保証されます。

最後に、モデルを実行できます。

この例では、ランダムな入力テンソルをMPSモデルに渡します。

デフォルトでは、すべてのテンソルはCPUに割り当てられます。

MPSバックエンドを使用するには、ここでmpsDeviceも提供する必要があります。

このテンソルのその後のすべての操作は、GPUで加速されます。

最後に、サンプル入力をMPSモデルに渡して予測を取得します。

MPSデバイスの使い方がわかったので、PyTorchの動作例を紹介します。

私はいつも有名なアーティストになりたいと思っていました。

そこで、機械学習とGPUを使用して、StyleTransferネットワークを使用してアートワークを作成することにしました。

このネットワークでは、画像に異なる芸術的スタイルを適用することができます。

この場合、目標は、この猫の写真に星空の夜のゴッホのスタイルを適用する方法を学ぶことです。

新しいMPSデバイスを使用すると、GPUを使用してPyTorchネットワークを大幅に高速にトレーニングできます。

これを実証するために、M1 MaxのCPUとGPUの両方で同時にこのネットワークのトレーニングを開始します。

このスタイルを学ぶには何千もの反復が必要ですが、GPUははるかに短い時間で合理的なモデルに収束することができます。

StyleTransferに加えて、これらすべてのPyTorchベンチマークで驚くべきスピードアップを見てきました。

M1 Ultraでは、最大20倍のスピードアップが見られ、平均8.3倍速くなりました。

PyTorchは機械学習モデルの開発を容易にし、Apple GPUを使用してそれらを訓練することで多くの時間を節約できます。

次に、今年TensorFlowに対して行ったすべての機能強化について詳しく説明します。

TensorFlow Metalアクセラレーションは、TensorFlow Metalプラグインを介してTensorFlowバージョン2.5から利用可能になりました。

それ以来、いくつかの追加機能と改善が追加されました。

これらには、より大きなバッチによるトレーニングの改善、新しい操作とカスタム操作のサポート、RNNの改善、および分散トレーニングが含まれます。

TensorFlow Metalプラグインのリリースは、主要なTensorFlowのリリースと一致しているため、TensorFlowパッケージを更新して最新の機能と改善点を確認してください。

より大きなバッチサイズから始めましょう。

今年のTensorFlow Metalのソフトウェア改善により、Appleシリコンアーキテクチャのユニークな利点を活用することができます。

このグラフは、さまざまなバッチサイズでResNet50モデルをトレーニングするスピードアップを示しています。

データは、各グラデーションの更新が真のグラデーションにより密接に対応しているため、より大きなバッチサイズでパフォーマンスが向上することを示しています。

Appleシリコンのユニファイドメモリアーキテクチャにより、より大きなネットワークやより大きなバッチサイズを実行できます。

これで、クラウドクラスターに分割するのではなく、単一のMac Studioでワークロードを実行できます。これは素晴らしいことです!

Apple Siliconアーキテクチャは、1ワットあたりのパフォーマンスも高いため、ネットワークはこれまで以上に効率的に実行されます。

次に、新しい操作とカスタム操作について説明します。

Tensorflow Metalプラグインは、argMin、all、pack、adaDeltaなど、さまざまな新しい操作のためのGPUアクセラレーションを備えています。

しかし、現在TensorFlow APIでサポートされていない操作のGPUアクセラレーションが必要な場合はどうなりますか?

これを行うには、カスタム操作を作成する必要があります。

2回の反復で実行されている単純な畳み込みネットワークの例を次に示します。

タイムラインは、それぞれ上下のGPUとCPUで行われた作業を表しています。

ネットワークは畳み込みを行い、続いてmaxpool-ingを行い、次にソフトマックスクロスエントロピー損失を行います。

これらの操作はすべて、MPSグラフを介してTensorFlow MetalプラグインでGPUアクセラレーションされますが、カスタム損失関数を使用することをお勧めします。

このカスタム損失に対するMPS GPUアクセラレーションがなければ、その作業は同期オーバーヘッドを導入し、GPUを飢えさせるCPUタイムラインで実行する必要があります。

GPUでこのカスタム損失を行うことで、はるかに優れたパフォーマンスを達成できます。

カスタム操作を実装するには、TensorFlow Metal Streamプロトコルを理解する必要があります。

これは、GPU操作をエンコードするために使用するプロトコルです。

Metalストリームには、GPUカーネルをエンコードするために使用するMTLCommandBufferへの参照があります。

また、複数のスレッドが作業を送信する可能性があるため、エンコード中にCPU側の同期に使用するdispatch_queueを公開します。

commitまたはcommitAndWaitメソッドを使用して、GPUに作業を送信します。

CommitAndWaitは、シリアル化された送信を観察できるように、現在のコマンドバッファが完了するまで待つデバッグツールです。

では、これらの概念を使用してカスタム操作を実装する方法を見てみましょう。

カスタム操作を書くには3つのステップがあります。

まず、操作を登録します。

次に、MetalStreamを使用して操作を実装します。

そして最後に、操作をトレーニングスクリプトにインポートして使い始めます。

操作の登録から始めます。

TensorFlowコアによって公開されるREGISTER_OPマクロを使用して、opのセマンティクスと、TensorFlow Metalプラグインでどのように定義するかを指定します。

次に、TensorFlow_MetalStreamを使用してopを実装します。

「計算」関数を定義することから始めます。

さて、この関数内で、入力のTensorFlow_Tensorオブジェクトを取得し、割り当てが必要な出力を定義します。

次に、Metalストリームのコマンドバッファを使用してエンコーダを作成します。

次に、カスタムGPUカーネルを定義します。

あなたのopは、Metalストリームによって提供されるdispatch_queue内でエンコードされている必要があります。

これにより、複数のスレッドからの提出物がシリアル化されることが保証されます。

次に、TensorFlow_MetalStreamプロトコルで提供されるメソッドを使用してカーネルをコミットします。

最後に、割り当てられたテンソルへの参照を削除します。

最後に、操作をトレーニングスクリプトにインポートして使用を開始します。

このステップでは、zero_out.soと呼ばれるカスタムopの共有動的ライブラリファイルをビルドします。

.soファイルの構築とインポート方法については、Metal Developer Resourcesを参照してください。

この例では、オプションのステップであるTensorFlow load_op_libraryを使用して、操作をトレーニングスクリプトにインポートします。

これで、これはPythonラッパーのように機能し、カスタム操作をトレーニングスクリプトで呼び出すことができます。

次に、Neural Radiance Fields、またはNeRFと呼ばれる興味深いアプリケーションの例を紹介したいと思います。

より良いアルゴリズムのためにGPUアクセラレーションを有効にすることで、ネットワークのパフォーマンスを向上させるカスタム操作を書きました。

NeRFは、モデルの3Dビューを合成するために使用されるネットワークです。

トレーニングのために、NeRFは入力として、さまざまな角度からオブジェクトの画像を取ります。

NeRFネットワークは2つの積み重ねられた多層パーセプトロンで構成され、出力はモデルの体積表現です。

リアルタイムトレーニングのための重要なパフォーマンスの最適化は、ハッシュテーブルの実装を使用します。

この更新されたネットワークは、はるかに小さな多層パーセプトロンを可能にします。

TensorFlowはハッシュテーブルをネイティブにサポートしていないため、カスタムop機能を使用してMetalプラグインに実装します。

ハッシュテーブルのGPUアクセラレーションにより、NeRFをはるかに高速にトレーニングできます。

このMacBookから始めて、オリジナルの多層パーセプトロン実装を実行します。

合理的なものをレンダリングするには、少なくとも20エポックが必要ですが、各エポックは約100秒かかります。

つまり、何かが見られるまでに約30分かかるということです。

だから今、私は事前に30分間トレーニングするために残された事前にトレーニングされたチェックポイントファイルからトレーニングを再開します。

これはエポック20から始まります。

3Dモデルは、30分間のトレーニングの後でもぼやけて不明瞭です。

ネットワークがより明確なモデルを学ぶには、はるかに長いトレーニング時間が必要です。

カスタムハッシュテーブルなしの元の2つの積み重ねられた多層パーセプトロンアプローチは遅すぎます。

さて、このMacBookでは、カスタムハッシュテーブルを使用する最適化されたバージョンを開始します。

この実装はすでにはるかに明確なモデルをレンダリングすることができ、各エポックは学習に10秒しかかかりません。

このプロジェクトの詳細については、Metal Developer Resourcesにアップロードしたサンプルコードを確認してください。

NeRFは、ネットワークを超高速に実行するために、独自のカスタム操作にGPUアクセラレーションを実装する方法を示す多くのネットワークの1つにすぎません。

今後、あなたが作るすべての創造的なカスタマイズについて学ぶことを楽しみにしています。

次に、Apple GPUを使用してMLワークロードのトレーニングを配布する方法をお見せしたいと思います。

ワークロードのトレーニングを配布するために、トレーニングスクリプトの複数のインスタンスを別々のプロセスで実行し、各プロセスがモデルの単一の反復を評価できます。

各プロセスは、中央データストアからデータを読み取ります。

その後、モデルを駆け抜け、モデルの勾配を計算します。

次に、プロセスはグラデーションを平均化し、これを相互に通信するので、各プロセスは次の反復の前に同じグラデーションを持ちます。

最後に、モデルが更新され、すべての反復が使い果たされるまでこのプロセスを繰り返すことができます。

TensorFlowでこれを実証するために、Horovodと呼ばれる一般的なオープンソースフレームワークを使用した分散トレーニングの例を使用します。

Horovodは、リングオールリデュースアプローチを使用しています。

このアルゴリズムでは、Nノードのそれぞれが2つのピアと複数回通信します。

この通信を使用して、ワーカープロセスは各反復の前にグラデーションを同期させます。

Thunderboltケーブルで互いに接続された4つのMac Studiosを使用して、これを実際にお見せします。

この例では、画像の分類器であるResNetをトレーニングします。

各Mac Studioの横にあるバーは、このネットワークのトレーニング中のGPU使用率を示しています。

単一のMac Studioの場合、パフォーマンスは毎秒約200枚の画像です。

Thunderbolt経由で接続された別のMac Studioを追加すると、両方のGPUが最大限に活用されるため、パフォーマンスは毎秒400画像にほぼ倍増します。

最後に、さらに2つのMacスタジオを接続すると、パフォーマンスは毎秒800画像に向上します。

これは、コンピューティングバウンドトレーニングワークロードのほぼ線形スケーリングです。

それでは、TensorFlowの分散トレーニングパフォーマンスを見てみましょう。

このチャートは、1つ、2つ、4つのMac Studiosの相対的なスピードアップを示しています。

それらはリングトポロジで接続され、最新のTensorFlow MetalプラグインとHorovodを使用して、resNetやDistilBERTなどのコンピューティングバインドされたTensorFlowネットワークを実行します。

ベースは、単一のMac Studioでのパフォーマンスです。

グラフは、各GPUを追加してネットワークパフォーマンスが拡張されるため、複数のデバイスでGPUを活用してトレーニング時間を短縮し、すべてのAppleデバイスを最大限に活用できることを示しています。

今年TensorFlowでロック解除されたすべての改善と機能は、CPU実装に対する相対的なパフォーマンスを示すこのチャートで最高潮に達し、将来的にはさらに改善される予定です。

今、MatteoはMPSGraphフレームワークの新機能を共有します。

Matteo: ありがとう、Dhruva。

こんにちは、私の名前はマッテオで、GPUソフトウェアエンジニアです。

PyTorchとTensorFlowは、MPSGraphフレームワークの上にあります。

次に、MPSGraphは、MPSフレームワークによって公開された並列プリミティブを使用して、GPUでの作業を加速します。

今日は、MPSGraphでコンピューティングワークロードをさらに高速化するために使用できる2つの機能について説明します。

まず、2つのグラフ間で作業を同期できる新しい共有イベントAPIを紹介します。

次に、MPSGraphでさらに多くのことを行うために使用できる新しい操作について確認します。

共有イベントAPIから始めます。

同じコマンドキューでアプリケーションを実行すると、ワークロード間の同期が保証されます。

この例では、後処理や表示などの他のワークロードがディスパッチされる前に、コンピューティングワークロードが常に終了することが保証されています。

このような場合は、各ディスパッチ内でGPUの並列処理を活用します。

ただし、一部のアプリケーションは、GPUの最初の部分がコンピューティングに使用され、2番目の部分が後処理と表示に使用される、より多くの並列性の恩恵を受ける可能性があります。

これは、複数のコマンドキューでGPUに作業を提出することで達成できます。

残念ながら、この場合、計算が結果を出す前に後処理パイプラインが派遣され、データレースが導入される可能性があります。

共有イベントAPIを使用して、この問題を解決し、コマンドキュー間で同期を導入して、ワークフローの依存関係を確実に満たすことができます。

コード内で共有イベントを使用するのはとても簡単です。

2つのグラフで作業していると仮定しましょう。

1つ目は、コンピューティングワークロードを担当します。

2つ目は、後処理の作業負荷を担当します。

また、計算グラフの結果が後処理グラフの入力として使用され、異なるコマンドキューで実行されると仮定しましょう。

Metal System Traceの新しいMPSGraphトラックは、コマンドキューが互いに重なっていることを示しています。

これにより、データレースが発生します。

共有イベントを使用してこの問題を解決できます。

まず、Metalデバイスを使用してイベントを作成します。

次に、実行記述子でシグナルメソッドを呼び出し、イベント、アクション、および値を提供します。

次に、イベント変数と値を提供する2番目の記述子でwaitメソッドを呼び出すだけです。

これで、Metalシステムトレースは、2つのコマンドキューが順番に実行され、計算グラフと後処理グラフの間の依存関係が解決されたことを示します。

それが、共有イベントを使用して、アプリケーションの同期の問題を解決する方法です。

次に、MPSGraphでサポートされている新しい操作について説明します。

これらの操作により、フレームワークでさらに多くのことを行うことができます。

RNNから始めて、これらの新しい操作の詳細をいくつか見ます。

MPSGraphは現在、リカレントニューラルネットワークアプリケーション内で一般的に使用される3つの操作を公開しています。

これらはRNN、LSTM、およびGRUレイヤーです。

これらの操作はすべて同じように機能するので、今日はLSTMに焦点を当てます。

LSTM操作は、自然言語処理やその他のアプリケーションに一般的に使用されます。

この図は、LSTM操作がどのように機能するかを示しています。

詳細については、以前のWWDCセッションをご覧ください。

LSTMユニットは自分で実装できますが、これを行うには、このかなり複雑なカスタムサブグラフを作成する必要があります。

代わりに、リカレントユニットが必要とするすべてのGPU作業を効率的にエンコードする新しいLSTM操作を使用できます。

この新しい操作により、LSTMベースのCoreML推論モデルが大幅に高速になります。

新しいLSTM操作を使用するには、まずMPSGraphLSTMDescriptorを作成します。

アクティベーション機能を選択するなど、必要に応じて記述子のプロパティを変更できます。

次に、LSTMユニットをグラフに追加し、入力テンソルを提供します。

また、バイアスベクトル、および操作の初期状態とセルを指定することもできます。

最後に、記述子を提供します。

LSTMを設定するために必要なのはそれだけです。

他のRNN業務も同様に機能します。

これらの操作を試して、アプリケーションでどのようなスピードアップが得られるかを確認することをお勧めします。

次に、Max Poolingの改善されたサポートを紹介します。

最大プーリング操作は、入力テンソルとウィンドウサイズを取り、ウィンドウの各アプリケーションに対して、ウィンドウ内の入力の最大値を計算します。

画像の次元を減らすために、コンピュータビジョンで一般的に使用されています。

APIは、プーリング演算子によって抽出された最大値の場所のインデックスを返すように拡張されました。

グラデーションパスでインデックスを使用できます。グラデーションは、最大値が抽出された場所に伝播する必要があります。

新しいAPIはトレーニングにも機能します。

トレーニング中にインデックスを再利用すると、PyTorchとTensorFlowでは最大6倍高速になります。

これをコードで設定するには、まずGraphPooling記述子を作成します。

returnIndicesMode、例えばglobalFlatten4Dを指定できます。

次に、Return Indices APIを使用してグラフのプーリング操作を呼び出すことができます。

操作の結果は2倍です。

まず、プーリングTensor、そして2番目に、インデックスTensor。

トレーニングパイプラインなど、後で使用するためにindicesTensorをキャッシュできます。

MPSグラフは、トレーニンググラフの重みを初期化するために使用できる新しい並列乱数ジェネレータを公開するようになりました。

新しいランダム操作はPhiloxアルゴリズムを使用し、特定のシードに対してTensorFlowと同じ結果を返します。

新しい操作は、入力として状態テンソルを取ります。出力としてランダムテンソルと、2番目のランダム操作の入力として使用できる新しい状態テンソルを返します。

新しいランダム操作を使用するには、randomPhiloxStateTensorメソッドを呼び出します。

このメソッドは、指定されたシードで入力状態Tensorを初期化します。

次に、分布とデータ型を入力として取るRandomOp記述子を宣言します。

この例では、記述子は32ビット浮動小数点値の切り捨てられた正規分布を指定します。

正規分布と統一分布を使用することもできます。

平均、標準偏差、最小値、最大値を指定することで、分布特性をさらに定義できます。

最後に、shapeTensor、記述子、および作成したばかりのstateTensorを提供するランダムな操作を作成できます。

ランダムに加えて、MPSGraphは2つのビットベクトル間のハミング距離を計算するための新しいGPUアクセラレーション操作をサポートするようになりました。

同じ長さの2つの入力間で異なるビット数として定義されるハミング距離は、2つのシーケンス間の編集距離の尺度であり、バイオインフォマティクスから暗号学まで、いくつかのアプリケーションで使用されます。

HammingDistanceを使用するには、グラフ上のAPIを呼び出すと、primaryTensor、secondaryTensor、およびresultDataTypeを提供します。

新しいカーネルは、GPU上のバッチディメンションでのブロードキャストをサポートしていることに注意してください。

さて、非常に使いやすい新しいテンソル操作についてすべてお見せします。

たとえば、テンソルの次元を2次元から3次元に拡張できるようになりました。

そして、寸法を絞り戻すことができます。

また、いくつかのスライスと軸を提供してテンソルを均等に分割することもできます。

または、与えられた軸に沿ってテンソルを積み重ねます。

また、特定の入力形状のテンソル寸法に沿って座標値を生成することもできます。

たとえば、形状のテンソルを0軸に沿った座標で2×4で埋めることができます。

これは、range1D操作を実装するためにも使用できます。

たとえば、3から27までの数値の範囲を4単位で生成したいと仮定します。

最初に形状6のテンソルの次元0に沿って座標を作成することで、これを行うことができます。

次に、増分に掛けてオフセットを追加するだけです。

これらはすべて今年追加された新しい操作です。

これらすべての新しい操作により、MPSGraphを使用して、Appleのエコシステム全体でさらに多くのことを行い、より高いパフォーマンスを得ることができます。

さて、MPSGraphからAppleシリコンで得られるパフォーマンスの向上をお見せします。

Blackmagicは、MPS Graphを使用して機械学習ワークロードを高速化するDaVinci Resolveバージョン18をリリースしました。

マジックマスクは、機械学習を使用して画面上の動く物体を識別し、その上に選択的にフィルターを適用するResolveの機能です。

まず、以前のバージョンのResolveでこれがどのように機能するかを実演し、その後、現在のバージョンと比較します。

マスクを作成するには、ターゲットオブジェクトを選択するだけです。

オーバーレイを切り替えることでマスクを見ることができます。

マスクは、被写体の形状を正しくマークする赤い領域によって識別されます。

さて、ビデオを再生すると、マスクは画面上を移動するオブジェクトを追跡します。

これは素晴らしく見えますが、機械学習パイプラインがボンネットの下で実行されるため、かなり低いフレームレートで実行されています。

次に、MPSGraphを使用してMagic Maskネットワークを加速するResolveの最新バージョンに切り替えます。

同じタイムラインを再度実行すると、フレームレートは以前よりもずっと速くなります。

これにより、Appleシリコンでの編集体験がはるかに向上します。

これらは、MPSグラフを採用するだけで得られる種類のスピードアップです。

アプリにどのようなパフォーマンスをもたらすことができるかを探ることをお勧めします。

最後に、PyTorchのGPUアクセラレーションを活用できるようになり、プロジェクトはオープンソースになりました。

カスタム操作や分散トレーニングなど、TensorFlow Metalプラグインを使用してトレーニングワークロードを加速する新しい方法を見つけることができます。

最後に、MPSGraphフレームワークを使用して最も要求の厳しい機械学習タスクを最適化し、共有イベントと新しい操作を使用して、Appleシリコンを最大限に活用することができます。

Dhruvaと私は、アプリケーションでこれらの新機能をどのように使用するかを見るのが待ちきれません。

セッションをご覧いただきありがとうございます。素晴らしいWWDCをお過ごしください。