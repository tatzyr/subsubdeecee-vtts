110332

♪まろやかなインストゥルメンタルヒップホップ音楽♪

♪

ナマスカル！こんにちは、WWDC22へようこそ。

私の名前はCreate MLチームのエンジニアであるVrushali Mundheです。Create MLの新機能について皆さんと共有できることを嬉しく思います。

Create MLを使用すると、収集したデータを使用して強力な機械学習モデルを簡単にトレーニングして、ユニークなエクスペリエンスを提供し、アプリを強化できます。

Create MLはXcodeにバンドルされたアプリとして出荷され、コードなしでMac上でCore MLモデルをすばやく構築してトレーニングできます。

Create MLは、SDKで出荷されるSwiftフレームワークとしても利用できます。

APIを使用すると、モデルの作成を簡単に自動化したり、独自のアプリ内から直接トレーニングによるダイナミックな体験を作成したりできます。

Create MLのコア機能の詳細については、これらの以前のセッションをご覧ください。

このセッションでは、Create MLの新機能について説明します。

モデルの精度と有用性を評価するのに役立つCreate MLアプリの新機能から始めます。

その後、Create MLフレームワーク、その拡張機能、および独自のアプリのモデルを高度にカスタマイズする機能に注意を向けます。

モデル作成のための典型的なワークフローを見直すことから始めましょう。

特定されたタスクが与えられた場合、データを収集して注釈を付けることから始めます。

例えば、食料品を視覚的に識別したいとします。

この画像分類タスクでは、出発点は画像の収集とラベル付けです。ここでは、いくつかの果物と野菜。

Create MLは、アプリで使用できるこのデータからモデルをトレーニングするのに役立ちます。

しかし、このモデルを使用する前に、重要なステップは、それがどれほどうまく機能するかを評価することです。ここでは、トレーニングセットの一部ではなかった画像でモデルがどれほど正確であるかを確認しています。

評価によっては、追加のデータと変更されたトレーニング設定でモデルを反復するか、モデルが十分に機能したら、アプリに統合する準備が整いました。この評価にさらに焦点を当てたいと思います。

評価を実行するとき、私たちはしばしば、トレーニングから持ち出された新しいデータでモデルをテストすることによって測定された一連の指標に目を向けます。

トップレベルの精度メトリックを見ることから始めるか、クラスごとの統計に飛び込んで、モデルの行動の一般的な感覚と、訓練されたものを超えて一般化する能力を得ることができます。

最終的に、モデルはアプリでデータ駆動型のエクスペリエンスを強化する責任があり、評価中は、入力やシナリオのカテゴリの観点からモデルの主な長所と短所を特定したいと考えています。それはうまくいくか、期待を下回る可能性があります。

Create MLアプリには、モデル作成の旅のこの部分に役立つ新機能があります。

私が取り組んでいるプロジェクトをお見せしましょう。

ここでは、食料品を識別するためのモデルを作成するためのプロジェクトを設定しています。

私はトレーニングデータとしてさまざまな果物や野菜の画像を収集し、適切にラベル付けすることから始めました。

これは私の異なるクラスと各クラスの画像の数です。

私はすでに25回の反復のために画像分類器を訓練しました。

次に、[評価]タブをクリックすると、新しいテストデータを追加できます。これは、テスト用に取っておいたトレーニングデータとは別に、一連の画像です。

次に、[評価]をクリックしてテストを開始します。

評価が完了すると、UIは結果の詳細を提供します。

上部には、テストの精度をすばやく把握できる高レベルの要約セクションがあります。

ここでは、このテストデータの精度は89%です。

このメトリクスタブの下にある表は、各クラスの豊富なメトリクスを提供します。

これらのドロップダウンメニューを使用してここに表示されているものを調整し、偽陽性や偽陰性などの指標を追加できます。

これらのクラスの1つを復習しましょう。

トマトはどうですか？

このモデルは、32枚のトマト画像のうち29枚を正しく分類しました。

また、このクラスの精度が91%であることを示しています。これは、モデルが何かがトマトであると言う時間の9%を意味し、それは間違っています。

これらの数字と統計は非常に便利ですが、データ自体のコンテキストでそれらを見ることがさらに重要な場合があります。

精度をクリックすると、トマトとして誤って分類された画像が表示されます。

テストデータには、これらのケースの3つを次に示します。

各画像について、アプリはサムネイル、モデルが予測したクラス、およびその下にある真のラベルを表示します。

この最初の例では、モデルはこれをトマトに分類しましたが、ジャガイモとラベル付けされていました。

しかし、これは確かに私にはトマトのように見えます。

これは、テストデータが誤ってラベル付けされたケースのようです。

実際、これらの3つの例はすべて誤ってラベル付けされているようです。

これは簡単に対処できるはずです。

テストセットのラベル付けを再確認して再検討するようにメモします。

これは明らかに私の側のエラーでしたが、それが唯一のエラーの原因ですか?

私は私が選んだランダムなクラスのメトリクスを探索してここに来ました。

「どこから始めればいいの？」と疑問に思うかもしれません。

または、「次は何を探索すればよいですか?」

トップレベルの要約セクションは、あなたを助けるためにここにあります。

アプリは、あなたの探検を始めるのに最適な場所として役立つことができる最も重要な評価の詳細のいくつかを選択しました。

上からやり直して、成功したケースを確認させてください。

ここをクリックすると、この正しいカウント...

ここでは、モデルが正しく分類されたすべての162枚の画像をすばやく見ることができます。

次に、間違ったものをクリックして、すべての失敗のレビューと対比させてください。

合計で21の失敗があります。

これはまた誤ったラベルのトマトです。

目立つ他の種類のエラーがあるかどうか確認させてください。

いかがですか...これ？

この画像はニンジンとラベル付けされていますが、モデルはジャガイモと予測しています。

この小さなサムネイルではわかりにくいですが、この画像をクリックして確認して、より良いビューを取得しましょう。

まあ、これは私には足のように見えます。

これは明らかに私が慣れている長くて細いニンジンの形ではありませんが、ジャガイモとして簡単に混同する可能性があります。

おそらく、ニンジンのトレーニングデータにより多くの形状のバリエーションを追加することを検討する必要があります。

これもメモしておきます。

今回は、ファイル名の横にある矢印をクリックして、Finderのこの画像に移動します。

次のデータ収集で再検討したいことを思い出させるために、右クリックしてこれを赤のラベルを付けます。

この拡張されたビューの中から私の探検を続けさせてください。

このビューには、完全な予測結果も表示され、すべてのクラスにおけるモデルの信頼度がリストされていることに注意してください。

また、これらの左右の矢印を使用して例をナビゲートすることもできます。

ここから別の例に移ります。

これは興味深いケースです。

1つの画像に複数の野菜があります。

それはナスだと書いてあり、ここにナスがあるのは事実ですが、他のものもあります。

これが私のアプリで考慮すべき重要なユースケースであるかどうかを考える必要があります。

おそらく、UIは、一度に1種類の食料品のみを指すようにユーザーを導くことができるか、複数のタイプをサポートしたい場合は、画像分類器全体ではなく、オブジェクト検出器（アプリ内の別のテンプレート）の使用を検討することをお勧めします。

要約セクションに戻ると、トップの混乱についてこの行を確認させてください。

ここでは「ペッパー」と「ビーン」と書かれています。

クリックしてこのケースを調査しましょう。

ピーマンとラベル付けされた4つの画像は、誤って豆に分類されています。

これらは私にはスパイシーなピーマンのように見えますが、豆のように緑色だと思います。

モデルは一般的にピーマンに問題があるのだろうか。 

このクエリオプションをIncorrectからCort Correctに切り替えさせてください...

...これらの失敗を正しく分類されたピーマンと対比する。

32枚の画像を正しく分類しました。しかし、これらのほとんどがピーマンであることに気づきました。

トレーニングデータをチェックして、複数のピーマンをうまく表現していることを確認する必要があります。

この迅速な調査は、トレーニングとテストデータの量、質、多様性が機械学習にとってどれほど重要であるかを思い出させてくれました。

ほんの数分で、このアプリはラベル付けと表現に関するいくつかの問題を視覚的に特定するのに役立ちました。

トレーニングデータを微調整して、見た問題が解決するかどうかを確認する必要があります。

また、私が以前に考慮していなかったことを明らかにしました:ユーザーが1枚の写真で複数の野菜をキャプチャするとどうなりますか?

アプリのデザインについてもう少し考える必要があります。

評価するラベル付きデータのコレクションがあったため、この調査はすべて可能でした。

しかし、すぐにテストしたい、またはより多くのカメラアングルや照明条件を探求すべきかどうかを検討したいラベルのない例がある場合はどうなりますか?

プレビュータブが役立つのはここです。

同僚がここに送ってくれたいくつかの例をドラッグして、それがどれほどうまくいくかを見ることができます。

または、iPhoneをContinuityカメラとして使用して、これをライブでテストすることもできます。

私がこれらの実際の野菜を指摘すると、モデルはそれらをライブで正しく分類することができます。

これはコショウとトマトです。

要約すると、ラベル付けされたデータセットで訓練されたモデルの動作をより深く掘り下げることができます。

評価ペインには、拡張オプション付きの詳細なメトリックサマリーが提供されます。

新しいExploreタブは、現在画像分類器、ハンドポーズ分類器、およびオブジェクト検出テンプレートで利用可能な新しいインタラクティブUIで、関連するデータとともにテスト評価結果をフィルタリングして視覚化できるオプションを提供します。

ライブプレビューは、即時のフィードバックを可能にします。

画像分類器、ハンドアクション分類器、ボディアクション分類器テンプレートに拡張されています。

また、この機能を拡張して、接続されたウェブカメラから選択できるようにし、macOS VenturaのContinuityカメラもサポートしています。

これは、Create MLアプリの新機能の簡単な要約です。

Create MLフレームワークの新機能について話し合うためにシフトしましょう。

Create MLフレームワークは、macOS、iOS、iPadOSで利用できます。

今年は、tvOS 16へのサポートの一部を拡大します。

プログラマティックインターフェイスは、開発時にモデル作成を自動化できるだけでなく、ユーザーの入力やデバイス上の動作から直接学習する動的な機能を構築する多くの機会を開き、ユーザーのプライバシーを維持しながらパーソナライズされた適応性のある体験を提供します。

タスクのサポートはプラットフォームによって異なることに注意してください。

たとえば、表形式の分類器と回帰器はどこでも利用できますが、ビデオを含むものなど、より大きなデータと計算要件を持つタスクの中にはmacOSが必要です。

あなたが持つかもしれない一般的な質問の1つは、「私のアイデアをこれらのCreate MLの事前定義されたタスクの1つにマッピングできない場合はどうなりますか?」です。

この質問に答えるために、Create MLファミリーに新しいメンバーを導入します。Create ML Componentsです。

Create ML Componentsは、Create MLの基礎となる構成要素を公開します。

それらを組み合わせて、ユースケースに合わせてカスタマイズされたパイプラインとモデルを作成できます。

詳細については、これらのセッションをチェックすることを強くお勧めします。

「Create ML Componentsを知る」では、ビルディングブロックとそれらをどのように構成できるかについて学びます。

「Create ML Componentsを使用して高度なモデルを作成する」では、非同期時間的コンポーネントの使用とトレーニングのカスタマイズについて詳しく説明します。

無限の能力があります。私が個人的に興奮しているものを紹介しましょう：アクションの繰り返しカウント。

私が働いていないとき、おそらくあなたは私が踊っているのを見つけるでしょう。

私は専門的に訓練されたインドのクラシックダンスのカタックアーティストです。

私のフォームを改善するために、私はしばしば自分のルーチンを繰り返し練習することに頼っています。

振付師/教師として、パフォーマーに特定のカウントのステップを練習し、私に提出してもらいたいと思います。

Create MLの新しい繰り返しカウント機能は、実際にそれを行うのに役立ちます!

ここでは、これはチャッカー - 回転 - カタックダンスの不可欠な部分です。

私は自分のフォームとスタミナを構築するために、毎日特定のカウントのためにこれを練習したいと思います。

私は自分の動きを数えるCreate MLを使用して構築されたiOSアプリを持っています。

実際にやってみましょう。

私がチャッカーを取ると、カウントはそれに対応するように増加します。

ここで、私は5つのチャッカーをしました、そしてカウントはまさにそれを反映しています。

次に、右側と左側の動きで構成される別の小さなルーチンを試してみましょう。

カウンターはそれらを1つとしてカウントします。

ここでは、カウントは3を示しています。

別の簡単な片側腕の動きを試してみましょう。

それは4です。

アクション分類と組み合わせると、繰り返しアクションを同時にカウントして分類できます。

繰り返しカウントはランタイムAPIとして利用できます。

トレーニングデータを必要とせず、この機能をアプリに追加するのはほんの数行のコードです。

その実装は、クラスに依存しないように設計された事前訓練されたモデルに基づいています。

つまり、ジャンピングジャック、スクワット、トワール、チャッカーなどのフィットネスやダンスアクションに機能しますが、さまざまな全身反復アクションにも適用できます。

サンプルコードとこのセッションにリンクされている記事をチェックすることで、このモデルと潜在的なユースケースについて詳しく知ることができます。

つまり、Create MLの新機能の簡単な概要です。

Create MLアプリのインタラクティブな評価とライブプレビューでは、トレーニングするモデルの理解を深めることができます。

Create MLフレームワークは、tvOSサポート、繰り返しカウントを追加し、アプリケーションのニーズに合わせて高度にカスタマイズされたモデルを構築するのに役立つ、基礎となるコンポーネントの豊富なセットにアクセスできるように拡張されています。

ありがとう、そして私はあなたがこれらすべてのエキサイティングな新機能を楽しんだことを願っています、そして私たちはあなたがそれらで何をするかを見るのが待ちきれません!

♪