10078

♪まろやかなインストゥルメンタルヒップヒップミュージック♪

♪

こんにちは、私はVidhi Goelです。このビデオでは、アプリのネットワーク遅延を減らし、より応答性を高める方法について話します。

まず、アプリをレスポンシブにするためにレイテンシを減らすことが重要である理由を説明します。

次に、不必要な遅延を取り除くために、アプリとサーバーでできることのリストを調べます。

最後に、ネットワーク自体の遅延を減らすために何ができるかを紹介します。

ネットワークレイテンシは、データが1つのエンドポイントから別のエンドポイントに取得するのにかかる時間です。

コンテンツがアプリにどれだけ早く配信できるかを決定します。

ネットワークを使用するすべてのアプリは、ネットワークトランザクションが遅くなり、アプリ体験が悪くなる可能性があります。

たとえば、ビデオ通話がフリーズしたり、遅れたりして、会議を中断することがあります。

これに対処するために、人々はしばしば帯域幅をアップグレードするためにサービスプロバイダーに電話をかけますが、それでも問題はまだ存在します。

この問題の根本原因を突き止めるには、アプリのパケットがネットワーク内でどのように移動するかを理解する必要があります。

アプリやフレームワークがサーバーからデータを要求すると、パケットはネットワークスタックによって送信されます。

多くの場合、パケットはネットワークに遅延なくサーバーに直接送信されると仮定されます。

しかし、実際には、ネットワークの最も遅いリンクには、通常、処理するパケットの大きなキューがあります。

したがって、アプリからのパケットは、その前のパケットが処理されるまで、実際にはこの大きなキューの後ろで待ちます。

最も遅いリンクでのこのキューイングは、アプリとサーバー間の各往復の期間を延ばします。

この問題は、アプリのリクエストに対する最初の応答を得るために複数の往復が必要な場合に悪化します。

たとえば、TCPでTLS 1.2を使用するときに最初の応答パケットを取得する時間は、各往復の期間に4回のトリップを乗じた時間です。

各往復時間は、ネットワーク内のキューイングによってすでに膨らんでいることを考えると、結果として生じる合計時間は単に長すぎます。

アプリの応答性を決定するために乗算する2つの要因があります。各往復の期間と往復の回数です。

これらを減らすと、アプリのレイテンシが下がり、アプリの応答性が向上します。

ページの読み込み時間に対する帯域幅の増加とレイテンシの減少の影響を調べる研究がありました。

最初のテストでは、レイテンシは固定され、帯域幅は1から10Mbpsに段階的に増加します。

最初は、帯域幅を1から2Mbpsに増やすと、ページの読み込み時間がほぼ40%短縮され、これは素晴らしいことです。

しかし、4Mbpsの後、増加するたびに、ページの読み込み時間がほとんど改善されません。

これが、ギガビットインターネットにアップグレードした後でもアプリが遅くなる可能性がある理由です。

一方、レイテンシテストの結果は、レイテンシが20ミリ秒減少するごとに、ページの読み込み時間が直線的に改善されることを示しています。

そして、これらの結果は、アプリ内のすべてのネットワークアクティビティに適用されます。

さて、レイテンシを減らし、アプリの応答性を高めるための簡単なアクションをいくつか確認します。

IPv6、TLS 1.3、HTTP/3などの最新のプロトコルを採用することで、アプリのレイテンシを大幅に削減できます。

そして、アプリでURLSessionとNetwork.framework APIを使用するだけで、これらのプロトコルはサーバーで有効にすると自動的に使用されます。

展開以来、HTTP / 3の使用が絶えず増加しており、わずか1年以内にWebトラフィックの20%がすでにHTTP / 3を使用しており、成長を続けています。

異なるHTTPバージョンのSafariトラフィックを比較すると、HTTP/3はそれらすべての中で最速です。

HTTP/3リクエストは、リクエスト完了時間の中央値を往復時間の倍数として見ると、HTTP/1と比較して半分強の時間がかかります。

これは、アプリのリクエストがはるかに速く完了することを意味します。

デバイスがWi-Fiから携帯電話に移動すると、新しい接続を再確立するのに時間がかかり、アプリケーションが停止する可能性があります。

接続移行を使用すると、これらのストールが排除されます。

オプトインするには、URLSession 設定または NWParameters で multipathServiceType プロパティを .handover に設定します。

このオプションを有効にして、アプリで動作することを確認してください。

UDPを直接使用する独自のプロトコルを設計する場合、iOS 16とmacOS Venturaはデータグラムを送信するより良い方法を導入します。

QUICデータグラムは、プレーンUDPよりも多くの利点を提供します。最も重要なのは、QUICデータグラムがネットワーク内の輻輳に反応し、ラウンドトリップ時間を低く抑え、パケット損失を減らすことです。

クライアントをオプトインするには、QUICオプションでisDatagramをtrueに設定し、使用する最大データグラムフレームサイズを設定します。

データグラムフローを作成した後、他のQUICストリームと同じように送受信できます。

これで、待ち時間を減らすためにアプリで何をすべきかがわかりました。

次に、サーバーがアプリの応答性にどのように影響するかを説明します。

最高級のハードウェアで実行されることが多いにもかかわらず、サーバーが実際にアプリの低速化の原因になる可能性があります。

macOS Montereyにネットワーク品質ツールを導入しました。このツールを使用して、サービスプロバイダーのネットワークとサーバーのバッファの肥大化を測定できます。

ネットワーク品質ツールの宛先として機能するようにサーバーを設定する必要があります。

完了したら、まずAppleのデフォルトサーバーに対して、次に自分で設定したサーバーに対して、networkQualityツールを実行します。

ツールがデフォルトのサーバーを使用してうまく採点するが、自分のサーバーと話すときにあまりうまくない場合は、サーバーの応答性を向上させる余地があるかもしれません。

さて、このテクニックを使用して、皆さんが今やっていること、つまりストリーミングビデオを改善した例を紹介します。

ビデオの別の場所にスキップして、リバフしている間に長時間待つことになるという経験があるかもしれません。

そこで、ランダムアクセスにおけるこの遅さの理由を調査しました。

ネットワーク品質ツールを使用してストリーミングサーバーの動作をテストしたところ、応答性スコアが低いことがわかりました。

右側では、WWDCのビデオをストリーミングしました。

それから、私はビデオで先にスキップしました。

ビデオが再バッファリングされている間、画面には何も表示されませんでした。

数秒後、ビデオが現れました。

macOSのネットワーク品質ツールからの詳細な出力の助けを借りて、サーバーに巨大なキューイングがあることがわかりました。

そこで、サーバーの設定を見てみました。

具体的には、それぞれ4MB、256KB、4MBに設定されたTCP、TLS、およびHTTPバッファサイズを調べました。

RAMが豊富であるため、バッファは巨大でした。

しかし、いくつかのバッファリングが良いからといって、必ずしもより多くのバッファリングが良いとは限りません。

私たちの応答性の測定は、この正確な問題を強調しました - 新しく生成されたパケットは、これらの大きなバッファの古いデータの後ろにキューに入れられ、これは最新のパケットの配信に多くの追加の遅延を引き起こしました。

そのため、バッファサイズをHTTPの場合は256KB、TLSの場合は16KB、TCPの場合は128KBに縮小しました。

これは、設定されたオプションを示すApache Traffic Serverの設定ファイルです。

TCPが送信されていないローウォーターマークは、バッファリングを下げるために有効になった他のオプションとともに128KBに設定されました。

TLSでは、動的レコードサイズを有効にし、HTTP/2では、低ウォーターマークとバッファブロックサイズを減らしました。

Apacheトラフィックサーバーにこれらの構成を使用することをお勧めします。別のWebサーバーを使用している場合は、同等のオプションを探してください。

これらの変更を行った後、ネットワーク品質ツールを再び実行しました。

そして、今回は高いRPMスコアを獲得しました!

右側では、同じビデオをストリーミングしましたが、今回はスキップすると、ビデオがすぐに再開されました。

サーバーでの不要なキューイングを取り除くことで、ランダムアクセスの応答性が向上しました。

アプリがネットワークをどのように使用しているかに関係なく、サーバー上のこれらの変更により、アプリの応答性が向上し、ユーザーエクスペリエンスが向上します。

それがあなたのアプリを改善し、サーバーを更新する方法です。

応答性に大きな影響を与える3番目の要因があります。ネットワーク自体です。

Appleは、iOS 15とmacOS Montereyにネットワーク品質ツールを導入した。

それ以来、他の人は同じ方法論を使用してネットワーク品質テストを開発してきました。

波形はバッファブロートテストを開始しました。

Goで書かれた応答性テストのオープンソース実装があります。

そして、OoklaはSpeedtestアプリに応答性測定を追加しました。

Ooklaのアプリは往復時間をミリ秒単位で表示し、60,000をその数で割ると、1分あたりの往復数、つまりRPMが表示されます。

これらのツールを使用して、自分のネットワークがどれだけうまく機能しているかを測定できます。

ネットワークの遅延を理解する最善の方法は、遅延に敏感なアプリケーションです。

だから、私の画面共有体験をリモートマシンに見せます。

私は、そのネットワークを共有する他のデバイスからのトラフィックを使用して、代表的なアクセスネットワークを模倣するようにネットワーク条件を設定しました。

ここでは、画面共有を使用してリモートマシンにログオンしました。

異なるFinderメニューをクリックしましたが、各メニューの表示が非常に遅かったです。

このインタラクションがどれだけ遅れたかを確認するために、ローカルマシンで時間を表示するアプリを起動し、リモートマシンで同じアプリを起動しました。

これらのコンピュータの時間は同期されていますが、私のリモート画面は定期的に更新されておらず、時間が数秒遅れています。

この更新が遅れた理由は、ネットワークの最も遅いリンクに大きなキューが存在し、画面共有アプリからのパケットがこの大きなキューで立ち往生していたためです。

このキューイングの問題を解決するために、AppleはL4Sと呼ばれる新しい技術でネットワーキングコミュニティと協力しています。

iOS 16とmacOS Venturaでベータ版として利用可能です。

L4Sは、キューイングの遅延を大幅に削減し、混雑損失をゼロにします。

一貫して短いキューを維持するために、ネットワークはパケットをドロップするのではなく、明示的に輻輳を通知し、送信者はネットワークからの輻輳フィードバックに基づいて送信速度を調整します。

これにより、パケットの損失なしにネットワーク内で非常に低いキューイングを維持することが可能になり、アプリは非常に応答性が高くなります。

さて、L4Sが画面共有をどのように改善したかを見てみましょう。

ここでは、同じマシンと同じネットワークを使用しましたが、今回はL4Sを有効にしました。

別のFinderメニューをクリックすると、すぐに開きました。

私は両方のマシンでタイムアプリを起動しました。

そして今、リモート画面とローカルマシンの両方の時間はほぼ完全に同期しています。

この技術は画面共有のためだけではありません。

L4Sは今日のすべてのアプリを改善し、今日でも不可能な将来のアプリの扉を開きます。

このチャートは、同じネットワークを共有する他のデバイスからのトラフィックと同時に実行されていた画面共有アプリからのパケットの観測された平均往復時間をプロットします。

古典的なキューイングとL4Sを比較すると、L4Sとの往復時間が大幅に短縮されることを示しています。

これが私の画面共有体験が劇的に改善された主な理由です。

L4SでHTTP/3またはQUICを使用するアプリをテストします。

開発者設定内のiOS 16またはデフォルトの書き込みを介してmacOS VenturaでL4Sを有効にすることができます。

Linuxサーバーを使用してテストするには、QUICの実装は正確なECNとスケーラブルな輻輳制御アルゴリズムをサポートする必要があります。

L4S対応ネットワークが展開されたときに準備ができていることを確認するために、L4Sとの互換性についてアプリをテストし、遭遇する可能性のある問題についてフィードバックを提供します。

これで、アプリの応答性を向上させるには、レイテンシを減らすことが不可欠であることを知っています。

したがって、HTTP/3とQUICを採用して、往復の数を減らし、アプリへのコンテンツの配信を高速化します。

サーバー上の不要なキューイングを排除して、より応答性の高いインタラクションを提供します。

開発者設定で有効にして、アプリのL4Sとの互換性をテストし、フィードバックを提供します。

そして最後に、L4Sサポートを有効にすることについてサーバープロバイダーに相談してください。

見てくれてありがとう!

♪