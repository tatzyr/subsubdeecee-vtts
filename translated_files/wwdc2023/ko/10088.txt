10088

♪ 부드러운 기악 힙합 ♪

♪

존 칼스비크: 환영합니다!

저는 존이고, RealityKit에서 일하고 있습니다.

블라디미르 부키체비치: 그리고 저는 유니티에서 온 블라드입니다.

존: 몰입형 앱에 대한 유니티 지원을 소개하게 되어 기쁩니다.

유니티는 이 새로운 플랫폼에 완전한 유니티 경험을 제공하기 위해 애플과 협력했다.

유니티는 수만 개의 앱에서 사용되며, 이제 유니티를 사용하여 몰입형 앱을 만들 수 있습니다.

트라이밴드는 유니티로 만들어진 애플 아케이드 타이틀인 What The Golf?를 이 플랫폼에 가져왔다.

아이폰으로 플레이하는 것은 정말 재미있고, 이런 식으로 플레이하는 것은 기분이 좋다.

유니티와 함께 이 플랫폼에서 몰입형 경험을 만들기 위한 두 가지 주요 접근 방식이 있습니다.

몰입형 경험으로 또는 다른 앱과 함께 공유 공간에서 패스스루를 사용하여 콘텐츠를 실제 물체와 혼합하는 경험을 만들 수 있습니다.

당신은 또한 플랫폼에 완전히 몰입형 유니티 경험을 가져올 수 있습니다.

이 접근 방식에 관심이 있다면, "Unity VR 앱을 완전히 몰입형 공간으로 가져오세요"를 확인하는 것이 좋습니다.

유니티와 공유 공간을 위한 경험을 만드는 것은 당신의 앱에 흥미진진한 기회를 열어줍니다.

여기 당신에게 더 말해줄 블라드가 있습니다.

블라디미르: 고마워, 존.

유니티와 애플은 당신의 유니티 콘텐츠가 플랫폼에서 멋지게 보이도록 하기 위해 지난 2년 동안 협력해 왔습니다.

기존 프로젝트로 시작하든, 완전히 새로운 것을 구축하든, 유니티는 친숙한 도구와 새로운 기능을 사용하여 몰입형 경험을 만들 수 있는 훌륭한 도구입니다.

이 플랫폼에서는 유니티의 셰이더와 재료를 사용하여 원하는 시각적 모양을 얻을 수 있습니다.

우리는 장치에 직접 플레이 모드로 전환할 수 있는 기능을 도입하여 반복 시간을 개선하고 있습니다.

유니티 장면의 콘텐츠가 현실 세계로 어떻게 도입되는지 제어하는 볼륨 카메라라는 새로운 개념도 있습니다.

이 새로운 장치에 대한 입력은 룩 앤 탭 제스처만큼 간단하거나 더 복잡한 상호 작용을 포함할 수 있다.

그리고 공간 컴퓨팅을 위한 유니티 콘텐츠를 준비하기 위해 오늘 할 수 있는 몇 가지가 있습니다.

여기 함께 작동하는 이러한 요소 중 일부의 예가 있습니다.

이 장면은 유니티의 셰이더 그래프로 만들어진 재료를 사용하며, 패스스루가 있는 시뮬레이터의 공유 공간에 표시됩니다.

뒤에 있는 오거처럼 완전히 조작된 애니메이션 캐릭터가 있다.

물리학 상호 작용은 당신이 익숙한 것처럼 작동합니다.

이 마을의 모든 주민들은 캐릭터 내비게이션을 사용하여 돌아다니고 있으며, 사용자 지정 동적 스크립트 동작은 이 장면이 살아있음을 느끼게 하는 데 사용됩니다.

우리는 Asset Store의 도움으로 2주 안에 이것을 모았고, 당신이 가까이서 어떤 각도에서든 장면을 볼 수 있는 당신의 공간에서 볼 때 멋져 보입니다.

공유 공간의 모든 콘텐츠는 RealityKit을 사용하여 렌더링됩니다.

당신의 유니티 자료와 셰이더는 이 새로운 환경으로 번역되어야 합니다.

유니티는 당신을 위해 이 번역을 처리하고 이 환경에 많은 유니티 기능을 제공하는 PolySpatial을 만들었습니다.

PolySpatial은 재료, 일반 및 스킨 메쉬 렌더링, 입자 효과 및 스프라이트를 번역합니다.

유니티 시뮬레이션 기능이 지원되며, MonoBehaviours, 스크립트 가능한 개체 및 기타 표준 도구를 계속 사용합니다.

세 가지 범주의 자료가 번역되었다.

그것들은 물리적으로 기반한 재료, 맞춤형 재료, 그리고 일부 특수 효과 재료이다.

유니티의 물리적 기반 셰이더를 기반으로 한 자료는 RealityKit으로 직접 변환됩니다.

유니버설 렌더링 파이프라인을 사용하는 경우, 재료에 Lit, Simple Lit 또는 Complex Lit Shaders를 사용할 수 있습니다.

내장된 파이프라인을 사용하면 표준 셰이더를 사용할 수 있습니다.

이 모든 것은 RealityKit PhysicallyBasedMaterial로 번역됩니다.

사용자 지정 셰이더와 재료 유형은 유니티 셰이더 그래프를 통해 지원됩니다.

유니티 셰이더 그래프는 복잡한 재료의 표준 교환 형식인 MaterialX로 변환됩니다.

MaterialX 셰이더는 RealityKit에서 ShaderGraphMaterial이 된다.

많은 유니티 셰이더 그래프 노드가 지원되므로 복잡하고 흥미로운 효과를 만들 수 있습니다.

손으로 쓴 셰이더는 RealityKit을 통한 렌더링에 지원되지 않지만, Unity의 RenderTextures와 함께 사용할 수 있습니다.

그런 다음 그 RenderTexture를 RealityKit을 통해 표시하기 위한 셰이더 그래프의 텍스처 입력으로 사용할 수 있습니다.

두 가지 추가 재료 셰이더 유형이 지원됩니다.

첫 번째는 조명의 영향을 받지 않는 단색이나 질감을 가진 물체를 만들 수 있는 Unlit Shader입니다.

두 번째는 물체를 통해 통과할 수 있는 오클루전 셰이더이다.

월드 메쉬 데이터와 함께 오클루전 셰이더를 사용하여 콘텐츠가 현실 세계와 더 통합될 수 있도록 할 수 있습니다.

Unity MeshRenderers와 SkinnedMeshRenderers는 지원되며 시각적 콘텐츠를 실제 공간으로 가져오는 주요 방법입니다.

조작된 캐릭터와 애니메이션을 사용할 수 있습니다.

유니버설 또는 내장 렌더링 파이프라인을 사용할 수 있으며, 콘텐츠는 Unity PolySpatial을 통해 RealityKit으로 변환됩니다.

RealityKit이 최종 렌더링을 수행하기 때문에 후처리 효과 및 사용자 지정 파이프라인 단계와 같은 렌더링 기능을 사용할 수 없습니다.

유니티의 슈리켄 시스템을 사용하는 입자 효과는 호환되는 경우 RealityKit의 입자 시스템으로 변환되거나 구운 메쉬로 변환됩니다.

스프라이트는 3D 메쉬가 되지만, 공간적 맥락에서 어떻게 사용하는지 고려해야 합니다.

PolySpatial은 Unity와 RealityKit 간의 렌더링을 최적화하고 번역하기 위해 작동합니다.

Unity의 시뮬레이션 기능은 물리학, 애니메이션 및 타임라인, Pathfinding 및 NavMesh, 사용자 지정 MonoBehaviours 및 기타 비렌더링 기능과 같이 익숙한 것처럼 작동합니다.

모양을 미세 조정하고 반복 속도를 높이기 위해, Unity PolySpatial은 "장치로 재생"을 가능하게 합니다.

장치에서 콘텐츠가 어떻게 보이는지 보기 위해 빌드 프로세스를 거치는 데 시간이 걸릴 수 있습니다.

PolySpatial을 사용하면 처음으로 장치 플레이에 액세스할 수 있습니다.

장치에서 재생하면 장면의 즉각적인 미리보기를 보고 실시간으로 변경할 수 있습니다.

그것은 시뮬레이터에서 작동하며 장치에서도 잘 작동합니다.

Play to Device를 사용하여 요소 추가 및 제거를 포함하여 콘텐츠의 배치와 크기를 빠르게 탐색할 수 있습니다.

재료, 텍스처, 심지어 셰이더 그래프를 변경하여 패스스루로 콘텐츠를 제자리에 보면서 모양을 미세 조정할 수 있습니다.

이벤트가 편집기로 다시 전송되기 때문에 상호 작용을 테스트할 수 있습니다.

시뮬레이션은 계속 실행되므로, 편집기에 첨부하기만 하면 쉽게 디버깅할 수 있습니다.

여기 당신이 전에 본 것과 같은 성 장면이 있습니다.

왼쪽의 유니티에서 열었고, 장치로 플레이하면 오른쪽의 시뮬레이터에서 실행되는 것을 볼 수 있습니다.

내 장면으로 드래그하는 것만으로도 더 많은 오거를 추가할 수 있다.

그것들은 시뮬레이터나 장치에서 즉시 볼 수 있다.

분홍색이나 네온 그린 오거가 어떻게 생겼는지 보고 싶다면, 할 수 있어.

Play to Device는 콘텐츠를 반복하기 위한 매우 효율적인 워크플로우이며, 현재 Unity에서는 공유 공간에서 콘텐츠를 만들기 위해서만 사용할 수 있습니다.

유니티를 사용하여 공유 공간에 참여하는 볼륨 콘텐츠를 만들고 있기 때문에, 볼륨 카메라라는 새로운 개념을 사용하면 장면이 현실 세계로 어떻게 도입되는지 제어할 수 있습니다.

볼륨 카메라는 경계와 경계가 없는 두 가지 유형의 볼륨을 만들 수 있으며, 각각 다른 특성을 가지고 있다.

당신의 지원서는 언제든지 둘 사이를 전환할 수 있습니다.

제한된 볼륨은 다른 앱과 게임과 함께 공유 공간에 볼륨으로 존재한다.

그들은 유니티의 차원과 변형뿐만 아니라 특정 실제 크기를 가지고 있다.

그것들은 재배치될 수 있지만, 사람들은 크기를 조정할 수 없다.

볼륨 카메라의 크기와 변환은 앱이 볼륨으로 표시할 장면의 영역을 정의합니다.

그것들은 장면 단위로 지정되어 있다.

유니티의 장면 보기에서 녹색으로 볼륨의 미리보기를 볼 수 있습니다.

볼륨 카메라의 치수와 변환을 조작함으로써, 장면의 다른 부분을 볼륨으로 가져올 수 있다.

카메라를 움직이거나 돌리면, 내 공간에서 새로운 물체가 보이게 된다.

크기를 늘리면, 더 많은 장면이 시야에 들어온다.

두 경우 모두, 볼륨은 같은 크기로 유지된다.

그 안에서 보이는 내용만 바뀐다.

볼륨 카메라의 초기 배치에서 스프링이 볼륨의 측면과 교차한다는 것을 주목하세요; 콘텐츠는 RealityKit에 의해 잘립니다.

볼륨의 가장자리와 교차하는 콘텐츠가 있다면, 잘린 부분을 채우기 위해 뒷면을 향한 재료로 장면에 같은 메쉬를 두 번째로 배치하는 것을 고려해 보세요.

무제한 볼륨은 이 플랫폼의 전체 공간에 표시되며 콘텐츠가 패스스루와 완전히 혼합되어 몰입감 있는 경험을 할 수 있습니다.

그것은 당신의 전체 장면을 선택하기 때문에 차원이 없으며, 그 변환은 당신의 장면 단위가 실제 단위에 어떻게 매핑되는지 지정합니다.

한 번에 하나의 무제한 볼륨 카메라만 활성화될 수 있습니다.

우리가 상호 작용에 대해 이야기할 때 무제한 볼륨의 예를 보게 될 것입니다.

유니티는 이 플랫폼에서 앱에 대한 여러 입력 유형을 지원합니다.

이 플랫폼에서, 사람들은 눈과 손을 사용하여 콘텐츠를 보고 손가락을 탭하여 선택합니다.

전체 손 추적과 머리 포즈 데이터를 사용하면 현실적인 상호 작용을 만들 수 있습니다.

ARKit의 증강 현실 데이터는 키보드와 게임 컨트롤러와 같은 블루투스 장치와 마찬가지로 사용할 수 있습니다.

탭 제스처는 이 플랫폼의 콘텐츠와 상호 작용하는 가장 일반적인 방법입니다.

당신의 물체가 이러한 이벤트를 수신하려면, 입력 충돌기가 구성되어 있어야 합니다.

멀리서 물체를 보고 탭하여 선택하거나, 손가락으로 물체를 직접 만질 수 있습니다.

최대 두 개의 동시 탭 동작이 진행될 수 있습니다.

유니티에서 탭은 월드터치 이벤트로 사용할 수 있습니다.

그것들은 2D 탭 이벤트와 비슷하지만, 완전한 3D 위치를 가지고 있다.

손과 머리 자세 추적은 각 손 관절과 글로벌 추적 원점에 대한 시청자의 머리 위치에 대한 정확한 정보를 제공합니다.

낮은 수준의 손 데이터는 유니티의 손 패키지를 통해 제공되며, 머리 포즈는 입력 시스템을 통해 제공됩니다.

이 두 가지 모두 무제한 볼륨에서만 사용할 수 있으며, 손 추적에 액세스하려면 애플리케이션이 데이터를 받을 수 있는 권한을 요청해야 합니다.

감지된 평면, 세계 메쉬 및 이미지 마커와 같은 증강 현실 데이터는 ARKit과 Unity의 AR Foundation을 통해 사용할 수 있습니다.

손과 머리 포즈와 마찬가지로, AR 데이터는 무제한 볼륨에서만 사용할 수 있으며 추가 권한이 필요합니다.

마지막으로, 키보드, 컨트롤러 및 기타 지원되는 장치와 같은 블루투스 장치는 유니티의 입력 시스템을 통해 액세스할 수 있습니다.

일부 유형의 입력은 무제한 볼륨에서만 사용할 수 있기 때문에, 어떤 유형의 상호 작용을 구축하고 싶은지 결정해야 합니다.

룩 앤 탭을 사용하면 콘텐츠가 다른 응용 프로그램과 함께 살 수 있는 제한된 볼륨에서 작동할 수 있지만, 손 추적 또는 증강 현실 데이터에 액세스해야 하는 경우, 무제한 볼륨을 사용하고 권한을 요청해야 합니다.

이들 각각은 적절한 메커니즘을 통해 유니티 애플리케이션으로 전달됩니다.

이 샘플은 무제한 볼륨 장면에서 태핑, 손 추적 및 평면 감지를 사용합니다.

ARKit 평면 감지를 통해 발견된 표면을 보고 손가락을 따라 드래그하여 꽃을 만들 수 있습니다.

꽃은 손 추적을 사용하여 칠해져 있으며, 탭하여 꽃을 키울 수 있습니다.

당신이 키우는 꽃은 유니티의 물리학 시스템을 사용하여 손의 움직임에 반응합니다.

이런 식으로 현실 세계를 콘텐츠에 통합함으로써, 당신은 훨씬 더 깊은 몰입감을 만들 수 있습니다.

기존 상호 작용을 조정하는 가장 좋은 방법은 유형에 따라 다릅니다.

이미 iPhone과 같은 터치로 작업하고 있다면, 적절한 입력 충돌기를 추가하고 탭을 기본 입력 메커니즘으로 계속 사용할 수 있습니다.

VR 컨트롤러를 사용하는 경우, 얼마나 복잡한지에 따라 탭 또는 수동 입력 측면에서 상호 작용을 재정의해야 합니다.

기존의 수동 기반 입력은 변경 없이 작동해야 한다.

그리고 유니티의 UI 시스템 중 하나를 사용하는 기존 UI 패널이 있다면, 이 플랫폼으로 가져올 수 있습니다.

uGUI를 사용하여 구축된 사용자 인터페이스 요소와 UI 툴킷이 지원됩니다.

다른 UI 시스템을 사용하는 경우, 메쉬와 MeshRenderer를 사용하거나 메쉬에 배치되는 RenderTexture에 그리는 한 작동합니다.

Apple 플랫폼의 공간 컴퓨팅 지원은 Unity 2022를 기반으로 한 베타 버전으로 곧 제공될 예정입니다.

하지만, 당신은 오늘부터 콘텐츠를 준비하기 시작할 수 있습니다.

새로운 프로젝트를 시작하는 경우, 유니티 2022 이상을 사용하세요.

기존 프로젝트가 있다면, 2022년으로 업그레이드를 시작하세요.

프로젝트에 손으로 쓴 셰이더가 있다면, 셰이더 그래프로 변환하기 시작하세요.

유니버설 렌더링 파이프라인을 채택하는 것을 고려해 보세요.

내장 그래픽 파이프라인이 지원되는 동안, 향후 모든 개선 사항은 유니버설 파이프라인에 있을 것이다.

아직 하지 않았다면, 입력 시스템 패키지를 사용하기 시작하세요.

혼합 모드 입력이 지원되지만, 플랫폼 이벤트는 입력 시스템을 통해서만 전달됩니다.

마지막으로, 기존 앱이나 게임을 공간 컴퓨팅에 어떻게 가져올 수 있는지, 또는 어떤 새로운 경험을 만들고 싶은지 생각해 보세요.

당신의 아이디어가 사람들에게 더 많은 유연성을 제공하기 위해 공유 공간에 맞는지, 아니면 앱에 전체 공간의 힘이 필요한지 고려하십시오.

이 플랫폼에 대한 유니티의 지원에 대한 자세한 정보를 얻고 초기 베타 액세스에 가입하려면 unity.com/spatial을 방문하십시오.

유니티와 이 새로운 장치로 만들 모든 놀라운 것들을 보게 되어 기쁩니다.

존: 유니티는 실행을 시작하고 몰입형 앱을 만드는 놀라운 방법입니다.

그리고 그것은 이 새로운 플랫폼에서 RealityKit과 잘 작동합니다.

오늘부터 프로젝트 준비를 시작할 수 있습니다.

유니티로 완전히 몰입할 수 있는 경험을 만들고 싶다면, "유니티 VR 앱을 완전히 몰입할 수 있는 공간으로 가져오세요" 세션을 추천합니다.

그리고 이 플랫폼을 위한 게임 개발 기술에 대한 개요를 얻기 위해 "공간 컴퓨팅을 위한 훌륭한 게임 만들기"를 놓치지 마세요.

우리는 네가 뭘 만드는지 빨리 보고 싶어.

블라디미르: 봐줘서 고마워.

♪