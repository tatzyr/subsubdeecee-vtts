10181

안녕! 내 이름은 잭슨이야.

그리고 난 데이비드야.

이 세션에서, 저는 HDR 이미지와 이 분야에서 최근에 발표된 표준에 대한 배경을 제공할 것입니다.

그런 다음 신규 및 기존 API를 사용하여 앱에서 이러한 이미지를 지원하는 방법을 다루겠습니다.

데이비드는 HDR 이미지 파이프라인 처리에 대한 세부 사항에 대해 자세히 알아볼 것이며, 나는 높은 다이내믹 레인지 콘텐츠를 표시하는 것과 관련된 몇 가지 고급 주제로 마무리할 것이다.

HDR이 어떻게 작동하는지 알아봅시다.

물리적 세계에서, 인간은 우리의 눈의 적응 능력 덕분에 엄청난 범위의 빛 수준을 인식할 수 있다.

대조적으로, 전형적인 표준 다이내믹 레인지 또는 SDR 디스플레이는 제한된 범위의 빛만 생산할 수 있다.

이것은 장면의 이미지가 캡처될 때, 넓은 범위의 조명 수준이 어떻게든 더 작은 SDR 범위로 압축되어야 한다는 것을 의미한다.

높은 다이내믹 레인지 또는 HDR 디스플레이를 사용하면 압축하지 않고도 훨씬 더 넓은 범위의 조명 수준을 표시할 수 있습니다.

이를 통해 원본 장면과 더 비슷하고 더 밝고 생생한 이미지를 표시할 수 있습니다.

우리는 수년 동안 높은 다이내믹 레인지를 캡처할 수 있었지만, 과거에는 캡처된 범위를 SDR 디스플레이 범위로 압축해야 했을 것입니다.

이제, HDR 디스플레이에 표시할 때, 원래 나타난 것처럼 장면을 렌더링할 수 있습니다.

예를 들어, 눈 장면 위의 일출 이미지에는 다양한 실제 조명 수준으로 떨어지는 영역이 있다.

SDR 디스플레이에서는 장면의 일부만 정확하게 나타낼 수 있습니다.

HDR 디스플레이를 사용하면 대비를 손상시키지 않으면서 훨씬 더 많은 장면을 표현할 수 있습니다.

따라서 HDR 범위의 디스플레이를 사용하면 가장 밝은 SDR 흰색보다 장면의 일부를 더 밝게 렌더링할 수 있습니다.

이것은 일반적으로 헤드룸이라고 불린다.

이 패러다임에서, 참조 흰색은 SDR 디스플레이가 생산했을 가장 밝은 흰색이다.

그 지점 위의 모든 것은 헤드룸이다.

지난 회담에서, 우리는 HDR 지원 디스플레이의 헤드룸에서 렌더링할 수 있는 콘텐츠와 상호 작용하기 위해 확장 다이내믹 레인지 또는 EDR을 도입했습니다.

EDR 패러다임에서, 참조 흰색은 1.0이며, 피크는 디스플레이가 나타낼 수 있는 최대 값이다.

오늘 소개하는 HDR API는 EDR을 사용하여 높은 다이내믹 레인지 콘텐츠를 위한 보다 완벽한 파이프라인을 구현합니다.

EDR에 대해 더 알고 싶다면, "EDR로 HDR 렌더링 탐색" 토크를 확인하세요.

다음은 작동 중인 HDR의 예입니다.

창문 앞에 앉아 있는 사람의 이 SDR 이미지는 책에 있는 종이의 흰색이 참조 흰색 바로 아래에 있을 때 좋아 보인다.

창문과 같이 더 밝은 것은 굴러가거나 잘린다.

그러나, HDR로 이미지를 표시할 수 있을 때, 하이라이트에서 훨씬 더 많은 세부 사항을 표시하고 장면 전체에서 대비를 더 안정적으로 유지할 수 있습니다.

이것은 HDR을 지원함으로써 얻을 수 있는 이점입니다.

그렇다면 왜 HDR 이미지를 지원하나요? 사용자가 만들거나 제공된 콘텐츠가 중요한 앱을 구축하는 경우, HDR을 지원하면 그 경험이 훨씬 더 좋아질 것입니다.

HDR 지원은 거의 모든 Apple 플랫폼에서 사용할 수 있으며, Apple의 놀라운 디스플레이 하드웨어를 최대한 활용할 수 있도록 이러한 API를 도입했습니다.

지금 HDR 지원을 고려해야 하는 또 다른 중요한 이유는 애플이 올해 HDR 이미지에 대한 새로운 기술 사양을 발표하기 위해 사진 기술 위원회를 통해 국제 표준 기구와 협력해 왔다는 것이다.

이 사양인 TS22028-5는 품질을 손상시키지 않으면서 HDR 콘텐츠를 기존 스틸 이미지 형식으로 인코딩하는 구조를 제공합니다.

HDR 비디오, 캡처 또는 디스플레이와 같은 다른 형태의 HDR과의 혼동을 피하기 위해 이 ISO 사양을 따르는 HDR 이미지를 "ISO HDR"이라고 부를 것입니다.

sRGB와 디스플레이 P3를 포함한 이전의 전형적인 SDR 이미지에서 우리의 규모를 상기하면서, 흑백을 제곱 미터당 0.2칸델라와 80칸델라로 정의합니다.

한편, ISO HDR은 검은색과 기본 참조 흰색을 각각 .0005와 203으로 정의한다.

203 위의 모든 것은 헤드룸이다.

그래서 이 새로운 이미지 파일에는 무엇이 있나요?

이 사양은 인코딩 전송 기능으로 Hybrid Log-Gamma, HLG 또는 Perceptual Quantizer, PQ가 필요합니다.

이것들은 SDR 이미지에 사용되는 감마 곡선과 기능적으로 유사하다.

ISO HDR 파일의 컬러 프라이머리는 BT.2020 프라이머리이다.

이것은 지금까지 비디오에서만 일반적으로 사용되는 넓은 색 공간이다.

밴딩 문제를 피하기 위해, HDR 이미지는 구성 요소당 10비트 이상이어야 합니다.

이것은 HEIF와 같은 일부 형식은 HDR을 인코딩할 수 있지만, 전통적인 JPEG와 같은 다른 형식은 구성 요소당 8비트만 지원하기 때문에 22028-5를 준수할 수 없다는 것을 의미합니다.

그리고 필요한 메타데이터의 경우, 전통적인 ICC 프로필과 CICP 태그가 모두 유효합니다.

이러한 요구 사항은 함께 새로운 ISO HDR 파일을 정의합니다.

당신과 관련이 있을 수 있는 ISO HDR 파일과 관련된 몇 가지 추가 선택적 메타데이터 필드가 있습니다.

참조 환경 태그는 콘텐츠 참조 조건의 주변 조건을 정의합니다.

확산 흰색 휘도는 참조 흰색이 이 콘텐츠에 해당하는 위치를 정의합니다.

기본값은 내가 앞서 언급한 203이다.

장면 참조 태그는 HLG가 전송 곡선일 때 사용할 수 있습니다.

그것은 이미지 내용이 장면인지 아니면 언급된 디스플레이인지를 정의한다.

이 태그의 기본값은 표시된다.

마스터링 및 콘텐츠 색상 볼륨 태그는 기존 HDR 비디오에 공통적이며 이미지에 존재하는 색상 범위에 대한 정보를 정의합니다.

마지막으로, 콘텐츠 라이트 레벨 태그는 이미지에서 장면의 라이트 레벨에 대한 정보를 제공합니다.

ISO HDR에 대한 자세한 내용은 ISO 웹사이트에서 사양을 확인하세요.

ISO HDR 외에도, iPhone에서 캡처한 최고의 이미지 버전에 액세스하는 방법을 처음으로 알려드리게 되어 매우 기쁩니다.

2020년부터, 수조 개의 iPhone 이미지가 SDR 이미지에서 HDR 표현을 재구성할 수 있는 추가 데이터로 캡처되었습니다.

나는 이런 종류의 HDR을 "Gain Map HDR"이라고 부른다.

오늘, 데이비드와 저는 앱에서 이 HDR 표현에 액세스하기 위한 새로운 API를 보여줄 것이며, 이미 사진 라이브러리에 있는 모든 세대의 게인 맵 HDR의 놀라운 HDR 이미지를 보여줄 수 있는 옵션을 제공할 것입니다.

이제 이 새로운 API를 사용하여 HDR 이미지를 앱에 통합하는 방법에 대해 이야기해 봅시다.

제가 보여드릴 API는 SwiftUI, UIKit 및 AppKit에서 사용할 수 있습니다.

SwiftUI와 UIKit API를 살펴봅시다.

이 예에서는 URL을 통해 액세스할 수 있는 ISO HDR 이미지 파일이 있으며, 이를 표시하고 싶습니다.

내가 해야 할 일은 UIImage를 만들고 높은 다이내믹 레인지를 활성화하기 위해 새로운 allowedDynamicRange 수정자와 함께 이미지 뷰에 제공하는 것이다.

그렇게 간단해.

마찬가지로, UIKit 앱에서 새로운 UIImageView 속성 "preferredImageDynamicRange"와 voila, HDR 결과를 설정할 수 있습니다.

다이내믹 레인지 속성에는 HDR 콘텐츠를 처리하는 방법에 대한 세 가지 옵션이 포함되어 있습니다.

이러한 속성은 SwiftUI 이미지, UIImage 및 NSImage 뷰에서 작동합니다.

높은 옵션을 사용하면 시스템이 높은 다이내믹 레인지 콘텐츠를 표시하고 싶다는 것을 알 수 있으며 디스플레이 상태가 변경될 때 업데이트를 포함하여 해당 콘텐츠를 현재 디스플레이에 매핑하는 무거운 작업을 수행할 수 있습니다.

이미지가 HDR이 아닌 경우, dynamicRange 플래그가 없는 것과 똑같은 경험을 할 수 있습니다.

HDR이 아닌 콘텐츠와 함께 이러한 옵션을 안전하게 사용할 수 있습니다.

표준 옵션은 높은 다이내믹 레인지 렌더링을 비활성화하고 대신 모든 콘텐츠를 SDR로 표시합니다.

이것은 SDR 범위를 벗어난 톤 매핑 콘텐츠를 의미합니다.

이것은 또한 HDR 기능이 없는 디스플레이에 이미지가 표시되는 방법이기도 하다.

마지막으로, 콘텐츠의 전체 범위가 아닌 일부 HDR을 표시하고 싶을 때 constrainedHigh 옵션을 사용해야 합니다.

왜 전부가 아니라 일부 HDR만 보여주고 싶나요?

음, 몇 가지 가능한 이유가 있습니다.

이 예에서, 나는 많은 이미지의 썸네일을 포함하는 스택 뷰를 가지고 있다.

이 이미지들 중 일부는 HDR이고, 일부는 그렇지 않다.

만약 내가 높은 DynamicRange 옵션을 사용한다면, 이것이 당신이 얻을 수 있는 것이다.

일부 이미지는 매우 밝고 HDR이지만, SDR 이미지는 그렇지 않으며 지금은 둔해 보이고, 심지어 비활성 상태일 수도 있다.

이제 constrainedHigh 옵션을 사용합시다.

HDR 콘텐츠가 사용할 수 있는 헤드룸을 제한함으로써, 나는 필름 스트립을 훨씬 더 일관성 있게 보이게 한다.

당신은 여전히 HDR 이미지를 SDR 이미지와 구별할 수 있지만, SDR 이미지가 더 이상 회색이나 비활성 상태로 보이는 문제가 없습니다.

특정 이미지 보기에 constrainedHigh 또는 표준을 사용하고 싶은 또 다른 이유는 HDR 콘텐츠가 때때로 매우 밝을 수 있으며, 앱의 다른 측면에서 관심을 빼앗는 것을 원하지 않을 수도 있기 때문입니다.

예를 들어, 여기에 전체 HDR로 표시될 때 앱의 가장 중요한 부분처럼 보이지만 중요한 컨트롤과 정보에서 주의를 끄는 더 작은 이미지가 있습니다.

제가 넘어가기 전에, 당신은 이미지의 톤 매핑을 포함하지 않는 옵션이 없다는 것을 눈치챘을 것입니다.

OS가 당신을 위해 톤 매핑을 하고 싶지 않은 상황에 있다면, 이 세션의 뒷부분에서 논의할 낮은 수준의 API를 사용해야 합니다.

명심해야 할 HDR의 중요한 측면은 HDR 데이터를 고정하거나 저하시키지 않는 파이프라인이 필요하다는 것이다.

오늘 논의한 API는 모두 완벽하게 지원되지만, 더 이상 사용되지 않는 API에는 HDR 안전 파이프라인이 없을 수 있습니다.

예를 들어, 더 이상 사용되지 않는 UIGraphicsBeginImageContextWithOptions를 사용하여 이미지의 크기를 조정하는 경우, HDR과 넓은 색영역을 잃게 됩니다.

HDR 지원 앱을 만들 때 이것을 피해야 합니다.

썸네일을 만들려고 한다면, UIKit은 iOS 15의 UIImage에 썸네일 API를 도입했습니다.

정확한 크기 조절이 필요하지 않다면, 이것은 HDR 썸네일을 얻는 데 권장되는 방법입니다.

iOS 15 이전에 더 많은 제어가 필요하거나 지원이 필요한 경우, UIKit은 UIGraphicsImageRenderer를 제공합니다.

imageRendererFormat을 사용하여, UIKit은 이미지의 HDR 정보를 다시 그릴 때 손실되지 않는 렌더러를 구성하는 방법을 알고 있습니다.

이미지 데이터를 앱에 넣는 한 가지 일반적인 방법을 살펴봅시다.

PhotoKit은 앱이 사진 라이브러리에 액세스할 수 있는 인터페이스를 제공합니다.

앱에서 기본 보기에 사진 선택기를 추가하여 사용자가 선택한 이미지에 쉽게 액세스할 수 있습니다.

PhotosPicker가 HDR 데이터를 보유하지 않는 형식으로 이미지를 트랜스코딩하려고 할 수 있기 때문에, 저는 "현재" 인코딩 정책과 일반적인 "이미지" 매칭 유형을 사용할 것입니다.

사진 선택기가 어떻게 작동하는지에 대한 자세한 내용은 "앱에 사진 선택기 포함" 세션을 확인하세요.

ISO HDR 이미지를 사용하면 DataRepresentation에서 UIImage를 만들고 추가 코드 없이 이미지 보기와 직접 사용할 수 있습니다.

게인 맵 HDR도 지원한다면, 새로운 UIImageReader를 사용하여 사용 가능할 때 HDR 표현을 얻을 수 있습니다.

이 API는 HDR 디스플레이와 SDR 버전에서는 기본적으로 HDR 표현을 반환합니다.

우리가 지금까지 논의한 API는 이미지가 HDR이거나 이미지가 HDR이라는 것을 아는 것에 의존하지 않습니다.

이미지 보기에 높은 다이내믹 레인지를 보여줘야 한다는 것을 알릴 때, 그 이미지가 HDR인지는 중요하지 않다는 것을 기억하세요.

그러나, 이미지가 HDR인지 식별하고자 하는 파이프라인이나 앱이 있을 수 있습니다.

UIKit을 사용하면 isHighDynamicRange 속성을 확인하여 콘텐츠가 ISO HDR과 호환되는지 확인할 수 있습니다.

AppKit, CoreGraphics 및 CoreImage를 사용하면 이미지의 CGColorSpace를 확인해야 합니다.

CGColorSpaceUsesITUR_2100TF 함수는 ISO HDR 이미지에 대해 true를 반환합니다.

HDR 이미지는 다양한 헤드룸을 사용할 수 있다.

예를 들어, 현재 아이폰은 최대 8배의 헤드룸을 사용하는 이미지를 생성한다.

그러나, 일부 디스플레이만 HDR을 표시할 수 있으며, 모든 HDR 디스플레이가 동일한 것은 아닙니다.

iPhone 14는 참조 흰색보다 최대 8배 더 밝은 HDR 하이라이트를 표시할 수 있으며, 12.9인치 iPad Pro와 MacBook Pro는 최대 16배, Pro XDR 디스플레이는 최대 400배까지 표시할 수 있습니다.

대부분의 다른 Apple 디스플레이는 최대 2배의 헤드룸을 표시할 수 있습니다.

그러나, 이것은 대부분의 HDR 콘텐츠에 충분하지 않을 수 있다.

지원되는 HDR 기능을 갖춘 외부 디스플레이도 있습니다.

이러한 디스플레이의 완전한 목록은 없지만, 앱이 현재 표시되는 디스플레이의 기능을 결정할 수 있는 API가 있습니다.

iOS 및 iPad OS의 potentialEDRHeadroom과 macOS의 maximumPotentialExtendedDynamicRange- ColorComponentValue를 쿼리하여 앱이 나타나는 디스플레이의 기능을 결정할 수 있습니다.

고급 주제로 넘어가기 전에, HDR을 표시하는 것이 말이 되는 시기에 대해 이야기해 봅시다.

제가 논의했듯이, HDR은 멋져 보이며 이미지를 보여주는 것이 앱의 주요 부분일 때 지원을 포함하는 것을 고려해야 합니다.

하지만 가끔은 산만해질 수 있다.

따라서 HDR이 제공할 수 있는 추가 팝이 필요하지 않다고 생각한다면, constrainedHigh 또는 표준 옵션을 사용하는 것을 고려해 보세요.

요약하자.

이제 ISO HDR 이미지를 식별하고, HDR 이미지를 표시하고, ISO HDR에 액세스하고, 사진 라이브러리에서 지도 HDR을 얻는 방법과 디스플레이가 HDR인지 여부를 결정하는 방법을 알게 되었습니다.

이제 데이비드는 HDR 이미지를 읽고, 쓰고, 조작하는 과정을 안내할 것입니다.

고마워, 잭슨. HDR 이미지로 작업할 때, 앱이 지원할 수 있는 몇 가지 일반적인 작업이 있습니다: ISO HDR을 읽거나 파일이나 데이터에서 메모리로 HDR 이미지를 얻기; HDR 콘텐츠를 유지하면서 메모리의 이미지를 수정하기; HDR을 잃지 않고 한 이미지 클래스에서 다른 이미지 클래스로 변환하기; 마지막으로, HDR 이미지를 ISO HDR 파일에 쓰기.

기능적인 HDR 이미지 파이프라인의 중요한 속성은 이미지 객체가 관련 색 공간을 가지고 있다는 것이다.

예를 들어, CGImage와 CIImage 객체 모두 이를 위해 CGColorSpace API를 사용합니다.

이미지는 지원되는 다양한 색상 공간을 가질 수 있지만, ISO HDR 이미지는 ITUR 2100 HLG 또는 PQ인 CGColorSpace를 가질 것이다.

이를 염두에 두고, ISO HDR 이미지를 읽는 방법부터 시작합시다.

UIImage와 NSImage는 이제 ISO HDR 이미지 읽기를 자동으로 지원합니다.

Apple의 색상 관리 인프라인 ColorSync는 HDR ICC 프로필을 처리하고 디스플레이에 적합한 이미지 개체를 제공할 것입니다.

게인 맵 HDR 이미지를 읽을 때, 하이 다이내믹 레인지를 선호하는 UIImageReader 구성을 만들어 HDR 표현을 요청할 수 있습니다.

이 새로운 행동은 게인 맵 HDR 이미지에만 영향을 미친다는 점에 유의하십시오.

NSImage와 UIImage와 마찬가지로, Core Image는 ISO HDR 파일 읽기를 자동으로 지원합니다.

CIImage contentsOfURL API를 사용하기만 하면 됩니다.

결과 CIImage 객체는 파일의 색상 공간에서 Core Image 확장 범위 작업 공간으로 변환하는 올바른 레시피를 자동으로 포함합니다.

코드를 디버깅할 때 Xcode의 QuickLook 기능을 사용하여 이미지 개체의 레시피를 검사할 수 있습니다.

이 예에서, QuickLook 팝오버는 이미지가 PQ ISO HDR 색 공간에서 변환되었음을 보여줍니다.

당신의 코드는 또한 파일의 색 공간을 검사하기 위해 .colorspace 속성을 얻을 수 있습니다.

이것은 sRGB 또는 디스플레이 P3와 같은 SDR 색 공간 또는 HDR 색 공간일 수 있습니다.

CoreGraphics API를 사용하는 것을 선호한다면, decodeToHDR로 설정된 새로운 decodeRequest 키와 함께 CGImageSourceCreateImageAtIndex를 사용하여 동등한 동작을 얻을 수 있습니다.

몇 분 전에, 잭슨은 왜 HDR 이미지를 SDR로 제한하고 싶은지 설명했다.

마찬가지로, Core Image를 사용하는 앱은 이미지가 SDR에 톤 매핑되도록 자동 HDR 지원을 재정의할 수 있습니다.

이것은 기능 감지와 같은 특정 시나리오에서 HDR을 사용하지 않으려면 유용할 수 있습니다.

이를 활성화하려면, CIImage를 만들 때 toneMapHDRtoSDR 옵션을 제공하기만 하면 됩니다.

이 경우, 반환된 CIImage 객체는 다른 작업이 적용되기 전에 HDR 소스를 SDR 범위로 매핑하는 레시피 단계를 포함할 것이다.

이 옵션은 이미지에 HDR 색 공간이 있는 경우에만 효과가 있다는 점에 유의하십시오.

결과 CIImage는 이미지 보기가 dynamicRange.standard 옵션을 사용해야 한다고 지정하는 것과 동일하게 보일 것이다.

또한, 이것은 decodeRequest가 decodeToSDR로 설정된 CGImageSourceCreateImageAtIndex를 사용하는 것과 동등한 동작을 가지고 있다.

전통적으로, 게인 맵 HDR 이미지는 사진 앱에서 전체 다이내믹 레인지를 표시하지만, Core Image 및 ImageIO와 같은 API에서는 SDR 표현만 사용할 수 있었다.

애플리케이션이 모든 범위의 게인 맵 HDR 이미지에 액세스할 수 있는 새로운 API를 설명하게 되어 정말 기쁩니다.

API는 사용하기 매우 간단하다.

CIImage를 초기화할 때 expandToHDR 옵션을 제공하세요.

이 경우, 반환된 CIImage 객체는 기본 이미지와 게인 맵을 결합하여 HDR 이미지를 생성하는 레시피를 포함합니다.

사진 라이브러리에 이를 지원하는 추가 게인 맵 데이터가 포함되어 있을 때 이미지의 .colorspace 속성은 HDR 색상 공간이 될 것입니다.

이 동작은 decodeToHDR로 설정된 decodeRequest 키를 사용하여 CGImageSourceCreateImageAtIndex를 사용하는 것과 같습니다.

이 옵션들은 RAW 파일에서도 작동할 것이며, 이제 더 자세히 이야기할 것이다.

iPhone의 ProRAW 이미지와 카메라의 RAW 이미지는 사진작가에게 상당한 창의적인 제어를 제공하는 유연한 이미지 형식입니다.

여기에는 장면의 일부를 HDR 헤드룸으로 렌더링할 수 있는 기능이 포함됩니다.

많은 RAW 형식에는 많은 동적 범위가 포함되어 있으며 제한 없는 형태로 처리해야 합니다.

이게 어떻게 작동하는지 설명할게요.

먼저, 애플리케이션이 RAW 파일에 대한 기본 SDR 모양을 보여주고 싶다면, 평소와 같이 URL에서 이미지를 만드세요.

하지만 애플리케이션이 기본 HDR 렌더링 모양을 보여주고 싶다면, 새로운 expandToHDR 옵션을 추가하기만 하면 됩니다.

그러나, 앱이 RAW의 모든 기능을 잠금 해제하고 싶다면, 코드는 URL에서 CIRAWFilter를 만들어야 합니다.

그 필터에 출력 이미지를 요청하면, 기본 모양이 있는 CIImage를 얻을 수 있습니다.

하지만 이 API의 주요 장점은 필터를 쉽게 수정할 수 있다는 것이다.

각 CIRAWFilter 인스턴스에는 앱이 출력 이미지를 변경하기 위해 변경할 수 있는 몇 가지 속성이 있습니다.

이러한 속성은 "ProRAW 이미지 캡처 및 처리" 세션에 잘 설명되어 있지만, 이 HDR 토론과 특히 관련이 있는 것을 검토해 봅시다.

RAW 이미지의 동적 범위 양은 0에서 1까지의 값으로 조정할 수 있습니다.

extendedDynamicRangeAmount 속성은 잭슨이 이전에 설명한 viewDynamicRange 컨트롤과 유사하다.

이 속성의 기본값은 0이며, 이는 출력 이미지가 SDR이어야 함을 나타냅니다.

이 속성의 최대 값은 1이며, 이는 출력 이미지가 파일에 있는 헤드룸의 대부분을 사용해야 함을 나타냅니다.

그것은 ISO HDR 이미지를 읽는 다양한 방법을 마무리한다.

다음으로, HDR 이미지를 수정하는 방법에 대한 몇 가지 권장 사항에 대해 논의해 봅시다.

Core Image는 HDR을 지원하는 150개 이상의 내장 필터가 포함되어 있기 때문에 HDR 이미지 작업을 위한 강력하고 유연한 API를 제공합니다.

이 모든 필터는 HDR 콘텐츠가 포함된 이미지를 생성하거나 처리할 수 있습니다.

이 모든 필터는 코어 이미지 작업 색 공간이 클램프되지 않고 선형이기 때문에 작동하며, 0에서 1 범위 외부의 RGB 값을 허용합니다.

앱을 개발할 때, 주어진 필터가 HDR을 지원하는지 확인할 수 있습니다.

이렇게 하려면, 필터의 인스턴스를 만든 다음, 범주에 대한 필터의 속성을 요청한 다음, 배열에 범주 높은 동적 범위가 포함되어 있는지 확인합니다.

내장 CI 필터 및 사용자 지정 CI 커널에 대한 자세한 내용은 "Core Image, Metal 및 SwiftUI로 EDR 콘텐츠 표시" 세션을 참조하십시오.

다음으로, HDR 이미지를 ISO HDR 파일로 작성하는 것에 대해 논의해 봅시다.

종종, 당신의 앱은 메모리에 있는 이미지 객체를 새로운 파일 표현에 쓰고 싶어 할 것입니다.

전통적으로, UIImage, jpegData 및 pngData API를 사용하면 8비트 정밀 SDR 이미지를 저장할 수 있습니다.

올해 새로운 UIImage는 객체에 HDR 콘텐츠가 포함되어 있을 때 16비트 PNG 또는 10비트 HEIF 형식을 사용하여 ISO HDR 이미지를 자동으로 쓸 수 있습니다.

원본 이미지가 게인 맵 HDR 이미지라면 ISO HDR로 변환될 것이다.

마찬가지로, Core Image는 HDR 색상 공간을 지정하고 RGBA16 형식을 요청하는 writePNGRepresentationOfImage를 호출할 때 HDR PNG 파일을 쓸 수 있습니다.

또는 Core Image는 HDR 색 공간을 지정하고 RGBA16 형식을 요청하는 writeTIFFRepresentationOfImage를 호출할 때 HDR TIFF 파일을 쓸 수 있습니다.

PNG와 TIFF 모두 무손실 압축을 사용하며 파일 크기가 훨씬 더 커집니다.

결과적으로, 가장 좋은 방법은 writeHEIF10RepresentationOfImage를 사용하여 HEIF 파일을 작성하고 HDR 색상 공간을 지정하는 것입니다.

한 프레임워크 클래스에서 다른 클래스로 또는 한 색 공간에서 다른 색 공간으로 변환해야 하는 경우가 있을 수 있습니다.

이미지 클래스 UIImage, CIImage, CGImage, IOSurface 및 CVPixelBuffer 간에 변환하는 과정은 대부분 동일하게 유지됩니다.

그렇긴 하지만, HDR 파이프라인으로 작업할 때 살펴봐야 할 몇 가지 사항이 있습니다.

먼저 IOSurface 또는 CVPixelBuffer 객체로 변환하는 것에 대해 논의해 봅시다.

이 이미지 유형은 예를 들어, CALayer의 내용으로 사용될 수 있기 때문에 유용하다.

또한, 그것은 매우 메모리 효율적인 이중 평면 크로마 서브샘플링 이미지를 저장할 수 있다.

CVPixelBuffer를 사용하기 전에, ISO HDR 호환 콘텐츠가 있다고 선언해야 합니다.

첫 번째 단계는 10비트 이중 평면 전체 범위와 같은 적절한 형식으로 픽셀 버퍼를 만드는 것입니다.

당신이 그것을 하는 동안, 최상의 성능을 위해, IOSurfacePropertiesKey를 제공하여 버퍼가 표면으로 뒷받침되어야 한다고 명시해야 합니다.

다음으로, 시스템이 ISO HDR 호환 색상 공간 속성이 포함되어 있다는 것을 알 수 있도록 CVPixelBuffer에 첨부 파일을 추가해야 합니다.

일단 CVPixelBuffer가 있으면, 그것을 CIImage로 변환하는 것은 사소하다.

CIImage withCVPixelBuffer API를 호출하세요.

그리고 CIContext를 사용하여 버퍼로 렌더링하여 CIImage에서 CVPixelBuffer로 변환할 수 있습니다.

앱이 Core Image와 CGImageRef API 간에 변환할 수 있는 몇 가지 상황이 있습니다.

이 변환으로 HDR 콘텐츠를 보존하려면 HDR 색상 공간을 선택하고 RGBA16 또는 RGBAh 형식과 같은 딥 픽셀 형식을 요청해야 합니다.

그리고 올해 새로운 CoreImage는 깊지만 메모리의 절반을 사용하는 RGB10 형식을 추가했다.

CGImages가 다양한 API에서 지원된다는 점을 감안할 때 CIImage를 CGImage로 변환하는 것은 매우 편리합니다.

하지만 그렇게 하는 것은 사용자 상호 작용 렌더링의 최상의 성능을 위해 권장되지 않는다는 점에 유의하십시오.

가장 빠른 성능을 위해, CoreImage를 MTKView로 직접 렌더링하거나 PixelBuffer를 통해 CALayer로 렌더링하는 것이 가장 좋습니다.

CALayers에 대해 말하자면, 잭슨으로 돌아가서 더 복잡한 워크플로우에 필요할 수 있는 낮은 수준의 API에 대해 자세히 알아봅시다.

고마워, 데이비드!

CALayers는 최고의 렌더링 성능이나 콘텐츠가 앱에 어떻게 합성되는지에 대한 더 많은 제어가 필요할 때 강력한 도구입니다.

CALayers에서 HDR 렌더링을 활성화하려면, 이제 wantsExtendedDynamicRangeContent 속성을 설정할 수 있습니다.

이것은 CAMetalLayers가 디스플레이의 헤드룸에 콘텐츠를 표시하기 위해 사용하는 속성과 유사합니다.

이 두 방법의 주요 차이점은 CALayer 속성이 레이어 내용의 톤 매핑을 가능하게 하는 반면 CAMetalLayer는 그렇지 않다는 것이다. 이것은 실제로 무엇을 의미하나요?

이 이미지와 줄거리는 10배의 헤드룸을 가진 콘텐츠를 보여준다.

최소 10배의 헤드룸을 사용할 수 있는 디스플레이로 렌더링될 때, 두 레이어 모두 동일하게 작동합니다.

이제 디스플레이에 5배의 헤드룸만 사용할 수 있다고 가정해 봅시다.

CAMetalLayer의 경우, 5배 이상의 이미지 데이터는 디스플레이가 표시할 수 있는 것에 고정되어 이미지의 날카로운 불연속성을 초래합니다.

CALayer의 경우, 이미지는 그 불연속성을 피하기 위해 톤 매핑될 것이다.

사용된 정확한 톤 매핑 알고리즘은 그 이미지와 함께 사용되는 전송 곡선에 따라 달라집니다.

이러한 알고리즘에 대한 자세한 내용은 HLG 및 PQ에 대한 ITU 표준을 참조하십시오.

CALayers는 HDR 콘텐츠를 화면에 가져올 수 있는 빠르고 간단한 방법을 제공하는 반면, CAMetalLayers는 자신만의 톤 매핑 파이프라인을 만들 수 있는 자유를 제공합니다.

CALayer를 직접 사용하여 HDR을 렌더링하려면, 이러한 사용 가능한 클래스 중 하나를 사용해야 합니다.

ISO HDR로 적절하게 태그된 CGImage, CVPixelBuffer 또는 IOSurface 유형의 객체는 CALayer에 의해 렌더링되고 톤 매핑됩니다.

CALayer를 직접 사용하고 이 클래스 중 하나를 사용하지 않는다면, David가 설명한 방법 중 하나를 사용하여 변환할 수 있습니다.

HDR 워크플로우로 작업할 때, 올바른 픽셀 형식을 사용하는 것이 중요합니다.

이러한 픽셀 형식은 HDR 데이터를 처리할 때 사용하기에 안전합니다.

16비트 및 32비트 플로트 포맷은 항상 높은 다이내믹 레인지를 지원합니다.

16비트 정수 형식은 적절한 파일 형식과 컨텍스트에서 HDR 콘텐츠를 지원하는 데에도 작동합니다.

마지막으로, 메모리와 파일 크기가 중요할 때 사용할 수 있는 10비트 픽셀 형식이 있습니다.

이것은 대부분의 압축된 ISO HDR 이미지의 기본 비트 심도입니다.

HDR 콘텐츠에 사용할 수 있는 CGImage를 만들 때 CoreGraphics 플래그도 있습니다.

이전 목록과 마찬가지로, float, half float, 16비트 정수 및 10비트 RGB를 사용할 수 있습니다.

이와 같은 새로운 기능을 도입할 때 마지막으로 중요한 주제는 이전 버전과의 호환성이다.

HDR 이미지를 다룰 때 이전 버전의 iOS와 macOS를 지원하기 위해 무엇을 할 수 있나요?

ISO HDR 이미지의 경우, CoreImage는 HDR을 SDR로 변환하는 toneMapHDRtoSDR 옵션을 제공합니다.

마찬가지로, CoreGraphics CGContext를 사용하여 렌더링할 때, SDR CGColorspace를 타겟팅할 수 있으며, 이미지는 해당 공간에 톤 매핑됩니다.

게인 맵 HDR의 경우, 새로운 expandToHDR 옵션이 사용될 때 버전 검사를 사용하여 게이트에 이동하십시오.

이러한 옵션이 생략되면, 파일의 SDR 버전은 HDR 버전 대신 항상 로드됩니다.

마무리하기 위해, 우리는 HDR 이미지를 읽고, 쓰고, 표시하기 위한 새로운 API를 도입했고, 게인 맵 HDR 표현에 액세스하는 방법을 보여주었고, 완전한 HDR 지원 파이프라인으로 작업하기 위한 API를 제공했습니다.

우리는 당신이 HDR로 만드는 놀라운 것들을 빨리 보고 싶어요!

함께: 봐줘서 고마워!

.