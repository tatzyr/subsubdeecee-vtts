10203

♪ 부드러운 기악 힙합 ♪

♪

안녕하세요, 제 이름은 피터이고, 저는 Apple의 RealityKit Tools 팀에서 일하고 있습니다.

오늘, 우리는 당신이 어떻게 첫 번째 몰입형 앱 개발을 시작할 수 있는지 살펴볼 것입니다.

공간 컴퓨팅은 콘텐츠를 제시하고 앱에 더 깊은 수준의 몰입도를 통합하는 완전히 새로운 방법을 제공합니다.

플랫폼 자체는 새로운 것이지만, 앱을 구축하는 것은 이미 당신에게 친숙할 수 있는 워크플로우를 사용합니다.

이 세션에서, 우리는 Xcode에서 새로운 앱 프로젝트를 만드는 것으로 시작할 것입니다.

시뮬레이터를 통해 시뮬레이션된 장면에서 앱을 경험할 수 있는 방법과 빠른 반복을 위해 Xcode 미리보기를 어떻게 사용할 수 있는지 알아보겠습니다.

앱의 공간 콘텐츠를 준비하고 미리 보는 데 도움이 되는 새로운 도구인 Reality Composer Pro를 소개합니다.

마지막으로, 앱이 몰입형 장면을 만들고 RealityKit 엔티티에 SwiftUI 제스처를 타겟팅하는 방법을 보여드리겠습니다.

당신과 같은 수백만 명의 개발자가 매일 Xcode를 사용하여 배포할 앱을 생성, 미리보기, 디버그, 프로필 및 준비합니다.

Xcode는 첫 번째 앱을 만들 수 있는 최고의 장소입니다.

Xcode 프로젝트 생성 과정을 살펴보고 이 플랫폼의 새로운 기능을 살펴봅시다.

Xcode에서 새 프로젝트를 만들 때, 새로운 프로젝트 어시스턴트가 제공됩니다.

그것은 플랫폼과 프로젝트 유형별로 프로젝트 템플릿을 구성한다.

앱 프로젝트 템플릿은 플랫폼 탭 아래의 애플리케이션 섹션에서 사용할 수 있습니다.

새로운 프로젝트 어시스턴트가 아직 설치되지 않은 경우 플랫폼 지원을 다운로드하도록 요청할 수 있습니다.

새로운 프로젝트 어시스턴트는 우리에게 몇 가지 옵션을 제공하며, 그 중 두 개는 이 플랫폼에 새로운 것이다.

이 새로운 옵션들 각각을 자세히 살펴봅시다.

첫 번째 새로운 옵션인 초기 장면을 사용하면 앱에 자동으로 포함된 초기 장면의 유형을 지정할 수 있습니다.

새로운 프로젝트 어시스턴트는 항상 여기서 선택한 유형의 단일 장면으로 시작점을 만듭니다.

개발자로서, 당신은 나중에 추가 장면을 추가할 수 있습니다.

이것들은 당신의 초기 장면과 같은 유형일 수도 있고, 완전히 다른 장면 유형일 수도 있습니다.

템플릿은 두 개의 초기 장면, 창과 볼륨을 제공한다.

이것들의 차이점을 살펴봅시다.

윈도우는 주로 2차원적인 콘텐츠를 제공하도록 설계되었다.

그들은 평면 치수로 크기를 조정할 수 있지만, 깊이는 고정되어 있다.

윈도우는 일반적으로 실행 중인 다른 앱과 함께 표시됩니다.

"공간 컴퓨팅을 위한 SwiftUI를 만나보세요" 세션에서 SwiftUI의 추가 및 변경 사항과 함께 창 장면 유형에 대한 자세한 내용을 배울 수 있습니다.

볼륨은 주로 3D 콘텐츠를 제공하도록 설계되었습니다.

모든 3차원의 크기는 앱 자체에 의해 제어되지만, 앱을 사용하는 사람이 조정할 수는 없습니다.

윈도우와 마찬가지로, 볼륨은 일반적으로 실행 중인 다른 앱과 함께 표시됩니다.

"SwiftUI를 다음 차원으로 가져가세요" 세션은 볼륨 장면 유형에 대한 더 많은 정보를 제공합니다.

두 번째 새로운 옵션인 몰입형 공간은 앱에 몰입형 콘텐츠의 시작점을 추가할 수 있는 기회를 제공합니다.

앱에 몰입형 공간 장면 유형을 추가하면, 무한 캔버스의 어느 곳에서나 무제한 콘텐츠를 표시하는 데 사용할 수 있습니다.

앱이 이 장면 유형을 활성화하면, 공유 공간에서 전체 공간으로 이동합니다.

전체 공간에서, 산만함을 피하기 위해 실행 중인 다른 앱이 숨겨져 있다.

앱은 또한 전용 렌더링 리소스에 액세스할 수 있으며, 손 추적과 같은 ARKit 기능을 활성화할 수 있는 권한을 요청할 수 있습니다.

앱에 몰입형 경험을 만들고 싶다면, SwiftUI는 장면에 대한 세 가지 스타일을 제공합니다: 혼합 몰입, 점진적 몰입, 완전 몰입.

혼합 몰입 스타일을 사용하면 앱이 무제한 가상 콘텐츠를 풀 스페이스에 배치할 수 있으며, 패스스루를 통해 주변 환경과 연결된 상태를 유지할 수 있습니다.

진보적인 몰입 스타일은 사람들을 주변 환경에서 완전히 제거하지 않는 더 몰입감 있는 경험을 제공하기 위해 포털을 엽니다.

포털이 열리면, 사람들은 당신의 몰입형 콘텐츠를 약 180도 볼 수 있으며, 디지털 크라운을 사용하여 포털의 크기를 조정할 수 있습니다.

완전한 몰입 스타일은 패스스루를 완전히 숨기고 앱의 환경으로 사람들을 둘러싸고 새로운 장소로 이동시킨다.

우리는 이 세션의 뒷부분에서 몰입형 공간에 대해 더 이야기할 것이다.

딥 다이빙을 위해, 우리는 당신이 "SwiftUI로 창 너머로 가세요" 세션을 시청하도록 초대합니다.

기본적으로, 몰입형 공간은 앱에 추가되지 않습니다.

이것은 없음 옵션을 선택할 때의 행동입니다.

그러나, 몰입형 공간 옵션 중 하나를 선택하면, 템플릿은 선택한 몰입형 공간 스타일로 두 번째 SwiftUI 장면을 자동으로 추가합니다.

기본적으로, 누군가가 몰입형 콘텐츠를 열 수 있도록 창이 있는 장면에 SwiftUI 버튼을 제공합니다.

일반적으로, 우리는 앱이 항상 이 플랫폼의 창에서 시작하고, 사람들이 당신의 콘텐츠에 더 몰입할 때를 결정할 수 있도록 명확한 출입 제어를 제공하는 것이 좋습니다.

사람들이 모르는 사이에 더 몰입감 있는 경험으로 옮기는 것을 피하세요.

이 세션을 위해 프로젝트를 구성합시다.

우리는 몰입형 공간이 없는 초기 볼륨으로 시작할 것이다.

우리는 평소와 같이 프로젝트를 만들고, 이름을 지정하고, Xcode에 어디에 저장해야 하는지 알려줍니다.

일단 만들어지면, 새로운 프로젝트가 열린다.

왼쪽에는 Xcode의 프로젝트 네비게이터가 있습니다.

첫 번째 파일은 초기 볼륨을 제공하는 앱에 대한 WindowGroup을 선언하는 MyFirstImmersiveApp.swift입니다.

WindowGroup은 앱이 제공하는 최상위 SwiftUI 뷰를 지정하는 iOS에서 본 것과 동일한 구성입니다.

두 번째 파일은 이 초기 볼륨에 표시된 보기인 ContentView.swift입니다.

이 프로젝트는 메인 편집기에서 ContentView.swift로 열립니다.

Xcode는 또한 프로젝트에 자동으로 포함된 RealityKit 콘텐츠 패키지의 내용을 로드하는 ContentView의 미리보기를 보여줍니다.

새 프로젝트의 대부분의 코드는 ContentView에 있다.

ContentView는 몇 가지 새로운 플랫폼별 기능을 사용하므로, 자세히 살펴봅시다.

ContentView는 볼륨에 의해 제공되는 SwiftUI 뷰의 이름입니다.

그것은 간단한 효과를 위해 사용되는 "확대"라고 불리는 단일 SwiftUI 상태 속성을 정의한다.

SwiftUI 보기로서, 우리의 콘텐츠는 본문 재산에 의해 제공됩니다.

본문은 VStack에 중첩된 두 개의 뷰로 구성되어 있다.

VStack은 중첩된 뷰를 수직으로 쌓게 한다.

첫 번째 중첩된 보기는 RealityView이다.

RealityView는 이 플랫폼의 새로운 것이며, 우리는 잠시 후에 다시 돌아올 것입니다.

두 번째 중첩된 보기는 다른 VStack에 내장된 표준 SwiftUI 토글 보기입니다.

토글 보기는 확대 속성의 값을 토글합니다.

VStack은 버튼이 읽기 쉽고 쉽게 상호 작용할 수 있도록 glassBackgroundEffect를 제공합니다.

SwiftUI로 작업했다면, 이미 토글 보기를 보았을 가능성이 높습니다.

다른 플랫폼에서 이미 지원되는 대부분의 SwiftUI 컨트롤은 예상대로 작동할 것이다.

잠시 후에, 우리는 제스처를 사용하여 확대 속성을 전환하는 방법을 볼 것이다.

하지만 먼저, RealityView를 자세히 살펴봅시다.

RealityView를 사용하면 Reality 콘텐츠를 SwiftUI 뷰 계층 구조에 배치할 수 있습니다.

ContentView에 사용되는 RealityView 이니셜라이저는 두 개의 클로저, make 클로저와 업데이트 클로저를 매개 변수로 사용합니다.

Make closure은 초기 RealityKit 콘텐츠를 뷰에 추가합니다.

RealityKit 콘텐츠 패키지의 내용을 로드하려고 합니다.

그리고 성공하면, content.add를 사용하여 로드된 콘텐츠를 보기에 추가합니다.

우리는 또한 초기 콘텐츠를 절차적으로 생성하거나, 절차적 콘텐츠와 로드된 콘텐츠의 조합을 사용할 수 있습니다.

업데이트 폐쇄는 선택 사항이지만, 제공되는 경우 SwiftUI 상태가 변경될 때마다 호출됩니다.

그것은 make closure에 추가된 것이기 때문에 content.entites에서 첫 번째 엔티티를 얻는 것으로 시작합니다.

그런 다음 SwiftUI 상태의 확대 속성 값에 따라 균일 스케일 요소를 선택하고 이 스케일을 엔티티에 적용합니다.

RealityView 업데이트 폐쇄는 렌더링 업데이트 루프가 아니며 모든 프레임에서 호출되지 않는다는 점에 유의하는 것이 중요합니다.

대신, 업데이트 클로저는 SwiftUI 상태가 변경될 때만 호출됩니다.

마지막으로, RealityView에는 제스처가 첨부되어 있다.

RealityKit 콘텐츠를 탭하면 확대 속성의 값을 전환하여 이전에 다루었던 토글 보기를 탭하는 것과 동일한 효과를 냅니다.

RealityView와 제스처에 대해 자세히 알아보려면, "RealityKit으로 공간 경험 구축"을 볼 수 있습니다.

이제 ContentView를 살펴보았으니, 시뮬레이터를 소개하고 시뮬레이션된 장면에서 실행되는 앱을 탐색하고 상호 작용하는 방법을 보여드리겠습니다.

그런 다음 시뮬레이터에서 앱이 어떻게 보이는지 볼 것입니다.

시뮬레이터는 다른 플랫폼에 사용했다면 당신에게 친숙한 창에 표시됩니다.

처음 실행되면, 애플리케이션 런처가 표시됩니다.

시뮬레이터는 누군가가 장치를 착용하는 것을 볼 수 있는 것을 모방한다.

기본적으로, 포인터는 당신이 보고 있는 것을 제어합니다.

마우스나 트랙패드를 클릭하면 탭이 시뮬레이션되고, 클릭을 길게 누르면 핀치가 시뮬레이션됩니다.

공간 컴퓨팅의 큰 부분은 주변을 둘러보고 움직일 수 있다는 것이다.

시뮬레이터는 정확히 그것을 하기 위한 추가 컨트롤을 제공한다.

시뮬레이터 창의 오른쪽 하단 모서리에는 시뮬레이션된 장치를 제어하기 위한 몇 가지 버튼이 있습니다.

마우스나 트랙패드를 움직이는 동안 길게 클릭하면 주변을 둘러볼 수 있습니다...

...팬...

...궤도...

...그리고 앞뒤로 움직이세요.

이러한 컨트롤을 클릭하고 길게 누르면 콘텐츠와의 상호 작용과 보고 돌아다니는 것 사이를 빠르게 전환할 수 있습니다.

마우스 버튼을 계속 누를 필요가 없도록 이 버튼을 클릭하여 주어진 제어 모드로 전환할 수도 있습니다.

예를 들어, 팬 버튼을 클릭한 다음, 뷰포트를 클릭하고 드래그하면 뷰가 표시됩니다.

가장 왼쪽 컨트롤을 클릭하면 모양과 탭을 제어하기 위해 다시 전환됩니다.

시뮬레이터에는 다른 방과 조명 조건에서 실행되는 앱을 보는 데 사용할 수 있는 몇 가지 시뮬레이션 장면이 함께 제공됩니다.

도구 모음의 시뮬레이션 장면 메뉴를 통해 그들 사이를 전환할 수 있습니다.

시뮬레이터 사용에 대한 자세한 내용은 developer.apple.com의 문서를 참조하십시오.

이제 시뮬레이터에 익숙해졌으니, 그곳에서 실행 중인 새로운 앱을 살펴봅시다.

평소와 같이, 우리는 제품 메뉴에서 실행을 클릭하여 Xcode에서 앱을 실행합니다.

앱이 실행되면, RealityKit 콘텐츠 패키지의 내용을 보여주는 볼륨을 볼 수 있습니다.

RealityView 콘텐츠 확대 버튼을 탭하면 콘텐츠가 확대되고, 다시 탭하면 원래 크기로 돌아갑니다.

우리는 또한 RealityView의 제스처 때문에 구를 탭하여 확대할 수 있습니다.

구를 탭하면 버튼의 하이라이트가 바뀝니다.

탭 제스처는 SwiftUI 상태를 업데이트하여 RealityView와 Toggle 보기가 상태 변경에 반응하게 합니다.

Xcode 미리보기를 사용하면 앱 뷰의 모양과 동작에 빠르게 집중하고 반복할 수 있습니다.

SwiftUI 미리보기 공급자가 포함된 소스 파일을 편집할 때, 미리보기 캔버스가 Xcode에서 자동으로 열립니다.

시뮬레이터와 마찬가지로, Xcode 미리보기는 시뮬레이션된 장치 보기로 표시됩니다.

시뮬레이터를 탐색하는 데 사용한 것과 동일한 컨트롤을 사용하여 미리보기 창을 탐색할 수 있습니다.

컨트롤을 사용하여 콘텐츠에 조금 더 가까이 이동합시다.

오른쪽 하단 모서리의 컨트롤을 사용하여 시뮬레이션된 장면과 카메라 각도를 변경할 수도 있습니다.

우리는 SwiftUI 코드를 변경하고 실시간으로 미리보기 업데이트를 볼 수 있습니다.

토글의 텍스트를 "크기 변경"으로 변경해 봅시다.

우리가 텍스트를 변경할 때 미리보기 업데이트에 주목하세요.

또한, 버튼이 Xcode 미리보기에서 여전히 작동한다는 것을 주목하세요.

우리는 이것을 사용하여 RealityView 클로저의 내용을 반복할 수 있습니다.

Xcode Previews에는 앱의 범위를 넘어 확장되는 콘텐츠를 검색할 수 있는 개체 모드와 사용자 지정 카메라 각도를 포함하여 더 많은 고급 기능이 있습니다.

개발자 문서에서 Xcode 미리보기에 대해 자세히 알아볼 수 있습니다.

RealityKit 콘텐츠 패키지로 작업하는 데 도움이 되는 새로운 도구를 만들었습니다.

Reality Composer Pro는 앱의 공간 콘텐츠를 준비하고 미리 볼 수 있는 좋은 장소입니다.

우리 앱의 ContentView는 RealityView를 사용하여 RealityKit 콘텐츠 패키지에서 콘텐츠를 로드합니다.

템플릿에서 만든 콘텐츠 패키지는 RealityKitContent라고 불리며 Xcode 프로젝트의 패키지 그룹에 있습니다.

여기서 우리는 RealityKitContent가 선택된 프로젝트를 볼 수 있습니다.

RealityKit 콘텐츠 패키지는 RealityKit 콘텐츠를 포함하는 Swift 패키지입니다.

그것들은 런타임 사용을 위해 콘텐츠를 최적화하기 위해 빌드 시간에 처리됩니다.

RealityContent의 공개 표시기를 클릭하면 콘텐츠 패키지의 내용을 볼 수 있습니다.

큐브 아이콘과 함께 패키지를 클릭하면 콘텐츠 패키지의 장면 중 하나를 미리 볼 수 있습니다.

콘텐츠 패키지를 편집하려면, 오른쪽 상단의 Open in Reality Composer Pro 버튼을 클릭하세요.

이것은 Reality Composer Pro를 출시할 것이다.

Reality Composer Pro가 출시되면, ContentView에 의해 로드된 3D 콘텐츠를 볼 수 있습니다.

Xcode의 주요 초점은 소스 파일과 앱 리소스 편집에 있지만, Reality Composer Pro는 3D 콘텐츠를 전면과 중심에 둔다.

그것의 주요 보기는 시뮬레이터와 유사한 컨트롤을 사용하여 탐색할 수 있는 3D 뷰포트이다.

Reality Composer Pro는 내용을 장면으로 구성한다.

프로젝트 템플릿에 포함된 콘텐츠 패키지는 단일 장면으로 시작합니다.

우리의 프로젝트를 향상시키기 위해, 몰입형 공간을 위한 콘텐츠를 포함하는 새로운 장면을 만들어 봅시다.

Reality Composer Pro의 파일 메뉴에서 신규 > 장면을 선택하세요.

이름을 지정하세요 - 이 경우, 우리는 단순히 ImmersiveScene이라고 부를 것입니다 - 그런 다음 저장을 클릭하세요.

장면을 만든 후, 자동으로 열리고, 창 하단의 프로젝트 브라우저에서 빈 장면의 썸네일을 볼 수 있습니다.

창 상단의 이름을 클릭하거나 프로젝트 브라우저에서 두 번 클릭하여 장면을 전환할 수 있습니다.

우리는 이제 새로운 장면에 몰입형 콘텐츠를 추가할 준비가 되었습니다.

Xcode 프로젝트를 구성할 때, SwiftUI의 ImmersiveSpace를 사용하여 주변 어디에서나 무제한 콘텐츠를 제공하는 방법을 언급했습니다.

이 장면 유형에 대해 이해해야 할 두 가지 주요 세부 사항이 더 있다.

첫째, 창과 볼륨 장면 유형과 달리, ImmersiveSpace는 발의 추론된 위치를 콘텐츠의 원점으로 사용합니다.

이 좌표계에서, 양의 x축은 오른쪽에 있고, 양의 y축은 위에 있고, 음의 z축은 당신 앞에 있습니다.

둘째, 앱이 전체 공간에서 실행될 때, 손의 정확한 위치와 방향과 같은 추가 데이터에 대한 액세스를 요청할 수 있습니다.

이 데이터 중 일부는 사생활에 민감하다는 것을 명심하세요.

앱이 개인 정보 보호에 민감한 데이터를 요청하는 경우, 앱을 사용하는 사람에게 이 요청을 승인하라는 메시지가 표시됩니다.

이것은 공유 공간의 앱에서 사용할 수 없습니다.

몰입형 공간을 제공하는 앱의 사용 가능한 추가 데이터 및 개인 정보 보호 고려 사항에 대한 자세한 내용은 "공간 컴퓨팅을 위한 ARKit 만나기" 세션을 참조하십시오.

이제 몰입형 경험을 만드는 방법에 대해 더 많이 알았으니, ImmersiveSpace에서 잘 작동할 콘텐츠를 조립해 봅시다.

몰입형 경험에 적합한 콘텐츠를 만드는 데 사용할 USDZ 클라우드 모델이 있습니다.

Reality Composer Pro 장면에 USDZ 모델을 추가하려면, 파일 메뉴를 열고 가져오기를 클릭하세요.

그런 다음 파일을 선택하세요.

USDZ 모델이 프로젝트 브라우저에 나타난다는 것을 주목하세요.

장면에 추가하려면, 뷰포트로 드래그하기만 하면 됩니다.

또한 파인더 창에서 뷰포트로 USDZ 파일을 드래그 앤 드롭하여 동시에 가져와서 장면에 추가할 수 있습니다.

이제, 몰입형 장면에 클라우드를 배치해 봅시다.

우리는 그것들을 선택하고 나타나는 핸들을 사용하여 물체를 이동할 수 있습니다.

또는 오른쪽의 인스펙터 패널에서 수동으로 값을 설정할 수 있습니다.

이 장면 유형은 발의 추론된 위치를 원점으로 사용하기 때문에, 우리는 구름이 우리가 즉시 볼 수 있는 어딘가에 나타날 수 있도록 배치해야 합니다.

이 경우, 우리는 그것을 눈높이보다 약간 높은 당신의 앞과 오른쪽에 놓을 것입니다.

나는 이 구름이 약간 오른쪽으로 나타나길 바란다.

양의 x축은 오른쪽에 있으므로, X를 50으로 설정합시다.

우리가 이 변화를 만들 때, 클라우드는 뷰포트 밖으로 이동한다.

다시 집중하려면, 왼쪽의 장면 계층 구조에서 두 번 클릭하세요.

구름이 다시 보이는 상태에서, Y 좌표에 대해 생각해 봅시다.

우리는 구름이 우리 위에 나타나기를 원하므로, 그것을 200센티미터 높이에 두자.

그것은 바닥에서 약 6피트 반이다.

구름이 다시 뷰포트를 떠나니, 다시 보기 위해 다시 보자.

우리는 그것을 보기 위해 똑바로 볼 필요가 없도록 구름을 우리 앞에 놓아야 한다.

우리에게서 멀리 떨어진 방향은 음의 z축이므로, Z 위치를 -200센티미터로 설정합시다.

장면 계층 구조에서 한 번 더 두 번 클릭하여 전면과 중앙으로 가져오세요.

구름은 우리의 몰입형 장면을 위한 작은 면에 있다.

우리가 어떻게 그것을 더 크게 만들 수 있는지 보자.

스케일을 높이려면, 원을 멀리 드래그하세요.

우리는 그것이 수입되었을 때보다 약 5배 더 커지기를 바랍니다.

마지막으로, 이번에는 왼쪽에 두 번째 구름을 추가합시다.

편집 메뉴 > 복제 명령을 사용하여 첫 번째 클라우드의 복사본을 만들 수 있습니다.

복사본을 왼쪽에 두려면, X 좌표를 -50으로 설정하세요.

뷰포트에서 장면의 모든 내용을 프레임하려면, 계층 구조에서 루트를 두 번 클릭하세요.

좋아요, 이제 우리는 몰입형 경험에 적합한 콘텐츠가 있는 장면이 있습니다.

파일 > 모두 저장을 사용하여 Xcode로 돌아가기 전에 변경 사항을 저장합시다.

Reality Composer Pro는 공간 콘텐츠를 앱에 준비, 미리보기 및 통합하기 위한 강력한 도구입니다.

더 자세한 소개를 위해, "Meet Reality Composer Pro" 세션을 시청하도록 초대합니다.

"Xcode에서 Reality Composer Pro 콘텐츠 작업" 세션은 첫 번째를 기반으로 하며 RealityKit 콘텐츠 패키지의 콘텐츠를 앱과 긴밀하게 통합하는 방법을 보여줍니다.

다음 단계는 우리가 앱에서 만든 몰입형 콘텐츠를 제시하는 것입니다.

앱에 의해 제시된 장면은 프로젝트 이름 앞에 접두사가 붙은 소스 파일 App.swift에 있습니다.

이제 좀 더 자세히 살펴봅시다.

당신은 우리 앱이 ContentView를 제시하는 방법을 어떻게 알고 있는지 스스로에게 물어봤을 것입니다.

우리는 앱이 ContentView를 볼륨의 내용으로 표시하기 위해 단일 WindowGroup을 사용한다는 것을 알 수 있습니다.

WindowGroup은 주어진 보기를 나타내는 하나 이상의 창이나 볼륨을 만드는 장면이다.

바디 속성의 첫 번째 장면은 앱이 실행될 때 표시되는 장면이며, 첫 번째 장면 뒤에 추가하여 앱에 추가 장면을 추가할 수 있습니다.

우리는 앱이 Reality Composer Pro에서 방금 만든 콘텐츠로 몰입형 공간을 제공하기를 바랍니다.

이 공간은 우리가 앱에 추가할 ImmersiveView라는 새로운 뷰의 내용을 보여줄 것이다.

우리는 그 공간에 ID를 할당해야 한다.

우리는 문자열 "ImmersiveSpace"를 ID로 선택했으며, 나중에 공간을 열 때 사용할 것입니다.

이 코드를 프로젝트의 App.swift 소스 파일에 추가한 다음 ImmersiveView에 코드를 추가하여 Reality Composer Pro에서 만든 새로운 장면을 로드합시다.

저는 이미 Xcode의 SwiftUI View 템플릿을 사용하여 프로젝트에 ImmersiveView.swift를 추가했습니다.

우리 프로젝트의 App.swift에서, 우리는 ImmersiveSpace를 추가합니다.

그런 다음 ImmersiveView.swift 상단에서 RealityKit 콘텐츠 패키지를 사용할 수 있도록 RealityKitContent를 가져옵니다.

우리는 또한 RealityView를 사용하려면 RealityKit을 가져와야 합니다.

ImmersiveView의 기본 콘텐츠는 텍스트 상자일 뿐입니다.

콘텐츠 패키지에 추가한 새로운 장면의 콘텐츠를 로드하는 RealityView로 대체합시다.

그렇게 하려면, 왼쪽에 있는 프로젝트 계층 구조에서 ContentView를 두 번 클릭하고, 첫 번째 클로저와 함께 RealityView의 코드를 선택하고 복사하세요.

열린 파일 탭을 사용하여 ImmersiveView로 돌아가서 텍스트 보기를 선택한 다음 붙여넣어 RealityView 코드로 바꿀 수 있습니다.

당신은 우리가 RealityView의 업데이트 폐쇄를 복사하지 않았다는 것을 알아챘을 것입니다.

이것은 우리가 SwiftUI 상태 변경에 대응하여 이 보기의 내용을 업데이트할 의도가 없기 때문입니다.

마지막으로, 우리가 만든 몰입형 장면의 콘텐츠를 로드하려면, 로드된 장면의 이름을 "Scene"에서 "ImmersiveScene"로 변경하십시오.

미리보기는 이제 ImmersiveScene의 콘텐츠를 로드하고 있지만, 왜 미리보기 캔버스에서 볼 수 없나요?

우리가 ImmersiveView를 만들었을 때, Xcode Preview가 우리를 위해 자동으로 만들어졌다.

좀 더 자세히 살펴보자.

ImmersiveView.swift의 하단을 보면, Xcode에 미리보기를 표시하도록 지시하는 코드를 볼 수 있습니다.

#Preview로 시작하는 코드 블록입니다.

기본적으로 미리보기는 기본 장면 경계로 잘립니다.

이러한 범위를 벗어난 콘텐츠를 로드하는 뷰를 제시한다면, 콘텐츠는 보이지 않을 것이다.

이러한 범위를 넘어서는 몰입형 콘텐츠 미리보기를 지원하려면, .previewLayout(.sizeThatFits)로 준비 중인 보기를 수정하기만 하면 됩니다.

지금 그렇게 하자.

ImmersiveView의 미리보기에 .previewLayout(.sizeThatFits)를 추가하면 미리보기가 업데이트되고 몰입형 콘텐츠를 볼 수 있습니다.

마지막으로, 우리 앱이 몰입형 공간을 열도록 합시다.

iOS에서 멀티씬 SwiftUI 앱으로 작업한 적이 있다면, SwiftUI 코드에서 추가 장면이 어떻게 열리는지 이미 보았을 것입니다.

첫 번째 단계는 뷰의 SwiftUI 환경에서 클로저를 캡처하는 것이며, 이는 버튼을 누르는 것과 같은 이벤트에 대한 응답으로 호출됩니다.

몰입형 공간을 제시하는 것은 캡처된 클로저가 "openImmersiveSpace"라고 불리며 비동기적이라는 점을 제외하고는 새로운 플랫폼의 SwiftUI에서 동일한 방식으로 작동하므로 코드가 몰입형 공간이 언제 제시되었는지 알 수 있습니다.

ContentView로 돌아가서, 우리는 단순히 SwiftUI 환경에서 openImmersiveSpace 클로저를 캡처한 다음, 그것을 호출하는 버튼을 추가합니다.

우리는 이제 앱이 몰입형 콘텐츠를 제공하는 데 필요한 모든 변경 사항을 만들었습니다.

시뮬레이터에서 콘텐츠를 경험할 수 있지만, 몰입감은 장치 자체에서 특히 매력적입니다.

확인해 보자.

우리는 이제 누를 때 구름을 ImmersiveSpace의 내용으로 보여주는 새로운 버튼을 본다.

우리는 우리 앞에 두 개의 구름이 보이는데, 하나는 왼쪽에 있고 다른 하나는 오른쪽에 있다.

몰입형 공간은 앱의 초기 장면과 구별된다는 점에 유의하십시오.

초기 장면을 옮기면, ImmersiveSpace의 콘텐츠가 고정된 상태로 유지된다는 것을 알 수 있습니다.

사람이 앱의 초기 볼륨을 원하는 곳으로 이동할 수 있지만, ImmersiveSpace는 열릴 때 고정된 위치에 배치됩니다.

몰입형 공간을 옮기는 대신, 몰입형 공간 안에서 자신을 움직인다.

우리는 몰입형 공간을 사용하여 머리 위에 구름을 보여주는 간단한 앱을 만들었습니다.

만약 우리가 우리의 앱이 구름과의 상호 작용에 반응하기를 원한다면 어떨까요?

간단히 말해서, 구름을 두드리면 하늘을 가로질러 부드럽게 떠오른다고 상상해 보세요.

우리가 이것을 어떻게 성취할 수 있는지 봅시다.

SwiftUI 뷰가 입력 이벤트에 응답하려면, 제스처를 첨부할 수 있습니다.

이 예시에서, 우리는 간단한 텍스트 보기를 가지고 있다.

TapGesture를 뷰에 첨부함으로써, 우리는 사람이 뷰를 탭할 때 응답할 수 있습니다.

제스처가 뷰에 부착되면, 제스처가 인식될 때 호출될 수 있는 폐쇄가 주어진다.

RealityView는 또 다른 SwiftUI 보기이기 때문에, 같은 방식으로 제스처에 반응할 것이다.

그러나, RealityView는 여러 엔티티가 있는 RealityKit 콘텐츠를 포함할 수 있습니다.

예를 들어, 우리 앱은 클라우드 모델이 포함된 RealityView를 보여주는 ImmersiveSpace를 엽니다.

사람이 구름 중 하나를 탭하면, SwiftUI는 RealityView에서 TapGesture를 호출합니다.

하지만 어떤 클라우드가 탭의 표적이 되었는지 어떻게 알 수 있을까요?

이것이 엔티티 타겟팅이 들어오는 곳이다.

targetedToAnyEntity 수정자는 RealityView에 첨부된 제스처에서 작동하여 제스처가 타겟팅된 정확한 엔티티를 결정합니다.

엔티티를 타겟팅하는 다른 방법이 있다.

특정 엔티티를 타겟팅하거나 쿼리와 일치하는 모든 엔티티를 타겟팅할 수 있습니다.

자세한 내용은 developer.apple.com의 문서를 읽어보세요.

onEnded와 같은 제스처 핸들러에게 전달된 값은 그 사람이 RealityView 내부의 엔티티와 상호 작용했음을 나타내는 엔티티 속성을 가지고 있다.

엔티티 타겟팅이 주어진 RealityKit 엔티티에서 작동하려면 엔티티에 CollisionComponent와 InputTargetComponent가 모두 있어야 합니다.

RealityKit 엔티티가 이러한 구성 요소를 갖도록 요구하면 RealityView에서 콘텐츠의 선택된 부분으로만 상호 작용을 제한할 수 있습니다.

이러한 구성 요소를 Reality Composer Pro의 엔티티에 추가하거나 앱에서 프로그래밍 방식으로 추가할 수 있습니다.

이제 엔티티 타겟팅이 어떻게 작동하는지 보았으니, 사람이 클라우드를 탭할 때 감지하는 데 사용합시다.

이 상호 작용이 발생하면, 우리는 RealityKit 애니메이션을 시작할 것이다.

Reality Composer Pro에 필요한 구성 요소를 추가하는 것으로 시작합시다.

RealityKit 콘텐츠 패키지에서는 Command-click을 사용하여 뷰 계층 구조에서 두 클라우드를 한 번에 선택할 수 있습니다.

그런 다음 인스펙터 패널 하단의 "구성 요소 추가" 버튼을 클릭하고 충돌을 선택합니다.

인스펙터 패널에서 CollisionComponent가 구름에 추가된 것을 볼 수 있습니다.

Reality Composer Pro는 적절한 충돌 모양을 자동으로 선택하여 모델에 대한 CollisionComponent를 생성합니다.

필요하다면 이 충돌 모양을 바꿀 수 있습니다.

우리는 이제 InputTargetComponent에 대해서도 똑같이 한다.

우리는 구성 요소 추가 버튼을 다시 클릭하고, 이번에는 입력 대상을 선택합니다.

좋아! 파일 > 모두 저장을 선택하여 변경 사항을 저장합시다.

실제로 구름이 하늘을 가로질러 움직이게 하기 위해, 우리는 구름이 도청될 때 호출되는 제스처 핸들러에서 RealityKit 애니메이션을 사용할 것입니다.

먼저 클라우드 변환의 현재 값을 가변 값으로 캡처한 다음, 변환에 오프셋을 추가하여 100센티미터를 앞뒤로 이동한 다음, 클라우드 엔티티에서 .move를 호출하여 RealityKit 변환 애니메이션을 적용합니다.

앱을 완성하기 위해 Xcode로 돌아가자.

ImmersiveView는 몰입형 콘텐츠로 RealityView를 제공하는 소스 파일입니다.

TapGesture를 RealityView에 첨부하는 코드를 추가하고 엔티티 타겟팅을 사용합시다.

그리고 탭이 감지되면, 변환 애니메이션을 수행하세요.

시뮬레이터에서 실행해서 실제로 작동하는 것을 봅시다!

우리는 이전과 같이 구름이 있는 ImmersiveSpace를 열려면 버튼을 탭합니다.

하지만 이제, 우리가 구름을 두드리면, 그것은 하늘을 가로질러 부드럽게 떠 있다.

엔티티 타겟팅은 SwiftUI 상호 작용을 RealityKit 콘텐츠에 연결하는 접착제입니다.

우리의 예에서, 우리는 탭에 대한 응답으로 구름 위에서 간단한 애니메이션을 수행했다.

더 복잡한 앱에서는 엔티티 타겟팅을 사용하여 추가 보기를 표시하거나, 오디오를 재생하거나, 애니메이션을 시작하는 것과 같은 더 정교한 작업을 트리거할 수 있습니다.

우리는 오늘 많은 주제를 다루었습니다; 그것들을 요약해 봅시다.

우리는 Xcode의 새로운 프로젝트 어시스턴트를 사용하여 첫 번째 몰입형 앱을 만드는 방법부터 시작했습니다.

그런 다음 우리는 새로운 플랫폼을 위한 시뮬레이터를 소개했고, Xcode Previews가 어떻게 앱의 콘텐츠를 쉽게 반복할 수 있는지 보여주었습니다.

우리는 또한 Reality Composer Pro를 소개하고 RealityKit 콘텐츠를 쉽게 준비하고 미리 볼 수 있는 방법을 보았습니다.

마지막으로, 우리는 ImmersiveSpace를 열고 엔티티 타겟팅을 사용하여 몰입형 콘텐츠와의 상호 작용을 프로그래밍 방식으로 활성화하고 대응하는 방법을 보여주었습니다.

우리는 당신이 이 프레젠테이션을 즐겼기를 바랍니다.

새로운 SwiftUI 및 RealityKit API에 대한 심층적인 세션과 Reality Composer Pro의 고급 사용 사례를 살펴보는 것이 좋습니다.

봐줘서 고마워!

♪