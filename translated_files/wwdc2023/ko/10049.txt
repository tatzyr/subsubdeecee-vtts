10049

♪ ♪

Ben: 안녕하세요, 저는 Core ML 팀의 엔지니어인 Ben Levine입니다.

오늘, 저는 Core ML을 앱에 통합할 때 새로운 것에 대해 이야기할 것입니다.

앱에서 지능형 경험을 구축하는 것이 그 어느 때보다 쉬워졌습니다.

Xcode SDK는 기계 학습 기반 기능을 활용하고 배포하기 위한 견고한 기반을 제공합니다.

도메인별 프레임워크 세트를 통해 간단한 API를 통해 내장된 인텔리전스에 액세스할 수 있습니다.

그들이 제공하는 기능은 Apple이 훈련하고 최적화한 모델에 의해 구동된다.

이 모델들은 코어 ML을 통해 실행된다.

코어 ML 프레임워크는 장치에서 기계 학습 모델을 실행하기 위한 엔진을 제공한다.

앱에 맞춤화된 모델을 쉽게 배포할 수 있습니다.

Accelerate 및 Metal 프레임워크 제품군의 도움으로 Apple 실리콘의 고성능 컴퓨팅 기능을 활용하면서 하드웨어 세부 사항을 추상화합니다.

Core ML의 임무는 기계 학습 모델을 앱에 통합할 수 있도록 돕는 것입니다.

올해, 코어 ML에 대한 우리의 초점은 성능과 유연성이었다.

우리는 워크플로우, API 표면 및 기본 추론 엔진을 개선했습니다.

워크플로우에 뛰어들고 Core ML 통합을 최적화할 수 있는 새로운 기회를 강조하기 전에, 최신 OS로 업데이트하기만 하면 자동으로 얻을 수 있는 잠재적인 성능 이점에 대한 아이디어가 있습니다.

iOS 16과 17 사이의 상대적인 예측 시간을 비교할 때, iOS 17이 많은 모델에서 더 빠르다는 것을 알게 될 것입니다.

추론 엔진의 이러한 속도 향상은 OS와 함께 제공되며 모델을 다시 컴파일하거나 코드를 변경할 필요가 없습니다.

다른 플랫폼도 마찬가지입니다.

당연히, 속도 향상의 양은 모델과 하드웨어에 따라 다르다.

의제로 넘어가서, Core ML을 앱에 통합할 때 워크플로우에 대한 개요부터 시작하겠습니다.

그 과정에서, 나는 워크플로우의 다른 부분에 대한 최적화 기회를 강조할 것이다.

그런 다음 모델 통합에 집중하고 컴퓨팅 가용성, 모델 수명 주기 및 비동기 예측에 대한 새로운 API와 동작에 대해 논의할 것입니다. Core ML 워크플로우에 대한 개요부터 시작하겠습니다.

Core ML을 앱에 통합하기 위한 두 단계가 있습니다.

첫 번째는 모델을 개발하는 것이고, 두 번째는 앱 내에서 그 모델을 사용하는 것입니다.

모델 개발을 위해, 당신은 몇 가지 옵션이 있습니다.

자신만의 모델을 개발하는 가장 편리한 방법 중 하나는 Create ML을 사용하는 것입니다.

Create ML은 일반적인 기계 학습 작업을 위한 다양한 템플릿을 제공하며 OS에 내장된 고도로 최적화된 모델을 활용할 수 있습니다.

모델 개발 워크플로우를 안내하고 결과를 대화식으로 평가할 수 있습니다.

더 알고 싶다면, 올해의 Create ML 비디오를 확인하세요.

모델을 개발하는 또 다른 방법은 여러 파이썬 기계 학습 프레임워크 중 하나를 사용하여 모델을 훈련시키는 것이다.

그런 다음, CoreMLTools 파이썬 패키지를 사용하여 Core ML 모델 형식으로 변환하십시오.

마지막으로, Apple 하드웨어의 정확성과 성능 측면에서 모델을 평가하는 것이 중요합니다.

평가의 피드백을 사용하면 종종 모델을 더욱 최적화하기 위해 이러한 단계 중 일부를 재검토하게 됩니다.

이 단계에서 최적화를 위한 많은 기회가 있다.

훈련의 경우, 훈련 데이터를 수집하고 선택하는 방법이 중요합니다.

배포되고 사용자의 손에 있을 때 모델에 전달되는 데이터와 일치해야 합니다.

당신이 선택한 모델 아키텍처도 중요합니다.

훈련 데이터 요구 사항, 정확성, 크기 및 성능 간의 절충안이 있는 여러 옵션을 탐색할 수 있습니다.

이러한 절충안의 대부분은 훈련 시간에 완전히 보이지 않을 수 있으며 전체 개발 흐름을 통해 몇 번의 반복이 필요할 수 있습니다.

다음은 모델 변환입니다.

Core ML 도구는 변환된 모델의 정밀도, 풋프린트 및 계산 비용을 최적화하는 데 도움이 되는 다양한 옵션을 제공합니다.

불필요한 복사본을 피하기 위해 앱의 데이터 흐름에 가장 적합한 입력 및 출력 형식을 선택할 수 있습니다.

입력 모양이 다를 수 있다면, 하나의 모양을 선택하거나 여러 모양별 모델 사이에서 전환하는 대신 그 변화를 지정할 수 있습니다.

계산 정밀도는 또한 전체 모델이나 개별 작업에 대해 명시적으로 설정할 수 있다.

Float32와 float16 모두 사용할 수 있습니다.

계산의 정밀도 외에도, 당신은 또한 모델 매개 변수가 어떻게 표현되는지 어느 정도 제어할 수 있습니다.

CoreMLTools는 훈련 후 무게 양자화 및 압축을 위한 유틸리티 세트와 함께 제공됩니다.

이러한 유틸리티는 모델의 공간을 크게 줄이고 장치 내 성능을 향상시키는 데 도움이 될 수 있습니다.

그러나, 이러한 혜택을 달성하기 위해, 정확성에는 약간의 절충안이 있다.

이 공간에 도움이 되는 몇 가지 새로운 도구가 있습니다. CoreMLTools 패키지에 새로운 최적화 하위 모듈이 있습니다.

그것은 훈련 후 압축 유틸리티를 통합하고 업데이트하며 PyTorch를 위한 새로운 정량화 인식 교육 확장을 추가합니다.

이를 통해 교육 중에 양자화된 모델의 정확성을 유지하는 데 도움이 되는 데이터 기반 최적화에 액세스할 수 있습니다.

이것은 Core ML의 ML 프로그램 모델 유형에서 활성화 양자화를 지원하는 새로운 작업과 결합됩니다.

자세한 내용은 Core ML로 기계 학습 모델을 압축하는 것에 대한 올해의 세션을 확인하세요.

다음은 평가입니다.

모델을 평가하는 한 가지 옵션은 CoreMLTools를 사용하여 파이썬 코드에서 직접 변환된 모델에 대한 예측을 실행하는 것입니다.

앱 코드가 사용하는 것과 동일한 Core ML 추론 스택을 사용하며 모델 변환 중 선택이 모델의 정확성과 성능에 어떤 영향을 미치는지 빠르게 확인할 수 있습니다.

Xcode는 또한 모델의 평가와 탐색과 관련하여 몇 가지 유용한 도구를 제공합니다.

모델 미리보기는 많은 일반적인 모델 유형에서 사용할 수 있습니다.

이를 통해 모델에 샘플 입력을 제공하고 코드를 작성하지 않고도 예측된 출력을 미리 볼 수 있습니다.

Core ML 성능 보고서는 연결된 모든 장치에서 로드, 예측 및 컴파일 시간에 대한 모델 계산 성능 분석을 제공합니다.

이것은 모델 아키텍처를 훈련시키기도 전에 평가하는 데 유용할 수 있습니다.

이제, 전체 워크플로우로 돌아가서, 다음 주제는 모델 통합이다.

모델 통합은 앱 개발의 일부입니다.

앱에서 사용하는 다른 리소스와 마찬가지로, Core ML 모델을 사용하는 방법을 신중하게 관리하고 최적화해야 합니다.

모델 통합에는 세 단계가 있다.

먼저 모델을 사용하기 위해 응용 프로그램 코드를 작성하세요.

모델을 언제 어디서 로드할지, 모델의 입력 데이터를 준비하고, 예측을 하고, 결과를 사용하는 방법에 대한 코드가 있습니다.

그런 다음 모델과 함께 이 코드를 컴파일합니다.

그리고 셋째, 앱 내에서 실행되는 모델을 테스트, 실행 및 프로파일링합니다.

프로파일링과 관련하여, 코어 ML과 신경 엔진 도구가 도움이 될 수 있습니다.

이것은 또한 배송 준비가 될 때까지 디자인과 최적화의 반복적인 과정입니다.

올해 모델 통합을 최적화하기 위한 몇 가지 새로운 추가 사항이 있습니다.

첫 번째는 컴퓨팅 가용성이다.

Core ML은 모든 Apple 플랫폼에서 지원되며 기본적으로 실행을 최적화하기 위해 사용 가능한 모든 컴퓨팅을 고려합니다.

여기에는 가능한 경우 CPU, GPU 및 신경 엔진이 포함됩니다.

그러나, 이러한 컴퓨팅 장치의 성능 특성과 가용성은 앱이 실행될 수 있는 지원되는 하드웨어에 따라 다릅니다.

이것은 ML 기반 기능에 대한 사용자의 경험에 영향을 미치거나 모델과 구성의 선택에 영향을 미칠 수 있습니다.

예를 들어, 일부 경험은 성능 또는 전력 요구 사항을 충족하기 위해 신경 엔진에서 실행되는 모델을 요구할 수 있습니다.

이제 컴퓨팅 장치 가용성에 대한 런타임 검사를 위한 새로운 API가 있습니다.

MLComputeDevice 열거형은 관련 값 내에서 컴퓨팅 장치의 유형과 특정 컴퓨팅 장치의 속성을 캡처합니다.

MLModel에서 사용 가능한 ComputeDevices 속성을 사용하면 Core ML에서 사용할 수 있는 장치를 검사할 수 있습니다.

예를 들어, 이 코드는 사용 가능한 신경 엔진이 있는지 확인합니다.

더 구체적으로, 사용 가능한 모든 컴퓨팅 장치의 컬렉션에 유형이 신경 엔진인 장치가 포함되어 있는지 확인합니다.

모델 통합의 다음 주제는 모델 수명 주기를 이해하는 것이다.

다른 모델 자산 유형을 검토하는 것으로 시작하겠습니다.

두 가지 종류가 있다: 소스 모델과 컴파일된 모델.

소스 모델은 MLModel 또는 MLPackage의 파일 확장자를 가지고 있습니다.

그것은 건설과 편집을 위해 설계된 개방형 형식이다.

컴파일된 모델은 MLModelC의 파일 확장자를 가지고 있다.

그것은 런타임 액세스를 위해 설계되었다.

대부분의 경우, 앱 대상에 소스 모델을 추가한 다음, Xcode는 모델을 컴파일하여 앱의 리소스에 넣습니다.

런타임에, 모델을 사용하기 위해, 당신은 MLModel을 인스턴스화합니다.

인스턴스화는 URL을 컴파일된 양식과 선택적 구성으로 가져옵니다.

결과 MLModel은 지정된 구성과 장치별 하드웨어 기능을 기반으로 최적의 추론에 필요한 모든 리소스를 로드했습니다.

이 로드 중에 무슨 일이 일어나는지 더 자세히 살펴보겠습니다.

먼저, Core ML은 캐시를 확인하여 구성과 장치에 따라 이미 모델을 전문화했는지 확인합니다.

만약 있다면, 캐시에서 필요한 자원을 로드하고 반환합니다.

이것은 캐시된 로드라고 불린다.

캐시에서 구성을 찾을 수 없다면, 장치 전문 컴파일을 트리거합니다.

이 과정이 완료되면, 캐시에 출력을 추가하고 거기에서 로드를 완료합니다.

이것은 캐싱되지 않은 로드라고 불린다.

특정 모델의 경우, 캐싱되지 않은 하중은 상당한 시간이 걸릴 수 있다.

그러나, 그것은 장치의 모델을 최적화하고 가능한 한 빨리 후속 부하를 만드는 데 초점을 맞추고 있다.

장치 전문화 중에, Core ML은 먼저 모델을 구문 분석하고 일반적인 최적화 패스를 적용합니다.

그런 다음 예상 성능과 하드웨어 가용성에 따라 특정 컴퓨팅 장치의 운영 체인을 분할합니다.

그런 다음 이 세분화는 캐시된다.

마지막 단계는 각 세그먼트가 할당된 컴퓨팅 장치에 대한 컴퓨팅 장치별 컴파일을 거치는 것입니다.

이 컴파일에는 특정 컴퓨팅 장치에 대한 추가 최적화가 포함되어 있으며 컴퓨팅 장치가 실행할 수 있는 아티팩트를 출력합니다.

완료되면, Core ML은 후속 모델 로드에 사용할 이러한 아티팩트를 캐시합니다.

코어 ML은 디스크의 특수 자산을 캐시한다.

그것들은 모델의 경로와 구성에 묶여 있다.

이러한 자산은 앱 실행과 장치의 재부팅 전반에 걸쳐 지속되기 위한 것입니다.

장치의 여유 디스크 공간이 부족하거나, 시스템 업데이트가 있거나, 컴파일된 모델이 삭제되거나 수정되면, 운영 체제는 캐시를 삭제합니다.

이런 일이 발생하면, 다음 모델 로드는 장치 전문화를 다시 수행할 것이다.

모델 로드가 캐시에 도달하는지 여부를 알아내기 위해, Core ML Instrument로 앱을 추적하고 로드 이벤트를 볼 수 있습니다.

"준비 및 캐시"라는 레이블이 있다면, 캐시되지 않은 로드였기 때문에 Core ML은 장치 전문화를 수행하고 결과를 캐시했습니다.

로드 이벤트에 "캐시" 레이블이 있다면, 그것은 캐시된 로드였고 장치 전문화가 발생하지 않았다.

이것은 특히 MLProgram 모델을 위한 새로운 것이다.

핵심 ML 성능 보고서는 또한 부하 비용에 대한 가시성을 제공할 수 있습니다.

기본적으로, 그것은 캐시된 부하의 중앙값을 보여준다.

이제 캐싱되지 않은 로드 시간도 표시할 수 있는 옵션이 있습니다.

모델을 로드하는 것은 대기 시간과 메모리 측면에서 비쌀 수 있기 때문에, 여기에 몇 가지 일반적인 모범 사례가 있습니다.

먼저, UI 스레드에서 앱을 실행하는 동안 모델을 로드하지 마세요.

대신, 비동기 로딩 API를 사용하거나 모델을 게으르게 로드하는 것을 고려해 보세요.

다음으로, 애플리케이션이 시퀀스의 각 예측에 대한 모델을 다시 로드하는 대신 연속으로 많은 예측을 실행할 가능성이 있는 경우 모델을 로드된 상태로 유지하십시오.

마지막으로, 앱이 한동안 사용하지 않으면 모델을 언로드할 수 있습니다.

이것은 메모리 압력을 완화하는 데 도움이 될 수 있으며, 캐싱 덕분에 후속 로드가 더 빨라야 합니다.

모델이 로드되면, 모델로 예측을 실행하는 것에 대해 생각할 때입니다.

나는 새로운 비동기 옵션을 보여주기 위해 데모에 뛰어들 것이다.

새로운 비동기 예측 API를 보여주기 위해, 저는 이미지 갤러리를 표시하고 이미지에 필터를 적용할 수 있는 앱을 사용할 것입니다.

그레이스케일 이미지를 입력으로 사용하고 이미지의 컬러 버전을 출력하는 코어 ML 모델을 사용하는 컬러화 필터에 초점을 맞출 것이다.

다음은 실행 중인 앱의 예입니다.

그레이스케일로 된 원본 이미지를 로드하는 것으로 시작한 다음, 컬러 이미지 모드를 선택하면 Core ML을 사용하여 이미지를 색칠합니다.

내가 아래로 스크롤할 때, 그 모델은 확실히 작동하고 있지만, 내가 예상했던 것보다 조금 느리다.

또한, 내가 훨씬 아래로 스크롤하면, 이미지가 색칠되는 데 꽤 시간이 걸린다는 것을 알 수 있다.

위로 스크롤할 때, 도중에 모든 이미지를 색칠하는 데 시간을 보내는 것 같다.

하지만 내 SwiftUI 코드에서, 나는 이미지를 보관하기 위해 LazyVGrid를 사용하고 있으므로, 보기가 화면에서 벗어날 때 작업을 취소해야 한다.

왜 성과가 부족한지 그리고 왜 취소되는 작업을 존중하지 않는지 이해하기 위해 현재 구현을 살펴보겠습니다.

이것이 실행이다.

동기 예측 API는 스레드로부터 안전하지 않기 때문에, 앱은 예측이 모델에서 연속적으로 실행되도록 해야 한다.

이것은 ColorizingService를 배우로 만들어 한 번에 colorize 메소드에 대한 호출만 허용함으로써 달성된다.

이 배우는 앱과 함께 번들로 제공되는 모델을 위해 생성되는 자동 생성 인터페이스인 colorizerModel을 소유하고 있습니다.

채색 방법은 현재 두 가지 작업을 수행합니다.

먼저 모델의 입력 크기에 맞게 이미지 크기를 조정하는 모델에 대한 입력을 준비합니다.

그런 다음 모델을 통해 입력을 실행하고 컬러 출력을 얻습니다.

나는 Core ML Instruments 템플릿으로 실행되는 앱의 Instruments 추적을 캡처했다.

인스트루먼트 추적을 볼 때, 그것은 예측이 연속적으로 실행된다는 것을 보여주며, 이는 배우 격리에 의해 보장된다.

그러나, 다음 예측이 실행되기 전에 각 예측에는 격차가 있으며, 이는 성능 부족에 기여하고 있다.

이것들은 모델 예측뿐만 아니라 입력 준비에 대한 배우 격리의 결과이다.

한 가지 개선 사항은 입력 준비를 분리되지 않은 방법으로 표시하는 것이므로, 다음 채색 요청이 배우에 들어가는 것을 차단하지 않을 것이다.

이것이 도움이 되지만, 코어 ML 예측 자체는 여전히 직렬화될 것이며, 이는 내 처리의 병목 현상이다.

코어 ML 예측 자체를 위한 동시성을 활용하기 위해, 내가 고려할 수 있는 옵션은 배치 예측 API이다.

그것은 입력 배치를 받아 모델을 통해 실행한다.

후드 아래에서, Core ML은 가능하면 동시성을 활용할 것이다.

채색 방법의 배치 버전을 만드는 것은 꽤 간단하다.

그러나, 도전적인 부분은 내가 어떻게 입력을 배치로 수집하고 이 방법으로 전달할지 알아내는 것이다.

이 사용 사례에는 실제로 배치 예측 API를 사용하기 어렵게 만드는 여러 측면이 있다.

배치 API는 알려진 양의 작업이 있을 때 가장 잘 사용됩니다.

이 경우, 처리될 이미지의 양은 고정된 것이 아니라 화면 크기와 스크롤의 양에 대한 기능이다.

나는 배치 크기를 직접 선택할 수 있지만, 배치 크기가 충족되지 않지만 여전히 처리되어야 하는 경우를 처리해야 할 것이다.

또한, 나는 이미지가 배치로 채색되는 다른 UI 경험을 할 것이다.

마지막으로, 사용자가 스크롤해도 배치를 취소할 수 없습니다.

이러한 도전들 때문에, 나는 차라리 한 번에 하나의 예측을 처리하는 API를 고수하고 싶다.

이것은 새로운 비동기 예측 API가 매우 유용할 수 있는 곳이다.

그것은 스레드로부터 안전하며 Swift 동시성과 함께 Core ML을 사용하는 데 잘 작동합니다.

코드의 비동기 디자인으로 전환하기 위해, 나는 먼저 채색 방법을 비동시로 변경했다.

그런 다음 새로운 비동기 버전의 API를 사용하는 데 필요한 예측 호출 앞에 await 키워드를 추가했습니다.

그리고 나서 나는 ColorizingService를 배우가 아닌 수업으로 바꿨다.

그렇게 하면, 여러 이미지를 동시에 색칠할 수 있다.

마지막으로, 나는 그 방법의 시작 부분에 취소 수표를 추가했다.

비동기 예측 API는 특히 여러 예측이 동시에 요청될 때 취소에 대응하기 위해 최선을 다할 것이지만, 이 경우 시작 시 추가 검사를 포함하는 것이 가장 좋습니다.

그렇게 하면, 컬러화 방법이 입력되기 전에 작업이 취소된 경우 입력 준비를 피할 수 있습니다.

이제 나는 이러한 변경을 하고 앱을 다시 실행할 것이다.

이전과 마찬가지로, 나는 그것을 컬러화 모드로 설정할 것이다.

나는 이미 이미지가 훨씬 더 빨리 색칠되는 것을 볼 수 있다.

그리고 하단으로 빠르게 스크롤하면, 이미지가 거의 즉시 로드됩니다.

조금 위로 스크롤하면, 다시 스크롤할 때 이미지가 채색되고 있는지 확인할 수 있습니다. 즉, 처음으로 하단으로 빠르게 스와이프했을 때 채색 호출이 성공적으로 취소되었다는 것을 의미합니다.

이 새로운 비동기 디자인을 사용하여 추적을 볼 때, 예측이 여러 이미지에서 동시에 실행되고 있음을 보여줍니다.

이것은 수직으로 쌓인 여러 예측 간격으로 표시됩니다.

이 모델은 신경 엔진에서 부분적으로 실행되기 때문에, 신경 엔진 장비에서도 관찰할 수 있다.

이미지를 연속적으로 색칠한 초기 구현으로, 스크롤하지 않고 이미지의 초기 보기를 색칠하는 데 약 2초가 걸렸다.

이미지를 동시에 채색한 비동기 구현으로 전환한 후, 그 시간은 절반에서 약 1초로 단축되었다.

그래서 전반적으로, 나는 비동기 예측 API와 Colorizer 모델과의 동시성을 활용하여 총 처리량을 약 2배 개선할 수 있었다.

그러나, 주어진 모델과 사용 사례가 동시 설계의 혜택을 받을 수 있는 양은 모델의 작업, 컴퓨팅 단위 및 하드웨어 조합, 그리고 컴퓨팅 장치가 바쁠 수 있는 기타 작업을 포함하는 몇 가지 요인에 크게 의존한다는 점에 유의하는 것이 중요합니다.

또한, ML 프로그램과 파이프라인 모델 유형은 예측을 동시에 실행함으로써 최고의 성능 향상을 제공할 것이다.

전반적으로, 앱에 동시성을 추가할 때, 실제로 사용 사례에 도움이 되는지 확인하기 위해 워크로드를 신중하게 프로파일링해야 합니다.

앱에 동시성을 추가할 때 명심해야 할 또 다른 중요한 것은 메모리 사용량입니다.

메모리에 동시에 로드된 많은 모델 입력과 출력 세트를 갖는 것은 애플리케이션의 최대 메모리 사용량을 크게 증가시킬 수 있습니다.

코어 ML 악기와 할당 악기를 결합하여 이것을 프로파일링할 수 있습니다.

추적은 컬러라이저 모델을 실행하기 위해 많은 입력을 메모리에 로드함에 따라 내 앱의 메모리 사용량이 빠르게 증가하고 있음을 보여준다.

잠재적인 문제는 내 코드의 채색 방법이 흐름 제어가 없기 때문에 동시에 채색되는 이미지의 양에는 고정된 제한이 없다는 것이다.

모델 입력과 출력이 작다면 이것은 문제가 되지 않을 수 있다.

그러나, 그것들이 크다면, 메모리에 이러한 입력과 출력의 많은 세트를 동시에 갖는 것은 앱의 최대 메모리 사용량을 크게 증가시킬 수 있다.

이것을 개선하는 방법은 기내 예측의 최대 양을 제한하는 논리를 추가하는 것이다.

이로 인해 메모리에 동시에 로드되는 입력과 출력이 줄어들어 예측을 실행하는 동안 피크 메모리 사용량을 줄일 수 있습니다.

이 예에서, 이미 작업 중인 두 개의 항목이 있다면, 이전 항목이 완료될 때까지 새로운 작업 항목을 연기합니다.

최선의 전략은 당신의 사용 사례에 달려 있습니다.

예를 들어, 카메라에서 데이터를 스트리밍할 때, 작업을 연기하는 대신 작업을 중단하고 싶을 수도 있습니다.

이렇게 하면 프레임을 축적하고 더 이상 일시적으로 관련이 없는 일을 하는 것을 피할 수 있습니다.

조금 뒤로 물러서서, 여기에 다른 예측 API를 언제 사용해야 하는지에 대한 일반적인 지침이 있습니다.

동기 컨텍스트에 있고 사용 가능한 각 입력 사이의 시간이 모델 대기 시간에 비해 크면, 동기화 예측 API는 잘 작동합니다.

입력을 배치로 사용할 수 있다면, 배치 예측 API는 자연스럽게 적합합니다.

비동기 컨텍스트에 있고 시간이 지남에 따라 많은 양의 입력을 개별적으로 사용할 수 있다면, 비동기 API가 가장 유용할 수 있습니다.

요약하면, Core ML 워크플로우를 진행하면서 모델 개발과 모델 통합 모두에서 최적화할 수 있는 많은 기회가 있습니다.

새로운 컴퓨팅 가용성 API는 장치에서 사용할 수 있는 하드웨어를 기반으로 런타임에 결정을 내리는 데 도움이 될 수 있습니다.

모델 수명 주기와 캐싱 동작을 이해하면 언제 어디서 모델을 로드하고 내릴지 가장 잘 결정하는 데 도움이 될 수 있습니다.

그리고 마지막으로, 비동기 예측 API는 Core ML을 다른 비동기 Swift 코드와 통합하고 동시 예측을 지원하여 처리량을 개선하는 데 도움이 될 수 있습니다.

이것은 코어 ML 팀의 벤이었고, 나는 AI가 아니다.