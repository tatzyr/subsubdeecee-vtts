10088

♪まろやかなインストゥルメンタルヒップホップ♪

♪

ジョン・カルスベーク:ようこそ!

私はジョンで、RealityKitに取り組んでいます。

ウラジミール・ヴキチェヴィッチ:そして、私はユニティ出身のヴラドです。

ジョン：没入型アプリのUnityサポートを導入できることに興奮しています。

UnityはAppleと協力して、この新しいプラットフォームに完全なUnity体験をもたらしました。

Unityは何万ものアプリで使用されており、Unityを使用して没入型アプリを構築できるようになりました。

Tribandは、Unityで構築されたApple Arcadeのタイトル「What The Golf?」をこのプラットフォームに持ち込んだ。

iPhoneでプレイするのは本当に楽しいし、このようにプレイするのは素晴らしい気分です。

Unityを使用して、このプラットフォームで没入型体験を作成するには、主に2つのアプローチがあります。

没入型エクスペリエンスとして、または他のアプリと一緒に共有スペースで、パススルーを使用してコンテンツと現実世界のオブジェクトをミックスするエクスペリエンスを作成できます。

また、完全に没入型のUnity体験をプラットフォームに持ち込むこともできます。

このアプローチに興味がある場合は、「Unity VRアプリを完全に没入感のある空間に活用する」をチェックすることをお勧めします。

Unityで共有スペースの体験を作成することは、アプリにエキサイティングな機会を開きます。

ヴラドが詳しくお伝えします。

ウラジミール:ありがとう、ジョン。

UnityとAppleは、Unityのコンテンツがプラットフォーム上で素晴らしく見えるようにするために、過去2年間協力してきました。

既存のプロジェクトから始める場合でも、まったく新しいものを構築する場合でも、Unityは使い慣れたツールといくつかの新しい機能を使用して没入感のある体験を作成するための素晴らしいツールです。

このプラットフォームでは、Unityのシェーダーとマテリアルを使用して、必要な視覚的な外観を実現できます。

デバイスに直接プレイモードに入る機能を導入し、反復時間を改善しています。

また、Unityシーンのコンテンツがどのように現実世界に持ち込まれるかを制御するボリュームカメラと呼ばれる新しいコンセプトもあります。

この新しいデバイスへの入力は、ルックアンドタップジェスチャーと同じくらい簡単にしたり、より複雑なインタラクションを伴うことができます。

そして、空間コンピューティング用のUnityコンテンツを準備するために、今日できることがいくつかあります。

以下は、これらの要素のいくつかが連携している例です。

このシーンは、Unityのシェーダーグラフで構築された素材を使用し、パススルーでシミュレータの共有スペースに表示されています。

後ろの鬼のように、完全に装備されたアニメーションキャラクターがいます。

物理学の相互作用は、あなたが慣れているように機能します。

この町のすべての住民は、キャラクターナビゲーションを使用して動き回っており、カスタムの動的スクリプト化された動作を使用して、このシーンを生き生きと感じさせます。

アセットストアの助けを借りて2週間でこれをまとめました。あなたのスペースで見ると見栄えが良く、近くであらゆる角度からシーンを見ることができます。

共有スペース内のすべてのコンテンツは、RealityKitを使用してレンダリングされます。

Unityの素材とシェーダーは、この新しい環境に翻訳する必要があります。

UnityはPolySpatialを作成しました。これは、この翻訳を処理し、この環境に多くのUnity機能をもたらします。

PolySpatialは、材料、規則的およびスキンされたメッシュレンダリング、および粒子効果とスプライトを変換します。

Unityシミュレーション機能がサポートされており、MonoBehaviours、スクリプト可能なオブジェクト、およびその他の標準ツールを引き続き使用します。

3つのカテゴリーの資料が翻訳されています。

それらは物理的ベースの材料、カスタム材料、およびいくつかの特殊効果材料です。

Unityの物理ベースのシェーダーに基づく素材は、RealityKitに直接翻訳されます。

ユニバーサルレンダリングパイプラインを使用している場合は、材料にLit、Simple Lit、またはComplex Litシェーダーのいずれかを使用できます。

パイプラインが組み込まれているため、標準シェーダーを使用できます。

これらはすべて、RealityKit PhysicallyBasedMaterialに翻訳されます。

カスタムシェーダーとマテリアルタイプは、Unity Shader Graphを通じてサポートされています。

Unity Shaderグラフは、複雑な材料の標準的な交換形式であるMaterialXに変換されます。

MaterialXシェーダーは、RealityKitのShaderGraphMaterialになります。

多くのUnity Shader Graphノードがサポートされているため、複雑で興味深い効果を作成できます。

手書きシェーダーはRealityKitによるレンダリングにはサポートされていませんが、UnityのRenderTexturesで使用できます。

その後、そのRenderTextureをShader Graphへのテクスチャ入力として使用して、RealityKitを介して表示することができます。

2つの追加のマテリアルシェーダータイプがサポートされています。

まず、Unlit Shaderで、照明の影響を受けずに単色や質感のオブジェクトを作成できます。

2つ目は、オブジェクトを介してパススルーを表示できるようにするオクルージョンシェーダーです。

オクルージョンシェーダーをワールドメッシュデータと一緒に使用して、コンテンツが現実世界とより統合されていると感じることができます。

Unity MeshRenderersとSkinnedMeshRenderersはサポートされており、ビジュアルコンテンツを実際の空間に持ち込む主な方法です。

装備されたキャラクターとアニメーションが利用可能です。

ユニバーサルまたは組み込みのレンダリングパイプラインのいずれかを使用でき、コンテンツはUnity PolySpatialを介してRealityKitに翻訳されます。

RealityKitが最終的なレンダリングを実行するため、後処理効果やカスタムパイプラインステージなどのレンダリング機能は利用できません。

UnityのShurikenシステムを使用したパーティクルエフェクトは、互換性がある場合はRealityKitのパーティクルシステムに翻訳されるか、ベイクドメッシュに変換されます。

スプライトは3Dメッシュになりますが、空間的な文脈でどのように使用するかを検討する必要があります。

PolySpatialは、UnityとRealityKitの間のレンダリングを最適化し、翻訳するために機能します。

Unityのシミュレーション機能は、物理学、アニメーションとタイムライン、パスファインディングとNavMesh、カスタムMonoBehaviours、その他の非レンダリング機能など、慣れているように機能します。

外観を微調整し、反復を高速化するために、Unity PolySpatialは「デバイスに再生」を有効にします。

デバイス上のコンテンツがどのように見えるかを確認するには、ビルドプロセスに時間がかかる場合があります。

PolySpatialを使用すると、初めてデバイスに再生できます。

デバイスに再生すると、シーンのインスタントプレビューを見たり、ライブで変更を加えたりできます。

シミュレーターで動作し、デバイスでもうまく機能します。

Play to Deviceを使用すると、要素の追加や削除など、コンテンツの配置とサイズを迅速に探索できます。

マテリアル、テクスチャ、さらにはシェーダーグラフを変更して、パススルーでコンテンツを所定の位置に表示しながら外観を微調整できます。

イベントがエディタに送り返されるため、インタラクションをテストできます。

シミュレーションは引き続き実行されるので、エディタに添付するだけで簡単にデバッグできます。

これはあなたが先ほど見たのと同じ城のシーンです。

左側のUnityで開いていて、デバイスにプレイすると、右側のシミュレータで実行されているのが見えます。

シーンにドラッグするだけで、さらに鬼を追加できます。

それらはシミュレーターまたはデバイスで即座に表示されます。

ピンクやネオングリーンの鬼がどのように見えるか見たい場合は、できます。

デバイスへの再生は、コンテンツを反復するための非常に効率的なワークフローであり、現在、共有スペースでコンテンツを作成するためにのみUnityで利用可能です。

Unityを使用して共有スペースに参加するボリュームコンテンツを作成しているため、ボリュームカメラと呼ばれる新しいコンセプトにより、シーンがどのように現実世界に持ち込まれるかを制御できます。

ボリュームカメラは、境界と非境界の2種類のボリュームを作成でき、それぞれに異なる特性があります。

アプリケーションはいつでも2つを切り替えることができます。

境界付きボリュームは、他のアプリやゲームと並んで、ボリュームとして共有スペースに存在します。

彼らはUnityの次元と変換、そして特定の現実世界のサイズを持っています。

配置を変更できますが、サイズを変更することはできません。

ボリュームカメラの寸法と変換は、アプリがボリュームで表示するシーンの領域を定義します。

それらはシーンユニットで指定されています。

Unityのシーンビューでは、ボリュームのプレビューを緑色で見ることができます。

ボリュームカメラの寸法と変換を操作することで、シーンのさまざまな部分をボリュームに取り込むことができます。

カメラを動かしたり回転したりすると、新しい物体が私の空間に見えてくります。

サイズを大きくすると、より多くのシーンが視界に入ります。

どちらの場合も、ボリュームは同じサイズのままです。

その中に表示されているコンテンツのみが変更されます。

ボリュームカメラの最初の配置では、スプリングがボリュームの側面と交差することに注意してください。コンテンツはRealityKitによってクリップされます。

ボリュームの端と交差するコンテンツがある場合は、クリップされたセクションを埋めるために、後ろ向きの素材でシーンに同じメッシュをもう一度配置することを検討してください。

無制限のボリュームは、このプラットフォームの完全なスペースに表示され、コンテンツがより没入感のある体験のためにパススルーと完全にブレンドすることができます。

シーン全体を選択するため、ディメンションはなく、その変換はシーンユニットが現実世界のユニットにどのようにマッピングされるかを指定します。

一度にアクティブになる無制限のボリュームカメラは1つだけです。

インタラクションについて話すと、無制限のボリュームの例が表示されます。

Unityは、このプラットフォーム上のアプリの複数の入力タイプをサポートしています。

このプラットフォームでは、人々は目と手を使ってコンテンツを見て、指を合わせて選択します。

フルハンドトラッキングとヘッドポーズデータにより、現実的なインタラクションを作成できます。

ARKitの拡張現実データは、キーボードやゲームコントローラーなどのBluetoothデバイスと同様に利用可能です。

タップジェスチャーは、このプラットフォーム上のコンテンツとやり取りする最も一般的な方法です。

オブジェクトがこれらのイベントを受信するには、入力コライダーが設定されている必要があります。

見てタップして遠くからオブジェクトを選択することも、手を伸ばして指でオブジェクトに直接触れることもできます。

最大2つの同時タップアクションが進行中です。

Unityでは、タップはWorldTouchイベントとして利用できます。

それらは2Dタップイベントに似ていますが、完全な3Dポジションを持っています。

手と頭のポーズトラッキングは、各ハンドジョイントとグローバルトラッキングオリジンに対する視聴者の頭の位置に関する正確な情報をアプリケーションに提供します。

低レベルのハンドデータはUnityのHandsパッケージを介して提供され、ヘッドポーズは入力システムを通じて提供されます。

これらは両方とも無制限のボリュームでのみ利用可能であり、ハンドトラッキングにアクセスするには、アプリケーションがデータを受け取る許可を要求する必要があります。

検出された飛行機、ワールドメッシュ、画像マーカーなどの拡張現実データは、ARKitとUnityのAR Foundationを通じて入手できます。

手や頭のポーズと同様に、ARデータは無制限のボリュームでのみ利用可能で、追加の許可が必要です。

最後に、キーボード、コントローラー、その他のサポートされているデバイスなどのBluetoothデバイスは、Unityの入力システムからアクセスできます。

一部のタイプの入力は無制限のボリュームでのみ使用できるため、構築するインタラクションの種類を決定する必要があります。

ルックアンドタップを使用すると、コンテンツは他のアプリケーションと一緒に使用できる制限されたボリュームで機能しますが、ハンドトラッキングや拡張現実データにアクセスする必要がある場合は、制限されていないボリュームを使用して許可を要求する必要があります。

これらのそれぞれは、適切なメカニズムを介してUnityアプリケーションに配信されます。

このサンプルでは、無制限のボリュームシーンでタップ、ハンドトラッキング、平面検出を使用します。

ARKitの平面検出で見つかった表面を見て、それに沿って指をドラッグして花を作ることができます。

花はハンドトラッキングで描かれており、タップして花を育てることができます。

あなたが育てた花は、Unityの物理システムを使って手の動きに反応します。

このように現実世界をコンテンツに組み込むことで、より深い没入感を生み出すことができます。

既存のインタラクションを適応させる最善の方法は、タイプによって異なります。

iPhoneなど、すでにタッチで作業している場合は、適切な入力コライダーを追加し、タップを主要な入力メカニズムとして引き続き使用できます。

VRコントローラーを使用している場合は、複雑さに応じて、タップまたはハンドベースの入力の観点からインタラクションを再定義する必要があります。

既存のハンドベースの入力は、変更なしで機能するはずです。

また、UnityのUIシステムの1つを使用して既存のUIパネルがある場合は、このプラットフォームに持ち込むことができます。

uGUIとUIツールキットを使用して構築されたユーザーインターフェイス要素がサポートされています。

他のUIシステムを使用している場合は、メッシュとMeshRendererを使用するか、RenderTextureに描画し、メッシュに配置される限り動作します。

Appleプラットフォームでの空間コンピューティングのサポートは、Unity 2022をベースにしたベータ版で間もなく提供される予定です。

しかし、今日からコンテンツの準備を始めることができます。

新しいプロジェクトを開始する場合は、Unity 2022以降を使用してください。

既存のプロジェクトがある場合は、2022年にアップグレードを開始してください。

プロジェクトに手書きのシェーダーがある場合は、シェーダーグラフに変換し始めます。

ユニバーサルレンダリングパイプラインの採用を検討してください。

組み込みのグラフィックスパイプラインはサポートされていますが、将来のすべての改善はユニバーサルパイプラインで行われます。

まだ使用していない場合は、入力システムパッケージの使用を開始してください。

混合モード入力はサポートされていますが、プラットフォームイベントは入力システムを介してのみ配信されます。

最後に、既存のアプリやゲームを空間コンピューティングに持ち込む方法、またはどのような新しい体験を作りたいかについて考え始めます。

あなたのアイデアが人々により多くの柔軟性を与えるために共有スペースに収まるかどうか、またはあなたのアプリがフルスペースの力を必要とするかどうかを検討してください。

このプラットフォームに対するUnityのサポートに関する詳細情報を入手し、早期ベータアクセスにサインアップするには、unity.com/spatialにアクセスしてください。

私はあなたがUnityとこの新しいデバイスで作成するすべての素晴らしいものを見ることに興奮しています。

ジョン：Unityは、稼働し、没入型アプリを構築する素晴らしい方法です。

そして、この新しいプラットフォームでRealityKitとうまく機能します。

プロジェクトの準備を今日から始めることができます。

Unityで完全に没入感のある体験を作りたい場合は、「Unity VRアプリを完全に没入感のある空間に」というセッションをお勧めします。

そして、このプラットフォームのゲーム開発技術の概要を知るために、「空間コンピューティングのための素晴らしいゲームを構築する」をお見逃しなく。

あなたが作ったものを見るのが待ちきれません。

ウラジミール:見てくれてありがとう。

♪