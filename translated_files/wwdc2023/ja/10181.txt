10181

こんにちは！私の名前はジャクソンです。

そして私はデビッドです。

このセッションでは、この分野でHDR画像と最近公開された標準に関する背景を提供します。

次に、新規および既存のAPIを使用してアプリでこれらの画像をサポートする方法について説明します。

デビッドはHDR画像パイプラインの処理の詳細に飛び込み、ハイダイナミックレンジコンテンツの表示に関するいくつかのより高度なトピックをまとめます。

HDRの仕組みについて掘り下げてみましょう。

物理的な世界では、私たちの目が適応する能力のおかげで、人間は膨大な範囲の光レベルを知覚することができます。

対照的に、典型的な標準ダイナミックレンジ、またはSDRディスプレイは、限られた範囲の光しか生成できません。

これは、シーンの画像がキャプチャされると、広い範囲の光レベルを何らかの形でより小さなSDR範囲に圧縮する必要があります。

ハイダイナミックレンジ、またはHDRディスプレイを使用すると、それらを圧縮することなく、はるかに広い範囲の光レベルを表示できます。

これにより、元のシーンに似ており、より明るく、より鮮やかな画像を表示できます。

私たちは長年にわたってハイダイナミックレンジをキャプチャする能力を持っていましたが、過去には、そのキャプチャ範囲を取り、SDR表示範囲に圧縮する必要がありました。

これで、HDRディスプレイに表示すると、シーンを元のようにレンダリングできます。

例えば、スノーシーンの上の日の出のこの画像では、現実世界の光レベルの広い範囲に落ちる領域があります。

SDRディスプレイでは、シーンの一部のみを正確に表現できます。

HDRディスプレイを使用すると、コントラストを損なうことなく、はるかに多くのシーンを表現できます。

したがって、HDR範囲のディスプレイを使用すると、シーンの一部を最も明るいSDRホワイトよりも明るくレンダリングできます。

これは一般的にヘッドルームと呼ばれています。

このパラダイムでは、リファレンスホワイトはSDRディスプレイが生成した最も明るいホワイトです。

その点を超えるものはヘッドルームです。

過去の講演では、HDR対応ディスプレイのヘッドルームでレンダリングできるコンテンツと対話するために、拡張ダイナミックレンジ（EDR）を導入しました。

EDRパラダイムでは、参照白は1.0で、ピークはディスプレイが表すことができる最大値です。

今日紹介するHDR APIは、EDRを使用して、ハイダイナミックレンジコンテンツのより完全なパイプラインを実装しています。

EDRについてもっと知りたい場合は、「EDRでHDRレンダリングを探索する」トークをチェックしてください。

これは、動作中のHDRの例です。

窓の前に座っている人のこのSDR画像は、本の中の紙の白が参考白のすぐ下にあるときによく見えます。

窓など、より明るいものは、転がされたり、クリップされたりします。

ただし、HDRで画像を表示できる場合は、ハイライトでより多くの詳細を表示し、シーン全体でコントラストをより確実に維持できます。

これは、HDRをサポートすることで得られる利点です。

では、なぜHDR画像をサポートするのですか?ユーザーが作成または提供したコンテンツが重要なアプリを構築している場合、HDRをサポートすると、その体験がさらに良くなります。

HDRサポートはほぼすべてのAppleプラットフォームで利用でき、Appleの信じられないほどのディスプレイハードウェアを最大限に活用できるように、これらのAPIを導入しました。

現在HDRサポートを検討するもう1つの重要な理由は、Appleが写真技術委員会を通じて国際標準化機構と協力して、今年HDR画像の新しい技術仕様を公開していることです。

この仕様であるTS22028-5は、品質を損なうことなく、HDRコンテンツを既存の静止画フォーマットにエンコードする構造を提供します。

HDRビデオ、キャプチャ、ディスプレイなどの他の形式のHDRとの混同を避けるために、このISO仕様に従うHDR画像を「ISO HDR」と呼びます。

sRGBとディスプレイP3を含む以前の典型的なSDR画像からスケールを想起し、白黒を1平方メートルあたり0.2と80カンデラと定義します。

一方、ISO HDRは、黒とデフォルトの参照白をそれぞれ.0005と203と定義しています。

203を超えるものはすべてヘッドルームです。

では、これらの新しい画像ファイルには何がありますか?

この仕様では、エンコーディング転送機能として、Hybrid Log-Gamma、HLG、またはPerceptual Quantizer、PQが必要です。

これらは、SDR画像で使用されるガンマ曲線に機能的に類似しています。

ISO HDRファイルのカラープライマリーはBT.2020プライマリーです。

これは広い色域で、これまではビデオでしか一般的に使用されませんでした。

バンディングの問題を避けるために、HDR画像はコンポーネントごとに10ビット以上である必要があります。

これは、HEIFのような一部のフォーマットはHDRをエンコードできますが、従来のJPEGのような他のフォーマットは、コンポーネントごとに8ビットしかサポートしていないため、22028-5に準拠できないことを意味します。

また、必要なメタデータについては、従来のICCプロファイルとCICPタグの両方が有効です。

これらの要件は、新しいISO HDRファイルを定義します。

あなたに関連する可能性のあるISO HDRファイルに関連付けられている追加のオプションのメタデータフィールドがいくつかあります。

参照環境タグは、コンテンツ参照条件の環境条件を定義します。

拡散白色輝度は、参照白色がこのコンテンツのどこに該当するかを定義します。

デフォルトは先ほど述べた203です。

シーン参照タグは、HLGが転送曲線である場合に使用できます。

画像コンテンツがシーンかディスプレイかを定義します。

このタグのデフォルト値は表示参照です。

マスタリングとコンテンツのカラーボリュームタグは、既存のHDRビデオに共通しており、画像に存在する色範囲に関する情報を定義します。

最後に、コンテンツライトレベルタグは、画像内のシーンのライトレベルに関する情報を提供します。

ISO HDRの詳細については、ISOのウェブサイトで仕様を確認してください。

ISO HDRに加えて、iPhoneでキャプチャされた画像のベストバージョンにアクセスする方法を初めてお伝えできることを非常に嬉しく思います。

2020年以来、数兆枚のiPhone画像が、SDR画像からHDR表現を再構築できる追加データでキャプチャされました。

私はこのタイプのHDRを「ゲインマップHDR」と呼んでいます。

今日、デビッドと私は、あなたのアプリでこのHDR表現にアクセスするための新しいAPIを紹介し、すでにあなたの写真ライブラリにある任意の世代のゲインマップHDRから信じられないほどのHDR画像を表示するオプションを提供します。

では、これらの新しいAPIを使用してHDR画像をアプリに組み込む方法について話しましょう。

お見せするAPIは、SwiftUI、UIKit、AppKitで利用できます。

SwiftUIとUIKit APIを見てみましょう。 

この例では、URL経由でアクセスできるISO HDR画像ファイルがあり、それを表示したいです。

私がしなければならないのは、UIImageを作成し、ハイダイナミックレンジを有効にするための新しい許可されたDynamicRange修飾子と一緒にイメージビューに提供することだけです。

それはとても簡単です。

同様に、UIKitアプリでは、新しいUIImageViewプロパティ「preferredImageDynamicRange」と、HDR結果を設定できます。

ダイナミックレンジのプロパティには、HDRコンテンツの処理方法に関する3つのオプションが含まれています。

これらのプロパティは、SwiftUI Image、UIImage、およびNSImageビューで動作します。

ハイオプションは、ハイダイナミックレンジのコンテンツを表示したいことをシステムに知らせ、表示状態が変更されたときの更新を含め、そのコンテンツを現在のディスプレイにマッピングする重い作業を行うことができます。

画像がHDRでない場合は、dynamicRangeフラグがない場合とまったく同じエクスペリエンスが得られることに注意してください。

これらのオプションは、HDR以外のコンテンツで安全に使用できます。

標準オプションは、ハイダイナミックレンジレンダリングを無効にし、代わりにすべてのコンテンツをSDRとして表示します。

これは、SDR範囲外のトーンマッピングコンテンツを意味します。

これは、HDR機能のないディスプレイに画像が表示される方法でもあります。

最後に、いくつかのHDRを表示したいが、コンテンツの全範囲を表示しない場合は、constrainedHighオプションを使用する必要があります。

なぜ、すべてではなく、いくつかのHDRだけを表示したいのですか?

さて、考えられる理由はいくつかあります。

この例では、多くの画像のサムネイルを含むスタックビューがあります。

これらの画像の中にはHDRであるものもあれば、そうでないものもあります。

私が高いDynamicRangeオプションを使用すると、これはあなたが得るものです。

一部の画像は非常に明るくHDRですが、SDR画像はそうではなく、今では鈍く見え、おそらく非アクティブでさえあります。

では、constrainedHighオプションを使ってみましょう。

HDRコンテンツの使用が許可されるヘッドルームを制限することで、フィルムストリップをより一貫性のあるものにします。

あなたはまだHDR画像をSDR画像と区別することができますが、私はもはやSDR画像が灰色または非アクティブに見えるという問題はありません。

特定の画像ビューにconstrainedHighまたは標準を使用したいもう1つの理由は、HDRコンテンツが非常に明るくなる場合があり、アプリの他の側面から注意をそらしたくない可能性があることです。

たとえば、ここでは、フルHDRで表示すると、アプリの最も重要な部分のように見えますが、重要なコントロールや情報から注意をそらしている小さな画像です。

先に進む前に、ここには画像のトーンマッピングを含まないオプションがないことに気づいたかもしれません。

OSにトーンマッピングをさせたくない場合は、下位レベルのAPIを使用する必要があります。このセッションの後半で説明します。

心に留めておくべきHDRの重要な側面は、HDRデータをクランプしたり劣化させたりしないパイプラインが必要であることです。

今日議論するAPIはすべて完全にサポートされていますが、非推奨のAPIにはHDRセーフなパイプラインがない可能性があります。

たとえば、非推奨のUIGraphicsBeginImageContextWithOptionsを使用して画像のサイズを変更すると、HDRと広色域の色が失われます。

HDR対応アプリを作成する際には、これは避けるべきです。

サムネイルを作成しようとしている場合、UIKitはiOS 15のUIImageにサムネイルAPIを導入しました。

正確なサイズ制御を必要としない場合、これはHDRサムネイルを取得するための推奨される方法です。

iOS 15より前により多くのコントロールが必要な場合やサポートが必要な場合、UIKitはUIGraphicsImageRendererを提供しています。

imageRendererFormatを使用することで、UIKitは、再描画時に画像内のHDR情報が失われないレンダラーを構築する方法を知っています。

画像データをアプリに取り込む一般的な方法を見てみましょう。

PhotoKitは、アプリがフォトライブラリにアクセスするためのインターフェースを提供します。

私のアプリでは、メインビューに写真ピッカーを追加し、ユーザーが選択した画像に簡単にアクセスできます。

PhotosPickerはHDRデータを保持しない形式に画像をトランスコードしようとする可能性があるため、「現在の」エンコーディングポリシーと一般的な「画像」マッチングタイプを使用します。

フォトピッカーの仕組みの詳細については、「写真ピッカーをアプリに埋め込む」セッションをチェックしてください。

ISO HDR画像を使用すると、DataRepresentationからUIImageを作成し、余分なコードなしで画像ビューで直接使用できます。

ゲインマップHDRもサポートしている場合は、新しいUIImageReaderを使用して、利用可能なときにHDR表現を取得できます。

このAPIは、HDRディスプレイの場合、デフォルトでHDR表現を返し、それ以外の場合はSDRバージョンを返します。

これまで議論したAPIは、画像がHDRであることや、画像がHDRであることを知ることに依存していません。

画像ビューに高いダイナミックレンジを表示する必要があることを知らせるとき、その画像がHDRであるかどうかは問題ではないことを思い出してください。

ただし、画像がHDRであるかどうかを識別したいパイプラインやアプリがあるかもしれません。

UIKitを使用すると、isHighDynamicRangeプロパティをチェックして、コンテンツがISO HDR互換かどうかを判断できます。

AppKit、CoreGraphics、CoreImageでは、画像のCGColorSpaceを確認する必要があります。

CGColorSpaceUsesITUR_2100TF関数は、ISO HDR画像に対してtrueを返します。

HDR画像は、幅広いヘッドルームを使用できます。

たとえば、現在のiPhoneは、最大8倍のヘッドルームを使用する画像を生成します。

ただし、一部のディスプレイのみがHDRを表示でき、すべてのHDRディスプレイが同じというわけではありません。

iPhone 14は、リファレンスホワイトよりも最大8倍明るくHDRハイライトを表示でき、12.9インチのiPad ProとMacBook Proは最大16倍、Pro XDRディスプレイは最大400倍を表示できます。

他のほとんどのAppleディスプレイは、最大2倍のヘッドルームを表示できます。

しかし、これはほとんどのHDRコンテンツでは十分ではないかもしれません。

サポートされているHDR機能を備えた外部ディスプレイもあります。

これらのディスプレイの完全なリストはありません。ただし、アプリが現在表示されているディスプレイの機能を判断するためのAPIがあります。

iOSとiPad OSでは潜在的なEDRHeadroomを照会し、macOSではmaximumPotentialExtendedDynamicRange-ColorComponentValueを照会して、アプリが表示されているディスプレイの機能を判断できます。

より高度なトピックに移る前に、HDRを表示することが理にかなっているときについて話しましょう。

私が議論したように、HDRは素晴らしく見え、画像を表示するときにサポートを含めることを検討する必要があります。

しかし、時には気が散ることがあります。

したがって、HDRがあなたに与えることができる余分なポップを必要としないと思う場合は、constrainedHighまたは標準オプションの使用を検討してください。

要約しましょう。

これで、ISO HDR画像を識別し、HDR画像を表示し、フォトライブラリからISO HDRとゲインマップHDRにアクセスする方法、およびディスプレイがHDRであるかどうかを判断する方法がわかります。

今、デビッドはHDR画像の読み取り、書き込み、操作を案内します。

ありがとう、ジャクソン。HDR画像を扱う場合、アプリがサポートする可能性のある一般的な操作がいくつかあります。ファイルまたはデータからISO HDRまたはゲインマップHDR画像をメモリに読み込む。HDRコンテンツを保持しながらメモリ内の画像を変更する。HDRを失うことなく、ある画像クラスから別の画像クラスに変換する。そして最後に、HDR画像をISO HDRファイルに書き込む。

機能的なHDR画像パイプラインの重要な特性は、画像オブジェクトが関連する色空間を持っていることです。

たとえば、CGImageとCIImageの両方のオブジェクトは、これにCGColorSpace APIを使用します。

画像はさまざまなサポートされている色空間を持つことができますが、ISO HDR画像にはITUR 2100 HLGまたはPQのいずれかのCGColorSpaceがあります。

それを念頭に置いて、ISO HDR画像の読み方から始めましょう。

UIImageとNSImageは、ISO HDR画像の読み取りを自動的にサポートするようになりました。

Appleのカラー管理インフラストラクチャであるColorSyncは、HDR ICCプロファイルを処理し、表示に適した画像オブジェクトを提供します。

ゲインマップHDR画像を読むときは、ハイダイナミックレンジを好むUIImageReader構成を作成することで、HDR表現をリクエストできます。

この新しい動作は、ゲインマップHDR画像にのみ影響することに注意してください。

NSImageやUIImageと同様に、Core ImageはISO HDRファイルの読み取りを自動的にサポートします。

あなたがする必要があるのは、CIImage contentsOfURL APIを使用することだけです。

結果のCIImageオブジェクトには、ファイルの色空間からCore Imageの拡張範囲の作業空間に変換する正しいレシピが自動的に含まれます。

コードをデバッグするときにXcodeのQuickLook機能を使用して、画像オブジェクトのレシピを調べることができます。

この例では、QuickLookポップオーバーは、画像がPQ ISO HDR色空間から変換されていることを示しています。

コードは、ファイルの色空間を検査するために.colorspaceプロパティを取得することもできます。

これは、sRGBやDisplay P3などのSDR色空間、またはHDR色空間である可能性があります。

CoreGraphics APIを使用する場合は、新しいdecodeRequestキーをdecodeToHDRに設定してCGImageSourceCreateImageAtIndexを使用することで、同等の動作を得ることができます。

数分前、ジャクソンはHDR画像をSDRに制限したい理由を説明しました。

同様に、Core Imageを使用しているアプリは、画像がSDRにトーンマッピングされていることを確認するために、自動HDRサポートをオーバーライドしたい場合があります。

これは、機能検出などの特定のシナリオでHDRの使用を避けたい場合に役立ちます。

これを有効にするには、CIImageの作成時にtoneMapHDRtoSDRオプションを提供するだけです。

この場合、返されるCIImageオブジェクトには、他の操作が適用される前にHDRソースをSDR範囲にトーンマップするレシピステップが含まれます。

このオプションは、画像にHDR色空間がある場合にのみ効果があることに注意してください。

結果のCIImageは、画像ビューがdynamicRange.standardオプションを使用することを指定するのと同じです。

また、これは、decodeRequestがdecodeToSDRに設定されているCGImageSourceCreateImageAtIndexを使用するのと同じ動作です。

従来、ゲインマップHDR画像は写真アプリでフルダイナミックレンジを表示しますが、Core ImageやImageIOなどのAPIではSDR表現のみが利用可能でした。

アプリケーションがゲインマップHDR画像のフルレンジにアクセスできるようにする新しいAPIについて説明できることを本当に楽しみにしています。

APIはとても使いやすいです。

CIImageを初期化するときに、expandToHDRオプションを提供するだけです。

この場合、返されるCIImageオブジェクトには、プライマリ画像とゲインマップを組み合わせてHDR画像を生成するレシピが含まれます。

フォトライブラリにこれをサポートするための追加のゲインマップデータが含まれている場合、画像の.colorspaceプロパティはHDR色空間になります。

この動作は、decodeRequestキーをdecodeToHDRに設定してCGImageSourceCreateImageAtIndexを使用することと同等です。

これらのオプションはRAWファイルでも機能しますが、これから詳しく説明します。

iPhoneからのProRAW画像とカメラからのRAW画像は、写真家に重要な創造的なコントロールを与える柔軟な画像フォーマットです。

これには、シーンの一部をHDRヘッドルームにレンダリングする機能が含まれます。

多くのRAWフォーマットには十分なダイナミックレンジが含まれており、単に制約のないフォームに処理する必要があります。

これがどのように機能するかを説明しましょう。

まず、アプリケーションがデフォルトのSDRを表示したい場合は、通常どおりURLから画像を作成します。

しかし、アプリケーションがデフォルトのHDRレンダリングの外観を表示したいだけなら、あなたがする必要があるのは新しいexpandToHDRオプションを追加することだけです。

ただし、アプリがRAWの完全な機能のロックを解除したい場合は、コードはURLからCIRAWFilterを作成する必要があります。

そのフィルターに出力画像を尋ねると、デフォルトの外観のCIImageが表示されます。

しかし、このAPIの主な利点は、フィルターを簡単に変更できることです。

各CIRAWFilterインスタンスには、アプリが出力画像を変更するために変更できるいくつかのプロパティがあります。

これらのプロパティは、「ProRAW画像のキャプチャと処理」セッションでよく説明されていますが、このHDRディスカッションに特に関連するものを確認しましょう。

RAW画像のダイナミックレンジの量は、0から1までの任意の値に調整できます。

extendedDynamicRangeAmountプロパティは、Jacksonが以前に説明したviewDynamicRangeコントロールに似ています。

このプロパティのデフォルト値は0で、出力画像がSDRである必要があることを示します。

このプロパティの最大値は1で、出力画像がファイルに存在するヘッドルームを最大限に活用する必要があることを示します。

これは、ISO HDR画像を読み取るさまざまな方法をまとめています。

次に、HDR画像を変更する方法に関する推奨事項について話し合いましょう。

Core Imageは、HDRをサポートする150以上のフィルターが組み込まれているため、HDR画像を操作するための強力で柔軟なAPIを提供します。

これらのフィルターはすべて、HDRコンテンツを含む画像を生成または処理できます。

これらのフィルタはすべて、コア画像の作業色空間がクランプされておらず線形であるため、0から1の範囲外のRGB値を可能にするため、機能します。

アプリを開発する際に、特定のフィルターがHDRをサポートしているかどうかを確認できます。

これを行うには、フィルターのインスタンスを作成し、フィルターの属性にカテゴリを尋ね、配列にカテゴリの高いダイナミックレンジが含まれているかどうかを確認します。

組み込みのCIフィルタとカスタムCIカーネルの詳細については、「Core Image、Metal、SwiftUIでEDRコンテンツを表示する」セッションを参照してください。

次に、HDR画像をISO HDRファイルに書き込むことについて議論しましょう。

多くの場合、アプリはメモリ内の画像オブジェクトを新しいファイル表現に書き込む必要があります。

従来、UIImage、jpegData、およびpngData APIを使用すると、8ビットの精度SDRイメージが保存されます。

今年の新機能、UIImageは、オブジェクトにHDRコンテンツが含まれている場合、16ビットPNGまたは10ビットHEIF形式のいずれかを使用してISO HDR画像を自動的に書き込むことができます。

また、元の画像がゲインマップHDR画像の場合、ISO HDRに変換されます。

同様に、Core Imageは、HDR色空間を指定し、RGBA16形式を要求するwritePNGRepresentationOfImageを呼び出すと、HDR PNGファイルを書き込むことができます。

または、Core Imageは、HDR色空間を指定し、RGBA16形式を要求するwriteTIFFRepresentationOfImageを呼び出すと、HDR TIFFファイルを書き込むことができます。

PNGとTIFFの両方がロスレス圧縮を使用しており、ファイルサイズがはるかに大きくなることに注意してください。

その結果、ベストプラクティスは、writeHEIF10RepresentationOfImageを使用してHEIFファイルを作成し、HDR色空間を指定することです。

あるフレームワーククラスから別のクラスへ、またはある色空間から別の色空間に変換する必要がある場合があります。

画像クラスUIImage、CIImage、CGImage、IOSurface、およびCVPixelBufferの間で変換するプロセスは、ほとんど同じままです。

とはいえ、HDRパイプラインで作業する際に見るべき点がいくつかあります。

まず、IOSurfaceまたはCVPixelBufferオブジェクトへの変換について話し合いましょう。

この画像タイプは、たとえば、CALayerのコンテンツとして使用できるため便利です。

また、バイプレーナークロマサブサンプリング画像を保持できるため、非常にメモリ効率が高まります。

CVPixelBufferを使用する前に、ISO HDR互換コンテンツがあることを必ず宣言してください。

最初のステップは、10ビットのバイプレーナーフルレンジなどの適切なフォーマットでピクセルバッファを作成することです。

その間、最高のパフォーマンスのために、IOSurfacePropertiesKeyを提供することで、バッファをサーフェスバックする必要があることを必ず指定してください。

次に、CVPixelBufferに添付ファイルを追加して、ISO HDR互換の色空間プロパティが含まれていることをシステムが認識できるようにします。

CVPixelBufferがあれば、それをCIImageに変換するのは簡単です。

CIImage withCVPixelBuffer APIを呼び出すだけです。

また、CIContextを使用してバッファにレンダリングすることで、CIImageからCVPixelBufferに変換できます。

アプリがCore ImageとCGImageRef APIの間で変換したい状況がいくつかあります。

この変換でHDRコンテンツを保存したい場合は、HDR色空間を選択し、RGBA16やRGBAh形式などのディープピクセル形式をリクエストする必要があります。

そして今年新しく、CoreImageは深いがメモリの半分を使用するRGB10フォーマットを追加しました。

CIImageをCGImageに変換することは、CGImagesがさまざまなAPIでサポートされていることを考えると、非常に便利です。

しかし、ユーザー対話型レンダリングの最高のパフォーマンスのためにそうすることは推奨されないことに注意してください。

最速のパフォーマンスを得るには、CoreImageをMTKViewに直接レンダリングするか、PixelBufferを介してCALayerにレンダリングするのが最善です。

CALayersといえば、ジャクソンに戻って、より複雑なワークフローに必要な低レベルのAPIについて詳しく学びましょう。

ありがとう、デビッド!

CALayersは、最高のレンダリングパフォーマンスや、コンテンツがどのようにアプリに合成されるかをより詳細に制御する必要があるときに強力なツールです。

CALayersでHDRレンダリングを有効にするには、 wantsExtendedDynamicRangeContentプロパティを設定できるようになりました。

これは、CAMetalLayersがディスプレイのヘッドルームにコンテンツを表示できるようにするために使用されるプロパティに似ています。

これら2つの方法の主な違いは、CALayerプロパティがレイヤーコンテンツのトーンマッピングを可能にするのに対し、CAMetalLayerはできないことです。これは実際にはどういう意味ですか?

この画像とプロットは、10倍のヘッドルームを持つコンテンツを示しています。

少なくとも10倍のヘッドルームが利用可能なディスプレイにレンダリングされると、両方のレイヤーは同じように動作します。

ディスプレイには5倍のヘッドルームしかないと仮定しましょう。

CAMetalLayerの場合、5回を超える画像データは、ディスプレイが表示できるものに固定され、画像の急激な不連続が生じます。

CALayerの場合、その不連続性を避けるために、画像はトーンマッピングされます。

使用される正確なトーンマッピングアルゴリズムは、その画像で使用される転送曲線によって異なります。

これらのアルゴリズムの詳細については、HLGとPQのITU規格を参照してください。

CALayersはHDRコンテンツを画面に表示するための迅速かつ簡単な方法を提供し、CAMetalLayersは独自のトーンマッピングパイプラインを自由に作成できます。

CALayerを直接使用してHDRをレンダリングするには、これらの利用可能なクラスのいずれかを使用する必要があります。

ISO HDRとして適切にタグ付けされたCGImage、CVPixelBuffer、またはIOSurfaceタイプのオブジェクトは、CALayerによってレンダリングされ、トーンがマッピングされます。

CALayerを直接使用し、これらのクラスの1つを使用していない場合は、Davidが説明した方法の1つを使用して変換できます。

HDRワークフローで作業するときは、正しいピクセルフォーマットを使用することが重要です。

これらのピクセルフォーマットは、HDRデータを扱うときに安全に使用できます。

16ビットと32ビットのフロートフォーマットは、常に高いダイナミックレンジをサポートしています。

16ビット整数形式は、適切なファイル形式とコンテキストでHDRコンテンツをサポートするためにも機能します。

最後に、メモリとファイルサイズが重要な場合に使用できる10ビットピクセルフォーマットがあります。

これは、ほとんどの圧縮されたISO HDR画像のデフォルトのビット深度です。

HDRコンテンツに使用できるCGImageを作成する際には、CoreGraphicsフラグもあります。

前のリストと同様に、float、half float、16ビット整数、10ビットRGBを使用できます。

このような新機能を導入する際の最後の重要なトピックの1つは、下位互換性です。

HDR画像を扱う際に、古いバージョンのiOSとmacOSをサポートするために何ができますか?

ISO HDR画像の場合、CoreImageはHDRをSDRに変換するtoneMapHDRtoSDRオプションを提供します。

同様に、CoreGraphics CGContextを使用してレンダリングする場合、SDR CGColorspaceをターゲットにすることができ、画像はそのスペースにトーンマップされます。

ゲインマップHDRでは、新しいexpandToHDRオプションが使用されたときにバージョンチェックを使用してゲートします。

これらのオプションを省略すると、ファイルのSDRバージョンが常にHDRバージョンの代わりに読み込まれます。

最後に、HDR画像の読み取り、書き込み、表示のための新しいAPIを導入し、ゲインマップHDR表現にアクセスする方法を示し、完全にHDR対応のパイプラインを操作するためのAPIを提供します。

あなたがHDRで作る素晴らしいものを見るのが待ちきれません!

一緒に:見てくれてありがとう!

。