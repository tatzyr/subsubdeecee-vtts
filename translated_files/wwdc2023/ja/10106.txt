10106

♪ ♪

ニコラス：こんにちは、「iPadOSアプリで外部カメラをサポートする」へようこそ。

私はカメラソフトウェアチームのニコラス・ゲロです。このセッションでは、iPadアプリが外部カメラの使用を開始する方法についてです。

ステージマネージャーの強力な機能セットには、iPadのディスプレイを複数の画面に拡張する機能が含まれます。

また、iPadOS 17では、アプリはApple Studio Displayのような外部カメラを使い始めることができます。

このiPad Proでは、FaceTimeが開いていて、接続されているディスプレイのカメラを使用しています。

この大きなApple Studio Displayでアプリを実行すると、通話の反対側の人々が私のより良い視野角を持っているので、これは素晴らしいことです。

私はまた、それと一緒にセンターステージを使用することができ、それは私が動き回るときに私をフレームに保つのに役立ちます。

FaceTime、コードスキャナー、WebKitは外部カメラを使用しており、アプリができることの素晴らしい例です。

Apple Pro Display XDRのようにカメラを内蔵していないモニターを使用する場合、人々はしばしばその上にUSBカメラを置きます。

USBカメラがモニターに接続されている場合、モニターがiPadに接続されると、カメラもアプリで利用できるようになります。

iPadアプリは、外部カメラやウェブカメラを使って写真を撮ったり、映画を録画したりできます。

また、コントロールセンターから利用可能なポートレートブラーやスタジオライトビデオエフェクトなど、他のシステムカメラ機能もサポートしています。

USB-Cコネクタ付きのiPadは、外部カメラをサポートしています。

アプリは、USBビデオクラスまたはUVCの仕様に準拠したデバイスを使用できます。

これは、ビデオストリーミングをサポートするUSBデバイスの標準を定義しています。

そして、あなたのアプリが使用できる人気のあるカメラがたくさんあります。

一部の外部カメラにはマイクが内蔵されており、アプリでも利用できます。

一部のメーカーは、複数の入力間で切り替えて単一のビデオストリームを出力するHDMIスイッチャーなど、UVC仕様に準拠した非カメラデバイスを製造しています。

iPadOSでは、アプリはこのようなデバイスを使用できます。

外部カメラのサポートは、iPadのリッチメディアエコシステムの大きな強化です。

発見と使用から始めて、あなたのアプリがどのようにそれらを使用できるかを紹介します。

次に、サークルバックして、ビデオの回転をわかりやすくします。

次に、あなたのアプリが外部カメラに含まれているマイクをどのように使用できるかについて説明します。

そして最後に、あなたのアプリのベストプラクティスについて話し合います。

まず、iPadアプリが外部カメラの使用を開始する方法について説明します。

iPadアプリは、写真を撮ったり、映画を録画したり、ビデオ通話のためにネットワーク経由でカメラフレームを送信したりするなど、多くの機能にカメラを使用します。

AVFoundationフレームワークを使用すると、アプリは内蔵カメラと外部カメラ、特にAVCaptureプレフィックス付きクラスを使用できます。

アプリがカメラをどのように使用できるかを確認しましょう。

まず、アプリはカメラとマイクを表すAVCaptureDevicesを使用します。

次に、AVCaptureDeviceInputsでラップされ、AVCaptureSessionに接続できます。

AVCaptureSessionは、AVCaptureグラフの中央制御オブジェクトです。

AVCaptureOutputsは、さまざまな方法で入力からデータをレンダリングします。

MovieFileOutputはQuickTimeムービーを記録します。

PhotoOutputは、高品質の静止画とLive Photosをキャプチャします。

VideoDataOutputやAudioDataOutputなどのデータ出力は、カメラやマイクからアプリにビデオまたはオーディオバッファを配信します。

また、メタデータや深度など、他の種類のデータ出力もあります。

ライブカメラのプレビューには、CALayerのサブクラスであるAVCaptureVideoPreviewLayerという特別なタイプの出力があります。

データは、AVCaptureConnectionsを介してキャプチャ入力から互換性のある出力に流れます。

これらのクラスは、iOS、macOS、およびtvOSで利用できます。

AVCaptureを初めてご利用の方は、developer.apple.comのCapture Setupのスタートページで詳細をご覧ください。

iPadOS 17の新機能で、アプリはAVCaptureで外部カメラにアクセスできます。

アプリがすでに内蔵カメラを使用している場合は、簡単な更新を行い、外部カメラの使用を開始できます。

それらを発見するのは簡単です。

各外部カメラはAVCaptureDeviceインスタンスで表されます。

また、AVCaptureDeviceとAVCaptureDeviceDiscoverySessionから既存のAPIでそれらを見つけることができます。

AVCaptureDeviceには、メディアタイプ、デバイスタイプ、位置の3つの主な属性があります。

外部カメラは、内蔵カメラと同じようにビデオメディアデータを提供します。

そして、彼らのデバイスタイプは外部です。

外部カメラの使用に精通しているmacOSアプリ開発者にとって、これは外部の未知のデバイスタイプを廃止します。

外部カメラはiPadから独立して移動できるため、デバイスの位置は指定されていません。

これらの3つの属性は、AVCapture APIを使用して外部カメラを見つけるために使用できます。

アプリで外付けカメラを使い始めるのは簡単です。

このセッションでは、人気のサンプルカメラアプリAVCamを変更して、Apple Studio Displayの外部カメラからストリーミングします。

このセッションで行ったすべての変更を含むAVCamの完成版は、developer.apple.comからダウンロードできます。

現在、このアプリは内蔵カメラを使用しており、ユーザーがボタンを押すとフロントカメラとリアカメラを切り替えることができます。

AVCamが起動すると、背面カメラから始まります。

アプリが内蔵カメラよりも外付けカメラを探すことを好むようにコードを変更します。

iPadをApple Studio Displayに接続すると、アプリを実行し、起動すると外部カメラを使用します。

これは素晴らしいです。

AVCamは現在、外部カメラを使用しており、必要なのは数行のコードだけでした。

AVCaptureVideoPreviewLayerはデフォルトで外部カメラをミラーリングし、Apple Studioディスプレイでカメラを使用するのに適しています。

必要に応じて、この動作を無効にすることができます。

このセッションの最後に、ベストプラクティスのセクションでこれを行う方法について説明します。

では、アプリをiPadのディスプレイに移動します。

そして、楽しみのために、外付けカメラのプラグを抜きます。

ああ、アプリのカメラプレビューがフリーズしていて、今はカメラを使っていません。

AVCamは、外部カメラの接続と切断イベントを処理するために、より多くの変更が必要になります。

内蔵カメラとは異なり、ユーザーはいつでもiPadから接続および切断できるため、外部カメラには特別な注意が必要です。

アプリはこれらのイベントを監視して、カメラがいつ利用可能になったか、使用できなくなったかを知ることができます。

同じ物理デバイスが再接続されると、AVCaptureDeviceの新しいインスタンスを使用して表現されます。

アプリが接続と切断のイベントをリッスンするために使用できる既存のAPIがあります。

AVCaptureDeviceのisConnectedプロパティ、またはカメラが行き来するにつれて更新されるAVCaptureDeviceDiscoverySessionのデバイスプロパティをキー値で観察できます。

AVCaptureDevicesはまた、接続ステータスが変更されたときに通知を投稿し、アプリはカメラの可用性を監視するためにそれらを監視することができます。

システムはキー値観察コードを呼び出し、バックグラウンドキューに通知を投稿します。

したがって、必ず処理をAVCaptureSessionキューとメインスレッドと同期させてください。

AVCamに戻ると、外部カメラの接続と切断イベントをリッスンするためのコードを追加します。

アプリがデフォルトのデバイスを確認した後、カメラが切断されたときを観察します。

そして、それが起こると、AVCamは内蔵カメラに切り替わります。

アプリが起動しても、まだ外部カメラを使用しています。

そして、接続が切断されると、アプリは内蔵カメラに切り替わります。

しかし、外部カメラが再接続されると、AVCamはそれに切り替わりません。

AVCamは、実行中に接続されている外部カメラをどのように処理する必要がありますか?

プラグを差し込んだ後、それに切り替えるべきですか？

iPadアプリに外部カメラを採用することの難しい側面は、接続と切断のイベントを処理することです。

これを簡単にするために、iPadOSは自動カメラ選択のためのAPIを導入しています。

APIを使用すると、アプリはオペレーティングシステムと統合して、利用可能な最高のカメラを使用できます。

これは、アプリがカメラを変更する別の方法です。

macOS Venturaは、Continuity Cameraをサポートするための自動カメラ選択のためのAPIを導入しました。

このセッションで説明する行動は、iOSに固有のものです。

Mac用のこのAPIの使用方法の詳細については、2022年の以前のセッション「Continuity Camera to your macOS app」とそのセクション「Making a magical Experience」を参照してください。

自動カメラ選択は、iOSのAVCaptureDeviceに導入された2つの新しいクラスプロパティ、userPreferredCameraとsystemPreferredCameraを使用して機能します。

これらのプロパティは両方ともキー値で観察可能です。

userPreferredCameraは、使用するカメラのユーザーの選択を示す読み取り/書き込みプロパティです。

ユーザーがアプリでカメラを選ぶたびに設定する必要があります。

そうすることで、システムはユーザーの好みを知ることができます。

systemPreferredCameraは、システムによって決定される最適なカメラを指定する読み取り専用プロパティです。

デフォルトでは、システムはフロントカメラの使用を推奨していますが、代わりにバックカメラを使用する場合、アプリは目的の動作をシステムに通知できます。

異なるカメラがユーザーによって選択されるため、推奨事項が変更されます。

しかし、あなたはシステムがどのカメラが最適かをどうやって知っているのか疑問に思うかもしれません。

もう少ししたらそれに飛び込みます。

まず、AVCaptureDeviceのuserPreferredCameraプロパティについて説明します。

このプロパティでは、システムは起動とシステムの再起動中に各アプリに選択されたカメラの短い履歴を保存します。

これにより、アプリはユーザーの履歴と、現在接続されているカメラに関するシステムの知識を組み合わせることができます。

したがって、カメラが切断された場合、システムはユーザーの履歴に基づいて次に利用可能なカメラを返します。

ユーザー選択履歴がない場合、または優先カメラが接続されていない場合、システムは常に使用できるカメラを返却し、以前にストリーミングされたカメラを優先しようとします。

アプリはこのプロパティを使用して、システムにユーザーのカメラ設定を保存させることができます。

AVCaptureDeviceのsystemPreferredCameraプロパティは、使用するのに最適なカメラをインテリジェントに返します。

最初にユーザーの好みをチェックします。

そして、ユーザーが外部カメラをiPadに接続すると、システムは新しいデバイスを返します。

これは、ユーザーが新しいカメラを接続すると、暗黙のうちにそれを使用する意図を示しているためです。

これら2つの入力は、システムが好むカメラを決定します。

自動カメラ選択APIは、アプリがシステムとどのように統合するかを選択するのに柔軟です。

iPadのみが外部カメラをサポートしていますが、iPhoneアプリはユーザーが好むカメラストレージにAPIを使用することもできます。

ユーザーがカメラを変更できるアプリもあれば、切り替える方法を与えずにカメラに固執するアプリもあります。

APIを使用すると、アプリは自動カメラと手動カメラの選択を選択できます。

FaceTime、コードスキャナ、WebKitは、ニーズに合わせてカメラの選択動作が異なる素晴らしい例です。

FaceTimeを起動すると、常にフロントカメラまたは外部カメラを使用します。

また、通話中、ユーザーは内蔵カメラを切り替えることができます。

しかし、外部カメラを使用すると、カメラのスイッチボタンが非表示になります。

FaceTimeは、デバイスを切り替えるときにuserPreferredCameraを設定し、外部デバイスが接続されているときにsystemPreferredCameraプロパティを観察することで、この動作を可能にします。

また、自動カメラ選択APIを使用するのが適切な時期についても、独自の決定を下します。

たとえば、FaceTimeビデオ通話でバックカメラを使用できますが、通話のリストを表示するメイン画面のフロントカメラまたは外部カメラを常に使用します。

コントロールセンターから入手できるコードスキャナーは、動作が異なります。

起動時に背面カメラを使用し、ユーザーはカメラを変更することはできませんが、systemPreferredCameraプロパティをリッスンし、通知されたときに切り替えます。

WebKitフレームワークを使用すると、ウェブページはiPadのカメラにアクセスできます。

任意のカメラに切り替えることができますが、システム優先カメラをリストの最初のカメラとして返します。

自動カメラ選択の仕組みをお見せしたので、AVCamでサポートを追加します。

AVCamは、写真を撮ったり映画を録画したりできるので、伝統的な写真アプリです。

これは、それぞれ通信アプリとユーティリティアプリであるFaceTimeとコードスキャナー、およびシステムフレームワークであるWebKitとは異なります。

AVCamは、フォールバック付きの外部カメラを見つけるために一連の「if、else if」ステートメントを必要とする代わりに、システム優先カメラを取得するために1行だけが必要です。

アプリが自動カメラ選択APIを使用するのはこれが初めてなので、システムは内蔵のフロントカメラを返します。

しかし、AVCamはバックカメラから始めることを好みます。

システムが優先するカメラを取得する前に、アプリは、アプリのユーザーデフォルトに保存されている値を探して、これが初めて問い合わせたかどうかを確認します。

値が保存されていない場合、アプリは自動カメラ選択の初期状態を設定していません。

したがって、これが初めて起動する場合、アプリはユーザーが好むカメラをバックデバイスに設定します。

アプリは、提供されたデバイスタイプを使用してデバイスのリストを並べ替えるAVCaptureDeviceDiscoverySessionを使用してバックカメラを見つけます。

次に、ユーザーが好むカメラを設定し、アプリのユーザー設定に値を保存するので、この設定は一度だけ行います。

外部カメラの接続と切断を処理するには、特定のカメラの接続状態を観察する必要がなくなりなくなります。

代わりに、AVCamキー値は、システムが優先するカメラプロパティを観察します。

これにより、利用可能な最高のカメラに自動的に切り替えることができます。

KVO処理では、アプリは新しいシステム優先カメラを取得し、それに切り替えます。

しかし、AVCamが録音の途中にある場合はどうなりますか?

アプリはカメラを切り替えて録画を中断すべきではありません。

したがって、アプリは録音の最中ではない場合にのみ切り替わります。

その後、映画の録画が終了すると、アプリはシステムが優先するカメラを照会し、現在使用しているものと異なるかどうかを確認します。

システムが優先するカメラが変更された場合、アプリはそれに切り替わります。

このようにして、録音を中断しません。

このような決定は、外部カメラと自動カメラ選択APIを採用する際に行う必要がある手順です。

あなたのアプリにとって最も理にかなっていることをしてください。

AVCamにはカメラを切り替えるボタンがあり、前面と背面のデバイスを切り替えて動作します。

このiPad Proには、両方の位置で使用できる複数のカメラがあります。

したがって、AVCamには、特定の位置で使用するカメラを選択するためのロジックがあります。

アプリが外部カメラをサポートしている今、ボタンはどのように機能するべきですか?

外部カメラを前面に向いているように扱うことを選択します。

このApple Studio Displayのカメラは、iPadの内蔵フロントカメラのように私を向いています。

changeCamera機能に切り替える特定のデバイスがない場合、アプリは現在のデバイスの位置をチェックします。

現在のデバイスの位置をチェックするスイッチステートメントでは、アプリは、現在不特定の位置または前面位置のカメラを使用している場合、背面カメラを探します。

外部カメラは、位置が不特定であると報告している。

また、アプリが背面カメラを使用している場合は、利用可能な場合は外部デバイスに切り替えます。

それ以外の場合は、内蔵のフロントカメラに切り替わります。

外部カメラを見つけるために、アプリは外部デバイスタイプ、ビデオメディアタイプ、および不特定のデバイス位置を使用してAVCaptureDeviceDiscoverySessionを作成します。

次に、現在のデバイスの位置が戻ったときにスイッチステートメントで、最初に外部カメラを探します。

また、見つからない場合は、内蔵のフロントカメラに切り替わります。

次に、アプリが使用したいカメラを見つけると、AVCaptureDeviceにuserPreferredCameraクラスのプロパティを設定して、選択をシステムに伝えます。

このプロパティを設定すると、システムはユーザーの好みを学習できます。

アプリが外部カメラをサポートする方法と、ユーザーが外部カメラを切り替える方法を選択できます。

AVCamの場合、外部カメラを前面のように扱うことで、ユーザーがフロントカメラ、バックカメラ、外部カメラを切り替えることを選択しました。

このようにして、カメラのスイッチボタンは2つのデバイス間でのみ変更されます。

AVCamは外部カメラをほぼサポートする準備ができています。

処理すべき側面がもう1つあります。

私がAVCamを使用している間ずっと、iPadは右側のUSB-Cポートで横向きに取り付けられています。

iPadを回転させると、外部カメラのプレビューが逆さまになります。

しかし、ディスプレイの外部カメラは動いていません。

iPadだけが持っています。

しかし、AVCamは内蔵カメラでこの回転の問題はありません。

これは、アプリがiPadから独立した外部カメラの位置を方向付ける方法を知らないためです。

AVCamは、外部カメラのビデオプレビューを適切に表示するために、さらに変更する必要があります。

次に、ライブプレビューとキャプチャされた写真や映画が正しく表示されるように、ビデオのローテーションが重要な理由について説明します。

ビデオの回転は、カメラアプリの新しい概念ではありません。

しかし、外付けカメラを使用する場合は、iPadから独立して移動することを知っておくことが重要です。

アプリは内蔵カメラに使用されます。

このため、彼らはiPadの向きに頼ってカメラのビデオを回転させ、AVCaptureVideoOrientation列挙型を使用します。

これはAVCamが以前のデモでやっていたことです。

iPadの向きに合わせて外部カメラを回転させようとした。

iPadOS 17では、AVCaptureVideoOrientationと、この列挙型を使用するAPIは非推奨です。

これは、iPadがどのように向きになっているかを説明し、カメラがデバイスと一緒に回転することを前提としています。

独立して動く外部カメラを方向付けるには十分な表現力がありません。

この列挙型を使用するには、アプリは通常、iPadも記述し、カメラを方向付けるための間接的な信号であるUIDeviceOrientationから変換されます。

そのため、ビデオローテーションを処理するための新しいAPIを導入しています。

iPadOSを含むすべてのプラットフォームで新しく、AVCaptureDeviceRotationCoordinatorクラスは、あらゆるカメラの適切な方向付けに役立ちます。

クラスの初期化子は、AVCaptureDeviceと、オプションでカメラのビデオプレビューを表示するCALayerを取ります。

アプリは、多くの場合、AVCaptureVideoPreviewLayerまたはAVSampleBufferDisplayLayerを使用してカメラのプレビューを表示します。

これらは両方ともCALayerのサブクラスであり、初期化子に渡すことができます。

Metalやその他のレンダリング方法を使用するアプリは、カメラのプレビューを表示するUIViewのレイヤーを渡すだけです。

コーディネーターには、地平線レベルのプレビューのためのビデオ回転角度と地平線レベルのキャプチャのための別の角度の2つのプロパティがあります。

これらの読み取り専用プロパティは両方とも角度を度で返し、キー値で観測可能です。

コンテンツの地平線レベルのプレビューとキャプチャは、デバイスが縦向き、横向き、または逆さまであるかどうかに関係なく、カメラからのビデオフレームが常に重力に対して直立していることを意味します。

videoRotationAngleForHorizonLevelPreviewを使用して、コーディネーターの初期化子に渡されたCALayerのビデオフレームを表示します。

プレビューに適用するローテーションの量を説明しています。

角度はUIKitとSwiftUIの座標系に対して相対的です。

videoRotationAngleForHorizonLevelCaptureを使用すると、アプリは写真やビデオを撮影できるため、後で誰かがそれらを見るとき、常に直立します。

このプロパティは、カメラの物理的な向きを表します。

そして、その値は、アプリがプレビューに必要な角度とは異なる場合があります。

これら2つのプロパティには異なる目的があります。

ビデオローテーションを説明するために、内蔵カメラを使用する際によく知っているシナリオから始めます。

後で、AVCamを変更するときに、これらの概念が外部カメラにどのように適用されるかを説明します。

iPhoneのカメラアプリは、地平線レベルのプレビューとキャプチャのためのビデオ回転角度の違いの良い例です。

バックカメラのプレビューを表示するアプリのこの例では、iPhoneは縦向きです。

UIKit座標系の原点は描画領域の左上にあり、正のx軸は右に伸び、正のy軸は下に伸びています。

バックカメラセンサーの座標系は起源が異なります。

カメラセンサーは、最初に電話の高さに沿ってスキャンし、次に幅に沿ってスキャンします。

カメラの物理的な向きを考慮するために、アプリはUIでプレビューするためにカメラのビデオフレームを90度回転させます。

また、キャプチャした写真やムービーを回転させるので、後で見ると直立します。

iPhoneが横向きの場合、動作が異なります。

このアプリは、デバイスの向きに関係なく、UIを縦向きでのみ表示します。

ホーム・インフォーダンス・インジケーターがどこにあるかによってわかります。

iPhoneのカメラアプリの場合、常にポートの横にとどまります。

UIKit座標系の原点はまだ描画領域の左上にあり、この場合、アプリのUIは1つの向きしかサポートしていないため、デバイス上の単一の場所に固定されたままです。

そして、バックカメラセンサーの座標系は依然としてUIとは異なります。

アプリはUIを縦向きでしか表示しないため、iPhoneの向きに関係なく、プレビューのために一定の90度の回転を適用します。

しかし、プレビューとは異なり、このアプリはiPhoneが横向きのときに写真やビデオを撮るときに異なる回転量を適用します。

iPhoneがカメラセンサーのネイティブ向きにある場合、アプリは写真やムービーを回転させて直立させる必要はありません。

この回転の話のすべては、本当にあなたの頭を回転させます。

しかし、AVCaptureDeviceRotationCoordinatorはこの複雑さに対処し、すべてのカメラからプレビューしてキャプチャするための正しい角度を提供します。

自分で計算しようとするのではなく、角度を提供するためにそれに頼ってください。

アプリがカメラを切り替えるときに、必ず新しいローテーションコーディネーターを作成してください。

ビデオローテーションを適用するには、コーディネーターが提供するアングルを使用してAVCaptureConnectionの新しいAPIを使用します。

ビデオまたはデプスメディアデータを提供する接続のみがローテーションをサポートします。

接続が角度をサポートしているかどうかを確認するには、isVideoRotationAngleSupportedメソッドを呼び出すことができます。

接続が回転を実行するには、videoRotationAngleプロパティをサポートされている値に設定します。

videoRotationAngleForHorizonLevelPreviewを使用して、カメラのプレビューを表示します。

AVCaptureVideoPreviewLayerを使用するアプリは、AVCaptureConnectionインスタンスのvideoRotationAngleプロパティにプロパティの値を適用できます。

アプリは、CALayerでビデオデータ出力からのバッファを表示するときにも使用できます。

システムアニメーションと同期するには、アプリのキー値観察コードでプレビューの回転をすぐに変更します。

アプリは、UIを更新するために、メインキューでこのプロパティの更新を受け取ることを期待できます。

すべてのアプリがカメラのプレビューを表示するためにAVCaptureVideoPreviewLayerを使用しているわけではありません。

一部のアプリは、カスタムエフェクトやフィルターを適用するときに、ビデオデータ出力からバッファを表示します。

カスタムプレビューを表示するオプションの1つは、AVSampleBufferDisplayLayerを使用することです。

ビデオデータ出力のAVCaptureConnectionの角度を設定することで、回転を要求しないでください。

接続の角度を変更すると、キャプチャレンダリングパイプラインが自分自身を再構成して新しい回転量を適用すると、フレーム配信が中断されます。

代わりに、カメラのプレビューを表示するCALayerを回転させます。

そうすることで、アプリのカメラプレビューがスムーズに回転できます。

写真や映画のときはvideoRotationAngleForHorizonLevelCaptureを使用するので、重力に対して水平になります。

アプリは、キャプチャ接続にプロパティの値を写真出力またはムービーファイル出力に適用できます。

または、アプリがカスタムムービーを録画するためにAVAssetWriterでビデオデータ出力を使用する場合は、AVCaptureConnectionでビデオを回転させないでください。

代わりに、AVAssetWriterInputインスタンスの変換プロパティで回転を設定し、出力ファイルのメタデータを変更します。

このアプローチでは、ビデオアプリは再生中に回転を適用し、キャプチャ接続で各フレームを回転させるよりも少ないエネルギーを使用します。

アセットライター入力はラジアンで回転を適用するCGAffineTransformを使用するため、アプリは回転角度を度から変換する必要があります。

一部の出力は、オーバーヘッドを追加せずに回転を効率的に適用します。

たとえば、ムービーファイルの出力は、QuickTimeトラックマトリックスを使用して回転を適用します。

写真の出力は、Exifタグで向きを処理します。

そして、プレビューレイヤーは、ローテーションを実行するためにその内容を変換します。

ただし、ビデオまたは深度データ出力がより多くのメモリとエネルギーを使用してバッファを回転させるため、デバイスの消費電力が増加する可能性があります。

代わりに、あなたのアプリは、ビデオや深度出力からバッファをプレビューするCALayerを回転させることで、より効率的なアプローチを取ることができます。

iOS、tvOS、macOSなど、利用可能なすべてのプラットフォームでAVCaptureDeviceRotationCoordinatorを使用してください。

MacのMac CatalystとiOSアプリも使用できます。

アプリはローテーションコーディネーターを使用して、写真や映画を正しく方向付け、任意のカメラのビデオプレビューを表示できます。

また、Stage Managerや外部ディスプレイにあるときに、アプリが複雑なレイアウトを処理するのに役立ちます。

今、AVCamの外部カメラをサポートするための最終的な変更の時間です。

キャプチャセッションを設定すると、アプリはカメラのプレビューを設定します。

そのため、デバイス回転コーディネーターを作成し、アプリにプレビューとキャプチャに必要な回転角度を提供します。

コーディネーターを作成するとき、アプリはプレビューのために現在の回転角度でプレビューレイヤーを更新します。

また、角度の変化を観察し、プレビューを更新します。

AVCamがデバイスを切り替えると、新しいローテーションコーディネーターも作成されるため、プレビューは新しいカメラにぴったりです。

写真を撮るとき、アプリはキャプチャに回転角度を使用して、誰かが後でそれらを見るときに直立していることを確認します。

そして、映画を録画するときも同じことをします。

これらの変更により、AVCamは外部カメラをサポートする準備が整いました。

iPadを回転させると、外部カメラが正しく表示されます。

このセッションではこれまでに多くのことを取り上げてきましたが、私と一緒にフォローしていただきありがとうございます。

iPadアプリが外部カメラをどのように使用できるかを示したので、これらのデバイスに含まれているマイクを使用する方法について説明します。

一部のウェブカメラやディスプレイにはマイクが含まれています。

iPadに接続すると、アプリで使用できます。 アプリが使用できます。

iPadOS 17は、USB-Cを搭載したiPadの外部マイクのサポートを改善しました。

Core AudioのAUVoiceIOオーディオユニットを使用するテレフォニーアプリは、ウェブカメラやディスプレイに含まれているような外部マイクを使用できるようになりました。

以前は、これらのアプリが使用できる唯一の外部有線デバイスはヘッドセットマイクでした。

AUVoiceIOは、エコーキャンセルを実行し、外部マイク用の新しいチューニングが導入されているため、人気のあるインターフェースです。

コントロールセンターから利用可能な音声分離モードは、キーボードでの入力、マウスクリック、または近所のどこかで実行されているリーフブロワーなど、不要なバックグラウンドノイズを除去します。

アプリは、このシステム機能を外部マイクで使用できます。

iOSオーディオルーティングシステムでは、一度に1つのマイクしか使用できません。

また、最後に接続されたマイクにも自動的に変更されます。

これは、カメラを接続するときと同じように、ユーザーが新しく接続されたマイクを使用する必要があることを示しているためです。

iOSでは、システムはマイク用のAVCaptureDeviceを1つだけ返します。

オーディオメディアタイプまたは新しいマイクデバイスタイプのデバイスを検索して見つけることができます。これは、すべてのマイクがiPadに組み込まれているわけではないため、builtInMicrophoneを廃止します。

オーディオルーティングシステムは、内蔵または外部を問わず、どの利用可能なマイクを使用するかを決定します。

システムが入力ルートを変更すると、マイクAVCaptureDeviceのlocalizedNameプロパティは、使用中のデバイスを反映するように変更されます。

アプリはAVAudioSessionを使用して、マイクをより詳細に制御できます。

カテゴリまたはモードを設定することで、アプリのオーディオ動作を設定できます。

また、優先入力を設定することで、外部カメラに含まれているような特定のマイクを使用することを選択できます。

このセッションの最後のトピックでは、外部カメラを使用する際のアプリのベストプラクティスについて説明します。

採用を開始する際には、アプリにとって何が最も理にかなっているかを検討してください。

以前、FaceTime、Code Scanner、WebKitが外部カメラを異なる方法でサポートすることを選んだことを示しました。

アプリが採用できるさまざまな方法の例として使用してください。

USB-Cポートが外部カメラで使用されている間に、Xcodeでワイヤレスデバッグ用にiPadを設定します。

アプリが内蔵カメラに期待できる一部の機能は、外部デバイスではサポートされない場合があります。

たとえば、アプリがいくつかの機能で深度データキャプチャに依存している場合、外部カメラが使用されているときに無効にする必要があるかもしれません。

AVCaptureMultiCamSessionで同時に複数のカメラを使用するアプリは、クリエイティブなキャプチャ設定のために外部カメラを追加できます。

iPadOSは、外部カメラにフロントカメラにも適用されるいくつかの治療を提供します。

AVCaptureVideoPreviewLayerは、デフォルトで外部カメラをミラーリングします。

これは、カメラがiPadユーザーを向いているときにうまく機能します。

しかし、これはすべてのユースケースに適しているわけではありません。

アプリのユーザーがHDMIスイッチャーからストリーミングしたり、外部カメラを遠ざけたりする場合は、ユーザーがプレビューミラーリングを無効にすることを検討してください。

前のセクションでは、カメラの回転について説明しました。

アプリは外部カメラにビデオローテーションを適用する必要はありませんが、その場合、システムは外部カメラを向いているシーンに向かって時計回りに回転させることに注意してください。

これは、内蔵カメラの回転を適用するのと同じ方法です。

さまざまな機能を備えたカメラを扱うためのアプリを準備してください。

たとえば、一部の外部カメラは、640x480のVGAフォーマットと1280x720のHDフォーマットの2つのフォーマットしか報告しない場合があります。

また、一部の外部カメラは、iOSでは一般的に使用されていないピクセルフォーマットをサポートしています。

私たちは、これらをiOSカメラアプリが扱うのに慣れているより一般的なフォーマットに変換することを選択しました。

Yuvsや2vuyのような非圧縮フォーマットは420vに変換されます。

また、ストリーミングJPEGやH264などの圧縮フォーマットは420fに変換されます。

外部カメラは任意のサイズのフォーマットを持つことができるため、すべてのAVCaptureSessionPresetsをサポートしていない可能性があります。

たとえば、HD 4Kプリセットでは、デバイスに互換性のあるフォーマットが必要です。

アプリは、AVCaptureDeviceのsupportsSessionPresetメソッドを呼び出すことで、プリセットを使用できるかどうかを確認できます。

アプリは、解像度、フレームレート、ズーム率の変更など、外部カメラを設定できます。

iPadOSは、USBビデオクラス仕様で利用可能なカメラコントロールの限られたセットをサポートしています。

したがって、AVCaptureDeviceの機能を照会してください。

先ほど話したことをすべてまとめましょう。

外部カメラを見つけて使用する方法、カメラのビデオフレームを適切に回転させる方法、外部マイクを使用する方法、そして最後にアプリのベストプラクティスを示しました。

iPadアプリで外付けカメラを使い始める方法にワクワクしています。

ありがとう、あなたのアプリがうまくいくことを願っています。

♪ ♪