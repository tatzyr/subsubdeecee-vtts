10191

♪まろやかなインストゥルメンタルヒップホップ♪

♪

Lei Zhou: こんにちは、私はオブジェクトキャプチャチームのLeiです。

このセッションでは、同僚のモナと私は、iOS用のオブジェクトキャプチャを紹介します。

始める前に、オブジェクトキャプチャとは何か、そしてそれが今日どのように機能するかを確認しましょう。

オブジェクトキャプチャは、最先端のコンピュータビジョン技術を使用して、さまざまな角度で撮影された一連の画像からリアルな3Dモデルを作成します。

これらの画像はMacに転送され、Object Capture APIを使用して数分で3Dモデルを再構築します。

Mac用APIのリリース以来、オブジェクトキャプチャを活用して高品質の3Dモデルを生成する多くのアプリを見てきました。

私たちはあなたから多くのフィードバックを受けています。

私たちは今、iOSに完全なオブジェクトキャプチャ体験をもたらすために大きな一歩を踏み出しています!

これは、ユーザーフレンドリーなインターフェースとデバイス上のモデル再構築の両方でキャプチャできるようになったことを意味します。

また、このワークフローをiOSで実証するためのサンプルアプリも提供しています。

動作中のサンプルアプリを見てみましょう。

サンプルアプリを使用して、美しい花瓶の3Dモデルを簡単に作成します。

まず、サンプルアプリを開き、オブジェクトにポイントします。

キャプチャを開始する前に、自動バウンディングボックスが生成されます。

次に、オブジェクトを一周し、オブジェクトキャプチャが自動的に適切な画像をキャプチャします。

より多くの画像が必要な地域に関する視覚的なガイダンスと、最高品質のショットをキャプチャするのに役立つ追加のフィードバックメッセージを提供します。

1つの軌道を終えたら、オブジェクトをひっくり返して底を捉えることができます。

3つのセグメントのスキャンが完了したら、iOSデバイスでローカルで実行される再構築段階に進みます。

わずか数分で、USDZモデルが使用可能になります。

開発者ドキュメントの一部として、このアプリのソースコードを提供しているので、すぐにダウンロードして自分で試すことができます。

また、独自のアプリケーションを作成するための出発点として使用することもできます。

新しいサンプルアプリでオブジェクトキャプチャのデモを見たので、今年はすべての新しいエキサイティングな機能に移りましょう。

まず、LiDARを使用してより多くのオブジェクトのスキャンをサポートするオブジェクトキャプチャの改善点を紹介します。

次に、オブジェクトのデータキャプチャを簡素化するガイド付きキャプチャ機能を実演します。

次に、Object Capture APIを使用してiOSでオブジェクトキャプチャフローを作成する方法を説明します。

最後に、モデル再構築機能のいくつかの新しい機能強化を強調します。

まず、LiDARでより多くのオブジェクトのサポートを見てみましょう。

高品質の3Dモデルを作成するには、優れた特性を持つオブジェクトを選択することが重要です。

当社のオブジェクトキャプチャシステムは、十分なテクスチャの詳細を持つオブジェクトに最適ですが、今年はさらに改善しました。

現在、LiDARスキャナーを活用して、低質感のオブジェクトの再構築をサポートしています。

この椅子を例として見てみましょう。

テクスチャの詳細が欠けているため、オブジェクトキャプチャが優れたモデルを作成するのが困難です。

しかし、LiDARを使用すると、より良い品質で再構築することができます。

キャプチャ中に、この椅子のRGB写真を撮ります。

しかし、シートとバックはテクスチャレスであるため、その完全なモデルを回復することはできません。

RGB画像に加えて、当社のAPIはLiDARで点群データも収集し、カバレッジと密度が向上したオブジェクトの3D形状の包括的な表現を生成するのに役立ちます。

最後に、融合点のクラウドデータから完全な3Dモデルが生成されます。

これは、当社のLiDAR対応システムによって品質が改善された追加の低テクスチャオブジェクトのモデルです。

現在、低テクスチャのオブジェクトをサポートしていますが、一部のオブジェクトにはまだ課題があります。

反射的、透明、または非常に薄い構造を含む物体を避けるのが最善です。

どのオブジェクトがサポートされているかを見たので、ガイド付きキャプチャを使用してオブジェクトを簡単にスキャンする方法を詳しく見てみましょう。

画像とLiDARデータを自動的にキャプチャするガイド付きキャプチャを提供します。

また、キャプチャプロセス中に有用なフィードバックを提供します。

さらに、オブジェクトを反転させるべきかどうかについてのガイダンスを提供します。

良い視野角を手動で選択してボタンを押すことを要求するのではなく、データキャプチャ体験を自動化します。

オブジェクトの周りを一周すると、当社のシステムは、良好なシャープネス、明瞭さ、露出を持つ画像ショットを自動的に選択し、さまざまな視野角からLiDARポイントを収集します。

オブジェクトのすべての詳細をキャプチャするには、できるだけ多くの角度から写真を撮ることを強くお勧めします。

オブジェクトのどの領域に十分な画像があるかを示すキャプチャダイヤルを提供します。

あらゆる角度からオブジェクトをスキャンして、キャプチャダイヤルを完全に充填することをお勧めします。

自動キャプチャに加えて、キャプチャプロセス中にお客様を支援するためのリアルタイムのフィードバックを提供します。

まず、正確な色表現を得るために、環境に良い照明があることを確認してください。

暗すぎると、照明条件を調整するためのリマインダーが届きます。

物体表面の反射やハイライトを最小限に抑えるために、拡散光を使用することをお勧めします。

次に、ぼやけた画像を避けるために、カメラをしっかりと持ちながら、ゆっくりとスムーズに物体の周りを移動します。

動きが速すぎると、自動キャプチャが停止し、減速するように思い出させます。

第三に、オブジェクトがカメラフレームに適切に収まるように、カメラとオブジェクトの間に適切な距離を維持します。

距離が遠すぎたり近すぎたりすると、テキストリマインダーが表示されます。

最後に、常にオブジェクトをフレーム内に保持します。

オブジェクトが視野外に行くと、自動キャプチャが一時停止し、矢印記号が表示され、表示方向を調整することを思い出させます。

オブジェクトの完全な3Dモデルを取得するには、そのすべての側面をキャプチャすることが重要です。

オブジェクトを反転させると、これを達成するのに役立ちます。

しかし、オブジェクトを反転させるかどうかは、その属性に依存します。

あなたのオブジェクトが硬い場合、反転は良い考えです。

しかし、変形可能なオブジェクトの場合、形状が簡単に変化する可能性があるため、動かさない方が良いです。

テクスチャが豊富なオブジェクトの場合は、反転が推奨されますが、システムに誤解を招く可能性があるため、対称的または反復的なテクスチャを持つオブジェクトを反転させないようにすることが重要です。

さらに、テクスチャレスオブジェクトを反転させると、異なるセグメントを縫い合わせるのに十分なテクスチャが必要なため、オブジェクトキャプチャにとって困難な場合があります。

これを助けるために、オブジェクトが反転するのに十分なテクスチャであるかどうかを提案するAPIを提供します。

オブジェクトを反転させる場合は、すべての側面の画像を取得できるように、3つの向きでスキャンすることをお勧めします。

また、物体の表面の影と反射を最小限に抑えるために、拡散光を使用するのが最善です。

異なるスキャンパス間の画像の重なりも重要です。

スキャンパスのオブジェクトの一部は、以前のパスでキャプチャする必要があります。

オブジェクトを適切に反転させる方法についての視覚的なガイダンスを提供します。

オブジェクトを反転できない場合は、3つの異なる高さからキャプチャして、さまざまな視野角から画像を取得することをお勧めします。

主にテクスチャレスオブジェクトの場合、目立つことができるテクスチャ背景に配置することをお勧めします。

オブジェクトキャプチャは、iPhone 12 Pro、iPad Pro 2021、およびそれ以降のモデルで利用できます。

お使いのデバイスがオブジェクトキャプチャをサポートしているかどうかを確認するために、簡単な検証のためのAPIを提供しています。

次に、MononaがObject Capture APIについて詳しく説明します。

モナ・ユーソフシャヒ:ありがとう、レイ!

サンプルアプリの動作を見たので、Object Capture APIを使用してこのアプリを作成する方法を見てみましょう。

デモで見たように、オブジェクトキャプチャには、画像キャプチャとモデル再構築の2つのステップがあります。

まず、画像キャプチャを見てみましょう。

Image Capture APIには、セッションとSwiftUIビューの2つの部分があります。

このセッションでは、画像キャプチャ中にステートマシンの流れを観察および制御できます。

SwiftUIビューはカメラフィードを表示し、セッションの状態に基づいて表示するUI要素を自動的に適応させます。

私たちのSwiftUIは、2Dテキストやボタンなしで提供されます。

これにより、アプリの外観をカスタマイズし、既存のアプリにオブジェクトキャプチャをより簡単に組み込むことができます。

オブジェクトキャプチャステートマシンを詳しく見てみましょう。

セッションは、作成時に初期化状態で開始されます。

次に、状態を進めるために関数呼び出しを行います。

セッションは、準備、検出、キャプチャ、および終了を通じて移行します。

終了状態になると、セッションは自動的に完了した状態に移行します。

この時点で、安全に取り壊して、デバイス上の再構築を続けることができます。

これを実際に使う方法を見てみましょう。

RealityKitとSwiftUIをインポートすることから始めます。

次に、ObjectCaptureSessionのインスタンスを作成します。

参照型であるため、完了するまで、セッションを地上真実データモデル内に永続状態として保存することをお勧めします。

これにより、セッションは初期化状態で開始されます。

キャプチャした画像を保存する場所をセッションに指示するディレクトリを使用して、start()関数を呼び出して続行します。

また、構成でチェックポイントディレクトリを提供することもできます。これは、後で再構築プロセスを高速化するために使用できます。

この呼び出しの後、セッションは準備完了状態に移行します。

ObjectCaptureViewでセッションを使用する方法を見てみましょう。

私たちは、他のSwiftUIビューと同様にObjectCaptureViewを使用します。

私たちはそれを別のビューの体の中に置き、作成したばかりの地上の真実のセッションを渡します。

ObjectCaptureViewは、常にセッションの現在の状態に対応するUIを表示します。

ここで準備完了状態でわかるように、ビューには、キャプチャするオブジェクトを選択するためのレチクル付きのカメラフィードが表示されます。

状態を進めるには、アプリはセッションにオブジェクトの検出を開始するように指示するUIを提供する必要があります。

ここでは、ObjectCaptureViewの上に[続行]ボタンを積み重ねます。

押すと、startDetecting()関数を呼び出してバウンディングボックスの検出状態に移動します。

検出状態では、ビューは自動的に変更され、現在検出されたオブジェクトの周りにバウンディングボックスが表示されます。

必要に応じて、バウンディングボックスのサイズと向きを手動で調整できます。

当社のサンプルアプリは、別のオブジェクトを選択したい場合にオブジェクト選択プロセスを再開するためのリセットボタンも提供します。

これにより、セッションは準備状態に戻ります。

準備から検出への移行と同様に、オブジェクトの選択に満足したら、セッションにキャプチャを開始するように指示するボタンを提供する必要があります。

ここでは、startCapturing()関数を呼び出すStart Captureボタンを使用します。

この呼び出しの後、セッションはキャプチャ状態に移行します。

キャプチャ状態では、オブジェクトの周りをゆっくりと移動しながら、セッションは自動的に画像を取得します。

ビューには、ポイントクラウドとキャプチャダイヤルが表示され、オブジェクトの十分な画像を収集した場所と、さらにキャプチャする必要がある場所が表示されます。

スキャンパスは、キャプチャダイヤルが完全に満たされると完了します。

キャプチャダイヤルが完了すると、セッションはuserCompletedScanPassプロパティをtrueに設定します。

この時点で、私たちのサンプルアプリは、セッションを終了するか、より多くの画像をキャプチャし続けるオプションを提供します。

各オプションにボタンを割り当てます。

最適なモデル再構築のために、3つのスキャンパスを完了することをお勧めします。

次のスキャンパスに移動する方法を見てみましょう。

オブジェクトを反転するかどうかに応じて、2つの方法で新しいスキャンパスを開始できます。

反転を使用すると、オブジェクトの下部など、現在のパスに表示されないオブジェクトの側面をキャプチャできます。

このため、beginNewScanPassAfterFlip()を呼び出すと、状態を準備完了に戻します。

その後、新しい向きでボックス選択を実行する必要があります。

オブジェクトを反転しないことにした場合は、代わりに別の高さでより多くの画像をキャプチャできます。

このために、beginNewScanPass()を呼び出します。

これにより、キャプチャダイヤルがリセットされますが、バウンディングボックスが変更されていないため、セッションはキャプチャ状態のままです。

すべてのパスが完了すると、サンプルアプリは終了ボタンを提供します。

このボタンは finish() 関数を呼び出し、画像のキャプチャが完了したことをセッションに伝え、仕上げプロセスを開始できます。

終了状態の間、セッションはすべてのデータが保存されるのを待ちます。

終了すると、セッションは自動的に完了した状態に移行します。

私たちは安全にそれを取り壊し、デバイス上の再構築を開始することができます。

イメージディレクトリが突然使用できなくなった場合など、回復不能なエラーが発生した場合、セッションは失敗した状態に移行します。

このような場合は、新しいセッションを作成する必要があります。

そして最後に、点群を表示して、最初に配置された、または最後に反転してから、オブジェクトのどの部分がスキャンされたかをプレビューすることもできます。

これを行うには、ObjectCapturePointCloudViewをObjectCaptureViewに交換します。

これにより、キャプチャセッションが一時停止され、ポイントクラウドと対話してあらゆる角度からプレビューできます。

ここでは、このビューをいくつかのテキストとボタンと組み合わせて表示しますが、ポイントクラウドをフルスクリーンで表示することもできます。

オブジェクトの画像をキャプチャしたので、その3Dモデルを作成する方法を見てみましょう。

今年から、iOSで再構築APIを実行できます。

これにより、同じデバイスで画像キャプチャと再構築を実行できます。

以下は、非同期再構築APIの使用方法の要約です。

iOSでもmacOSでも同じように動作します。

まず、作成したビューにタスク修飾子を添付します。

タスク修飾子では、フォトグラメトリセッションを作成し、それを画像に向けます。

オプションで、画像キャプチャ中に使用したのと同じチェックポイントディレクトリを提供して、再構築プロセスを高速化できます。

次に、process()関数を呼び出してmodelFileを要求します。

最後に、ループ内のメッセージストリームを待ち、到着した出力メッセージを処理します。

詳細については、前回の講演を必ず確認してください。

モバイルデバイスでのモデルの生成と表示を最適化するために、iOSでは削減された詳細レベルのみをサポートします。

再構築されたモデルには、拡散、アンビエントオクルージョン、および通常のテクスチャマップが含まれており、すべてモバイルディスプレイ用に設計されています。

他の詳細レベルでモデルを生成したい場合は、再構築のために画像をMacに転送できます。

今年、Macの再構築は、画像に保存したLiDARデータも利用します。

新しいオブジェクトキャプチャセッションは、このフローもサポートしています。

やり方を見てみましょう。

デフォルトでは、iOSデバイスの再構築制限に達すると、オブジェクトキャプチャセッションは画像のキャプチャを停止します。

macOSの再構築では、セッションがデバイス上の再構築が使用できるよりも多くの画像を撮影できるようにすることができます。

これを行うには、セッションの設定でisOverCaptureEnabledをtrueに設定します。

これらの追加ショットは、デバイス上の再構築には使用されませんが、画像フォルダに保存されます。

Macで画像を再構築するには、コードを書く必要さえありません。

Object Captureは、Reality Composer Proと呼ばれる新しいmacOSアプリに統合されています。

画像をアプリにインポートし、詳細レベルを選択し、モデルを取得するだけです。

このアプリの詳細については、Reality Composer Proのセッションを必ず見てください。

新しいiOS APIで3Dモデルを作成する方法を見たので、非常に要求されたいくつかの再構築機能強化を簡単に説明しましょう。

Macのモデル品質と再構築速度を改善しました。

進捗率に加えて、推定再建時間を提供しています。

ポーズ出力とカスタム詳細レベルなど、他の2つの追加について詳しく見てみましょう。

画像ごとに高品質のポーズをリクエストできるようになりました。

各ポーズには、当社のコンピュータビジョンアルゴリズムに基づいて、その画像のカメラの推定位置と向きが含まれています。

ポーズを取得するには、process()関数呼び出しにポーズ要求を追加します。

次に、出力メッセージストリームに到着したときにポーズ出力を処理します。

ポーズは、モデルが生成される前に、再構築プロセスの早い段階で返されます。

今年は、再構築されたモデルを完全に制御できるmacOSの新しいカスタム詳細レベルも追加しました。

以前は、縮小、中、フル、生の詳細レベルから選択できます。

カスタム詳細レベルでは、メッシュデシメーションの量、テクスチャマップの解像度、フォーマット、および含めるテクスチャマップを制御できます。

そして、それはiOS用のオブジェクトキャプチャのラップです。

オブジェクトキャプチャにより、LiDARサポートでより多くのオブジェクトをスキャンできるようになりました。

iOSデバイスでモデルを完全にキャプチャ、再構築、表示する方法を紹介しました。

iOS用オブジェクトキャプチャは、電子商取引、デザイン、教育、ゲームなど、さまざまなアプリケーションの新しいワークフローを可能にします。

オブジェクトキャプチャをアプリにどのように組み込むかを楽しみにしています。

見てくれてありがとう!

♪