10203

♪まろやかなインストゥルメンタルヒップホップ♪

♪

こんにちは、私の名前はピーターで、AppleのRealityKit Toolsチームで働いています。

今日は、最初の没入型アプリの開発を開始する方法を見ていきます。

空間コンピューティングは、コンテンツを提示し、アプリへのより深いレベルの没入を統合するまったく新しい方法を提供します。

プラットフォーム自体は新しいですが、アプリを構築するには、すでに馴染みのあるワークフローが使用されます。

このセッションでは、Xcodeで新しいアプリプロジェクトを作成することから始めます。

シミュレーターで、シミュレートされたシーンでアプリを体験する方法と、Xcodeプレビューを使用してすばやく反復する方法について説明します。

アプリの空間コンテンツの準備とプレビューに役立つ新しいツールであるReality Composer Proを紹介します。

最後に、アプリが没入型シーンを作成し、SwiftUIジェスチャーをRealityKitエンティティにターゲットにする方法を紹介します。

あなたのような何百万人もの開発者が毎日Xcodeを使用して、配布用のアプリを作成、プレビュー、デバッグ、プロファイル、準備しています。

Xcodeは、最初のアプリを作成するのに最適な場所です。

Xcodeプロジェクトの作成プロセスを見て、このプラットフォームの新機能を見てみましょう。

Xcodeで新しいプロジェクトを作成すると、新しいプロジェクトアシスタントが表示されます。

プロジェクトテンプレートをプラットフォームとプロジェクトタイプ別に整理します。

アプリプロジェクトテンプレートは、[プラットフォーム]タブの[アプリケーション]セクションにあります。

新しいプロジェクトアシスタントは、まだインストールされていない場合は、プラットフォームサポートをダウンロードするよう要求する可能性があることに注意してください。

新しいプロジェクトアシスタントは、いくつかのオプションを提示し、そのうちの2つはこのプラットフォームにとって新しいものです。

これらの新しいオプションのそれぞれを詳しく見てみましょう。

最初の新しいオプションである初期シーンでは、アプリに自動的に含まれる初期シーンのタイプを指定できます。

新しいプロジェクトアシスタントは、常にここで選択したタイプの単一のシーンで出発点を作成します。

開発者として、後で追加のシーンを追加できます。

これらは、最初のシーンと同じタイプにすることも、まったく異なるシーンタイプにすることもできます。

テンプレートは、ウィンドウとボリュームの2つの初期シーンを提供します。

これらの違いを見てみましょう。 それらの違いを見てみましょう。

Windowsは、主に2次元のコンテンツを表示するように設計されています。

平面寸法でサイズを変更できますが、深さは固定されています。

Windowsは通常、他の実行中のアプリと一緒に表示されます。

ウィンドウシーンタイプの詳細と、SwiftUIの追加と変更については、「空間コンピューティングのためのSwiftUIに会いましょう」というセッションで学ぶことができます。

ボリュームは主に3Dコンテンツを提示するように設計されています。

3次元すべてのサイズはアプリ自体によって制御されますが、アプリを使用している人が調整することはできません。

Windowsと同様に、ボリュームは通常、他の実行中のアプリと一緒に表示されます。

「SwiftUIを次の次元に連れて行く」セッションは、ボリュームシーンタイプに関する詳細情報を提供します。

2番目の新しいオプションであるImmersive Spaceは、没入型コンテンツの出発点をアプリに追加する機会を提供します。

アプリに没入型スペースシーンタイプを追加すると、それを使用して無限のキャンバスのどこにでも無制限のコンテンツを表示できます。

アプリがこのシーンタイプをアクティブにすると、共有スペースからフルスペースに移動します。

フルスペースでは、気晴らしを避けるために、他の実行中のアプリが隠されています。

アプリは専用のレンダリングリソースにアクセスすることもでき、ハンドトラッキングなどのARKit機能を有効にする許可を要求できます。

アプリの没入型体験を作りたい場合、SwiftUIはシーンにミックスイマージョン、プログレッシブイマージョン、フルイマージョンの3つの異なるスタイルを提供します。

混合イマージョンスタイルにより、アプリは無制限の仮想コンテンツをフルスペースに配置しながら、パススルーを通じて人々を周囲に接続し続けることができます。

プログレッシブイマージョンスタイルは、人々を周囲から完全に排除しない、より没入感のある体験を提供するポータルを開きます。

ポータルが開くと、人々はあなたの没入型コンテンツに約180度のビューを取得し、デジタルクラウンを使用してポータルのサイズを調整することができます。

完全なイマージョンスタイルは、パススルーを完全に隠し、アプリの環境で人々を囲み、新しい場所に運びます。

このセッションの後半で、没入型スペースについて詳しく説明します。

深く掘り下げるには、「SwiftUIで窓を越えて」というセッションをご覧ください。

デフォルトでは、没入型スペースはアプリに追加されません。

これは、オプション「なし」を選択した場合の動作です。

ただし、没入型スペースオプションの1つを選択すると、テンプレートは選択した没入型スペーススタイルで2番目のSwiftUIシーンを自動的に追加します。

デフォルトでは、誰かが没入型コンテンツを開くことができるように、ウィンドウシーンにSwiftUIボタンも提供します。

一般的に、アプリは常にこのプラットフォームのウィンドウで開始し、人々がコンテンツにもっと没頭するタイミングを決定できるように、明確な入退出コントロールを提供することをお勧めします。

知らないうちに人々をより没入感のある体験に移動させることは避けてください。

このセッションのプロジェクトを設定しましょう。

最初のボリュームから始めて、没入型スペースはありません。

いつものようにプロジェクトを作成し、名前を付け、保存する場所をXcodeに伝えます。

作成されると、新しいプロジェクトが開きます。

左側には、Xcodeのプロジェクトナビゲーターがあります。

最初のファイルはMyFirstImmersiveApp.swiftで、最初のボリュームを表示するアプリのWindowGroupを宣言します。

WindowGroupは、iOSで見たのと同じ構造で、アプリが提示するトップレベルのSwiftUIビューを指定します。

2番目のファイルはContentView.swiftで、この最初のボリュームに示されているビューです。

プロジェクトはメインエディタのContentView.swiftで開きます。

Xcodeは、プロジェクトに自動的に含まれていたRealityKitコンテンツパッケージのコンテンツをロードするContentViewのプレビューも表示します。

新しいプロジェクトのコードのほとんどはContentViewにあります。

ContentViewはいくつかの新しいプラットフォーム固有の機能を使用しているので、詳しく見てみましょう。

ContentViewは、ボリュームによって表示されるSwiftUIビューの名前です。

これは、単純な効果に使用される「拡大」と呼ばれる単一のSwiftUI Stateプロパティを定義します。

SwiftUIビューとして、当社のコンテンツはボディプロパティによって提供されます。

本体は、VStackにネストされた2つのビューで構成されています。

VStackは、ネストされたビューを垂直にスタックします。

最初のネストされたビューはRealityViewです。

RealityViewはこのプラットフォームにとって新しく、すぐに戻ってきます。またすぐに戻ってきます。

2番目のネストされたビューは、別のVStackに埋め込まれた標準のSwiftUIトグルビューです。

トグルビューは、拡大プロパティの値を切り替えます。

VStackは、ボタンが読みやすく、操作しやすいように、glassBackgroundEffectを提供します。

SwiftUIで作業したことがある場合は、すでにトグルビューを見た可能性が高いです。

他のプラットフォームですでにサポートされているSwiftUIコントロールのほとんどは、期待どおりに動作します。

すぐに、ジェスチャーを使用して拡大プロパティを切り替える方法を見ていきます。

しかし、まず、RealityViewを詳しく見てみましょう。

RealityViewを使用すると、RealityコンテンツをSwiftUIビュー階層に配置できます。

ContentViewで使用されるRealityView初期化子は、パラメータとして、makeクロージャとupdateクロージャの2つのクロージャを取ります。

makeクロージャは、最初のRealityKitコンテンツをビューに追加します。

RealityKitコンテンツパッケージの内容を読み込もうとします。

そして、成功すると、content.addを使用してロードされたコンテンツをビューに追加します。

また、最初のコンテンツを手続き的に生成したり、手続きコンテンツとロードされたコンテンツの組み合わせを使用することもできます。

アップデートクロージャはオプションですが、提供されている場合は、SwiftUIの状態が変更されるたびに呼び出されます。

それはmakeクロージャで追加されたものなので、content.entitesから最初のエンティティを取得することから始まります。

次に、SwiftUI状態の拡大プロパティの値に基づいてuniformScale係数を選択し、このスケールをエンティティに適用します。

RealityViewの更新クロージャはレンダリング更新ループではなく、すべてのフレームで呼び出されるわけではないことに注意することが重要です。

代わりに、更新クロージャはSwiftUIの状態が変更された場合にのみ呼び出されます。

最後に、RealityViewにはジェスチャーが添付されています。

RealityKitコンテンツをタップすると、拡大プロパティの値を切り替え、以前に説明したトグルビューをタップするのと同じ効果が得られます。

RealityViewとジェスチャーの詳細については、「RealityKitで空間体験を構築する」をご覧ください。

ContentViewを見てみましょう。シミュレータを紹介し、シミュレートされたシーンで実行されているアプリをナビゲートして操作する方法を紹介しましょう。

その後、私たちのアプリがシミュレータでどのように見えるかを見ていきます。

シミュレータは、他のプラットフォームで使用したことがあれば、馴染みのあるウィンドウに表示されます。

最初に起動すると、アプリケーションランチャーが表示されます。

シミュレータは、誰かがデバイスを身に着けているのを見るものを模倣します。

デフォルトでは、ポインタはあなたが見ているものを制御します。

マウスまたはトラックパッドをクリックするとタップがシミュレートされ、クリックを長押しするとピンチがシミュレートされます。

空間コンピューティングの大部分は、周囲を見たり移動したりできることです。

シミュレータは、まさにそれを行うための追加のコントロールを提供します。

シミュレータウィンドウの右下隅には、シミュレートされたデバイスを制御するためのいくつかのボタンがあります。

これらのマウスやトラックパッドを動かしながらクリックしたまま長押しすると、周りを見回すことができます...

...パン...

...軌道...

...そして前後に進みます。

これらのコントロールをクリックおよび長押しすると、コンテンツとのやり取りと表示と移動をすばやく切り替えることができます。

これらのボタンをクリックして特定のコントロールモードに切り替えることもできるので、マウスボタンを押し続ける必要はありません。

たとえば、パンボタンをクリックすると、ビューポートをクリックしてドラッグすると、ビューがパンされます。

一番左のコントロールをクリックすると、ルックアンドタップのコントロールに戻ります。

シミュレータには、さまざまな部屋や照明条件でアプリが実行されているのを見るために使用できるいくつかのシミュレートされたシーンが付属しています。

ツールバーのシミュレートされたシーンメニューからそれらを切り替えることができます。

シミュレータの使用の詳細については、developer.apple.comのドキュメントを参照してください。

シミュレーターに精通したので、そこで実行されている新しいアプリを見てみましょう。

いつものように、製品メニューの「実行」をクリックして、Xcodeからアプリを実行します。

アプリが起動すると、RealityKitコンテンツパッケージの内容を示すボリュームが表示されます。

「RealityView Contentを拡大」ボタンをタップするとコンテンツが拡大し、再度タップすると元のサイズに戻ります。

RealityViewのジェスチャーにより、球をタップして拡大することもできます。

球体をタップすると、ボタンのハイライトが変わります。

タップジェスチャーはSwiftUI状態を更新しており、RealityViewとToggleビューの両方が状態の変化に反応します。

Xcodeプレビューを使用すると、アプリのビューの外観と動作にすばやく集中して反復できます。

SwiftUIプレビュープロバイダーを含むソースファイルを編集すると、プレビューキャンバスがXcodeで自動的に開きます。

シミュレータと同様に、Xcodeプレビューはシミュレートされたデバイスビューとして表示されます。

シミュレータをナビゲートするために使用したのと同じコントロールを使用してプレビューウィンドウをナビゲートできます。

コントロールを使って、コンテンツに少し近づきましょう。

右下隅のコントロールを使用して、シミュレートされたシーンとカメラアングルを変更することもできます。

SwiftUIコードに変更を加え、プレビューの更新をリアルタイムで見ることができます。

先に進んで、トグルのテキストを変更して、「サイズ変更」に変更しましょう。

テキストを変更すると、プレビューの更新に注意してください。

また、Xcodeプレビューでは、ボタンがまだ機能していることに注意してください。

これを使用して、RealityViewクロージャの内容を反復することもできます。

Xcodeプレビューには、アプリの境界を超えたコンテンツを検出できるオブジェクトモードや、カスタムカメラアングルなど、さらに多くの高度な機能があります。

Xcodeプレビューの詳細については、開発者ドキュメントを参照してください。

RealityKitコンテンツパッケージの操作に役立つ新しいツールを作成しました。

Reality Composer Proは、アプリの空間コンテンツを準備してプレビューするのに最適な場所です。

私たちのアプリのContentViewは、RealityViewを使用して、RealityKitコンテンツパッケージからコンテンツをロードします。

テンプレートによって作成されたコンテンツパッケージはRealityKitContentと呼ばれ、Xcodeプロジェクトのパッケージグループにあります。

ここでは、RealityKitContentが選択されたプロジェクトを見ることができます。

RealityKitコンテンツパッケージは、RealityKitコンテンツを含むSwiftパッケージです。

それらは、ランタイム使用のためにコンテンツを最適化するために、ビルド時に処理されます。

RealityContentの開示インジケーターをクリックすると、コンテンツパッケージの内容が表示されます。

キューブアイコンでパッケージをクリックすると、コンテンツパッケージ内のシーンの1つのプレビューが表示されます。

コンテンツパッケージを編集するには、右上の「Reality Composer Proで開く」ボタンをクリックします。

これにより、Reality Composer Proがローンチされます。

Reality Composer Proを起動すると、ContentViewによってロードされた3Dコンテンツが表示されます。

Xcodeの主な焦点はソースファイルとアプリリソースの編集ですが、Reality Composer Proは3Dコンテンツを前面と中央に置きます。

その主なビューは3Dビューポートで、シミュレータと同様のコントロールを使用してナビゲートできます。

Reality Composer Proは、その内容をシーンに整理します。

プロジェクトテンプレートに含まれていたコンテンツパッケージは、単一のシーンから始まります。

プロジェクトを強化するために、没入型スペースのコンテンツを含む新しいシーンを作成しましょう。

Reality Composer Proのファイルメニューから、「新規」>「シーン」を選択します。

名前を付けます。この場合は、単にImmersiveSceneと呼び、[保存]をクリックします。

シーンを作成すると、自動的に開き、ウィンドウの下部にあるプロジェクトブラウザに空のシーンのサムネイルが表示されます。

ウィンドウの上部にある名前をクリックするか、プロジェクトブラウザでシーンをダブルクリックすることで、シーンを切り替えることができます。

これで、新しいシーンに没入型コンテンツを追加する準備が整いました。

Xcodeプロジェクトを設定したとき、SwiftUIのImmersiveSpaceを使用して、周囲のどこにでも無制限のコンテンツを表示する方法について言及しました。

このシーンタイプについて理解するには、さらに2つの重要な詳細があります。

まず、ウィンドウやボリュームシーンのタイプとは異なり、ImmersiveSpaceは足の推測された位置をコンテンツの原点として使用します。

この座標系では、正のx軸が右側にあり、正のy軸が上にあり、負のz軸が目の前にあります。

第二に、アプリがフルスペースで実行されると、手の正確な位置や向きなどの追加データへのアクセスを要求できます。

このデータの一部はプライバシーに敏感であることを覚えておいてください。

アプリがプライバシーに敏感なデータを要求する場合、アプリを使用している人はこのリクエストを承認するように求められます。

これは、共有スペースのアプリでは利用できません。

没入型スペースを提示するアプリの利用可能な追加データとプライバシーに関する考慮事項の詳細については、セッション「空間コンピューティングのためのARKitに会う」を参照してください。

没入型体験を作成する方法について詳しくわかったので、ImmersiveSpaceでうまく機能するコンテンツを組み立てましょう。

私は、没入型体験に適したコンテンツを作成するために使用するUSDZクラウドモデルを持っています。

Reality Composer ProのシーンにUSDZモデルを追加するには、[ファイル]メニューを開き、[インポート]をクリックします。

次に、ファイルを選択します。

USDZモデルがプロジェクトブラウザに表示されることに注意してください。

シーンに追加するには、ビューポートにドラッグするだけです。

また、FinderウィンドウからビューポートにUSDZファイルをドラッグアンドドロップするだけで、同時にシーンにインポートして追加することもできます。

では、没入型シーンにクラウドを配置しましょう。

オブジェクトを選択し、表示されるハンドルを使用することで、オブジェクトを移動できます。

または、右側のインスペクタパネルで値を手動で設定することもできます。

このシーンタイプは、足の推測された位置を原点として使用するため、雲がどこかに現れてすぐに見えるように配置する必要があります。

この場合、目の高さよりやや上、あなたの前と少し右に配置します。

この雲を少し右に見せたい。

正のx軸は右側にあるので、Xを50に設定しましょう。

この変更を行うと、クラウドがビューポートから移動することに注意してください。

もう一度焦点を合わせるには、左側のシーン階層でダブルクリックします。

雲が再び見えるので、Y座標について考えてみましょう。

雲が私たちの上に現れるようにしたいので、200センチの高さに置きましょう。

それは床から約6フィート半です。

雲が再びビューポートを離れるので、それを視界に戻しましょう。

雲を目の前に置いて、まっすぐ見上げる必要がないようにする必要があります。

私たちから離れた方向は負のz軸なので、Zの位置を-200センチメートルに設定しましょう。

シーン階層でもう一度ダブルクリックして、前面と中央にします。

雲は私たちの没入型シーンのための小さな側にあります。

どうすればそれを大きくできるか見てみましょう。

スケールを増やすには、円をそこから引き離します。

輸入時の約5倍の大きさにしたいと思います。

最後に、今回は左側に2番目のクラウドを追加しましょう。

[編集] メニュー > [複製] コマンドを使用して、最初のクラウドのコピーを作成できます。

コピーを左に置くには、X座標を-50に設定します。

ビューポートでシーンのすべてのコンテンツをフレーム化するには、階層内のルートをダブルクリックします。

素晴らしい、今、私たちは没入型体験に適したコンテンツを持つシーンを持っています。

「ファイル」>「すべて保存」を使用してXcodeに戻る前に、変更を保存しましょう。

Reality Composer Proは、空間コンテンツを準備、プレビュー、アプリに統合するための強力なツールです。

より詳細な紹介については、セッション「Meet Reality Composer Pro」をご覧ください。

セッション「XcodeでReality Composer Proコンテンツと連携」は、最初のセッションに基づいて構築され、RealityKitコンテンツパッケージのコンテンツをアプリと密接に統合する方法を示します。

次のステップは、アプリで作成した没入型コンテンツを提示することです。

アプリによって提示されたシーンは、プロジェクト名の接頭辞が付いたソースファイルApp.swiftにあります。

今、それを詳しく見てみましょう。

あなたは私たちのアプリがContentViewを提示することをどのように知っているかを自問したかもしれません。

私たちのアプリは、ボリュームのコンテンツとしてContentViewを表示するために単一のWindowGroupを使用していることがわかります。

WindowGroupは、指定されたビューを表示する1つ以上のウィンドウまたはボリュームを作成するシーンです。

ボディプロパティの最初のシーンは、起動時にアプリによって表示されるシーンであり、最初のシーンの後にシーンを追加することで、アプリに追加シーンを追加できます。

私たちのアプリは、Reality Composer Proで作成したばかりのコンテンツで没入型空間を提示したいと考えています。

このスペースには、アプリに追加するImmersiveViewと呼ばれる新しいビューの内容が表示されます。

スペースにIDを割り当てる必要があります。

IDとして文字列「ImmersiveSpace」を選択しました。これは、後でスペースを開くときに使用します。

このコードをプロジェクトのApp.swiftソースファイルに追加し、ImmersiveViewにコードを追加して、Reality Composer Proで作成した新しいシーンをロードしましょう。

私はすでにXcodeのSwiftUI Viewテンプレートを使用してImmersiveView.swiftをプロジェクトに追加しました。

私たちのプロジェクトのApp.swiftでは、ImmersiveSpaceを追加します。

次に、ImmersiveView.swiftの上部で、RealityKitコンテンツパッケージを使用できるようにRealityKitContentをインポートします。

また、RealityViewを使用するには、RealityKitをインポートする必要があります。

ImmersiveViewのデフォルトコンテンツは単なるテキストボックスです。

コンテンツパッケージに追加した新しいシーンからコンテンツをロードするRealityViewに置き換えましょう。

これを行うには、左側のプロジェクト階層のContentViewをダブルクリックし、最初のクロージャとともにRealityViewのコードを選択してコピーします。

開いているファイルタブを使用して、ImmersiveViewに戻り、テキストビューを選択し、貼り付けてRealityViewコードに置き換えることができます。

RealityViewの更新終了をコピーしなかったことに気付いたかもしれません。

これは、SwiftUI状態の変更に対応して、このビューの内容を更新するつもりはないためです。

最後に、作成した没入型シーンのコンテンツをロードするには、ロードされたシーンの名前を「Scene」から「ImmersiveScene」に変更します。

プレビューは現在、ImmersiveSceneのコンテンツを読み込んでいますが、プレビューキャンバスで表示できないのはなぜですか?

ImmersiveViewを作成すると、Xcodeプレビューが自動的に作成されました。

詳しく見てみましょう。 

ImmersiveView.swiftの下部を見ると、Xcodeにプレビューを表示するように指示するコードが表示されます。

それは#Previewで始まるコードのブロックです。

デフォルトでは、プレビューはデフォルトのシーン境界にクリップされます。

これらの範囲外にコンテンツをロードするビューを表示している場合、コンテンツは表示されません。

これらの範囲を超えた没入型コンテンツのプレビューをサポートするには、.previewLayout(.sizeThatFits)で準備されているビューを変更するだけです。

今それをやりましょう。

ImmersiveViewのプレビューに.previewLayout(.sizeThatFits)を追加すると、プレビューが更新され、没入型コンテンツが表示されます。

最後に、アプリに没入型スペースを開いてもらいましょう。

iOSでマルチシーンのSwiftUIアプリで作業したことがある場合は、SwiftUIコードから追加のシーンがどのように開かれるかをすでに見ているかもしれません。

最初のステップは、ビューのSwiftUI環境からクロージャをキャプチャすることです。これは、ボタンを押すなどのイベントに応答して呼び出されます。

没入型空間の提示は、新しいプラットフォーム上のSwiftUIでも同じように機能しますが、キャプチャされたクロージャは「openImmersiveSpace」と呼ばれ、非同期であり、没入型空間がいつ提示されたかをコードで知ることができます。

ContentViewに戻ると、SwiftUI環境からopenImmersiveSpaceクロージャをキャプチャし、それを呼び出すボタンを追加するだけです。

アプリが没入型コンテンツを表示するために必要なすべての変更を加えました。

シミュレーターでコンテンツを体験できますが、没入感はデバイス自体で特に魅力的です。

調べてみましょう。

押すと、ImmersiveSpaceのコンテンツとして雲を表示する新しいボタンが表示されます。

目の前に2つの雲が見えます。1つは左に、もう1つは右にあります。

没入型スペースは、アプリの最初のシーンとは異なることに注意してください。

最初のシーンを移動すると、ImmersiveSpaceのコンテンツが固定されたままであることがわかります。

人はアプリの初期ボリュームを好きな場所に移動できますが、ImmersiveSpaceを開くと固定された場所に配置されます。

没入型空間を動かすのではなく、没入型空間の中で動き回ります。

私たちは、没入型スペースを使用して頭の上に雲を提示するシンプルなアプリを構築しました。

アプリがクラウドとの相互作用に応答したかったらどうでしょうか?

簡単にするために、雲をタップすると空を横切って穏やかに浮かぶと想像してみてください。

これをどうやって達成できるか見てみましょう。

SwiftUIビューが入力イベントに応答するには、ジェスチャーを添付できます。

この例では、単純なテキストビューがあります。

ビューにTapGestureを添付することで、人がビューをタップしたときに応答することができます。

ジェスチャーがビューにアタッチされると、ジェスチャーが認識されたときに呼び出されるクロージャが与えられます。

RealityViewは単なるSwiftUIビューなので、同じようにジェスチャーに反応します。

ただし、RealityViewには、複数のエンティティを持つRealityKitコンテンツが含まれている場合があります。

たとえば、私たちのアプリは、クラウドモデルを含むRealityViewを表示するImmersiveSpaceを開きます。

人がクラウドの1つをタップすると、SwiftUIはRealityViewでTapGestureを呼び出します。

しかし、どのクラウドがタップによって標的にされたかをどうやって知ることができますか?

ここでエンティティターゲティングの出番です。

targetedToAnyEntity修飾子は、RealityViewにアタッチされたジェスチャーで動作し、ジェスチャーがターゲットとする正確なエンティティを決定します。

利用可能なエンティティをターゲットにする他の方法があります。

特定のエンティティをターゲットにすることも、クエリに一致するすべてのエンティティをターゲットにすることもできます。

詳細については、developer.apple.comのドキュメントをお読みください。

onEndedなどのジェスチャーのハンドラに渡される値には、その人がRealityView内でそのエンティティと対話したことを示すエンティティプロパティがあります。

エンティティターゲティングが特定のRealityKitエンティティで動作するには、エンティティがCollisionComponentとInputTargetComponentの両方を持っている必要があることに注意してください。

RealityKitエンティティにこれらのコンポーネントを要求することで、RealityViewのコンテンツの選択した部分のみにインタラクションを制限することができます。

これらのコンポーネントをReality Composer Proのエンティティに追加することも、アプリでプログラムで追加することもできます。

エンティティターゲティングがどのように機能するかを見たので、それを使って人がクラウドをタップしたときに検出しましょう。

このインタラクションが発生すると、RealityKitアニメーションを開始します。

Reality Composer Proに必要なコンポーネントを追加することから始めましょう。

RealityKitコンテンツパッケージでは、Commandキーを押しながらクリックを使用して、ビュー階層から両方のクラウドを一度に選択できます。

次に、インスペクタパネルの下部にある「コンポーネントを追加」ボタンをクリックし、衝突を選択します。

インスペクタパネルでは、CollisionComponentがクラウドに追加されていることがわかります。

Reality Composer Proは、適切な衝突形状を自動的に選択することで、モデルのCollisionComponentを作成することに注意してください。

必要に応じて、この衝突形状を変更できます。

私たちは今、InputTargetComponentにも同じことをします。

コンポーネントの追加ボタンをもう一度クリックし、今回は入力ターゲットを選択します。

すごい！「ファイル」>「すべて保存」を選択して、変更を保存しましょう。

実際に雲を空を移動させるには、雲がタップされたときに呼び出されるジェスチャーハンドラでRealityKitアニメーションを使用します。

まず、クラウドの変換の現在の値を可変値としてキャプチャし、次に翻訳にオフセットを追加して前方と右の両方に100センチメートル移動し、クラウドエンティティで.moveを呼び出してRealityKit変換アニメーションを適用します。

Xcodeに戻ってアプリを完成させましょう。 アプリを完成させましょう。

ImmersiveViewは、没入型コンテンツでRealityViewを提示するソースファイルです。

TapGestureをRealityViewに添付するコードを追加し、エンティティターゲティングを使用しましょう。

そして、タップが検出されたら、変換アニメーションを実行します。

シミュレーターで実行して、実際に見てみましょう!

ボタンをタップすると、以前のように雲が入ったImmersiveSpaceが開きます。

しかし今、雲をタップすると、それは空を横切って穏やかに浮かびます。

エンティティターゲティングは、SwiftUIインタラクションをRealityKitコンテンツに接続する接着剤です。

この例では、タップに応答して雲の上で簡単なアニメーションを実行しました。

より複雑なアプリでは、エンティティターゲティングを使用して、追加のビューの表示、オーディオの再生、アニメーションの開始など、より洗練されたアクションをトリガーできます。

今日は多くのトピックを取り上げました。それらを要約しましょう。

Xcodeの新しいプロジェクトアシスタントを使用して、最初の没入型アプリを作成する方法から始めました。

その後、新しいプラットフォーム用のシミュレータを導入し、Xcodeプレビューがアプリのコンテンツを簡単に反復する方法を示しました。

また、Reality Composer Proを導入し、RealityKitコンテンツを簡単に準備してプレビューする方法を見ました。

最後に、ImmersiveSpaceを開き、エンティティターゲティングを使用して、没入型コンテンツとのインタラクションをプログラムで有効にし、応答する方法を示しました。

このプレゼンテーションを楽しんでいただければ幸いです。

新しいSwiftUIとRealityKit APIに関するより詳細なセッション、およびReality Composer Proのより高度なユースケースを探索することをお勧めします。

見てくれてありがとう!

♪