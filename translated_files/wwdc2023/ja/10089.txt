10089

♪まろやかなインストゥルメンタルヒップホップ♪

♪

こんにちは、私はアップルのソフトウェアエンジニア、パウ・サストレ・ミゲルです。

今日は、xrOSでMetalで没入型体験を作成する方法について話します。

今年は、xrOSの発売により、Appleのエコシステムで使い慣れた技術で没入型体験を生み出すことができます。

RealityKitを使用すると、仮想コンテンツと現実世界を融合させる体験を作成できます。

一方、アプリケーションがユーザーを完全に没入型体験に連れて行く場合、xrOSでは、現実世界のコンテンツを独自の仮想コンテンツに完全に置き換えることもできます。

完全に没入感のある体験を作成する場合、レンダリング方法に関してはいくつかの選択肢があります。

RealityKitを引き続き使用することも、必要に応じてMetalとARKit APIを選択できます。

RecRoomは、CompositorServicesを使用してレンダリングセッションを作成し、Metal APIを使用してフレームをレンダリングし、ARKitを使用して世界とハンドトラッキングを取得する完全没入型体験を提供するアプリケーションの素晴らしい例です。

彼らはUnityエディタのおかげで、これらすべての技術にサポートをもたらすことができました。

独自のエンジンを書きたい場合は、CompositorServices APIを使用すると、xrOS上のMetalレンダリングにアクセスできます。

ワールドトラッキングとハンドトラッキングを追加するARKitと組み合わせて、完全に没入感のある体験を作り出すことができます。

CompositorServicesは、xrOSで動作するようにエンジンを設定するための鍵です。

レンダリングループの設定方法と、1つのフレームをレンダリングする方法を紹介します。

最後に、ARKitを使って体験をインタラクティブにする方法を紹介します。

xrOSアプリのアーキテクチャから始めましょう。

メタルAPIとメタルレンダリング技術の経験があれば、今日のセッションを最大限に活用できます。

以前にMetalを使用したことがない場合は、developer.apple.com/Metalでコードサンプルとドキュメントをチェックしてください。

MetalでxrOSで没入型体験を作成するときは、SwiftUIから始めてアプリケーションとレンダリングセッションを作成します。

レンダリングセッションを作成した後、CやC++など、より馴染みのある言語に切り替えて、エンジンの内部部分を定義できます。

SwiftUIアプリプロトコルに準拠したタイプを作成することから始めます。

このプロトコルに準拠するには、アプリでシーンのリストを定義します。

xrOSには、主に3つのシーンタイプがあります。

ウィンドウタイプは、macOSのような2Dプラットフォームに似た体験を提供します。

ボリュームタイプは、その範囲内でコンテンツをレンダリングし、共有スペースで他のアプリケーションと共存します。

また、ImmersiveSpaceを使用すると、どこにでもコンテンツをレンダリングできます。

メタルで完全に没入感のある体験をレンダリングするたびに、ImmersiveSpaceタイプを選択します。

ImmersiveSpaceは、xrOSで利用可能な新しいSwiftUIシーンタイプです。

それは完全に没入型体験のための容器として機能します。

ImmersiveSpaceの使い方を学ぶには、「SwiftUIで窓を越えて行く」セッションをチェックしてください。

ImmersiveSpaceシーンを作成すると、アプリケーションはImmersiveSpaceContentプロトコルに準拠したタイプを使用してコンテンツを提供します。

多くの場合、ImmersiveSpaceシーンのコンテンツを作成するとき、アプリケーションはRealityKitを使用します。

ボンネットの下にCoreAnimationとMaterialXを使用しています。

しかし、代わりに、Metalの力を使ってアプリケーションのコンテンツをレンダリングしたい場合は、別の選択肢があります。

CompositorServices APIは、MetalとARKitを使用して、アプリケーションに没入型レンダリング機能を提供します。

xrOSで導入された新しいCompositorServices APIは、ImmersiveSpaceの内容をレンダリングできるMetalレンダリングインターフェイスを提供します。

CompositorServicesを使用すると、アプリケーションはコンポジターサーバーに直接レンダリングできます。

レイテンシを最小限に抑えるためにIPCオーバーヘッドが低く、CとSwiftの両方のAPIをサポートするためにゼロから構築されています。

CompositorServicesを使用する場合、ImmersiveSpaceContentはCompositorLayerと呼ばれます。

CompositorLayerを作成するには、2つのパラメータを指定する必要があります。

1つ目はCompositorLayerConfigurationプロトコルです。

このプロトコルは、レンダリングセッションの動作と機能を定義します。

2つ目はLayerRendererです。

これは、レイヤーレンダリングセッションのインターフェースです。

アプリケーションはこのオブジェクトを使用して、新しいフレームをスケジュールおよびレンダリングします。

Metalで没入型体験を書くときは、アプリのタイプを定義することから始めます。

シーンタイプとして、ImmersiveSpaceを使用します。

コンテンツタイプには、CompositorLayerを使用してください。

CompositorLayerがコンテンツをレンダリングする準備ができたら、システムはレンダリングセッションのインスタンスでアプリケーションを呼び出します。

これは、カスタムエンジンのインスタンスを作成するのに適した場所です。

エンジンインスタンスができ、レンダリングスレッドを作成し、startを呼び出してレンダリングループを実行できます。

アプリケーションでシーンリストを定義する際に考慮すべきことの1つは、アプリの最初のシーンがImmersiveSpaceであっても、デフォルトでSwiftUIがウィンドウシーンを作成することです。

そのデフォルトの動作を変更するには、アプリの情報plistを変更できます。

キーUIApplicationPreferred DefaultSceneSessionRoleをアプリケーションシーンマニフェストに追加して、アプリケーションのデフォルトのシーンタイプを変更できます。

Compositor SpaceContentでスペースを使用している場合は、CPSceneSessionRole ImmersiveSpaceApplicationを使用します。

アプリケーションを設定した後、レンダリングループに入る前に、LayerRendererの設定方法をCompositorServicesに伝えます。

CompositorLayerに構成を提供するには、CompositorLayerConfigurationプロトコルに準拠した新しいタイプを作成します。

このプロトコルを使用すると、レンダリングセッションのセットアップと動作の一部を変更できます。

CompositorLayerConfigurationは2つのパラメータを提供します。

1つ目はレイヤー機能です。

これにより、デバイスで利用可能な機能を照会できます。

機能を使用して、有効な設定を作成します。

そして2番目のパラメータは、LayerRendererの設定です。

このタイプは、レンダリングセッションの設定を定義します。

設定により、エンジンがコンテンツをレイヤーにマッピングする方法を定義し、フォベレーションレンダリングを有効にし、パイプラインの色管理を定義できます。

さて、これらの各プロパティがエンジンにどのように影響するかについて話します。

1つ目はフォベレーションレンダリングです。

この機能の主な目的は、より大きなテクスチャサイズを使用せずに、より高いピクセル/度密度でコンテンツをレンダリングできるようにすることです。

通常のディスプレイパイプラインでは、ピクセルはテクスチャに直線的に分布します。

xrOSは、ディスプレイのどの領域がより低いサンプリングレートを使用できるかを定義するマップを作成することで、このワークフローを最適化します。

これは、ディスプレイの視覚的な忠実度を維持しながら、フレームをレンダリングするために必要な電力を減らすのに役立ちます。

より良い視覚体験につながるため、可能な限りfoveationを使用することは重要です。

foveationがレンダリングパイプラインにどのように影響するかを視覚化する素晴らしい方法は、XcodeのMetal Debuggerを使用することです。

Metal Debuggerを使用すると、レンダリングパイプラインで使用されているターゲットテクスチャとラスタライズレートマップを検査できます。

このキャプチャは、ラスタライズレートマップのスケーリングなしでテクスチャの内容を表示します。

より圧縮されたテクスチャの領域に焦点を合わせることで、異なるサンプルレートに気づくことができます。

メタルデバッガの添付ファイルビューアオプションを使用すると、画像を拡大縮小して、ディスプレイに表示される最終結果を視覚化できます。

コンポジターは、各フレームのMTLRasterizationRateMapを使用してフォベーションマップを提供します。

フォベーションがサポートされているかどうかを常に確認することをお勧めします。

これはプラットフォームによって変わります。

たとえば、xrOSシミュレータでは、フォベネーションは利用できません。

foveationを有効にするには、設定でisFoveationEnabledを設定できます。

2番目のプロパティはLayerRendererレイアウトです。

このプロパティは、エンジンにとって最も重要な構成の1つです。

ヘッドセットからの各ディスプレイがアプリケーションのレンダリングされたコンテンツにどのようにマッピングされるかを定義します。

それぞれの目は、コンポジターが提供するメタルテクスチャに最初にマッピングされます。

次に、Compositorは、そのテクスチャ内でどのスライスを使用するかのインデックスを提供します。

そして最後に、コンポジターは、そのテクスチャスライス内で使用するビューポートを提供します。

LayerRendererのレイアウトでは、テクスチャスライスとビューポートの間で異なるマッピングを選択できます。

レイヤーでは、コンポジターは2つのスライスと2つのビューポートを持つ1つのテクスチャを使用します。

専用では、コンポジターはそれぞれ1つのスライスと1つのビューポートを持つ2つのテクスチャを使用します。

そして最後に、共有では、Compositorはそのスライスに1つのテクスチャ、1つのスライス、および2つの異なるビューポートを使用します。

使用するレイアウトの選択は、レンダリングパイプラインの設定方法によって異なります。

たとえば、レイヤーと共有を使用すると、1回のパスでレンダリングを実行できるため、レンダリングパイプラインを最適化できます。

共有レイアウトでは、フォベレーションされたレンダリングがオプションではない既存のコードベースを移植する方が簡単かもしれません。

レイヤードレイアウトは、フォベレーションされたレンダリングを維持しながら、ワンパスでシーンをレンダリングできるため、最適なレイアウトです。

議論する最後の構成プロパティはカラーマネジメントです。

コンポジターは、コンテンツが拡張リニアディスプレイP3色空間でレンダリングされることを期待しています。

xrOSは2.0のEDRヘッドルームをサポートしています。

それはSDR範囲の2倍です。

デフォルトでは、CompositorはHDRレンダリング可能なピクセル形式を使用しませんが、アプリケーションがHDRをサポートしている場合は、レイヤー構成でrgba16Floatを指定できます。

EDRでHDRをレンダリングする方法についてもっと知りたい場合は、「EDRでHDRレンダリングを探索する」セッションをチェックしてください。

アプリケーションでカスタム設定を作成するには、CompositorLayerConfigurationプロトコルに準拠した新しいタイプを定義することから始めます。

このプロトコルに準拠するには、makeConfigurationメソッドを追加します。

このメソッドは、レイヤーの機能と変更できる構成を提供します。

前に述べた3つのプロパティを有効にするには、まずフォベーションがサポートされているかどうかを確認してください。

次に、このデバイスでサポートされているレイアウトを確認してください。

この情報を使用して、設定で有効なレイアウトを設定できます。

コンポジターが1つのビューのみをレンダリングするシミュレータのような一部のデバイスでは、レイヤードは利用できません。

Foveationの場合、デバイスがサポートしている場合はtrueに設定します。

そして最後に、colorFormatをrgba16Floatに設定して、HDRコンテンツをレンダリングできるようにします。

コンポジターレイヤーを作成したコードに戻ると、作成したばかりの構成タイプを追加できるようになりました。

レンダリングセッションが設定されたので、レンダリングループを設定できます。

まず、CompositorLayerのLayerRendererオブジェクトを使用します。

まず、リソースをロードし、エンジンがフレームをレンダリングするために必要なオブジェクトを初期化します。

次に、レイヤーの状態を確認します。

レイヤーが一時停止している場合は、レイヤーが実行されるまで待ちます。

レイヤーが待機からブロック解除されたら、レイヤーの状態をもう一度確認してください。

レイヤーが実行されている場合は、フレームをレンダリングできます。

そして、そのフレームがレンダリングされたら、次のフレームをレンダリングする前にレイヤーの状態をもう一度確認してください。

レイヤー状態が無効になっている場合は、レンダリングループ用に作成したリソースを解放します。

さて、render_loopのメイン関数を定義する時が来ました。

今まで、ImmersiveSpace APIはSwiftでしか利用できないので、Swiftを使っています。

しかし、ここからレンダリングループを書くためにCに切り替えます。

前述したように、レンダリングループの最初のステップは、フレームをレンダリングするために必要なすべてのオブジェクトを割り当てて初期化することです。

これを行うには、カスタムエンジンのセットアップ関数を呼び出すことができます。

次に、ループのメインセクションです。

最初のステップは、layerRendererの状態を確認することです。

状態が一時停止されている場合、レイヤーレンダラーが実行されるまでスレッドはスリープ状態になります。

レイヤー状態が実行されている場合、エンジンは1つのフレームをレンダリングします。

そして最後に、レイヤーが無効になっている場合、レンダリングループは終了します。

Render_loop関数の最後のステップは、使用したリソースをクリアすることです。

アプリがレンダリングループを通過したので、1つのフレームをレンダリングする方法を説明します。

xrOSでのコンテンツのレンダリングは、常にデバイスの観点からです。

ARKitを使用して、デバイスの向きと翻訳を取得できます。

ARKitはすでにiOSで利用可能であり、現在xrOSは、没入型体験を作成するのに役立つ追加機能を備えたまったく新しいAPIを導入しています。

ARKitを使用すると、ワールドトラッキング、ハンドトラッキング、その他のワールドセンシング機能をアプリケーションに追加できます。

新しいARKit APIは、CおよびSwift APIをサポートするためにゼロから構築されているため、既存のレンダリングエンジンとの統合が容易になります。

xrOSのARKitの詳細については、「空間コンピューティングのためのARKitの出会い」をご覧ください。

レンダリングループ内で、1つのフレームをレンダリングする時が来ました。

フレームをレンダリングするとき、Compositorは2つの主要なセクションを定義します。

1つ目はアップデートです。

ここでは、入力遅延が重要ではない作業を行う場所です。

これは、シーンのアニメーションを更新したり、キャラクターを更新したり、ハンドスケルトンのポーズのようにシステムに入力を集めたりします。

フレームの2番目のセクションは提出セクションです。

ここでは、レイテンシクリティカルな作業を実行する場所です。

また、ヘッドセットポーズに依存するコンテンツをここでレンダリングします。

これらの各セクションのタイミングを定義するために、Compositorはタイミングオブジェクトを提供します。

この図は、タイミングがさまざまなフレームセクションにどのように影響するかを定義します。

CPUとGPUのトラックは、アプリケーションによって行われている作業を表します。

また、コンポジタートラックは、コンポジターサーバーがフレームを表示するために行った作業を表します。

コンポジターサービスのタイミングタイプは、3つの主要な時間値を定義します。

1つ目は最適な入力時間です。

これは、レイテンシクリティカルな入力を照会し、フレームのレンダリングを開始するのに最適な時期です。

2つ目はレンダリングの締め切りです。

それは、CPUとGPUがフレームをレンダリングするために作業する時間です。

そして3つ目はプレゼンテーションの時間です。

それはあなたのフレームが展示される時間です。

フレームの2つのセクションでは、更新セクションは最適な入力時間の前に行われるはずです。

更新後、フレームの送信を開始する前に、最適な入力時間を待ちます。

次に、フレーム送信を実行し、レンダリング作業をGPUに提出します。

CPUとGPUの作業はレンダリングの締め切り前に完了する必要があることに注意することが重要です。そうしないと、Compositorサーバーはこのフレームを使用できず、代わりに以前のフレームを使用します。

最後に、レンダリング期限に、コンポジターサーバーはこのフレームをシステム内の他のレイヤーと合成します。

レンダリングループコードに戻ると、render_new_frame関数を定義する時が来ました。

エンジンのrender_new_frame関数では、まずlayerRendererからフレームを照会します。

フレームオブジェクトを使用すると、タイミング情報を予測できます。

そのタイミング情報を使用して、更新をスコープし、間隔を送信します。

次に、更新セクションを実装します。

フレームの開始と終了の更新を呼び出して、このセクションを定義します。

内部では、デバイスの入力を収集し、フレームの内容を更新します。

更新が完了したら、最適な入力時間を待ってから送信を開始します。

待機後、送信の開始と終了の送信を呼び出して、送信セクションを定義します。

このセクション内で、まず描画可能なオブジェクトを照会します。

CAMetalLayerと同様に、描画可能なオブジェクトには、ターゲットテクスチャとレンダリングパイプラインを設定するために必要な情報が含まれています。

描画可能になったので、Compositorがこのフレームをレンダリングするために使用する最終的なタイミング情報を取得できます。

最終的なタイミングで、ar_poseを照会できます。

コンポジターがフレームに再投影を実行するために使用されるため、ドローableにポーズを設定することが重要です。

ここでは、エンジンオブジェクトのget_ar_pose関数を呼び出してポーズを取得しています。

ただし、ARKitワールドトラッキングAPIを使用して、この機能の内容を実装する必要があります。

機能の最後のステップは、すべてのGPU作業をエンコードしてフレームを提出することです。

Submit_frame内で、ドローアブルを使用して、通常どおりフレームの内容をレンダリングします。

レンダリングループがフレームをレンダリングするようになったので、没入型の体験をインタラクティブにする時が来ました。

このビデオは、Unityを使用するRecRoomがすでにARKitとCompositor APIを利用してアプリケーションにインタラクティブ性を追加する方法を示しています。

この相互作用を推進する2つの主要な入力ソースがあります。

ARKitのHandTrackingは、仮想の手をレンダリングするためのハンドスケルトンを提供しています。

そして、LayerRendererからのピンチイベントがユーザーインタラクションを推進しています。

体験をインタラクティブにするために、まずユーザーの入力を収集し、それをシーンの内容に適用します。

この作業はすべて、フレームの更新セクションで行われます。

LayerRendererとARKit HandTrackingプロバイダーの2つの主要な入力ソースがあります。

LayerRendererを使用すると、アプリケーションがピンチイベントを受信するたびに更新されます。

これらの更新は、空間イベントの形で公開されます。

これらのイベントには3つの主要なプロパティが含まれています。

フェーズは、イベントがアクティブかどうか、終了したかどうか、またはキャンセルされたかどうかを教えてくれます。

選択光線を使用すると、イベントが始まったときに注目を集めたシーンの内容を判断できます。

そして、最後のイベントプロパティはマニピュレーターのポーズです。

これはピンチのポーズで、イベント期間中、すべてのフレームが更新されます。

HandTracking APIから、左手と右手の両方のスケルトンを取得できます。

さあ、コードに入力サポートを追加する時が来ました。

入力を収集する前に、アプリケーションが仮想ハンドをレンダリングしているのか、パススルーハンドを使用しているのかを決定します。

UpperLimbVisibilityシーン修飾子をImmersiveSpaceに追加して、パススルーの手を表示または非表示にします。

空間イベントにアクセスするには、CompositorLayerレンダリングハンドラを定義した場所に戻ります。

ここでは、layerRendererにブロックを登録して、新しい空間イベントがあるたびに更新を取得します。

エンジンコードをCで書く場合は、SwiftUI空間イベントをCタイプにマッピングします。

Cコード内で、Cイベントコレクションを受け取ることができます。

空間イベントの更新を処理する際に留意すべきことの1つは、更新がメインスレッドで配信されることです。

これは、エンジンでイベントを読み書きするときに、いくつかの同期メカニズムを使用することを意味します。

イベントがエンジンに保存されたので、gather入力機能を実装する時が来ました。

最初のステップは、このフレームの現在の入力状態を格納するオブジェクトを作成することです。

この入力状態は、LayerRendererから受信したイベントを保存します。

安全な方法で内部ストレージにアクセスしていることを確認してください。

ハンドスケルトンについては、ARKitのハンドトラッキングプロバイダーAPIを使用して、最新のハンドアンカーを入手できます。

そして、アプリケーションが入力サポートを利用できるようになったので、xrOSで完全に没入感のある体験を作成するためのすべてのツールを自由に利用できます。

要約すると、SwiftUIでは、アプリケーションを定義します。

CompositorServicesとMetalを使用すると、レンダリングループを設定し、3Dコンテンツを表示します。

そして最後に、ARKitを使用すると、あなたの体験をインタラクティブにすることができます。

見てくれてありがとう!

♪