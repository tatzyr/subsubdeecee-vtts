10260

♪まろやかなインストゥルメンタルヒップホップ♪

♪

ジム・ティランダー：こんにちは、私はRealityKitチームのエンジニアであるジムです。

今日、ARKitチームの同僚のクリストファーが、空間コンピューティング用のアプリの構築を開始する方法をご案内します。

飛び込もう！

私たちは、空間コンピューティングのための新しいプラットフォームに興奮しています。

このプラットフォームは、人々が使用し、あなたがアプリを開発するための使い慣れた基盤の上に構築されています。

実際のコンテンツと仮想コンテンツをブレンドし、自然な入力を使用してアプリと対話する新しいエキサイティングな可能性を開きます。システム全体が人々のプライバシーを保護するように設計されており、アプリの経験に集中する安心感を提供します。

空間コンピューティングの語彙と概念を構築するための基礎について少し話しましょう。

その後、アプリを使い始めるためのさまざまな方法について説明します。

その後、同僚のクリストファーがアプリの構築方法を説明し、空間コンピューティングの詳細を深く掘り下げます。

さて、いくつかのファンダメンタルズを見てみましょう。

まず、使い慣れたUIの概念と新しいUIの概念の両方が空間コンピューティングで何を意味するのかを取り上げましょう。

デフォルトでは、アプリは共有スペースに起動します。

これは、Macデスクトップ上の複数のアプリのように、アプリが並んで存在する場所です。

人々はパススルーを通じて周囲とつながっています。

各アプリは1つ以上のウィンドウを持つことができます。

これらは、通常のmacOSウィンドウのようにサイズを変更してリフローできるSwiftUIシーンです。

従来のビューとコントロール、および3Dコンテンツを含めることができ、2Dと3Dをミックスしてマッチさせることができます。

人々は、予想通り、現在の空間で自分の好みに合わせて窓を再配置することができます。

ボリュームを使用すると、アプリは定義された範囲で3Dコンテンツを表示し、他のアプリとスペースを共有できます。

ボリュームは、チェス盤などの3Dコンテンツを紹介するのに最適です。

人々は空間でボリュームを再配置することができ、さまざまな角度から見ることができます。

ボリュームはSwiftUIシーンであり、使い慣れた方法でレイアウトを行うことができ、RealityKitの力を使って3Dコンテンツを表示します。

時には、アプリの没入レベルをもっとコントロールしたいと思うかもしれません...ビデオを見ながら集中したり、ゲームをしたりするかもしれません。

これを行うには、専用のフルスペースを開くと、アプリのウィンドウ、ボリューム、3Dオブジェクトだけがビューに表示されます。

フルスペースでは、ARKitのAPIを利用することもできます。

たとえば、システムが提供するジェスチャーに加えて、より詳細な骨格ハンドトラッキングを取得して、人々の手の構造をあなたの経験に本当に組み込むことができます。

あなたのアプリはさまざまな方法でフルスペースを使用できます。

現実世界の地上コンテンツへのパススルーを使用して、人々を周囲とのつながりに保つことができます。

また、空間オーディオを再生し、RealityKitを介して3Dをレンダリングすると、デバイスが部屋の理解を継続的に更新し、人々の周囲にビジュアルとサウンドをブレンドし、これらの仮想オブジェクトが本当に自分の部屋に属していると感じさせるという事実を自動的に利用します。

また、完全に没入型のスペースにレンダリングして、視野全体を埋めることもできます。

これにより、アプリは、仮想オブジェクトの照明をカスタマイズし、オーディオ特性を選択する機能により、アプリの創造的な意図を柔軟に提供できます。

これらは空間コンピューティングの基本的な要素です:窓、ボリューム、スペース。

彼らは、没入の連続にまたがることができるアプリを構築するための柔軟なツールセットを提供します。

クリストファーは後でこれについてもっと話します。

空間コンピューティングの基本的な要素を導入したので、ウィンドウ、ボリューム、スペースと対話する方法を探りましょう。

このプラットフォームでは、目と手を使うだけでアプリと対話できます。

たとえば、ボタンを見て指を合わせてタップして選択することで、ボタンを操作できます。

人々は3D空間で同じボタンに手を伸ばして物理的に触れることもできます。

これらの種類のインタラクションの両方について、タップ、長押し、ドラッグ、回転、ズームなど、さまざまなジェスチャーが可能です。

システムはこれらを自動的に検出し、アプリが応答するためのタッチイベントを生成します。

ジェスチャーはSwiftUIとうまく統合されています。

同じジェスチャーAPIは、RealityKitエンティティとシームレスに連携します。

これにより、人々はあなたの3Dシーン要素と直接簡単に対話することができます。

たとえば、この3Dモデルに直接フラグを配置したり、仮想ジッパーの制御を想像したり、仮想チェスの駒を操作して拾ったりするのに便利です。

ボウリングのゲームをしたり、人々の手をバーチャルクラブに変えたい場合は、ARKitのSkeletal Hand Trackingを通じてこれを行うことができます。

ここでは、タップを使用してテーブルにキューブを積み重ね、手でテーブルに貼り付ける方法の例を見ることができます。

これは、アプリ固有の手のインプットをエクスペリエンスに持ち込むことができる強力な方法です。

そして最後に、システムは自動的にワイヤレスキーボード、トラックパッド、およびアクセシビリティハードウェアからの入力をアプリに直接もたらし、ゲームコントローラーフレームワークでは、ワイヤレスゲームコントローラーのサポートも追加できます。

協力し、一緒に物事を探求することは、空間コンピューティングの基本的な部分です。

これは、SharePlayとグループアクティビティフレームワークを通じて行います。

このプラットフォームでは、macOSと同様に、このクイックルックエクスペリエンスのように、人々は任意のウィンドウを共有できます。

人々がクイックルック3Dモデルを共有すると、参加者間で向き、スケール、アニメーションを同期し、異なる場所にいても簡単に共同作業できます。

人々が自分の空間に表示され、物理的に指しているものに協力しているとき、SharePlayセッションの全員が同じ経験を持つことが重要です。

これは、物体へのジェスチャーなどの自然な参照を可能にし、物理的に一緒にいる感覚を強化します。

共有コンテキストの概念をシステムに追加しました。

システムは、この共有コンテキストを管理し、SharePlayセッションの参加者全員が同じ方法でコンテンツを体験できるようにします。

空間ペルソナテンプレートを使用して、人々があなたのコンテンツをどのように体験するかをさらにカスタマイズできます。

詳細については、このプラットフォームの空間的なSharePlayエクスペリエンスの設計と構築に関するセッションをご覧ください。

デバイスが周囲や人々に関する多くの親密な知識を持っていることを考えると、私たちは人々のプライバシーを保護するために多くのアーキテクチャを導入しました。

それに飛び込みましょう。

プライバシーは、このプラットフォームの設計を導くための基本原則であり、開発者としてAPIを活用してデバイスの多くの機能を利用することを容易にします。

アプリがセンサーから直接データにアクセスできるようにする代わりに、システムはあなたのためにそれを行い、イベントや視覚的な手がかりをアプリに提供します。

たとえば、システムは3D空間で誰かの手の目の位置とジェスチャーを知り、それをタッチイベントとして提供します。

また、システムは、それが注目の焦点であるが、人が見ているアプリと通信しない場合、ビューにホバー効果をレンダリングします。

多くの状況では、システムが提供する動作は、アプリがインタラクションに応答するのに十分です。

実際により機密性の高い情報にアクセスする必要がある場合、システムは最初に人々に許可を求めます。

たとえば、壁や家具を検出するためのシーンの理解にアクセスする許可をユーザーに求めたり、カスタムインタラクションをアプリに持ち込むためにSkeletal Hand Trackingにアクセスしたりします。

アプリで利用可能な機能のいくつかを見たので、それらのアプリをどのように開発しているかを探りましょう。

すべては、Appleの統合開発環境であるXcodeから始まります。

Xcodeは、プロジェクト管理サポート、UIのビジュアルエディタ、デバッグツール、シミュレータなど、アプリを開発するためのツールの完全なセットを提供します。

そして最も重要なことは、Xcodeには、アプリの開発に使用するフレームワークとAPIの完全なセットを提供するプラットフォームSDKも付属しています。

ソースファイルにSwiftUIプレビュープロバイダーが含まれている場合、プレビューキャンバスはXcodeで自動的に開きます。

プレビューキャンバスは3Dをサポートするように拡張され、アニメーションやカスタムコードなど、シーンのRealityKitコードを視覚化できます。

これにより、反復時間を短縮し、ライブコードを編集し、変更や調整の結果を直接確認する際に、アプリの適切なルックアンドフィールを見つけることができます。

軌道速度と衛星のサイズを変更して、衛星が地球を周回している様子を少し実験してみましょう。

プレビューはコードの変更を反映しているため、コードの迅速な実験の結果を簡単に見ることができます。

Xcodeプレビューには、3Dレイアウトのクイックプレビューを可能にするオブジェクトモードもあります。たとえば、レイアウトがビューの境界内に収まるかどうかを確認するなどです。

これは、従来のUIと新しい3Dビジュアルの両方で緊密に統合されたシーンを構築するのに最適です。

Xcodeプレビューは、アプリを実行する直前にレイアウトを取得する素晴らしい方法を提供します。

シミュレーターは、アプリとのインタラクティブ性をテストする素晴らしい方法です。

キーボード、マウス、または互換性のあるゲームコントローラーを使用して、シーン内を移動したり見回したりできます。

また、シミュレートされたシステムジェスチャーを使用して、アプリと簡単にやり取りできます。

シミュレータには3つの異なるシミュレートされたシーンが付属しており、それぞれに昼と夜の照明が付いています。

これにより、さまざまな条件下でアプリを簡単に見ることができます。

シミュレータは、ほとんどのアプリを実行してデバッグし、非常に予測可能な環境で開発中にすばやく反復するのに最適な方法です。

また、デバッグ中に多くのランタイムビジュアライゼーションをサポートするようにXcodeを拡張し、シーンを見るだけでバグをすばやく理解して追跡できるようにしました。

ここでは、それらの平面の意味的な意味やシーン内の衝突形状など、平面推定が見られます。

Xcodeのデバッガから焦点を合わせたいビジュアライゼーションを切り替えるのは簡単です。

これらのビジュアライゼーションは、シミュレータとデバイスの両方でうまく機能します。

アプリケーションのパフォーマンスと応答性を磨く時が来たら、Instrumentsのような使い慣れたツールがあります。

Instrumentsは、Xcodeに含まれている強力なパフォーマンス分析ツールです。

Instrumentsを使用して、実行中のアプリの実用的な洞察を提供できます。

また、空間コンピューティングの場合、Instruments 15には新しいテンプレートであるRealityKit Traceが含まれており、プラットフォーム上の新しい行動についてさらに深い洞察を提供します。

RealityKitトレーステンプレートには、開発者がアプリのGPU、CPU、システム電力への影響を理解し、パフォーマンスのホットスポットを特定できる新しい機器があります。

フレームのボトルネックを簡単に観察して理解し、提出された合計三角形やシミュレートされたRealityKitエンティティの数などの重要な指標にさかのぼることができます。

これにより、潜在的なパフォーマンスの問題を迅速に見つけて対処できます。

詳細については、セッション「Meet RealityKit Trace」をご覧ください。

また、Reality Composer Proという新しい開発者ツールも導入しました。

アプリの3Dコンテンツをプレビューして準備できます。

Reality Composer Proは、すべてのアセットの概要と、それらがシーンにどのように適合するかを把握するのに役立ちます。

RealityKitに追加した新機能はパーティクルで、Reality Composer Proのワークフローを使用して作成してプレビューできます。

シーンに粒子を加えることは、動き、人生、そして無限の可能性を提供します。

雲、雨、火花は、短時間で構築できる効果のほんの一部です。

シーンにオーディオを追加し、それらをオブジェクトに関連付けるのは簡単です。

また、シーン全体の形状とコンテキストを考慮したオーディオを空間的にプレビューすることもできます。

ほとんどの仮想オブジェクトは、RealityKitの物理ベースの素材を使用して、さまざまな現実世界の素材を表現します。

RealityKitは、センサーデータを使用して、現実世界の照明情報をこれらの材料に供給し、人々の周囲に接地します。

RealityKitには、アプリが一般的なシナリオで使用できる追加の標準資料もいくつかあります。

おそらく創造的な意図を伝えるために、非常に特定のニーズがある場合は、オープンスタンダードのMaterialXを使用してReality Composer Proでカスタム資料を作成できます。

コードに触れることなく、使いやすいノードグラフでこれを行うことができ、ビューポートで直接すばやくプレビューできます。

これについては、セッション「Explore materials in Reality Composer Pro」で詳しく知ることができます。

3Dコンテンツについて気分が良いときは、シーンをデバイスに送信し、コンテンツを直接テストすることができます。

これは、アプリを構築する必要さえないので、反復時間に最適です。

詳細については、セッション「Meet Reality Composer Pro」をご覧ください。

利用可能なもう1つのオプションはUnityです。

Unityは、使い慣れたワークフローで、プラグインを必要とせずに空間コンピューティング用のアプリを書く機能をもたらします。

既存のコンテンツを持ち込むことで、新しい没入型体験に力を与えることができます。

詳細については、Unityで没入型アプリを書く方法をカバーするこれらのセッションをご覧ください。

利用可能な基本的な概念とツールのいくつかを理解したので、アプリの構築を開始する方法を見てみましょう。

始めるには2つの方法があります。新しいアプリをゼロから空間的に設計するか、この新しい空間プラットフォームに持ち込みたい既存のアプリを持っているかのどちらかです。

新しいアプリを構築する方法を探りましょう。

アプリケーションをゼロから空間的に設計することは、空間コンピューティングの新しいユニークな機能をすばやく受け入れるのに役立ちます。

開始するには、このプラットフォームに新しいアプリテンプレートを使用できます。

アプリテンプレートには2つの新しい重要なオプションがあります。

まず、初期シーンタイプを「ウィンドウ」または「ボリューム」のいずれかに選択できます。

これにより、最初の開始コードが生成され、後で追加のシーンを簡単に追加できます。

2番目のオプションでは、没入型スペースのエントリーポイントをアプリに追加できます。

デフォルトでは、アプリは共有スペースで起動します。

「スペース」に没入型シーンタイプを選択すると、このフルスペースに起動する方法を示すサンプルボタンとともに、2番目のシーンがアプリに追加されます。

そして、アシスタントを終えると、RealityKitでレンダリングされた3Dオブジェクトと混ざったおなじみのボタンを示すSwiftUIの最初の作業アプリが表示されます。

詳細については、「最初の没入型アプリを開発する」セッションをご覧ください。

また、コードサンプルも公開しており、それぞれが異なるトピックを説明し、迅速にスピードアップします。

デスティネーションビデオは、3Dビデオと空間オーディオを組み込んだ共有された没入型再生体験を構築する方法を示しています。

ハッピービームは、カスタムハンドジェスチャーを含む没入型スペースを活用して、友達と楽しいゲームを作成する方法の例です。

そして、Hello Worldは、3Dグローブで異なるビジュアルモードを移行する方法を示しています。

クリストファーは後でハローワールドについて詳しく話します。

このプラットフォームでアプリをゼロから構築して設計することは、空間コンピューティングの概念を簡単に受け入れる機会を提供します。

しかし、空間コンピューティングに持ち込みたい既存のアプリを持っている人もいるかもしれません。

最初から、iPadとiPhoneのアプリは見た目も気分も最高です。

アプリがiPadをサポートしている場合、iPhoneのみのアプリは完全にサポートされていますが、そのバリアントはiPhoneよりも優先されます。

シミュレーターに示されているレシピアプリを見てみましょう。

このプラットフォームには独自の暗いスタイルがありますが、iPadとiPhoneのアプリはライトモードスタイルを保持しています。

Windowsは使いやすくするために拡張でき、アプリの回転が処理され、さまざまなレイアウトを見ることができます。

詳細については、「共有スペースでiPadとiPhoneのアプリを実行する」セッションを見て、システムの組み込み動作、機能の違い、シミュレータでテストする方法について学んでください。

しかし、既存のiPadやiPhoneアプリを実行することはほんの始まりに過ぎません。

クリックするだけで、このプラットフォームのXcodeプロジェクトに宛先を簡単に追加できます。

その後、ターゲットデバイスを選択し、再コンパイルして実行するだけです。

再コンパイルすると、ネイティブの間隔、サイジング、リレーアウトが得られる。

ウィンドウとマテリアルはすべて自動的にプラットフォームのルックアンドフィールに移動し、どんな光条件でも読みやすさを確保し、アプリはカスタムコントロールのハイライトなどの組み込み機能を利用することができます。

さて、クリストファーは、これまでに取り上げた概念を使用して、アプリをさらに進化させる方法を紹介します。

ありがとう、ジム。

以前に学んだ要素を組み込んだアプリケーションを構築する方法を説明します。 では、

Hello Worldから始めて、アプリに統合できる素晴らしい機能のいくつかを探りましょう。

これが動作中のサンプルです。

シミュレータでアプリを実行すると、Hello Worldは私たちの目の前にある共有スペースへのウィンドウで起動します。

これはSwiftUIで作られた使い慣れた外観のウィンドウで、テキスト、画像、ボタンなどのさまざまな要素が含まれています。

タップジェスチャーを使用すると、アプリ内のナビゲーションが可能になります。

私たちの新しいビューに3Dコンテンツがどのように埋め込まれているかを観察してください。

SwiftUIと3Dコンテンツがシームレスに連携するようになりました。

メインウィンドウに戻り、惑星地球を選択すると、新しいビューが表示されます。

新しい要素が表示されます。これはボリュームです。

これには、いくつかのUI要素とともに、地球の3Dモデルが含まれています。

ウィンドウバーを動かすことで、音量の位置は周囲のどこでも調整できます。

再びメインウィンドウに戻り、「宇宙空間を見る」を選択すると、太陽系に入るための招待状が表示されます。

ここから、「フル」のイマージョンスタイルでここに示されている空間に入ることができます。

私たちの例は、惑星地球をレンダリングし、パススルーを暗くし、周囲の気を散らすことなくコンテンツに集中することができます。

これがどのように見えるかを見たので、Hello Worldの機能のいくつかを分解し、これらの概念を独自のアプリで使用する方法を紹介しましょう。

ジムから学んだように、ウィンドウ、ボリューム、スペースなど、複数の要素があります。

これは、特定の瞬間にアプリを使用する人々にとって何が最善かに応じて、アプリが上下に曲がるために使用できるスペクトルとして見ることができます。

共有スペースに1つまたは複数のウィンドウを表示することを選択できます。

彼らはパススルーを見ることができ、他のアプリを並べて持つ選択肢があります。

または...アプリがスペースを完全に引き継ぐことで、イマージョンレベルを上げることを選択できます。

特定の瞬間にアプリの経験に最も適した要素を見つけ、それらの間で曲げることは、空間コンピューティングのためにアプリを設計する際に重要な考慮事項です。

次に、あなたの経験の一部としてWindowsを使用する方法をさらに見てみましょう。

Windowsはアプリの出発点として機能します。

それらはシーンを使用してSwiftUIで構築されており、従来のビューとコントロールが含まれています。

このプラットフォームのWindowsは、2Dコンテンツと3Dコンテンツの混合をサポートしています。

これは、3Dコンテンツを2D UIと一緒にウィンドウで表示できることを意味します。

Windowsはスペースでサイズ変更および配置を変更できます。

人々は自分の好みに合わせてそれらを配置することができます。

私たちの例に戻りましょう。

Hello Worldでは、コンテンツビューには、SwiftUIの画像、テキスト、ボタン、およびより没入感のあるコンテンツを得るための行動の呼びかけが保持されます。

ウィンドウの作成は、シーンにWindowGroupを追加するのと同じくらい簡単です。

WindowGroup内では、コンテンツビューを表示します。

当社のコンテンツビューは、3Dコンテンツを追加して、アプリに新しい次元の深さをもたらすことができます。

これを行うには、新しいModel3Dビューを使用できます。

Model3Dは画像に似ており、RealityKitによってレンダリングされたアプリに美しい3Dコンテンツを簡単にロードして表示できます。

Model3Dをビューに追加するには、衛星モデルの名前を渡してModel3Dを初期化します。

これにより、Model3Dはモデルを見つけてロードし、ビュー階層に配置します。

今、このウィンドウにはビューに衛星が埋め込まれており、z軸から出てくるのを見ることができ、アプリに新しい次元の深さを追加します。

衛星を追加したので、インタラクションを追加できます。

インタラクションは基本的にシステムに組み込まれ、SwiftUIによって提供されます。

SwiftUIは、Tap、onHover、RotateGestureなど、Appleプラットフォームですでに慣れ親しんでいるジェスチャーリコグナイザを提供します。

このプラットフォームは、3D空間での回転、3Dオブジェクトのタップなど、3Dインタラクション用に作られた新しいジェスチャーリコグナイザを提供します。

衛星との相互作用を可能にするコードを見てみましょう。

衛星をつかんで移動できるように、空間タップジェスチャーを有効にします。

Model3Dから始めて、ジェスチャーを追加できるようになりました。

内部には、衛星エンティティを対象としたDragGestureを追加します。

その後、更新クロージャから渡された値を使用して衛星を移動できます。

それがどのように見えるか見てみましょう。

衛星がレンダリングされている衛星ビューに戻ると、DragGestureを使用すると、モデルをタップしてドラッグし、インタラクションで移動できます。

先ほど見たように、2Dと3DのコンテンツをModel3Dと組み合わせるのは簡単です。

これらは窓でできることのほんの一部です。

では、別のタイプの要素、ボリュームを見てみましょう。

ボリュームが何を提供しなければならないか見てみましょう。

ボリュームはウィンドウの拡張機能であり、同様の機能を提供します。

ボリュームは、3Dコンテンツに最適な新しいスタイルのウィンドウです。

彼らはあなたの2Dまたは3Dコンテンツを含む複数のSwiftUIビューをホストすることができます。

ボリュームはフルスペースで使用できますが、実際には共有スペース用に構築されているため、コンテンツはボリュームの範囲内にとどまる必要があります。

シーンにボリュームを追加する方法を見てみましょう。

まず、新しいWindowGroupを作成し、そのwindowStyleをvolumetricに設定します。

次に、プロパティの幅、高さ、深さを含むdefaultSizeを指定する必要があります。

体積の単位は、ポイントまたはメーターで指定できます。

シミュレーターで実行されているこの実行を見てみましょう。

アプリケーションが提示されると、ボリュームは人の前に置かれます。

このボリュームには、プラットフォームコントロールとともに、指定した寸法があります。アプリケーションタイトルバーは、アプリ名を表示し、このボリュームがどのアプリに属しているかを簡単に識別できます。ウィンドウバー、ボリュームを配置できるようにします。閉じるボタンは、タップしたときにアプリを一時停止し、ボリュームを閉じます。

現在、私たちのボリュームは地球の3Dモデルをレンダリングしていますが、より多くのコンテンツと異なる動作を追加し始めることをお勧めします。

これを行うには、アプリの一部としてRealityViewを採用できます。

RealityViewは、シーンに追加できる新しいビューで、SwiftUI内で任意の数のエンティティを直接管理できます。

SwiftUIとRealityViewを使用すると、SwiftUIの管理された状態とエンティティのプロパティに接続することで、アプリを簡単に統合できます。

これにより、アプリのデータモデルからの真実のソースを使用して、3Dモデルの動作を簡単に推進できます。

座標空間間の変換は、RealityViewが提供する変換機能で簡単で、RealityViewは添付ファイルを介して3Dシーン内にSwiftUI要素を配置する方法を提供します。

少し時間を取って、RealityView内で添付ファイルを使用する方法を見てみましょう。

使用するRealityView初期化子には、makeクロージャ、更新クロージャ、添付ファイルViewBuilderの3つのパラメータが必要です。

Makeクロージャを使用すると、エンティティを作成してルートエンティティにアタッチできます。

ビューの状態が変更されるたびに呼び出される更新クロージャ。

そして最後に、添付ファイルのクロージャは、RealityViewがビューをエンティティに変換できるようにするタグプロパティでSwiftUIビューを追加する場所です。

では、RealityViewで添付ファイルを使用する方法の例を見ていきます。

添付ファイルの追加は、SwiftUIビューをRealityViewの添付ファイルクロージャーに入れるのと同じくらい簡単です。

このおいしいペストリーのアイコンを使って、3Dグローブの場所を表現しましょう。

添付ファイルごとに、添付ファイルに名前を付けるタグを追加する必要があります。

私はこれを「ピン」と名付けます。

添付ファイルを表示するには、RealityViewのコンテンツに追加します。

アップデートクロージャで、シーンのルートエンティティに追加します。

ここでは、以前に作成した添付ファイルを見ることができ、私のお気に入りのパン屋の場所の上に地球上にレンダリングされています。

先ほど見たように、RealityKitを使用すると、Model3D、RealityView、添付ファイルなどの強力な機能が解放されます。

これらはあなたのアプリに簡単に統合できます。

これは、RealityKitができることの表面を引っ掻いているだけです。

もっと知りたい場合は、「RealityKitで空間体験を構築する」と「RealityKitで空間コンピューティングアプリを強化する」を見ることをお勧めします。

これまでに経験したことを要約しましょう。

ボリュームは、2Dおよび3Dコンテンツに最適なコンテナです。

ボリュームは共有スペース用に構築され、ウィンドウと共存でき、指定された次元に制限されています。

次に、最後のタイプの要素であるスペースに飛び込みましょう。

アプリが専用のフルスペースを開くと、システムは他のすべてのアプリを非表示にし、アプリのみを表示したままにします。

これで、アプリのウィンドウ、ボリューム、コンテンツを周りのどこにでも配置できます。

ARKitとRealityKitのおかげで、仮想コンテンツは周囲と対話することさえできます。

仮想ボールを部屋に投げて、それが壁から跳ね返って床に転がるのを見ることができます。

また、ハンドトラッキングを追加して、カスタムジェスチャーやインタラクションを構築したり、人々の手に関連してコンテンツを配置したりできます。

これらの機能の多くはARKitから来ています。

より深く掘り下げ、アプリでそれらを活用する方法を学ぶには、「空間コンピューティングのためのARKitに会う」セッションを必ずチェックしてください。

スペースを使用すると、作成時にどのスタイルが選択されるかに応じて、アプリはさまざまなレベルの没入感を提供することもできます。

ジムは、フルスペースで利用可能な没入のスペクトルについて少し話しました。

飛び込んで、アプリにもっと没頭する方法についてもっと学びましょう。

イマージョンスタイルは、フルスペースで渡すことができるパラメータです。

.Mixedと.fullと呼ばれる2つの基本的なスタイルがあります。

混合スタイルは、パススルーの上にアプリのコンテンツを重ねます。

フルスタイルはパススルーを隠し、コンテンツのみを表示します。

プログレッシブを選択して、2つを組み合わせることもできます。

このスタイルは、最初はいくつかのパススルーを可能にしますが、デバイスの上部にあるデジタルクラウンを回すことで、没入のレベルを完全に変更することができます。

私たちの例に戻って、イマージョンスタイルを探りましょう。

私は混合スタイルから始めて、それがどのように見えるか見てみます。

また、Full SpaceはSwiftUIシーンなので、RealityViewを使って地球を表示できます。

これが高軌道から見た地球です...そしてこれが私のアプリでシーンを表示する方法です。

実際にイマージョンスタイルを指定していないことに注意してください。

なぜなら、没入型スペースを作成すると、SwiftUIはデフォルトで混合スタイルを想定しているからです。

また、別のイマージョンスタイルを追加して、アプリを完全に没入させましょう。

今回は、イマージョンスタイル「フル」を使用します。

ImmersiveSpaceの最後に没入型スタイルを追加するのは簡単です。

没入型スタイルを状態変数に保存し、タイプをフルに設定します。

私たちは人々に没入型体験に入るときの選択肢を与えたいので、この没入型スタイルに入るかどうかを決定できるようにボタンを追加することをお勧めします。

では、新しい没入型スタイルの動作を見てみましょう。

私たちのアプリに戻って、私はハローワールドを1つのウィンドウから完全に没頭させ、あらゆる角度から惑星地球を見ることができるようにしました。

そして、それはあなたの空間アプリでできることの始まりにすぎません。

ここからどこに行けるか見てみましょう。

このセッションでは、基本、つまり開始方法を取り上げ、アプリ構築の基本を説明しました。

空間デザインの原則について、SwiftUIとRealityKitを使用したアプリの構築について学んだり、3Dコンテンツの作成を開始したりするなど、次の目的地となる素晴らしいセッションがいくつかあります。

空間コンピューティングを使用すると、アプリの作成は、あなたの創意工夫に導かれた新しいエキサイティングな道に挑戦することができます。

見てくれてありがとう!

♪