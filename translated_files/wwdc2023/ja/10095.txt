10095

♪まろやかなインストゥルメンタルヒップホップ♪

♪

こんにちは！私はイワンで、RealityKitチームのエンジニアです。

私のセッション「空間コンピューティングのためのレンダリングを探る」へようこそ。

RealityKitは、3Dモデルをレンダリング、アニメーション化、シミュレートするためのフレームワークです。

RealityKitの最も強力なスーツの1つは、コンテンツにリアルなレンダリングを適用することです。

RealityKitのレンダリング機能を最大限に活用し、コンテンツの外観を向上させるために、空間コンピューティング用のアプリを開発する際に留意すべきいくつかのレンダリングの考慮事項を共有したいと思いました。

3Dコンテンツの照明と影から始めます。

その後、RealityKitの素材の新機能を学びます。

次に、システムのパフォーマンスを大幅に向上させるラスタライズレートマップを紹介します。

この最適化でうまく機能するようにコンテンツを調整する方法についての推奨事項を共有します。

最後に、UIが常にシャープであることを保証するダイナミックコンテンツスケーリングと呼ばれるテクニックを紹介します。

照明と影から始めましょう。

iOSとmacOSのRealityKitに精通している場合、その知識のほとんどが空間体験の構築にも当てはまることがわかります。

コンテンツをリアルに見せるために、RealityKitに画像ベースの照明を導入しました。

画像ベースの照明、またはIBLは、右側のようなテクスチャを使用して現実的な反射を生成します。

影は、オブジェクトが互いにどのように配置されているかを理解するのに役立ちます。

新機能を見る前に、画像ベースの照明のコンポーネントを簡単に見てみましょう。

IBLには2つの主要なコンポーネントがあります。ARKitによって提供され、部屋の物理的なスペースに固有の環境プローブテクスチャと、OSにパッケージ化されたシステムIBLテクスチャです。

システムIBLテクスチャは、コンテンツがどの環境でも素晴らしく見えるように、追加のハイライトを追加します。

2つのコンポーネントが一緒に追加され、組み合わせたIBLテクスチャが生成されます。

アクティブな環境がある場合は、組み合わせたIBLテクスチャにも影響します。

今年、RealityKitは、照明をカスタマイズするためにシステムIBLテクスチャをオーバーライドする機能を追加します。

例を見てみましょう。 例を見てみましょう。

これは、太陽系の眺めを提供する「ハローワールド」体験です。

デフォルトでは、RealityKitはシステムIBLを使用して点灯します。

ただし、新しい画像ベースの光コンポーネントに新しいIBLを割り当てると、システムIBLを置き換え、周囲の没入型環境を使用してそれらのオブジェクトを照らします。

それがどのように行われるかをお見せしましょう。

ここでは、まず3Dコンテンツをロードします。

この場合、それは衛星モデルです。

次に、Sunlightという環境リソースをロードします。

地球を取り囲む太陽と星の画像が含まれています。

IBLを設定するにはモデルと環境リソースの両方が必要なので、両方のロード操作が終了したことを確認しましょう。

次に、ImageBasedLightComponentを追加します。

ロードしたばかりの環境リソースを参照しています。

最後に、ImageBasedLightReceiverComponentを衛星エンティティに追加します。

これらのレシーバーコンポーネントを他のエンティティに追加して、同じIBLを使用して点灯させることができます。

そして、RealityKitで照明をカスタマイズするのはとても簡単です。

次に、アプリケーションに影を追加する方法を見てみましょう。 影を追加します。

この花瓶のような3Dオブジェクトを浮遊面の上に置く簡単な例を考えてみましょう。

影がオンになっていないと、花瓶と飛行機の相対的な位置を理解するのは難しいかもしれません。

しかし、RealityKitの接地影を追加するだけで、花瓶が飛行機の中心の上にあることがはるかに明確になります。

コードでこれを行う方法を見てみましょう。

花瓶モデルをロードすることから始めます。

ここでは、flower_tulipは私たちのプロジェクトの3Dモデルの名前です。

次に、グラウンディングシャドウコンポーネントを追加します。

castsShadowフラグをtrueに設定してください。

そして、それだけです!

花瓶の実体は今、接地影を投げかけます。

シンプルですね。

グラウンディングシャドウは、物理環境のオブジェクトだけでなく、3Dモデルの上に表示されます。

カスタムIBLを使用してシーンを照らし、グラウンディングシャドウを含めると、コンテンツをはるかに良く見せることができますが、素材を微調整することでオブジェクトの外観に直接取り組むこともできます。

macOSとiOSで利用可能なRealityKitの素材のほとんどは、xrOSでも使用できます。

それらをすぐに見直しましょう。

最も一般的に使用される材料はPhysicallyBasedMaterialです。

RealityKitのPhysicallyBasedMaterialは照明に反応し、プラスチックや金属などのさまざまな現実世界の材料を表現するために使用できます。

SimpleMaterialは照明にも反応しますが、パラメータの小さなサブセットを使用します。

素早い実験には特に適しています。

UnlitMaterialは照明に反応しません。

言い換えれば、それは変化する照明条件の下で一定の外観を維持します。

VideoMaterialは、ムービーファイルをエンティティの表面にマッピングできる点灯されていない素材のバリエーションです。

これらの素材に加えて、RealityKitはShaderGraphMaterialと呼ばれる新しいタイプの素材を導入しています。

Reality Composer Proで新しいShaderGraphMaterialを作成するか、MaterialXファイルから読み込むことができます。

ShaderGraphMaterialの詳細については、「Explore Materials in Reality Composer Pro」をご覧ください。

これらすべての材料の色出力は、トーンマッピングと呼ばれる特別なステップを経ます。

トーンマッピングは、RealityKitが素材の色出力にデフォルトで適用する変換です。

さまざまな技術を使用して、より自然な知覚色を可能にします。

そのようなテクニックの1つは、1より上の値を可視範囲に再マッピングすることです。

例を挙げて実演しましょう。

これは、トーンマッピングが無効になっているテレビの3Dレンダリングです。

非常に明るい値のテクスチャをディスプレイに割り当てました。

さて、トーンマッピングを有効にすると、これらの花びらのような明るい領域で詳細を見ることができます。

トーンマッピングは一般的にうまく機能し、美しいビジュアルをレンダリングします。しかし、いくつかのユースケースでは、トーンマッピングをオプトアウトする必要があるオブジェクトの正確な色を表示したい場合があります。

例を見てみましょう。 例を見てみましょう。

これは、信号機と「Stop」、「Wait」、「Go」というラベルが付いた3つのボタンを示すシンプルなアプリケーションです。

信号機自体は3Dモデルで、3つのボタンはSwiftUIを使用して追加されました。

ランプの色とボタンの色を正確に一致させるために、点灯していない材料は、照明条件に関係なく、オブジェクトの同じ一定の外観を維持するため、ランプに点灯していない材料を使用することができます。

ただし、点灯されていない素材の出力は、すべてのRealityKit素材でデフォルトでオンになっているトーンマッピングの影響を受けます。

したがって、SwiftUIボタンとランプの素材に同じ色が割り当てられていても、それらは互いにわずかに異なって見えるかもしれません。

あなたが見るスクリーンショットは、トーンマッピングが有効になっている状態で撮影されました。ランプ素材のトーンマッピングが無効になっているときの様子をお見せしましょう。

ランプとボタンの色が正確に一致していることに気付くでしょう。

ランプ素材のトーンマッピングをもう一度切り替えましょう。

これはトーンマッピングが有効になっており、これはトーンマッピングが無効になっている場合です。

トーンマッピングをコードで切り替える方法を示すコードサンプルを見てみましょう。

信号機モデルをロードすることから始めます。

ここでは、traffic_lightは私たちのプロジェクトの3Dモデルの名前です。

次に、red_lightという名前のエンティティを見つけます。

このエンティティは、信号機の上部ランプに対応しています。

エンティティを取得したら、そのモデルコンポーネントにアクセスします。

次に、新しい照明のない素材を作成します。

目的の色とapplyPostProcessToneMapと呼ばれる新しいブールパラメータの両方を渡します。

このブールパラメータは、このマテリアルのトーンマッピング変換を無効にするためにfalseに設定されています。

最後に、モデルコンポーネントの材料を交換し、モデルコンポーネントをエンティティに割り当てます。

これは3つのランプのそれぞれに対して行われます。

これで、ボタンの色とランプの色が密接に一致するはずです。

applyPostProcessToneMapフラグは、シーンの色の正確な表現を表示したい場合に便利です。

これは、RealityKitを使用してメニューやヘッドアップディスプレイのようなものを構築するときに便利です。

この新しいプロパティは、Reality Composer Proのマテリアルエディタでも公開されています。

さて、いくつかの品質に関する考慮事項を見てみましょう。

空間コンピューティングのラスタライズレートマップから始めます。

ヘッドセットで使用されるディスプレイは高解像度で、OSはこれらのディスプレイを1秒間に何度も更新する必要があります。

これを視覚的に説明させてください。

すでにご存知かもしれませんが、ヘッドセットは人の目がどこを見ているかを正確に検出する能力を持っています。

これは、人が目を右に動かしてから中央に戻るシミュレートされたシナリオです。

黄色の円は、その人の焦点の中心点を表しています。

その点を囲む領域は輝きで強調され、周辺は暗くなります。

ラスタライズレートマップにより、暗くなった領域で実行される計算が少なくなります。

いつでも、ハイライトされた領域が周辺領域と比較して小さいことがわかります。

これにより、システムはメモリとパフォーマンスを大幅に節約できます。

RealityKitでは、この最適化が自動的に有効になります。

システムのパフォーマンスが大幅に向上しますが、状況によっては、この最適化でうまく機能するようにコンテンツを調整する必要があるかもしれません。

たとえば、ここにヤシの葉の資産があります。画面の中央に置くと、シャープで詳細に見えます。

しかし、オブジェクトを左に動かし、再び目の動きのシミュレーションを適用すると、ヤシの葉のちらつきを観察することができます。

目の方向を表す黄色の円が画面の右端に近い場合、ちらつきは特に強いです。

ちらつきは、ラスタライズレートマップが人が見ているポイントの周りのより高いディテールを可能にし、目がそこから遠ざかるにつれてヤシの葉の周りのピクセルがより低いディテールでレンダリングされるために起こります。

これで、コンテンツのいくつかのパラメータを調整するだけで、ちらつきを減らすことができます。

これを見てみましょう。 見ていきましょう。

これは、上部に赤いワイヤーフレームオーバーレイが付いた同じヤシの葉の資産の表現です。

ここには小さな三角形がたくさんあることがわかります。それはたくさんの小さな三角形があります。

これらの小さな三角形は、周辺でちらつく理由でした。

三角形を大きくし、細かいディテールを不透明度のテクスチャに保存するだけで、ちらつきを減らすことができます。

資産を調整した後のシミュレーションの様子は次のとおりです。

RealityKitは、アセットがロードされたときに不透明度マップの低解像度バージョンを自動的に生成するため、この3Dモデルは調整後に見栄えが良くなります。

これらの低解像度バージョンのテクスチャはミップマップと呼ばれ、低詳細領域の外観を改善するためにGPUによって自動的に使用されます。

ラスタライズレートマップの詳細については、記事「異なるラスタライズレートでのレンダリング」を参照してください。

ラスタライズレートマップと同様に、SwiftUIを使用して作成されたコンテンツの外観を自動的に改善する「動的コンテンツスケーリング」と呼ばれる別の手法があります。

見てみましょう。 

これは、グリッドに配置された月のリストを表示するアプリケーションです。

毎月はテキストラベルで表されます。

目が6月を見ると、システムはその領域のテキストを最高レベルの詳細でラスタライズします。

「6月」を囲む青でマークされた領域は、わずかに縮小された詳細レベルでラスタライズされますが、それでも全体的に高品質を維持します。

しかし、紫色でマークされた領域は、人間の視覚システムが周辺でより少ない詳細を知覚し、それほど目立たないため、はるかに低い詳細レベルでラスタライズされています。

目が見ているものに基づいて、さまざまなレベルの詳細でこの種のラスタライズは、「動的コンテンツスケーリング」と呼ばれます。

このシステムは、UIコンテンツを適切なスケールで描画するために動的コンテンツスケーリングに依存し、常にシャープであることを保証します。

動的コンテンツスケーリングは、ラスタライズされたコンテンツのメモリの相対サイズに影響します。

言い換えれば、私たちのテキストラベルは、目が見ているポイントにどれだけ近いかに応じて、異なるサイズに拡大縮小されます。

たとえば、「6月」と書かれたラベルが最大であることがわかります - それは最も解像度と詳細を持っています。

次に、1月、2月、3月などの8ヶ月のグループがあり、詳細がわずかに少ないです。

最後に、目から見る方向から最も遠い4月、8月、12月の3ヶ月のグループがあります。

その最後のグループは、メモリ内のより小さな画像で表されます。

では、動的コンテンツスケーリングを有効にする方法を理解しましょう。

UIKitとSwiftUIを使用している場合、アプリケーションは自動的にこのテクニックの恩恵を受けます。

UIを構築するためにCore Animationフレームワークに依存している場合は、動的コンテンツのスケーリングを可能にする新しいAPIがあります。

このAPIを見てみましょう。 では、このAPIを見てみましょう。

動的コンテンツスケーリングは、CALayer wantsDynamicContentScalingのプロパティをtrueに設定することで有効にできます。

この手法は、より高い解像度でのラスタライズに依存しているため、主にビットマップベースのコンテンツで使用することはお勧めできません。

動的コンテンツのスケーリングに関する推奨事項の完全なリストは、developer.apple.comで見つけることができます。

私たちが学んだことをすべてまとめさせてください。

私たちは、RealityKitアプリケーションに画像ベースのライトと接地影を追加する方法を検討することから始めました。

次に、新しいShaderGraphMaterialなど、空間体験に利用できる資料をレビューしました。

また、照明されていない素材のトーンマッピングを制御する方法も学びました。

次に、周辺でのちらつきを減らすために3Dモデルを調整する方法の例など、ラスタライズレートマップが空間コンピューティングにどのように使用されるかを学びました。

最後に、動的コンテンツスケーリングがシステムでどのように機能し、それをどのように活用できるかを学びました。

私たちは今年のリリースに非常に興奮しており、xrOSで構築する美しい空間体験を見るのが待ちきれません。

ありがとうございます。