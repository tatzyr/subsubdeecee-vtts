10081

♪まろやかなインストゥルメンタルヒップホップ♪

♪

こんにちは、私の名前はユジンで、RealityKitチームのエンジニアです。

今日は、空間コンピューティングアプリを強化するために使用できるRealityKitの新機能を紹介します。

2019年にRealityKitをリリースして以来、アプリが豊富な機能セットを使用して素晴らしい体験を生み出すのを見てきました。

現在、空間コンピューティングは、ポータル、パーティクルエミッタ、RealityViewアタッチメントなど、RealityKitにさらに多くの機能を追加します。

「RealityKitで空間体験を構築する」と題されたセッションでは、RealityKitの基本的な構成要素について学びました。コンテナオブジェクトであるエンティティ、エンティティの特定の動作を定義するコンポーネント、エンティティとコンポーネントの両方に作用して機能を追加するシステムです。

SwiftUIとRealityKitの架け橋として機能するRealityView APIを取り上げました。

また、RealityKitシーンにインタラクション、アニメーション、空間オーディオを追加する方法も示しました。

まだ見ていない場合は、そのセッションをチェックすることを強くお勧めします。

このセッションでは、アプリをさらに魅力的で没入感のあるものにするのに役立つRealityKitの新機能について説明します。

まず、RealityViewの添付ファイルを使用して、SwiftUIビューをRealityKitコンテンツに埋め込む方法を学びます。

次に、RealityKitシーン内でビデオ再生を追加する方法を見ていきます。

次に、ポータルを使用して代替世界への窓を開く方法を学びます。

パーティクルエミッターAPIを使用して、視覚効果でシーンを強化する方法について説明します。

最後に、RealityKitのアンカーを使用して、壁などの現実世界の場所に3Dコンテンツを添付する方法を学びます。

RealityViewの添付ファイルから始めましょう。

添付ファイルは、SwiftUIコンテンツをRealityKitシーンに埋め込むのに便利な方法です。

このサンプルアプリでは、添付ファイルを使用して、地球と月のモデルの下にテキストラベルを付けました。

また、月が私たちの海の潮汐にどのように影響するかを説明する見解を添付しました。

これをコードで作る方法を見てみましょう。

アプリ内では、RealityViewを使って地球モデルをレンダリングしています。

RealityViewは、RealityKitエンティティを追加できるビューです。

レンダリング、アニメーション化、シミュレートするには、エンティティをRealityViewに追加する必要があります。

ここでは、地球のエンティティをロードし、RealityViewのコンテンツに追加するだけです。

それでは、添付ファイルを使用するようにRealityViewを変更しましょう。

添付ファイルは、RealityKitコンテンツに関連する特定の場所に配置できるビューです。

添付ファイルの設定には2つの部分があります。

まず、RealityViewのmakeクロージャに追加されたパラメータがあります。

次に、RealityViewに追加された添付ファイルビュービルダーがあります。

最初に添付ファイルビュービルダーをカバーしましょう。

ここでは、RealityKitコンテンツに追加したいSwiftUIビューを提供できます。

この例では、地球にラベルを付けるためのテキストビューを追加しました。

また、ビューがエンティティとしてmakeクロージャに配信されたときに後で識別できるように、ビューにタグ修飾子を追加します。

このタグは任意のハッシュ可能な値にすることができます。

ここでは、文字列earth_labelを使用しました。

RealityViewのmakeクロージャでは、添付ファイルパラメータには、エンティティとして表現されるビューが含まれています。

ビューをエンティティ形式で取得するには、添付ファイルでエンティティ(for:)を呼び出し、ビュービルダーのearth_labelで提供したのと同じタグを渡します。

その結果、他のエンティティと同様に、RealityKitコンテンツに追加できるビューアタッチメントエンティティが得られます。

ラベルを地球の下に表示するために、添付ファイルを地球エンティティの子として追加し、少し下に配置します。

それぞれに異なるタグを使用して追加したい他のすべての添付ファイルに対してこのプロセスを繰り返すことができます。

Xcodeで見てみましょう。 では見てみましょう。

サンプルアプリでは、RealityViewに3つの添付ファイルを追加します。

まず、地球の下にラベルを追加します。

私も月のために同じことをします。

最後に、潮汐における月の軌道の役割を説明する短い段落を追加します。 

SwiftUIのglassBackgroundEffectを使ってこれをスタイリングしました。

RealityViewを閉じる際に、対応するエンティティをコンテンツに追加します。

まず、地球の下にアースアタッチメントを追加します。

私は月のために同じことをします。

最後に、コンテナエンティティの左側に潮汐説明器を配置します。

アプリをビルドして実行すると、作成した添付ファイルがモデルの横に表示されます。

添付ファイルのデータフローをまとめましょう。

添付ファイルは、RealityViewの添付ファイルビュービルダーから始まります。

ここでは、RealityKitシーンに追加したいSwiftUIビューを提供できます。

RealityViewのmakeクロージャでは、添付ファイルをエンティティとして戻し、それをシーンに追加できます。

また、更新クロージャ内のエンティティを更新することもできます。

このクロージャは、SwiftUIビューの状態に変更があったときに呼び出されます。

これを使用して、RealityViewで動的に変化するコンテンツに対応できます。

添付ファイルのより詳細な使用方法については、「XcodeでReality Composer Proのコンテンツを使用する」セッションをチェックしてください。

RealityViewの添付ファイルは、他のUI要素のテキストコンテンツをシーンに追加する便利な方法です。

さらに、アプリにビデオを追加して、より魅力的にすることもできます。

これを行うには、VideoPlayerComponentを使用しましょう。

ビデオプレーヤーコンポーネントは、3Dシーン内にビデオコンテンツを埋め込むために使用されるRealityKitの新しいコンポーネントタイプです。

リマインダーとして、コンポーネントはエンティティにアタッチできる特定の動作を定義します。

VideoPlayerComponentを使用してビデオを再生するには、まずリソースバンドルからビデオファイルをロードします。

次に、それを使用してAVPlayerインスタンスを作成します。

これで、VideoPlayerComponentを作成できるようになりました。

VideoPlayerComponentをエンティティにアタッチすると、ビデオのアスペクト比に一致する長方形のメッシュが自動的に生成されます。

この動作は、SwiftUIのVideoPlayerやCore AnimationのAVPlayerLayerなど、既存のビデオプレーヤーAPIに似ています。

ただし、RealityKitは3Dフレームワークであるため、ビデオはメッシュを持つエンティティとして表現されるため、3D空間に移動して配置できます。

AV Foundationでサポートされているすべてのビデオフォーマットは、2DビデオフォーマットやMV-HEVCを使用した3Dビデオなど、VideoPlayerComponentで動作します。

最後に、VideoPlayerComponentは、AVPlayerを通じて提供されるキャプションを自動的に表示します。

3Dビデオを含む独自のビデオコンテンツを作成する方法の詳細については、「空間体験のためのビデオコンテンツを提供する」というタイトルのセッションをチェックしてください。

RealityKitシーンにビデオを追加するには、まずビデオアセットのURLを使用してAVPlayerItemを作成します。

次に、AVPlayerを作成します。

エンティティでは、作成したばかりのAVPlayerで初期化されたVideoPlayerComponentを追加します。

VideoPlayerComponentは、私のビデオのアスペクト比に基づいてサイズのメッシュを自動的に生成します。

RealityKitは現実世界のユニットで動作するため、デフォルトでは、ビデオの高さは1メートルになります。

ビデオを別のサイズにするには、エンティティをスケーリングできます。

私の場合、ビデオの高さを40センチにしたいので、エンティティスケールに0.4を掛けます。

最後に、ビデオを再生する準備が整いました。

現在のアイテムをAVPlayerItemに設定し、AVPlayerでプレイを呼び出します。

このコードでアプリを再構築して実行しましょう。

アプリに「詳細」ボタンを追加しました。これにより、ビデオエンティティがシーンに追加されます。

ボタンをクリックすると、不透明度コンポーネントとfromToByAnimationを使用してビデオをフェードインします。

私たちのビデオコンテンツのために、私は地球の上昇潮に対する月の重力の役割を説明する短いクリップを用意しました。

見てみましょう。 

月は私たちの惑星を周回します。

その重力は、私たちの海に強力な力を及ぼし、月の球体に向かってわずかに膨らみます。< VideoPlayerComponentは、キャプションのシステム全体の設定を尊重します。

アクセシビリティセクションの下にある設定アプリでそれらをオンにしましょう。

そして、1日2回、終わりのないサイクルで、地球と月のこの絶え間ない相互作用によって、潮が上がったり下がったりします。< VideoPlayerComponentは、パススルー着色もサポートしています。

この機能を有効にすると、パススルーコンテンツはビデオの色に合わせて調整されます。

これは、このプラットフォームのテレビアプリ内で映画やテレビ番組を見るときに使用されるのと同じ治療法です。

パススルーティンティングを使用するには、isPassthroughTintingEnabledプロパティをtrueに設定できます。

また、VideoPlayerEventsを購読して、コンテンツタイプ、表示モード、ビデオサイズなど、VideoPlayerComponentのプロパティが変更されたときに通知を受け取ることもできます。

イベントを購読するには、RealityViewsコンテンツの購読機能を呼び出し、イベントの種類とエンティティを指定できます。

イベントハンドラクロージャ内のイベントに応答できます。

VideoPlayerComponentは、私たちの3Dシーンへの素晴らしい追加です。

これまでのところ、私たちのアプリは地球と月のモデルを備えていますが、宇宙を背景に提示したいと思います。

宇宙空間で月の軌道を明らかにする部屋に魔法の窓を作ることができれば、かなりクールだと思います。

ポータルを使用してシーンをレンダリングできます。

ポータルは、メッシュサーフェスを通して見える別の世界への開口部を作成します。

この世界内のエンティティは別々の照明を使用し、ポータルのジオメトリによってマスクされています。

この例は、RealityKitの3つの異なる機能を示しています。

まず、ポータルは宇宙空間でシーンをレンダリングするために使用されます。

次に、パーティクル効果を使用してポータルの縁を飾ります。

最後に、アンカーは、私たちの部屋の壁にポータルを配置するために使用されます。

ポータルから始めましょう。

ポータルを作るには、まず世界を作らなければならない。

これを行うには、Worldコンポーネントを持つエンティティをシーンに追加します。

このコンポーネントは、そのエンティティツリーを別の世界に属しているとマークします。

世界のエンティティは、ポータルサーフェスを介してのみ表示されます。

私たちの世界にコンテンツを追加するには、世界のエンティティの子としてエンティティを添付することができます。

ここでは、空、地球、月のモデルと、世界内部の照明を定義するImageBasedLightを追加します。

世界の実体のすべての子孫は、この世界の中にのみ現れます。

次に、ポータルを作ります。

これを行うには、モデルコンポーネントを持つエンティティを追加します。

モデルコンポーネントには、メッシュと材料の2つのプロパティが含まれています。

メッシュの場合、ポータルの表面として機能する円形の平面を生成します。

素材については、メッシュをポータルとして表示するために、新しいポータル素材を割り当てます。

ポータルを世界と接続するには、エンティティにポータルコンポーネントを追加し、そのターゲットプロパティを世界のエンティティに設定します。

これにより、ポータルは私たちの世界の中のコンテンツを明らかにするためのマスクとして機能することができます。

これがコードでどのように見えるか見てみましょう。

RealityViewでは、makeWorldとmakePortalを実装する2つの関数に呼び出しを追加しました。

makeWorld機能では、ワールドエンティティを作成し、ポータルのコンテンツを入力します。

makePortal関数では、ポータルを作成し、作成したばかりの世界にリンクします。

最後に、これらのエンティティの両方をRealityViewのコンテンツに追加します。

これらの各機能について掘り下げてみましょう。

makeWorld関数内で、エンティティを作成し、WorldComponentを添付します。

次に、ImageBasedLightとして使用するEnvironmentResourceをロードします。

ImageBasedLightコンポーネントとImageBasedLight ReceiverComponentを使用して、これを世界に適用します。

RealityKitの画像ベースの照明の詳細については、セッション「空間コンピューティングのためのレンダリングを探る」をチェックしてください。

次に、私たちのコンテンツを世界に埋めます。

地球、月、空のモデルをロードし、子供の頃に世界に追加します。

これらのエンティティは世界の子供であるため、ポータルを通じてのみ表示されます。

makePortal関数に移りましょう。

ポータルを作るには、まずメッシュが必要です。

エンティティのモデルコンポーネントを作成して作成します。

ポータルを円形にするために、同じ寸法と半分の大きさのコーナー半径を持つ平面を生成します。

また、ModelComponentの素材として使用するPortalMaterialも作成します。

最後に、以前に作成したワールドエンティティで初期化されたポータルコンポーネントも添付します。

これにより、ポータルと世界がリンクされるため、メッシュを通して世界のコンテンツを見ることができます。

次に、ポータルの縁を粒子効果で飾りましょう。

これを行うには、RealityKitで提供されているParticleEmitterComponentを使用できます。

粒子エミッタは、火花、雪、インパクト効果など、RealityKitのさまざまな視覚効果を表すために使用できます。

パーティクルエミッタは、Reality Composer Proを介して、またはParticleEmitterComponentを介してRealityKitを使用して実行時に作成できます。ここでは、Reality Composer Proを使用してパーティクルアセットを準備しました。

これを使用して、以前に作成したポータルを飾ることができます。

これをシーンにロードし、RealityKitを使用して実行時にパーティクルプロパティを変更しましょう。

時間の経過とともにパーティクルを更新するために、ParticleTransitionSystemというカスタムシステムを作成しました。

ここでは、EntityQueryを使用して、ParticleEmitterComponentを持つエンティティを検索します。

システムアップデート内では、クエリを実行し、結果のエンティティを反復します。

各エンティティで、次に実装する関数updateParticlesを呼び出します。

RealityKitのカスタムシステムの詳細については、「RealityKitで空間体験を構築する」セッションをご覧ください。

updateParticles関数内では、まずエンティティからParticleEmitterComponentを取得します。

ParticleEmitterComponentには、粒子の外観と挙動のさまざまな側面を制御する多くの特性が含まれています。

ここでは、エンティティのスケールに基づいてlifeSpanとvortexStrengthプロパティを設定し、エンティティのサイズが大きくなるにつれて、パーティクルがポータルの周りをより速く回転し始めます。

最後に、コンポーネントをエンティティに割り当てて変更を適用しましょう。

そして、私たちは準備万端です。

パーティクルエミッタのすべての異なる特性について学ぶには、セッション「Meet Reality Composer Pro」をチェックしてください。

アプリに最後の仕上げを追加するのはほぼ終わりました。

最後に、ポータルを部屋の壁に取り付けましょう。

これを行うには、RealityKitでアンカーを使用できます。

アンカーは、壁、床、または頭や手に関連する場所にコンテンツを配置するために使用できます。

RealityKitのアンカーは、.continuousと.onceの2つのトラッキングモードをサポートしています。

連続追跡モードを使用する場合、アンカーエンティティは、頭が動くときなど、時間の経過とともにアンカーと一緒に移動します。

一度追跡モードを使用する場合、アンカーエンティティは一度配置された後は移動しません。

エンティティがアンカーになったときに聞くには、RealityKitでAnchoredStateChangedイベントを購読できます。

親エンティティにアンカーを使用して3Dコンテンツを配置できますが、アンカー自体の明示的な変換は、ユーザーのプライバシーを保護するためにアプリには表示されないことに注意してください。

アンカー変換にアクセスするには、ARKitを使用する必要があります。

これの詳細については、「空間コンピューティングのためのARKitに会う」というセッションをチェックしてください。

アプリでアンカーを使用するには、まず没入型スペースを使用するようにアプリを変更する必要があります。

没入型スペースは、アプリがウィンドウの外でコンテンツをレンダリングできる特別なタイプのコンテナです。

これを行うには、SwiftUIシーンにImmersiveSpaceを追加できます。

また、.immersionStyle修飾子を追加し、混合に設定します。

ImmersiveSpace内では、RealityViewを使用して、アンカーされるコンテンツを配置できます。

Immersive Spacesの詳細については、「SwiftUIでウィンドウを越える」セッションをチェックしてください。

RealityView内では、アンカーエンティティをポータルのコンテナとして使用できます。

コンテンツをアンカーしたいサーフェスのタイプの仕様でアンカーエンティティを初期化します。

私たちの場合、最小サイズが1メートル×1メートルの垂直壁を探しています。

仕様に一致するアンカーが見つかった場合、RealityKitは自動的にコンテンツを壁に貼り付けます。

そして、私たちはついに終わりました。

アプリを実行すると、壁に取り付けられたポータルを取得します。

ポータルやパーティクルからアンカーやアタッチメントまで、RealityKitは没入型体験を構築できる多くの機能を提供します。

このセッションで取りまとめたことをすべてまとめましょう。

RealityViewの添付ファイルを使用すると、SwiftUIコンテンツをエンティティ階層内に埋め込むことができ、UI要素を3D要素と一緒に配置できます。

VideoPlayerComponent、ポータル、パーティクルエフェクトを使用すると、RealityKitでシーンを強化するために動的要素を追加できます。

最後に、アンカーを使用すると、床や壁などの現実世界の表面に3Dコンテンツを取り付けることができます。

セッション「RealityKitで空間体験を構築する」では、エンティティ、コンポーネント、RealityViewなどの重要な概念について説明しています。

セッション「XcodeでReality Composer Proコンテンツを扱う」では、Reality Composer ProとRealityKitを使用して没入型アプリを構築するプロセスを説明します。

RealityKitでこれらの新機能を使って作成するすべてのものを見るのが待ちきれません。

ご覧いただきありがとうございます。

♪