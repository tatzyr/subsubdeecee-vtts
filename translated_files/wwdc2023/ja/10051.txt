10051

♪ ♪

David: こんにちは、ShazamKitチームのエンジニア、David Ilenwaborです。

ShazamKitは、アプリに音声認識をもたらすことができるフレームワークです。

Shazamの膨大な音楽カタログとオーディオを照合したり、カスタムカタログを使用して独自の録音済みオーディオと照合したりできます。

2022年には、ShazamKitにいくつかの素晴らしいアップデートがあり、カスタムカタログでの作業が大規模に改善されました。

カスタムカタログを使用するときに重いワークフローを処理するためのShazam CLI、より良い同期のための時間制限されたメディアアイテム、およびオーディオの2つの同様のサウンドビットを区別するための周波数スキューイングが導入されました。

これらの仕組みにまだ慣れていない場合は、ShazamKitビデオでカスタムカタログを大規模に作成してください。

しかし、簡単な概要を説明するために、ShazamKitでは、オーディオをシグネチャと呼ばれる特別な形式に変換してマッチを実行できます。

オーディオバッファのストリームまたはシグネチャデータをShazamKitセッションに渡すことができます。

その後、セッションは署名を使用して、Shazamカタログまたはカスタムカタログで一致するものを見つけます。

一致がある場合、セッションは一致のメタデータを表すメディアアイテムを持つ一致オブジェクトを返します。

その後、アプリにメディアアイテムを表示できます。

ShazamKitは、オーディオバッファのストリームから署名を生成するか、ディスクに保存できる署名ファイルを使用して、一致を実行できます。

署名は不可逆的であるため、署名から元の記録を再構築することはできません。

これにより、お客様のプライバシーが保護されます。

カタログは、関連するメディアアイテムを持つ署名のグループであり、クエリ署名がカタログ内の参照署名の一部と十分に一致する場合に一致が発生します。

レストランで音楽が再生されるなど、クエリ署名が騒々しい場合でも、一致が発生する可能性があります。

それをカバーしたので、今年はShazamKitのエキサイティングな新しいアップデートに移ります。

このセッションでは、ShazamKitでオーディオを認識するための新しい変更を行い、エキサイティングな新機能で再定義されたShazam Library APIについて説明します。

最後に、ShazamKitでより良いアプリ体験を作成するためのベストプラクティスをいくつかお行します。

始める前に、開発者ポータルで添付のサンプルコードプロジェクトをダウンロードすることをお勧めします。

私はこのビデオを通してこのプロジェクトを利用します。

カバーすることがたくさんあるので、始めます。

まず、音声認識。

ShazamKitを使用してマイクからの音声を認識するプロセスは、次の手順で要約できます。

まず、ユーザーにマイクの許可を求めます。

次に、許可が付与された後に録画を開始します。

次に、録音されたオーディオバッファをShazamKitに渡し、最後に結果を処理します。

これを実証するために、サンプルプロジェクトで見つけることができるデモアプリを構築しました。

私はダンスが大好きで、最新のトレンドに追いつくために、曲にトレンドのダンスの動きを発見するのに役立つアプリを構築しました。

このアプリは、マイクを使ってオーディオを聴くことで動作し、ダンスビデオを見つけるために進みます。

例えば、Siriに曲を探すのを手伝ってもらうことができます。

ねえ、Siri、デュークスの「Push It」をプレイして。

Siri: デュークスの「Push It」を再生中。

David: その後、Learn The Danceボタンをタップして録音を開始できます。

♪ ♪

ShazamKitは曲を認識し、アプリはそれに合わせて適切なダンスビデオを検索します。

私は1つ手に入れたようです。うーん！

私の双子のダンシングデイブは私にいくつかの動きを見せているようです。

これはエキサイティングに見えます。

では、これはどのように実装されましたか?

コードを案内させてください。

ここでは、サンプルプロジェクトをXcodeで開きました。

マイクへのアクセスを要求するために使用されるinfo.plistファイルにマイクの使用状況の説明を追加しました。

私はまた、ホーム画面とダンスビデオ画面のためのSwiftUIビューのホストを持っています。

しかし、このマッチャークラスは、音声認識のすべての魔法が起こる場所です。

初期化時に、オーディオエンジンを設定して設定する方法があります。

この方法では、タップをインストールしてPCMbuffersを受信し、オーディオエンジンを準備します。

また、「ダンスを学ぶ」ボタンをタップしたときに呼び出されるマッチメソッドがあります。

録音許可を要求し、これが許可された場合は、オーディオエンジンのスタートを呼び出すと録音を開始します。

次に、UIマッチングが開始されたことを伝え、session.resultsを呼び出し、マッチ結果の非同期シーケンスを待ちます。

結果を受け取った後、一致する場合は一致オブジェクトを設定し、不一致とエラーのケースを処理します。

このクラスには、オーディオエンジンを停止するstopRecording機能もあります。

これはうまくいきますが、オーディオバッファを受信する前に、オーディオエンジンを設定するためのセットアップコードがたくさんあることに注意してください。

特にオーディオプログラミングに精通していない場合は、これを正しく理解するのは難しいかもしれません。

そして、記録とマッチングを容易にするために、SHManagedSessionと呼ばれる新しいAPIを導入しました。

マネージドセッションは、オーディオバッファを設定する手間をかけずに、自動的に録音を開始します。

これにより、セットアップと使用が非常に簡単になります。

マネージドセッションを使用するには、マイクの許可が必要です。

この許可がなければ、セッションは録画を開始できません。

したがって、アプリのinfo.plistファイルにマイクの使用状況の説明エントリを追加することが重要です。

マネージドセッションは、ユーザーからマイクへのアクセスを求めるときに、この説明を使用します。

では、このAPIをコードで使用するにはどうすればよいですか?

まず、SHManagedSessionのインスタンスを作成し、結果メソッドを呼び出すことで結果を待つことができます。

このメソッドは、一致、NoMatch、またはエラーのいずれかである3つの状態を持つ列挙型を返します。

次に、一致の場合に返されたメディアアイテムを使用して結果を切り替え、不一致とエラーのケースを処理できます。

そして、時間の経過とともに多くの結果を返すことができる、より長い録音セッションをしたい場合はどうなりますか?

さて、managedSessionのasyncシーケンス結果プロパティを使用することでこれを行うことができます。

以前と同じように、シーケンスから受信した各結果を使用できます。

これにより、長時間オーディオを録音し続けることができます。

最後に、managedSessionでキャンセルを呼び出すことで、マッチングを停止できます。

これにより、現在実行中のマッチ試行がキャンセルされ、録画が停止されます。

そして、それだけです。

マネージドセッションでは、記録を開始し、照合後に結果を受け取るのはほんの数行のコードです。

アプリに戻って、ManagedSessionを使用するようにMatcherの実装を更新します。

SHSessionのすべてのインスタンスをSHManagedSessionに置き換えることができます。

その後、オーディオエンジンの設定方法とその使用法を削除できます。

そして、マッチメソッドでは、録音許可を要求し、オーディオエンジンを起動するために呼び出しを削除することができます。

最後に、stopRecordingメソッドでは、オーディオエンジンを停止するための既存のコードを、managedSessionのキャンセルメソッドを呼び出すだけで置き換えることができます。

次に、アプリを実行して、すべてが期待どおりに機能していることを確認します。

ねえ、Siri、デュークスの「Push It」をプレイして。

Siri:これはデュークスの「Push It」です。

♪ ♪

エキサイティング！

すべてが正常に動作していますが、今回はマネージドセッションでコードがさらに良く、クリーンになります。

それだけですか？

マネージドセッションについて話すことはさらにたくさんあります。

ユースケースによっては、ManagedSessionが事前に試合の試みに備えることをお勧めします。

マネージドセッションを準備すると、マッチング時にセッションの応答性が向上します。

また、試合に必要なリソースを事前に割り当て、試合の試みを見越して事前記録を開始します。

準備を使用する利点のアイデアを与えるために、ここに準備を呼び出すことなくセッションの動作を表すタイムラインがあります。

結果を求めると、セッションは一致試行のリソースを割り当て、記録を開始し、最後に一致を返します。

ただし、準備を呼び出すと、セッションはすぐにリソースを事前に割り当て、事前録音を開始します。

その後、結果を尋ねると、セッションは以前よりも速く一致を返します。

コードでこれを行うには、結果を尋ねる前にprepareメソッドを呼び出すだけです。

このメソッドを呼び出すのは完全にあなた次第であり、必要に応じてShazamKitはあなたに代わってそれを呼び出します。

さて、「セッションの現在の動作を追跡するにはどうすればよいですか?」と疑問に思うかもしれません。

「たとえば、長時間のセッションでは、「録音、マッチング、または何か他のことをしていることをどうやって知ることができますか?」

これを助けるために、マネージドセッションには、セッションの現在の状態を表すstateというプロパティがあります。

3つの状態は、アイドル状態、事前記録、およびマッチングです。

アイドル状態では、セッションは記録も試合の試みもしていません。

これは、セッションが1回の一致試行を完了したか、キャンセルを呼び出した場合、または複数の一致を実行するときにセッションが結果の非同期シーケンスを終了する場合に当てはまります。

事前録音は、セッションが準備された後の状態を表します。

この状態では、マッチングに必要なすべてのリソースの準備が整い、セッションはマッチの試みのために事前に記録されています。

その後、事前録音の照合またはキャンセルを続行できます。

マッチングは、セッションが少なくとも1回のマッチング試行をしていることを示す3番目の可能な状態です。

この状態で準備を呼び出すことは、セッションによって無視されます。

以下は、スウィフトUIでマネージドセッション状態を使用してビューの動作を促進する方法の例です。

ここでは、デモアプリからのサブビューの実装例があります。

状態がアイドル状態または一致している場合、このビューに異なる動作を実装しました。

現在、セッションの状態はアイドル状態であり、テキストビューはHear Musicに設定されています。

また、状態が一致しているかどうかを確認する条件があります。

そうでない場合は、進行状況ビューを表示し、そうでない場合は、ダンスを学ぶボタンを表示します。

状態は現在アイドル状態なので、ダンスを学ぶボタンが表示されます。

ボタンをタップすると、状態が一致に変わり、UIが自動的に更新されます。

今回はテキストがマッチングに設定され、マッチングが開始されたため、進行状況ビューがボタンを置き換えます。

セッションの状態が変更されるたびに、SwiftUIは自動的にビューを更新し、余分な作業なしでそれらの変更に応答します。

これは、managedSessionがObservableに準拠しているためです。これは、オブジェクトが変更をオブザーバーに自動的に通信させる新しいSwiftタイプです。

したがって、SwiftUIはmanagedSessionの状態変更に簡単に対応できます。

Observableの詳細については、Discover Observation of SwiftUIビデオをご覧ください。

音声認識を取り上げたので、Shazamライブラリについて話します。

2021年、ShazamKitは、有効なShazam IDがあれば、開発者がShazamライブラリに一致結果を書き込むことを可能にするAPIを提供しました。

これは、Shazamカタログの曲に対応することを意味します。

追加されたアイテムは、コントロールセンターの音楽認識モジュールとインストールされている場合はShazamアプリに表示されます。

また、デバイス間で同期されます。

Shazamライブラリに書き込むのに特別な許可は必要ありませんが、ライブラリに保存されているすべての曲は、それらを追加したアプリに起因するため、顧客に知らせずにコンテンツを保存しないことをお勧めします。

ここでは、リストの2番目の曲はShazamKit Dance Finderアプリによるものです。

長年にわたり、このAPIの使用はさまざまなユースケースを提示し、いくつかの欠点につながりました。

たとえば、自分のアプリに追加したアイテムを表示したい場合はどうなりますか?

頼りになる解決策は、処理するのが面倒でバグが発生しやすい独自のローカルストレージを管理することです。

これらの欠点のために、SHLibraryと呼ばれる新しいクラスが導入されました。

以前のSHMediaLibraryクラスと比較して、より広範な機能を提供するため、SHLibraryを採用することをお勧めします。

SHLibraryのコア機能には、SHMediaLibraryの対応する方法と同じように機能するShazamライブラリへのメディアアイテムの追加、メディアアイテムの読み取り、ライブラリからのメディアアイテムの削除などがあります。

アプリはライブラリに追加したものしか読み取ったり削除したりできないことに注意してください。

読んだときに返されるアイテムはアプリに固有のものであり、ライブラリ全体を表すものではありません。

また、アプリが追加していないメディアアイテムを削除しようとすると、エラーがスローされます。

次に、SHLibraryの使い方を説明します。

SHLibraryでの追加は、デフォルトのライブラリオブジェクトのaddItemsメソッドを呼び出すのと同じくらい簡単です。

このメソッドは、追加するメディアアイテムの配列を取ります。

図書館からの読書も同様に簡単です。

例として、ライブラリからアイテムを読み取り、SwiftUIでリストビューに入力する方法は次のとおりです。

ライブラリオブジェクトのアイテムプロパティをリスト初期化子に渡すだけです。

SHLibraryは新しいSwift Observableタイプにも準拠しているため、変更があるとSwiftUIビューが自動的にリロードされます。

また、非UIコンテキストでライブラリから読み取ることもできます。

たとえば、同期されたShazamsからユーザーの最も人気のあるジャンルを取得したい場合は、ライブラリの現在のアイテムを尋ねることができます。

次に、これを手に入れたら、アイテムの配列をフィルタリングして、返されたすべてのジャンルを取得し、最も高い頻度でジャンルを数えることができます。

最後に、ライブラリオブジェクトのremoveItemsを呼び出して、削除するメディアアイテムの配列を渡すことで、ライブラリからアイテムを削除できます。

アプリに戻ると、認識された曲をライブラリに追加したので、新しいSHLibraryを使用してこれらの曲を読むことができます。

RecentDancesViewには、初期化子に空のmediaItems配列を含むリストがあります。

空の配列をSHLibraryのアイテムに置き換えて、ライブラリのアイテムを自動的に読み込みます。

これらの変更でアプリを実行します。

アプリが読み込まれるとすぐに、アプリがShazamライブラリに追加した曲のリストを受け取ります。

SHLibraryを使用すると、この機能を無料で利用でき、一致した曲のデータベースを維持する必要はありません。

次に、各行のアクションを削除するスワイプを追加して、ライブラリから曲を削除します。

行ビューにスワイプアクションを追加できます。

次に、スワイプボタンをタップすると、SHLibraryのremoveItemsメソッドを呼び出して、削除するメディアアイテムを渡すことができます。

これで完了したら、これらの変更でアプリを実行します。

iPadでもアプリを開いています。私はアプリを開いています。

iPhoneでアイテムをスワイプして、削除ボタンをタップできます。

変更は同期され、削除された項目もiPadのリストから削除されます。

これは素晴らしいです。

新しいライブラリAPIの使用方法と、マネージドセッションを使用して記録を処理する方法を学んだので、今年導入された新機能のいくつかを使用する際のベストプラクティスを紹介し、いくつかのヒントを提供します。

SHManagedSessionとSHSessionは密接に関連しています。

彼らは異なる方法ではありますが、ほぼ同じことを達成することができます。

ShazamKitに録音を処理させたいときは、managedSessionを使用してください。

オーディオバッファを生成してフレームワークに渡すときは、SSHSessionを使用してください。

managedSessionを使用して、マイクまたはAirPodからの音声を認識します。

マイクからのオーディオストリーミングのみを認識したい場合は、SSHSessionを使用してください。

任意の署名とmanagedSessionとのマッチングはサポートされていません。

したがって、署名ファイルまたはメモリにロードされた署名データがある場合は、SHSessionを使用して一致させます。

最後に、managedSsessionはマッチングのオーディオフォーマットを自動的に処理し、SHSessionは複数のPCMオーディオフォーマットとのマッチングを可能にします。

SHSessionのオーディオフォーマットといえば、以前は、matchStreamingBufferメソッドは、これらのサンプルレートで特定のフォーマット設定でPCMオーディオバッファを一致させることしか許可しませんでした。

サポートされていない設定のオーディオバッファは、NoMatchになりました。

このリリースでは、SSHSessionは、さまざまなレートでサンプリングされたほとんどのフォーマット設定でPCMバッファをサポートするようになりました。

これらのバッファを渡すと、SHSessionがフォーマット変換を処理します。

最後に、カスタムカタログで同じように聞こえる2つ以上のオーディオビットがある場合、ShazamKitは、複数の参照署名に一致するクエリ署名を渡すと、カスタムカタログからすべての一致を返すことができます。

マッチは返され、最高のマッチ品質でソートされ、必要な適切なマッチ結果をフィルタリングできます。

ヒントとして、それぞれのメタデータで似ているように聞こえる参照署名に適切に注釈を付けて、必要な結果を区別することができます。

これを達成する方法の例を次に示します。

すべてのエピソードが同じイントロサウンドを持つテレビ番組があるとします。

各エピソードを表す参照署名でtelevisionShowCatalogを生成できます。

このカタログを使用してセッションを作成でき、イントロセクションを照合すると、ShazamKitは各エピソードのmediaItemsとの一致結果を返します。

その後、mediaItemsをフィルタリングして、エピソード2などの特定のエピソードのmediaItemsのみを返すことができます。

これが適切な注釈がどのように役立つかです。

今年はすべてエキサイティングなアップデートを経験したので、素晴らしいアプリに切り替えて、もう1つのダンスを学ぼうとします。

AirPodsに切り替えて曲を再生します。

私はアプリでマネージドセッションを使用しているので、AirPodで再生されているオーディオを聴いて、私のためにダンスビデオを見つけることができます。

AirPodsのタッチコントロールを押して曲を再生し、アプリが音声を検出するのを待ちます。

甘い！

ダンシングデイブはいくつかのアフロビートの動きを披露しているようですが、この話の後に学ぶために最善を尽くします。

あなたがこれらの新しいアップデートに私たちと同じくらい興奮していることを願っています。

ご参加いただきありがとうございます。素晴らしいWWDCをお過ごしください。

♪ ♪