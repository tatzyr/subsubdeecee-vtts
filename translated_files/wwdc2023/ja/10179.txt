10179

♪ ♪

エリン：こんにちは！私の名前はエリンで、CoreMotionチームのエンジニアです。

CoreMotionのクールなアップデートについてお伝えできることを嬉しく思います。

CoreMotionは、慣性センサーからモーションデータにアクセスするための中心的なフレームワークとして機能します。

ハードウェアが進歩するにつれて、モーション情報をキャプチャする能力も進歩しています。

クラッシュ検出、転倒検出、空間オーディオは、改善されたセンシング機能に依存する機能のほんの一部です。

CoreMotionを使用すると、これらの改善を自分のアプリでも活用できます。

このセッションでは、モーションデータと対話できる新しい方法のいくつかに焦点を当てますが、新しいものにたどり着く前に、モーションデータを生成するセンサーを簡単に思い出させたいと思います。

デバイスの移動方法をキャプチャすることは、私たちがそれらをどのように体験するかの中心です。

Appleのデバイスの多くは、内蔵センサーを使用して、空間を移動する概念を作成しています。

例えば、Apple Watchを考えてみましょう。

内蔵センサーには、加速度を測定する加速度計、回転を測定するジャイロスコープ、磁場を測定する磁力計、圧力を測定する気圧計などがあります。

一緒に、彼らはデバイスがどのように移動し、宇宙で方向づけるかを追跡するのに役立ちます。

デバイスの動きのアイデアを生み出すことは、私たちが楽しむ多くの機能の基本です。

これには、その日に取った歩数や、トレーニング中に消費したカロリーを追跡するなどが含まれます。

それは、私たちの空の星を探索するための星空観察アプリのように、デバイスの向きに依存する経験をサポートします。

自動車事故に遭ったときや転んだときに検出して私たちを安全に保つ機能も、同じセンサーを使用して動きを追跡することに依存しています。

これらは可能な多くのアプリケーションのほんの一部です。CoreMotionをどのように活用するかを常に楽しみにしています。

関連するいくつかのセンサーの概要を説明したので、AirPodsなどのオーディオ製品からモーションデータを取得し、水没データを更新し、最後に、より高いレートのセンサーデータをストリーミングする新しい方法について説明します。

ヘッドフォンの動きから始めましょう。

少し前に、ダイナミックヘッドトラッキングを備えた空間オーディオは、音楽や映画の体験方法を変えました。

ダイナミックヘッドトラッキングは、iPhoneとApple Watchに存在するのと同じデバイスモーションアルゴリズムに依存しています。

数年前にCMHeadphoneMotionManagerが導入されたとき、動的ヘッドトラッキングを可能にしたのと同じデータが利用可能になりました。

姿勢、ユーザーの加速、回転速度データを接続されたiOSまたはiPadOSデバイスにストリーミングすることで、頭の動きを追跡できます。

ヘッドトラッキングは、ゲームからフィットネスアプリケーションまで、多くのクールな機能のロックを解除しました。

そして今、今年、CMHeadphoneMotionManagerがmacOSに登場します。

いくつかの詳細を見てみましょう。 では。

CMHeadphoneMotionManagerは、iOSとiPadOS 14で初めて利用可能になりました。

そして今年から、macOS 14にも登場します。

CMHeadphoneMotionManagerを使用して、AirPods Proなどの動的ヘッドトラッキングを備えた空間オーディオをサポートするオーディオ製品から、接続されたiOS、iPadOS、またはmacOSデバイスにデバイスの動きをストリーミングできます。

iPhoneやApple Watchと同じように、サポートされているデバイスからのストリーミング中にCMDeviceMotionの姿勢、ユーザー加速度、回転速度データを調べます。

SensorLocationなど、CMHeadphoneMotionManagerに固有の追加情報に注意してください。これは、左からであろうと右の芽からであろうと、データのソースがどこにあるかを曖昧にするのに役立ちます。

データはリモートデバイスからストリーミングされるため、いつ接続されているかを理解することが重要です。

CMHeadphoneMotionManagerDelegateを使用すると、接続状態の更新を簡単に聞くことができます。

使い方をお見せしましょう。

接続状態の更新に対応するために、CMHeadphoneMotionManagerDelegateプロトコルを採用してください。

データは、オーディオデバイスがiPhone、iPad、Macなどのサポートされているストリーミングデバイスに接続されている場合に利用できます。

自動耳検出が有効になっていると、ヘッドトラッキングに影響を与えるイベントも受信されます。

イヤホンが耳から取り出されると切断イベントが発生し、元に戻されると接続イベントが行われます。

同様に、自動ヘッド検出が有効になっている場合、イヤーヘッドフォンの着脱はこれらのイベントをトリガーします。

これらのイベントをリッスンし、データをストリーミングするためにCMHeadphoneMotionManagerを設定するのは簡単です。やり方をお見せしましょう。

ストリーミングを開始する前に、デバイスのモーションデータが利用可能であることを確認する必要があります。これは、isDeviceMotionAvailableプロパティを使用して確認できます。

先ほど話した接続イベントを受け取るために代理人を割り当てます。

次に、データのストリーミングを開始します。

CMHeadphoneMotionManagerは、プッシュインターフェイスとプルインターフェイスの両方を公開してデータを取得します。

この例では、プッシュインターフェイスを使用します。

startDeviceMotionUpdatesを使用し、操作キューとハンドラを指定します。

モーションデータにアクセスしているので、承認は重要です。

アプリのユーザーは、Info.plistに追加したMotion Usage Descriptionキーを使用して、モーションデータに対してアプリを承認するように求められます。

authorizationStatusプロパティをチェックして、モーションデータの許可が許可されているかどうかを確認し、許可レベルに関係なくシームレスなエクスペリエンスを提供できます。

承認され、データのストリーミングが開始されると、各デバイスのモーションアップデートで提供される姿勢情報を使用して、ヘッドポーズを簡単に追跡できます。

たとえば、startingPoseとして参照態度を追跡し、乗算方法を使用して、現在のサンプルの元のポーズに対する相対的な変化を便利に取得できます。

姿勢、ユーザーの加速度、回転速度データに加えて、各デバイスのモーションアップデートにはセンサーの位置情報が含まれています。

モーションデータは一度に1つの芽から配信されるため、これは重要です。

各サンプルで配信されるSensorLocation列挙型を使用すると、どの芽がデータを調達しているかを特定できます。

データをストリーミングする芽は、自動耳検出が有効になっている場合、インイヤー状態など、多くの影響を受ける可能性があります。

たとえば、データが右のイヤホンからストリーミングされていたが、自動耳検出を有効にして耳から取り出すと、左のイヤホンがデータストリームを引き継ぎます。

これにより、よりシームレスなヘッドトラッキング体験が可能になります。

便利なヘッドトラッキングは、多くの異なる経験への扉を開きました。

腕立て伏せの数を数えたり、姿勢を監視したりすることがこれまで以上に簡単になりました。

そして今、macOSのサポートにより、ヘッドトラッキング対応のオーディオ製品からさらに幅広いデバイスにモーションデータをストリーミングできるようになりました。

私たちは、あなたがCMHeadphoneMotionManagerを使用して構築するものを見て興奮しています。

さて、あなたの頭がどのように動くかを追跡するために圧力を測定する必要はありませんが、他の何かがそうします。

CMWaterSubmersionManagerのクールなアップデートを使用して、水ベースのアクティビティと対話する方法について説明します。

シュノーケリングや水泳などの水ベースの活動では、水と水没状態について興味深いことがたくさんあります。

あなたはおそらく、あなたがどれくらい深く、水温が何であるかに興味があるでしょう。

また、水没した時期や、水から海岸やボートに戻ったかどうか、活動中の表面空気圧が何であるかを知ることも便利です。

内蔵のバロメーターを使用して、CMWaterSubmersionManagerは、水ベースの活動中にこれらの指標を追跡できます。

いくつか詳細をお伝えします。

CMWaterSubmersionManagerは、watchOS 9を実行しているApple Watch Ultraで利用できます。

CMWaterSubmersionManagerDelegateを使用して、深さ、温度、水没状態のデータを聞きます。

アプリにShallow Depth and Pressure機能を追加し、アプリのユーザーが自動起動設定を構成して水ベースのアクティビティを開始するときにシームレスな体験を得るようにしてください。

CMWaterSubmersionManagerを使い始める方法をお見せしましょう。

水没状態の追跡を開始するには、空き状況を確認した後、CMWaterSubmersionManagerを設定します。

次に、浸水状態とイベントに関する更新の受信を開始するデリゲートを割り当てます。

これらのアップデートを受け取る方法について少し話しましょう。

CMWaterSubmersionManagerDelegateを使用して更新を取得するのは簡単です。

受信できるアップデートにはさまざまな種類があります。

水に出入りするときなど、水没状態の更新は、CMWaterSubmersionEventのdidUpdateメソッドを使用して配信されます。

アプリのエンタイトルメントが欠落しているとき、またはサポートされていないプラットフォーム上にあるときに更新を受信しようとした場合など、問題がある場合は、errorOccurredアップデートを受け取ります。

水温の更新は、CMWaterTemperatureを使用して配信されます。

時計の温度が水と等しくなるのに数秒かかるため、不確実性の概念があります。

だから、最初に水没すると、不確実性が高くなり、水の中でより多くの時間を過ごすと収束し始めます。

水温は水没時にのみ利用可能であることに注意してください。

CMWaterSubmersionMeasurementを使用すると、深さ、圧力、表面圧力、および水没状態の更新を受け取ります。

水没したアクティビティの間、測定値は定期的にアプリに配信されます。

深度など、このデータの一部は、水没状態にある場合にのみ適用されるため、これらはオプションであることに注意してください。

水中の深さは、特定の深さの状態に対応します。

それらがどのようにマッピングされているかをお見せしましょう。

あなたが水没していない状態にあるとき、水から出た状態から始めましょう。

水中1メートル以上で、あなたは水没した浅い状態です。

1メートルを超えると、あなたは水没した深い状態です。

浅い深さと圧力機能により、アプリのユーザーが減圧病のリスクを最小限に抑える深さゾーン内にとどまるようにするのは簡単です。

最大深さを6メートルに保ち、その深さに近づいたときに知らせます。

最大深度プロパティを使用して、監視されている深度を確認できます。

6メートルに近づくと、接近するMaxDepth状態に入ります。

6メートルを超えると、あなたは過去のMaxDepth状態です。

データは6メートルまで販売され、過去のMaxDepth状態にある不確実性があります。

それを超えて、あなたはsensorDepthError状態です。

CMWaterSubmersionManagerは、深さをゾーンに分割することで、安全性とセンサーの制限に重点を置いて、深さの変化を簡単に監視できます。

最大6メートルの深さを超えるユースケースに興味がある場合は、管理対象資格の詳細については、ドキュメントをご覧ください。

どちらの方法を選択しても、CMWaterSubmersionManagerを使用すると、ウォータースポーツの素晴らしい体験がこれまで以上に簡単になります。

しかし、水から出るスポーツもたくさんあり、CMBatchedSensorManagerを使用して、これらの活動中に高レートモーションデータを消費する方法を共有することに興奮しています。

まず、いくつかの背景から始めましょう。

モーションデータがあなたに配信される方法について話しました。

デバイスモーションアルゴリズムは、内蔵の加速度計とジャイロスコープからのデータを融合させ、Apple Watchのようなデバイスが宇宙を移動する方法を簡単に追跡する方法を提供します。

これらのサンプルをサンプルごとにリアルタイムでアプリに配信するCMMotionManagerに精通しているかもしれません。

サポートされている最大周波数は100Hzです。

これは、デバイスの瞬間的な姿勢に依存するUIコンポーネントなど、低レイテンシの要件がある場合に素晴らしい選択であることを意味します。

さて、これは新しいCMBatchedSensorManagerを使用して高レートデータを配信する方法とどのように比較されますか?

CMBatchedSensorManagerは、固定スケジュールでセンサーデータのバッチを提供し、1秒あたりのデータのバッチを提供します。

これは、より低いオーバーヘッドでより高いレートのデータをあなたのアプリに提供できることを意味します。

既存のCMMotionManagerの100Hzと比較して、800Hzの加速度計と200Hzのデバイスの動きです。

これで、転倒や衝突検出など、私たちを安全に保つ機能を強化するのと同じデータストリームにアクセスできます。

データはバッチ処理されるため、CMBatchedSensorManagerの使用を検討する際に考慮すべきことがいくつかあります。

あなたのアプリがハイレートデータの恩恵を受けることができるワークアウト中心の機能を持っているが、非常に厳しいレイテンシ要件がない場合、CMBatchedSensorManagerは適しています。

私は、より高いレートのセンサーデータがどのようにあなたに配信されるか、そしてそれが既存のインターフェイスのいくつかによって提供されるものとどのように比較されるかを調べました。

使い方をいくつかお見せしましょう。

多くのスポーツは、短期間のインパクトベースのイベントを中心としています。

これには、いくつかの例を挙げると、ゴルフ、テニス、野球などの活動が含まれます。

これらでは、そのスイングの動き中により多くの情報をキャプチャすることは、フォームの評価とゲームの改善に不可欠である可能性があります。

これは、より高いレートのセンサーデータのキャプチャが機能する場所です。

これを具体的な例に固定することで利益を得ることができます。

野球のスイングに集中しましょう。

スイングにはいくつかの異なる段階があります。

この図では、スイング前のセットアップ、実際のスイング、そして衝撃後のフォロースルーを見ることができます。

スイング品質の重要な指標は、接触する時間です。

言い換えれば、バッターがバットのスイングを開始するときと、バットがボールを打つ時間の間にどれくらいの時間が経過するか。

高速センサーデータを使用して、これを3つのステップに分けることができます。

バッターの手首には、x、y、zの向きのApple Watchが見えます。

重力ベクトルが下を向いて、青でバッターの周りを移動する手首の経路を想像することができます。

接触時間を計算するには、まず800Hzの加速度計を使用してバットとボールの間の衝撃点を検出します。

次に、200 Hzのデバイスの動きで重力に沿った回転を使用して、スイングの開始を特定します。

最後に、スイングの開始からインパクトまで、接触時間と呼ばれるこれらのタイムスタンプの差を計算できます。

私たちが探しているものを理解するために、スイング中にセンサーデータを視覚化することから始めましょう。

ここでは、1つのスイングを含む1秒のウィンドウのz方向に加速度計データをプロットしました。

0.5秒から0.6秒の間に活動のバーストがあることがわかります。

衝撃点を検出するアルゴリズムは、この観察を中心にします。

スイング中に利用可能な信号情報の量を、上部に800Hzの加速度計、下部に100Hzの加速度計を比較してみましょう。

その興味のあるセクションでは、0.5秒から0.6秒の間に、10ではなく80のデータポイントがあり、何が起こっているのかをはるかに細かく把握できます。

これは、インパクトなど、私たちが興味を持っていることに焦点を合わせるのに役立ちます。

さて、デバイスの動きの観点から同じスイングを見てみましょう。

これは、200Hzの重力に沿った回転速度をプロットします。

回転速度が0.3秒前後で変化し始める方法によって、スイングスタートを見ることができます。

これらをまとめましょう。

これらのプロットを時間ごとに整列させると、800Hzの加速度計と200Hzのデバイスの動きの情報が、接触時間を計算するのにどのように役立つかを感じることができます。

センサーストリームにスイングがどのように表示されるかがわかったので、CMBatchedSensorManagerを使用してデータのストリーミングと処理を開始できます。

まず、このプラットフォームでデータが利用可能であることを確認したい。

isAccelerometerSupportedをチェックすることで、そうすることができます。

同様のプロパティを使用して、デバイスのモーションサポートを確認できます。

Apple Watch Series 8とUltraは、高速加速度計とデバイスの動きの両方をサポートしています。

これはワークアウト中心のAPIであるため、データを取得するにはアクティブなHealthKitワークアウトセッションが必要です。

HealthKitワークアウトセッションに入ったら、最新情報の受信を開始できます。

Swiftの非同期サポートにより、センサーデータのバッチを簡単に受信し、各バッチを処理できます。

ループを終了する条件を必ず評価してください。たとえば、ワークアウトが終了した場合などです。

モーションデータまたはサポートされていないプラットフォームで許可されていない場合、エラーが表面化されることを忘れないでください。

では、データのバッチごとに何をしたいのかをズームしてみましょう。

バッチごとに、フィード関数を呼び出して、データに対してアルゴリズムを実行します。

バットがボールと接触すると、z方向に顕著な反応が見られることが期待されます。

Z軸は時計の王冠に垂直であることを覚えておいてください。

この残響は、衝撃の良い近似値です。

これを念頭に置いて各加速度計バッチを処理します。

まず、接触時に力が移動するので、より高い周波数の応答をよりよく分離したい。

これを行うには、zサンプルをfzとしてフィルタリングします。

フィルタリングされたデータを使用して、フィルタリングされた信号のピークとして衝撃点を近似します。

そのサンプルに関連付けられているインデックスをインパクトインデックスとして追跡しましょう。

フィルタリングされた信号から引き出された impactIndexを使用して、元のデータのバッチから衝撃タイムスタンプを取得できます。

これにより、接触時間を計算する方法の2番目のステップに進みます。重力に沿った回転を使用してスイングの開始を検出します。

バッターがスイングするApple Watchの道を想像してみてください。ボールに会うために体の周りの道をたどります。

したがって、スイング中に重力に沿って非ゼロ回転率、スイング外の重力に沿ってゼロに近い回転率を見ることを期待しています。

高周波デバイスの動きをローカルバッファにストリーミングすることで、回転速度データを使用してスイングが始まった場所を特定できます。

私の計算関数がどのように見えるかを詳しく見てみましょう。

ローカルバッファを後方に反復して、興味のあるポイントであるインパクトタイムスタンプを調査します。

スイングの開始がインパクトに先行しなければならないことを知っているので、バッファ内の各サンプルを処理する前に、一連のshouldProcessチェックを実行できます。

これには、デバイスのモーションサンプルが衝撃時間前のものであることを確認するためのタイムスタンプチェックを含めることができます。

スイング期間に境界を置くこともできます。

スイングの開始がボールと接触する前に一定期間以上発生しないことは理にかなっています。

一連の初期チェックに合格したサンプルについては、各軸の回転率と重力値の積を合計するcomputeRotation関数で重力に沿った回転を計算します。

重力に沿った回転を計算すると、スイングの始まりを探し始めることができます。

単純なスイングスタートチェックは、しきい値を満たすために重力に沿った回転率の一貫した失敗を探すかもしれません。

重力に沿った回転率がそのしきい値を満たすのを見なくなったら、それをスイングの開始時間とループの出口として使用します。

最終チェックとして、検出したスイングを検証します。

ここでは、スイング中に重力に沿って蓄積された回転を見て、それが予想されるしきい値内にあることを確認することができます。

そして、それで、検出した開始タイムスタンプを返すことができます。

これにより、最後のステップであるステップ3に進み、連絡する時間を計算するために必要なものがすべて揃っています。

最初のフィード機能に戻りましょう。

CMBatchedSensorManagerを使用して、加速度計とデバイスのモーションデータをストリーミングし始めました。

z方向にフィルタリングされた加速度計データを使用して、impactTimeを検出しました。

次に、重力に沿った回転率を調べることで、その衝撃タイムスタンプの近くでスイングの開始を特定しました。

2つのタイムスタンプの差を取って、連絡する時間を計算します。

これは、センサーデータに基づいて機能を開発する方法の簡単な例でした。

高周波データストリームの余分な信号情報は、他の多くの調査への扉も開きます。

見てみましょう。 

私たちは以前、z方向の800 Hzの加速度計ストリームでこの加速度計データのトレースを見ました。

さて、2番目のプロットを見てみましょう。

かなり似ていますが、まったく同じではありません。

これは、バットが実際にボールと接触しなかった逃したスイングからの痕跡です。

スイングモーション自体は両方に似ていますが、高レートのデータストリームがこのような違いについてどのように余分な洞察を与えるかがわかります。

あなたが開発するアルゴリズムは、これらの違いを活用して、以前は不可能だったことを検出することができます。

要約すると、同じデバイスモーションアルゴリズムは、いくつかの異なる方法であなたにデータを提供します。

CMMotionManagerは、サンプルごとに最大100Hzでデータを販売します。

これは、サブセカンドスケールで低レイテンシ要件がある場合、またはワークアウト以外のモーションベースの機能がある場合に最適です。

新しいCMBatchedSensorManagerは、バッチスケジュールで200 Hzのデバイスモーションと800 Hzの加速度計のキャップで、より高いレートでデータを配信し、1秒あたりのデータのバッチを提供します。

これにより、高レートのデータの恩恵を受けることができるワークアウト中心の機能に役立ちます。

Apple Watch Series 8とUltraで利用できます。

私はCMBatchedSensorManagerを使用するために野球のスイングに焦点を当てましたが、これらのより高いレートのデータストリームは、特に短期間やインパクトベースの活動中に、すべてのトレーニングでApple Watchの動きに関する貴重な洞察を提供することができます。

それはCMBatchedSensorManagerであり、これでCoreMotionの新機能のレビューは終了です。

ヘッドフォンでもApple Watchでも、モーションとやり取りする素晴らしい方法があります。

モーションデータを使用するクールな方法はたくさんありますが、いくつかの例を取り上げました。

それらを試してみて、詳細についてはドキュメントを確認することをお勧めします。

フィードバックも必ず提供してください。

モビリティの測定など、モーションデータが健康ベースの機能にどのように変換されるかの例については、WWDC 2020の「Beyond Counting Steps」セッションをチェックしてください。

CMBatchedSensorManagerを活用するためのランニングワークアウトの詳細については、「WorkoutKitでカスタムワークアウトを構築する」をご覧ください。

モーションデータを使用して素晴らしい新しい体験を生み出す方法を見て、とても興奮しています。

ご覧いただきありがとうございます。