10071

♪まろやかなインストゥルメンタルヒップホップ♪

♪

こんにちは、私はクリスです。

私はAVFoundationチームのエンジニアであり、私たちのセッションにあなたを歓迎します。

この講演では、空間体験のためにストリーミングコンテンツを準備して配信する方法を見ていきます。

HTTPライブストリーミングを使用して2Dメディアを制作、準備、配信する現在の手順の簡単なレビューから始めます。

HLSとしても知られています。

2Dコンテンツの準備と配信をカバーするので、3Dビデオコンテンツに目を向けます - サポートされているものと、先ほど説明した手順の更新です。

コンテンツパイプラインを考慮すると、ビデオ、オーディオ、キャプションのメディアエンコーディングから始めます。

その後、これらのメディアリソースをパッケージ化し、HLS配信の準備ができている必要があります。

これが今日の2Dコンテンツの配信方法です。

3Dコンテンツを配信する目標は、現在の2Dプロセスに基づいて構築することです。

HLSは、重要な適応を可能にする断片化されたMP4時付けメタデータの新しいサポートを追加します。

Apple Developer WebサイトのHTTPライブストリーミングページには、ドキュメント、ツール、サンプルストリーム、開発者フォーラム、その他のリソースへのリンクがあります。

これは、この講演で取り上げられた詳細が時間の経過とともに利用可能になる場所です。

私たちの目標は、このプラットフォームに2D視聴覚コンテンツを配信することは、他のすべてのプラットフォームと同じであるべきです。

これは、HTTPライブストリーミング、AVFoundation、Core MediaなどのApple Mediaテクノロジーと、しばしばMPEG-4と考えられているISOベースのメディアファイル形式などの標準ベースのフォーマットを構築することによって達成されます。

これは、新しい空間体験のパラダイムをサポートしながら行われます。

視聴覚メディアの再生を最適にサポートする方法については、「ビデオ再生のための素晴らしい空間体験を作成する」セッションを参照してください。

ビデオの場合は、ソースビデオをエンコードします。

適切な長さに編集し、あなたにとって重要なビットレート層の色補正します。

ここでは、高効率ビデオコーディングの略であるHEVCなどのビデオエンコーダの設定方法と使用方法を選択します。

他のAppleプラットフォームに配信する既存の2D視聴覚メディアのサポートは完全にサポートされていますが、これらの再生機能に注意してください。

このプラットフォームは、最大4K解像度の再生をサポートし、最高品質のビデオを体験できます。

ディスプレイのリフレッシュレートは90ヘルツで、24フレーム/秒のビデオでは、特別な96ヘルツモードが自動的に使用できます。

標準および高ダイナミックレンジのサポートがあります。

ビデオの対応するオーディオについては、必要なソースオーディオストリームの数を特定して生成します。

数は、ターゲットとする話し言葉のセットとそのオーディオの役割によって異なります。

1つの役割はメインの対話であり、別の役割は音声説明かもしれません。

HLSを念頭に置いて配信のためにこれらのソースをエンコードします。

フォールバックステレオオーディオトラックとともに、空間オーディオを提供したいと思うかもしれません。

これにより、どこでも空間オーディオと信頼性の高い再生をサポートするデバイスに素晴らしい体験が保証されます。

HLS開発者ページには、オーディオの準備に関するドキュメントへのリンクがあります。

そして、キャプションがあります。

ここでは、キャプションには、さまざまな言語と役割をカバーする字幕とクローズドキャプションの両方が含まれています。

「字幕」という用語は、言語を話さない視聴者のために異なる言語で翻訳を提供する音声テキストの転写、または設定時間と場所を確立するために使用されます。

クローズドキャプションは字幕に似ていますが、視聴者が音声を聞くことができない場合に意図されています。

クローズキャプションは、対話だけでなく、効果音やその他の関連するオーディオキューの書き起こしも提供します。

聴覚障害者のための字幕、SDHも、同じ目的を果たすかもしれません。

ビデオやオーディオのエンコーディングと同様に、HLS、最も一般的にはWebVTTでサポートされているキャプションファイルとフォーマットを作成する必要があります。

ソースビデオ、オーディオ、キャプションを手元に置いて、次はパッケージです。

パッケージングは、信頼できる配信のために、ソースメディアをさまざまな種類のセグメントに変換するプロセスです。

これは、以前のHLSストリーミングページで利用可能なAppleのHLSツールで行うことができます。

一部のコンテンツプロバイダーは、独自のプロダクションツール、ハードウェア、またはワークフローを使用する場合があります。

他の人は、これらのサービスやツールを最初のグループに提供するベンダーかもしれません。

パッケージングの目標は、一連のメディアセグメント、その使用を促進するメディアプレイリスト、およびそれらをすべて結びつける多変量プレイリストを作成することです。

今日、最も一般的に使用されている2種類のHLSメディアセグメントが使用されています。

断片化されたMP4メディアセグメントは、すでにエンコードされたビデオまたはオーディオのムービーファイルから始めて、多くのリソースを生成することによって生成されます。

これらのリソースはメディアセグメントとして知られています。

再生中にクライアントデバイスによって取得されるのは、これらのセグメントです。

字幕ファイルにはセグメント化も必要です。

これは、メディアセグメントを生成するための字幕セグメントツールで行われます。

ソースWebVTTファイルは、ターゲットセグメントの期間中、任意の数のWebVTTファイルに分割できます。

最後に、HLSリソースのコレクションは、HTTP配信用のWebサーバーでホストされます。

これは、クライアントに直接サービスを提供する1つのサーバー、またはコンテンツ配信ネットワークで使用されるオリジンサーバー、またはCDNである可能性があります。

いずれにせよ、再生のためにクライアントデバイスに配信されるのはこれらのリソースです。

2D生産と配信のパイプラインを見直したので、3Dコンテンツと新しい特別な機能を活用した違いに目を向けましょう。

2Dコンテンツと3Dステレオスコピックコンテンツの違いに焦点を当てて、ソースエンコーディング、パッケージング、配信を再び見ていきます。

だから、私たちは3Dビデオについて話しています。

この用語を分解しましょう。

まず、それはビデオなので、ムービートラックまたはネットワークストリームのフレームのシーケンスです。

「3Dビデオ」の「3D」は、左目に画像を提供するステレオスコピックと、右目にわずかに異なる視点から別の非常に類似した画像と交換可能に使用されます。

視差と呼ばれる左右の画像のこれらの違いにより、提示されたときにビデオの3次元の深さを知覚します。

3Dビデオフレームの持ち運びには選択肢がありますが、役に立つと思われるいくつかの指導原則があります。

すべてのステレオフレームに単一のビデオトラックを使用することで、2Dビデオトラックを使用した従来の制作が保存されます。

左右の画像またはビューは、任意の表示時間に対して、単一の圧縮フレームにあります。

手にフレームがある場合は、両方のビューまたはステレオペアがあります。

それは効率的で、理想的には、Appleシリコンでサポートされており、可能な限り、非3D認識の再生によってデコーダ可能で、ビデオを2Dワークフローでオーディションできるようにする必要があります。

ステレオフレームを提供するために、「MV-HEVC」とも呼ばれるマルチビューHEVCの使用を導入します。

HEVCの延長です。

「MV」はマルチビューです。

各フレームに複数のビューを運ぶ各フレームには、圧縮された左右の画像のペアがあります。

MV-HEVCはその中心がHEVCであるため、Appleシリコンはそれをサポートしています。

MV-HEVCでは、各圧縮フレームにベースHEVC 2Dビューを保存します。

エンコーディングは、左右の画像の違い、またはデルタを決定します。

2Dプラスデルタとして知られるこの技術は、2Dデコーダが左目などのベース2Dビューを見つけて使用できることを意味します。

しかし、3Dデコーダは他のビューを計算して、対応する目に両方のビューを提示することができます。

ベース2D画像の違いは標準的なHEVC技術を使用し、左右のアイビューの違いだけがステレオフレームに記載されているため、効率が達成されます。

ビデオフォーマットの説明、またはMPEG-4のビジュアルサンプルエントリは、コーディングタイプ、コーデック、各ビューの寸法、およびビデオフレームをデコードするために必要なその他の詳細を示します。

ビデオフォーマットの説明の新しい拡張機能が導入されました。

ビデオ拡張使用ボックスと呼ばれ、ビデオが立体的であり、どのステレオアイビューが存在するかという軽量で簡単に発見できる信号として機能します。

HLS配信の場合、これは左と右の両方になります。

この新しいVEXUボックスを説明する仕様は、SDKで利用可能です。

その構造は進化し、それは仕様書に記載されます。

2Dコンテンツと同様に、3DビデオはHEVCを使用しますが、今回はMV-HEVCと呼ばれるバリエーションです。

これは、立体ビューを運ぶために必要です。

2D制作と同様に、MV-HEVCを搭載したローカルムービーを使用でき、他の2Dビデオのように振る舞う必要があります。

対応する目に左と右の両方の画像を提示すると、立体的な深さの知覚が生成され、相対的な深さの感覚が得られます。

ビデオシーン内のオブジェクトは、視差の量が異なるため、別のオブジェクトよりも近くまたは遠くに知覚される可能性があります。

立体深度の3つの主要なゾーンを定義できます。

それらは、視差の手がかりのないスクリーンプレーンです。負の視差は、スクリーンプレーンの前でオブジェクトを知覚します。正の視差は、スクリーンプレーンの後ろでオブジェクトは知覚されます。

キャプションのような要素が、負の視差の手がかりと同じ領域でフレームの視差なしでレンダリングされると、深さの競合が作成され、表示時に不快感が発生します。

質問。

立体視鏡的視差と深さの衝突の可能性を考えると、3Dビデオのキャプションの作成はどのように関与していますか?

私たちは以下をサポートできますか?

再生は水平キャプションで機能し、再生は垂直キャプションを含む言語間で機能し、再生はアクセシビリティ設定を使用してユーザーの好みのキャプションサイズを調整する場合に機能します。

さて、答えはイエスです。

次に説明するアプローチを使用したステレオスコピックビデオでは、キャプションはそのまま機能すると同時に、2Dと3Dの経験の間で同じ2Dキャプションアセットを共有できるようにする必要があります。

これは、先に述べた新しい時限メタデータを含めることで可能です。

ステレオスコピックビデオでは、深さの競合やビデオをオーバーレイする視覚的要素を避けることが重要です。

新しいキャプションフォーマットや既存のフォーマットの変更を要求する代わりに、各ビデオフレームの視差を特徴付ける方法を提供します。

これは、明らかに近く、視聴者から遠く離れたいくつかの領域で、フレーム全体で異なる場合があります。

私たちはこれを視差輪郭と呼び、ビデオトラックのフレームと同期したメタデータトラックにメタデータとして記録されます。

3Dビデオをタイルし、各タイルの深さの視差を示す場合、それを使用して、キャプションがステレオビデオの要素に干渉しないようにすることができます。

再生中、キャプションの視差は、深さの競合を避けるために自動的に調整されます。

このような視差ビデオの輪郭を持つ各メタデータ項目は、各タイルに関連付けられた最小視差値で、関連するビデオの2Dタイルを記述します。

各ビデオフレームのプレゼンテーションは、ビデオフレームの輪郭を記述するメタデータ項目に関連付ける必要があります。

ビデオの視差のさまざまな領域を特徴付けるために、ストレージと解像度の良いバランスとして、10×10のタイルをお勧めします。

この視差メタデータがどのように生成されるかを考慮して、各フレームの左右のビューから始めます。

これは、2つの同期ビデオトラックでプロダクションで行うことができ、MV-HEVCを必要としません。

次に、視差または格差分析を実行して、タイルの説明に適した視差情報を作成します。

ステレオフレームごとに、これは次のステップのためにメタデータペイロードにパッケージ化されます。

このメタデータの形式を説明する仕様は、SDKで利用できます。

この視差情報は、メタデータサンプルにパッケージ化され、時付けされたメタデータトラックに書き込まれます。

メタデータトラックは、それが説明する対応するビデオに関連付けられます。

HLSパッケージがビデオと視差メタデータの両方を含むビデオセグメントを生成するように、メタデータとビデオトラックをビデオと多重化する必要があります。

すでに2D用に制作しているキャプションは、3Dで再利用できます。

これは、今日使用されているプロセスまたはあなたが協力する可能性のあるベンダーが、3Dプロダクションで2Dで作業を続けることができることを意味します。

また、これは、3Dコンテンツが言語の選択、水平および垂直レイアウト、またはユーザーによるアクセシビリティ字幕設定の潜在的な使用に依存しないことを意味します。

説明された視差メタデータを追加することで、プラットフォームは構築した視差メタデータに動的に適応します。

3Dビデオでのオーディオ使用については、2D配信に同じオーディオ使用を使用できます。

プラットフォームはヘッドトラッキングをサポートしているため、空間オーディオ形式の使用を検討してください。

2D体験と3D体験で同じオーディオを共有するには、ビデオはタイミング的に一致し、同じ編集を行う必要があります。

それらが異なる場合は、2Dアセットと3Dアセットの間でオーディオトラックを分離する必要があります。

3Dのパッケージングに目を向けると、更新されたHLSツールが詳細を処理し、3Dアセットでプロセスを2Dとほぼ同じにします。

Appleのツールを使用しないほとんどの生産システムは、同等の機能を構築するためにリリースされている新しい仕様を使用することができます。

独自のプレイリストを作成したり、検査したりする場合は、いくつかの変更に注意してください。

REQ-VIDEO-LAYOUTは、ビデオがステレオスコピックであることを示すビデオストリーム用の新しいタグです。

属性値は、ビデオがステレオであるかどうかを示します。

アセットが3Dとしてロードされている場合、2Dに、またはその逆に切り替わらないことに注意してください。

2Dビデオは変更されず、同じプレイリストで3Dビデオと混ぜることができます。

REQ-VIDEO-LAYOUTにはHLS仕様の新しいバージョンが必要なため、バージョンは12に更新されます。

これはSDKで文書化されています。

以下は、バージョン番号を12に変更し、3DビデオストリームにREQ-VIDEO-LAYOUTを使用した多変量プレイリストの例です。

最高のナビゲーション体験を得るには、サムネイルスクラブをサポートするために、多変量プレイリストに2D iFrameストリームを含める必要があります。

最後に、HLS配信は3Dアセットで同じように機能します。

3Dアセットの提供は、2Dアセットの提供とほぼ同じですが、エクスペリエンスを最適化するためにできることがいくつかあります。

ソースアセットを準備し、3DビデオにMV-HEVCを使用し、新しい視差輪郭メタデータを含めるようにしてください。

オーディオとキャプションの制作は同じです。

更新されたパッケージを使用して、関連するセグメントとプレイリストを作成します。

ホスティングは同じままです。

閉じる前に、視覚的な快適さが3D体験の重要なコンテンツデザイン目標であることを強調したいと思います。

3Dコンテンツは、十分に長い期間にわたって快適に視聴できるはずです。

快適さの問題を引き起こす可能性のある3Dコンテンツの特性には、ネガティブとポジティブの両方の極端な視差、フォーカスの難しさを引き起こすコンテンツのハイモーション、および「ウィンドウ違反」と呼ばれるものに起因する深さの競合が含まれます。

画面サイズは、視聴者の水平視野にある画面の量に応じて、視聴の快適さに影響を与える可能性があります。

ユーザーは、より近くまたは遠くに配置することで、画面サイズに影響を与える可能性があることに注意してください。

だから、私たちの旅では、HTTPライブストリーミングで2Dと3D配信を見てきました。

ビデオでは、MV-HEVCを紹介しました。

オーディオについては、同じオーディオストリームを2Dと3Dで使用できると指摘しました。

キャプションの場合、同じストリームも同様に2Dと3Dで使用できます。

最後に、3Dビデオの視差を特徴付ける新しい時差メタデータ形式が導入され、同じキャプションを使用できるようになります。

最後に、既存の2Dコンテンツを空間体験にできるだけ簡単にしました。

現在の2Dパイプラインにいくつかの小さな変更を加えることで、MV-HEVCを使用して3Dコンテンツをサポートできます。

2Dアセットの既存のキャプションをすべて使い続けることもできます。

しかし、時指定のメタデータを提供すると、それらのキャプションは隠されず、快適な視聴体験を提供することができます。

ビデオの再生を実装する際の考慮事項については、コンパニオンセッションをご覧ください。

私たちは、あなた達が配信する素晴らしい新しいコンテンツを楽しみにしています。

今日はご参加いただきありがとうございます。

♪