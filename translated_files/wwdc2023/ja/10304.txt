10304

♪ ♪

オヌール・タキン:こんにちは。私の名前はオヌール・タッキです。

私はエンジニアリングマネージャーですが、今日はDockKitを使用した電動iPhoneスタンドとの統合を紹介します。

このビデオでは、DockKitとは何かについて話し、箱から出してすぐにどのように機能するかを掘り下げ、DockKitを使用してアプリをカスタマイズする方法を見て、最後にデバイスのアニメーションを使用してアフォーダンスとして動きます。

では、DockKitとは何ですか?

DockKitは、iPhoneが電動カメラスタンドの中央コンピューティングとして機能することを可能にするフレームワークです。

DockKitスタンドは、ピッチとヨーモーションモデルと自動システムトラッカーをサポートすることで、iPhoneカメラの視野を360度のパンと90度の傾きに拡張します。

これにより、ユーザーはカメラアプリのフレームにいることを心配することなく、自分のコンテンツに集中することができます。

これらのスタンドには、電源と追跡を無効にするための簡単なボタンと、追跡がアクティブでフレーム内にあるかどうかを知らせるLEDインジケーターが含まれている場合があります。

あなたは電話をスタンドとペアリングし、それは行って良いです。

すべての魔法は、iPhone自体のアプリケーションとシステムサービスで起こります。

モーター制御と被写体追跡がシステムレベルで処理されているため、iOSカメラAPIを使用するすべてのアプリはDockKitを利用できます。

これにより、ビデオキャプチャ、ライブストリーミング、ビデオ会議、フィットネス、エンタープライズ、教育、ヘルスケアなどのアプリで、より良い体験と新機能の機会が生まれます。

DockKitについて話すのではなく、あなたにそれを実演させてください。

目の前には、DockKitスタンドのプロトタイプがあります。

私はすでにそれをiPhoneとペアリングしました。

スタンドにいるとき、電話はDockKitを介してペアリングされたドックと通信します。

では、試してみましょう。

内蔵のカメラアプリを起動し、ここでこのボタンを押すと、追跡が開始されます。

テーブルの周りを動き回ると、ドックが私を追跡します。

私がフレームの中にいることを示すために緑色のLEDが点滅していることに注目してください。

では、バックカメラに切り替えさせてください。

私を視野に入れるために180度回転させることで、ドックがどのように反応するかに注目してください。

超かっこいい。

しかし、これは内蔵のカメラアプリだけでは機能しません。

カメラAPIを使用するアプリは、ドックで使用できます。

例えば、FILMICPROを試してみましょう。

これは、今日App Storeからダウンロードできるのと同じFILMICPROです。

アプリを起動すると、デフォルトで背面カメラになります。

そして、これはすべて箱から出して機能します。

DockKitスタンドを使用すると、周囲の空間や物体と対話できます。

例えば、私はここで私の本のスタックに行き、私の本について話すか、オブジェクトと対話して私のスペースを再配置することができます。

DockKitアプリケーションを使用すると、ストーリーテラーは視野を心配するのではなく、ストーリーに集中できます。

iPhoneの内蔵画像インテリジェンスと滑らかなモーターにより、これらのスタンドは本当に生き生きとしています。

これがどのように機能するかを掘り下げてみましょう。

DockKitシステムトラッカーは、カメラ処理パイプライン内で実行され、組み込みの推論を通じてカメラフレームを分析し、どの対象を追跡するかを決定し、対象の軌道を推定し、モーターを駆動して対象を適切にフレーミングします。

撮影監督が現実世界の出来事を観察し、カメラの視点を調整する方法と同様に、DockKitはカメラフレームからオブジェクトを推測し、ドックへの作動コマンドを介してモーターを調整します。

モーター制御は、DockKitスタンドを管理し、通信するDockKitデーモンを介して達成されます。

作動コマンドはDockKitプロトコルを介してスタンドに送信され、センサーフィードバックを使用してモータ制御のループを閉じます。

追跡を処理するために、カメラフレームはISP推論を介して分析され、毎秒30フレームでDockKitに渡されます。

フードの下には、複数人のシナリオに役立つ視覚的な理解フレームワークがあります。

フェイスとボディのバウンディングボックスが生成され、マルチモデルのシステムレベルのトラッカーに供給されます。

トラッカーは、追跡された各人またはオブジェクトのトラックを生成し、統計的なEKFフィルターを実行して、推論からのギャップやエラーを滑らかにします。

結局のところ、現実世界の信号は必ずしも完璧ではありません。

被験者のトラッカーの見積もりは、モーターの位置と速度のフィードバック、および電話IMUと組み合わせて、最終的な軌道とアクチュエータコマンドに到達します。

多くの場合、複数の被験者がフレーム内に存在することがあります。

デフォルトでは、DockKitは中央のフレーミングで主要な被写体を追跡します。

彼らが2人目またはオブジェクトと関わった場合、DockKitもその人またはオブジェクトをフレーム化しようとします。

例えば、ここにはMahmut、Steve、Dhruv、Vamsiがいます。

Mahmutは、緑色の境界ボックスで示される主な主題です。

検出された顔だけでなく、体にもバウンディングボックスがあることに注意してください。

他のチームメンバーがMahmutを妨害し、道を渡っても、トラッカーは主要な主題を追跡し続けます。

認識または推論が障害物のために誤った結果を与える場合、統計トラッカーはエラーを修正し、Mahmutを追跡し続けることができます。

それが、アプリに追加のコードを追加しなくても、DockKitの仕組みです。

しかし、DockKitと統合して、顧客が気に入る新機能を提供すると、物事は本当にエキサイティングになります。

DockKitアクセサリをコントロールする方法を探りましょう。

これには、ドックへの参照を取得することが含まれます。

そこから、フレーミングを変更するか、追跡されているものを指定するか、システム追跡を停止した後にモーターを直接制御するかを選択できます。

まず、ドックアクセサリの状態の変更を登録します。

ドッキングまたはドッキング解除通知は、人が互換性のあるドックアクセサリからiPhoneをドッキングまたは取り外すときに発生します。

通知は、追跡動作を変更するための前提条件です。

DockAccessoryManager Stateイベントを通じて、ドックの状態を照会できます。

関連する状態は、ドッキング済みとドッキング解除のみです。

接続性はDockKit自体によって管理されます。

ドッキング状態は、iPhoneがDockKitプロトコルを介してドックに接続されていることも意味します。

状態イベントを通じて、アプリケーションは追跡ボタンの状態を取得することもできます。

iPhoneがドッキングされていることがわかったら、アクセサリの他の側面を制御できます。

最も有用なものの1つは、アプリがビデオのトリミング方法を管理することです。

カメラの視野のトリミングを制御するには2つの方法があります。

まず、自動フレーミングの左揃え、中央揃え、右揃えを選択するか、関心のある特定の領域を指定することができます。

どちらかを選びたいケースを見てみましょう。 いずれかを選択したい場合があります。

デフォルトでは、DockKitは被写体をフレームの中央に保ちます。

これはビデオストリーミングのような単純なものにはうまく機能しますが、これが理想的ではないかもしれないユースケースがあります。

たとえば、アプリがこのロゴのようなカスタムグラフィックオーバーレイをビデオフレームに注入した場合はどうなりますか?

この場合、被写体がアートワークによって隠されていないことを確認する必要があります。

フレーミングモードを変更するだけで、これを修正できます。

ここでは、フレームの左3分の1に整列されたグラフィックとのバランスを取るために「右」を指定しています。

そして、そのシンプルなコードで、コンポジションはこのビデオのオープニングシーケンスに最適です。

トリミングを制御するもう1つの方法は、ビデオフレームに関心のある特定の領域を指定することです。

例えば、このビデオ会議アプリを見てみましょう。

すべてのビデオフレームは、正方形のアスペクト比にトリミングされることを意図しています。

ただし、DockKitのデフォルトのフレーミングにより、誰かの顔が切断される可能性があります。

DockKitアクセサリに関心のある領域を設定することで、これを修正できます。

iPhoneのディスプレイの左上隅は原点と見なされます。

関心のある領域は、正規化された座標で定義されます。

この例では、DockKitアクセサリに、関心のある領域は中央の正方形であることを伝えています。

関心のある領域への調整により、被写体はフレーム内で完全にトリミングされます。

DockKitを使用すると、ユーティリティまたはアフォーダンスとして、アプリでカスタムモーター制御を行うこともできます。

これにより、多くの新機能の機会を開くことができます。

DockKitはデフォルトでシステムトラッキングを有効にしているため、モーターを制御したり、独自のカスタムトラッキングを実行したりする前に、この値をfalseに設定する必要があります。

DockKitスタンドは、XとYの2つの回転軸で動作します。

傾き、具体的にはピッチ回転は、マグネットドックポイントの背後にあるモーターと整列したX軸の周りです。

ヨーとして知られるパンの場合、回転はスタンドの基部にあるモーターと一直線に沿ったY軸の周りです。

コードでこれを制御する例を見てみましょう。

毎秒0.1ラジアンをピッチダウンしながら、モーターを毎秒0.2ラジアンの低速で右に動かしたいとします。

まず、最初の速度ベクトルを定義し、そのベクトルをドックに送信します。

タスクをスリープ状態にすることで、2秒間動き続けることができます。

そして、異なるベクトルで方向を逆にして、0.2 rad/sで左に移動し、0.1 rad/sでピッチアップします。

さて、アプリがDockKitと統合されている場合、それがすべてではありません。

モーターを直接制御するだけでなく、推論を制御することもできます。

ビジョンフレームワーク、独自のカスタムMLモデル、またはアプリケーションが必要とする知覚アルゴリズムを使用できます。

カスタム推論出力から、オブジェクトを追跡するためにDockKitにフィードするオブザベーションを構築します。

では、観察とは何ですか?

オブザベーションは、カメラフレームに関心のある主題を表す長方形のバウンディングボックスです。

つまり、あなたが追跡したいものです。

それは顔、動物、あるいは手かもしれません。

正直なところ、時間の経過とともに観察できるオブジェクトやポイント。

バウンディングボックスは、原点の左下に基づいて正規化された座標で定義されます。

たとえば、この検出された顔の観察を作成するには、幅と高さが全体の画像フレームのパーセンテージを持つ約0.25、0.5のバウンディングボックスを使用します。

観測を作成するには、正規化された座標でCGRectを構築し、そこから観測を構築します。

その際、観察タイプが「ヒューマンフェイス」または「オブジェクト」のいずれかであることを指定します。

「humanFace」オプションを使用することで、システムレベルの複数人の追跡とフレーミングの最適化がまだ有効であることを確認できます。

オブザベーションが作成されると、トラッカーに入力できます。

まず、現在のカメラ情報を取得することから始めます。

この場合、座標が画面の左下隅に相対的であり、変換が不要であることをDockKitに知らせるために、向きが「修正」されることを指定し、観測配列とカメラ情報をドックアクセサリに渡します。

さて、良いニュースは、あなたが観察し、手で完全に追跡したいかもしれない多くのものの境界ボックスを計算する必要がないということです。

ビジョンフレームワークは、ボディポーズ検出、動物のボディポーズ検出、さらにはバーコード認識など、追跡可能な観察に簡単に変換できるバウンディングボックスを返す多くの組み込み要求がすでに含まれているため、カスタム推論に最適です。

また、Visionの座標系はDockKitでも同じなので、変換せずに直接渡すことができます。

デバイスの向きが何であるかをDockKitに知らせるだけです。

では、コードでのカスタムオブザベーションの実装について説明しましょう。

この場合、手のポーズ検出リクエストを使用して、デフォルトの顔と体の追跡を手の追跡に置き換えたいです。

まず、ビジョンリクエストとリクエストハンドラを作成します。このユースケースでは、VNDetectHumanHandPoseRequestを使用しています。その後、リクエストを実行します。

認識されたポイントに基づいて観測を構築できます。

簡単にするために、私は親指の先端のポイントに焦点を当てていますが、観察を構築するために他の指の関節や手全体を使用することができます。

そして最後に、観測をDockKitに渡して追跡します。

それで、それを実際に見てみましょう!

カスタムカメラアプリを起動して、追跡を開始します。

手を左に動かすと、左にパンするスタンドに注意してください。

そして、手を右に動かすと、スタンドは反対方向に続きます。

手を上に掃くと、スタンドが傾いて手をフレーム内に保ち、手を後ろに掃くときに再び続きます。

完璧。

DockKit APIを介してモーターを直接制御する機能により、アニメーションを通じてデバイスに命を吹き込むことができます!

ドックの動きは、確認のためのアフォーダンスとして、または感情を伝える方法として使用できます。

ダイレクトモーターコントロールを使用して独自のカスタムアニメーションを作成して、プッシュやプルなどの電話との物理的な相互作用をエミュレートしたり、組み込みのアニメーションの1つを活用したりできます。

内蔵のアニメーションは、Yes、No、Wakeup、Kapowです。

デバイスの起動が発生するたびに、ウェイクアップアニメーションが動作しているのを見ることができます。

先ほど実演したカスタムハンドトラッキングアプリに戻ると、特定のハンドジェスチャーが発生するといつでも組み込みアニメーションをトリガーできます。

これを行うには、まずカスタムハンドアクション分類モデルをトレーニングする必要があります。

これはCreate MLアプリを使って簡単にできます。

これらのモデルの1つを作成する方法の詳細については、2021年の「手のポーズとアクションを分類する」ビデオを必ずご覧ください。

カスタムモデルがハンドジェスチャーが発生したと予測するときはいつでも、アニメーションをトリガーできます。

最初にシステムトラッキングを無効にしてから、アニメーションを開始します。この場合は、Kapowです。

アニメーションはスタンドの現在の位置から始まり、非同期に実行されます。

アニメーションが実行されたら、システムトラッキングを再度有効にします。

さて、デモに戻って、動作を確認します。

私が少し後退するにつれて、アプリは私の手を追跡し続けます。

カメラを押しているというジェスチャーをしたら、カポウ!

カメラは振り子の動きで前後に揺れる。

それはとても楽しいので、もう一度やりましょう。

そしてカポウ!

このようなアニメーションを使用して、体験を終わらせたり、何かを表現したりすることができます。

これを試してみることをお勧めします。ぜひ、カスタムモーターコントロールを使用して独自のアニメーションを作成することを検討してください。

DockKitでは、電動スタンドを使用してオブジェクトを追跡する機能が導入され、アプリケーションに360度の視野を提供します。

オブジェクトは、システムレベルまたはカスタム推論を使用してアプリケーションで追跡できます。

そして、感情や実用性を伝えるためのアフォーダンスとして、アプリケーションで機械的な動きを使用することができます。

DockKitでカスタムトラッキングにVisionフレームワークを使用する方法の詳細については、動物のポーズの検出に関するビデオを必ず確認してください。

私はあなたがこれらの素晴らしいアクセサリーを手に入れ、あなたが1つを使用するときにあなたのアプリにもたらす経験を見るのが待ちきれません。