10048

♪ ♪

Adam: Chào mừng, tôi là Adam, một kỹ sư của VisionKit.

Tôi rất vui được dành thời gian với bạn hôm nay để nói về các tính năng mới và API mà nhóm đã làm việc trong năm nay.

Tóm lại, năm ngoái hỗ trợ Live Text đã được thêm vào VisionKit, cho phép các tương tác như lựa chọn văn bản, dịch, hỗ trợ QR và hơn thế nữa cho hình ảnh trong ứng dụng của bạn.

VisionKit cũng giới thiệu DataScannerViewController, Máy quét dữ liệu sử dụng nguồn cấp dữ liệu camera trực tiếp cung cấp một cách đơn giản và đầy đủ tính năng để chụp các loại văn bản cụ thể, cũng như nhiều biến thể của mã có thể đọc được bằng máy.

Thông tin về các API đó được bao gồm trong các phiên WWDC22 này.

Phản hồi từ các nhà phát triển thật tuyệt vời và năm nay tôi vui mừng thông báo VisionKit đang bổ sung hỗ trợ cho cả Nâng đối tượng và Tra cứu trực quan.

Ngoài ra còn có API Văn bản Trực tiếp mới để lựa chọn văn bản, hỗ trợ nền tảng mở rộng cho Catalyst và tích hợp menu ngữ cảnh cho các ứng dụng macOS gốc.

Và bây giờ tôi sẽ bắt đầu với Nâng Chủ đề.

Với một lần nhấn và giữ đơn giản vào chủ đề của một hình ảnh, nó sẽ nâng nó lên khỏi môi trường xung quanh và trở nên nổi bật với ánh sáng hoạt hình tuyệt đẹp này, và sau đó tôi được cung cấp một số tùy chọn để chia sẻ nó hoặc gọi Visual Look Up.

Mới cho iOS 17, giờ đây bạn có thể sử dụng bất kỳ chủ đề nào được nâng lên để tạo nhãn dán, với các hiệu ứng thú vị như sáng bóng, sưng húp và hơn thế nữa để chia sẻ với bạn bè và gia đình của bạn.

Bây giờ tin tốt là, việc tích hợp Nâng môn học rất đơn giản.

Trên thực tế, rất có thể bạn đã hoàn thành.

Đây là cùng một đoạn mã từ video năm ngoái, nơi tôi phân tích một hình ảnh và đặt nó trên tương tác.

Nhưng bây giờ, nó hỗ trợ Nâng Chủ đề, mà không có bất kỳ mã nào thay đổi.

Hãy cùng khám phá thêm.

Lưu ý rằng tôi sẽ không chuyển bất cứ điều gì đặc biệt vào cấu hình máy phân tích.

Điều này là do để duy trì sức mạnh và hiệu suất, phân tích Nâng đối tượng được xử lý riêng biệt bằng cách tương tác sau khi phân tích ban đầu hoàn tất.

Đối với iOS, quá trình này xảy ra sau khi nó xuất hiện trên màn hình trong vài giây và đối với macOS, nó sẽ xảy ra lần đầu tiên menu xuất hiện.

Điều này có nghĩa là bạn không cần phải xử lý trường hợp người dùng vuốt qua nhiều ảnh.

Sự tương tác sẽ xử lý việc này cho bạn.

Tất cả những gì bạn cần làm là đảm bảo bạn có một bộ loại tương tác thích hợp - trong trường hợp này là tự động - và phần còn lại được xử lý bởi tương tác.

Hãy kiểm tra các loại tương tác tương thích Nâng chủ đề gần hơn một chút.

Tự động cung cấp trải nghiệm mặc định, kết hợp tương tác văn bản, Nâng chủ đề và hơn thế nữa.

Nếu bạn chỉ muốn Nâng chủ đề, chứ không phải lựa chọn văn bản hoặc máy dò dữ liệu, bạn có thể đặt loại tương tác thành .imageSegmentation hoặc kết hợp nó với các loại khác.

Và cuối cùng, nếu Nâng chủ đề không có ý nghĩa đối với ứng dụng của bạn, nhưng bạn muốn hành vi tự động trước đó từ iOS 16, không vấn đề gì, bạn có thể sử dụng một loại mới, .automaticTextOnly.

Điều này cung cấp các tính năng như lựa chọn văn bản và máy dò dữ liệu, nhưng không cung cấp chủ đề.

Chúng tôi có một phiên chi tiết cụ thể về Nâng môn học có sẵn nếu bạn muốn tìm hiểu các chủ đề nâng cao về công nghệ mới tuyệt vời này trong cả VisionKit và Vision.

Năm nay VisionKit cũng hỗ trợ Visual Look Up.

Visual Look Up cho phép người dùng dễ dàng xác định và tìm hiểu về vật nuôi, thiên nhiên, địa danh, nghệ thuật và phương tiện truyền thông.

Và trong iOS 17, Visual Look Up sẽ hỗ trợ các miền bổ sung, bao gồm thực phẩm, sản phẩm, bảng hiệu và biểu tượng.

Bây giờ, cuối cùng, thật dễ dàng để tra cứu ý nghĩa của những biểu tượng đó trên thẻ giặt ủi của bạn.

Ý tôi là, điều đó khá tuyệt nếu bạn hỏi tôi.

Tính khả dụng của Visual Look Up dựa trên ngôn ngữ và có sẵn cho các ngôn ngữ này.

Hãy cùng xem nhanh dưới mui xe và khám phá cách Visual Look Up hoạt động.

Nó thực sự là một quá trình gồm hai phần.

Quá trình xử lý ban đầu được thực hiện hoàn toàn trên thiết bị tại thời điểm phân tích.

Nếu loại .visualLookUp có trong cấu hình máy phân tích, Visual Look Up sẽ xác định vị trí hộp giới hạn của kết quả và miền cấp cao nhất của chúng.

Ví dụ, nếu đó là một con mèo, cuốn sách hoặc thực vật.

Bước này cũng bao gồm trích xuất tính năng.

Khi người dùng yêu cầu tra cứu một đối tượng, sau đó, và chỉ sau đó, miền và hình ảnh nhúng từ trích xuất tính năng được gửi đến máy chủ để xử lý bổ sung.

Bây giờ bạn đã biết Visual Look Up hoạt động như thế nào, hãy nhanh chóng khám phá cách sử dụng nó và những hành động bạn cần thực hiện để thêm nó vào ứng dụng của mình.

Tra cứu trực quan có thể được gọi theo hai cách khác nhau.

Đầu tiên là kết hợp với Nâng chủ đề, nếu chủ đề nâng hiện tại chứa một và chỉ một kết quả Tra cứu trực quan tương quan, tùy chọn Tra cứu sẽ được cung cấp trong menu và chọn nó sẽ hiển thị kết quả Tra cứu đầy đủ.

VisionKit tự động xử lý tương tác này cho bạn.

Với tư cách là người chấp nhận, tất cả những gì bạn cần làm là thêm .visualLookUp vào cấu hình máy phân tích của bạn tại thời điểm phân tích.

Thứ hai, có một tương tác phương thức có sẵn trong đó các huy hiệu được đặt trên mỗi kết quả tìm kiếm trực quan.

Lưu ý cách các huy hiệu di chuyển đến góc nếu chúng rời khỏi khung nhìn, Người dùng có thể nhấn vào các huy hiệu này để hiển thị kết quả Tra cứu.

Ví dụ, đây là tương tác tương tự như nhấp vào nút thông tin trong ứng dụng Ảnh hoặc Xem nhanh.

Chế độ này được gọi bằng cách đặt .visualLookUp làm Loại Tương tác ưa thích trên tương tác của bạn.

Xin lưu ý: loại này sẽ được ưu tiên hơn các loại tương tác khác.

Ví dụ, bạn không thể chọn máy dò văn bản hoặc dữ liệu cùng lúc với Chế độ tra cứu trực quan được đặt.

Như vậy, điều này thường được sử dụng kết hợp với một nút hoặc một số cách đặt làm riêng khác để vào và ra khỏi chế độ này.

Ví dụ, Quick Look sử dụng nút thông tin để vào chế độ Visual Look Up.

Bây giờ hãy chuyển số và thảo luận về API và các tính năng mới cho Máy quét dữ liệu cũng như Văn bản trực tiếp.

Được giới thiệu trong iOS 16, DataScannerViewController được thiết kế để trở thành cách dễ nhất để sử dụng OCR với kính ngắm camera trực tiếp.

Trong iOS 17, nó đã được cải tiến với tính năng theo dõi luồng quang học cũng như hỗ trợ tiền tệ.

Theo dõi luồng quang học có thể tăng cường theo dõi văn bản cho trải nghiệm camera trực tiếp.

Đây là những gì chúng tôi có trong iOS 16.

Tôi đang quét văn bản với tính năng highFrameRateTracking được bật.

Và đây là những gì bạn sẽ nhận được với theo dõi dòng chảy quang học.

Bây giờ những điểm nổi bật cảm thấy ổn định và có căn cứ hơn nhiều so với trước đây.

Theo dõi luồng quang học đến miễn phí bất cứ khi nào bạn sử dụng DataScannerViewController, tuy nhiên, nó chỉ khả dụng khi nhận dạng văn bản chứ không phải mã có thể đọc được bằng máy.

Và bạn cũng được yêu cầu quét văn bản mà không cần đặt loại nội dung văn bản cụ thể.

Và cuối cùng, một lần nữa, đảm bảo theo dõi tốc độ khung hình cao được bật.

Đó là, thuận tiện, mặc định.

Bất kể bạn định cấu hình nó như thế nào, máy quét dữ liệu cung cấp theo dõi văn bản tuyệt vời; nhưng nếu trường hợp sử dụng của bạn cho phép cấu hình này, theo dõi luồng quang học mới có thể nâng cao nó hơn nữa.

Tiếp theo, trình quét dữ liệu có một tùy chọn mới cho phép người dùng tìm và tương tác với các giá trị tiền tệ.

Nó cực kỳ đơn giản để kích hoạt.

Chỉ cần đặt loại nội dung văn bản thành tiền tệ khi chỉ định nhận dạng văn bản trong trình khởi tạo của trình quét dữ liệu, giống như bạn làm với các loại nội dung khác như địa chỉ email hoặc số điện thoại.

Bây giờ tôi sẽ khám phá loại mới này chi tiết hơn với một ví dụ nhanh.

Khi trình quét dữ liệu nhận ra tiền tệ trong văn bản, nó chứa cả giới hạn và bảng điểm.

Bảng điểm có cả ký hiệu tiền tệ và số tiền.

Đây là một ví dụ mà tôi tìm thấy tổng của tất cả các giá trị trên một cái gì đó giống như biên lai.

Đầu tiên, tôi nhận được ký hiệu tiền tệ bằng cách sử dụng ngôn ngữ hiện tại.

Trong khi chờ kết quả của máy quét dữ liệu trong luồng Mục được nhận dạng, tôi có thể lặp qua từng mục được nhận dạng và lấy bảng điểm của nó.

Nếu bảng điểm chứa ký hiệu tiền tệ mà tôi quan tâm, tôi sẽ tiếp tục và cập nhật tổng giá trị.

Và cứ như vậy, bây giờ bạn sẽ có tổng của tất cả các giá trị.

Đây chỉ là một ví dụ đơn giản, nhưng điều này có thể rất mạnh mẽ, tôi rất vui khi thấy những gì bạn có thể xây dựng với điều này.

Và bây giờ tôi sẽ nói về những cải tiến cho Live Text.

Trước hết, Live Text đang đến nhiều khu vực hơn bằng cách mở rộng các ngôn ngữ được hỗ trợ của chúng tôi để bao gồm tiếng Thái và tiếng Việt.

Văn bản trực tiếp bao gồm các cải tiến để phát hiện cấu trúc tài liệu trong năm nay.

Phát hiện cấu trúc tài liệu? Điều đó thậm chí có nghĩa là gì?

Chà, ví dụ, trong iOS 16 Live Text hỗ trợ phát hiện danh sách.

Điều này cho phép bạn dễ dàng sao chép và dán danh sách vào một ứng dụng hiểu danh sách, chẳng hạn như Ghi chú và định dạng danh sách sẽ được duy trì.

Văn bản trực tiếp xử lý một số kiểu danh sách, chẳng hạn như số hoặc dấu đầu dòng.

Và bây giờ, Live Text đang cung cấp hỗ trợ tương tự cho Bảng, giúp việc lấy dữ liệu bảng có cấu trúc từ một hình ảnh vào các ứng dụng như Ghi chú hoặc Số trở nên dễ dàng hơn nhiều.

Bây giờ tôi có thể chọn, sao chép và dán bảng này vào Numbers, và cấu trúc được duy trì.

Chú ý cách nó tự động hợp nhất các ô nếu cần thiết.

Và cứ như vậy, bây giờ tôi chỉ còn vài cú nhấp chuột nữa để hình dung thông tin này trong một biểu đồ.

Tốt.

Và đó không phải là tất cả.

Chúng tôi cũng đang thêm Trình phát hiện dữ liệu nhận biết ngữ cảnh trong Văn bản trực tiếp.

Đối với tính năng này, máy dò dữ liệu và các mối quan hệ trực quan của chúng được sử dụng khi thêm danh bạ.

Lưu ý cách khi tôi thêm liên hệ này từ địa chỉ email, thông tin bổ sung từ các máy dò dữ liệu xung quanh hiện đã được bao gồm, cho phép tôi dễ dàng thêm tất cả thông tin này cùng một lúc.

Thêm một liên hệ từ danh thiếp hoặc tờ rơi chưa bao giờ dễ dàng hơn thế.

Ngoài những tính năng tuyệt vời này mà bạn cũng nhận được miễn phí, VisionKit cũng có một số API mới dành riêng cho văn bản.

Năm ngoái, bạn có thể nhận được toàn bộ nội dung văn bản bằng cách truy cập thuộc tính bảng điểm trên phân tích hình ảnh.

Dựa trên phản hồi của bạn, giờ đây bạn có toàn quyền truy cập vào văn bản thuần túy và được gán, phạm vi đã chọn và dễ dàng truy cập vào văn bản đã chọn.

Ngoài ra còn có một phương pháp đại diện mới để bạn có thể biết khi nào lựa chọn văn bản thay đổi và cập nhật giao diện người dùng của bạn khi thích hợp.

Giờ đây, thật dễ dàng để thêm các tính năng dựa trên những gì người dùng đã chọn.

Ví dụ: sử dụng API trình tạo menu, bạn có thể chèn một mục trình đơn tạo lời nhắc dựa trên lựa chọn văn bản hiện tại.

Bắt đầu trong bộ điều khiển chế độ xem sở hữu tương tác phân tích hình ảnh của bạn.

Đầu tiên lấy văn bản đã chọn và đảm bảo nó không trống.

Sau đó tạo một lệnh gọi trình xử lý của chúng tôi khi được chọn, Bây giờ hãy tạo một đối tượng menu giữ lệnh.

Và cuối cùng, chèn menu đó làm anh chị em sau tùy chọn menu chia sẻ.

Bây giờ bạn có một menu tùy chỉnh cùng với các mục hệ thống như sao chép và chia sẻ.

Bây giờ tôi sẽ nói về sự hỗ trợ nền tảng mở rộng của chúng tôi.

Và năm nay, đó là tất cả về Mac.

Chúng tôi đang triển khai hỗ trợ Catalyst để dễ dàng đưa Live Text từ các ứng dụng iOS của bạn lên Mac.

Và nếu bạn chưa quen với macOS API gốc và ImageAnalysisOverlayView, hãy theo dõi, bởi vì tôi sẽ xem xét một số chi tiết cụ thể, cũng như một số mẹo áp dụng chúng.

Cuối cùng, tôi sẽ nói về một hệ thống mới cho các menu, cung cấp khả dụng tích hợp VisionKit đơn giản và liền mạch vào các menu theo ngữ cảnh của bạn.

Việc áp dụng chất xúc tác rất đơn giản.

Nó phải là một bản biên dịch lại đơn giản để làm cho tương tác phân tích hình ảnh hoạt động trong Catalyst.

Chúng tôi hỗ trợ, Văn bản trực tiếp, Nâng chủ đề và Tra cứu trực quan, nhưng tiếc là hỗ trợ mã QR không khả dụng trong môi trường Catalyst hoặc macOS API gốc cho VisionKit.

Tuy nhiên, tôi muốn cho bạn biết rằng nếu bạn có một triển khai được chia sẻ, việc để .machineReadableCodes trong cấu hình máy phân tích của bạn cho Catalyst là hoàn toàn an toàn và chỉ trở thành một điều không hoạt động.

Ngoài ra, xin lưu ý rằng hỗ trợ phát hiện QR có sẵn trong Vision Framework nếu bạn cần chức năng này trên Mac.

Bây giờ tôi đang chuyển sang API macOS gốc.

Như với iOS, có hai lớp chính bạn cần lưu ý khi áp dụng VisionKit: ImageAnalyzer và ImageAnalysisOverlayView.

Đầu tiên, phần dễ dàng.

Quá trình phân tích và phân tích hình ảnh cho Mac giống hệt với iOS.

Ngoại trừ các mã có thể đọc được bằng máy là không hoạt động, như tôi đã đề cập trước đó, mọi thứ đều giống nhau và được sử dụng theo cùng một cách.

Sự khác biệt chính giữa iOS ImageAnalysisInteraction và ImageAnalysisOverlayView của macOS là cách tương tác được thêm vào ứng dụng của bạn.

Đối với iOS, ImageAnalysisInteraction là một UIInteraction được thêm vào chế độ xem, đã tồn tại trong hệ thống phân cấp chế độ xem ứng dụng của bạn.

Nhưng UIInteraction không tồn tại trên Mac.

Vậy bạn làm gì?

Trong trường hợp này, như tên cho thấy, chế độ xem lớp phủ phân tích hình ảnh là một lớp con của NSView.

Tôi chỉ cần thêm chế độ xem lớp phủ trong hệ thống phân cấp chế độ xem phía trên nội dung hình ảnh của mình.

Tôi có thể thêm nó, ví dụ, ở đây.

Hoặc thậm chí ở đây.

Nhưng cách đơn giản nhất là thêm nó dưới dạng chế độ xem phụ của chế độ xem nội dung của tôi.

Bất kỳ cách nào bạn chọn đều hoàn toàn ổn, nhưng tôi thấy việc thêm nó dưới dạng Chế độ xem phụ nói chung đơn giản hơn và dễ quản lý hơn vì bạn không phải xử lý việc định vị lại chế độ xem lớp phủ khi vị trí chế độ xem nội dung thay đổi.

Và bây giờ bạn đã biết cách và nơi để thêm nó vào ứng dụng của mình, Hãy nói về hình chữ nhật.

Vì OverlayView không lưu trữ hoặc hiển thị nội dung của bạn, nó cần biết chính xác nội dung tồn tại ở đâu liên quan đến giới hạn của nó.

Điều này được mô tả bởi contentsRect, nằm trong không gian tọa độ đơn vị với điểm gốc ở trên cùng bên trái.

Chà, đó là một ngụm.

Một ví dụ nhanh sẽ giúp làm rõ điều này.

Vì chế độ xem lớp phủ được đặt trực tiếp trên imageView, chúng có cùng giới hạn.

Tôi sẽ hiển thị các giới hạn với hình chữ nhật này.

Và tôi cũng sẽ thêm nội dung phù hợp của nó trực tràng.

Trường hợp dễ nhất là nếu nội dung khớp với giới hạn.

Ở đây nó chỉ đơn giản là hình chữ nhật đơn vị.

Bây giờ, đây là một khía cạnh phù hợp.

Lưu ý rằng phần này của imageView hiện không có nội dung bên dưới nó.

Và được phản ánh trong nội dung trực tiếp.

Và đây là một khía cạnh lấp đầy.

Phần này của hình ảnh không còn hiển thị với người dùng nữa, Lưu ý nội dung rect thay đổi như thế nào ở đây.

Bây giờ, một số tin tốt.

Cũng giống như với UIImageView trên iOS, nếu bạn đang sử dụng NSImageView, bạn có thể chỉ cần đặt thuộc tính trackingImageView trên chế độ xem lớp phủ và nó sẽ tự động tính toán tất cả những điều này cho bạn.

Nếu bạn không sử dụng NSImageView, đừng lo lắng.

Bạn có thể cung cấp nội dung rect bằng cách triển khai phương thức đại diện contentsRect(cho overlayView:) Chế độ xem lớp phủ sẽ yêu cầu điều này trong khi bố cục khi giới hạn của nó thay đổi.

Tuy nhiên, bạn có thể yêu cầu cập nhật thủ công điều này bằng cách gọi setContentsRectNeedsUpdate trên overlayView.

Được rồi, hãy chuyển sang các menu theo ngữ cảnh.

Như tôi chắc chắn rằng tất cả các bạn đều biết, các menu theo ngữ cảnh là một phần rất lớn trong trải nghiệm Mac.

Giờ đây, thật dễ dàng để thêm chức năng được cung cấp của VisionKit trực tiếp vào menu của bạn, cho các tính năng như Văn bản trực tiếp, Tra cứu và Nâng chủ đề, v.v.

Một câu hỏi bạn có thể có là, tại sao?

Hãy kiểm tra ứng dụng macOS Photos.

Nếu tôi nhấp chuột phải vào văn bản cho biển báo đường mang tính biểu tượng này, tôi sẽ chỉ được trình bày với menu văn bản VisionKit.

Nếu nó không phải là qua văn bản, thay vào đó tôi sẽ được cung cấp menu ứng dụng mà không có bất kỳ mục văn bản nào.

Điều này không lý tưởng.

Bây giờ trong macOS Sonoma, các mục có thể được kết hợp vào cùng một menu.

Bạn có thể dễ dàng truy cập cả chức năng văn bản và hình ảnh, bất kể sự kiện menu được bắt đầu ở đâu.

Đây là một trải nghiệm tốt hơn nhiều cho người dùng và rất đơn giản để thực hiện.

Hãy cùng khám phá cách điều này có thể được thực hiện trong ứng dụng của riêng bạn.

Bây giờ bạn có sẵn một phương thức đại diện mới, overlayview:updatedmenu:forevent:atpoint.

Các đối số bao gồm sự kiện đã kích hoạt menu và điểm trong giới hạn chế độ xem lớp phủ tọa độ không gian, vì vậy bạn có thể tạo bất kỳ menu nào bạn cần.

Từ đó, bạn chỉ cần quay lại menu mà bạn muốn hiển thị.

Việc triển khai mặc định trả về menu VisionKit.

Tuy nhiên, bạn có thể muốn thêm các mục của riêng mình vào menu đó hoặc lấy các mục từ menu đó và thêm nó vào menu của bạn.

Các mục menu VisionKit được xác định bằng các thẻ và có một cấu trúc có sẵn chứa các thẻ này.

Chúng tôi có sẵn một số mục để sao chép và chia sẻ hình ảnh và đối tượng, và một mục để Tra cứu.

Chúng tôi cũng có một mục đặc biệt mà bạn có thể sử dụng để tìm chỉ mục được đề xuất để thêm các mục vào menu được cung cấp bởi VisionKit, nhưng nhiều hơn về điều đó sau.

Đây là một số ví dụ về cách sử dụng cái này.

Nếu tôi có một menu hiện có và tất cả những gì tôi quan tâm là thêm mục copySubject, nó có thể dễ dàng được thêm vào như thế này.

Đầu tiên, lấy menu ứng dụng của bạn.

Sau đó lấy mặt hàng mà bạn quan tâm.

Trong trường hợp này, copySubject.

Và chèn nó vào thực đơn của bạn.

Bây giờ, điều quan trọng cần nhớ là các Mặt hàng sẽ chỉ có sẵn nếu chúng thực sự hợp lệ.

Ví dụ, nếu không có loại tương tác chủ đề nào có khả năng hiện diện, mục copySubject sẽ không có trong menu.

Ngoài ra, đối với các mục văn bản do hệ thống cung cấp, chúng được bao gồm nếu có, nhưng không phải tất cả đều có thể nhận dạng bằng thẻ.

Bạn thậm chí có thể tùy chỉnh những mặt hàng này theo cách bạn muốn.

Ví dụ, tôi đã thay đổi mục từ sao chép hình ảnh sang sao chép ảnh.

Và đừng lo lắng về việc thay đổi những thuộc tính này.

Những mục này được tạo lại mỗi lần và bạn có thể thay đổi chúng theo cách bạn muốn.

Bây giờ tôi đã đề cập đến việc thêm các mục vào menu hiện tại của bạn, tôi sẽ khám phá một ví dụ về cách thêm các mục vào menu VisionKit.

Như đã đề cập trước đó, overlayView sẽ cung cấp một mục có thẻ tại chỉ mục được đề xuất để chèn các mục của bạn được gọi là recommendedAppItems.

Bạn chỉ cần yêu cầu chỉ mục của mặt hàng này và chèn các mặt hàng của bạn vào chỉ mục đó.

Sử dụng chỉ mục này là tùy chọn và không bắt buộc.

Tuy nhiên, đó là một cách tốt để giữ mọi thứ nhất quán cho người dùng của bạn.

Bạn sẽ nhận thấy rằng một số mục trong thực đơn này có các thuộc tính đặc biệt.

Ví dụ, khi mục menu liên quan đến chủ đề được tô sáng, khu vực xung quanh con mèo KiKi của tôi ở đây mờ đi và hoạt ảnh phát sáng bắt đầu, chỉ ra chủ đề cho người dùng trước khi nó được sao chép hoặc chia sẻ.

VisionKit sử dụng menu xuất hiện như một trình kích hoạt để bắt đầu phân tích chủ đề, nếu nó chưa bắt đầu.

Tất cả điều này được xử lý tự động cho bạn.

Để cung cấp các tính năng này, VisionKit sẽ tự đặt làm đại diện cho bất kỳ menu nào bạn trả về từ phương thức menu cập nhật.

Nếu trước đây bạn đã dựa vào các cuộc gọi lại NSMenuDelegate này, VisionKit hiện cung cấp các cuộc gọi lại Delegate của riêng mình cho phép bạn giữ lại chức năng với các mục menu của mình nếu bạn đã sử dụng nó trước đây.

Và đây là một mẹo nhanh.

Nếu bạn đang ở trong tình huống này, tùy thuộc vào nơi menu được bắt đầu, nó có thể không đến từ VisionKit.

Vì vậy, bạn có thể sẽ muốn giữ việc triển khai hiện tại của mình.

Nói chung, cách đơn giản nhất để giữ cho tất cả điều này đồng bộ là yêu cầu triển khai OverlayViewDelegate của bạn gọi triển khai NSMenuDelegate phù hợp của bạn, điều chỉnh khi cần thiết.

Tất nhiên, hãy đảm bảo điều này có ý nghĩa đối với ứng dụng của bạn, nhưng nói chung, điều này thường thực hiện thủ thuật.

Và đó là tổng quan nhanh về những gì mới trong VisionKit.

Tôi rất hân hạnh được dành thời gian với bạn hôm nay để thảo luận về Nâng chủ đề và Tra cứu trực quan, cũng như các API macOS mới của chúng tôi và thông tin liên quan.

Tôi rất mong được nghe cách bạn sử dụng những khả năng mới này để làm hài lòng và gây bất ngờ cho khách hàng của mình.

Và nghiêm túc mà nói, như mọi khi, hãy vui vẻ!

Cảm ơn bạn!