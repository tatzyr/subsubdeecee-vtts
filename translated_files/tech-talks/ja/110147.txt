110147

ピエール・モーフ：AppleシリコンゲームのCPUジョブスケジューリングを調整する方法に関するセッションへようこそ。

私はピエール・モーフで、メタルエコシステムチームで働いています。

私は、いくつかのサードパーティの開発者がAppleプラットフォームでGPUとCPUのワークロードを最適化するのを支援してきました。

CoreOSチームの助けを借りて、ゲームでより良いCPUパフォーマンスと効率を達成するための情報とガイドラインをここに集めました。

私たちはゲームに焦点を当てています。なぜなら、彼らは通常、ハードウェアリソースの面で非常に要求が高いからです。

また、彼らの典型的なワークロードでは、すべてのフレームで数千ではないにしても数百のCPUジョブを処理する必要があります。

16ミリ秒以下でそれらを行うには、ジョブを最大CPUスループットに合わせて調整し、提出オーバーヘッドを最小限に抑える必要があります。

まず、AppleシリコンCPUとそのユニークなアーキテクチャの概要を説明します。

次に、CPU効率を最大化するために作業を整理する方法に関する基本的なガイダンスを提供します。

最後に、これらのガイドラインが実装されたら、活用するための有用なAPIについて説明します。

AppleのCPUアーキテクチャから始めましょう。

アップルは10年以上にわたって独自のチップを設計してきた。

それらはAppleデバイスの中核です。

Appleシリコンは、高いパフォーマンスと比類のない効率を提供します。

昨年、AppleはM1チップを導入した。

これは、Macコンピュータで利用可能になった最初のAppleシリコンチップでした。

そして今年は...

...M1 ProとM1 Maxを導入しました。

彼らの新しいデザインは、Appleシリコンにとって大きな飛躍であり、非常に要求の厳しいワークロードに効率的に取り組むことができます。

M1チップは、多くのコンポーネントを1つのパッケージに集めます。

CPU、GPU、ニューラルエンジンなどが含まれています。

また、高帯域幅、低遅延のユニファイドメモリも備えており、Apple Fabricを通じてすべてのチップコンポーネントにアクセスできます。

つまり、CPUとGPUはコピーせずに同じデータで動作する可能性があります。

CPUにズームインしましょう。

M1では、CPUにはパフォーマンスコアと効率コアの2つの異なるタイプのコアが含まれています。

それらは物理的に異なり、Eコアは小さくなっています。

効率コアは、非常に低いエネルギー消費で作業を処理することを目的としています。

非常に重要なポイントがあります。PコアとEコアは同様のマイクロアーキテクチャを使用しており、これは本当に彼らの内部作業です。

これらは、開発者がスレッドがPコアまたはEコアで動作するかどうかを気にする必要がないように設計されています。

プログラムがコアの種類でうまく機能するように最適化されている場合、もう一方ではうまく機能することが期待されます。

これらのコアは、少なくともそのタイプに応じて、物理的にクラスターにグループ化されます。

M1では、各クラスターには最後のレベルのキャッシュ（L2）があり、すべてのコアで共有されています。

クロスクラスター通信はApple Fabricを経由します。

ここに示されているCPUトポロジは、M1チップに固有のものです。

他のデバイスはCPUレイアウトが異なる場合があります。

たとえば、iPhone XSには、2つのPコアの1つのクラスターと4つのEコアの1つのクラスターがあります。

このアーキテクチャにより、システムは必要に応じてパフォーマンスを最適化したり、代わりに効率を最適化したりして、パフォーマンスが優先事項ではないときにバッテリー寿命を向上させることができます。

各クラスターは、現在のワークロード、そのクラスターの現在の熱圧力、およびその他の要因に応じて、独立してアクティブ化されるか、カーネルのスケジューラによって周波数が調整される場合があります。

最後に、Pコアの可用性は保証されていないことに注意してください。

システムは、重要な熱シナリオでそれらを利用できないようにする権利を留保します。

以下は、CPUと相互作用するさまざまなAPIレイヤーの概要です。

まず、XNUがあります - macOSとiOSを実行しているカーネルです。

それはスケジューラが住んでいる場所であり、CPUで何がいつ実行されるかを決定します。

その上、pthreadsを持つPOSIXとMachオブジェクトの2つのライブラリがあります。

どちらも、アプリケーションに基本的なスレッドと同期プリミティブを提供します。

その上、私たちはより高いレベルのライブラリを持っています。

スレッド関連のNSObjectsはPOSIXハンドルをカプセル化します。

例えば、NSLockはpthread_mutex_lockをカプセル化し、NSThreadはとりわけpthreadをカプセル化します。

そこはGCDが座っている場所でもあります。

GCDは高度なジョブマネージャーです。

後でカバーします。

このセッションでは、低レベルから始めて、API機能で仕上げます。

まず、CPUに最適なものと、スケジューラに置かれた作業負荷を軽くする方法に焦点を当てましょう。

これが私たちの基本的な効率ガイドラインになります。

それらは、ジョブマネージャーの実装に適用され、APIに依存しず、AppleシリコンとIntelベースのMacの両方を含む多くのプラットフォームに適用されます。

私たちが理想的な世界にいて、この仕事を持っていると想像してみましょう。

4つのコアに広げると、正確に4倍速く処理されるはずですよね?

残念ながら、それは実際のCPUではそれほど簡単ではありません。

多くの簿記作業が行われており、それぞれに実行時間がかかっています。

効率性のために覚えておくべき3つのコストがあるはずです。

コア1、2、3を見てください。

彼らは私たちの仕事を処理する前に何もしていませんでした。

まあ、CPUコアがかなり長い間何もすることがない場合、エネルギーを節約するためにアイドル状態になります。

そして、アイドルコアの再活性化には少し時間がかかります。

それが私たちの最初のコストであり、コアウェイクアップコストです。

ここに別のものがあります。

CPU作業は、最初にOSスケジューラによって開始されます。

次にどのプロセスとスレッドを実行するか、どのコアで実行するかを決定します。

その後、CPUコアはその実行コンテキストに切り替わります。

それをスケジューリングコストと呼びます。

さて、3番目と最後のタイプのコスト。

コア0で実行されているスレッドは、コア1、2、3で実行されているスレッドを考えてみましょう。

例えば、セマフォで。

そのシグナリングは瞬間的ではありません。

この間隔の間、カーネルはどのスレッドがプリミティブで待機しているかを特定する必要があります。スレッドがアクティブでなかった場合は、それをスケジュールする必要があります。

この遅延は同期レイテンシと呼ばれます。

これらのコストは、何らかの形で、ほとんどのCPUアーキテクチャに表示されます。

彼らは非常に、非常に短いので、それら自体は問題ではありません。

しかし、彼らが蓄積し、繰り返し頻繁に現れると、パフォーマンスヒットになる可能性があります。

それらの費用は実生活でどのように見えますか?

これは、M1で実行されているゲームの楽器の痕跡です。

そのゲームは問題のあるパターンを示し、そのフレームのほとんどを繰り返します。

非常に細かい粒度でジョブを並列化しようとします。

私たちはすでにそのタイムラインにたくさんズームしました。

あなたにアイデアを与えるために、そのセクションは18マイクロ秒しかかかりません。

そのCPUコアと、その2つのスレッドに焦点を当てましょう。

これらの2つのスレッドは並行して実行されていた可能性がありますが、同じコアで連続して実行されることになりました。

理由を見てみましょう。

彼らはお互いに非常に頻繁に同期します。

最初のものは、2番目のものが開始するように合図し、非常に迅速にそのピアが完了するのを待ちます。

2つ目は機能し始め、すぐに最初のものに信号を送り、その後すぐに待ちます。

このパターンは何度も繰り返されます。

ここでは2つの問題を見ることができます。第一に、同期プリミティブは非常に高い周波数で使用されます。

それは仕事を中断し、オーバーヘッドを導入します。

赤いセクションでオーバーヘッドが見えます。

第二に、アクティブな作業 - 青いセクション - は非常に短いです。

それは4マイクロ秒から20マイクロ秒の間しか持続しません。

この持続時間は非常に小さく、CPUコアを目覚めさせるのにかかる時間よりもかろうじて短いです。

これらの赤いセクションの間、OSスケジューラは主にCPUコアが起動するのを待っていました。

しかし、それが起こる直前に、スレッドがコアをブロックして解放します。

2番目のスレッドは、別のスレッドが目を覚ますのをもう少し待つのではなく、同じコアで実行されます。

これら2つのスレッドが並行して実行する小さな機会を失ったのは、その方法です。

この観察から、私たちはすでに2つのガイドラインを定義することができます。

まず、適切なジョブの粒度を選択します。

小さな仕事をより大きな仕事にマージすることで、それを達成することができます。

スレッドのスケジューリングには、何があっても少し時間がかかります。

ジョブが小さくなると、スケジューリングコストはスレッドのタイムラインの比較的大きな部分を占めます。

CPUは十分に活用されないだろう。

それどころか、より大きな仕事は、より長く実行することでスケジューリングコストを償却します。

30マイクロ秒の作業項目をたくさん提出するプロのアプリケーションを見て、それらをマージしたときのパフォーマンスを大幅に向上させました。

第二に、スレッドを活用する前に十分な作業を並べます。

これは、ほとんどの仕事を一度に準備することで、すべてのフレームで行うことができます。

シグナルを送信してスレッドを待つとき、それは通常、いくつかはCPUコアでスケジュールされ、いくつかはブロックされ、コアから移動されることを意味します。

それを何度も行うことはパフォーマンスの落とし穴です。

スレッドのスリープ解除と一時停止は、先ほど話したコストが増加します。

逆に、スレッドが中断することなくより多くのジョブを処理できるようにすると、同期ポイントが削除されます。

例として、ネストされたforループを扱う場合、より粗い粒度で外側を並列化する方がはるかに良い考えです。

これにより、内側のループは途切れません。

これにより、一貫性が向上し、キャッシュ使用率が向上し、全体的に同期ポイントが少なくなります。

より多くのスレッドを活用する前に、コストに見合う価値があるかどうかを判断してください。

それでは、別のゲームのトレースを見てみましょう。

それはiPhone XSで動いていた。

私たちはそれらのヘルパースレッドに焦点を当てます。

ここで同期の待ち時間を見ることができます。

これは、カーネルがそれらの異なるヘルパーに信号を送るのにかかった時間です。

ここには2つの問題があります。第一に、実際の作業は再び非常に小さく、約11マイクロ秒、特にオーバーヘッド全体と比較して

これらの仕事を統合すれば、よりエネルギー効率が高かったでしょう。

2番目の問題：その期間に、80の異なるスレッドが3つのコアにスケジュールされました。

ここでは、コンテキストスイッチ、アクティブな作業間の小さなギャップを見ることができます。

この例では、まだ問題ではありませんが、スレッドが増えると、コンテキストの切り替え時間が蓄積され、CPUのパフォーマンスを妨げる可能性があります。

典型的なゲームがフレームごとに少なくとも何百ものジョブを持っているとき、どのようにこれらの異なる種類のオーバーヘッドを最小限に抑えることができますか?

これを行う最善の方法は、ジョブプールを使用することです。

労働者の糸は、仕事の盗みを通してそれらを消費します。

スレッドのスケジューリングはカーネルによって行われます。時間がかかることがわかりました。

また、CPUはコンテキストの切り替えなどの作業も行う必要があります。

一方、ユーザースペースで新しい仕事を始める方がはるかに安いです。

一般的に、ワーカーはアトミックカウンターをデクリメントし、ジョブへのポインタをつかむだけです。

2番目のポイント：ワーカーを使用するとコンテキストスイッチの量が減るため、所定のスレッドとのやり取りは避けてください。

そして、彼らがより多くのジョブをつかむにつれて、あなたはすでにアクティブなコアですでにアクティブなスレッドを活用します。

最後に、プールを賢く使ってください。

列に並んでいる仕事にちょうど十分な労働者を起こしてください。

そして、前のルールはここでも当てはまります。ワーカースレッドを目覚めさせ、それを忙しく保つことを正当化するために、十分な作業が並んでいることを確認してください。

オーバーヘッドを削減しました。今、CPUサイクルを最大限に活用しなければなりません。

避けるべきパターンをいくつか紹介します。

忙しい待ち時間を避けてください。

彼らは、Pコアで何か有用なことをするのではなく、潜在的にPコアをロックします。

また、スケジューラがスレッドをEからPコアに昇格させるのを防ぎます。

また、エネルギーを無駄にし、不要な熱を生み出し、熱ヘッドルームを食い尽くしています。

第二に、イールド関数の定義は、プラットフォームやOS間で緩いです。

Appleのプラットフォームでは、「私が実行しているコアをシステム上の他のスレッド、その他のもの、優先順位が何であれ、譲渡してみてください」という意味です。

現在のスレッドの優先順位を効果的にゼロにします。

利回りには、システム定義の期間もあります。

それは非常に長いかもしれません - 最大10ミリ秒

第三に、睡眠の呼び出しも推奨されません。

特定のイベントを待つ方がはるかに効率的です。

また、Appleプラットフォームでは、sleep(0)は意味がなく、その呼び出しは破棄されることに注意してください。

これらのパターンは、一般的に、そもそも基本的なスケジューリングエラーが発生した兆候です。

代わりに、セマフォまたは条件付き変数で明示的な信号を待ちます。

最終ガイドライン：CPUコア数と一致するようにスレッド数をスケーリングします。

使用している各フレームワークやミドルウェアで新しいスレッドプールを再作成することは避けてください。

ワークロードに基づいてスレッド数をスケーリングしないでください。

ワークロードが劇的に増加すると、スレッドもカウントされます。

代わりに、CPU情報を照会してスレッドプールのサイズを適切に測定し、現在のシステムの並列化の機会を最大化します。

この情報を照会する方法を見てみましょう。

macOS MontereyとiOS 15以降、sysctlインターフェイスでCPUレイアウトに関する高度な詳細を照会できます。

すべてのCPUコアの全体的な数を取得することに加えて、マシンがnperflevelsで持っているコアの種類を照会できるようになりました。

M1には、PとEの2種類のコアがあります。

この範囲を使用して、コアタイプごとにデータを照会し、ゼロが最もパフォーマンスを発揮します。

たとえば、perflevel{N}.logicalcpuは、現在のCPUのPコアの数を示します。

これは単なる概要です。

また、同じL2を共有するコアの数など、他の多くの詳細を照会することもできます。

詳細については、sysctlのマニュアルページ、またはドキュメントのウェブページを参照してください。

CPU使用率をプロファイリングする場合、2つのインストゥルメントトラックが非常に便利です。

それらはゲームパフォーマンステンプレートで利用できます。

最初のシステム負荷は、CPUコアあたりのアクティブスレッド数を提供します。

2つ目はスレッドステートトレースです。

デフォルトでは、詳細ペインには、スレッド状態の変更の量とプロセスごとの期間が表示されます。

コンテキストスイッチビューに変更できます。

これにより、選択した時間範囲内のプロセスごとのコンテキストスイッチの数が表示されます。

コンテキストスイッチカウントは、アプリのスケジューリング効率を測定するのに便利な指標です。

このセクションを締めくくりましょう。

これらのガイドラインに従うことで、CPUを最大限に活用し、スケジューラがしなければならないことを合理化することができます。

小さくて小さなジョブを長時間実行するジョブに圧縮すると、キャッシュ、プリフェッチャー、予測などのマイクロアーキテクチャ機能の利点が高まります。

一度により多くのジョブを処理することは、割り込みレイテンシとコンテキストスイッチが少ないことを意味します。

適切にスケーリングされたスレッドプールにより、スケジューラはEコアとPコア間の作業の再調整が容易になります。

効率性とパフォーマンスのための重要なポイントは、ワークロードが広く狭くなる頻度を最小限に抑えることです。

それでは、これらのガイドラインを適用しながら活用できるAPIブロックについて調べてみましょう。

このセクションでは、優先順位付けとスケジューリングポリシー、同期プリミティブ、およびマルチスレッド時のメモリの考慮事項について説明します。

しかし、まずはGCDをのぞき見から始めましょう。

ジョブマネージャーがいなければ、または目指している高いパフォーマンスに達していない場合、GCDは素晴らしい選択です。

仕事を盗むことを使った汎用のジョブマネージャーです。

それはすべてのAppleプラットフォームとLinuxで利用可能で、オープンソースです。

このAPIは高度に最適化されています。

まず、それはすでにあなたのためのすべてのベストプラクティスに従います。

第二に、それはXNUカーネルに統合されています。

つまり、GCDは、現在の機械の放熱容量、P / Eコア比、現在の熱圧力など、内部の詳細を追跡する可能性があります。

そのインターフェースは、シリアルおよび同時ディスパッチキューに依存しています。

さまざまな優先順位で仕事をキューに入れることができます。

内部的には、各ディスパッチキューは、プライベートスレッドプールから可変量のスレッドを活用します。

その数は、キューの種類とジョブプロパティによって異なります。

この内部スレッドプールは、プロセス全体で共有されます。

つまり、特定のプロセスでは、複数のライブラリが新しいプールを再作成せずにGCDを使用できることを意味します。

GCDには多くの機能があります。

ここでは、それがどのように機能するかを理解するために、同時ディスパッチキューから2つの機能をすばやく確認します。

最初のpatch_asyncでは、関数ポインタとデータポインタで構成されたジョブをキューに入れることができます。

ジョブを開始するとき、次のジョブも処理する準備ができている場合、同時キューは追加のスレッドを活用する場合があります。

これは、典型的な非同期の独立したジョブに最適なオプションです。

しかし、大規模に並行する問題についてはそれほど多くはありません。

その場合、dispatch_applyがあります。

それは、GCDのスレッドマネージャーに過負荷をかけることなく、最初から多くのスレッドを活用します。

いくつかのプロアプリがdispatch_applyを使用するために並列に移行することでパフォーマンスを向上させるのを見てきました。

それはGCDの簡単な概要でした。

それと避けるべきパターンの詳細については、これら2つのWWDCセッションを参照してください。

それでは、カスタムジョブマネージャーに切り替えましょう。

スレッドを直接操作して同期する際に最も重要なポイントを取り上げます。

優先順位付けから始めましょう。

前のセクションでは、ジョブを提出する際のCPU効率を高める方法を確認しました。

しかし、これまでのところ、すべての仕事が平等ではないとは言っていませんでした。

いくつかは時間的に重要であり、その結果はできるだけ早く必要です。

そして、他のものは、次の1つか2つのフレームでのみ必要になります。

したがって、より重要なものにより多くのリソースを与えるために、仕事を処理するときに重要性の感覚を伝える必要があります。

これは、スレッドに優先順位を付けることで行うことができます。

正しいスレッドの優先順位を設定すると、ゲームがバックグラウンドアクティビティよりも重要であることをシステムに通知します。

これは、生のCPU優先値またはQoSクラスのいずれかでスレッドを設定することで実現できます。

どちらの概念も関連していますが、少し異なります。

生のCPU優先度は、計算スループットがどれほど重要であるかを示す整数値です。

Appleのプラットフォームでは、Linuxとは対照的に、これは上昇値であり、高ければ高いほど重要になります。

このCPUの優先順位は、他の要因の中でも、スレッドがPコアまたはEコアで実行されるべきかどうかを示唆しています。

さて、このCPUの優先順位は、スレッドが何をしているかについて意図を与えないため、残りのシステムリソースには影響しません。

代わりに、Quality of Service（略してQoS）でスレッドに優先順位を付けることができます。

QoSは、スレッドにセマンティクスをアタッチするように設計されています。

この意図は、スケジューラがタスクを実行するタイミングについてインテリジェントな決定を下すのに大いに役立ち、OSの応答性を高めます。

たとえば、エネルギーを節約するために、重要度の低いタスクが時間内にわずかに延期される可能性があります。

また、ネットワーク、ディスクアクセスなどのシステムリソースアクセスに優先順位を付けることもできます。

また、省エネ機能であるタイマー合体のためのしきい値も提供します。

QoSクラスには、CPUの優先順位も含まれます。

最も重要でないQOS_CLASS_BACKGROUNDから、最も高いQOS_CLASS_USER_INTERACTIVEまでの5つのQoSクラスがあります。

それぞれにデフォルトのCPU優先度が含まれています。

オプションで、限られた範囲内でわずかにダウングレードすることができます。

これは、同じQoSクラスにオプトインする複数のスレッドのCPU優先度を細かく微調整したい場合に便利です。

バックグラウンドクラスには細心の注意を払う必要があります。それを使用するスレッドは、非常に長い間まったく実行されない可能性があります。

したがって、全体として、ゲームは5から47の範囲のCPUの優先順位を使用します。

それが実際にどのように行われるか見てみましょう。

まず、デフォルト値でpthread属性を割り当てて初期化する必要があります。

次に、必要なQoSクラスを設定し、それらの属性をpthread_create関数に渡します。

属性構造を破壊して終了します。

QoSクラスを既存のスレッドに設定することもできます。

例として、その関数は呼び出しスレッドに影響します。

ここでは、-5のオフセットを使用し、クラスCPUの優先度を47から42にダウングレードしました。

関数名にnpサフィックスが表示されることに注意してください。

それは「nonportable」の略で、Appleプラットフォーム専用の機能に使用される命名規則です。

最後に、これらの関数を使用する代わりに、生のCPU優先値を直接設定する場合は、そのスレッドのQoSをオプトアウトすることに注意してください。

それは永続的であり、後でそのスレッドのQoSをオプトバックすることはできません。

iOSとmacOSは、ユーザー向けまたはバックグラウンドで実行されている多くのプロセスを処理します。

場合によっては、システムが過負荷になる可能性があります。

その場合、カーネルはすべてのスレッドがある時点で実行する機会を確保する方法が必要です。

それは優先減衰で行われます。

この特別なケースでは、カーネルは時間の経過とともにスレッドの優先順位をゆっくりと下げます。その後、すべてのスレッドが実行する機会があります。

優先減衰は、非常に特殊なケースでは問題になる可能性があります。

通常、ゲームには、メインスレッドやレンダリングスレッドなど、非常に重要なスレッドがいくつかあります。

レンダリングスレッドが先取りされると、プレゼンテーションウィンドウを見逃す可能性があり、ゲームが吃音になります。

そのような場合、スケジューリングポリシーで優先度減衰をオプトアウトできます。

デフォルトでは、SCHED_OTHERポリシーで作成されたaをスレッド化します。

これはタイムシェアリングポリシーです。

それを使用するスレッドは、優先順位の減衰の対象となる可能性があります。

また、以前に提示したQoSクラスとも互換性があります。

一方、オプションのSCHED_RRポリシーがあります。

RRは「ラウンドロビン」の略です。

それをオプトインするスレッドは、優先度の減衰の影響を受けない固定の優先度を持っています。

実行レイテンシの一貫性が向上します。

専用のレンダリングスレッドやフレームごとのワーカースレッドなど、一貫性のある周期的で優先度の高い作業専用に設計されています。

それをオプトインするスレッドは、非常に特定の時間枠で動作しなければならず、CPUの100%の時間を継続的に使用しないでください。

このポリシーを使用すると、他のスレッドの飢餓につながる可能性もあります。

最後に、このポリシーはQoSクラスと互換性がありません。スレッドは生のCPU優先度を使用する必要があります。

これはゲームスレッドの推奨レイアウトです。

まず、ゲーム内で何が優先度、中、低優先で、何がユーザーエクスペリエンスにとって重要かを定義します。

優先順位で作業を分割すると、アプリケーションのどの部分が最も重要かをシステムが知ることができます。

楽器を使用してゲームをプロファイリングし、実際に必要なスレッドに対してのみSCHED_RRにオプトインします。

また、複数のフレームを拡張して、長時間の作業にSCHED_RRを使用しないでください。

このような場合はQoSに依存して、システムが他のプロセスとパフォーマンスのバランスをとるのに役立ちます。

QoSを選択するもう1つの理由は、スレッドがGCDやNSOperationQueuesなどのAppleフレームワークと対話する場合です。

これらのフレームワークは、QoSクラスをジョブ発行者からジョブ自体に伝播しようとします。

発行スレッドがQoSを放棄した場合、それは明らかに無視されます。

優先順位に関連する最後の1つのポイントを取り上げましょう:優先順位の反転。

優先度反転は、優先度の高いスレッドが失速し、優先度の低いスレッドによってブロックされたときに発生します。

これは通常、相互の除外で起こります。

2つのスレッドが同じリソースにアクセスしようとし、同じロックを得るために戦います。

場合によっては、システムは優先度の低いスレッドをブーストすることで、この反転を解決できる場合があります。

それがどのように機能するか見てみましょう。

2つのスレッドを考えてみましょう。これが実行タイムラインです。

この例では、青いスレッドは優先度が低く、緑のスレッドは優先度が高いです。

真ん中にはロックタイムラインがあり、2つのスレッドのどちらがそのロックを所有するかを示しています。

青いスレッドが実行を開始し、ロックを取得します。

緑色の糸も始まります。

この時点で、緑色のスレッドは、現在青いスレッドが所有しているそのロックを取得しようとします。

緑色のスレッドがブロックされ、そのロックが再び利用可能になるのを待ちます。

この場合、ランタイムはどのスレッドがそのロックを所有しているかを知ることができます。

したがって、青いスレッドの低い優先度を高めることで、優先度の反転を解決できます。

どのプリミティブが優先度反転を解決する能力を持ち、どのプリミティブが解決できないか?

単一の既知の所有者を持つ対称プリミティブは、pthread_mutex_tや最も効率的なos_unfair_lockのように、それを行うことができます。

Pthread条件変数やdispatch_semaphoreのような非対称プリミティブは、ランタイムがどのスレッドがそれを通知するかを知らないため、この能力を持っていません。

同期プリミティブを選択するときは、この機能を念頭に置いて、相互に排他的なアクセスのために対称プリミティブを優先してください。

このセクションを終わらせるために、メモリに関するいくつかの推奨事項について話し合いましょう。

Objective-Cフレームワークと対話すると、一部のオブジェクトは自動リリースとして作成されます。

つまり、それらはリストに追加されるため、割り当て解除は後でのみ行われます。

オートリリースプールブロックは、そのようなオブジェクトを保持できる期間を制限するスコープです。

アプリのピークメモリフットプリントを効果的に削減するのに役立ちます。

すべてのスレッドエントリポイントに少なくとも1つの自動リリースプールを持つことが重要です。

スレッドが自動解放されたオブジェクト（たとえば、Metalを介して）を操作すると、メモリリークにつながります。

オートリリースプールブロックは、メモリがリサイクルされたときにより適切に制御するために、ネストすることができます。

レンダリングスレッドは、理想的には、繰り返されるフレームレンダリングルーチンの周りに2番目のスレッドを作成する必要があります。

ワーカースレッドは、アクティベーション時に開始し、ワーカーが駐車し、より多くの作業を待つときに閉じられる2番目のスレッドを持つ必要があります。

例を見てみましょう。

これはワーカースレッドのエントリポイントです。

それはすぐに自動リリースプールブロックから始まります。

その後、仕事が利用可能になるのを待ちます。

ワーカーがアクティブになると、新しい自動リリースプールブロックを追加し、ジョブを処理するときにそれを保持します。

スレッドが待って駐車しようとしているとき、私たちはネストされたプールを出ます。

結論として、記憶に関する1つの簡単なヒント。

パフォーマンスを向上させるために、複数のスレッドが同じキャッシュ行にあるデータを同時に書き込むことは避けてください。

それは「虚偽の共有」として知られています。

同じデータ構造からの複数の読み取りは問題ありませんが、このような競合する書き込みは、異なるハードウェアキャッシュ間のキャッシュラインのpingポンにつながります。

Appleシリコンでは、キャッシュ行の長さは128バイトです。

これに対する解決策の1つは、メモリの競合を減らすために、データ構造内にパディングを挿入することです。

この最後のセクションは終わりました。

締めくくりましょう。

私たちは最初にAppleのCPUアーキテクチャの概要と、その画期的なデザインがどのようにそれをはるかに効率的にするかについて説明しました。

次に、OSスケジューラに負荷をかけながら、CPUを効率的に供給し、スムーズに実行する方法に入りました。

最後に、スレッドの優先順位付け、スケジューリングポリシー、優先順位の反転、メモリに関するヒントなど、重要なAPIの概念をレビューしました。

パフォーマンスの問題を早期に発見できるように、作業負荷を監視するために、楽器でゲームを定期的にプロファイリングすることを忘れないでください。

ご清聴ありがとうございました。