608

Jaap van Muijden: A13 Bionicのメタルエンハンスメントへようこそ。

私の名前はAppleのGPUソフトウェアチームのJaap van Muijdenです。

今日は、A13 BionicでAppleが設計した最新のGPUと、それを可能にする新しいMetal機能を紹介します。

次に、これらの機能を使用してアプリのメモリ使用量を削減し、ランタイムのパフォーマンスを最適化する方法を紹介します。

新しいA13 Bionicは、一般的なパフォーマンス、最新のアプリの進化するニーズをよりよく満たすアーキテクチャの改善、高度なMetal機能の3つの主要な分野に焦点を当てることで、Appleが設計したGPUの急速な進化を続けています。

それぞれを見てみましょう。 

A13 BionicのGPUは、一般的なパフォーマンスにおいてA10 Fusionのほぼ3倍高速で、A11およびA12 Bionic GPUの優れたパフォーマンス向上に基づいています。

既存のアプリはA13でより速く実行され、より短い時間で各フレームを完了することができ、その結果、電力の節約とアプリの使用が延長されます。

Appleが設計したGPUアーキテクチャは、最新のアプリの要求をよりよく満たすために急速に進化しました。

A11以降、16ビットの浮動小数点とテクスチャリングレートが増加し、ゲームの一般的なボトルネックを緩和し、32ビットの浮動小数点演算の数値精度が向上し、高度なコンピューティングワークロードをより適切に処理しました。

A12 GPUは、メモリとの間でテクスチャコンテンツをロスレス圧縮および解凍することで、メモリ帯域幅を大幅に向上させます。

また、ユーザーインターフェイスをサポートするための専用ハードウェアを追加し、応答時間をさらに短縮するだけでなく、フォアグラウンドアプリへのUI要素の影響も軽減します。

また、A12以降のGPUは、アプリ間でリソースをより効率的に共有することで、iPadのエクスペリエンスを向上させます。

そして今、私たちはA13 GPUを持っています。

A13 GPUアーキテクチャは、16ビット浮動小数点演算の速度を2倍にし、ブラックレベルをよりよく保持する小さな16ビット数のサポートを追加することで、GPU上の高ダイナミックレンジコンテンツの処理を大幅に改善します。

A13 GPUはまた、レンダリングワークロードと同時に実行される独立したコンピューティング作業を大幅にサポートします。

Appleが設計したGPUは、A9以降、この非同期コンピューティング機能をサポートしてきましたが、A13 GPUは、より多くのハードウェアチャネルを追加し、より締め切りに敏感なレンダリングタスクへの影響を最小限に抑えることで、次のレベルに引き上げます。

A13の新しいメタル機能を説明する前に、A11とA12 GPUで導入された主要なメタル機能のいくつかを簡単に要約しましょう。

A11から始めましょう。

タイルシェーディング、イメージブロック、および永続的なスレッドグループメモリはすべて、Appleのタイルベースの遅延レンダリングアーキテクチャを明示的に活用し、多くの最新のレンダリング技術の帯域幅使用を最適化するために協力するように設計された機能です。

ラスタライズ注文グループを使用すると、GPU上の複雑なピクセル単位のデータ構造を管理でき、カラーレート制御は、高度なレンダリングアルゴリズムでのマルチサンプルアンチエイリアスの使用を最適化します。

そして今、A12に。

レイヤードレンダリングにより、各レンダリングされたプリミティブターゲットは2Dテクスチャ配列のユニークなスライスをターゲットにし、マルチビューポートレンダリングでは、各プリミティブは最大16のビューポートとシザー長方形で同じことを行うことができます。

ステンシルフィードバックにより、各フラグメントは高度なピクセルごとの効果に対して一意のステンシル参照値を設定できますが、ステンシルリゾル解決により、MSAAおよび非MSAAパス全体でステンシルバッファを再利用できます。

また、可能な限りロスレス圧縮はデフォルトで有効になっていますが、Metalは、最適なリードバックが必要な場合に、共有ストレージモードテクスチャのインプレース圧縮と解凍を直接制御することもできます。

それでは、A13 GPUをサポートする新しいApple GPUファミリー6を紹介しましょう。

スパーステクスチャは、各テクスチャの最も重要な領域を追跡し、それらの領域のみをメモリにマッピングすることにより、固定メモリ予算でオープンワールドゲームのより高品質のテクスチャストリーミングを可能にします。

ラスタライズレートマップは、最も重要な画像領域に高品質のラスタライズとシェーディングに焦点を当て、他の場所でレートを下げ、メモリとパフォーマンスの両方を節約します。

頂点増幅は、ジオメトリを共有する階層化されたレンダリングで発生する冗長な頂点処理を排除します。

GPU主導のパイプラインを使用すると、より大きく、より没入感のあるシーンを描くことができ、引数バッファティア2を使用すると、アプリはGPU主導のワークロードをこれまで以上に柔軟に実行できます。

SIMDグループの指示は、シェーディング中にSIMDグループのスレッド間の共有と同期を最適化します。

また、ASTC HDRは、高ダイナミックレンジのテクスチャに高品質の非可逆圧縮をもたらし、メモリと帯域幅を大幅に節約します。

まばらなテクスチャから始めて、これらのそれぞれをより詳細に見てみましょう。

スパーステクスチャは、A13 GPUに導入されたまったく新しい機能で、金属テクスチャのストレージとレジデンシーを細かい粒度で制御できます。

まばらなテクスチャはメモリに完全には常駐していません。

しかし、代わりに、スパースヒープと呼ばれる特別なメモリヒープにそれらのセクションを割り当てることができます。

ここでは、データの一部がそのようなスパースヒープに割り当てられている2つのスパーステクスチャを見ることができます。

1つのヒープは、多くのスパーステクスチャのストレージを提供でき、すべて事前に割り当てられた単一のメモリプールを共有します。

すべてのスパーステクスチャは、テクスチャ解像度やピクセル形式に関係なく同じメモリフットプリントを持つスパースタイルと呼ばれる単位に分割されます。

では、この機能の用途は何ですか?

そのうちの1つはテクスチャストリーミングです。

テクスチャストリーミングを使用すると、現在のビューに必要なテクスチャミップマップのみを読み込むことで、固定されたメモリフットプリントで信じられないほど大きなシーンをレンダリングできます。

従来のテクスチャストリーミングでは、個々のミップマップは必要なときにロードされ、不要になったとき、またはより重要なテクスチャがメモリを必要とするときに追い出されます。

テクスチャストリーミングは、伝統的にミップマップの粒度でテクスチャのレジデンシーを管理します。

より高品質のミップマップが要求された場合、ミップマップピラミッドの最低レベルは常駐しますが、まだストリーミングされていません。

読み込み操作が完了していないか、割り当てられたストリーミングメモリが不足しているため、まだ利用できない場合があります。

利用可能な最低レベルのミップマップを持つことで、低解像度であっても、サンプリングする有効なデータが常にあることが保証されます。

メタルのスパーステクスチャ機能は、このテクスチャストリーミングモデルを2つの方法で改善します。

まず、スパーステクスチャは、スパーステクスチャの各領域がアクセスされる頻度を決定するために使用できるテクスチャアクセスカウンタを提供します。

これにより、レンダラーがより頻繁にアクセスされる領域は、一般的に現在のビューでより表示されるため、テクスチャの読み込みに優先順位を付けることができます。

第二に、居住は、ミップマップの粒度ではなく、まばらなタイルの粒度で管理できます。

これにより、テクスチャメモリをさらに効率的にし、重要な場所でより目に見えるテクスチャの詳細が可能になります。

スパーステクスチャを組み合わせることで、同じメモリバジェットでより目に見えるディテールをストリーミングでき、品質が向上します。

では、Metalでスパーステクスチャを作成して使用する方法を見てみましょう。

スパーステクスチャの使用を開始するには、まずスパースヒープを作成し、そこから1つ以上のテクスチャを割り当てます。

新しいスパーステクスチャは、最初にマッピングされたスパースタイルなしで作成されます。

GPUを使用してヒープからメモリマッピングを要求する必要があります。

メモリは、仮想メモリページと同様に、スパースタイルと呼ばれるタイルサイズの単位でマッピングされます。

同様に、不要になったときにGPUにタイルのマッピングを解除するように要求する必要があります。

スパーステクスチャのサンプリングは、通常のテクスチャと同じように機能し、マッピングされていない領域のサンプリングはゼロを返します。

最後に、テクスチャアクセスカウンタは、スパーステクスチャから読み戻して、各タイルがアクセスされる頻度の見積もりを取得できるため、テクスチャのタイルをマッピングするときに正確に制御し、優先順位を付けることができます。

これらの各ステップをより詳細に見てみましょう。

ここでは、指定されたメモリサイズでまばらなテクスチャヒープを作成するメタルコードがあります。

まず、ヒープのサイズを計算し、それがまばらなタイルサイズの倍数であることを確認します。

ここでは、ローカルヘルパー関数を使用して、データサイズをスパースタイルサイズの最も近い倍数に切り上げます。

次に、スパースヒープ記述子を生成できます。ヒープタイプをスパースに設定し、ヒープのサイズをバイト単位で指定します。

次に、MTLDeviceオブジェクトを使用してスパースヒープを作成します。

まばらなテクスチャを作成するのはとても簡単です。

まず、通常どおりテクスチャ記述子を作成し、次にスパースヒープオブジェクトを使用してテクスチャを作成します。

スパーステクスチャを作成する方法を見たので、領域をメモリにマッピングする方法を見てみましょう。

テクスチャの領域のマッピングとアンマッピングは、リソース状態コマンドエンコーダでマップコマンドとアンマップコマンドをエンコードすることによって行われます。

このエンコーダは、Metalの他のレンダリングコマンドをエンコードするのと同様に、GPUタイムラインでマップ操作とマップ解除操作をスケジュールするために使用できます。

これがコードでどのように見えるか見てみましょう。

まず、エンコーダを作成します。

そして、単にマップ操作をエンコードします。テクスチャと、マッピングするテクスチャの領域、スライス、およびミップレベルを指定します。

領域がマッピングされ、マッピングされたメモリにテクスチャデータをブリットまたは作成できます。

セクションのマッピングを解除するには、同じ手順に従います。唯一の違いは、エンコードする更新のモードです。

テクスチャデータを作成してマッピングしたので、スパーステクスチャのサンプリングに移りましょう。

まばらなテクスチャからのサンプリングは、通常のテクスチャからのサンプリングと変わりません。

マッピングされていないセクションがアクセスされた場合には、明確に定義された動作があります。

マップされていない領域をサンプリングすると、ゼロのベクトルが返され、書き込みは破棄されます。

標準サンプリング機能に加えて、Metalは、マッピングされていない領域をテストするためにシェーダーで使用できるsparse_sample関数を提供します。

スパーステクスチャを作成、マッピング、サンプリングする方法を見たので、簡単な実装を見てみましょう。

スパーステクスチャを効率的にサンプリングする1つの方法は、フォールバックサンプリングを実行することです。

シェーダーでは、まず sparse_sampleメソッドを使用してテクセルを取得しようとすることができ、それが失敗した場合は、下位レベルのミップマップにフォールバックできます。

常に低いミップマップをロードしておくことで、有効なサンプルを見つけることが保証されます。

また、フォールバックサンプリングをよりよくサポートするために、メタルシェーディング言語は、min LODクランプと呼ばれるテクスチャメソッドに関する新しい議論もサポートしています。

最小LODクランプを使用すると、アクセスできるチェーンで最も高いミップマップを設定できます。

これにより、データがあることを知っている最高のミップマップを指定することで、有効なサンプルを保証できます。

それをコードで見てみましょう。

ここには、まばらなテクスチャからサンプリングするフラグメントシェーダーがあります。

Sparse_colorオブジェクトを返すsparse_sampleメソッドを使用して、スパーステクスチャのサンプリングを開始します。

その後、返されたオブジェクトの常駐メソッドを呼び出して、GPUがマッピングデータをサンプリングしたかどうかを判断できます。

もしそうなら、サンプリングされた値を取得して返します。

それ以外の場合は、スパーステクスチャを再度サンプリングしますが、今回はLODクランプを使用して、サンプラーにより高いミップマップをバイパスさせます。

このミップマップとそれ以下のミップマップにデータがあることを保証したため、2回目のサンプリングコールは通常のサンプルメソッドを使用して行われます。

スパーステクスチャデータをマッピングしてサンプリングする機能を見たので、スパーステクスチャタイルをマッピングまたは解放するタイミングを決定する方法について少し話しましょう。

従来のテクスチャストリーミングシステムは、アプリレベルの統計を手動で収集し、テクスチャレジデンシーの優先順位付けを支援します。

これらの方法は、多くの場合、オーバーヘッドを管理するのに役立つミップマップまたはメッシュの粒度で粗いです。

金属は代わりに、テクスチャアクセスカウンタと呼ばれるきめ細かいソリューションをサポートしています。

これらのカウンターは、非常に低いオーバーヘッドでGPUがスパースタイルにアクセスする頻度を正確に追跡します。

テクスチャアクセスカウンタはGPUから照会されます。

これがどのように機能するかを見てみましょう。

このメタルの例では、GPUからテクスチャアクセスカウンタを収集します。

まず、サンプリングされたカウンタを含むバッファを作成します。

そして、ブリットをエンコードして、スパーステクスチャからバッファにカウンターをコピーし、興味のあるミップレベル、スライス、領域を指定します。

従来のテクスチャストリーミング技術は、長年にわたって非常に役立っており、固定されたメモリ予算を考えると、ユーザーが見るテクスチャのミップレベルでストリーミングすることができます。

テクスチャ予算が使い果たされると、高解像度のミップレベルでストリーミングできなくなり、均一にぼやけたテクスチャが見え始めます。

しかし、まばらなテクスチャで、あなたは今、あなたのメモリのより良い使用を得ることができます。

メモリをマッピングして、特定のミップレベル内の各テクスチャタイルに最も適した品質レベルで、ユーザーが見る個々のテクスチャタイルのためのスペースを作ることができます。

これにより、最も視覚的なインパクトを与えるタイルのテクスチャメモリを分散できます。

さらに、この機能は、テクスチャをストリーミングするときに帯域幅を節約します。スパーステクスチャAPIを使用すると、ストリーミング中にメモリ内のミップマップチェーン全体をコピーして再配置する代わりに、個々のタイルをマッピングおよびマッピング解除できます。

それはまばらなテクスチャのためであり、テクスチャのストリーミング品質も向上させる本当に重要なメモリ最適化です。

それでは、ラスタライズレートマップと呼ばれるランタイム最適化手法に移りましょう。

ラスタライズレートマップを使用すると、知覚されない場所で品質を低下させながら、最高の解像度で最も重要な画像領域をラスタライズしてシェーディングすることで、Retinaディスプレイをより適切に活用できます。

ラスタライズレートマップを使用すると、画面スペースと物理レンダリングターゲットサイズ、および2つのスペース間の不均一なマッピングの両方を定義して、複数の解像度でラスタライズとシェーディングを行い、各領域の品質を制御できます。

物理的な解像度は画面容量よりも小さく、帯域幅を節約し、メモリフットプリントを削減します。

そして、不均一なマッピングは、ネイティブ解像度で画面全体をレンダリングするコストのほんの一部で、ゲームでよく使用される均一なアップスケールよりも高品質のビジュアルをもたらします。

これがどのように機能するかを詳しく見てみましょう。

これは、サンプルレンダラーのgバッファからの拡散レイヤーのスクリーンショットです。

従来のレンダリングは、各頂点の画面空間座標を計算し、結果のプリミティブを画面空間でラスタライズしてフラグメントを生成することによってジオメトリを描画します。

これらの画面空間座標は、ラスタ化中の物理レンダリングターゲットの座標への1対1のマッピングを持っています。

ラスタライズレートマップを使用すると、フラグメントを作成するときに画面空間座標を不均一にマッピングするようにラスタライザを設定できるため、生成される総フラグメントの数を減らし、同時にレンダリングターゲットを小さくすることができます。

どちらの画像でも、白いグリッドは仮想画面空間の均等な間隔のグリッドに対応します。

しかし、ここで見ることができるように、それは物理的な空間に不均等に分布しています。

この例では、ラスタライズレートマップを使用して、画面の解像度を画面の中央に保ちますが、画面の端に向かって減らしました。

これをより明確に見るために、中央のタイルの1つを拡大しましょう。

この物理タイルの解像度は、gバッファ内の同じ領域の解像度と一致します。

しかし、画面の端に向かって移動すると、そのタイル専用の物理的なスペースを効果的に減らすことで品質が低下します。

これにより、物理的な画像に歪んだ画像が表示されますが、このマッピングを逆にして、歪みのない最終画像を作成できることを示します。

しかし、まず、マッピングがどのように定義されているかを見てみましょう。

マッピングは、画面空間のX軸とY軸の2つの1D関数として定義されています。

これらの機能をMetalで説明し、品質要件を定義する一連のコントロールポイントを使用します。

この画像では、軸に沿った2つの1D機能を考えると、画面全体で効果的なラスタライズ率を見ることができます。

1つの品質レベルは、軸に沿ったすべての画面空間ピクセルに対してフラグメントシェーダーが呼び出されることを意味します。

そして、.5の品質レベルは、ピクセルの少なくとも50%に対して、与えられた軸に沿ってフラグメントシェーダーが呼び出されることを意味します。

品質レベルがゼロであるということは、各フラグメントシェーダーがMetalがサポートする最小レートで呼び出されることを意味します。

金属はこれらのコントロールポイントを再サンプリングして、最終的なレートマップを作成します。

最終的なマッピングを直接制御しなくても、Metalは最低品質が維持されることを保証します。

では、Metalでこのマッピングを作成しましょう。

これは、先ほど見たラスタライズレートマップを構築するMetalコードです。

まず、ラスタライズ関数を定義します。

この例では、マップの水平軸と垂直軸の両方について、以前に示した5つの値を使用します。

次に、レイヤー記述子を埋めて、ラスタライズレートマップ全体の品質を記述します。

次に、水平方向と垂直方向の品質機能を提供することで作成します。

品質を定義して、レイヤー記述子と最終的な画面空間解像度から金属ラスタライズレートマップ記述子を作成します。

最後に、Metalデバイスを使用して、その記述子を使用してラスタライズレートマップオブジェクトをインスタンス化します。

次に、このマップの物理的なレンダリングターゲットを作成する必要があります。

実際のラスタライズレートマップレートは実装に依存するため、まずマップからリソースの物理的なサイズを照会する必要があります。

次に、通常どおり物理レンダリングターゲットを作成します。正しい使用状況とストレージプロパティを指定し、Metalデバイスオブジェクトを使用してテクスチャをインスタンス化します。

最後に、作成したテクスチャとラスタライズマップを組み合わせて、レンダリングパスを設定し、通常どおりレンダリングします。

そして、それで、あなたはgバッファを不均一にラスタライズしました。

しかし、後のパスでgバッファをシェーディングするのはどうですか?

従来の遅延シェーディングパイプラインを使用すると、光のジオメトリがgバッファと同じ画面空間で正しくラスタライズされるため、同じラスタライズレートマップで照明を続けることができます。

タイルの遅延レンダラーでは、もう少し作業を行う必要があります。

タイルの遅延レンダリングにまだ慣れていない場合は、WWDC 2019でのModern Rendering with Metalトークをご覧ください。

タイル繰延では、レンダリングターゲットの物理空間は等しいサイズのピクセルブロックに分割され、各ブロックは軽いタイルの淘汰とシェーディングを実行します。

提示された画像では、サンプルコードは32×32ピクセルのブロックあたりのライト数のヒートマップを示しています。

画面空間はもはや物理空間に対応しないため、ラスタライズレートマップをタイル付き遅延レンダラーと統合するには、1つの追加ステップが必要です。

照明シェーダーは、物理空間のピクセル座標を仮想画面空間に変換する必要があります。

これは、ラスタライズ中に使用されるリバースマッピングです。

シェーダーでこのリバースマッピングを実行する方法を見てみましょう。

まず、ラスタライズレートマップパラメータをシェーダーからアクセスできるようにする必要があります。

これを行うには、まずパラメータを保持できるMTLBufferを作成します。

次に、パラメータデータをMTLBufferにコピーします。

そして最後に、MTLBufferをシェーダーにバインドします。

地図がバインドされたので、それを使おう。

シェーダーでは、対応するバッファバインドポイントでrasterization_rate_map_dataオブジェクトにアクセスできるようになりました。

そのオブジェクトを使用して、rasterization_rate_map _decoderオブジェクトをインスタンス化できます。

そして、デコーダを使用して、物理座標と画面座標の間で変換します。

タイル付き遅延レンダラーに戻り、デコーダを使用して仮想画面空間でタイルカリングを実行します。

光の淘汰を仮想画面空間に適応させることは、タイルがもはや正方形ではなく、画面空間の正しい領域に従うことを意味します。

このヒートマップを完全で均一な解像度のレンダリングと比較しましょう。

そして、ラスタライズレートマップバージョンに戻ります。

ご覧のとおり、ラスタライズレートマップを使用すると、画面上のシェーディングされたタイルの量が大幅に減少しました。

最後に、合成と最終プレゼンテーションのためにラスタライズレートマップがどのように準備されているかを考えてみましょう。

最後の画像を画面に表示する前に、先ほど説明したシェーダーマッピングを使用して、物理的な空間テクスチャを高解像度サーフェスに変換するフルスクリーンパスを使用して、ラップを解除する必要があります。

ご覧のとおり、このサンプルに選択された積極的なフォールオフにもかかわらず、品質のトレードオフに気づくことは非常に困難です。

ラスタライズレートマップは、品質のトレードオフを隠すために、被写界深度などの他の技術と組み合わせることを期待しています。

それはラスタライズレートマップ用です。

頂点増幅に移りましょう。

頂点増幅により、マルチビューレンダリングの場合のジオメトリ処理を削減できます。

多層およびマルチビューポートレンダリングは、インスタンスを使用して各ビューをターゲットにするために必要な描画呼び出しの数を減らします。

しかし、それはこれらの各インスタンスを処理するGPUコストを排除するものではありません。

多くの多層およびマルチビューポートレンダリング技術は、ビュー間でジオメトリを共有します。

たとえば、シャドウマップのカスケードや環境マップの側面の間。

これらの各インスタンスは、通常、ほぼ同じ方法でそのジオメトリを変換します。

したがって、位置はビューごとに一意ですが、法線、接線、テクスチャ座標などの属性は同じです。

頂点増幅では、これらの共有属性を一度だけ処理できるため、頂点シェーディングの効率が向上します。

カスケードシャドウマップのユースケースをより詳細に考えてみましょう。

ビュー距離に応じて、レンダラーはシャドウマップを1つ、2つ、または3つ以上の重なり合うシャドウカスケードに分割することがあります。

カスケードの数を増やすにつれて、各カスケードがカバーする仮想世界のサイズも大きくなります。

これにより、より大きく、より遠いカスケードは、より近いカスケードと比較して、より多くのジオメトリを蓄積します。

そして、より多くのカスケードで、複数のカスケードにレンダリングするオブジェクトの数が増えます。

それでは、カスケードシャドウマップが伝統的にどのようにレンダリングされるか、そして関連するコストを考えてみましょう。

マルチビューレンダリングの前に、各カスケードに別々に描画するだけです。

これにより、GPUとCPUの両方のオーバーヘッドが増加しました。

各頂点は複数回フェッチしてシェーディングする必要があり、各頂点も複数回出力されます。

マルチビューインスタンスレンダリングは、インスタンスIDを使用して、各プリミティブを宛先ビューにマッピングします。

複数のドローコールのCPUコストを排除しますが、GPUコストは同じままです。

レイヤードレンダリングにインスタンスを使用すると、インスタンスIDが実際のインスタンスIDとターゲットレイヤーの両方をエンコードするようになったため、実際のインスタンスジオメトリのレンダリングも複雑になります。

頂点増幅は、重複したフェッチ、シェーディング、および出力を排除します。

また、別の増幅IDも提供します。

動作中の頂点増幅を見てみましょう。

既存の頂点関数は、頂点増幅に簡単に適応できます。

この例では、増幅ごとに一意の位置を計算しますが、すべての増幅で色計算を共有します。

2つの属性でVertexOutputを宣言することから始めます。

コンパイラは通常、属性が一意であるか共有されているかを推測できますが、複雑なシェーダーの場合、どの属性が共有されているかを明示的にすることもできます。

共有属性の計算が増幅IDに依存している場合、コンパイラはエラーを報告します。

次に、増幅IDを保持する関数引数を宣言します。

このIDに関連付けられた計算は、シェーダー呼び出しごとに増幅されます。

color属性はそのIDに関連付けられていないため、一度だけ実行されます。

しかし、位置は正しいビュー投影行列を検索するためのIDに依存するため、式全体が増幅されます。

シェーダーコードはそれだけです。

では、増幅されたドローコールをどのように設定するかを見てみましょう。

増幅を可能にするパイプライン状態オブジェクトを作成することから始めましょう。

金属でサポートされている最大増幅係数は、デバイスから照会できます。

この場合、増幅係数が2つ欲しいとしましょう。

サポートされている場合は、パイプラインの最大増幅係数に設定します。

サポートされていない場合は、インスタンス化を通じて従来のマルチビューにフォールバックしたり、複数のドローコールを行うことに頼ることができます。

最後に、パイプラインを作成します。

パイプラインが作成され、増幅がサポートされていると仮定すると、ドロのエンコードを開始できます。

増幅で描画するには、増幅数を設定し、viewMappingsをバインドする必要があります。

viewMappingsは、増幅IDをターゲットレイヤーまたはビューポートにマッピングする方法について説明します。

頂点シェーダーがレンダリングターゲットまたはビューポート配列インデックスもエクスポートする場合、そのインデックスはviewMappings配列のベースオフセットとして機能します。

これで、目的の増幅を設定し、ドローをエンコードできます。

メタルフレームデバッガを詳しく見てみましょう。

このサンプルレンダリングでは、VertexAmplificationを使用して、カスケード2と3の両方にレンダリングされるすべての描画を増幅します。

ここでは、この描画呼び出しは、2つのレンダリングターゲットを指定するビューマッピングでレンダリングされることがわかります。

メッシュは、左側に示されている2番目のカスケードと、右側とジオメトリビューアの両方に表示される3番目のカスケードに同時にレンダリングされます。

それは頂点増幅のためです。

引数バッファと、それらがA13にどのように拡張されたかに移りましょう。

メタル2で引数バッファを導入しました。

引数バッファを使用すると、定数、テクスチャ、サンプラー、およびバッファ引数をMTLBuffersにエンコードできます。

すべての描画引数を1つのMetal引数バッファにエンコードすることで、最小限のCPUオーバーヘッドで複雑なシーンをレンダリングできます。

エンコードされると、引数バッファを再利用して、重複した冗長リソースバインディングを回避できます。

引数バッファは、GPU上のシーン全体のドロー引数へのアクセスを提供することで、GPU主導のパイプラインを有効にするためにも必要です。

その後、計算関数の引数バッファを変更して、シーンを動的に設定できます。

ティア2引数バッファは、引数バッファの機能を劇的に強化します。

A13を使用すると、Metal関数は引数バッファ内の任意のテクスチャをサンプリングまたは書き込むことができます。

また、事実上無制限の数のテクスチャと多くのサンプラーにアクセスすることもできます。

また、引数バッファは、複数のレベルの間接を持つ他の引数バッファも参照できるようになりました。

これにより、GPUまたはCPUで事前に引数バッファを組み立てることなく、すべてのシーンデータに対して単一の引数バッファをエンコードし、ドローでアクセスする機能のロックを解除します。

例を見てみましょう。 例を見てみましょう。

シーンオブジェクトモデル階層の例を次に示します。

WWDC 2019でのModern Rendering with Metalトークで同様の例を示しました。

階層は、すべてのジオメトリデータ、材料、およびモデルデータを記述します。

引数バッファを使用すると、このオブジェクトモデルを直接エンコードできます。

しかし、Tier 2のサポートでは、レンダリング中に階層を直接使用することもできます。

シェーダーの例を見てみましょう。 シェーダー

まず、引数バッファがメタルシェーディング言語で定数、テクスチャ、サンプラー、バッファの構造として宣言されていることを思い出してください。

これらの宣言は、先ほど説明したオブジェクト階層の例を直接反映します。

1つ目は材料表現で、2つ目はメッシュ、材料、モデルのセットを参照するシーンです。

さて、それでは、私たちのシーンを直接使用してシェードするフラグメント関数を見てみましょう。

最初の関数パラメータは、シーン引数バッファです。

2番目の関数パラメータは、描画ごとの定数です。

この例では、このドローのモデルIDと、以前の計算パスで選択された詳細の離散レベルをエンコードします。

次に、これらのIDを使用して、以前に計算されたIDを使用してシーンから素材を取得します。

そして、ネストされた引数バッファからテクスチャ、定数、サンプラーを使用してフラグメントの色を計算します。

そして、それだけです!

マテリアルパラメータをドローごとの引数バッファに収集するための介入コンピューティングパスはもうありません。

フラグメントシェーダーは、シーン引数バッファを直接使用するだけです。

しかし、先に進む前に、引数バッファの堅牢なツールサポートを強調したいと思います。

引数バッファとGPU駆動のパイプラインを使用すると、シーンのセットアップはGPUに移動し、デバッグも行います。

メタルフレームデバッガを使用すると、引数バッファとそれらを使用するシェーダーの両方を簡単にデバッグおよび検査できます。

バッファビューアを使用して、引数バッファ内のすべてのリソースを検査し、これらのリソースにすばやくジャンプしてさらに検査することができます。

シェーダーデバッガを使用して、シェーダーが引数バッファにどのようにアクセスまたは構築しているかを理解することもできます。

これは、引数バッファインデックスを計算したり、GPUの引数バッファを変更したりする場合に特に重要です。

ティア2の引数バッファはそれだけです。

それでは、新しいクラスのシェーダー最適化技術に移りましょう。

SIMDグループ機能は、コンピューティング機能とグラフィックス機能を最適化するための強力なツールです。

GPUワークロードは、GPUのアーキテクチャを活用することで、データと制御フロー情報を共有できます。

MetalのSIMD実行モデルをすばやくレビューして、それを解き明かしましょう。

Metalは、単一の命令、GPUの複数のデータの性質を利用するために、常にSIMDグループにスレッドを整理してきました。

Metalコンピューティング関数のSIMDグループを活用して、代わりにSIMDグループバリアを使用してスレッドグループ全体を同期するコストを削減した可能性があります。

SIMDグループのスレッドはロックステップで実行されるため、実行障壁は必要ありません。

したがって、SIMDグループバリアはメモリ操作のみを同期します。

SIMDグループ関数は、このロックステップ実行を利用して、スレッドグループメモリの代わりにレジスタを使用してスレッド間でデータを共有し、スレッドグループメモリバインド時のパフォーマンスを大幅に向上させることができます。

また、計算機能とレンダリング機能の両方に使用できます。

そして、少し見ればわかるように、これは非常に興味深いレンダリング最適化技術を可能にします。

まず、例を挙げて、SIMD実行のためのより良い直感を構築することから始めましょう。

左側は、SIMDグループをレーン0から始まる32レーンとして表しています。

レーンはSIMDグループ内の単一スレッドです。

では、このSIMDグループにいくつかの作業を実行させましょう。

まず、すべてのレーンが配列AをレーンIDでインデックス化し、結果を変数Xに格納します。

各車線がXの独自の値を持っていることに注意してください。

この実行モデルでは、Aからデータをロードする命令は一度だけフェッチされ、独自のインデックスを持つ32のスレッドによって同時に実行されます。

次に、laneIDで索引付けされた2番目の配列Bを読み取り、結果をYに格納します。

最後に、XとYを乗算した結果を3番目の配列Cに格納します。

実行された命令はグループ全体で1回しかフェッチされていないため、すべてのSIMDグループスレッドはロックステップで実行されます。

SIMDグループ機能により、グループ内の各スレッドは、最小限のオーバーヘッドでSIMDグループ全体のレジスタ値を検査できます。

この能力は、いくつかの興味深い機能を可能にします。

まず、simd_maxを紹介し、変数Yに適用しましょう。

各スレッドは、SIMDグループ内の任意のスレッドに見られるように、Yから最大の値を持つZ値を取得します。

次に、放送してXに適用します。

この例では、レーン0の値を1回の操作で他のすべてのレーンにブロードキャストします。

Metal for A13は、シャッフル、パーミュート、すべてのレーンでの回転など、他の多くの同様に動作するSIMD機能をサポートしています。

最後の例では、式がすべてのレーンで同じことを評価するかどうかを各レーンに伝えるsimd_allを見ていきます。

この例では、Z変数は確かにすべてのレーンで9であるため、trueを返します。

同様に、simd_anyは、式が任意のレーンに対して真と評価されるかどうかを指示します。

Simd_allを使用すると、すべてのスレッドが同じニーズを持つ場合、より最適なパスを選択することで、シェーダーの発散を減らすことができます。

例を見てみましょう。 例を見てみましょう。

これは、SIMDグループ関数を使用したいくつかの最適化を含む、以前のフラグメントシェーダーです。

要約すると、この関数は、引数バッファ、ユニフォーム、および頂点stage_inとしてエンコードされたシーンを入力として取ります。

通常、照明機能は、透明なフラグメントに対して最終色のさまざまなコンポーネントを異なる方法で評価するため、さまざまなポイントで動的制御フローを必要とします。

さて、すべてのフラグメントの不透明度を評価する代わりに、ここではsimd_allを使用して、SIMDグループ内のすべてのスレッドが不透明なフラグメントの照明を計算しているかどうかを動的にチェックします。

もしそうなら、不透明なオブジェクトのみを想定した最適なパスを取ります。

そして、そうでない場合は、不透明な断片と透明な断片の両方を照らすことができる以前のパスに戻ります。

これは、A13のSIMDグループ機能の場合です。

ギアを切り替えて、A13のASTCへのエキサイティングな追加のいくつかを見てみましょう。

ビデオで先に述べたように、A13 GPUは16ビット浮動小数点演算の速度を2倍にし、HDR処理をより適切に処理するために小さな16ビット数のサポートを追加します。

アプリは変更せずにこれらの改善を利用します。GPUでのHDR処理は、より速く、より正確になります。

Apple Family 6では、ASTC HDRと呼ばれるHDRデータの効率的なストレージとサンプリングをサポートする新しいピクセルフォーマットのサポートも追加されています。

ASTCは、多くのプラットフォームでサポートされているテクスチャ圧縮技術であり、帯域幅とメモリのほんの一部で高いテクスチャ画質を提供します。

これは、複数のビットレートと入力フォーマットをサポートすることによって行います。

ASTCローダイナミックレンジプロファイルは、Apple GPU Family 2からサポートされており、0から1の範囲で値を圧縮するのに適しています。

アプリがメモリと帯域幅を節約するためにASTCをまだ使用していない場合は、そうすることを強くお勧めします。

HDR画像に見られるより大きな輝度値をエンコードするには、ハイダイナミックレンジプロファイルが必要です。

ASTC HDRがなければ、このような画像は通常、はるかに高いメモリコストで16ビットの浮動小数点ピクセル形式で保存されます。

では、ASTC HDRはどのくらいのストレージを節約できますか?

たくさん。

例を考えてみましょう。

HDRゲームは、多くの場合、低解像度のキューブマップテクスチャを使用して、シーンを照らすためにハイダイナミックレンジ環境マップを表し、通常、ゲームの世界やレベル全体に多くのそのようなプローブを配置します。

ASTC HDRがなければ、各プローブは大量のメモリを消費することができ、そのようなプローブはすべてゲームのメモリ予算の大部分を簡単に消費する可能性があります。

この例では、256×256のプローブキューブマップだけで3MBを消費します。

ASTC HDRでは、同じプローブは何倍も少ないメモリを消費します。

ビットレートを変更して、フットプリントを本当に減らすこともできます。

HDRテクスチャの作成は、LDRに相当するものと同じくらい簡単です。

この例では、4×4のASTC LDRテクスチャを作成しています。

すべてのLDRフォーマットに一致するHDRフォーマットがあるため、これをHDRテクスチャに変換するには、ピクセルフォーマットを変更するだけです。

さて、それはA13 GPUの新しいMetal機能をまとめます。

私たちが学んだことをまとめましょう。

まばらなテクスチャで高品質のテクスチャストリーミングを可能にします。

これにより、ラスタライズレートマップで高価なシェーディングを必要な場所に焦点を合わせ、頂点増幅で冗長な頂点処理を排除することができます。

また、引数バッファTier 2と、シャッフルと投票命令によるSIMDグループ共有を備えた、より柔軟なGPU駆動型パイプラインを可能にします。

そして最後に、MetalはASTCでHDRパイプラインでメモリを節約できるようになりました。

Metal、A13 GPUの詳細、および最新のサンプルコードについては、developer.apple.comをご覧ください。

ありがとうございます。