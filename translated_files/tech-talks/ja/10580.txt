10580

ジェイソン・フィールダー：こんにちは、私の名前はジェイソン・フィールダーで、アップルのGPUソフトウェアエンジニアリングチームに所属しています。

新しいM1 ProおよびM1 Maxノートブックの素晴らしいグラフィックス処理機能を活用する方法を学び、GPUでアプリケーションを優れたパフォーマンスにするために採用できるベストプラクティスを探ります。

私たちの最新のMacBook Proは、私たちがこれまでに作った中で最も強力なチップを備えています。

M1 Proには最大16のGPUコアがあり、M1 Maxはそれを32に倍増します。

これは、はるかに高いDRAM帯域幅と相まって、MacBook Proのパフォーマンスが大幅に向上します。

システムメモリは、ユニファイドメモリアーキテクチャのおかげでGPUで利用可能になり、最大64GBが利用可能で、GPUアプリケーションはこれまで以上に多くのメモリにアクセスできます。

これらのMacBook Proは、開発者やクリエイティブなプロにとって全く新しい可能性の世界を開き、以前はデスクトップマシンのみをターゲットにしていたワークフローを可能にします。

では、この新しいGPUポテンシャルの世界をどのように開くのでしょうか?

GPUで作業をスケジュールできるようにするMetal Computeの要約から始めます。

次に、APIとGPUアーキテクチャを理解して、アプリの各段階のベストプラクティスを見ていきます。

次に、適用できる特定のカーネル最適化で締めくくります。

メタルコンピュートの簡単なリフレッシュから始めましょう。

Metalは、GPU作業を実行するためのAppleの最新の低オーバーヘッドAPIです。

できるだけ薄くて効率的であるように設計されており、統一されたグラフィックスとコンピューティングインターフェースを提供します。

Metalはマルチスレッドフレンドリーで、複数のCPUスレッドから作業を簡単にキューに入れることができ、開発者がオフラインまたはオンラインのシェーダーコンパイルパイプラインを使用する柔軟性を提供します。

ハードウェア層のボンネットの下には、CPUとGPUの両方が同じ物理メモリに接続されています。

CPUはユニファイドメモリブロック内にGPUリソースを作成し、GPUとCPUの両方がこれらのリソースを読み書きすることができます。

GPUで実行されるカーネルを見るために、いくつかのAPIレイヤーがあります。

最上層はコマンドキューです。

その名前の通り、このオブジェクトは、アプリケーションがGPU上のいくつかのポイントで実行のために作業をキューに入れることを可能にします。

コマンドは、コマンドバッファを介してCPUにバッチ処理されます。

これらのオブジェクトは一時的なものであり、アプリにとって意味のある粒度でこれらの多くを作成します。

これはCPUとGPUの同期に関する要件によって課せられているかもしれませんが、要するに、GPUを完全に忙しく保つのに十分な作業を確保したいと思うでしょう。

コマンドバッファに命令を入れるには、コマンドエンコーダが必要です。

さまざまな種類の作業をターゲットとするコマンドエンコーダにはさまざまな種類があります。

3D描画用のグラフィックエンコーダ、リソースをコピーするためのブリットエンコーダがありますが、この講演では、カーネルディスパッチ用のコンピューティングエンコーダに焦点を当てます。

コンピューティングエンコーダを導入することで、カーネルディスパッチをエンコードする準備が整いました。

カーネル機能自体に加えて、エンコーダはカーネルが必要とするリソースがそれにバインドされている方法です。

実際、複数のカーネルディスパッチを同じエンコーダにエンコードすることができます。

各ディスパッチ間でカーネルまたはバインドされたリソースを変更し、ディスパッチを同時に実行できるかどうか、または以前のディスパッチが完了した後にシリアル化して実行する必要があるかどうかをMetalに通知することもできます。

エンコーディングが完了したら、エンコーダを終了し、コマンドバッファを新しいエンコーダのエンコードを開始するか、実行のためにコマンドバッファをGPUにコミットできるようにします。

ここでは、合計3つのコンピューティングエンコーダをGPUにエンコードしました。

これは最初から最後までの作業の本体を表しており、GPUに実行を開始するように指示する準備ができています。

コミットの呼び出しはすぐに戻り、Metalは、キュー内の他のすべての作業が完了する前に、GPUで作業がスケジュールされ、実行されることを保証します。

CPUスレッドは、新しいコマンドバッファの構築を開始したり、GPUがビジーしている間に適切な他のアプリ作業を実行したりできるようになりました。

しかし、CPUは、結果を読み戻すことができるように、一連の作業がいつ完了したかを知る必要があるでしょう。

このため、コマンドバッファには2つのテクニックがあります。

ここでは、作業をコミットする前に、アプリケーションは作業が完了するとMetalによって呼び出される完了ハンドラ関数を追加できます。

単純なケースでは、呼び出し元のCPUスレッドをブロックするwaitUntilCompleteという同期メソッドがありますが、ここでは非同期メソッドを使用しています。

これが私たちの基本的な実行モデルです。

APIの最後の機能の1つは、複数のコマンドバッファを同時にエンコードできることです。

複数のCPUスレッドは、一度に複数のコマンドバッファをエンコードし、エンコードが完了したら作業をコミットできます。

順序付けが重要な場合は、enqueueを呼び出してコマンドキューで実行するためにコマンドバッファの場所を予約するか、単に目的の順序でコミットを呼び出します。

アプリケーションに最も適したアプローチを使用してください。

複数のコマンドキューを作成する可能性もあるため、Metalの柔軟性により、アプリはニーズに最も効率的なパターンでGPUに作業をエンコードすることができます。

それが、Metalが公開する実行モデルの要約です。

それに基づいて、それを最適化する方法を見てみましょう。 最適化する方法を見てみましょう。

ユニファイドメモリアーキテクチャを活用するためにアプリがGPUメモリにアクセスする方法、先ほどのコンピューティングモデルに合わせてGPUに作業を提出する方法、UMAと最もよく合わせるために割り当てるリソースを選択する方法について、いくつかの推奨事項があります。

最初に話すのは、間違いなくユニファイドメモリアーキテクチャです。

この一連のベストプラクティスは、GPUに必要な作業量を最小限に抑えることです。

ユニファイドメモリアーキテクチャを使用すると、システムRAMとビデオRAM間の従来のコピー管理が廃止されます。

Metalは、GPUとCPUが同じメモリを読み書きできるようにする共有リソースを通じてUMAを公開します。

リソース管理とは、システムメモリとビデオメモリの間でデータを複製したりシャドウイングしたりするのではなく、CPUとGPU間のアクセスを適切なタイミングで安全に同期させることです。

メモリ内のリソースの単一のインスタンスから作業すると、アプリが持つ可能性のあるメモリ帯域幅の要件が大幅に削減され、大きなパフォーマンスの向上が可能になります。

GPUがまだ最初のバッチを実行している間に、CPUが2番目のバッチの作業のバッファを更新する必要があるなど、競合の可能性がある場合は、明示的なマルチバッファモデルが必要です。

CPUはバッファnでコンテンツを準備し、GPUはバッファn-1から読み取り、次のバッチのnをインクリメントします。

これにより、アプリ開発者としてメモリのオーバーヘッドとアクセスパターンを調整し、不要なCPU/GPUのストールやコピーを回避できます。

アプリが割り当てることができるGPUリソースの量の制限には、注意すべき2つの値があります。

割り当てることができるGPUリソースの総量、そしてより重要なのは、単一のコマンドエンコーダが一度に参照できるメモリの量です。

この制限は、作業セットの制限として知られています。

recommendedMaxWorkingSetSizeを読むことで、実行時にMetalデバイスから取得できます。

使用するメモリの量を制御し、利用可能であることに頼るために、アプリでこれを使用することをお勧めします。

単一のコマンドエンコーダにはこの作業制限がありますが、Metalはこれを超えてさらにリソースを割り当てることができます。

Metalはこれらのリソースのレジデンシーを管理し、システムメモリの割り当てと同様に、GPUの割り当ても事実上割り当てられ、実行前に常駐します。

複数のコマンドエンコーダ間でリソース使用量を分割することで、アプリケーションは作業セットサイズを超える総リソースを使用し、ハードVRAM制限に関連する従来の制約を回避できます。

新しいMacBook Proの場合、GPUの作業セットのサイズをこの表に示します。

現在、32GBのシステムRAMを搭載したM1 ProまたはM1 Maxの場合、GPUは21GBのメモリにアクセスでき、64GBのRAMを搭載したM1 Maxの場合、GPUは48GBのメモリにアクセスできます。

これは、MacのGPUでこれまでに利用可能にした最大のメモリ量であり、新しいMacBook Proのラインナップは、ユーザーに大幅に拡張された機能を提供します。

私たちは、あなたがユーザーに力を与えることができる経験を見て、彼らがそれを使って作成するものを体験することに本当に興奮しています。

それがUMAと協力するためのベストプラクティスであり、次のトピックの準備ができています。

コマンドバッファレベルでは、送信に待ち時間があります。

少量の仕事は、働くよりも待つ時間が増える可能性があります。

コミットの呼び出しを行う前に、より多くのエンコーダを各コマンドバッファにバッチ処理してください。

アプリが次に何をディスパッチすべきかを知らせるためにGPUの結果を待つのに時間を費やした場合、バブルはGPUのタイムラインに表示されます。

これらのバブルでは、GPUはアイドル状態になり、次のディスパッチが到着するのを待っています。

これを隠すには、複数の作業で作業する複数のCPUスレッドを使用し、GPUを忙しく保つことを検討してください。

複数のコマンドバッファを作成するか、複数のコマンドキューを作成します。

カーネルディスパッチ自体の場合、GPUは作業するのに十分なスレッドを持ち、各スレッド内で起動のオーバーヘッドを正当化するのに十分な作業によってビジー状態が保たれます。

ここの画像処理の例では、各ピクセルは1つのスレッドで処理されます。

できる場合は、カーネルディスパッチの合計スレッド数を増やして、GPUのすべての処理コアを利用できるようにします。

ここでは、単一のカーネルディスパッチを使用してイメージ全体を処理し、MetalとGPUが利用可能なすべての処理コアに作業を最適に分散できるようにします。

最後に、スレッド数が少なくて必要な場合は、デフォルトのシリアライズモデルの代わりに同時ディスパッチモデルを使用してください。

M1ではうまく動作するが、M1 ProとM1 Maxではその可能性には及ばない多くのアプリケーションを観察しました。

これらの技術を使用して大量の作業を提出することは、アプリケーションが拡張し、その可能性に到達するための簡単な方法です。

私が話したい次の考慮事項は、L1キャッシュです。

Apple Silicon GPUには、テクスチャ読み取りとバッファ読み取り用の個別のL1キャッシュが含まれています。

Metalはグラフィックスとコンピューティング全体で統一されたAPIであるため、テクスチャオブジェクトとサンプラーの完全なスイートがアプリで利用できます。

したがって、アプリケーションがデータソースにバッファのみを使用している場合、これらのリソースの一部をテクスチャに移動することでパフォーマンス上の利点があります。

これにより、GPUの高性能キャッシュの利用が向上し、RAMからのトラフィックが削減され、パフォーマンスが向上します。

それがどのように見えるか見てみましょう。

GPUはすべてのリソースの読み取りのためにRAMにアクセスしますが、同じローカルメモリ領域への将来のバッファ読み取りのパフォーマンスを向上させるためのキャッシュがあります。

しかし、キャッシュはサイズが限られており、すぐにいっぱいになるため、しばらく読み込まれていない古いデータは、新しい読み取りに道を譲るために破棄されます。

仮説的には、カーネルが十分に小さなデータセットで動作した場合、キャッシュが入力されると、将来のすべての読み取りがキャッシュにヒットし、システムメモリのロードが完了するのを待つことによる失速や遅延なしで完了します。

キャッシュへの帯域幅は大幅に高く、システムRAMよりもレイテンシが低くなります。

読み取りがキャッシュを見逃すと、読み取りがRAMからフェッチされ、キャッシュに配置されている間、呼び出しスレッドは停止します。

データの読み取りは、オンチップキャッシュ帯域幅ではなく、システムメモリ帯域幅によって制限されます。

バッファから大量のデータにアクセスするカーネルは、このようにキャッシュをスラッシュし、パフォーマンスを低下させる可能性があります。

AppleシリコンGPUには、テクスチャ読み取り専用のバッファキャッシュと並んで2番目のキャッシュが含まれています。

アプリケーションは、ソースデータの一部をMetalバッファオブジェクトからMetalテクスチャオブジェクトに移動し、キャッシュスペースの量を効果的に増やし、パフォーマンスを向上させることができます。

また、テクスチャデータはねじれる可能性があり、Metalはアップロード時に自動的にこれを行います。

Twiddlingは、texelsがランダムアクセスパターンに対してより最適に順序付けられ、キャッシュ効率をさらに向上させ、通常のバッファよりも別のパフォーマンス向上を与えることを意味します。

これは、読み取り時にカーネルに対して透過的であるため、カーネルソースに複雑さを加えません。

実際、テクスチャは与え続ける贈り物です。

Apple Siliconは、テクスチャが作成された後、可能であれば、テクスチャの可逆圧縮を実行して、そこからの読み取りのメモリ帯域幅をさらに削減し、パフォーマンスを向上させることもできます。

これも、テクスチャの読み取りまたはサンプルで解凍が自動的に行われるため、シェーダーカーネルに対しても透明です。

Metalテクスチャは、GPUにプライベートの場合、デフォルトで圧縮されますが、共有および管理されたテクスチャは、blitコマンドエンコーダのOptimizeContentsForGPUAccessの呼び出しを介してアップロードした後、明示的に圧縮することができます。

可逆テクスチャ圧縮を利用できるようにするには、テクスチャの使用法をshaiderReadまたはrenderTargetのいずれかに設定する必要があります。

テクスチャオブジェクトを作成するときに、これが記述子に設定されていることを確認してください。

また、テクスチャデータが実際の画像データである場合、または非可逆圧縮が許容される方法で使用されている場合は、ASTCやBCなどのより高い比率の非可逆圧縮形式を検討してください。

これにより、メモリフットプリントと帯域幅の使用率の両方がさらに削減され、カーネルのパフォーマンスが向上します。

BCとASTCはどちらもオフラインツールを使用して生成でき、優れた画質を提供し、圧縮率は4:1から36:1の範囲です。

私たちの作業が最適にバッチ処理され、データ入力にバッファとテクスチャを利用し、UMAが実行しているコピー作業の量を減らすことを認識しているため、カーネルの最適化を検討する準備が整いました。

これらのベストプラクティスはすべて、カーネルのパフォーマンスを向上させることを目的としています。

それらのいくつかを見てみましょう。 それらのいくつかを見てみましょう。

カーネルの機会領域として、メモリインデックス、グローバルアトミック、占有に焦点を当てます。

また、カーネルのボトルネックを理解するためにプロファイリングツールのどこを見るべきか、および最適化が持つ可能性のある改善を測定する方法も見ていきます。

昨年のWWDCで、当社のGPUソフトウェアチームは、Appleシリコンの金属最適化技術に関するビデオを公開しました。

ここでその講演の内容を簡単に要約しますが、完全な詳細と例については、そのプレゼンテーションをご覧ください。

まず、メモリインデックスについて話したいと思います。

配列にインデックスを作成するときは、符号なし型よりも符号付き整数型を使用します。

ここにはforループがあり、count変数iは符号なしと宣言しました。

シェーダー言語仕様のuintのラッピング特性により、これはベクトル化されたロードを無効にします。

通常、これはあなたが望むものではなく、生成された余分なコードは、署名されたタイプを使用することで回避できます。

そしてここでは、intのラッピング動作が未定義であるため、負荷はベクトル化され、パフォーマンスが向上する可能性があります。

新しいMacBook ProのGPUコアとメモリ帯域幅の増加に伴い、一部のGPUワークロードの主なボトルネックがALUまたはメモリ帯域幅の使用から他の領域に移行するのを見てきました。

それらの分野の1つはグローバル原子です。

私たちの推奨事項は、カーネルでのアトミック操作の使用を最小限に抑えるか、代わりにスレッドグループアトミックを中心に構築された技術を使用することです。

すべての優れた最適化ワークフローと同様に、アトミックの適度な使用は問題にならないので、これがあなたが経験している問題であるかどうかを理解するために、最初にシェーダーをプロファイリングしてください。

では、この重要なプロファイリング情報をどのように入手するのですか?

Xcode内でGPUフレームデバッガを使用することで。

これは、この評価作業のための素晴らしいツールです。

これは、GPUで起こっている作業に関する豊富な洞察を提供し、キャプチャを取得すると、それを閲覧することができます。

タイムラインビューは、ワークロードの概要を説明し、GPUの主要なパフォーマンスカウンターを視覚化するグラフを示しています。

これらのカウンタの多くは、使用率とリミッター値の両方を与えます。

ここでALUを例にとると、使用率の数字は、カーネルが実行中にGPUのALU機能の約27%を使用したことを教えてくれます。

他の時間は、データの読み取りと書き込み、制御ロジックの決定など、他のタスクに費やされました。

リミッターの数字は、GPUがカーネルの実行時間の約31%の間、ALU使用率によってボトルネックされていることを意味します。

では、GPUはどのようにしてGPUのALU機能の27%を活用し、ALUによって31%のボトルネックになるのでしょうか？

リミッターは、行われたALU作業の効率と考えることができます。

これは、実際の作業に費やされた時間と、内部のストールや非効率性に費やされた時間です。

最良の場合、これらの時間は等しいですが、実際には違いがあります。

大きな違いは、GPUにはやるべき仕事があるが、何らかの理由でそれを行うことができないことを示しています。

たとえば、log（）や高価なテクスチャ形式を使用するなどの複雑なALU操作は、活用不足になる可能性があり、カーネルの数学を最適化するための範囲がある可能性があることを意味します。

これらの2つの数字は、カーネルが実行している作業の一般的な構成と、各カテゴリの作業がどれほど効率的であるかを理解するのに役立ちます。

この特定のカーネルでは、占有率が37%であることがわかります。

この価値は低く見え、それが増加できるかどうかを理解するために確かに調査する価値があります。

占有率を詳しく見てみましょう。

これは、最大値と比較して、GPUで現在アクティブなスレッドの数の尺度です。

この数字が低い場合は、その理由を理解し、これが予想されるのか、それとも問題を意味するのかを判断することが重要です。

たとえば、実行する作業が単に小さいため、提出された作業のスレッド数が比較的少ない場合、低占有率は驚くべきことでも回避可能でもありません。

GPUがALUなどの他のカウンターによって制限されている場合も問題ありません。

しかし、低リミッターカウンタと組み合わせた低占有率は、GPUが同時により多くのスレッドを実行する能力を持っていることを意味します。

では、何が問題のある低占有率を引き起こしている可能性がありますか?

これの一般的な理由は、スレッドまたはスレッドグループメモリの枯渇です。

これらのリソースは両方ともGPU上で有限であり、実行中のスレッド間で共有されています。

スレッドメモリはレジスタによってバックアップされており、レジスタの圧力が高まるにつれて、収容するために占有率を減らすことができます。

スレッドグループのメモリ使用量が多いため、占有率を増やす唯一の方法は、使用される共有メモリの量を減らすことです。

スレラドグループメモリを減らすことは、スレッドレジスタ圧力の影響を減らすのにも役立ちます。

パイプライン状態作成時にスレッドグループの最大スレッド数がわかっている場合、コンパイラがより効率的にレジスタをこぼす余地があります。

これらの最適化は、コンピューティングパイプライン状態記述子にmaxThreadsPerThreadgroupを設定するか、カーネルソースでMetal Shader langauge max_total_threads_per threadgroup属性を直接使用することで有効にできます。

この値を調整して、カーネルに最適なバランスを見つけてください。

アルゴリズムで動作するスレッド実行幅の最小倍数である値を目指します。

レジスタ圧力を深く掘り下げてみましょう。

これが高いと、XcodeのGPUプロファイラにレジスタが流出します。

このカーネルの例では、稼働率が16%であることがわかりますが、これは本当に低いです。

このカーネルのコンパイラ統計を見ると、こぼれたバイトを含む相対的な命令コストが示されます。

この流出は、一時的な登録簿とともに、私たちの貧弱な占有の原因である可能性が高い。

スレッドメモリを使い果たしており、実行されるスレッドのより多くのレジスタを解放するために占有率が削減されます。

レジスタはレジスタブロックのカーネルに割り当てられるため、占有率が増加する可能性があるためには、ブロックサイズまで使用量を減らす必要があります。

最小限のレジスタ使用量を最適化することは、複雑なカーネルにインパクトのあるパフォーマンスを向上させる素晴らしい方法ですが、これを行うにはどうすればよいですか?

32ビットタイプよりも16ビットタイプを好むと、カーネルの他の部分で利用可能なレジスタの数が増えます。

これらのタイプから32ビットのカウンターパートへの変換は通常無料です。

また、大きな配列や構造体など、スタックに保存されているデータを減らすことは、多数のレジスタを消費する可能性があり、それらを減らすことは効果的なツールです。

一定のアドレス空間を最大限に活用するために、シェーダー入力を調整してください。

これにより、不必要に使用される汎用レジスタの数を大幅に減らすことができます。

そして最後のヒントは、スタックに保存されている配列や動的インデックスを持つ定数データへのインデックス作成を避けることです。

この例をここに示します。ここでは、実行時に配列が初期化されます。

コンパイル時にインデックスがコンパイラに知られていない場合、配列はメモリに流出する可能性があります。

しかし、この2番目の例では、インデックスはコンパイル時に知られており、コンパイラはループを展開し、流出を最適化できる可能性があります。

これらの各技術は、レジスタの割り当てを減らし、流出を減らし、より高性能なカーネルの占有率を高めるのに役立ちます。

Apple SiliconのMetal最適化技術に関するより多くの洞察については、WWDC 2020のビデオ「Optimize Metal Performance for Apple Silicon Macs」をご覧ください。

そして、あなたはそれを持っています。

今日取り上げたことを復習しましょう。

私たちは、コマンドキュー、コマンドバッファ、コマンドエンコーダの役割のレビューから始めて、提出モデルと、MetalのGPUに作業がどのようにキューに入れられるかを思い出させ、CPUエンコーディング時間とコストを削減するために複数のスレッドからMetalコマンドをエンコードする方法を模索しました。

その知識で、アプリケーションを調整する方法に関する推奨事項を調べました。ユニファイドメモリアーキテクチャを利用するために不要なコピーを避ける。大量の作業を提出する。カーネルのリソースにメタルテクスチャとメタルバッファを使用します。

そして最後に、パフォーマンスのボトルネックを特定するためにツールを使用する方法のウォークスルーを取りました。

私たちは、GPUの使用率とリミッター値を解釈する方法と、それを発見した場合に問題のある低占有率にどのように対処できるかを理解しました。

ありがとうございます。これまでで最もパワフルなMacBook Proのラインナップでできることに、あなたが私と同じくらい興奮していることを願っています。