601

iOS 11 giới thiệu ARKit: một khuôn khổ mới để tạo các ứng dụng thực tế tăng cường cho iPhone và iPad.

ARKit đưa các ứng dụng vượt ra ngoài màn hình bằng cách đặt các đối tượng kỹ thuật số vào môi trường xung quanh bạn, cho phép bạn tương tác với thế giới thực theo những cách hoàn toàn mới.

Tại WWDC, chúng tôi đã giới thiệu ba khả năng chính cho ARKit.

Theo dõi vị trí phát hiện tư thế của thiết bị của bạn, cho phép bạn sử dụng iPhone hoặc iPad như một cửa sổ vào thế giới kỹ thuật số xung quanh bạn.

Hiểu cảnh phát hiện các bề mặt nằm ngang như mặt bàn, tìm các điểm neo ổn định và cung cấp ước tính về điều kiện ánh sáng xung quanh và tích hợp với các công nghệ kết xuất như SpriteKit, SceneKit và Metal, cũng như với các công cụ trò chơi phổ biến như Unity và Unreal.

Giờ đây với iPhone X, ARKit chuyển trọng tâm sang bạn, cung cấp tính năng theo dõi khuôn mặt bằng cách sử dụng camera mặt trước.

Khả năng mới này cho phép phát hiện khuôn mặt mạnh mẽ và theo dõi vị trí trong sáu bậc tự do.

Biểu cảm khuôn mặt cũng được theo dõi trong thời gian thực và các ứng dụng của bạn được cung cấp lưới tam giác vừa vặn và các thông số có trọng số đại diện cho hơn 50 chuyển động cơ cụ thể của khuôn mặt được phát hiện.

Đối với AR, chúng tôi cung cấp hình ảnh màu mặt trước từ máy ảnh, cũng như hình ảnh có độ sâu phía trước.

Và ARKit sử dụng khuôn mặt của bạn như một đầu dò ánh sáng để ước tính điều kiện ánh sáng và tạo ra các hệ số hài hòa hình cầu mà bạn có thể áp dụng cho kết xuất của mình.

Và như tôi đã đề cập, tất cả những điều này được hỗ trợ độc quyền trên iPhone X.

Có một số điều thực sự thú vị mà bạn có thể làm với Face Tracking.

Đầu tiên là hiệu ứng selfie, nơi bạn đang hiển thị một kết cấu bán trong suốt lên lưới mặt cho các hiệu ứng như hình xăm ảo, hoặc sơn mặt, hoặc để trang điểm, mọc râu hoặc ria mép, hoặc phủ lên lưới bằng đồ trang sức, mặt nạ, mũ và kính.

Thứ hai là chụp khuôn mặt, nơi bạn đang chụp biểu cảm khuôn mặt trong thời gian thực và sử dụng nó làm gian lận để chiếu biểu cảm lên hình đại diện hoặc cho một nhân vật trong trò chơi.

Vì vậy, hãy đi sâu vào chi tiết và xem cách bắt đầu với theo dõi khuôn mặt.

Điều đầu tiên bạn cần làm là tạo một ARSession.

ARSession là đối tượng xử lý tất cả quá trình xử lý được thực hiện cho ARKit, mọi thứ từ cấu hình thiết bị đến chạy các kỹ thuật AR khác nhau.

Để chạy một phiên, trước tiên chúng ta cần mô tả loại theo dõi mà chúng ta muốn cho ứng dụng này.

Vì vậy, để làm điều này, bạn sẽ tạo một Cấu hình AR cụ thể để theo dõi khuôn mặt và thiết lập nó.

Bây giờ để bắt đầu xử lý, bạn chỉ cần gọi phương thức "chạy" trong phiên và cung cấp cấu hình bạn muốn chạy.

Trong nội bộ, ARKit sẽ định cấu hình AVCaptureSession và CMMotionManager để bắt đầu nhận hình ảnh máy ảnh và dữ liệu cảm biến.

Và sau khi xử lý, kết quả sẽ được xuất ra dưới dạng ARFrames.

Mỗi ARFrame là một ảnh chụp nhanh theo thời gian, cung cấp hình ảnh máy ảnh, dữ liệu theo dõi và điểm neo - về cơ bản là mọi thứ cần thiết để hiển thị cảnh của bạn.

Bây giờ chúng ta hãy xem xét kỹ hơn ARConfiguration để theo dõi khuôn mặt.

Chúng tôi đã thêm một lớp con mới gọi là ARFaceTrackingConfiguration.

Đây là một lớp con cấu hình đơn giản yêu cầu ARSession cho phép theo dõi khuôn mặt thông qua camera mặt trước.

Có một vài thuộc tính cơ bản để kiểm tra tính khả dụng của tính khả dụng của theo dõi khuôn mặt trên thiết bị của bạn và có bật ước tính ánh sáng hay không.

Sau đó, một khi bạn gọi "chạy", bạn sẽ bắt đầu theo dõi và bắt đầu nhận ARFrames.

Khi một khuôn mặt được phát hiện, phiên sẽ tạo ra một ARFaceAnchor.

Điều này đại diện cho khuôn mặt chính - khuôn mặt lớn nhất, gần nhất trong tầm nhìn của máy ảnh.

ARFaceAnchor cung cấp cho bạn tư thế khuôn mặt trong tọa độ thế giới, thông qua thuộc tính biến đổi của siêu lớp của nó.

Nó cũng cung cấp cấu trúc liên kết 3D và các thông số của biểu cảm khuôn mặt hiện tại.

Và như bạn có thể thấy, tất cả đều được theo dõi, và lưới và các thông số được cập nhật, trong thời gian thực, 60 lần mỗi giây.

Giờ đây, tập trung vào cấu trúc liên kết, ARKit cung cấp cho bạn một lưới 3D chi tiết của khuôn mặt được trang bị trong thời gian thực với kích thước, hình dạng và phù hợp với biểu cảm khuôn mặt của người dùng.

Dữ liệu này có sẵn ở một vài dạng khác nhau; đầu tiên là lớp ARFaceGeometry.

Về cơ bản, đây là một lưới tam giác, vì vậy một mảng các đỉnh, chỉ số tam giác và tọa độ kết cấu, mà bạn có thể thực hiện để hình dung trong trình kết xuất của mình.

ARKit cũng cung cấp một cách dễ dàng để hình dung lưới trong SceneKit thông qua lớp ARSCNFaceGeometry, lớp này xác định một đối tượng hình học có thể được gắn vào bất kỳ nút SceneKit nào.

Bây giờ ngoài lưới hình học, chúng tôi cũng có một cái gì đó mà chúng tôi gọi là hình dạng pha trộn.

Các hình dạng pha trộn cung cấp một mô hình cấp cao về biểu cảm khuôn mặt hiện tại.

Chúng là một từ điển gồm các hệ số được đặt tên đại diện cho tư thế của các đặc điểm cụ thể - mí mắt, lông mày, hàm, mũi, v.v. của bạn - tất cả đều liên quan đến vị trí trung tính của chúng.

Chúng được biểu thị dưới dạng các giá trị dấu phẩy động từ 0 đến 1 và tất cả chúng đều được cập nhật trực tiếp.

Vì vậy, bạn có thể sử dụng các hệ số hình dạng pha trộn này để tạo hiệu ứng động hoặc giàn khoan, một nhân vật 2D hoặc 3D theo cách phản ánh trực tiếp chuyển động khuôn mặt của người dùng.

Chỉ để cung cấp cho bạn ý tưởng về những gì có sẵn, đây là danh sách các hệ số hình dạng pha trộn.

Vì vậy, mỗi thứ này đều được theo dõi và cập nhật độc lập - lông mày phải và trái, vị trí mắt, hàm, hình dạng nụ cười của bạn, vân vân.

Một cái gì đó đi đôi với việc kết xuất hình học khuôn mặt hoặc tạo hoạt hình cho một nhân vật 3D là ánh sáng thực tế.

Và bằng cách sử dụng khuôn mặt của bạn như một đầu dò ánh sáng, một ARSession đang chạy phát hiện khuôn mặt có thể cung cấp cho bạn ước tính ánh sáng định hướng, đại diện cho cường độ ánh sáng và hướng của nó trong không gian thế giới.

Đối với hầu hết các ứng dụng, vectơ ánh sáng và cường độ này là quá đủ.

Nhưng ARKit cũng cung cấp các hệ số hài hòa hình cầu độ hai, đại diện cho cường độ ánh sáng được phát hiện trong cảnh.

Vì vậy, đối với các ứng dụng có yêu cầu nâng cao hơn, bạn cũng có thể tận dụng điều này.

Và một vài tính năng nữa để đề cập đến.

Ngoài hình ảnh máy ảnh mặt trước với dữ liệu màu, ARKit cũng có thể cung cấp cho ứng dụng của bạn hình ảnh chiều sâu mặt trước.

Và tôi đang hiển thị điều này ở đây dưới dạng hình ảnh thang độ xám.

Bản thân dữ liệu được cung cấp dưới dạng đối tượng AVDepthData, cùng với dấu thời gian.

Nhưng điều quan trọng cần lưu ý, điều này đang được chụp ở 15Hz, đây là tần số thấp hơn so với hình ảnh màu mà ARKit chụp ở 60Hz.

Và cuối cùng, một tính năng có thể được sử dụng với bất kỳ phiên ARKit nào, nhưng đặc biệt thú vị với tính năng theo dõi khuôn mặt là: Ghi lại âm thanh.

Bây giờ nó bị tắt theo mặc định, nhưng nếu được bật, thì trong khi ARSession của bạn đang chạy, nó sẽ thu các mẫu âm thanh từ micrô và gửi một chuỗi CMSampleBuffers đến ứng dụng của bạn.

Vì vậy, điều này rất hữu ích nếu bạn muốn ghi lại khuôn mặt và giọng nói của người dùng cùng một lúc.

Để biết thêm thông tin về theo dõi khuôn mặt và liên kết đến mã mẫu, vui lòng truy cập trang web Nhà phát triển của chúng tôi tại developer.apple.com/arkit.

Cảm ơn bạn đã xem!