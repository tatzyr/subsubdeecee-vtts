10580

제이슨 필더: 안녕하세요, 제 이름은 제이슨 필더이고, 저는 여기 애플의 GPU 소프트웨어 엔지니어링 팀과 함께 있습니다.

우리는 새로운 M1 Pro 및 M1 Max 노트북의 멋진 그래픽 처리 기능을 활용하는 방법을 배울 것이며, 애플리케이션이 GPU에서 훌륭하게 작동하도록 하기 위해 채택할 수 있는 모범 사례를 모색할 것입니다.

우리의 최신 맥북 프로는 우리가 만든 가장 강력한 칩을 특징으로 한다.

M1 Pro는 최대 16개의 GPU 코어를 가지고 있으며, M1 Max는 32코어로 두 배가 된다.

이것은 훨씬 더 높은 DRAM 대역폭과 함께 맥북 프로의 성능을 크게 향상시킨다.

시스템 메모리는 이제 통합 메모리 아키텍처 덕분에 GPU에서 사용할 수 있으며, 최대 64GB를 사용할 수 있는 GPU 애플리케이션은 그 어느 때보다 더 많은 메모리에 액세스할 수 있습니다.

이 맥북 프로는 개발자와 창의적인 전문가에게 완전히 새로운 가능성의 세계를 열어 이전에 데스크톱 컴퓨터만을 대상으로 했던 워크플로우를 가능하게 할 것이다.

그렇다면 이 새로운 GPU 잠재력의 세계를 어떻게 열 수 있을까요?

우리는 GPU에서 작업을 예약할 수 있는 Metal Compute의 요약으로 시작할 것입니다.

그런 다음, API와 GPU 아키텍처를 이해하면서, 우리는 앱의 각 단계에 대한 모범 사례를 살펴볼 것입니다.

그런 다음 우리는 당신이 적용할 수 있는 몇 가지 특정 커널 최적화로 결론을 내릴 것입니다.

Metal Compute의 빠른 새로 고침으로 시작합시다.

메탈은 GPU 작업을 수행하기 위한 애플의 현대적인 낮은 오버헤드 API이다.

그것은 가능한 한 얇고 효율적으로 설계되었으며 통합 그래픽과 컴퓨팅 인터페이스를 제공합니다.

메탈은 멀티스레드 친화적이며, 여러 CPU 스레드에서 작업을 사소한 대기열로 만들 수 있으며, 개발자에게 오프라인 또는 온라인 셰이더 컴파일 파이프라인을 사용할 수 있는 유연성을 제공합니다.

하드웨어 계층의 후드 아래에는 CPU와 GPU가 모두 동일한 물리적 메모리에 연결되어 있습니다.

CPU는 통합 메모리 블록 내에서 GPU 리소스를 생성하며, GPU와 CPU 모두 이러한 리소스를 읽고 쓸 수 있습니다.

우리는 GPU에서 실행되는 커널을 보기 위해 작업할 몇 가지 API 계층이 있습니다.

최상층은 명령 대기열이다.

이름에 따라, 이 객체는 애플리케이션이 GPU의 일부 지점에서 실행을 위해 대기열 작업을 할 수 있게 해준다.

명령은 명령 버퍼를 통해 CPU에 일괄 처리됩니다.

이 객체들은 일시적이며, 당신은 당신의 앱에 의미가 있는 세분성으로 이것들을 많이 만들 것입니다.

이것이 CPU와 GPU 동기화에 대한 요구 사항에 의해 부과될 수 있지만, 간단히 말해서, GPU를 완전히 바쁘게 유지하기에 충분한 작업이 있는지 확인하고 싶을 것입니다.

명령 버퍼에 명령을 넣으려면, 명령 인코더가 필요합니다.

다양한 유형의 작업을 대상으로 하는 다양한 유형의 명령 인코더가 있습니다.

3D 그리기를 위한 그래픽 인코더, 리소스를 복사하기 위한 blit 인코더가 있지만, 이 강연에서는 커널 디스패치를 위한 컴퓨팅 인코더에 초점을 맞출 것입니다.

컴퓨팅 인코더를 사용하면, 이제 커널 디스패치를 인코딩할 준비가 되었습니다.

커널 기능 자체와 함께, 인코더는 커널에 필요한 자원이 그것에 바인딩되는 방식이다.

사실 우리는 여러 개의 커널 디스패치를 동일한 인코더로 인코딩할 수 있다.

우리는 커널을 변경하거나 각 디스패치 사이에 자원을 바인딩할 수 있으며, 디스패치가 동시에 실행될 수 있는지 또는 이전 디스패치가 완료된 후 직렬화 및 실행되어야 하는지 여부를 Metal에 알릴 수 있습니다.

인코딩이 완료되면, 우리는 명령 버퍼가 새 인코더 인코딩을 시작하거나 실행을 위해 명령 버퍼를 GPU에 커밋하는 데 사용할 수 있는 인코더를 종료합니다.

여기서 우리는 총 세 개의 컴퓨팅 인코더를 GPU로 인코딩했습니다.

이것은 처음부터 끝까지 작업을 나타내며, 우리는 GPU에 실행을 시작하도록 지시할 준비가 되어 있습니다.

커밋 요청이 즉시 반환되며, Metal은 대기열에서 완료되기 전에 다른 모든 작업이 완료되면 GPU에서 작업이 예약되고 실행되도록 할 것입니다.

CPU 스레드는 이제 새로운 명령 버퍼 구축을 시작하거나 GPU가 바쁜 동안 적절한 다른 앱 작업을 수행할 수 있습니다.

하지만 CPU는 결과를 다시 읽을 수 있도록 작업이 언제 완료되었는지 알아야 할 것이다.

이를 위해, 명령 버퍼는 우리를 위한 두 가지 기술을 가지고 있다.

여기서, 작업을 커밋하기 전에, 애플리케이션은 작업이 완료되면 Metal에 의해 호출될 완료 핸들러 기능을 추가할 수 있습니다.

간단한 경우, 호출 CPU 스레드를 차단하는 waitUntilComplete라는 동기 메서드가 있지만, 여기서는 비동기 메서드를 사용하고 있습니다.

그래서 이것이 우리의 기본 실행 모델이다.

API의 마지막 기능 중 하나는 여러 명령 버퍼를 동시에 인코딩할 수 있다는 것이다.

여러 CPU 스레드는 한 번에 여러 명령 버퍼를 인코딩할 수 있으며, 인코딩이 완료되면 작업을 커밋할 수 있습니다.

순서가 중요한 경우, enqueue를 호출하여 명령 대기열에서 실행을 위해 명령 버퍼의 위치를 예약하거나, 또는 원하는 순서로 커밋을 호출하십시오.

당신의 응용 프로그램에 가장 적합한 접근 방식을 사용하세요.

여러 명령 대기열을 만들 수 있는 가능성으로, Metal의 유연성은 앱이 필요에 가장 효율적인 패턴으로 GPU에 작업을 인코딩할 수 있게 해준다.

그래서 그것이 메탈이 노출한 실행 모델의 요약이다.

그것을 기반으로 하고 그것을 최적화하는 방법을 살펴봅시다.

통합 메모리 아키텍처를 활용하기 위해 앱이 GPU 메모리에 액세스하는 방법, 방금 살펴본 컴퓨팅 모델과 일치하도록 GPU에 작업을 제출하는 방법, UMA와 가장 잘 맞추기 위해 할당할 리소스를 선택하는 방법에 대한 몇 가지 권장 사항이 있습니다.

가장 먼저 이야기할 것은 확실히 통합 메모리 아키텍처이다.

이 모범 사례 세트는 GPU에 필요한 작업의 양을 최소화하는 것이다.

통합 메모리 아키텍처를 사용하면 시스템 RAM과 비디오 RAM 간의 전통적인 복사본 관리가 없어집니다.

메탈은 GPU와 CPU가 동일한 메모리를 읽고 쓸 수 있는 공유 리소스를 통해 UMA를 노출시킨다.

그런 다음 리소스 관리는 시스템 메모리와 비디오 메모리 간의 데이터를 복제하거나 섀도잉하는 대신 CPU와 GPU 간의 액세스를 적시에 안전하게 동기화하는 것입니다.

메모리에 있는 리소스의 단일 인스턴스에서 작업하면 앱이 가질 수 있는 메모리 대역폭에 대한 요구 사항이 크게 감소하여 큰 성능 향상을 가능하게 합니다.

GPU가 여전히 첫 번째 배치를 실행하는 동안 두 번째 배치 작업을 위해 버퍼를 업데이트해야 하는 CPU와 같은 가능한 경합이 있는 경우, 명시적인 다중 버퍼 모델이 필요합니다.

CPU는 버퍼 n에서 콘텐츠를 준비하고, GPU는 버퍼 n-1에서 읽은 다음 다음 배치를 위해 n을 증가시킨다.

이를 통해 앱 개발자는 메모리 오버헤드와 액세스 패턴을 조정하고 불필요한 CPU/GPU 스톨이나 복사본을 피할 수 있습니다.

앱이 할당할 수 있는 GPU 리소스의 양에 대한 제한에는 알아야 할 두 가지 값이 있다.

할당할 수 있는 GPU 리소스의 총량, 그리고 더 중요한 것은 단일 명령 인코더가 한 번에 참조할 수 있는 메모리의 양입니다.

이 제한은 작업 설정 제한으로 알려져 있다.

recommendedMaxWorkingSetSize를 읽음으로써 런타임에 금속 장치에서 가져올 수 있습니다.

사용할 수 있는 메모리의 양을 제어하고 사용 가능한 것에 의존하기 위해 앱에서 이것을 사용하는 것이 좋습니다.

단일 명령 인코더에는 이 작업 설정 제한이 있지만, 메탈은 이 이상으로 더 많은 자원을 할당할 수 있다.

메탈은 당신을 위해 이러한 자원의 상주를 관리하며, 시스템 메모리 할당과 마찬가지로 GPU 할당도 실행 전에 가상으로 할당되고 상주됩니다.

여러 명령 인코더에서 리소스 사용을 분리함으로써, 애플리케이션은 작업 세트 크기를 초과하는 총 리소스를 사용하고 하드 VRAM 제한과 관련된 전통적인 제약을 피할 수 있습니다.

새로운 맥북 프로의 경우, GPU 작동 세트 크기가 이 표에 나와 있습니다.

이제 32GB의 시스템 RAM이 있는 M1 Pro 또는 M1 Max의 경우 GPU는 21GB의 메모리에 액세스할 수 있으며, 64GB의 RAM이 있는 M1 Max의 경우 GPU는 48GB의 메모리에 액세스할 수 있습니다.

이것은 지금까지 우리가 Mac의 GPU에서 사용할 수 있는 가장 많은 양의 메모리이며, 새로운 맥북 프로 라인업은 사용자에게 크게 확장된 기능을 제공합니다.

우리는 당신이 사용자에게 힘을 실어주고 그들이 그것으로 무엇을 만들 것인지 경험할 수 있는 경험을 보게 되어 정말 기쁩니다.

그것이 UMA와 함께 일하기 위한 우리의 모범 사례이며, 우리는 다음 주제에 대한 준비가 되어 있습니다.

명령 버퍼 수준에서, 그것을 제출할 때 지연이 있다.

적은 양의 작업은 일하는 것보다 기다리는 데 더 많은 시간을 할애할 수 있다.

커밋을 요청하기 전에 더 많은 인코더를 각 명령 버퍼에 함께 배치하세요.

앱이 다음에 발송해야 할 것을 알리기 위해 GPU 결과를 기다리는 데 시간을 소비한다면, 거품은 GPU 타임라인에 나타날 것입니다.

이 거품 속에서, GPU는 다음 파견이 도착하기를 기다리며 유휴 상태이다.

이것을 숨기려면, 여러 작업에서 작업하는 여러 CPU 스레드를 사용하고 GPU를 바쁘게 유지하는 것을 고려하십시오.

여러 명령 버퍼를 만들거나 여러 명령 큐를 만들어.

커널 디스패치 자체의 경우, GPU는 작업할 수 있는 충분한 스레드가 있고, 각 스레드 내에서 실행의 오버헤드를 정당화하기 위해 충분한 작업으로 바쁘게 유지된다.

여기의 이미지 처리 예에서, 각 픽셀은 단일 스레드로 처리됩니다.

할 수 있을 때, GPU의 모든 처리 코어를 활용할 수 있도록 커널 디스패치의 총 스레드 수를 늘리세요.

여기서, 단일 커널 디스패치는 전체 이미지를 처리하는 데 사용되어 Metal과 GPU가 사용 가능한 모든 처리 코어에 작업을 최적으로 분배할 수 있습니다.

마지막으로, 더 작은 스레드 수가 필요한 경우, 기본 직렬화 모델 대신 동시 디스패치 모델을 사용하세요.

우리는 M1에서 잘 실행되지만 M1 Pro와 M1 Max에서는 잠재력이 부족한 많은 응용 프로그램을 관찰했습니다.

이러한 기술을 사용하여 더 많은 양의 작업을 제출하는 것은 응용 프로그램을 확장하고 잠재력을 발휘할 수 있는 쉬운 방법입니다.

내가 이야기하고 싶은 다음 고려 사항은 L1 캐시이다.

Apple Silicon GPU에는 텍스처 읽기와 버퍼 읽기를 위한 별도의 L1 캐시가 포함되어 있습니다.

메탈은 그래픽과 컴퓨팅 전반에 걸쳐 통합된 API이기 때문에, 앱에서 텍스처 객체와 샘플러의 전체 제품군을 사용할 수 있습니다.

따라서 애플리케이션이 데이터 소스에 버퍼만 사용하는 경우, 이러한 리소스 중 일부를 텍스처로 이동하면 성능 이점이 있습니다.

이를 통해 GPU의 고성능 캐시를 더 잘 활용하고, RAM의 트래픽을 줄이며, 성능을 향상시킬 수 있습니다.

그게 어떻게 생겼는지 보자.

GPU가 모든 리소스를 읽기 위해 RAM에 액세스하는 동안, 동일한 로컬 메모리 영역에 대한 향후 버퍼 읽기의 성능을 개선하기 위한 캐시가 있습니다.

하지만 캐시는 크기가 제한되어 있으며, 빠르게 채워질 것이므로, 한동안 읽지 않은 오래된 데이터는 새로운 읽기를 위한 길을 만들기 위해 폐기될 것이다.

가설적으로, 우리의 커널이 충분히 작은 데이터 세트에서 작동한다면, 캐시가 채워지면, 모든 미래의 읽기는 캐시에 충돌하고 시스템 메모리 로드가 완료되기를 기다리면서 발생하는 지연이나 지연 없이 완료될 것이다.

캐시에 대한 대역폭은 상당히 높으며, 시스템 RAM보다 대기 시간이 낮다.

읽기가 캐시를 놓치면, 읽기가 RAM에서 가져와 캐시에 배치되는 동안 호출 스레드가 중단됩니다.

데이터 읽기는 온칩 캐시 대역폭이 아닌 시스템 메모리 대역폭에 의해 제한된다.

버퍼에서 많은 양의 데이터에 액세스하는 커널은 이러한 방식으로 캐시를 스래시하고 성능을 저하시킬 수 있다.

애플 실리콘 GPU는 텍스처 읽기 전용 버퍼 캐시와 함께 두 번째 캐시를 포함한다.

애플리케이션은 소스 데이터의 일부를 금속 버퍼 객체에서 금속 텍스처 객체로 이동할 수 있으며, 캐시 공간의 양을 효과적으로 늘리고 성능을 향상시킬 수 있습니다.

또한, 텍스처 데이터는 뒤틀릴 수 있으며, 메탈은 업로드 시 자동으로 이를 수행할 것입니다.

트위들링은 텍셀이 무작위 액세스 패턴에 대해 더 최적으로 정렬된다는 것을 의미하며 캐시 효율성을 더욱 개선하여 일반 버퍼보다 또 다른 성능 향상을 줄 수 있습니다.

이것은 읽을 때 커널에 투명하므로 커널 소스에 복잡성을 추가하지 않습니다.

사실, 질감은 계속 주는 선물이다.

애플 실리콘은 또한 텍스처가 만들어진 후 그리고 가능한 경우 텍스처의 무손실 압축을 수행하여 읽기의 메모리 대역폭을 더욱 줄이고 다시 성능을 향상시킬 수 있다.

이것은 또한 텍스처 읽기 또는 샘플에서 감압이 자동으로 발생하기 때문에 셰이더 커널에 투명하다.

금속 텍스처는 GPU에 비공개인 경우 기본적으로 압축되지만, blit 명령 인코더에서 optimizeContentsForGPUAccess 호출을 통해 업로드 후 공유 및 관리되는 텍스처를 명시적으로 압축할 수 있습니다.

무손실 텍스처 압축을 사용하려면, 텍스처의 사용을 shaderRead 또는 renderTarget으로 설정해야 합니다.

텍스처 객체를 만들 때 이것이 설명자에 설정되어 있는지 확인하세요.

그리고 텍스처 데이터가 실제 이미지 데이터이거나 손실 압축이 허용되는 방식으로 사용되는 경우, ASTC 또는 BC와 같은 더 높은 비율의 손실 압축 형식을 고려하십시오.

이것은 메모리 풋프린트와 대역폭 활용을 더욱 줄여 커널의 성능을 증가시킬 것이다.

BC와 ASTC는 모두 오프라인 도구를 사용하여 생성할 수 있으며, 훌륭한 이미지 품질을 제공하며, 압축 비율은 4:1에서 36:1입니다.

이제 우리의 작업이 최적으로 배치되고, 데이터 입력을 위해 버퍼와 텍스처를 활용하고, UMA가 우리가 수행하는 복사 작업의 양을 줄이기 위해 인식함에 따라, 우리는 커널 최적화를 살펴볼 준비가 되었습니다.

이러한 모든 모범 사례는 커널의 성능을 높이는 것을 목표로 합니다.

그것들 중 몇 개를 살펴봅시다.

저는 메모리 인덱싱, 글로벌 원자, 그리고 당신의 커널에서 기회의 영역으로 점유에 집중할 것입니다.

우리는 또한 커널의 병목 현상과 최적화가 가질 수 있는 개선을 측정하는 방법을 이해하기 위해 프로파일링 도구에서 어디를 살펴볼 것입니다.

작년 WWDC에서, 우리의 GPU 소프트웨어 팀은 애플 실리콘의 금속 최적화 기술에 대한 비디오를 발표했다.

여기서 그 이야기의 내용 중 일부를 간략하게 요약하겠지만, 자세한 내용과 예시를 보려면, 그 프레젠테이션을 보세요.

먼저, 저는 메모리 인덱싱에 대해 이야기하고 싶습니다.

배열에 인덱싱할 때, 부호 없는 유형보다 부호 있는 정수 유형을 사용하세요.

여기에 내가 서명되지 않은 것으로 선언한 카운트 변수가 있는 for 루프가 있습니다.

셰이더 언어 사양에서 uint의 래핑 특성으로 인해, 이것은 벡터화된 부하를 비활성화합니다.

보통, 이것은 당신이 원하는 것이 아니며, 생성된 추가 코드는 서명된 유형을 사용하여 피할 수 있습니다.

그리고 여기서, int의 래핑 동작이 정의되지 않았기 때문에, 로드는 벡터화되어 성능 향상을 제공할 것이다.

새로운 맥북 프로의 GPU 코어와 메모리 대역폭이 증가함에 따라, 우리는 일부 GPU 워크로드의 주요 병목 현상이 ALU 또는 메모리 대역폭 사용에서 다른 영역으로 이동하는 것을 보았습니다.

그 분야 중 하나는 글로벌 원자이다.

우리의 권장 사항은 커널에서 원자 연산의 사용을 최소화하거나, 대신 스레드 그룹 원자를 중심으로 구축된 기술을 사용하는 것입니다.

모든 좋은 최적화 워크플로우와 마찬가지로, 원자의 적당한 사용은 문제가 되지 않을 것이기 때문에 이것이 당신이 겪고 있는 문제인지 이해하기 위해 셰이더를 먼저 프로파일링하십시오.

그렇다면 이 중요한 프로파일링 정보를 어떻게 얻을 수 있을까요?

Xcode 내부의 GPU 프레임 디버거를 사용하여.

그것은 이 평가 작업을 위한 훌륭한 도구이다.

그것은 GPU에서 발생하는 작업에 대한 풍부한 통찰력을 제공하며, 일단 캡처하면, 우리는 그것을 탐색할 수 있습니다.

타임라인 뷰는 우리에게 워크로드에 대한 훌륭한 개요를 제공하며, GPU의 주요 성능 카운터를 시각화하는 그래프를 보여줍니다.

이 카운터들 중 다수는 활용도와 제한 값을 모두 제공한다.

여기서 ALU를 예로 들자면, 활용 번호는 커널이 실행 중에 GPU의 ALU 기능의 약 27%를 사용했다고 말하고 있다.

다른 시간은 데이터 읽기 및 쓰기, 제어 논리 결정 등과 같은 다른 작업을 수행하는 데 소비되었다.

리미터 수치는 GPU가 커널 실행 시간의 약 31% 동안 ALU 활용에 의해 병목 현상이 있음을 의미합니다.

그렇다면 어떻게 GPU가 GPU의 ALU 기능의 27%를 활용하지만 31% 동안 ALU에 의해 병목될 수 있을까요?

제한기는 완료된 ALU 작업의 효율성으로 생각할 수 있다.

그것은 실제 일을 하는 데 소요되는 시간과 내부 노점이나 비효율성에 소요되는 시간이다.

가장 좋은 경우, 이 시간은 동일하지만, 실제로는 차이가 있다.

큰 차이는 GPU가 해야 할 일이 있지만, 어떤 이유로 그것을 할 수 없다는 것을 나타낸다.

예를 들어 log()와 같은 복잡한 ALU 작업이나 값비싼 텍스처 형식을 사용하면 활용도가 부족할 수 있으며, 커널의 수학을 최적화할 수 있는 범위가 있을 수 있음을 나타냅니다.

이 두 인물은 당신의 커널이 수행하고 있는 작업의 일반적인 구성과 각 범주의 작업이 얼마나 효율적인지 이해하는 데 도움을 주기 위해 손을 잡고 일합니다.

이 특정 커널을 통해, 우리는 점유율이 37%라는 것을 알 수 있다.

이 가치는 낮아 보이고 그것이 증가할 수 있는지 이해하기 위해 확실히 조사할 가치가 있다.

점유에 대해 좀 더 자세히 살펴봅시다.

그것은 가능한 최대치에 비해 현재 GPU에서 활성화된 스레드 수의 척도이다.

이 수치가 낮을 때, 이유를 이해하고, 이것이 예상되는지 아니면 문제를 의미하는지 결정하는 것이 중요하다.

예를 들어, 제출할 작업이 수행해야 할 작업이 단순히 작기 때문에 스레드 수가 비교적 적은 경우, 낮은 점유율은 때때로 놀랍거나 피할 수 없습니다.

GPU가 ALU와 같은 다른 카운터에 의해 제한된다면 괜찮을 수도 있다.

그러나 낮은 리미터 카운터와 결합된 낮은 점유율은 GPU가 더 많은 스레드를 동시에 실행할 수 있는 능력을 가지고 있음을 의미한다.

그래서 무엇이 문제가 되는 낮은 점유율을 일으킬 수 있을까요?

이것에 대한 일반적인 이유는 스레드 또는 스레드 그룹 메모리를 소모하는 것이다.

이 두 리소스 모두 GPU에서 유한하며 실행 중인 스레드 간에 공유됩니다.

스레드 메모리는 레지스터에 의해 뒷받침되며, 레지스터에 대한 압력이 증가함에 따라 수용 인원을 줄일 수 있습니다.

스레드 그룹 메모리 사용량이 높기 때문에, 점유율을 늘리는 유일한 방법은 사용되는 공유 메모리의 양을 줄이는 것이다.

탈라드 그룹 메모리를 줄이는 것은 또한 스레드 레지스터 압력의 영향을 줄이는 데 도움이 될 수 있다.

파이프라인 상태 생성 시간에 스레드 그룹의 최대 스레드 수가 알려질 때 컴파일러가 레지스터를 더 효율적으로 유출할 수 있는 범위가 있다.

이러한 최적화는 컴퓨팅 파이프라인 상태 설명자에 maxThreadsPerThreadgroup을 설정하거나 커널 소스에서 직접 Metal Shader langauge max_total_threads_per threadgroup 속성을 사용하여 활성화할 수 있습니다.

커널에 가장 적합한 균형을 찾기 위해 이 값을 조정하세요.

알고리즘에 맞는 스레드 실행 너비의 가장 작은 배수인 값을 목표로 하세요.

등록 압력에 더 깊이 들어가자.

이것이 높을 때, 우리는 Xcode의 GPU 프로파일러에서 레지스터 유출을 보게 될 것이다.

이 커널 예시를 통해, 우리는 우리의 점유율이 16퍼센트라는 것을 알 수 있으며, 이것은 정말 낮다.

이 커널의 컴파일러 통계를 보면 유출된 바이트를 포함하여 상대적인 명령 비용을 알 수 있다.

이 유출은, 임시 등록부와 함께, 우리의 빈약한 점유의 원인일 가능성이 높다.

우리는 스레드 메모리를 소진하고 있으며, 실행될 스레드에 대한 더 많은 레지스터를 확보하기 위해 점유가 줄어듭니다.

레지스터는 레지스터 블록의 커널에 할당되며, 따라서 점유의 잠재적 증가를 보려면 블록 크기까지 사용량을 줄여야 합니다.

최소한의 레지스터 사용을 최적화하는 것은 복잡한 커널에 영향을 미치는 성능 개선을 할 수 있는 좋은 방법이지만, 어떻게 해야 할까요?

32비트 유형보다 16비트 유형을 선호하면 커널의 다른 부분에서 사용할 수 있는 레지스터 수가 증가합니다.

이러한 유형을 32비트로 변환하는 것은 보통 무료입니다.

그리고 스택에 저장된 데이터(예를 들어, 큰 배열이나 구조체)를 줄이는 것은 많은 수의 레지스터를 소비할 수 있으며 이를 줄이는 것이 효과적인 도구이다.

일정한 주소 공간을 최대한 활용하기 위해 셰이더 입력을 조정하세요.

이것은 불필요하게 사용되는 범용 레지스터의 수를 크게 줄일 수 있다.

그리고 마지막 팁은 스택에 저장된 배열이나 동적 인덱스가 있는 상수 데이터로 인덱싱하는 것을 피하는 것이다.

이것의 예는 런타임에 배열이 초기화되는 여기에 표시됩니다.

컴파일 타임에 컴파일러가 인덱스를 알지 못한다면, 배열은 메모리로 유출될 가능성이 높다.

하지만 이 두 번째 예에서 인덱스는 컴파일 타임에 알려져 있으며, 컴파일러는 루프를 풀고 유출을 최적화할 수 있을 것이다.

이러한 각 기술은 레지스터 할당을 줄이고, 유출을 줄이며, 더 성능이 뛰어난 커널의 점유율을 높이는 데 도움이 될 것이다.

Apple Silicon의 금속 최적화 기술에 대한 더 많은 통찰력을 얻으려면 WWDC 2020 비디오인 "Apple Silicon Mac을 위한 금속 성능 최적화"를 시청하세요.

그리고 거기에 네가 있어.

오늘 우리가 다룬 것을 검토해 봅시다.

우리는 명령 대기열, 명령 버퍼 및 명령 인코더의 역할에 대한 검토를 시작하여 제출 모델과 작업이 Metal의 GPU에 대기하는 방법에 대해 상기시키고, CPU 인코딩 시간과 비용을 줄이기 위해 여러 스레드에서 Metal 명령을 인코딩하는 방법을 탐구했습니다.

그 지식으로, 우리는 응용 프로그램을 조정하는 방법에 대한 권장 사항을 살펴보았습니다. 통합 메모리 아키텍처를 활용하기 위해 불필요한 복사본을 피하고, 더 많은 양의 작업을 제출하고, 커널 리소스에 금속 텍스처와 금속 버퍼를 사용했습니다.

그리고 마지막으로, 우리는 성능 병목 현상을 식별하기 위해 도구를 사용하는 방법을 살펴봤다.

우리는 GPU의 활용도와 제한기 값을 해석하는 방법과, 우리가 그것을 발견하면 문제가 있는 낮은 점유율을 어떻게 해결할 수 있는지 이해했다.

정말 감사합니다, 그리고 저는 당신이 가장 강력한 맥북 프로 라인업으로 가능한 것에 대해 나만큼 흥분하기를 바랍니다.