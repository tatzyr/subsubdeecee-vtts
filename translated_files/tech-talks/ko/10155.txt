10155

안녕. 저는 Create ML 팀의 엔지니어인 Shreya Jain입니다.

오늘 우리는 물체 감지 템플릿의 개선 사항을 탐구하고 더 나은 모델을 만들기 위해 그것들을 활용할 것입니다.

Create ML의 객체 감지에 익숙하지 않다면, WWDC 2019에서 이 비디오를 보는 것이 좋습니다.

물체 감지는 매력적인 앱 경험을 가능하게 할 수 있다.

사람들이 쓰레기를 분류하고, 애완 고양이의 가상 안경을 사용해 볼 수 있도록 앱을 만들 수 있습니다...

그리고 심지어 감지된 재료를 기반으로 레시피를 추천할 수 있는 앱도 있습니다.

이 앱의 모델을 구축하는 것은 Create ML과 새로운 기능을 실제로 볼 수 있는 좋은 방법입니다.

물체 탐지에 상당한 개선이 이루어졌다.

더 적은 훈련 데이터로 정확하고 작은 모델을 훈련하고 더 많은 구성 옵션을 노출하여 훈련을 사용자 정의할 수 있습니다.

그러니까 바로 뛰어들자.

시작하려면, Spotlight에서 Create ML 앱을 열겠습니다.

내가 가장 먼저 보는 것은 개체 감지를 선택할 템플릿 선택기이다.

이것은 Create ML 프로젝트에 대한 세부 사항을 입력하기 위한 대화 상자를 엽니다.

이 프로젝트의 이름을 "FindMyRecipe"로 지정하고 재료를 감지하는 데 도움이 되는 설명을 추가하겠습니다.

나는 그것을 만들기 전에 프로젝트의 위치를 바꿀 수 있다.

다음으로, 나는 설정 탭에 착륙한다.

데이터와 구성 옵션은 훈련 전에 여기에서 조정할 수 있습니다.

데이터를 로드하기 전에, 이 데이터가 어떻게 준비되는지 안내해 드리겠습니다.

객체 감지 데이터는 모든 훈련 이미지와 JSON 파일의 주석이 포함된 폴더에 저장되어야 합니다.

Annotations.json의 내용은 빵 한 조각과 토마토라는 두 가지 물체가 있는 이 이미지를 예로 들어 이해할 수 있다.

각 개체 주석은 개체의 라벨과 이미지의 위치로 구성됩니다.

위치는 이미지의 왼쪽 상단 모서리를 기반으로 합니다.

훈련 데이터 이미지의 모든 물체는 이런 식으로 주석을 달 수 있다.

이 모든 주석은 이 형식의 단일 JSON 파일에 추가됩니다.

나는 훈련 데이터를 준비하기 위해 이 정보를 사용할 것이다.

데이터가 준비되면, Create ML 앱에서 로드할 수 있습니다.

보기 버튼을 클릭하면 내 데이터 세트의 클래스 분포가 표시됩니다.

보시다시피, 제 수업은 토마토, 치즈, 빵, 바질입니다.

설정 탭으로 돌아가면, 모델이 보이지 않는 데이터에서 잘 작동할 수 있도록 검증 데이터를 선택적으로 제공할 수 있습니다.

여기서, 나는 유효성 검사 데이터를 자동으로 설정하여 Create ML이 내 데이터 세트의 작은 부분을 사용할 수 있도록 했다.

모델의 훈련을 더 잘 제어할 수 있는 새로운 훈련 매개 변수도 있습니다.

그것들은 알고리즘, 반복, 배치 크기 및 그리드 크기이다.

훈련을 위한 두 가지 알고리즘이 있다.

첫 번째는 전체 네트워크이다.

전체 네트워크 알고리즘을 더 자세히 살펴봅시다.

전체 네트워크는 2019년에 Create ML에 도입되었으며 그 이후로 기본 훈련 알고리즘이었다.

이 알고리즘은 YOLOv2 아키텍처를 기반으로 한다.

이 네트워크의 모든 매개 변수는 당신의 데이터를 사용하여 훈련됩니다.

결과 코어 ML 모델은 학습된 모든 매개 변수를 인코딩합니다.

이 코어 ML 모델은 16비트 정밀도로 가중치를 저장하도록 양자화되었다.

결과 모델 크기는 우리가 이전에 얻은 것의 절반이다.

그래서 이전에 약 65메가바이트였던 모델은 이제 33메가바이트가 될 것이다.

이 알고리즘은 수업당 200개 이상의 경계 상자와 같은 많은 양의 훈련 데이터가 있을 때 권장됩니다.

결과 모델은 이전 버전과 호환되며, iOS 12로 거슬러 올라간다.

우리는 당신이 더 적은 훈련 데이터로 매우 정확한 모델을 구축할 수 있도록 하고 싶었기 때문에 물체 감지를 위한 전송 학습 알고리즘을 도입하고 있습니다.

전송 학습은 이미 운영 체제에 있는 기계 학습 모델을 활용한다.

예를 들어, 사진 앱에는 검색과 추억을 지원하는 모델이 포함되어 있습니다.

포토가 사용하는 사전 훈련된 백본 중 하나는 오브젝트 프린트라고 불린다.

이것은 엄청난 양의 다양한 데이터에 대해 훈련되었다.

전송 학습을 통해, 이를 활용하여 데이터 요구 사항을 줄일 수 있습니다.

Create ML의 전송 학습 알고리즘은 헤드 네트워크와 함께 객체 인쇄를 사용합니다.

헤드 네트워크만이 당신의 데이터에 대해 훈련되어, 배워야 할 매개 변수의 수를 줄입니다.

결과적으로, 코어 ML 모델에는 헤드 네트워크 매개 변수만 포함되어 있어 모델이 전체 네트워크보다 5배 더 작습니다.

2019년에 65메가바이트와 양자화 후 33메가바이트였던 동일한 모델은 전송 학습 알고리즘을 사용하여 7메가바이트에 불과할 것이다.

전송 학습은 데이터가 제한되어 있고 가벼운 모델을 원할 때 훌륭한 옵션입니다.

그것은 수업당 80개의 훈련 예시로 잘 한다.

결과 모델은 OS와 함께 제공된 개체 인쇄를 활용하기 위해 iOS 14가 필요합니다.

알고리즘은 새로운 구성 중 하나일 뿐이다.

반복과 배치 크기와 같은 매개 변수도 추가되었습니다.

반복은 모델의 매개 변수가 업데이트되는 횟수이다.

기본값은 데이터 세트 크기에 따라 선택됩니다.

특정 사용 사례의 경우, 모델이 아직 수렴되지 않은 경우 반복을 늘리거나 모델이 일찍 잘 수행되면 줄일 수 있습니다.

배치 크기는 한 번의 반복에서 사용되는 훈련 예제의 수를 나타낸다.

기본값은 하드웨어 제한에 따라 선택됩니다.

더 높은 배치 크기가 더 좋지만, 기본값을 사용하거나 성능 제한에 따라 줄일 수 있습니다.

마지막으로, 전체 네트워크의 경우, 그리드 크기를 사용자 정의할 수 있습니다.

그리드 크기를 이해하려면 전체 네트워크에 대한 예측이 어떻게 작동하는지에 대한 지식이 필요합니다.

좀 더 자세히 살펴보자.

이 입력 이미지로 시작해서...

그것을 훈련된 전체 네트워크 모델로 전달하기...

경계 상자가 있는 많은 예측된 물체를 초래한다.

이미지에서 물체를 찾기 위해, 모델은 그리드와 앵커 박스 세트를 활용한다.

지정된 그리드는 입력 이미지의 종횡비와 모델이 감지된 물체를 찾을 위치를 정의합니다.

예를 들어, 모델이 5x5의 그리드 차원으로 어떻게 동작할지 봅시다.

이미지는 그리드에 맞게 크기가 조정됩니다. 이 경우 정사각형 이미지로 조정된 다음 정의된 수의 셀로 나뉩니다.

그런 다음 네트워크는 각 그리드 셀에 대해 하나씩 예측을 생성합니다.

각 예측에는 다음과 같은 정보가 포함되어 있습니다: 셀에 객체가 있는지 여부, 객체의 클래스 및 경계 상자.

YOLO는 각 물체가 하나의 격자 셀과 연결된 여러 물체에서 잘 작동합니다.

이 이미지에서 볼 수 있듯이, 바나나와 개의 중심은 같은 세포에 떨어진다.

각 세포는 하나의 클래스만 예측할 수 있기 때문에, 바나나나 개를 골라야 한다.

바나나와 개를 모두 예측하기 위해, 앵커 박스가 정의된다.

앵커 박스는 종횡비가 설정되어 있으며 그리드 셀 내에서 여러 물체를 감지합니다.

Create ML은 총 169개의 셀인 13x13의 기본 그리드 차원을 사용합니다.

다양한 종횡비의 15개의 앵커 박스 세트가 각 셀에 대해 평가됩니다.

따라서, 기본 모델은 이미지당 총 2,535개의 예측을 하고 있다.

이 주사위 이미지와 물체 감지가 3-x3의 그리드 차원에서 어떻게 작동하는지 고려하십시오.

비슷한 종횡비의 여러 주사위가 단일 셀에 존재하기 때문에, 그 중 하나만 감지될 것이다.

큰 격자 크기로, 더 많은 주사위가 감지된다.

그러나, 이것은 이미지당 예측의 수를 증가시킬 것이다.

그리드 크기를 변경할 때 계산 비용을 고려하는 것이 중요하다.

1500 x 800 크기의 비 정사각형 입력 이미지의 경우, 이 이미지에 8 x 8 그리드를 사용하면 정보가 손실되고 물체의 자연스러운 모양이 왜곡됩니다.

이것은 모델이 훈련하는 동안 더 미세한 입자 패턴을 포착하는 것을 방지하고 예측력을 방해한다.

15-x-8의 그리드 크기를 선택하면 입력 이미지의 원래 종횡비를 보존하고 더 많은 정보를 배우고 더 나은 결과를 제공할 수 있는 모델이 됩니다.

FindMyRecipe 프로젝트의 모델 훈련으로 돌아가서, 전송 학습 알고리즘을 선택하고, 1000번의 반복을 설정하고, 배치 크기에 대한 자동을 설정할 수 있습니다.

재생 버튼을 클릭하면, 모델이 훈련을 시작합니다.

교육 탭은 배치가 준비되고 있음을 보여준다.

이 단계는 실제 데이터에 대한 견고성과 일반화를 돕기 위해 일련의 표준 이미지 증강을 수행합니다.

곧, 각 반복에 대한 손실 값을 플로팅하는 그래프가 나타난다.

교육이 진행됨에 따라, 스냅샷 버튼을 클릭하여 그 당시 모델을 얻을 수 있습니다.

스냅샷은 훈련 진행 상황을 확인하는 데 도움이 된다.

이 모델을 사용하여 몇 개의 이미지에 대한 예측을 미리 볼 수 있습니다.

모든 이미지에 대해, 모델 예측은 미리보기 탭에 표시됩니다.

하단의 각 수업에 대한 자신감을 보려면 이 경계 상자를 클릭할 수 있습니다.

스냅샷은 또한 앱 내에서 실험하는 데 사용될 수 있다.

교육이 완료된 후, 교육 및 검증 데이터에 대한 평가 지표는 평가 탭에서 볼 수 있습니다.

이 숫자들은 무슨 뜻이야?

물체 감지 모델에 대한 평가는 두 배가 되어야 한다.

우리는 올바른 라벨을 원할 뿐만 아니라, 올바른 위치에 있어야 한다.

경계 상자를 주석이 달린 상자와 정확히 일치하도록 하는 것은 어렵다.

예측된 상자가 주석이 달린 상자에 얼마나 가까운지 포착하는 숫자가 필요하다.

이것은 intersection-over-union이라고 불리는 점수로 측정된다.

그것은 겹치지 않는 0% 사이의 값이다...

100%까지, 이는 완벽한 중복이다.

예측이 올바른 것으로 간주되려면, 올바른 클래스 라벨과 미리 정의된 임계값보다 큰 교차 교차 유니온 점수가 있어야 합니다.

교차로 오버 유니온 점수가 임계값보다 작거나 예측된 클래스가 올바르지 않다면, 전반적인 예측은 올바르지 않습니다.

이 정보는 평균 평균 정밀도 또는 mAP라는 메트릭을 계산하는 데 사용됩니다.

나는 이 숫자들을 보기 위해 평가 탭으로 돌아갈 것이다.

이 숫자들은 두 개의 임계값으로 계산된 클래스당 평균 정밀도를 나타낸다.

하나는 50%로 고정되어 있고 다른 하나는 여러 임계값으로 다양하다.

데이터 세트의 전체 평균 평균 정밀도는 오른쪽 상단 모서리에서 볼 수 있습니다.

더 높은 mAP는 더 정확한 예측을 반영한다.

우리 모델의 mAP는 전반적으로 좋아 보인다.

모델 예측이 올바르게 보이는지 확인하기 위해 몇 가지 예제에서 모델을 미리 볼 것입니다.

모든 게 좋아 보여.

이제 이 모델을 우리 앱에 넣을 수 있습니다.

방금 본 추가 기능으로, Create ML을 사용하여 객체 감지 모델을 만드는 것은 간단합니다.

Create ML은 교육에 대한 더 많은 제어를 제공하여 모델을 사용자 정의할 수 있도록 도와줍니다.

더 적은 데이터와 더 작은 출력 크기로 정확한 모델을 만드는 데 도움을 줍니다.

우리는 당신이 이 새로운 기능을 사용하여 테이블에 가져오는 멋진 아이디어를 빨리 보고 싶습니다.